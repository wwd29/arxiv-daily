<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-04</h1>
<h3>Title: Leveraging Large Language Models to Enhance Machine Learning Interpretability and Predictive Performance: A Case Study on Emergency Department Returns for Mental Health Patients</h3>
<ul>
<li><strong>Authors: </strong>Abdulaziz Ahmed, Mohammad Saleem, Mohammed Alzeen, Badari Birur, Rachel E Fargason, Bradley G Burk, Hannah Rose Harkins, Ahmed Alhassan, Mohammed Ali Al-Garadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00025">https://arxiv.org/abs/2502.00025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00025">https://arxiv.org/pdf/2502.00025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00025]] Leveraging Large Language Models to Enhance Machine Learning Interpretability and Predictive Performance: A Case Study on Emergency Department Returns for Mental Health Patients(https://arxiv.org/abs/2502.00025)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Objective: To evaluate whether integrating large language models (LLMs) with traditional machine learning approaches improves both the predictive accuracy and clinical interpretability of ED mental health returns risk models. Methods: This retrospective cohort study analyzed 42,464 ED visits for 27,904 unique mental health patients at an Academic Medical Center in the deep South of the United States between January 2018 and December 2022. Main Outcomes and Measures: Two primary outcomes were evaluated: (1) 30 days ED return prediction accuracy and (2) model interpretability through a novel retrieval-augmented generation (RAG) framework integrating SHAP (SHapley Additive exPlanations) values with contextual clinical knowledge. Results: The proposed machine learning interpretability framework, leveraging LLM, achieved 99% accuracy in translating complex model predictions into clinically relevant explanations. Integration of LLM-extracted features enhanced predictive performance, improving the XGBoost model area under the curve (AUC) from 0.73 to 0.76. The LLM-based feature extraction using 10-shot learning significantly outperformed traditional approaches, achieving an accuracy of 0.882 and an F1 score of 0.86 for chief complaint classification (compared to conventional methods with an accuracy range of 0.59 to 0.63) and demonstrating accuracy values ranging from 0.65 to 0.93 across multiple SDoH categories, underscoring its robust performance in extracting features from clinical notes. Conclusions and Relevance: Integrating LLMs with traditional machine learning models yielded modest but consistent improvements in ED return prediction accuracy while substantially enhancing model interpretability through automated, clinically relevant explanations. This approach offers a framework for translating complex predictive analytics into actionable clinical insights.</li>
</ul>

<h3>Title: Safeguarding the Future of Mobility: Cybersecurity Issues and Solutions for Infrastructure Associated with Electric Vehicle Charging</h3>
<ul>
<li><strong>Authors: </strong>Md Rakibul Karim Akanda, Joao Raimundo Queiroz Pires Santana De Oliveira Lima, Amaya Alexandria Holmes, Christina Bonner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00035">https://arxiv.org/abs/2502.00035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00035">https://arxiv.org/pdf/2502.00035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00035]] Safeguarding the Future of Mobility: Cybersecurity Issues and Solutions for Infrastructure Associated with Electric Vehicle Charging(https://arxiv.org/abs/2502.00035)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The development of an ecosystem that balances consumer convenience and security is imperative given the expanding market for electric vehicles (EVs). The vast amount of data that EV charging station management systems (EVCSMSs) give is powered by the Internet of Things (IoT) ecosystem. Intrusion Detection Systems (IDSs), which track network traffic to spot potentially dangerous data exchanges in IT and IoT contexts, are constantly improving in terms of efficacy and accuracy. Intrusion detection is becoming a major topic in academia because of the acceleration of IDS development caused by machine learning and deep learning techniques. The goal of the research presented in this paper is to use a machine-learning-based intrusion detection system with low false-positive rates and high accuracy to safeguard the ecosystem of EV charging stations (EVCS).</li>
</ul>

<h3>Title: Efficient Client Selection in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>William Marfo, Deepak K. Tosh, Shirley V. Moore</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00036">https://arxiv.org/abs/2502.00036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00036">https://arxiv.org/pdf/2502.00036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00036]] Efficient Client Selection in Federated Learning(https://arxiv.org/abs/2502.00036)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables decentralized machine learning while preserving data privacy. This paper proposes a novel client selection framework that integrates differential privacy and fault tolerance. The adaptive client selection adjusts the number of clients based on performance and system constraints, with noise added to protect privacy. Evaluated on the UNSW-NB15 and ROAD datasets for network anomaly detection, the method improves accuracy by 7% and reduces training time by 25% compared to baselines. Fault tolerance enhances robustness with minimal performance trade-offs.</li>
</ul>

<h3>Title: Optimization Strategies for Enhancing Resource Efficiency in Transformers & Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tom Wallace, Naser Ezzati-Jivan, Beatrice Ombuki-Berman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00046">https://arxiv.org/abs/2502.00046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00046">https://arxiv.org/pdf/2502.00046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00046]] Optimization Strategies for Enhancing Resource Efficiency in Transformers & Large Language Models(https://arxiv.org/abs/2502.00046)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Advancements in Natural Language Processing are heavily reliant on the Transformer architecture, whose improvements come at substantial resource costs due to ever-growing model sizes. This study explores optimization techniques, including Quantization, Knowledge Distillation, and Pruning, focusing on energy and computational efficiency while retaining performance. Among standalone methods, 4-bit Quantization significantly reduces energy use with minimal accuracy loss. Hybrid approaches, like NVIDIA's Minitron approach combining KD and Structured Pruning, further demonstrate promising trade-offs between size reduction and accuracy retention. A novel optimization equation is introduced, offering a flexible framework for comparing various methods. Through the investigation of these compression methods, we provide valuable insights for developing more sustainable and efficient LLMs, shining a light on the often-ignored concern of energy efficiency.</li>
</ul>

<h3>Title: Contextually Entangled Gradient Mapping for Optimized LLM Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Colin Sisate, Alistair Goldfinch, Vincent Waterstone, Sebastian Kingsley, Mariana Blackthorn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00048">https://arxiv.org/abs/2502.00048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00048">https://arxiv.org/pdf/2502.00048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00048]] Contextually Entangled Gradient Mapping for Optimized LLM Comprehension(https://arxiv.org/abs/2502.00048)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Contextually Entangled Gradient Mapping (CEGM) introduces a new approach to gradient optimization, redefining the relationship between contextual embeddings and gradient updates to enhance semantic coherence and reasoning capabilities in neural architectures. By treating gradients as dynamic carriers of contextual dependencies rather than isolated numerical entities, the proposed methodology bridges critical gaps in existing optimization strategies. The integration of entangled gradient dynamics into a loss regularization framework demonstrated significant improvements in tasks involving long-form reasoning, contextual retention, and adaptability to unseen domains. Experimental evaluations showed that the CEGM-enhanced model consistently outperformed baseline approaches, achieving higher accuracy in token-level predictions and greater resilience to noisy inputs. Practical implementations involved modifications to training pipelines, introducing entanglement layers and dynamic coefficient adjustments that seamlessly align with existing architectures. Results further highlighted reductions in semantic drift during sequential transformations and improvements in embedding coherence across paraphrased sentences, showing the robustness and versatility of the proposed methodology. The findings demonstrate the broader implications of gradient entanglement for both theoretical advancements and practical applications in optimization strategies.</li>
</ul>

<h3>Title: Large Language Models are Few-shot Multivariate Time Series Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Yakun Chen, Zihao Li, Chao Yang, Xianzhi Wang, Guandong Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00059">https://arxiv.org/abs/2502.00059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00059">https://arxiv.org/pdf/2502.00059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00059]] Large Language Models are Few-shot Multivariate Time Series Classifiers(https://arxiv.org/abs/2502.00059)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been extensively applied in time series analysis. Yet, their utility in the few-shot classification (i.e., a crucial training scenario due to the limited training data available in industrial applications) concerning multivariate time series data remains underexplored. We aim to leverage the extensive pre-trained knowledge in LLMs to overcome the data scarcity problem within multivariate time series. Specifically, we propose LLMFew, an LLM-enhanced framework to investigate the feasibility and capacity of LLMs for few-shot multivariate time series classification. This model introduces a Patch-wise Temporal Convolution Encoder (PTCEnc) to align time series data with the textual embedding input of LLMs. We further fine-tune the pre-trained LLM decoder with Low-rank Adaptations (LoRA) to enhance its feature representation learning ability in time series data. Experimental results show that our model outperformed state-of-the-art baselines by a large margin, achieving 125.2% and 50.2% improvement in classification accuracy on Handwriting and EthanolConcentration datasets, respectively. Moreover, our experimental results demonstrate that LLM-based methods perform well across a variety of datasets in few-shot MTSC, delivering reliable results compared to traditional models. This success paves the way for their deployment in industrial environments where data are limited.</li>
</ul>

<h3>Title: From Data to Action: Charting A Data-Driven Path to Combat Antimicrobial Resistance</h3>
<ul>
<li><strong>Authors: </strong>Qian Fu, Yuzhe Zhang, Yanfeng Shu, Ming Ding, Lina Yao, Chen Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.PE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00061">https://arxiv.org/abs/2502.00061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00061">https://arxiv.org/pdf/2502.00061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00061]] From Data to Action: Charting A Data-Driven Path to Combat Antimicrobial Resistance(https://arxiv.org/abs/2502.00061)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Antimicrobial-resistant (AMR) microbes are a growing challenge in healthcare, rendering modern medicines ineffective. AMR arises from antibiotic production and bacterial evolution, but quantifying its transmission remains difficult. With increasing AMR-related data, data-driven methods offer promising insights into its causes and treatments. This paper reviews AMR research from a data analytics and machine learning perspective, summarizing the state-of-the-art and exploring key areas such as surveillance, prediction, drug discovery, stewardship, and driver analysis. It discusses data sources, methods, and challenges, emphasizing standardization and interoperability. Additionally, it surveys statistical and machine learning techniques for AMR analysis, addressing issues like data noise and bias. Strategies for denoising and debiasing are highlighted to enhance fairness and robustness in AMR research. The paper underscores the importance of interdisciplinary collaboration and awareness of data challenges in advancing AMR research, pointing to future directions for innovation and improved methodologies.</li>
</ul>

<h3>Title: A Multi-Layered Large Language Model Framework for Disease Prediction</h3>
<ul>
<li><strong>Authors: </strong>Malak Mohamed, Rokaia Emad, Ali Hamdi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00063">https://arxiv.org/abs/2502.00063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00063">https://arxiv.org/pdf/2502.00063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00063]] A Multi-Layered Large Language Model Framework for Disease Prediction(https://arxiv.org/abs/2502.00063)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Social telehealth has revolutionized healthcare by enabling patients to share symptoms and receive medical consultations remotely. Users frequently post symptoms on social media and online health platforms, generating a vast repository of medical data that can be leveraged for disease classification and symptom severity assessment. Large language models (LLMs), such as LLAMA3, GPT-3.5 Turbo, and BERT, process complex medical data to enhance disease classification. This study explores three Arabic medical text preprocessing techniques: text summarization, text refinement, and Named Entity Recognition (NER). Evaluating CAMeL-BERT, AraBERT, and Asafaya-BERT with LoRA, the best performance was achieved using CAMeL-BERT with NER-augmented text (83% type classification, 69% severity assessment). Non-fine-tuned models performed poorly (13%-20% type classification, 40%-49% severity assessment). Integrating LLMs into social telehealth systems enhances diagnostic accuracy and treatment outcomes.</li>
</ul>

<h3>Title: Evaluating Large Language Models in Vulnerability Detection Under Variable Context Windows</h3>
<ul>
<li><strong>Authors: </strong>Jie Lin, David Mohaisen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00064">https://arxiv.org/abs/2502.00064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00064">https://arxiv.org/pdf/2502.00064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00064]] Evaluating Large Language Models in Vulnerability Detection Under Variable Context Windows(https://arxiv.org/abs/2502.00064)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This study examines the impact of tokenized Java code length on the accuracy and explicitness of ten major LLMs in vulnerability detection. Using chi-square tests and known ground truth, we found inconsistencies across models: some, like GPT-4, Mistral, and Mixtral, showed robustness, while others exhibited a significant link between tokenized length and performance. We recommend future LLM development focus on minimizing the influence of input length for better vulnerability detection. Additionally, preprocessing techniques that reduce token count while preserving code structure could enhance LLM accuracy and explicitness in these tasks.</li>
</ul>

<h3>Title: Decoding User Concerns in AI Health Chatbots: An Exploration of Security and Privacy in App Reviews</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Hassan, Abdullah Ghani, Muhammad Fareed Zaffar, Masooda Bashir</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00067">https://arxiv.org/abs/2502.00067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00067">https://arxiv.org/pdf/2502.00067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00067]] Decoding User Concerns in AI Health Chatbots: An Exploration of Security and Privacy in App Reviews(https://arxiv.org/abs/2502.00067)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>AI powered health chatbot applications are increasingly utilized for personalized healthcare services, yet they pose significant challenges related to user data security and privacy. This study evaluates the effectiveness of automated methods, specifically BART and Gemini GenAI, in identifying security privacy related (SPR) concerns within these applications' user reviews, benchmarking their performance against manual qualitative analysis. Our results indicate that while Gemini's performance in SPR classification is comparable to manual labeling, both automated methods have limitations, including the misclassification of unrelated issues. Qualitative analysis revealed critical user concerns, such as data collection practices, data misuse, and insufficient transparency and consent mechanisms. This research enhances the understanding of the relationship between user trust, privacy, and emerging mobile AI health chatbot technologies, offering actionable insights for improving security and privacy practices in AI driven health chatbots. Although exploratory, our findings highlight the necessity for rigorous audits and transparent communication strategies, providing valuable guidance for app developers and vendors in addressing user security and privacy concerns.</li>
</ul>

<h3>Title: Privacy Preserving Charge Location Prediction for Electric Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Robert Marlin, Raja Jurdak, Alsharif Abuadbba, Dimity Miller</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00068">https://arxiv.org/abs/2502.00068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00068">https://arxiv.org/pdf/2502.00068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00068]] Privacy Preserving Charge Location Prediction for Electric Vehicles(https://arxiv.org/abs/2502.00068)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, transformer</a></li>
<li><strong>Abstract: </strong>By 2050, electric vehicles (EVs) are projected to account for 70% of global vehicle sales. While EVs provide environmental benefits, they also pose challenges for energy generation, grid infrastructure, and data privacy. Current research on EV routing and charge management often overlooks privacy when predicting energy demands, leaving sensitive mobility data vulnerable. To address this, we developed a Federated Learning Transformer Network (FLTN) to predict EVs' next charge location with enhanced privacy measures. Each EV operates as a client, training an onboard FLTN model that shares only model weights, not raw data with a community-based Distributed Energy Resource Management System (DERMS), which aggregates them into a community global model. To further enhance privacy, non-transitory EVs use peer-to-peer weight sharing and augmentation within their community, obfuscating individual contributions and improving model accuracy. Community DERMS global model weights are then redistributed to EVs for continuous training. Our FLTN approach achieved up to 92% accuracy while preserving data privacy, compared to our baseline centralised model, which achieved 98% accuracy with no data privacy. Simulations conducted across diverse charge levels confirm the FLTN's ability to forecast energy demands over extended periods. We present a privacy-focused solution for forecasting EV charge location prediction, effectively mitigating data leakage risks.</li>
</ul>

<h3>Title: Large Capacity Data Hiding in Binary Image black and white mixed regions</h3>
<ul>
<li><strong>Authors: </strong>Yuanlin Yang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00069">https://arxiv.org/abs/2502.00069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00069">https://arxiv.org/pdf/2502.00069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00069]] Large Capacity Data Hiding in Binary Image black and white mixed regions(https://arxiv.org/abs/2502.00069)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>Information hiding technology utilizes the insensitivity of human sensory organs to redundant data, hiding confidential information in the redundant data of these public digital media, and then transmitting it. The carrier media after hiding secret information only displays its own characteristics, which can ensure the transmission of confidential information without being detected, thereby greatly improving the security of the information. In theory, any digital media including image, video, audio, and text can serve as a host carrier. Among them, hiding information in binary images poses great challenges. As we know, any information hiding method involves modifying the data of the host carrier. The more information hidden, the more data of the host carrier are modified. In this paper, we propose information hiding in the black-and-white mixed region of binary images, which can greatly reduce visual distortion. In addition, we propose an efficient encoding to achieve high-capacity information hiding while ensuring image semantics. By selecting binary images of different themes, we conduct experiments. The experimental results prove the feasibility of our technique and verify the expected performance. Since the candidate units for information hiding are selected from equally sized blocks that the image is divided into, and the hiding and extraction of information are based on a shared encoding table, the computational cost is very low, making it suitable for real-time information hiding applications.</li>
</ul>

<h3>Title: LLM Cyber Evaluations Don't Capture Real-World Risk</h3>
<ul>
<li><strong>Authors: </strong>Kamilė Lukošiūtė, Adam Swanda</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00072">https://arxiv.org/abs/2502.00072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00072">https://arxiv.org/pdf/2502.00072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00072]] LLM Cyber Evaluations Don't Capture Real-World Risk(https://arxiv.org/abs/2502.00072)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are demonstrating increasing prowess in cybersecurity applications, creating creating inherent risks alongside their potential for strengthening defenses. In this position paper, we argue that current efforts to evaluate risks posed by these capabilities are misaligned with the goal of understanding real-world impact. Evaluating LLM cybersecurity risk requires more than just measuring model capabilities -- it demands a comprehensive risk assessment that incorporates analysis of threat actor adoption behavior and potential for impact. We propose a risk assessment framework for LLM cyber capabilities and apply it to a case study of language models used as cybersecurity assistants. Our evaluation of frontier models reveals high compliance rates but moderate accuracy on realistic cyber assistance tasks. However, our framework suggests that this particular use case presents only moderate risk due to limited operational advantages and impact potential. Based on these findings, we recommend several improvements to align research priorities with real-world impact assessment, including closer academia-industry collaboration, more realistic modeling of attacker behavior, and inclusion of economic metrics in evaluations. This work represents an important step toward more effective assessment and mitigation of LLM-enabled cybersecurity risks.</li>
</ul>

<h3>Title: BTS: Harmonizing Specialized Experts into a Generalist LLM</h3>
<ul>
<li><strong>Authors: </strong>Qizhen Zhang, Prajjwal Bhargava, Chloe Bi, Chris X. Cai, Jakob Foerster, Jeremy Fu, Punit Singh Koura, Ruan Silva, Sheng Shen, Emily Dinan, Suchin Gururangan, Mike Lewis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00075">https://arxiv.org/abs/2502.00075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00075">https://arxiv.org/pdf/2502.00075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00075]] BTS: Harmonizing Specialized Experts into a Generalist LLM(https://arxiv.org/abs/2502.00075)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present Branch-Train-Stitch (BTS), an efficient and flexible training algorithm for combining independently trained large language model (LLM) experts into a single, capable generalist model. Following Li et al., we start with a single seed language model which is branched into domain-specific (e.g., coding or math) experts with continual pretraining. BTS combines experts into a generalist model using lightweight stitch layers, which are inserted between frozen experts and the seed LLM, and trained on a small datamix of the expert domains. Stitch layers enable the seed LLM to integrate representations from any number of experts during the forward pass, allowing it to generalize to new domains, despite remaining frozen. Because BTS does not alter the constituent LLMs, BTS provides a modular and flexible approach: experts can be easily removed and new experts can be added with only a small amount of training. Compared to alternative model merging approaches, BTS yields the best generalist performance on a variety of downstream tasks, retaining the specialized capabilities of each of the experts.</li>
</ul>

<h3>Title: Influence of color correction on pathology detection in Capsule Endoscopy</h3>
<ul>
<li><strong>Authors: </strong>Bidossessi Emmanuel Agossou, Marius Pedersen, Kiran Raja, Anuja Vats, Pål Anders Floor</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00076">https://arxiv.org/abs/2502.00076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00076">https://arxiv.org/pdf/2502.00076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00076]] Influence of color correction on pathology detection in Capsule Endoscopy(https://arxiv.org/abs/2502.00076)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Pathology detection in Wireless Capsule Endoscopy (WCE) using deep learning has been explored in the recent past. However, deep learning models can be influenced by the color quality of the dataset used to train them, impacting detection, segmentation and classification tasks. In this work, we evaluate the impact of color correction on pathology detection using two prominent object detection models: Retinanet and YOLOv5. We first generate two color corrected versions of a popular WCE dataset (i.e., SEE-AI dataset) using two different color correction functions. We then evaluate the performance of the Retinanet and YOLOv5 on the original and color corrected versions of the dataset. The results reveal that color correction makes the models generate larger bounding boxes and larger intersection areas with the ground truth annotations. Furthermore, color correction leads to an increased number of false positives for certain pathologies. However, these effects do not translate into a consistent improvement in performance metrics such as F1-scores, IoU, and AP50. The code is available at this https URL. Keywords: Wireless Capsule Endoscopy, Color correction, Retinanet, YOLOv5, Detection</li>
</ul>

<h3>Title: CerraData-4MM: A multimodal benchmark dataset on Cerrado for land use and land cover classification</h3>
<ul>
<li><strong>Authors: </strong>Mateus de Souza Miranda, Ronny Hänsch, Valdivino Alexandre de Santiago Júnior, Thales Sehn Körting, Erison Carlos dos Santos Monteiro</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00083">https://arxiv.org/abs/2502.00083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00083">https://arxiv.org/pdf/2502.00083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00083]] CerraData-4MM: A multimodal benchmark dataset on Cerrado for land use and land cover classification(https://arxiv.org/abs/2502.00083)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The Cerrado faces increasing environmental pressures, necessitating accurate land use and land cover (LULC) mapping despite challenges such as class imbalance and visually similar categories. To address this, we present CerraData-4MM, a multimodal dataset combining Sentinel-1 Synthetic Aperture Radar (SAR) and Sentinel-2 MultiSpectral Imagery (MSI) with 10m spatial resolution. The dataset includes two hierarchical classification levels with 7 and 14 classes, respectively, focusing on the diverse Bico do Papagaio ecoregion. We highlight CerraData-4MM's capacity to benchmark advanced semantic segmentation techniques by evaluating a standard U-Net and a more sophisticated Vision Transformer (ViT) model. The ViT achieves superior performance in multimodal scenarios, with the highest macro F1-score of 57.60% and a mean Intersection over Union (mIoU) of 49.05% at the first hierarchical level. Both models struggle with minority classes, particularly at the second hierarchical level, where U-Net's performance drops to an F1-score of 18.16%. Class balancing improves representation for underrepresented classes but reduces overall accuracy, underscoring the trade-off in weighted training. CerraData-4MM offers a challenging benchmark for advancing deep learning models to handle class imbalance and multimodal data fusion. Code, trained models, and data are publicly available at this https URL.</li>
</ul>

<h3>Title: Efficient Beam Search for Large Language Models Using Trie-Based Decoding</h3>
<ul>
<li><strong>Authors: </strong>Brian J Chan, Jui-Hung Cheng, Mao Xun Huang, Chao-Ting Chen, Hen-Hsen Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00085">https://arxiv.org/abs/2502.00085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00085">https://arxiv.org/pdf/2502.00085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00085]] Efficient Beam Search for Large Language Models Using Trie-Based Decoding(https://arxiv.org/abs/2502.00085)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In Transformer-based sequence-to-sequence generation, beam search has proven effective in enhancing the quality of generated sequences compared to greedy decoding. Conventional beam search methods typically adopt either a sequential or batch-based approach. The sequential approach, while memory-efficient, requires multiple decoding passes to construct a complete search tree, leading to significantly slower inference. On the other hand, the batch-based approach enables parallel computation across beams, but at the expense of high memory consumption due to the need to maintain separate key-value (KV) caches for each beam. In this study, we introduce a novel trie (prefix-tree)-based parallel decoding method that addresses the memory inefficiency of batch-based beam search. By sharing a single KV cache among all beams that share the same prefix, the proposed method not only reduces memory consumption dramatically but also enables parallel decoding across all branches. This innovative use of a prefix tree offers an efficient alternative for beam search, achieving significant memory savings while preserving inference speed, making it particularly well-suited for memory-constrained environments or large-scale model deployments.</li>
</ul>

<h3>Title: Ensembles of Low-Rank Expert Adapters</h3>
<ul>
<li><strong>Authors: </strong>Yinghao Li, Vianne Gao, Chao Zhang, MohamadAli Torkamani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00089">https://arxiv.org/abs/2502.00089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00089">https://arxiv.org/pdf/2502.00089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00089]] Ensembles of Low-Rank Expert Adapters(https://arxiv.org/abs/2502.00089)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The training and fine-tuning of large language models (LLMs) often involve diverse textual data from multiple sources, which poses challenges due to conflicting gradient directions, hindering optimization and specialization. These challenges can undermine model generalization across tasks, resulting in reduced downstream performance. Recent research suggests that fine-tuning LLMs on carefully selected, task-specific subsets of data can match or even surpass the performance of using the entire dataset. Building on these insights, we propose the Ensembles of Low-Rank Expert Adapters (ELREA) framework to improve the model's capability to handle diverse tasks. ELREA clusters the training instructions based on their gradient directions, representing different areas of expertise and thereby reducing conflicts during optimization. Expert adapters are then trained on these clusters, utilizing the low-rank adaptation (LoRA) technique to ensure training efficiency and model scalability. During inference, ELREA combines predictions from the most relevant expert adapters based on the input data's gradient similarity to the training clusters, ensuring optimal adapter selection for each task. Experiments show that our method outperforms baseline LoRA adapters trained on the full dataset and other ensemble approaches with similar training and inference complexity across a range of domain-specific tasks.</li>
</ul>

<h3>Title: AIN: The Arabic INclusive Large Multimodal Model</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Heakl, Sara Ghaboura, Omkar Thawkar, Fahad Shahbaz Khan, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00094">https://arxiv.org/abs/2502.00094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00094">https://arxiv.org/pdf/2502.00094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00094]] AIN: The Arabic INclusive Large Multimodal Model(https://arxiv.org/abs/2502.00094)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Amid the swift progress of large language models (LLMs) and their evolution into large multimodal models (LMMs), significant strides have been made in high-resource languages such as English and Chinese. While Arabic LLMs have seen notable progress, Arabic LMMs remain largely unexplored, often narrowly focusing on a few specific aspects of the language and visual understanding. To bridge this gap, we introduce AIN-the Arabic Inclusive Multimodal Model-designed to excel across diverse domains. AIN is an English-Arabic bilingual LMM designed to excel in English and Arabic, leveraging carefully constructed 3.6 million high-quality Arabic-English multimodal data samples. AIN demonstrates state-of-the-art Arabic performance, while also possessing strong English-language visual capabilities. On the recent CAMEL-Bench benchmark comprising 38 sub-domains including, multi-image understanding, complex visual perception, handwritten document understanding, video understanding, medical imaging, plant diseases, and remote sensing-based land use understanding, our AIN demonstrates strong performance with the 7B model outperforming GPT-4o by an absolute gain of 3.4% averaged over eight domains and 38 sub-domains. AIN's superior capabilities position it as a significant step toward empowering Arabic speakers with advanced multimodal generative AI tools across diverse applications.</li>
</ul>

<h3>Title: Sparse Autoencoder Insights on Voice Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Daniel Pluth, Yu Zhou, Vijay K. Gurbani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00127">https://arxiv.org/abs/2502.00127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00127">https://arxiv.org/pdf/2502.00127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00127]] Sparse Autoencoder Insights on Voice Embeddings(https://arxiv.org/abs/2502.00127)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in explainable machine learning have highlighted the potential of sparse autoencoders in uncovering mono-semantic features in densely encoded embeddings. While most research has focused on Large Language Model (LLM) embeddings, the applicability of this technique to other domains remains largely unexplored. This study applies sparse autoencoders to speaker embeddings generated from a Titanet model, demonstrating the effectiveness of this technique in extracting mono-semantic features from non-textual embedded data. The results show that the extracted features exhibit characteristics similar to those found in LLM embeddings, including feature splitting and steering. The analysis reveals that the autoencoder can identify and manipulate features such as language and music, which are not evident in the original embedding. The findings suggest that sparse autoencoders can be a valuable tool for understanding and interpreting embedded data in many domains, including audio-based speaker recognition.</li>
</ul>

<h3>Title: ProtoSnap: Prototype Alignment for Cuneiform Signs</h3>
<ul>
<li><strong>Authors: </strong>Rachel Mikulinsky, Morris Alper, Shai Gordin, Enrique Jiménez, Yoram Cohen, Hadar Averbuch-Elor</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00129">https://arxiv.org/abs/2502.00129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00129">https://arxiv.org/pdf/2502.00129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00129]] ProtoSnap: Prototype Alignment for Cuneiform Signs(https://arxiv.org/abs/2502.00129)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The cuneiform writing system served as the medium for transmitting knowledge in the ancient Near East for a period of over three thousand years. Cuneiform signs have a complex internal structure which is the subject of expert paleographic analysis, as variations in sign shapes bear witness to historical developments and transmission of writing and culture over time. However, prior automated techniques mostly treat sign types as categorical and do not explicitly model their highly varied internal configurations. In this work, we present an unsupervised approach for recovering the fine-grained internal configuration of cuneiform signs by leveraging powerful generative models and the appearance and structure of prototype font images as priors. Our approach, ProtoSnap, enforces structural consistency on matches found with deep image features to estimate the diverse configurations of cuneiform characters, snapping a skeleton-based template to photographed cuneiform signs. We provide a new benchmark of expert annotations and evaluate our method on this task. Our evaluation shows that our approach succeeds in aligning prototype skeletons to a wide variety of cuneiform signs. Moreover, we show that conditioning on structures produced by our method allows for generating synthetic data with correct structural configurations, significantly boosting the performance of cuneiform sign recognition beyond existing techniques, in particular over rare signs. Our code, data, and trained models are available at the project page: this https URL</li>
</ul>

<h3>Title: A Three-Branch Checks-and-Balances Frameworkfor Context-Aware Ethical Alignment of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Edward Y. Chang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00136">https://arxiv.org/abs/2502.00136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00136">https://arxiv.org/pdf/2502.00136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00136]] A Three-Branch Checks-and-Balances Frameworkfor Context-Aware Ethical Alignment of Large Language Models(https://arxiv.org/abs/2502.00136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a three-branch checks-and-balances framework for ethical alignment of Large Language Models (LLMs), inspired by governmental systems. It implements three independent yet interacting components: LLMs as the executive branch for knowledge generation, DIKE as the legislative branch establishing ethical guardrails, and ERIS as the judicial branch for contextual interpretation. The adversarial DIKE-ERIS duality enables adaptation to diverse cultural contexts while upholding consistent ethical principles. This architecture addresses limitations of reinforcement learning with human feedback (RLHF) by providing interpretable, adaptable, and culturally-aware ethical reasoning. Through self-supervised learning and adversarial testing, our framework demonstrates how emotional modeling can guide linguistic behaviors toward ethical outcomes while preserving independence across knowledge generation, ethical oversight, and contextual interpretation.</li>
</ul>

<h3>Title: ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Joseph Fioresi, Ishan Rajendrakumar Dave, Mubarak Shah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00156">https://arxiv.org/abs/2502.00156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00156">https://arxiv.org/pdf/2502.00156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00156]] ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition(https://arxiv.org/abs/2502.00156)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, segmentation</a></li>
<li><strong>Abstract: </strong>Bias in machine learning models can lead to unfair decision making, and while it has been well-studied in the image and text domains, it remains underexplored in action recognition. Action recognition models often suffer from background bias (i.e., inferring actions based on background cues) and foreground bias (i.e., relying on subject appearance), which can be detrimental to real-life applications such as autonomous vehicles or assisted living monitoring. While prior approaches have mainly focused on mitigating background bias using specialized augmentations, we thoroughly study both biases. We propose ALBAR, a novel adversarial training method that mitigates foreground and background biases without requiring specialized knowledge of the bias attributes. Our framework applies an adversarial cross-entropy loss to the sampled static clip (where all the frames are the same) and aims to make its class probabilities uniform using a proposed entropy maximization loss. Additionally, we introduce a gradient penalty loss for regularization against the debiasing process. We evaluate our method on established background and foreground bias protocols, setting a new state-of-the-art and strongly improving combined debiasing performance by over 12% on HMDB51. Furthermore, we identify an issue of background leakage in the existing UCF101 protocol for bias evaluation which provides a shortcut to predict actions and does not provide an accurate measure of the debiasing capability of a model. We address this issue by proposing more fine-grained segmentation boundaries for the actor, where our method also outperforms existing approaches. Project Page: this https URL</li>
</ul>

<h3>Title: Resolving Editing-Unlearning Conflicts: A Knowledge Codebook Framework for Large Language Model Updating</h3>
<ul>
<li><strong>Authors: </strong>Binchi Zhang, Zhengzhang Chen, Zaiyi Zheng, Jundong Li, Haifeng Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00158">https://arxiv.org/abs/2502.00158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00158">https://arxiv.org/pdf/2502.00158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00158]] Resolving Editing-Unlearning Conflicts: A Knowledge Codebook Framework for Large Language Model Updating(https://arxiv.org/abs/2502.00158)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in natural language processing by encoding extensive human knowledge, but their utility relies on timely updates as knowledge evolves. Updating LLMs involves two key tasks simultaneously: unlearning to remove unwanted knowledge and editing to incorporate new information. Existing methods face two major challenges: ineffective knowledge storage (either too sparse or too dense) and task conflicts between editing and unlearning, as validated through our theoretical and experimental results. To address these issues, we propose LOKA, a conflict-free framework for LLM updating based on a knowledge codebook. During training, updated knowledge is stored in multiple codebook memories. To optimize knowledge storage, a similarity-aware knowledge mapping ensures that related knowledge pieces are clustered and allocated to the same memory. Additionally, LOKA resolves task conflicts by employing task-specific and multi-task memories guided by a conflict score. In the inference stage, LOKA retrieves the most relevant memory from the codebook and plugs it into the original LLM to apply the updated knowledge. A learning-based router controls codebook activation to further improve knowledge utilization. Extensive experiments demonstrate the effectiveness of LOKA in LLM knowledge updating tasks.</li>
</ul>

<h3>Title: Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Rohan Chacko, Nicolai Haeni, Eldar Khaliullin, Lin Sun, Douglas Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00173">https://arxiv.org/abs/2502.00173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00173">https://arxiv.org/pdf/2502.00173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00173]] Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance Segmentation(https://arxiv.org/abs/2502.00173)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>We introduce Lifting By Gaussians (LBG), a novel approach for open-world instance segmentation of 3D Gaussian Splatted Radiance Fields (3DGS). Recently, 3DGS Fields have emerged as a highly efficient and explicit alternative to Neural Field-based methods for high-quality Novel View Synthesis. Our 3D instance segmentation method directly lifts 2D segmentation masks from SAM (alternately FastSAM, etc.), together with features from CLIP and DINOv2, directly fusing them onto 3DGS (or similar Gaussian radiance fields such as 2DGS). Unlike previous approaches, LBG requires no per-scene training, allowing it to operate seamlessly on any existing 3DGS reconstruction. Our approach is not only an order of magnitude faster and simpler than existing approaches; it is also highly modular, enabling 3D semantic segmentation of existing 3DGS fields without requiring a specific parametrization of the 3D Gaussians. Furthermore, our technique achieves superior semantic segmentation for 2D semantic novel view synthesis and 3D asset extraction results while maintaining flexibility and efficiency. We further introduce a novel approach to evaluate individually segmented 3D assets from 3D radiance field segmentation methods.</li>
</ul>

<h3>Title: Designing Scheduling for Diffusion Models via Spectral Analysis</h3>
<ul>
<li><strong>Authors: </strong>Roi Benita, Michael Elad, Joseph Keshet</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00180">https://arxiv.org/abs/2502.00180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00180">https://arxiv.org/pdf/2502.00180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00180]] Designing Scheduling for Diffusion Models via Spectral Analysis(https://arxiv.org/abs/2502.00180)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have emerged as powerful tools for modeling complex data distributions and generating realistic new samples. Over the years, advanced architectures and sampling methods have been developed to make these models practically usable. However, certain synthesis process decisions still rely on heuristics without a solid theoretical foundation. In our work, we offer a novel analysis of the DM's inference process, introducing a comprehensive frequency response perspective. Specifically, by relying on Gaussianity and shift-invariance assumptions, we present the inference process as a closed-form spectral transfer function, capturing how the generated signal evolves in response to the initial noise. We demonstrate how the proposed analysis can be leveraged for optimizing the noise schedule, ensuring the best alignment with the original dataset's characteristics. Our results lead to scheduling curves that are dependent on the frequency content of the data, offering a theoretical justification for some of the heuristics taken by practitioners.</li>
</ul>

<h3>Title: Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study</h3>
<ul>
<li><strong>Authors: </strong>Jungwon Seo, Ferhat Ozgur Catak, Chunming Rong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00182">https://arxiv.org/abs/2502.00182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00182">https://arxiv.org/pdf/2502.00182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00182]] Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study(https://arxiv.org/abs/2502.00182)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>As privacy concerns and data regulations grow, federated learning (FL) has emerged as a promising approach for training machine learning models across decentralized data sources without sharing raw data. However, a significant challenge in FL is that client data are often non-IID (non-independent and identically distributed), leading to reduced performance compared to centralized learning. While many methods have been proposed to address this issue, their underlying mechanisms are often viewed from different perspectives. Through a comprehensive investigation from gradient descent to FL, and from IID to non-IID data settings, we find that inconsistencies in client loss landscapes primarily cause performance degradation in non-IID scenarios. From this understanding, we observe that existing methods can be grouped into two main strategies: (i) adjusting parameter update paths and (ii) modifying client loss landscapes. These findings offer a clear perspective on addressing non-IID challenges in FL and help guide future research in the field.</li>
</ul>

<h3>Title: Byzantine-Resilient Zero-Order Optimization for Communication-Efficient Heterogeneous Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Egger, Mayank Bakshi, Rawad Bitar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00193">https://arxiv.org/abs/2502.00193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00193">https://arxiv.org/pdf/2502.00193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00193]] Byzantine-Resilient Zero-Order Optimization for Communication-Efficient Heterogeneous Federated Learning(https://arxiv.org/abs/2502.00193)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>We introduce CyBeR-0, a Byzantine-resilient federated zero-order optimization method that is robust under Byzantine attacks and provides significant savings in uplink and downlink communication costs. We introduce transformed robust aggregation to give convergence guarantees for general non-convex objectives under client data heterogeneity. Empirical evaluations for standard learning tasks and fine-tuning large language models show that CyBeR-0 exhibits stable performance with only a few scalars per-round communication cost and reduced memory requirements.</li>
</ul>

<h3>Title: DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access Dermatology Datasets</h3>
<ul>
<li><strong>Authors: </strong>Abdurrahim Yilmaz, Furkan Yuceyalcin, Ece Gokyayla, Donghee Choi, Ozan Erdem Ali Anil Demircali, Rahmetullah Varol, Ufuk Gorkem Kirabali, Gulsum Gencoglan, Joram M. Posma, Burak Temelkuran</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00196">https://arxiv.org/abs/2502.00196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00196">https://arxiv.org/pdf/2502.00196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00196]] DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access Dermatology Datasets(https://arxiv.org/abs/2502.00196)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A major barrier to developing vision large language models (LLMs) in dermatology is the lack of large image--text pairs dataset. We introduce DermaSynth, a dataset comprising of 92,020 synthetic image--text pairs curated from 45,205 images (13,568 clinical and 35,561 dermatoscopic) for dermatology-related clinical tasks. Leveraging state-of-the-art LLMs, using Gemini 2.0, we used clinically related prompts and self-instruct method to generate diverse and rich synthetic texts. Metadata of the datasets were incorporated into the input prompts by targeting to reduce potential hallucinations. The resulting dataset builds upon open access dermatological image repositories (DERM12345, BCN20000, PAD-UFES-20, SCIN, and HIBA) that have permissive CC-BY-4.0 licenses. We also fine-tuned a preliminary Llama-3.2-11B-Vision-Instruct model, DermatoLlama 1.0, on 5,000 samples. We anticipate this dataset to support and accelerate AI research in dermatology. Data and code underlying this work are accessible at this https URL.</li>
</ul>

<h3>Title: Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review</h3>
<ul>
<li><strong>Authors: </strong>Yisong Chen, Chuqing Zhao, Yixin Xu, Chuanhao Nie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00201">https://arxiv.org/abs/2502.00201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00201">https://arxiv.org/pdf/2502.00201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00201]] Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review(https://arxiv.org/abs/2502.00201)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>This paper systematically reviews advancements in deep learning (DL) techniques for financial fraud detection, a critical issue in the financial sector. Using the Kitchenham systematic literature review approach, 57 studies published between 2019 and 2024 were analyzed. The review highlights the effectiveness of various deep learning models such as Convolutional Neural Networks, Long Short-Term Memory, and transformers across domains such as credit card transactions, insurance claims, and financial statement audits. Performance metrics such as precision, recall, F1-score, and AUC-ROC were evaluated. Key themes explored include the impact of data privacy frameworks and advancements in feature engineering and data preprocessing. The study emphasizes challenges such as imbalanced datasets, model interpretability, and ethical considerations, alongside opportunities for automation and privacy-preserving techniques such as blockchain integration and Principal Component Analysis. By examining trends over the past five years, this review identifies critical gaps and promising directions for advancing DL applications in financial fraud detection, offering actionable insights for researchers and practitioners.</li>
</ul>

<h3>Title: Reward-aware Preference Optimization: A Unified Mathematical Framework for Model Alignment</h3>
<ul>
<li><strong>Authors: </strong>Shengyang Sun, Yian Zhang, Alexander Bukharin, David Mosallanezhad, Jiaqi Zeng, Soumye Singhal, Gerald Shen, Adi Renduchintala, Tugrul Konuk, Yi Dong, Zhilin Wang, Dmitry Chichkov, Olivier Delalleau, Oleksii Kuchaiev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00203">https://arxiv.org/abs/2502.00203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00203">https://arxiv.org/pdf/2502.00203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00203]] Reward-aware Preference Optimization: A Unified Mathematical Framework for Model Alignment(https://arxiv.org/abs/2502.00203)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of large language model (LLM) alignment algorithms has resulted in a complex and fragmented landscape, with limited clarity on the effectiveness of different methods and their inter-connections. This paper introduces Reward-Aware Preference Optimization (RPO), a mathematical framework that unifies popular preference optimization techniques in LLM alignment, including DPO, IPO, SimPO, and REINFORCE (LOO), among others. RPO provides a structured approach to disentangle and systematically study the impact of various design choices, such as the optimization objective, the number of responses per prompt, and the use of implicit versus explicit reward models, on LLM preference optimization. We additionally propose a new experimental setup that enables the clean and direct ablation of such design choices. Through an extensive series of ablation studies within the RPO framework, we gain insights into the critical factors shaping model alignment, offering practical guidance on the most effective strategies for improving LLM alignment.</li>
</ul>

<h3>Title: EcoWeedNet: A Lightweight and Automated Weed Detection Method for Sustainable Next-Generation Agricultural Consumer Electronics</h3>
<ul>
<li><strong>Authors: </strong>Omar H. Khater, Abdul Jabbar Siddiqui, M. Shamim Hossain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00205">https://arxiv.org/abs/2502.00205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00205">https://arxiv.org/pdf/2502.00205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00205]] EcoWeedNet: A Lightweight and Automated Weed Detection Method for Sustainable Next-Generation Agricultural Consumer Electronics(https://arxiv.org/abs/2502.00205)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Sustainable agriculture plays a crucial role in ensuring world food security for consumers. A critical challenge faced by sustainable precision agriculture is weed growth, as weeds share essential resources with the crops, such as water, soil nutrients, and sunlight, which notably affect crop yields. The traditional methods employed to combat weeds include the usage of chemical herbicides and manual weed removal methods. However, these could damage the environment and pose health hazards. The adoption of automated computer vision technologies and ground agricultural consumer electronic vehicles in precision agriculture offers sustainable, low-carbon solutions. However, prior works suffer from issues such as low accuracy and precision and high computational expense. This work proposes EcoWeedNet, a novel model with enhanced weed detection performance without adding significant computational complexity, aligning with the goals of low-carbon agricultural practices. Additionally, our model is lightweight and optimal for deployment on ground-based consumer electronic agricultural vehicles and robots. The effectiveness of the proposed model is demonstrated through comprehensive experiments on the CottonWeedDet12 benchmark dataset reflecting real-world scenarios. EcoWeedNet achieves performance close to that of large models yet with much fewer parameters. (approximately 4.21% of the parameters and 6.59% of the GFLOPs of YOLOv4). This work contributes effectively to the development of automated weed detection methods for next-generation agricultural consumer electronics featuring lower energy consumption and lower carbon footprint. This work paves the way forward for sustainable agricultural consumer technologies.</li>
</ul>

<h3>Title: BICompFL: Stochastic Federated Learning with Bi-Directional Compression</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Egger, Rawad Bitar, Antonia Wachter-Zeh, Nir Weinberger, Deniz Gündüz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.IT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00206">https://arxiv.org/abs/2502.00206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00206">https://arxiv.org/pdf/2502.00206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00206]] BICompFL: Stochastic Federated Learning with Bi-Directional Compression(https://arxiv.org/abs/2502.00206)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We address the prominent communication bottleneck in federated learning (FL). We specifically consider stochastic FL, in which models or compressed model updates are specified by distributions rather than deterministic parameters. Stochastic FL offers a principled approach to compression, and has been shown to reduce the communication load under perfect downlink transmission from the federator to the clients. However, in practice, both the uplink and downlink communications are constrained. We show that bi-directional compression for stochastic FL has inherent challenges, which we address by introducing BICompFL. Our BICompFL is experimentally shown to reduce the communication cost by an order of magnitude compared to multiple benchmarks, while maintaining state-of-the-art accuracies. Theoretically, we study the communication cost of BICompFL through a new analysis of an importance-sampling based technique, which exposes the interplay between uplink and downlink communication costs.</li>
</ul>

<h3>Title: Understanding Why Adam Outperforms SGD: Gradient Heterogeneity in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Akiyoshi Tomihari, Issei Sato</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00213">https://arxiv.org/abs/2502.00213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00213">https://arxiv.org/pdf/2502.00213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00213]] Understanding Why Adam Outperforms SGD: Gradient Heterogeneity in Transformers(https://arxiv.org/abs/2502.00213)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models are challenging to optimize with SGD and typically require adaptive optimizers such as Adam. However, the reasons behind the superior performance of Adam over SGD remain unclear. In this study, we investigate the optimization of transformer models by focusing on \emph{gradient heterogeneity}, defined as the disparity in gradient norms among parameters. Our analysis shows that gradient heterogeneity hinders gradient-based optimization, including SGD, while sign-based optimization, a simplified variant of Adam, is less affected. We further examine gradient heterogeneity in transformer models and show that it is influenced by the placement of layer normalization. Additionally, we show that the momentum term in sign-based optimization is important for preventing the excessive growth of linear-head parameters in tasks with many classes. Experimental results from fine-tuning transformer models in both NLP and vision domains validate our theoretical analyses. This study provides insights into the optimization challenges of transformer models and offers guidance for designing future optimization algorithms. Code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Fantastic Multi-Task Gradient Updates and How to Find Them In a Cone</h3>
<ul>
<li><strong>Authors: </strong>Negar Hassanpour, Muhammad Kamran Janjua, Kunlin Zhang, Sepehr Lavasani, Xiaowen Zhang, Chunhua Zhou, Chao Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00217">https://arxiv.org/abs/2502.00217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00217">https://arxiv.org/pdf/2502.00217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00217]] Fantastic Multi-Task Gradient Updates and How to Find Them In a Cone(https://arxiv.org/abs/2502.00217)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Balancing competing objectives remains a fundamental challenge in multi-task learning (MTL), primarily due to conflicting gradients across individual tasks. A common solution relies on computing a dynamic gradient update vector that balances competing tasks as optimization progresses. Building on this idea, we propose ConicGrad, a principled, scalable, and robust MTL approach formulated as a constrained optimization problem. Our method introduces an angular constraint to dynamically regulate gradient update directions, confining them within a cone centered on the reference gradient of the overall objective. By balancing task-specific gradients without over-constraining their direction or magnitude, ConicGrad effectively resolves inter-task gradient conflicts. Moreover, our framework ensures computational efficiency and scalability to high-dimensional parameter spaces. We conduct extensive experiments on standard supervised learning and reinforcement learning MTL benchmarks, and demonstrate that ConicGrad achieves state-of-the-art performance across diverse tasks.</li>
</ul>

<h3>Title: Algorithmic Clustering based on String Compression to Extract P300 Structure in EEG Signals</h3>
<ul>
<li><strong>Authors: </strong>Guillermo Sarasa, Ana Granados, Francisco B Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00220">https://arxiv.org/abs/2502.00220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00220">https://arxiv.org/pdf/2502.00220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00220]] Algorithmic Clustering based on String Compression to Extract P300 Structure in EEG Signals(https://arxiv.org/abs/2502.00220)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>P300 is an Event-Related Potential widely used in Brain-Computer Interfaces, but its detection is challenging due to inter-subject and temporal variability. This work introduces a clustering methodology based on Normalized Compression Distance (NCD) to extract the P300 structure, ensuring robustness against variability. We propose a novel signal-to-ASCII transformation to generate compression-friendly objects, which are then clustered using a hierarchical tree-based method and a multidimensional projection approach. Experimental results on two datasets demonstrate the method's ability to reveal relevant P300 structures, showing clustering performance comparable to state-of-the-art approaches. Furthermore, analysis at the electrode level suggests that the method could assist in electrode selection for P300 detection. This compression-driven clustering methodology offers a complementary tool for EEG analysis and P300 identification.</li>
</ul>

<h3>Title: Should You Use Your Large Language Model to Explore or Exploit?</h3>
<ul>
<li><strong>Authors: </strong>Keegan Harris, Aleksandrs Slivkins</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00225">https://arxiv.org/abs/2502.00225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00225">https://arxiv.org/pdf/2502.00225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00225]] Should You Use Your Large Language Model to Explore or Exploit?(https://arxiv.org/abs/2502.00225)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We evaluate the ability of the current generation of large language models (LLMs) to help a decision-making agent facing an exploration-exploitation tradeoff. We use LLMs to explore and exploit in silos in various (contextual) bandit tasks. We find that while the current LLMs often struggle to exploit, in-context mitigations may be used to substantially improve performance for small-scale tasks. However even then, LLMs perform worse than a simple linear regression. On the other hand, we find that LLMs do help at exploring large action spaces with inherent semantics, by suggesting suitable candidates to explore.</li>
</ul>

<h3>Title: HackerRank-ASTRA: Evaluating Correctness & Consistency of Large Language Models on cross-domain multi-file project problems</h3>
<ul>
<li><strong>Authors: </strong>Jun Xing, Mayur Bhatia, Sahil Phulwani, Darshan Suresh, Rafik Matta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00226">https://arxiv.org/abs/2502.00226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00226">https://arxiv.org/pdf/2502.00226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00226]] HackerRank-ASTRA: Evaluating Correctness & Consistency of Large Language Models on cross-domain multi-file project problems(https://arxiv.org/abs/2502.00226)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating the real-world applicability of large language models (LLMs) provides valuable insights for their development and use in software development tasks. Existing benchmarks often focus on standalone coding problems or specific libraries, overlooking multi-file, project-based scenarios and lacking a rigorous evaluation of consistency. The HackerRank-ASTRA Benchmark introduces project-based coding problems that mirror real-world scenarios. It evaluates model consistency through 32 runs (k = 32) and median standard deviation while incorporating taxonomy-level analysis to assess sub-skill capabilities. Initial evaluations on 65 problems show that the top three models -- o1, o1-preview, and Claude-3.5-Sonnet-1022 -- achieved comparable average scores of 75%, with no statistically significant differences in performance. Notably, Claude-3.5-Sonnet-1022 demonstrated the highest consistency across problems, with low variability (SD = 0.0497), which was statistically significant compared to other models, highlighting its reliability for real-world software development tasks.</li>
</ul>

<h3>Title: Fast Solvers for Discrete Diffusion Models: Theory and Applications of High-Order Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Yinuo Ren, Haoxuan Chen, Yuchen Zhu, Wei Guo, Yongxin Chen, Grant M. Rotskoff, Molei Tao, Lexing Ying</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, math.NA, physics.comp-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00234">https://arxiv.org/abs/2502.00234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00234">https://arxiv.org/pdf/2502.00234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00234]] Fast Solvers for Discrete Diffusion Models: Theory and Applications of High-Order Algorithms(https://arxiv.org/abs/2502.00234)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Discrete diffusion models have emerged as a powerful generative modeling framework for discrete data with successful applications spanning from text generation to image synthesis. However, their deployment faces challenges due to the high dimensionality of the state space, necessitating the development of efficient inference algorithms. Current inference approaches mainly fall into two categories: exact simulation and approximate methods such as $\tau$-leaping. While exact methods suffer from unpredictable inference time and redundant function evaluations, $\tau$-leaping is limited by its first-order accuracy. In this work, we advance the latter category by tailoring the first extension of high-order numerical inference schemes to discrete diffusion models, enabling larger step sizes while reducing error. We rigorously analyze the proposed schemes and establish the second-order accuracy of the $\theta$-trapezoidal method in KL divergence. Empirical evaluations on GPT-2 level text and ImageNet-level image generation tasks demonstrate that our method achieves superior sample quality compared to existing approaches under equivalent computational constraints.</li>
</ul>

<h3>Title: Mordal: Automated Pretrained Model Selection for Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shiqi He, Insu Jang, Mosharaf Chowdhury</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00241">https://arxiv.org/abs/2502.00241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00241">https://arxiv.org/pdf/2502.00241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00241]] Mordal: Automated Pretrained Model Selection for Vision Language Models(https://arxiv.org/abs/2502.00241)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Incorporating multiple modalities into large language models (LLMs) is a powerful way to enhance their understanding of non-textual data, enabling them to perform multimodal tasks. Vision language models (VLMs) form the fastest growing category of multimodal models because of their many practical use cases, including in healthcare, robotics, and accessibility. Unfortunately, even though different VLMs in the literature demonstrate impressive visual capabilities in different benchmarks, they are handcrafted by human experts; there is no automated framework to create task-specific multimodal models. We introduce Mordal, an automated multimodal model search framework that efficiently finds the best VLM for a user-defined task without manual intervention. Mordal achieves this both by reducing the number of candidates to consider during the search process and by minimizing the time required to evaluate each remaining candidate. Our evaluation shows that Mordal can find the best VLM for a given problem using up to $8.9\times$--$11.6\times$ lower GPU hours than grid search. In the process of our evaluation, we have also discovered new VLMs that outperform their state-of-the-art counterparts.</li>
</ul>

<h3>Title: Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion</h3>
<ul>
<li><strong>Authors: </strong>Tianyuan Zou, Yang Liu, Peng Li, Yufei Xiong, Jianqing Zhang, Jingjing Liu, Xiaozhou Ye, Ye Ouyang, Ya-Qin Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00245">https://arxiv.org/abs/2502.00245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00245">https://arxiv.org/pdf/2502.00245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00245]] Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion(https://arxiv.org/abs/2502.00245)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, generative</a></li>
<li><strong>Abstract: </strong>Substantial quantity and high quality are the golden rules of making a good training dataset with sample privacy protection equally important. Generating synthetic samples that resemble high-quality private data while ensuring Differential Privacy (DP), a formal privacy guarantee, promises scalability and practicality. However, existing methods relying on pre-trained models for data synthesis %that avoid fine-tuning large pre-trained generative models often struggle in data-deficient scenarios, suffering from limited sample size, inevitable generation noise and existing pre-trained model bias. To address these challenges, we propose a novel contrAstive private data Synthesis via Weighted multiple Pre-trained language models (PLM) framework, named as WASP. WASP utilizes limited private samples for more accurate private data distribution estimation via a Top-Q voting mechanism, and leverages low-quality synthetic samples for contrastive generation via collaboration among dynamically weighted multiple pre-trained this http URL experiments on 6 well-developed datasets with 6 open-source and 3 closed-source PLMs demonstrate the superiority of WASP in improving model performance over diverse downstream tasks. Code is available at this https URL.</li>
</ul>

<h3>Title: Context-Preserving Tensorial Reconfiguration in Large Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Larin Tonix, Morgana Baskerville, Nathaniel Stourton, Ophelia Tattershall</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00246">https://arxiv.org/abs/2502.00246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00246">https://arxiv.org/pdf/2502.00246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00246]] Context-Preserving Tensorial Reconfiguration in Large Language Model Training(https://arxiv.org/abs/2502.00246)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Handling long-range dependencies in neural architectures has remained a persistent challenge due to computational limitations and inefficient contextual retention mechanisms. Tensorial operations have provided a foundation for restructuring model representations, yet conventional architectures have struggled to incorporate such techniques without introducing excessive complexity. A novel approach, Context-Preserving Tensorial Reconfiguration (CPTR), enables dynamic reorganization of weight tensors through structured factorization and adaptive contraction, allowing for enhanced contextual integration without substantial computational overhead. Empirical evaluations demonstrate that CPTR improves coherence retention across extended sequences, leading to measurable reductions in perplexity and improved recall accuracy for long-context tasks. Performance comparisons reveal that CPTR-enhanced models exhibit greater computational efficiency and reduced memory consumption while maintaining competitive language generation fluency and accuracy. Gradient stability metrics further validate the improved training efficiency, revealing more controlled variance in weight updates. Comparative studies across baseline and CPTR-enhanced models confirm that tensorial reconfiguration contributes to more stable and computationally efficient language modeling. The findings support the potential of CPTR in refining contemporary neural architectures for tasks requiring long-range contextual understanding and efficient memory utilization.</li>
</ul>

<h3>Title: Transformer-Based Vector Font Classification Using Different Font Formats: TrueType versus PostScript</h3>
<ul>
<li><strong>Authors: </strong>Takumu Fujioka (1), Gouhei Tanaka (1 and 2) ((1) Nagoya Institute of Technology, (2) The University of Tokyo)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00250">https://arxiv.org/abs/2502.00250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00250">https://arxiv.org/pdf/2502.00250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00250]] Transformer-Based Vector Font Classification Using Different Font Formats: TrueType versus PostScript(https://arxiv.org/abs/2502.00250)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Modern fonts adopt vector-based formats, which ensure scalability without loss of quality. While many deep learning studies on fonts focus on bitmap formats, deep learning for vector fonts remains underexplored. In studies involving deep learning for vector fonts, the choice of font representation has often been made conventionally. However, the font representation format is one of the factors that can influence the computational performance of machine learning models in font-related tasks. Here we show that font representations based on PostScript outlines outperform those based on TrueType outlines in Transformer-based vector font classification. TrueType outlines represent character shapes as sequences of points and their associated flags, whereas PostScript outlines represent them as sequences of commands. In previous research, PostScript outlines have been predominantly used when fonts are treated as part of vector graphics, while TrueType outlines are mainly employed when focusing on fonts alone. Whether to use PostScript or TrueType outlines has been mainly determined by file format specifications and precedent settings in previous studies, rather than performance considerations. To date, few studies have compared which outline format provides better embedding representations. Our findings suggest that information aggregation is crucial in Transformer-based deep learning for vector graphics, as in tokenization in language models and patch division in bitmap-based image recognition models. This insight provides valuable guidance for selecting outline formats in future research on vector graphics.</li>
</ul>

<h3>Title: ProxSparse: Regularized Learning of Semi-Structured Sparsity Masks for Pretrained LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hongyi Liu, Rajarshi Saha, Zhen Jia, Youngsuk Park, Jiaji Huang, Shoham Sabach, Yu-Xiang Wang, George Karypis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00258">https://arxiv.org/abs/2502.00258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00258">https://arxiv.org/pdf/2502.00258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00258]] ProxSparse: Regularized Learning of Semi-Structured Sparsity Masks for Pretrained LLMs(https://arxiv.org/abs/2502.00258)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated exceptional performance in natural language processing tasks, yet their massive size makes serving them inefficient and costly. Semi-structured pruning has emerged as an effective method for model acceleration, but existing approaches are suboptimal because they focus on local, layer-wise optimizations using heuristic rules, failing to leverage global feedback. We present ProxSparse, a learning-based framework for mask selection enabled by regularized optimization. ProxSparse transforms the rigid, non-differentiable mask selection process into a smoother optimization procedure, allowing gradual mask exploration with flexibility. ProxSparse does not involve additional weight updates once the mask is determined. Our extensive evaluations on 7 widely used models show that ProxSparse consistently outperforms previously proposed semi-structured mask selection methods with significant improvement, demonstrating the effectiveness of our learned approach towards semi-structured pruning.</li>
</ul>

<h3>Title: Your submission contained main.bib and main.tex file, but no main.bbl file (include main.bbl, or submit without main.bib; and remember to verify references)</h3>
<ul>
<li><strong>Authors: </strong>Dianwei Chen, Zifan Zhang, Yuchen Liu, Xianfeng Terry Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00262">https://arxiv.org/abs/2502.00262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00262">https://arxiv.org/pdf/2502.00262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00262]] Your submission contained main.bib and main.tex file, but no main.bbl file (include main.bbl, or submit without main.bib; and remember to verify references)(https://arxiv.org/abs/2502.00262)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Autonomous driving systems face significant challenges in handling unpredictable edge-case scenarios, such as adversarial pedestrian movements, dangerous vehicle maneuvers, and sudden environmental changes. Current end-to-end driving models struggle with generalization to these rare events due to limitations in traditional detection and prediction approaches. To address this, we propose INSIGHT (Integration of Semantic and Visual Inputs for Generalized Hazard Tracking), a hierarchical vision-language model (VLM) framework designed to enhance hazard detection and edge-case evaluation. By using multimodal data fusion, our approach integrates semantic and visual representations, enabling precise interpretation of driving scenarios and accurate forecasting of potential dangers. Through supervised fine-tuning of VLMs, we optimize spatial hazard localization using attention-based mechanisms and coordinate regression techniques. Experimental results on the BDD100K dataset demonstrate a substantial improvement in hazard prediction straightforwardness and accuracy over existing models, achieving a notable increase in generalization performance. This advancement enhances the robustness and safety of autonomous driving systems, ensuring improved situational awareness and potential decision-making in complex real-world scenarios.</li>
</ul>

<h3>Title: Beyond the Permutation Symmetry of Transformers: The Role of Rotation for Model Fusion</h3>
<ul>
<li><strong>Authors: </strong>Binchi Zhang, Zaiyi Zheng, Zhengzhang Chen, Jundong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00264">https://arxiv.org/abs/2502.00264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00264">https://arxiv.org/pdf/2502.00264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00264]] Beyond the Permutation Symmetry of Transformers: The Role of Rotation for Model Fusion(https://arxiv.org/abs/2502.00264)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Symmetry in the parameter space of deep neural networks (DNNs) has proven beneficial for various deep learning applications. A well-known example is the permutation symmetry in Multi-Layer Perceptrons (MLPs), where permuting the rows of weight matrices in one layer and applying the inverse permutation to adjacent layers yields a functionally equivalent model. While permutation symmetry fully characterizes the equivalence set for MLPs, its discrete nature limits its utility for transformers. In this paper, we introduce rotation symmetry, a novel form of parameter space symmetry for transformers that generalizes permutation symmetry by rotating parameter matrices in self-attention layers. Unlike permutation symmetry, rotation symmetry operates in a continuous domain, thereby significantly expanding the equivalence set for transformers. Based on this property, we propose a theoretically optimal parameter matching algorithm as a plug-and-play module to enhance model fusion. We evaluate our approach using pre-trained transformers across diverse natural language and vision tasks. Experimental results demonstrate that our rotation symmetry-based matching algorithm substantially improves model fusion, highlighting the potential of parameter space symmetry to facilitate model fusion. Our code is available on this https URL.</li>
</ul>

<h3>Title: MCM: Multi-layer Concept Map for Efficient Concept Learning from Masked Images</h3>
<ul>
<li><strong>Authors: </strong>Yuwei Sun, Lu Mi, Ippei Fujisawa, Ryota Kanai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00266">https://arxiv.org/abs/2502.00266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00266">https://arxiv.org/pdf/2502.00266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00266]] MCM: Multi-layer Concept Map for Efficient Concept Learning from Masked Images(https://arxiv.org/abs/2502.00266)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Masking strategies commonly employed in natural language processing are still underexplored in vision tasks such as concept learning, where conventional methods typically rely on full images. However, using masked images diversifies perceptual inputs, potentially offering significant advantages in concept learning with large-scale Transformer models. To this end, we propose Multi-layer Concept Map (MCM), the first work to devise an efficient concept learning method based on masked images. In particular, we introduce an asymmetric concept learning architecture by establishing correlations between different encoder and decoder layers, updating concept tokens using backward gradients from reconstruction tasks. The learned concept tokens at various levels of granularity help either reconstruct the masked image patches by filling in gaps or guide the reconstruction results in a direction that reflects specific concepts. Moreover, we present both quantitative and qualitative results across a wide range of metrics, demonstrating that MCM significantly reduces computational costs by training on fewer than 75% of the total image patches while enhancing concept prediction performance. Additionally, editing specific concept tokens in the latent space enables targeted image generation from masked images, aligning both the visible contextual patches and the provided concepts. By further adjusting the testing time mask ratio, we could produce a range of reconstructions that blend the visible patches with the provided concepts, proportional to the chosen ratios.</li>
</ul>

<h3>Title: Scaling Flaws of Verifier-Guided Search in Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Fei Yu, Yingru Li, Benyou Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00271">https://arxiv.org/abs/2502.00271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00271">https://arxiv.org/pdf/2502.00271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00271]] Scaling Flaws of Verifier-Guided Search in Mathematical Reasoning(https://arxiv.org/abs/2502.00271)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) struggle with multi-step reasoning, where inference-time scaling has emerged as a promising strategy for performance improvement. Verifier-guided search outperforms repeated sampling when sample size is limited by selecting and prioritizing valid reasoning paths. However, we identify a critical limitation: scaling flaws, prevalent across different models (Mistral 7B and DeepSeekMath 7B), benchmarks (GSM8K and MATH), and verifiers (outcome value models and process reward models). As sample size increases, verifier-guided search exhibits diminishing advantages and eventually underperforms repeated sampling. Our analysis attributes this to verifier failures, where imperfect verifiers misrank candidates and erroneously prune all valid paths. These issues are further exacerbated in challenging and out-of-distribution problems, restricting search effectiveness. To mitigate verifier failures, we explore reducing reliance on verifiers and conduct preliminary investigations using two simple methods. Our findings reveal fundamental limitations in verifier-guided search and suggest future directions.</li>
</ul>

<h3>Title: Regularized Langevin Dynamics for Combinatorial Optimization</h3>
<ul>
<li><strong>Authors: </strong>Shengyu Feng, Yiming Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00277">https://arxiv.org/abs/2502.00277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00277">https://arxiv.org/pdf/2502.00277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00277]] Regularized Langevin Dynamics for Combinatorial Optimization(https://arxiv.org/abs/2502.00277)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This work proposes a simple yet effective sampling framework for combinatorial optimization (CO). Our method builds on discrete Langevin dynamics (LD), an efficient gradient-guided generative algorithm. However, we observed that directly applying LD often leads to limited exploration. To overcome this limitation, we propose the Regularized Langevin Dynamics (RLD), which enforces an expected distance between the sampled and current solutions, effectively avoiding local minima. We develop two CO solvers on top of RLD, one based on simulated annealing (SA) and the other one based on neural network (NN). Empirical results on three classical CO problems demonstrate that both of our methods can achieve comparable or better performance against the previous state-of-the-art (SOTA) SA and NN-based solvers. In particular, our SA algorithm reduces the running time of the previous SOTA SA method by up to 80\%, while achieving equal or superior performance. In summary, RLD offers a promising framework for enhancing both traditional heuristics and NN models to solve CO problems.</li>
</ul>

<h3>Title: Improving realistic semi-supervised learning with doubly robust estimation</h3>
<ul>
<li><strong>Authors: </strong>Khiem Pham, Charles Herrmann, Ramin Zabih</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00279">https://arxiv.org/abs/2502.00279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00279">https://arxiv.org/pdf/2502.00279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00279]] Improving realistic semi-supervised learning with doubly robust estimation(https://arxiv.org/abs/2502.00279)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A major challenge in Semi-Supervised Learning (SSL) is the limited information available about the class distribution in the unlabeled data. In many real-world applications this arises from the prevalence of long-tailed distributions, where the standard pseudo-label approach to SSL is biased towards the labeled class distribution and thus performs poorly on unlabeled data. Existing methods typically assume that the unlabeled class distribution is either known a priori, which is unrealistic in most situations, or estimate it on-the-fly using the pseudo-labels themselves. We propose to explicitly estimate the unlabeled class distribution, which is a finite-dimensional parameter, \emph{as an initial step}, using a doubly robust estimator with a strong theoretical guarantee; this estimate can then be integrated into existing methods to pseudo-label the unlabeled data during training more accurately. Experimental results demonstrate that incorporating our techniques into common pseudo-labeling approaches improves their performance.</li>
</ul>

<h3>Title: Sigmoid Self-Attention is Better than Softmax Self-Attention: A Mixture-of-Experts Perspective</h3>
<ul>
<li><strong>Authors: </strong>Fanqi Yan, Huy Nguyen, Pedram Akbarian, Nhat Ho, Alessandro Rinaldo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00281">https://arxiv.org/abs/2502.00281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00281">https://arxiv.org/pdf/2502.00281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00281]] Sigmoid Self-Attention is Better than Softmax Self-Attention: A Mixture-of-Experts Perspective(https://arxiv.org/abs/2502.00281)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>At the core of the popular Transformer architecture is the self-attention mechanism, which dynamically assigns softmax weights to each input token so that the model can focus on the most salient information. However, the softmax structure slows down the attention computation due to its row-wise nature, and inherently introduces competition among tokens: as the weight assigned to one token increases, the weights of others decrease. This competitive dynamic may narrow the focus of self-attention to a limited set of features, potentially overlooking other informative characteristics. Recent experimental studies have shown that using the element-wise sigmoid function helps eliminate token competition and reduce the computational overhead. Despite these promising empirical results, a rigorous comparison between sigmoid and softmax self-attention mechanisms remains absent in the literature. This paper closes this gap by theoretically demonstrating that sigmoid self-attention is more sample-efficient than its softmax counterpart. Toward that goal, we illustrate that each row of the self-attention matrix can be represented as a mixture of experts. Our analysis shows that ''experts'' in sigmoid self-attention require significantly less data to achieve the same approximation error as those in softmax self-attention. We corroborate our theoretical findings through extensive experiments on both synthetic and real-world datasets.</li>
</ul>

<h3>Title: Estimating LLM Uncertainty with Logits</h3>
<ul>
<li><strong>Authors: </strong>Huan Ma, Jingdong Chen, Guangyu Wang, Changqing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00290">https://arxiv.org/abs/2502.00290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00290">https://arxiv.org/pdf/2502.00290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00290]] Estimating LLM Uncertainty with Logits(https://arxiv.org/abs/2502.00290)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Large Language Models (LLMs) have seen remarkable advancements and have been extensively integrated across various fields. Despite their progress, LLMs are prone to hallucinations, producing responses that may not be dependable if the models lack sufficient grounding knowledge. To mitigate this issue, methods for estimating uncertainty have been adopted, with a focus on critical tokens as indicators of reliability. Nevertheless, probability-based approaches have shown limitations in assessing token-level reliability due to the erosion of evidence strength information acquired during training. In this paper, we introduce Logits-induced Token Uncertainty (LogU), a novel framework designed to estimate token-specific uncertainty in LLMs in real time, without the need for multiple sampling rounds. By leveraging evidence modeling for the implementation of LogU, we utilize the derived uncertainty measures to steer downstream tasks. Our experimental findings highlight the substantial effectiveness and potential of LogU, marking a significant advancement in addressing the challenge of model hallucinations.</li>
</ul>

<h3>Title: ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Xiang Liu, Zhenheng Tang, Peijie Dong, Zeyu Li, Bo Li, Xuming Hu, Xiaowen Chu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00299">https://arxiv.org/abs/2502.00299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00299">https://arxiv.org/pdf/2502.00299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00299]] ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference(https://arxiv.org/abs/2502.00299)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To reduce memory costs in long-context inference with Large Language Models (LLMs), many recent works focus on compressing the key-value (KV) cache of different tokens. However, we identify that the previous KV cache compression methods measure token importance individually, neglecting the dependency between different tokens in the real-world language characterics. In light of this, we introduce ChunkKV, grouping the tokens in a chunk as a basic compressing unit, and retaining the most informative semantic chunks while discarding the less important ones. Furthermore, observing that ChunkKV exhibits higher similarity in the preserved indices across different layers, we propose layer-wise index reuse to further reduce computational overhead. We evaluated ChunkKV on cutting-edge long-context benchmarks including LongBench and Needle-In-A-HayStack, as well as the GSM8K and JailbreakV in-context learning benchmark. Our experiments with instruction tuning and multi-step reasoning (O1 and R1) LLMs, achieve up to 10\% performance improvement under aggressive compression ratios compared to existing methods.</li>
</ul>

<h3>Title: Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations</h3>
<ul>
<li><strong>Authors: </strong>Alistair Dombrowski, Beatrix Engelhardt, Dimitri Fairbrother, Henry Evidail</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00301">https://arxiv.org/abs/2502.00301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00301">https://arxiv.org/pdf/2502.00301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00301]] Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations(https://arxiv.org/abs/2502.00301)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Token representations influence the efficiency and adaptability of language models, yet conventional tokenization strategies impose rigid segmentation boundaries that do not adjust dynamically to evolving contextual relationships. The introduction of contextual morphogenesis establishes a self-organizing mechanism that restructures token boundaries based on learned contextual dependencies, allowing embeddings to evolve progressively across iterative processing steps. Empirical evaluations demonstrate that dynamically adjusted tokenization contributes to reductions in perplexity while maintaining representational stability, particularly in linguistically complex domains where static segmentation fails to capture nuanced dependencies. Computational trade-offs associated with self-organizing token structures indicate that additional processing overhead remains within feasible limits, provided that optimization strategies account for segmentation update efficiency. Comparative assessments across different linguistic corpora suggest that adaptive tokenization preserves interpretability while improving alignment with contextual cues, reinforcing the potential of morphogenetic segmentation mechanisms to refine predictive accuracy. Stability analyses confirm that evolving token structures maintain consistent segmentation behaviors across varied text distributions, ensuring that representational adaptations remain linguistically coherent. The effectiveness of contextual morphogenesis in refining structural stability and predictive performance highlights its viability as an alternative to traditional tokenization methods. Further analysis of computational efficiency considerations suggests that hybrid strategies integrating both static and dynamic segmentation techniques may offer a balanced approach to optimizing representational flexibility while maintaining inference efficiency.</li>
</ul>

<h3>Title: Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Ali Naseh, Yuefeng Peng, Anshuman Suri, Harsh Chaudhari, Alina Oprea, Amir Houmansadr</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00306">https://arxiv.org/abs/2502.00306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00306">https://arxiv.org/pdf/2502.00306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00306]] Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation(https://arxiv.org/abs/2502.00306)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, extraction, membership infer, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.</li>
</ul>

<h3>Title: A Diffusion Model Translator for Efficient Image-to-Image Translation</h3>
<ul>
<li><strong>Authors: </strong>Mengfei Xia, Yu Zhou, Ran Yi, Yong-Jin Liu, Wenping Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00307">https://arxiv.org/abs/2502.00307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00307">https://arxiv.org/pdf/2502.00307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00307]] A Diffusion Model Translator for Efficient Image-to-Image Translation(https://arxiv.org/abs/2502.00307)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Applying diffusion models to image-to-image translation (I2I) has recently received increasing attention due to its practical applications. Previous attempts inject information from the source image into each denoising step for an iterative refinement, thus resulting in a time-consuming implementation. We propose an efficient method that equips a diffusion model with a lightweight translator, dubbed a Diffusion Model Translator (DMT), to accomplish I2I. Specifically, we first offer theoretical justification that in employing the pioneering DDPM work for the I2I task, it is both feasible and sufficient to transfer the distribution from one domain to another only at some intermediate step. We further observe that the translation performance highly depends on the chosen timestep for domain transfer, and therefore propose a practical strategy to automatically select an appropriate timestep for a given task. We evaluate our approach on a range of I2I applications, including image stylization, image colorization, segmentation to image, and sketch to image, to validate its efficacy and general utility. The comparisons show that our DMT surpasses existing methods in both quality and efficiency. Code will be made publicly available.</li>
</ul>

<h3>Title: Sparse Gradient Compression for Fine-Tuning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>David H. Yang, Mohammad Mohammadi Amiri, Tejaswini Pedapati, Subhajit Chaudhury, Pin-Yu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00311">https://arxiv.org/abs/2502.00311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00311">https://arxiv.org/pdf/2502.00311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00311]] Sparse Gradient Compression for Fine-Tuning Large Language Models(https://arxiv.org/abs/2502.00311)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) for downstream tasks has become increasingly crucial due to their widespread use and the growing availability of open-source models. However, the high memory costs associated with fine-tuning remain a significant challenge, especially as models increase in size. To address this, parameter efficient fine-tuning (PEFT) methods have been proposed to minimize the number of parameters required for fine-tuning LLMs. However, these approaches often tie the number of optimizer states to dimensions of model parameters, limiting flexibility and control during fine-tuning. In this paper, we propose sparse gradient compression (SGC), a training regime designed to address these limitations. Our approach leverages inherent sparsity in gradients to compress optimizer states by projecting them onto a low-dimensonal subspace, with dimensionality independent of the original model's parameters. By enabling optimizer state updates in an arbitrary low-dimensional subspace, SGC offers a flexible tradeoff between memory efficiency and performance. We demonstrate through experiments that SGC can decrease memory usage in optimizer states more effectively than existing PEFT methods. Furthermore, by fine-tuning LLMs on various downstream tasks, we show that SGC can deliver superior performance while substantially lowering optimizer state memory requirements, particularly in both data-limited and memory-limited settings.</li>
</ul>

<h3>Title: MonoDINO-DETR: Depth-Enhanced Monocular 3D Object Detection Using a Vision Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Jihyeok Kim, Seongwoo Moon, Sungwon Nah, David Hyunchul Shim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00315">https://arxiv.org/abs/2502.00315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00315">https://arxiv.org/pdf/2502.00315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00315]] MonoDINO-DETR: Depth-Enhanced Monocular 3D Object Detection Using a Vision Foundation Model(https://arxiv.org/abs/2502.00315)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes novel methods to enhance the performance of monocular 3D object detection models by leveraging the generalized feature extraction capabilities of a vision foundation model. Unlike traditional CNN-based approaches, which often suffer from inaccurate depth estimation and rely on multi-stage object detection pipelines, this study employs a Vision Transformer (ViT)-based foundation model as the backbone, which excels at capturing global features for depth estimation. It integrates a detection transformer (DETR) architecture to improve both depth estimation and object detection performance in a one-stage manner. Specifically, a hierarchical feature fusion block is introduced to extract richer visual features from the foundation model, further enhancing feature extraction capabilities. Depth estimation accuracy is further improved by incorporating a relative depth estimation model trained on large-scale data and fine-tuning it through transfer learning. Additionally, the use of queries in the transformer's decoder, which consider reference points and the dimensions of 2D bounding boxes, enhances recognition performance. The proposed model outperforms recent state-of-the-art methods, as demonstrated through quantitative and qualitative evaluations on the KITTI 3D benchmark and a custom dataset collected from high-elevation racing environments. Code is available at this https URL.</li>
</ul>

<h3>Title: Physics-Inspired Distributed Radio Map Estimation</h3>
<ul>
<li><strong>Authors: </strong>Dong Yang, Yue Wang, Songyang Zhang, Yingshu Li, Zhipeng Cai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00319">https://arxiv.org/abs/2502.00319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00319">https://arxiv.org/pdf/2502.00319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00319]] Physics-Inspired Distributed Radio Map Estimation(https://arxiv.org/abs/2502.00319)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>To gain panoramic awareness of spectrum coverage in complex wireless environments, data-driven learning approaches have recently been introduced for radio map estimation (RME). While existing deep learning based methods conduct RME given spectrum measurements gathered from dispersed sensors in the region of interest, they rely on centralized data at a fusion center, which however raises critical concerns on data privacy leakages and high communication overloads. Federated learning (FL) enhance data security and communication efficiency in RME by allowing multiple clients to collaborate in model training without directly sharing local data. However, the performance of the FL-based RME can be hindered by the problem of task heterogeneity across clients due to their unavailable or inaccurate landscaping information. To fill this gap, in this paper, we propose a physics-inspired distributed RME solution in the absence of landscaping information. The main idea is to develop a novel distributed RME framework empowered by leveraging the domain knowledge of radio propagation models, and by designing a new distributed learning approach that splits the entire RME model into two modules. A global autoencoder module is shared among clients to capture the common pathloss influence on radio propagation pattern, while a client-specific autoencoder module focuses on learning the individual features produced by local shadowing effects from the unique building distributions in local environment. Simulation results show that our proposed method outperforms the benchmarks in achieving higher performance.</li>
</ul>

<h3>Title: From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation</h3>
<ul>
<li><strong>Authors: </strong>Xingchen Wan, Han Zhou, Ruoxi Sun, Hootan Nakhost, Ke Jiang, Sercan Ö. Arık</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00330">https://arxiv.org/abs/2502.00330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00330">https://arxiv.org/pdf/2502.00330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00330]] From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation(https://arxiv.org/abs/2502.00330)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in long-context large language models (LLMs) have led to the emerging paradigm of many-shot in-context learning (ICL), where it is observed that scaling many more demonstrating examples beyond the conventional few-shot setup in the context can lead to performance benefits. However, despite its promise, it is unclear what aspects dominate the benefits and whether simply scaling to more examples is the most effective way of improving many-shot ICL. In this work, we first provide an analysis of the factors driving many-shot ICL, and we find that 1) many-shot performance can still be attributed to often a few disproportionately influential examples and 2) identifying such influential examples ("optimize") and using them as demonstrations to regenerate new examples ("generate") can lead to further improvements. Inspired by the findings, we propose BRIDGE, an algorithm that alternates between the optimize step with Bayesian optimization to discover the influential sets of examples and the generate step to reuse this set to expand the reasoning paths of the examples back to the many-shot regime automatically. On Gemini, Claude, and Mistral LLMs of different sizes, we show that BRIDGE to significant improvements across a diverse set of tasks, including symbolic reasoning, numerical reasoning, and code generation.</li>
</ul>

<h3>Title: BiMaCoSR: Binary One-Step Diffusion Model Leveraging Flexible Matrix Compression for Real Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Kai Liu, Kaicheng Yang, Zheng Chen, Zhiteng Li, Yong Guo, Wenbo Li, Linghe Kong, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00333">https://arxiv.org/abs/2502.00333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00333">https://arxiv.org/pdf/2502.00333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00333]] BiMaCoSR: Binary One-Step Diffusion Model Leveraging Flexible Matrix Compression for Real Super-Resolution(https://arxiv.org/abs/2502.00333)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While super-resolution (SR) methods based on diffusion models (DM) have demonstrated inspiring performance, their deployment is impeded due to the heavy request of memory and computation. Recent researchers apply two kinds of methods to compress or fasten the DM. One is to compress the DM into 1-bit, aka binarization, alleviating the storage and computation pressure. The other distills the multi-step DM into only one step, significantly speeding up inference process. Nonetheless, it remains impossible to deploy DM to resource-limited edge devices. To address this problem, we propose BiMaCoSR, which combines binarization and one-step distillation to obtain extreme compression and acceleration. To prevent the catastrophic collapse of the model caused by binarization, we proposed sparse matrix branch (SMB) and low rank matrixbranch (LRM). Both auxiliary branches pass the full-precision (FP) information but in different ways. SMB absorbs the extreme values and its output is high rank, carrying abundant FP information. Whereas, the design of LRMB is inspired by LoRA and is initialized with the top r SVD components, outputting low rank representation. The computation and storage overhead of our proposed branches can be safely ignored. Comprehensive comparison experiments are conducted to exhibit BiMaCoSR outperforms current state-of-the-art binarization methods and gains competitive performance compared with FP one-step model. BiMaCoSR achieves a 23.8x compression ratio and a 27.4x speedup ratio compared to FP counterpart. Our code and model are available at this https URL.</li>
</ul>

<h3>Title: UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xin Xu, Qiyun Xu, Tong Xiao, Tianhao Chen, Yuchen Yan, Jiaxin Zhang, Shizhe Diao, Can Yang, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00334">https://arxiv.org/abs/2502.00334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00334">https://arxiv.org/pdf/2502.00334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00334]] UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models(https://arxiv.org/abs/2502.00334)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in solving complex reasoning tasks, particularly in mathematics. However, the domain of physics reasoning presents unique challenges that have received significantly less attention. Existing benchmarks often fall short in evaluating LLMs' abilities on the breadth and depth of undergraduate-level physics, underscoring the need for a comprehensive evaluation. To fill this gap, we introduce UGPhysics, a large-scale and comprehensive benchmark specifically designed to evaluate UnderGraduate-level Physics (UGPhysics) reasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics problems in both English and Chinese, covering 13 subjects with seven different answer types and four distinct physics reasoning skills, all rigorously screened for data leakage. Additionally, we develop a Model-Assistant Rule-based Judgment (MARJ) pipeline specifically tailored for assessing answer correctness of physics problems, ensuring accurate evaluation. Our evaluation of 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by OpenAI-o1-mini), emphasizes the necessity for models with stronger physics reasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ, will drive future advancements in AI for physics reasoning.</li>
</ul>

<h3>Title: Denoising Score Matching with Random Features: Insights on Diffusion Models from Precise Learning Curves</h3>
<ul>
<li><strong>Authors: </strong>Anand Jerry George, Rodrigo Veiga, Nicolas Macris</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00336">https://arxiv.org/abs/2502.00336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00336">https://arxiv.org/pdf/2502.00336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00336]] Denoising Score Matching with Random Features: Insights on Diffusion Models from Precise Learning Curves(https://arxiv.org/abs/2502.00336)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We derive asymptotically precise expressions for test and train errors of denoising score matching (DSM) in generative diffusion models. The score function is parameterized by random features neural networks, with the target distribution being $d$-dimensional standard Gaussian. We operate in a regime where the dimension $d$, number of data samples $n$, and number of features $p$ tend to infinity while keeping the ratios $\psi_n=\frac{n}{d}$ and $\psi_p=\frac{p}{d}$ fixed. By characterizing the test and train errors, we identify regimes of generalization and memorization in diffusion models. Furthermore, our work sheds light on the conditions enhancing either generalization or memorization. Consistent with prior empirical observations, our findings indicate that the model complexity ($p$) and the number of noise samples per data sample ($m$) used during DSM significantly influence generalization and memorization behaviors.</li>
</ul>

<h3>Title: Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Jingyuan Yi, Zeqiu Xu, Tianyi Huang, Peiyang Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00339">https://arxiv.org/abs/2502.00339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00339">https://arxiv.org/pdf/2502.00339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00339]] Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions(https://arxiv.org/abs/2502.00339)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The pervasiveness of the dissemination of fake news through social media platforms poses critical risks to the trust of the general public, societal stability, and democratic institutions. This challenge calls for novel methodologies in detection, which can keep pace with the dynamic and multi-modal nature of misinformation. Recent works include powering the detection using large language model advances in multimodal frameworks, methodologies using graphs, and adversarial training in the literature of fake news. Based on the different approaches which can bring success, some key highlights will be underlined: enhanced LLM-improves accuracy through more advanced semantics and cross-modality fusion for robust detections. The review further identifies critical gaps in adaptability to dynamic social media trends, real-time, and cross-platform detection capabilities, as well as the ethical challenges thrown up by the misuse of LLMs. Future directions underline the development of style-agnostic models, cross-lingual detection frameworks, and robust policies with a view to mitigating LLM-driven misinformation. This synthesis thus lays a concrete foundation for those researchers and practitioners committed to reinforcing fake news detection systems with complications that keep on growing in the digital landscape.</li>
</ul>

<h3>Title: Enhancing Token Filtering Efficiency in Large Language Model Training with Collider</h3>
<ul>
<li><strong>Authors: </strong>Di Chai, Pengbo Li, Feiyuan Zhang, Yilun Jin, Han Tian, Junxue Zhang, Kai Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00340">https://arxiv.org/abs/2502.00340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00340">https://arxiv.org/pdf/2502.00340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00340]] Enhancing Token Filtering Efficiency in Large Language Model Training with Collider(https://arxiv.org/abs/2502.00340)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Token filtering has been proposed to enhance utility of large language models (LLMs) by eliminating inconsequential tokens during training. While using fewer tokens should reduce computational workloads, existing studies have not succeeded in achieving higher efficiency. This is primarily due to the insufficient sparsity caused by filtering tokens only in the output layers, as well as inefficient sparse GEMM (General Matrix Multiplication), even when having sufficient sparsity. This paper presents Collider, a system unleashing the full efficiency of token filtering in LLM training. At its core, Collider filters activations of inconsequential tokens across all layers to maintain sparsity. Additionally, it features an automatic workflow that transforms sparse GEMM into dimension-reduced dense GEMM for optimized efficiency. Evaluations on three LLMs-TinyLlama-1.1B, Qwen2.5-1.5B, and Phi1.5-1.4B-demonstrate that Collider reduces backpropagation time by up to 35.1% and end-to-end training time by up to 22.0% when filtering 40% of tokens. Utility assessments of training TinyLlama on 15B tokens indicate that Collider sustains the utility advancements of token filtering by relatively improving model utility by 16.3% comparing to regular training, and reduces training time from 4.7 days to 3.5 days using 8 GPUs. Collider is designed for easy integration into existing LLM training frameworks, allowing systems already using token filtering to accelerate training with just one line of code.</li>
</ul>

<h3>Title: FinchGPT: a Transformer based language model for birdsong analysis</h3>
<ul>
<li><strong>Authors: </strong>Kosei Kobayashi, Kosuke Matsuzaki, Masaya Taniguchi, Keisuke Sakaguchi, Kentaro Inui, Kentaro Abe</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00344">https://arxiv.org/abs/2502.00344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00344">https://arxiv.org/pdf/2502.00344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00344]] FinchGPT: a Transformer based language model for birdsong analysis(https://arxiv.org/abs/2502.00344)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The long-range dependencies among the tokens, which originate from hierarchical structures, are a defining hallmark of human language. However, whether similar dependencies exist within the sequential vocalization of non-human animals remains a topic of investigation. Transformer architectures, known for their ability to model long-range dependencies among tokens, provide a powerful tool for investigating this phenomenon. In this study, we employed the Transformer architecture to analyze the songs of Bengalese finch (Lonchura striata domestica), which are characterized by their highly variable and complex syllable sequences. To this end, we developed FinchGPT, a Transformer-based model trained on a textualized corpus of birdsongs, which outperformed other architecture models in this domain. Attention weight analysis revealed that FinchGPT effectively captures long-range dependencies within syllables sequences. Furthermore, reverse engineering approaches demonstrated the impact of computational and biological manipulations on its performance: restricting FinchGPT's attention span and disrupting birdsong syntax through the ablation of specific brain nuclei markedly influenced the model's outputs. Our study highlights the transformative potential of large language models (LLMs) in deciphering the complexities of animal vocalizations, offering a novel framework for exploring the structural properties of non-human communication systems while shedding light on the computational distinctions between biological brains and artificial neural networks.</li>
</ul>

<h3>Title: Actor Critic with Experience Replay-based automatic treatment planning for prostate cancer intensity modulated radiotherapy</h3>
<ul>
<li><strong>Authors: </strong>Md Mainul Abrar, Parvat Sapkota, Damon Sprouts, Xun Jia, Yujie Chi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00346">https://arxiv.org/abs/2502.00346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00346">https://arxiv.org/pdf/2502.00346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00346]] Actor Critic with Experience Replay-based automatic treatment planning for prostate cancer intensity modulated radiotherapy(https://arxiv.org/abs/2502.00346)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Background: Real-time treatment planning in IMRT is challenging due to complex beam interactions. AI has improved automation, but existing models require large, high-quality datasets and lack universal applicability. Deep reinforcement learning (DRL) offers a promising alternative by mimicking human trial-and-error planning. Purpose: Develop a stochastic policy-based DRL agent for automatic treatment planning with efficient training, broad applicability, and robustness against adversarial attacks using Fast Gradient Sign Method (FGSM). Methods: Using the Actor-Critic with Experience Replay (ACER) architecture, the agent tunes treatment planning parameters (TPPs) in inverse planning. Training is based on prostate cancer IMRT cases, using dose-volume histograms (DVHs) as input. The model is trained on a single patient case, validated on two independent cases, and tested on 300+ plans across three datasets. Plan quality is assessed using ProKnow scores, and robustness is tested against adversarial attacks. Results: Despite training on a single case, the model generalizes well. Before ACER-based planning, the mean plan score was 6.20$\pm$1.84; after, 93.09% of cases achieved a perfect score of 9, with a mean of 8.93$\pm$0.27. The agent effectively prioritizes optimal TPP tuning and remains robust against adversarial attacks. Conclusions: The ACER-based DRL agent enables efficient, high-quality treatment planning in prostate cancer IMRT, demonstrating strong generalizability and robustness.</li>
</ul>

<h3>Title: PM-MOE: Mixture of Experts on Private Model Parameters for Personalized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yu Feng, Yangli-ao Geng, Yifan Zhu, Zongfu Han, Xie Yu, Kaiwen Xue, Haoran Luo, Mengyang Sun, Guangwei Zhang, Meina Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00354">https://arxiv.org/abs/2502.00354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00354">https://arxiv.org/pdf/2502.00354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00354]] PM-MOE: Mixture of Experts on Private Model Parameters for Personalized Federated Learning(https://arxiv.org/abs/2502.00354)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has gained widespread attention for its privacy-preserving and collaborative learning capabilities. Due to significant statistical heterogeneity, traditional FL struggles to generalize a shared model across diverse data domains. Personalized federated learning addresses this issue by dividing the model into a globally shared part and a locally private part, with the local model correcting representation biases introduced by the global model. Nevertheless, locally converged parameters more accurately capture domain-specific knowledge, and current methods overlook the potential benefits of these parameters. To address these limitations, we propose PM-MoE architecture. This architecture integrates a mixture of personalized modules and an energy-based personalized modules denoising, enabling each client to select beneficial personalized parameters from other clients. We applied the PM-MoE architecture to nine recent model-split-based personalized federated learning algorithms, achieving performance improvements with minimal additional training. Extensive experiments on six widely adopted datasets and two heterogeneity settings validate the effectiveness of our approach. The source code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Sampling in High-Dimensions using Stochastic Interpolants and Forward-Backward Stochastic Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Anand Jerry George, Nicolas Macris</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00355">https://arxiv.org/abs/2502.00355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00355">https://arxiv.org/pdf/2502.00355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00355]] Sampling in High-Dimensions using Stochastic Interpolants and Forward-Backward Stochastic Differential Equations(https://arxiv.org/abs/2502.00355)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a class of diffusion-based algorithms to draw samples from high-dimensional probability distributions given their unnormalized densities. Ideally, our methods can transport samples from a Gaussian distribution to a specified target distribution in finite time. Our approach relies on the stochastic interpolants framework to define a time-indexed collection of probability densities that bridge a Gaussian distribution to the target distribution. Subsequently, we derive a diffusion process that obeys the aforementioned probability density at each time instant. Obtaining such a diffusion process involves solving certain Hamilton-Jacobi-Bellman PDEs. We solve these PDEs using the theory of forward-backward stochastic differential equations (FBSDE) together with machine learning-based methods. Through numerical experiments, we demonstrate that our algorithm can effectively draw samples from distributions that conventional methods struggle to handle.</li>
</ul>

<h3>Title: Exploring Representation-Aligned Latent Space for Better Generation</h3>
<ul>
<li><strong>Authors: </strong>Wanghan Xu, Xiaoyu Yue, Zidong Wang, Yao Teng, Wenlong Zhang, Xihui Liu, Luping Zhou, Wanli Ouyang, Lei Bai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00359">https://arxiv.org/abs/2502.00359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00359">https://arxiv.org/pdf/2502.00359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00359]] Exploring Representation-Aligned Latent Space for Better Generation(https://arxiv.org/abs/2502.00359)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Generative models serve as powerful tools for modeling the real world, with mainstream diffusion models, particularly those based on the latent diffusion model paradigm, achieving remarkable progress across various tasks, such as image and video synthesis. Latent diffusion models are typically trained using Variational Autoencoders (VAEs), interacting with VAE latents rather than the real samples. While this generative paradigm speeds up training and inference, the quality of the generated outputs is limited by the latents' quality. Traditional VAE latents are often seen as spatial compression in pixel space and lack explicit semantic representations, which are essential for modeling the real world. In this paper, we introduce ReaLS (Representation-Aligned Latent Space), which integrates semantic priors to improve generation performance. Extensive experiments show that fundamental DiT and SiT trained on ReaLS can achieve a 15% improvement in FID metric. Furthermore, the enhanced semantic latent space enables more perceptual downstream tasks, such as segmentation and depth estimation.</li>
</ul>

<h3>Title: Shape from Semantics: 3D Shape Generation from Multi-View Semantics</h3>
<ul>
<li><strong>Authors: </strong>Liangchen Li, Caoliwen Wang, Yuqi Zhou, Bailin Deng, Juyong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00360">https://arxiv.org/abs/2502.00360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00360">https://arxiv.org/pdf/2502.00360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00360]] Shape from Semantics: 3D Shape Generation from Multi-View Semantics(https://arxiv.org/abs/2502.00360)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose ``Shape from Semantics'', which is able to create 3D models whose geometry and appearance match given semantics when observed from different views. Traditional ``Shape from X'' tasks usually use visual input (e.g., RGB images or depth maps) to reconstruct geometry, imposing strict constraints that limit creative explorations. As applications, works like Shadow Art and Wire Art often struggle to grasp the embedded semantics of their design through direct observation and rely heavily on specific setups for proper display. To address these limitations, our framework uses semantics as input, greatly expanding the design space to create objects that integrate multiple semantic elements and are easily discernible by observers. Considering that this task requires a rich imagination, we adopt various generative models and structure-to-detail pipelines. Specifically, we adopt multi-semantics Score Distillation Sampling (SDS) to distill 3D geometry and appearance from 2D diffusion models, ensuring that the initial shape is consistent with the semantic input. We then use image restoration and video generation models to add more details as supervision. Finally, we introduce neural signed distance field (SDF) representation to achieve detailed shape reconstruction. Our framework generates meshes with complex details, well-structured geometry, coherent textures, and smooth transitions, resulting in visually appealing and eye-catching designs. Project page: this https URL</li>
</ul>

<h3>Title: Soft Diffusion Actor-Critic: Efficient Online Reinforcement Learning for Diffusion Policy</h3>
<ul>
<li><strong>Authors: </strong>Haitong Ma, Tianyi Chen, Kai Wang, Na Li, Bo Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00361">https://arxiv.org/abs/2502.00361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00361">https://arxiv.org/pdf/2502.00361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00361]] Soft Diffusion Actor-Critic: Efficient Online Reinforcement Learning for Diffusion Policy(https://arxiv.org/abs/2502.00361)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion policies have achieved superior performance in imitation learning and offline reinforcement learning (RL) due to their rich expressiveness. However, the vanilla diffusion training procedure requires samples from target distribution, which is impossible in online RL since we cannot sample from the optimal policy, making training diffusion policies highly non-trivial in online RL. Backpropagating policy gradient through the diffusion process incurs huge computational costs and instability, thus being expensive and impractical. To enable efficient diffusion policy training for online RL, we propose Soft Diffusion Actor-Critic (SDAC), exploiting the viewpoint of diffusion models as noise-perturbed energy-based models. The proposed SDAC relies solely on the state-action value function as the energy functions to train diffusion policies, bypassing sampling from the optimal policy while maintaining lightweight computations. We conducted comprehensive comparisons on MuJoCo benchmarks. The empirical results show that SDAC outperforms all recent diffusion-policy online RLs on most tasks, and improves more than 120% over soft actor-critic on complex locomotion tasks such as Humanoid and Ant.</li>
</ul>

<h3>Title: Machine Learning Models for Reinforced Concrete Pipes Condition Prediction: The State-of-the-Art Using Artificial Neural Networks and Multiple Linear Regression in a Wisconsin Case Study</h3>
<ul>
<li><strong>Authors: </strong>Mohsen Mohammadagha, Mohammad Najafi, Vinayak Kaushal, Ahmad Mahmoud Ahmad Jibreen</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00363">https://arxiv.org/abs/2502.00363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00363">https://arxiv.org/pdf/2502.00363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00363]] Machine Learning Models for Reinforced Concrete Pipes Condition Prediction: The State-of-the-Art Using Artificial Neural Networks and Multiple Linear Regression in a Wisconsin Case Study(https://arxiv.org/abs/2502.00363)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The aging sewer infrastructure in the U.S., covering 2.1 million kilometers, encounters increasing structural issues, resulting in around 75,000 yearly sanitary sewer overflows that present serious economic, environmental, and public health hazards. Conventional inspection techniques and deterministic models do not account for the unpredictable nature of sewer decline, whereas probabilistic methods depend on extensive historical data, which is frequently lacking or incomplete. This research intends to enhance predictive accuracy for the condition of sewer pipelines through machine learning models artificial neural networks (ANNs) and multiple linear regression (MLR) by integrating factors such as pipe age, material, diameter, environmental influences, and PACP ratings. ANNs utilized ReLU activation functions and Adam optimization, whereas MLR applied regularization to address multicollinearity, with both models assessed through metrics like RMSE, MAE, and R2. The findings indicated that ANNs surpassed MLR, attaining an R2 of 0.9066 compared to MLRs 0.8474, successfully modeling nonlinear relationships while preserving generalization. MLR, on the other hand, offered enhanced interpretability by pinpointing significant predictors such as residual buildup. As a result, pipeline degradation is driven by pipe length, age, and pipe diameter as key predictors, while depth, soil type, and segment show minimal influence in this analysis. Future studies ought to prioritize hybrid models that merge the accuracy of ANNs with the interpretability of MLR, incorporating advanced methods such as SHAP analysis and transfer learning to improve scalability in managing infrastructure and promoting environmental sustainability.</li>
</ul>

<h3>Title: NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhixi Cai, Fucai Ke, Simindokht Jahangard, Maria Garcia de la Banda, Reza Haffari, Peter J. Stuckey, Hamid Rezatofighi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00372">https://arxiv.org/abs/2502.00372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00372">https://arxiv.org/pdf/2502.00372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00372]] NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning(https://arxiv.org/abs/2502.00372)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Visual Grounding (VG) tasks, such as referring expression detection and segmentation tasks are important for linking visual entities to context, especially in complex reasoning tasks that require detailed query interpretation. This paper explores VG beyond basic perception, highlighting challenges for methods that require reasoning like human cognition. Recent advances in large language methods (LLMs) and Vision-Language methods (VLMs) have improved abilities for visual comprehension, contextual understanding, and reasoning. These methods are mainly split into end-to-end and compositional methods, with the latter offering more flexibility. Compositional approaches that integrate LLMs and foundation models show promising performance but still struggle with complex reasoning with language-based logical representations. To address these limitations, we propose NAVER, a compositional visual grounding method that integrates explicit probabilistic logic reasoning within a finite-state automaton, equipped with a self-correcting mechanism. This design improves robustness and interpretability in inference through explicit logic reasoning. Our results show that NAVER achieves SoTA performance comparing to recent end-to-end and compositional baselines. The code is available at this https URL .</li>
</ul>

<h3>Title: Scalable Framework for Classifying AI-Generated Content Across Modalities</h3>
<ul>
<li><strong>Authors: </strong>Anh-Kiet Duong, Petra Gomez-Krämer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00375">https://arxiv.org/abs/2502.00375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00375">https://arxiv.org/pdf/2502.00375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00375]] Scalable Framework for Classifying AI-Generated Content Across Modalities(https://arxiv.org/abs/2502.00375)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The rapid growth of generative AI technologies has heightened the importance of effectively distinguishing between human and AI-generated content, as well as classifying outputs from diverse generative models. This paper presents a scalable framework that integrates perceptual hashing, similarity measurement, and pseudo-labeling to address these challenges. Our method enables the incorporation of new generative models without retraining, ensuring adaptability and robustness in dynamic scenarios. Comprehensive evaluations on the Defactify4 dataset demonstrate competitive performance in text and image classification tasks, achieving high accuracy across both distinguishing human and AI-generated content and classifying among generative methods. These results highlight the framework's potential for real-world applications as generative AI continues to evolve. Source codes are publicly available at this https URL.</li>
</ul>

<h3>Title: SSRepL-ADHD: Adaptive Complex Representation Learning Framework for ADHD Detection from Visual Attention Tasks</h3>
<ul>
<li><strong>Authors: </strong>Abdul Rehman, Ilona Heldal, Jerry Chun-Wei Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00376">https://arxiv.org/abs/2502.00376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00376">https://arxiv.org/pdf/2502.00376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00376]] SSRepL-ADHD: Adaptive Complex Representation Learning Framework for ADHD Detection from Visual Attention Tasks(https://arxiv.org/abs/2502.00376)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Self Supervised Representation Learning (SSRepL) can capture meaningful and robust representations of the Attention Deficit Hyperactivity Disorder (ADHD) data and have the potential to improve the model's performance on also downstream different types of Neurodevelopmental disorder (NDD) detection. In this paper, a novel SSRepL and Transfer Learning (TL)-based framework that incorporates a Long Short-Term Memory (LSTM) and a Gated Recurrent Units (GRU) model is proposed to detect children with potential symptoms of ADHD. This model uses Electroencephalogram (EEG) signals extracted during visual attention tasks to accurately detect ADHD by preprocessing EEG signal quality through normalization, filtering, and data balancing. For the experimental analysis, we use three different models: 1) SSRepL and TL-based LSTM-GRU model named as SSRepL-ADHD, which integrates LSTM and GRU layers to capture temporal dependencies in the data, 2) lightweight SSRepL-based DNN model (LSSRepL-DNN), and 3) Random Forest (RF). In the study, these models are thoroughly evaluated using well-known performance metrics (i.e., accuracy, precision, recall, and F1-score). The results show that the proposed SSRepL-ADHD model achieves the maximum accuracy of 81.11% while admitting the difficulties associated with dataset imbalance and feature selection.</li>
</ul>

<h3>Title: CoHiRF: A Scalable and Interpretable Clustering Framework for High-Dimensional Data</h3>
<ul>
<li><strong>Authors: </strong>Bruno Belucci, Karim Lounici, Katia Meziani</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00380">https://arxiv.org/abs/2502.00380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00380">https://arxiv.org/pdf/2502.00380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00380]] CoHiRF: A Scalable and Interpretable Clustering Framework for High-Dimensional Data(https://arxiv.org/abs/2502.00380)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Clustering high-dimensional data poses significant challenges due to the curse of dimensionality, scalability issues, and the presence of noisy and irrelevant features. We propose Consensus Hierarchical Random Feature (CoHiRF), a novel clustering method designed to address these challenges effectively. CoHiRF leverages random feature selection to mitigate noise and dimensionality effects, repeatedly applies K-Means clustering in reduced feature spaces, and combines results through a unanimous consensus criterion. This iterative approach constructs a cluster assignment matrix, where each row records the cluster assignments of a sample across repetitions, enabling the identification of stable clusters by comparing identical rows. Clusters are organized hierarchically, enabling the interpretation of the hierarchy to gain insights into the dataset. CoHiRF is computationally efficient with a running time comparable to K-Means, scalable to massive datasets, and exhibits robust performance against state-of-the-art methods such as SC-SRGF, HDBSCAN, and OPTICS. Experimental results on synthetic and real-world datasets confirm the method's ability to reveal meaningful patterns while maintaining scalability, making it a powerful tool for high-dimensional data analysis.</li>
</ul>

<h3>Title: Masked Generative Nested Transformers with Decode Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Sahil Goyal, Debapriya Tula, Gagan Jain, Pradeep Shenoy, Prateek Jain, Sujoy Paul</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00382">https://arxiv.org/abs/2502.00382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00382">https://arxiv.org/pdf/2502.00382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00382]] Masked Generative Nested Transformers with Decode Time Scaling(https://arxiv.org/abs/2502.00382)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in visual generation have made significant strides in producing content of exceptional quality. However, most methods suffer from a fundamental problem - a bottleneck of inference computational efficiency. Most of these algorithms involve multiple passes over a transformer model to generate tokens or denoise inputs. However, the model size is kept consistent throughout all iterations, which makes it computationally expensive. In this work, we aim to address this issue primarily through two key ideas - (a) not all parts of the generation process need equal compute, and we design a decode time model scaling schedule to utilize compute effectively, and (b) we can cache and reuse some of the computation. Combining these two ideas leads to using smaller models to process more tokens while large models process fewer tokens. These different-sized models do not increase the parameter size, as they share parameters. We rigorously experiment with ImageNet256$\times$256 , UCF101, and Kinetics600 to showcase the efficacy of the proposed method for image/video generation and frame prediction. Our experiments show that with almost $3\times$ less compute than baseline, our model obtains competitive performance.</li>
</ul>

<h3>Title: It's Not Just a Phase: On Investigating Phase Transitions in Deep Learning-based Side-channel Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sengim Karayalçin, Marina Krček, Stjepan Picek</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00384">https://arxiv.org/abs/2502.00384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00384">https://arxiv.org/pdf/2502.00384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00384]] It's Not Just a Phase: On Investigating Phase Transitions in Deep Learning-based Side-channel Analysis(https://arxiv.org/abs/2502.00384)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, interpretability</a></li>
<li><strong>Abstract: </strong>Side-channel analysis (SCA) represents a realistic threat where the attacker can observe unintentional information to obtain secret data. Evaluation labs also use the same SCA techniques in the security certification process. The results in the last decade have shown that machine learning, especially deep learning, is an extremely powerful SCA approach, allowing the breaking of protected devices while achieving optimal attack performance. Unfortunately, deep learning operates as a black-box, making it less useful for security evaluators who must understand how attacks work to prevent them in the future. This work demonstrates that mechanistic interpretability can effectively scale to realistic scenarios where relevant information is sparse and well-defined interchange interventions to the input are impossible due to side-channel protections. Concretely, we reverse engineer the features the network learns during phase transitions, eventually retrieving secret masks, allowing us to move from black-box to white-box evaluation.</li>
</ul>

<h3>Title: The Impact of Persona-based Political Perspectives on Hateful Content Detection</h3>
<ul>
<li><strong>Authors: </strong>Stefano Civelli, Pietro Bernardelle, Gianluca Demartini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00385">https://arxiv.org/abs/2502.00385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00385">https://arxiv.org/pdf/2502.00385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00385]] The Impact of Persona-based Political Perspectives on Hateful Content Detection(https://arxiv.org/abs/2502.00385)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>While pretraining language models with politically diverse content has been shown to improve downstream task fairness, such approaches require significant computational resources often inaccessible to many researchers and organizations. Recent work has established that persona-based prompting can introduce political diversity in model outputs without additional training. However, it remains unclear whether such prompting strategies can achieve results comparable to political pretraining for downstream tasks. We investigate this question using persona-based prompting strategies in multimodal hate-speech detection tasks, specifically focusing on hate speech in memes. Our analysis reveals that when mapping personas onto a political compass and measuring persona agreement, inherent political positioning has surprisingly little correlation with classification decisions. Notably, this lack of correlation persists even when personas are explicitly injected with stronger ideological descriptors. Our findings suggest that while LLMs can exhibit political biases in their responses to direct political questions, these biases may have less impact on practical classification tasks than previously assumed. This raises important questions about the necessity of computationally expensive political pretraining for achieving fair performance in downstream tasks.</li>
</ul>

<h3>Title: Efficient Adaptive Label Refinement for Label Noise Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenzhen Zhang, Debo Cheng, Guangquan Lu, Bo Zhou, Jiaye Li, Shichao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00386">https://arxiv.org/abs/2502.00386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00386">https://arxiv.org/pdf/2502.00386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00386]] Efficient Adaptive Label Refinement for Label Noise Learning(https://arxiv.org/abs/2502.00386)</code><input type="text"></li>
<li><strong>Keywords: </strong>noise learning</a></li>
<li><strong>Abstract: </strong>Deep neural networks are highly susceptible to overfitting noisy labels, which leads to degraded performance. Existing methods address this issue by employing manually defined criteria, aiming to achieve optimal partitioning in each iteration to avoid fitting noisy labels while thoroughly learning clean samples. However, this often results in overly complex and difficult-to-train models. To address this issue, we decouple the tasks of avoiding fitting incorrect labels and thoroughly learning clean samples and propose a simple yet highly applicable method called Adaptive Label Refinement (ALR). First, inspired by label refurbishment techniques, we update the original hard labels to soft labels using the model's predictions to reduce the risk of fitting incorrect labels. Then, by introducing the entropy loss, we gradually `harden' the high-confidence soft labels, guiding the model to better learn from clean samples. This approach is simple and efficient, requiring no prior knowledge of noise or auxiliary datasets, making it more accessible compared to existing methods. We validate ALR's effectiveness through experiments on benchmark datasets with artificial label noise (CIFAR-10/100) and real-world datasets with inherent noise (ANIMAL-10N, Clothing1M, WebVision). The results show that ALR outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: Minimalistic Video Saliency Prediction via Efficient Decoder & Spatio Temporal Action Cues</h3>
<ul>
<li><strong>Authors: </strong>Rohit Girmaji, Siddharth Jain, Bhav Beri, Sarthak Bansal, Vineet Gandhi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00397">https://arxiv.org/abs/2502.00397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00397">https://arxiv.org/pdf/2502.00397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00397]] Minimalistic Video Saliency Prediction via Efficient Decoder & Spatio Temporal Action Cues(https://arxiv.org/abs/2502.00397)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces ViNet-S, a 36MB model based on the ViNet architecture with a U-Net design, featuring a lightweight decoder that significantly reduces model size and parameters without compromising performance. Additionally, ViNet-A (148MB) incorporates spatio-temporal action localization (STAL) features, differing from traditional video saliency models that use action classification backbones. Our studies show that an ensemble of ViNet-S and ViNet-A, by averaging predicted saliency maps, achieves state-of-the-art performance on three visual-only and six audio-visual saliency datasets, outperforming transformer-based models in both parameter efficiency and real-time performance, with ViNet-S reaching over 1000fps.</li>
</ul>

<h3>Title: Exploring Linear Attention Alternative for Single Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Rongchang Lu, Changyu Li, Donghang Li, Guojing Zhang, Jianqiang Huang, Xilai Li</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00404">https://arxiv.org/abs/2502.00404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00404">https://arxiv.org/pdf/2502.00404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00404]] Exploring Linear Attention Alternative for Single Image Super-Resolution(https://arxiv.org/abs/2502.00404)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Deep learning-based single-image super-resolution (SISR) technology focuses on enhancing low-resolution (LR) images into high-resolution (HR) ones. Although significant progress has been made, challenges remain in computational complexity and quality, particularly in remote sensing image processing. To address these issues, we propose our Omni-Scale RWKV Super-Resolution (OmniRWKVSR) model which presents a novel approach that combines the Receptance Weighted Key Value (RWKV) architecture with feature extraction techniques such as Visual RWKV Spatial Mixing (VRSM) and Visual RWKV Channel Mixing (VRCM), aiming to overcome the limitations of existing methods and achieve superior SISR performance. This work has proved able to provide effective solutions for high-quality image reconstruction. Under the 4x Super-Resolution tasks, compared to the MambaIR model, we achieved an average improvement of 0.26% in PSNR and 0.16% in SSIM.</li>
</ul>

<h3>Title: Social media polarization during conflict: Insights from an ideological stance dataset on Israel-Palestine Reddit comments</h3>
<ul>
<li><strong>Authors: </strong>Hasin Jawad Ali, Ajwad Abrar, S.M. Hozaifa Hossain, M. Firoz Mridha</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00414">https://arxiv.org/abs/2502.00414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00414">https://arxiv.org/pdf/2502.00414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00414]] Social media polarization during conflict: Insights from an ideological stance dataset on Israel-Palestine Reddit comments(https://arxiv.org/abs/2502.00414)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In politically sensitive scenarios like wars, social media serves as a platform for polarized discourse and expressions of strong ideological stances. While prior studies have explored ideological stance detection in general contexts, limited attention has been given to conflict-specific settings. This study addresses this gap by analyzing 9,969 Reddit comments related to the Israel-Palestine conflict, collected between October 2023 and August 2024. The comments were categorized into three stance classes: Pro-Israel, Pro-Palestine, and Neutral. Various approaches, including machine learning, pre-trained language models, neural networks, and prompt engineering strategies for open source large language models (LLMs), were employed to classify these stances. Performance was assessed using metrics such as accuracy, precision, recall, and F1-score. Among the tested methods, the Scoring and Reflective Re-read prompt in Mixtral 8x7B demonstrated the highest performance across all metrics. This study provides comparative insights into the effectiveness of different models for detecting ideological stances in highly polarized social media contexts. The dataset used in this research is publicly available for further exploration and validation.</li>
</ul>

<h3>Title: Parameter Efficient Fine-Tuning of Segment Anything Model</h3>
<ul>
<li><strong>Authors: </strong>Carolin Teuber, Anwai Archit, Constantin Pape</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00418">https://arxiv.org/abs/2502.00418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00418">https://arxiv.org/pdf/2502.00418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00418]] Parameter Efficient Fine-Tuning of Segment Anything Model(https://arxiv.org/abs/2502.00418)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Segmentation is an important analysis task for biomedical images, enabling the study of individual organelles, cells or organs. Deep learning has massively improved segmentation methods, but challenges remain in generalization to new conditions, requiring costly data annotation. Vision foundation models, such as Segment Anything Model (SAM), address this issue through broad segmentation capabilities. However, these models still require finetuning on annotated data, although with less annotations, to achieve optimal results for new conditions. As a downside, they require more computational resources. This makes parameter-efficient finetuning (PEFT) relevant for their application. We contribute the first comprehensive study of PEFT for SAM applied to biomedical segmentation by evaluating 9 PEFT methods on diverse datasets. We also provide an implementation of QLoRA for vision transformers and a new approach for resource-efficient finetuning of SAM. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization</h3>
<ul>
<li><strong>Authors: </strong>JiangYong Yu, Sifan Zhou, Dawei Yang, Shuo Wang, Shuoyu Li, Xing Hu, Chen Xu, Zukang Xu, Changyong Shu, Zhihang Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00425">https://arxiv.org/abs/2502.00425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00425">https://arxiv.org/pdf/2502.00425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00425]] MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization(https://arxiv.org/abs/2502.00425)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have garnered widespread attention due to their ability to understand multimodal input. However, their large parameter sizes and substantial computational demands severely hinder their practical deployment and this http URL quantization is an effective way to reduce model size and inference latency, its application to MLLMs remains underexplored. In this paper, we propose MQuant, a post-training quantization (PTQ) framework designed to tackle the unique challenges of multimodal large language models (MLLMs). Conventional quantization often struggles with MLLMs because of (a) high inference latency from large visual token counts, (b) distributional disparities between visual and textual tokens, and (c) extreme outliers introduced by Hadamard-based transformations. To address these issues, MQuant introduces: Modality-Specific Static Quantization (MSQ), assigning distinct static scales for visual vs. textual tokens; Attention-Invariant Flexible Switching (AIFS), reordering tokens to preserve casual attention while eliminating expensive token-wise scale computations; Rotation Magnitude Suppression (RMS), mitigating weight outliers arising from online Hadamard rotations. On five mainstream MLLMs (including Qwen-VL, MiniCPM-V, CogVLM2), MQuant under W4A8 achieves near-floating-point accuracy (<1% degradation) while reducing inference latency by up to 30%, significantly outperforming existing PTQ baselines. Our MQuant effectively bridges the gap for efficient and accurate MLLMs inference in resource-constrained devices. Code will be released.</li>
</ul>

<h3>Title: TeST-V: TEst-time Support-set Tuning for Zero-shot Video Classification</h3>
<ul>
<li><strong>Authors: </strong>Rui Yan, Jin Wang, Hongyu Qu, Xiaoyu Du, Dong Zhang, Jinhui Tang, Tieniu Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00426">https://arxiv.org/abs/2502.00426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00426">https://arxiv.org/pdf/2502.00426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00426]] TeST-V: TEst-time Support-set Tuning for Zero-shot Video Classification(https://arxiv.org/abs/2502.00426)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Recently, adapting Vision Language Models (VLMs) to zero-shot visual classification by tuning class embedding with a few prompts (Test-time Prompt Tuning, TPT) or replacing class names with generated visual samples (support-set) has shown promising results. However, TPT cannot avoid the semantic gap between modalities while the support-set cannot be tuned. To this end, we draw on each other's strengths and propose a novel framework namely TEst-time Support-set Tuning for zero-shot Video Classification (TEST-V). It first dilates the support-set with multiple prompts (Multi-prompting Support-set Dilation, MSD) and then erodes the support-set via learnable weights to mine key cues dynamically (Temporal-aware Support-set Erosion, TSE). Specifically, i) MSD expands the support samples for each class based on multiple prompts enquired from LLMs to enrich the diversity of the support-set. ii) TSE tunes the support-set with factorized learnable weights according to the temporal prediction consistency in a self-supervised manner to dig pivotal supporting cues for each class. $\textbf{TEST-V}$ achieves state-of-the-art results across four benchmarks and has good interpretability for the support-set dilation and erosion.</li>
</ul>

<h3>Title: CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xinle Cheng, Zhuoming Chen, Zhihao Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00433">https://arxiv.org/abs/2502.00433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00433">https://arxiv.org/pdf/2502.00433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00433]] CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models(https://arxiv.org/abs/2502.00433)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have revolutionized generative tasks, especially in the domain of text-to-image synthesis; however, their iterative denoising process demands substantial computational resources. In this paper, we present a novel acceleration strategy that integrates token-level pruning with caching techniques to tackle this computational challenge. By employing noise relative magnitude, we identify significant token changes across denoising iterations. Additionally, we enhance token selection by incorporating spatial clustering and ensuring distributional balance. Our experiments demonstrate reveal a 50%-60% reduction in computational costs while preserving the performance of the model, thereby markedly increasing the efficiency of diffusion models. The code is available at this https URL</li>
</ul>

<h3>Title: SatMamba: Development of Foundation Models for Remote Sensing Imagery Using State Space Models</h3>
<ul>
<li><strong>Authors: </strong>Chuc Man Duc, Hiromichi Fukui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00435">https://arxiv.org/abs/2502.00435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00435">https://arxiv.org/pdf/2502.00435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00435]] SatMamba: Development of Foundation Models for Remote Sensing Imagery Using State Space Models(https://arxiv.org/abs/2502.00435)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Foundation models refer to deep learning models pretrained on large unlabeled datasets through self-supervised algorithms. In the Earth science and remote sensing communities, there is growing interest in transforming the use of Earth observation data, including satellite and aerial imagery, through foundation models. Various foundation models have been developed for remote sensing, such as those for multispectral, high-resolution, and hyperspectral images, and have demonstrated superior performance on various downstream tasks compared to traditional supervised models. These models are evolving rapidly, with capabilities to handle multispectral, multitemporal, and multisensor data. Most studies use masked autoencoders in combination with Vision Transformers (ViTs) as the backbone for pretraining. While the models showed promising performance, ViTs face challenges, such as quadratic computational scaling with input length, which may limit performance on multiband and multitemporal data with long sequences. This research aims to address these challenges by proposing SatMamba, a new pretraining framework that combines masked autoencoders with State Space Model, offering linear computational scaling. Experiments on high-resolution imagery across various downstream tasks show promising results, paving the way for more efficient foundation models and unlocking the full potential of Earth observation data. The source code is available in this https URL.</li>
</ul>

<h3>Title: UniAttn: Reducing Inference Costs via Softmax Unification for Post-Training LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yizhe Xiong, Wei Huang, Xin Ye, Hui Chen, Zijia Lin, Haoran Lian, Zhenpeng Su, Jungong Han, Guiguang Ding</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00439">https://arxiv.org/abs/2502.00439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00439">https://arxiv.org/pdf/2502.00439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00439]] UniAttn: Reducing Inference Costs via Softmax Unification for Post-Training LLMs(https://arxiv.org/abs/2502.00439)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Post-training is essential for adapting Large Language Models (LLMs) to real-world applications. Deploying post-trained models faces significant challenges due to substantial memory overhead and noticeable inference latency. Existing work has identified significant redundancies in LLMs and proposed efficient architectures, namely intra-layer KV sharing and cross-layer KV sharing. However, intra-layer KV sharing still results in high inference costs, while cross-layer KV sharing leads to significant performance degradation. As a result, both methods remain suboptimal for post-training pre-trained LLMs. In this paper, we identify that the \texttt{Softmax} operation is a primary bottleneck for LLM inference and discover that it is actually highly redundant during post-training. We propose Softmax \textbf{Uni}fication in \textbf{Att}e\textbf{n}tion (\textbf{UniAttn}), a novel post-training method that unifies Softmax activations across transformer blocks to reduce LLM inference costs. Additionally, UniAttn adopts a linear projection to compensate for the errors induced by Softmax unification. Experiments show that UniAttn matches the performance of standard post-training while significantly reducing inference costs, outperforming existing efficient architectures during post-training. Our code will be available at \url{this https URL}.</li>
</ul>

<h3>Title: HERA: Improving Long Document Summarization using Large Language Models with Context Packaging and Reordering</h3>
<ul>
<li><strong>Authors: </strong>Taiji Li, Hao Chen, Fei Yu, Yin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00448">https://arxiv.org/abs/2502.00448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00448">https://arxiv.org/pdf/2502.00448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00448]] HERA: Improving Long Document Summarization using Large Language Models with Context Packaging and Reordering(https://arxiv.org/abs/2502.00448)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the rapid growth of context length of large language models (LLMs) , LLMs still perform poorly in long document summarization. An important reason for this is that relevant information about an event is scattered throughout long documents, and the messy narrative order impairs the accurate understanding and utilization of LLMs for long documents. To address these issues, we propose a novel summary generation framework, called HERA. Specifically, we first segment a long document by its semantic structure and retrieve text segments about the same event, and finally reorder them to form the input context. We evaluate our approach on two long document summarization datasets. The experimental results show that HERA outperforms foundation models in ROUGE, BERTScore and faithfulness metrics, while HERA does not require additional fine-tuning and resources.</li>
</ul>

<h3>Title: Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00451">https://arxiv.org/abs/2502.00451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00451">https://arxiv.org/pdf/2502.00451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00451]] Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities(https://arxiv.org/abs/2502.00451)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Mental illness is a widespread and debilitating condition with substantial societal and personal costs. Traditional diagnostic and treatment approaches, such as self-reported questionnaires and psychotherapy sessions, often impose significant burdens on both patients and clinicians, limiting accessibility and efficiency. Recent advances in Artificial Intelligence (AI), particularly in Natural Language Processing and multimodal techniques, hold great potential for recognizing and addressing conditions such as depression, anxiety, bipolar disorder, schizophrenia, and post-traumatic stress disorder. However, privacy concerns, including the risk of sensitive data leakage from datasets and trained models, remain a critical barrier to deploying these AI systems in real-world clinical settings. These challenges are amplified in multimodal methods, where personal identifiers such as voice and facial data can be misused. This paper presents a critical and comprehensive study of the privacy challenges associated with developing and deploying AI models for mental health. We further prescribe potential solutions, including data anonymization, synthetic data generation, and privacy-preserving model training, to strengthen privacy safeguards in practical applications. Additionally, we discuss evaluation frameworks to assess the privacy-utility trade-offs in these approaches. By addressing these challenges, our work aims to advance the development of reliable, privacy-aware AI tools to support clinical decision-making and improve mental health outcomes.</li>
</ul>

<h3>Title: Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know...</h3>
<ul>
<li><strong>Authors: </strong>Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00456">https://arxiv.org/abs/2502.00456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00456">https://arxiv.org/pdf/2502.00456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00456]] Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know...(https://arxiv.org/abs/2502.00456)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Ensuring the reliability and safety of automated decision-making is crucial. This paper proposes a new approach for measuring the reliability of predictions in machine learning models. We analyze how the outputs of a trained neural network change using clustering to measure distances between outputs and class centroids. We propose this distance as a metric to evaluate the confidence of predictions. We assign each prediction to a cluster with centroid representing the mean softmax output for all correct predictions of a given class. We then define a safety threshold for a class as the smallest distance from an incorrect prediction to the given class centroid. We evaluate the approach on the MNIST and CIFAR-10 datasets using a Convolutional Neural Network and a Vision Transformer, respectively. The results show that our approach is consistent across these data sets and network models, and indicate that the proposed metric can offer an efficient way of determining when automated predictions are acceptable and when they should be deferred to human operators.</li>
</ul>

<h3>Title: MambaGlue: Fast and Robust Local Feature Matching With Mamba</h3>
<ul>
<li><strong>Authors: </strong>Kihwan Ryoo, Hyungtae Lim, Hyun Myung</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00462">https://arxiv.org/abs/2502.00462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00462">https://arxiv.org/pdf/2502.00462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00462]] MambaGlue: Fast and Robust Local Feature Matching With Mamba(https://arxiv.org/abs/2502.00462)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In recent years, robust matching methods using deep learning-based approaches have been actively studied and improved in computer vision tasks. However, there remains a persistent demand for both robust and fast matching techniques. To address this, we propose a novel Mamba-based local feature matching approach, called MambaGlue, where Mamba is an emerging state-of-the-art architecture rapidly gaining recognition for its superior speed in both training and inference, and promising performance compared with Transformer architectures. In particular, we propose two modules: a) MambaAttention mixer to simultaneously and selectively understand the local and global context through the Mamba-based self-attention structure and b) deep confidence score regressor, which is a multi-layer perceptron (MLP)-based architecture that evaluates a score indicating how confidently matching predictions correspond to the ground-truth correspondences. Consequently, our MambaGlue achieves a balance between robustness and efficiency in real-world applications. As verified on various public datasets, we demonstrate that our MambaGlue yields a substantial performance improvement over baseline approaches while maintaining fast inference speed. Our code will be available on this https URL</li>
</ul>

<h3>Title: Enhancing Memory and Imagination Consistency in Diffusion-based World Models via Linear-Time Sequence Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jia-Hua Lee, Bor-Jiun Lin, Wei-Fang Sun, Chun-Yi Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00466">https://arxiv.org/abs/2502.00466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00466">https://arxiv.org/pdf/2502.00466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00466]] Enhancing Memory and Imagination Consistency in Diffusion-based World Models via Linear-Time Sequence Modeling(https://arxiv.org/abs/2502.00466)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>World models are crucial for enabling agents to simulate and plan within environments, yet existing approaches struggle with long-term dependencies and inconsistent predictions. We introduce EDELINE, a novel framework that integrates diffusion models with linear-time state space modelsto enhance memory retention and temporal consistency. EDELINE employs a recurrent embedding module based on Mamba SSMs for processing unbounded sequences, a unified architecture for joint reward and termination prediction, and dynamic loss harmonization to balance multi-task learning. Our results across multiple benchmarks demonstrate EDELINE's superiority and robustness over prior baselines in long-horizon tasks.</li>
</ul>

<h3>Title: Binned Spectral Power Loss for Improved Prediction of Chaotic Systems</h3>
<ul>
<li><strong>Authors: </strong>Dibyajyoti Chakraborty, Arvind T. Mohan, Romit Maulik</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00472">https://arxiv.org/abs/2502.00472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00472">https://arxiv.org/pdf/2502.00472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00472]] Binned Spectral Power Loss for Improved Prediction of Chaotic Systems(https://arxiv.org/abs/2502.00472)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Forecasting multiscale chaotic dynamical systems with deep learning remains a formidable challenge due to the spectral bias of neural networks, which hinders the accurate representation of fine-scale structures in long-term predictions. This issue is exacerbated when models are deployed autoregressively, leading to compounding errors and instability. In this work, we introduce a novel approach to mitigate the spectral bias which we call the Binned Spectral Power (BSP) Loss. The BSP loss is a frequency-domain loss function that adaptively weighs errors in predicting both larger and smaller scales of the dataset. Unlike traditional losses that focus on pointwise misfits, our BSP loss explicitly penalizes deviations in the energy distribution across different scales, promoting stable and physically consistent predictions. We demonstrate that the BSP loss mitigates the well-known problem of spectral bias in deep learning. We further validate our approach for the data-driven high-dimensional time-series forecasting of a range of benchmark chaotic systems which are typically intractable due to spectral bias. Our results demonstrate that the BSP loss significantly improves the stability and spectral accuracy of neural forecasting models without requiring architectural modifications. By directly targeting spectral consistency, our approach paves the way for more robust deep learning models for long-term forecasting of chaotic dynamical systems.</li>
</ul>

<h3>Title: Weak-to-Strong Diffusion with Reflection</h3>
<ul>
<li><strong>Authors: </strong>Lichen Bai, Masashi Sugiyama, Zeke Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00473">https://arxiv.org/abs/2502.00473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00473">https://arxiv.org/pdf/2502.00473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00473]] Weak-to-Strong Diffusion with Reflection(https://arxiv.org/abs/2502.00473)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The goal of diffusion generative models is to align the learned distribution with the real data distribution through gradient score matching. However, inherent limitations in training data quality, modeling strategies, and architectural design lead to inevitable gap between generated outputs and real data. To reduce this gap, we propose Weak-to-Strong Diffusion (W2SD), a novel framework that utilizes the estimated difference between existing weak and strong models (i.e., weak-to-strong difference) to approximate the gap between an ideal model and a strong model. By employing a reflective operation that alternates between denoising and inversion with weak-to-strong difference, we theoretically understand that W2SD steers latent variables along sampling trajectories toward regions of the real data distribution. W2SD is highly flexible and broadly applicable, enabling diverse improvements through the strategic selection of weak-to-strong model pairs (e.g., DreamShaper vs. SD1.5, good experts vs. bad experts in MoE). Extensive experiments demonstrate that W2SD significantly improves human preference, aesthetic quality, and prompt adherence, achieving SOTA performance across various modalities (e.g., image, video), architectures (e.g., UNet-based, DiT-based, MoE), and benchmarks. For example, Juggernaut-XL with W2SD can improve with the HPSv2 winning rate up to 90% over the original results. Moreover, the performance gains achieved by W2SD markedly outweigh its additional computational overhead, while the cumulative improvements from different weak-to-strong difference further solidify its practical utility and deployability.</li>
</ul>

<h3>Title: A framework for river connectivity classification using temporal image processing and attention based neural networks</h3>
<ul>
<li><strong>Authors: </strong>Timothy James Becker, Derin Gezgin, Jun Yi He Wu, Mary Becker</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00474">https://arxiv.org/abs/2502.00474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00474">https://arxiv.org/pdf/2502.00474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00474]] A framework for river connectivity classification using temporal image processing and attention based neural networks(https://arxiv.org/abs/2502.00474)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Measuring the connectivity of water in rivers and streams is essential for effective water resource management. Increased extreme weather events associated with climate change can result in alterations to river and stream connectivity. While traditional stream flow gauges are costly to deploy and limited to large river bodies, trail camera methods are a low-cost and easily deployed alternative to collect hourly data. Image capturing, however requires stream ecologists to manually curate (select and label) tens of thousands of images per year. To improve this workflow, we developed an automated instream trail camera image classification system consisting of three parts: (1) image processing, (2) image augmentation and (3) machine learning. The image preprocessing consists of seven image quality filters, foliage-based luma variance reduction, resizing and bottom-center cropping. Images are balanced using variable amount of generative augmentation using diffusion models and then passed to a machine learning classification model in labeled form. By using the vision transformer architecture and temporal image enhancement in our framework, we are able to increase the 75% base accuracy to 90% for a new unseen site image. We make use of a dataset captured and labeled by staff from the Connecticut Department of Energy and Environmental Protection between 2018-2020. Our results indicate that a combination of temporal image processing and attention-based models are effective at classifying unseen river connectivity images.</li>
</ul>

<h3>Title: Oscillations Make Neural Networks Robust to Quantization</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Wenshøj, Bob Pepin, Raghavendra Selvan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00490">https://arxiv.org/abs/2502.00490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00490">https://arxiv.org/pdf/2502.00490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00490]] Oscillations Make Neural Networks Robust to Quantization(https://arxiv.org/abs/2502.00490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We challenge the prevailing view that oscillations in Quantization Aware Training (QAT) are merely undesirable artifacts caused by the Straight-Through Estimator (STE). Through theoretical analysis of QAT in linear models, we demonstrate that the gradient of the loss function can be decomposed into two terms: the original full-precision loss and a term that causes quantization oscillations. Based on these insights, we propose a novel regularization method that induces oscillations to improve quantization robustness. Contrary to traditional methods that focuses on minimizing the effects of oscillations, our approach leverages the beneficial aspects of weight oscillations to preserve model performance under quantization. Our empirical results on ResNet-18 and Tiny ViT demonstrate that this counter-intuitive strategy matches QAT accuracy at >= 3-bit weight quantization, while maintaining close to full precision accuracy at bits greater than the target bit. Our work therefore provides a new perspective on model preparation for quantization, particularly for finding weights that are robust to changes in the bit of the quantizer -- an area where current methods struggle to match the accuracy of QAT at specific bits.</li>
</ul>

<h3>Title: Data Overvaluation Attack and Truthful Data Valuation</h3>
<ul>
<li><strong>Authors: </strong>Shuyuan Zheng, Sudong Cai, Chuan Xiao, Yang Cao, Jainbin Qin, Masatoshi Yoshikawa, Makoto Onizuka</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00494">https://arxiv.org/abs/2502.00494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00494">https://arxiv.org/pdf/2502.00494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00494]] Data Overvaluation Attack and Truthful Data Valuation(https://arxiv.org/abs/2502.00494)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>In collaborative machine learning, data valuation, i.e., evaluating the contribution of each client' data to the machine learning model, has become a critical task for incentivizing and selecting positive data contributions. However, existing studies often assume that clients engage in data valuation truthfully, overlooking the practical motivation for clients to exaggerate their contributions. To unlock this threat, this paper introduces the first data overvaluation attack, enabling strategic clients to have their data significantly overvalued. Furthermore, we propose a truthful data valuation metric, named Truth-Shapley. Truth-Shapley is the unique metric that guarantees some promising axioms for data valuation while ensuring that clients' optimal strategy is to perform truthful data valuation. Our experiments demonstrate the vulnerability of existing data valuation metrics to the data overvaluation attack and validate the robustness and effectiveness of Truth-Shapley.</li>
</ul>

<h3>Title: Convolutional Fourier Analysis Network (CFAN): A Unified Time-Frequency Approach for ECG Classification</h3>
<ul>
<li><strong>Authors: </strong>Sam Jeong, Hae Yong Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00497">https://arxiv.org/abs/2502.00497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00497">https://arxiv.org/pdf/2502.00497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00497]] Convolutional Fourier Analysis Network (CFAN): A Unified Time-Frequency Approach for ECG Classification(https://arxiv.org/abs/2502.00497)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Machine learning has transformed the classification of biomedical signals such as electrocardiograms (ECGs). Advances in deep learning, particularly convolutional neural networks (CNNs), enable automatic feature extraction, raising the question: Can combining time- and frequency-domain attributes enhance classification accuracy? To explore this, we evaluated three ECG classification tasks: (1) arrhythmia detection, (2) identity recognition, and (3) apnea detection. We initially tested three methods: (i) 2-D spectrogram-based frequency-time classification (SPECT), (ii) time-domain classification using a 1-D CNN (CNN1D), and (iii) frequency-domain classification using a Fourier transform-based CNN (FFT1D). Performance was validated using K-fold cross-validation. Among these, CNN1D (time only) performed best, followed by SPECT (time-frequency) and FFT1D (frequency only). Surprisingly, SPECT, which integrates time- and frequency-domain features, performed worse than CNN1D, suggesting a need for a more effective time and frequency fusion approach. To address this, we tested the recently proposed Fourier Analysis Network (FAN), which combines time- and frequency-domain features. However, FAN performed comparably to CNN1D, excelling in some tasks while underperforming in others. To enhance this approach, we developed the Convolutional Fourier Analysis Network (CFAN), which integrates FAN with CNN. CFAN outperformed all previous methods across all classification tasks. These findings underscore the advantages of combining time- and frequency-domain features, demonstrating CFAN's potential as a powerful and versatile solution for ECG classification and broader biomedical signal analysis</li>
</ul>

<h3>Title: Video Latent Flow Matching: Optimal Polynomial Projections for Video Interpolation and Extrapolation</h3>
<ul>
<li><strong>Authors: </strong>Yang Cao, Zhao Song, Chiwun Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00500">https://arxiv.org/abs/2502.00500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00500">https://arxiv.org/pdf/2502.00500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00500]] Video Latent Flow Matching: Optimal Polynomial Projections for Video Interpolation and Extrapolation(https://arxiv.org/abs/2502.00500)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper considers an efficient video modeling process called Video Latent Flow Matching (VLFM). Unlike prior works, which randomly sampled latent patches for video generation, our method relies on current strong pre-trained image generation models, modeling a certain caption-guided flow of latent patches that can be decoded to time-dependent video frames. We first speculate multiple images of a video are differentiable with respect to time in some latent space. Based on this conjecture, we introduce the HiPPO framework to approximate the optimal projection for polynomials to generate the probability path. Our approach gains the theoretical benefits of the bounded universal approximation error and timescale robustness. Moreover, VLFM processes the interpolation and extrapolation abilities for video generation with arbitrary frame rates. We conduct experiments on several text-to-video datasets to showcase the effectiveness of our method.</li>
</ul>

<h3>Title: Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhi Zhou, Tan Yuhao, Zenan Li, Yuan Yao, Lan-Zhe Guo, Xiaoxing Ma, Yu-Feng Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00511">https://arxiv.org/abs/2502.00511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00511">https://arxiv.org/pdf/2502.00511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00511]] Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning(https://arxiv.org/abs/2502.00511)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, single-shot inference often yields unreliable results for complex reasoning tasks, leading researchers to explore multiple reasoning paths through methods such as perplexity and self-consistency. In this paper, we present the first theoretical error decomposition analysis of these techniques, breaking down their error into estimation error and model error. Our analysis reveals a fundamental trade-off: perplexity methods suffer from substantial model error due to the absence of a proper consistency function, while self-consistency exhibits high estimation error due to a slow error convergence rate. To overcome these limitations, we propose Reasoning-Pruning Perplexity Consistency (RPC). This approach combines Perplexity Consistency, which seamlessly integrates LLM perplexity with self-consistency, and Reasoning Pruning, which eliminates low-probability reasoning paths to effectively prevent the degeneration of estimation error reduction. Theoretical analysis demonstrates that RPC not only accelerates the convergence rate of estimation error to an exponential level but also holds strong potential for further reducing model error. Extensive empirical evaluations on seven benchmark datasets confirm that RPC can significantly improve reasoning performance, sample efficiency, and confidence reliability.</li>
</ul>

<h3>Title: PolarQuant: Leveraging Polar Transformation for Efficient Key Cache Quantization and Decoding Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Songhao Wu, Ang Lv, Xiao Feng, Yufei Zhang, Xun Zhang, Guojun Yin, Wei Lin, Rui Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00527">https://arxiv.org/abs/2502.00527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00527">https://arxiv.org/pdf/2502.00527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00527]] PolarQuant: Leveraging Polar Transformation for Efficient Key Cache Quantization and Decoding Acceleration(https://arxiv.org/abs/2502.00527)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The KV cache in large language models is a dominant factor in memory usage, limiting their broader applicability. Quantizing the cache to lower bit widths is an effective way to reduce computational costs; however, previous methods struggle with quantizing key vectors due to outliers, resulting in excessive overhead. We propose a novel quantization approach called PolarQuant, which efficiently addresses the outlier challenge. We observe that outliers typically appear in only one of two dimensions, which are rotated together by a specific angle when rotary position embeddings are applied. When represented as two-dimensional vectors, these dimensions exhibit well-structured patterns, with radii and angles smoothly distributed in polar coordinates. This alleviates the challenge of outliers on per-channel quantization, making them well-suited for quantization. Thus, PolarQuant divides key vectors into groups of two-dimensional sub-vectors, encoding them as the corresponding quantized radius and the polar angle, rather than quantizing original key vectors directly. PolarQuant achieves the superior efficiency in KV cache quantization and accelerates the decoding process by turning the query-key inner product into a table lookup, all while maintaining the downstream performance of full-precision models.</li>
</ul>

<h3>Title: Vision-Language Modeling in PET/CT for Visual Grounding of Positive Findings</h3>
<ul>
<li><strong>Authors: </strong>Zachary Huemann, Samuel Church, Joshua D. Warner, Daniel Tran, Xin Tie, Alan B McMillan, Junjie Hu, Steve Y. Cho, Meghan Lubner, Tyler J. Bradshaw</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00528">https://arxiv.org/abs/2502.00528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00528">https://arxiv.org/pdf/2502.00528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00528]] Vision-Language Modeling in PET/CT for Visual Grounding of Positive Findings(https://arxiv.org/abs/2502.00528)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models can connect the text description of an object to its specific location in an image through visual grounding. This has potential applications in enhanced radiology reporting. However, these models require large annotated image-text datasets, which are lacking for PET/CT. We developed an automated pipeline to generate weak labels linking PET/CT report descriptions to their image locations and used it to train a 3D vision-language visual grounding model. Our pipeline finds positive findings in PET/CT reports by identifying mentions of SUVmax and axial slice numbers. From 25,578 PET/CT exams, we extracted 11,356 sentence-label pairs. Using this data, we trained ConTEXTual Net 3D, which integrates text embeddings from a large language model with a 3D nnU-Net via token-level cross-attention. The model's performance was compared against LLMSeg, a 2.5D version of ConTEXTual Net, and two nuclear medicine physicians. The weak-labeling pipeline accurately identified lesion locations in 98% of cases (246/251), with 7.5% requiring boundary adjustments. ConTEXTual Net 3D achieved an F1 score of 0.80, outperforming LLMSeg (F1=0.22) and the 2.5D model (F1=0.53), though it underperformed both physicians (F1=0.94 and 0.91). The model achieved better performance on FDG (F1=0.78) and DCFPyL (F1=0.75) exams, while performance dropped on DOTATE (F1=0.58) and Fluciclovine (F1=0.66). The model performed consistently across lesion sizes but showed reduced accuracy on lesions with low uptake. Our novel weak labeling pipeline accurately produced an annotated dataset of PET/CT image-text pairs, facilitating the development of 3D visual grounding models. ConTEXTual Net 3D significantly outperformed other models but fell short of the performance of nuclear medicine physicians. Our study suggests that even larger datasets may be needed to close this performance gap.</li>
</ul>

<h3>Title: CAD: Confidence-Aware Adaptive Displacement for Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Xiao, Zhihao Xu, Guiping Liang, Yangjun Deng, Yi Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00536">https://arxiv.org/abs/2502.00536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00536">https://arxiv.org/pdf/2502.00536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00536]] CAD: Confidence-Aware Adaptive Displacement for Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2502.00536)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised medical image segmentation aims to leverage minimal expert annotations, yet remains confronted by challenges in maintaining high-quality consistency learning. Excessive perturbations can degrade alignment and hinder precise decision boundaries, especially in regions with uncertain predictions. In this paper, we introduce Confidence-Aware Adaptive Displacement (CAD), a framework that selectively identifies and replaces the largest low-confidence regions with high-confidence patches. By dynamically adjusting both the maximum allowable replacement size and the confidence threshold throughout training, CAD progressively refines the segmentation quality without overwhelming the learning process. Experimental results on public medical datasets demonstrate that CAD effectively enhances segmentation quality, establishing new state-of-the-art accuracy in this field. The source code will be released after the paper is published.</li>
</ul>

<h3>Title: Detecting Ambiguities to Guide Query Rewrite for Robust Conversations in Enterprise AI Assistants</h3>
<ul>
<li><strong>Authors: </strong>Md Mehrab Tanjim, Xiang Chen, Victor S. Bursztyn, Uttaran Bhattacharya, Tung Mai, Vaishnavi Muppala, Akash Maharaj, Saayan Mitra, Eunyee Koh, Yunyao Li, Ken Russell</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00537">https://arxiv.org/abs/2502.00537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00537">https://arxiv.org/pdf/2502.00537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00537]] Detecting Ambiguities to Guide Query Rewrite for Robust Conversations in Enterprise AI Assistants(https://arxiv.org/abs/2502.00537)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-turn conversations with an Enterprise AI Assistant can be challenging due to conversational dependencies in questions, leading to ambiguities and errors. To address this, we propose an NLU-NLG framework for ambiguity detection and resolution through reformulating query automatically and introduce a new task called "Ambiguity-guided Query Rewrite." To detect ambiguities, we develop a taxonomy based on real user conversational logs and draw insights from it to design rules and extract features for a classifier which yields superior performance in detecting ambiguous queries, outperforming LLM-based baselines. Furthermore, coupling the query rewrite module with our ambiguity detecting classifier shows that this end-to-end framework can effectively mitigate ambiguities without risking unnecessary insertions of unwanted phrases for clear queries, leading to an improvement in the overall performance of the AI Assistant. Due to its significance, this has been deployed in the real world application, namely Adobe Experience Platform AI Assistant.</li>
</ul>

<h3>Title: Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Xiaotong Tu, Chenyu Ma, Qingyao Wu, Yinhao Liu, Hongyang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00545">https://arxiv.org/abs/2502.00545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00545">https://arxiv.org/pdf/2502.00545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00545]] Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis(https://arxiv.org/abs/2502.00545)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent generalizable fault diagnosis researches have effectively tackled the distributional shift between unseen working conditions. Most of them mainly focus on learning domain-invariant representation through feature-level methods. However, the increasing numbers of unseen domains may lead to domain-invariant features contain instance-level spurious correlations, which impact the previous models' generalizable ability. To address the limitations, we propose the Fourier-based Augmentation Reconstruction Network, namely this http URL methods are motivated by the observation that the Fourier phase component and amplitude component preserve different semantic information of the signals, which can be employed in domain augmentation techniques. The network comprises an amplitude spectrum sub-network and a phase spectrum sub-network, sequentially reducing the discrepancy between the source and target domains. To construct a more robust generalized model, we employ a multi-source domain data augmentation strategy in the frequency domain. Specifically, a Frequency-Spatial Interaction Module (FSIM) is introduced to handle global information and local spatial features, promoting representation learning between the two sub-networks. To refine the decision boundary of our model output compared to conventional triplet loss, we propose a manifold triplet loss to contribute to generalization. Through extensive experiments on the CWRU and SJTU datasets, FARNet demonstrates effective performance and achieves superior results compared to current cross-domain approaches on the benchmarks.</li>
</ul>

<h3>Title: Milmer: a Framework for Multiple Instance Learning based Multimodal Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zaitian Wang, Jian He, Yu Liang, Xiyuan Hu, Tianhao Peng, Kaixin Wang, Jiakai Wang, Chenlong Zhang, Weili Zhang, Shuang Niu, Xiaoyang Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00547">https://arxiv.org/abs/2502.00547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00547">https://arxiv.org/pdf/2502.00547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00547]] Milmer: a Framework for Multiple Instance Learning based Multimodal Emotion Recognition(https://arxiv.org/abs/2502.00547)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Emotions play a crucial role in human behavior and decision-making, making emotion recognition a key area of interest in human-computer interaction (HCI). This study addresses the challenges of emotion recognition by integrating facial expression analysis with electroencephalogram (EEG) signals, introducing a novel multimodal framework-Milmer. The proposed framework employs a transformer-based fusion approach to effectively integrate visual and physiological modalities. It consists of an EEG preprocessing module, a facial feature extraction and balancing module, and a cross-modal fusion module. To enhance visual feature extraction, we fine-tune a pre-trained Swin Transformer on emotion-related datasets. Additionally, a cross-attention mechanism is introduced to balance token representation across modalities, ensuring effective feature integration. A key innovation of this work is the adoption of a multiple instance learning (MIL) approach, which extracts meaningful information from multiple facial expression images over time, capturing critical temporal dynamics often overlooked in previous studies. Extensive experiments conducted on the DEAP dataset demonstrate the superiority of the proposed framework, achieving a classification accuracy of 96.72% in the four-class emotion recognition task. Ablation studies further validate the contributions of each module, highlighting the significance of advanced feature extraction and fusion strategies in enhancing emotion recognition performance. Our code are available at this https URL.</li>
</ul>

<h3>Title: Muti-Fidelity Prediction and Uncertainty Quantification with Laplace Neural Operators for Parametric Partial Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Haoyang Zheng, Guang Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00550">https://arxiv.org/abs/2502.00550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00550">https://arxiv.org/pdf/2502.00550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00550]] Muti-Fidelity Prediction and Uncertainty Quantification with Laplace Neural Operators for Parametric Partial Differential Equations(https://arxiv.org/abs/2502.00550)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Laplace Neural Operators (LNOs) have recently emerged as a promising approach in scientific machine learning due to the ability to learn nonlinear maps between functional spaces. However, this framework often requires substantial amounts of high-fidelity (HF) training data, which is often prohibitively expensive to acquire. To address this, we propose multi-fidelity Laplace Neural Operators (MF-LNOs), which combine a low-fidelity (LF) base model with parallel linear/nonlinear HF correctors and dynamic inter-fidelity weighting. This allows us to exploit correlations between LF and HF datasets and achieve accurate inference of quantities of interest even with sparse HF data. We further incorporate a modified replica exchange stochastic gradient Langevin algorithm, which enables a more effective posterior distribution estimation and uncertainty quantification in model predictions. Extensive validation across four canonical dynamical systems (the Lorenz system, Duffing oscillator, Burgers equation, and Brusselator reaction-diffusion system) demonstrates the framework's effectiveness. The results show significant improvements, with testing losses reduced by 40% to 80% compared to traditional approaches. This validates MF-LNO as a versatile tool for surrogate modeling in parametric PDEs, offering significant improvements in data efficiency and uncertainty-aware prediction.</li>
</ul>

<h3>Title: Optimal Sensor Placement in Power Transformers Using Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Sirui Li, Federica Bragone, Matthieu Barreau, Tor Laneryd, Kateryna Morozovska</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00552">https://arxiv.org/abs/2502.00552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00552">https://arxiv.org/pdf/2502.00552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00552]] Optimal Sensor Placement in Power Transformers Using Physics-Informed Neural Networks(https://arxiv.org/abs/2502.00552)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Our work aims at simulating and predicting the temperature conditions inside a power transformer using Physics-Informed Neural Networks (PINNs). The predictions obtained are then used to determine the optimal placement for temperature sensors inside the transformer under the constraint of a limited number of sensors, enabling efficient performance monitoring. The method consists of combining PINNs with Mixed Integer Optimization Programming to obtain the optimal temperature reconstruction inside the transformer. First, we extend our PINN model for the thermal modeling of power transformers to solve the heat diffusion equation from 1D to 2D space. Finally, we construct an optimal sensor placement model inside the transformer that can be applied to problems in 1D and 2D.</li>
</ul>

<h3>Title: Complex Wavelet Mutual Information Loss: A Multi-Scale Loss Function for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Renhao Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00563">https://arxiv.org/abs/2502.00563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00563">https://arxiv.org/pdf/2502.00563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00563]] Complex Wavelet Mutual Information Loss: A Multi-Scale Loss Function for Semantic Segmentation(https://arxiv.org/abs/2502.00563)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in deep neural networks have significantly enhanced the performance of semantic segmentation. However, class imbalance and instance imbalance remain persistent challenges, where smaller instances and thin boundaries are often overshadowed by larger structures. To address the multiscale nature of segmented objects, various models have incorporated mechanisms such as spatial attention and feature pyramid networks. Despite these advancements, most loss functions are still primarily pixel-wise, while regional and boundary-focused loss functions often incur high computational costs or are restricted to small-scale regions. To address this limitation, we propose complex wavelet mutual information (CWMI) loss, a novel loss function that leverages mutual information from subband images decomposed by a complex steerable pyramid. The complex steerable pyramid captures features across multiple orientations and preserves structural similarity across scales. Meanwhile, mutual information is well-suited for capturing high-dimensional directional features and exhibits greater noise robustness. Extensive experiments on diverse segmentation datasets demonstrate that CWMI loss achieves significant improvements in both pixel-wise accuracy and topological metrics compared to state-of-the-art methods, while introducing minimal computational overhead. The code is available at this https URL</li>
</ul>

<h3>Title: Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions</h3>
<ul>
<li><strong>Authors: </strong>Samiran Dey, Christopher R.S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00568">https://arxiv.org/abs/2502.00568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00568">https://arxiv.org/pdf/2502.00568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00568]] Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions(https://arxiv.org/abs/2502.00568)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Emerging research has highlighted that artificial intelligence based multimodal fusion of digital pathology and transcriptomic features can improve cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction. However, such direct fusion for joint decision is impractical in real clinical settings, where histopathology is still the gold standard for diagnosis and transcriptomic tests are rarely requested, at least in the public healthcare system. With our novel diffusion based crossmodal generative AI model PathoGen, we show that genomic expressions synthesized from digital histopathology jointly predicts cancer grading and patient survival risk with high accuracy (state-of-the-art performance), certainty (through conformal coverage guarantee) and interpretability (through distributed attention maps). PathoGen code is available for open use by the research community through GitHub at this https URL.</li>
</ul>

<h3>Title: Contrastive Forward-Forward: A Training Algorithm of Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Hossein Aghagolzadeh, Mehdi Ezoji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00571">https://arxiv.org/abs/2502.00571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00571">https://arxiv.org/pdf/2502.00571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00571]] Contrastive Forward-Forward: A Training Algorithm of Vision Transformer(https://arxiv.org/abs/2502.00571)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Although backpropagation is widely accepted as a training algorithm for artificial neural networks, researchers are always looking for inspiration from the brain to find ways with potentially better performance. Forward-Forward is a new training algorithm that is more similar to what occurs in the brain, although there is a significant performance gap compared to backpropagation. In the Forward-Forward algorithm, the loss functions are placed after each layer, and the updating of a layer is done using two local forward passes and one local backward pass. Forward-Forward is in its early stages and has been designed and evaluated on simple multi-layer perceptron networks to solve image classification tasks. In this work, we have extended the use of this algorithm to a more complex and modern network, namely the Vision Transformer. Inspired by insights from contrastive learning, we have attempted to revise this algorithm, leading to the introduction of Contrastive Forward-Forward. Experimental results show that our proposed algorithm performs significantly better than the baseline Forward-Forward leading to an increase of up to 10% in accuracy and boosting the convergence speed by 5 to 20 times on Vision Transformer. Furthermore, if we take Cross Entropy as the baseline loss function in backpropagation, it will be demonstrated that the proposed modifications to the baseline Forward-Forward reduce its performance gap compared to backpropagation on Vision Transformer, and even outperforms it in certain conditions, such as inaccurate supervision.</li>
</ul>

<h3>Title: Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with Prompt Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Stuart Armstrong, Matija Franklin, Connor Stevens, Rebecca Gorman</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00580">https://arxiv.org/abs/2502.00580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00580">https://arxiv.org/pdf/2502.00580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00580]] Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with Prompt Evaluation(https://arxiv.org/abs/2502.00580)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent work showed Best-of-N (BoN) jailbreaking using repeated use of random augmentations (such as capitalization, punctuation, etc) is effective against all major large language models (LLMs). We have found that $100\%$ of the BoN paper's successful jailbreaks (confidence interval $[99.65\%, 100.00\%]$) and $99.8\%$ of successful jailbreaks in our replication (confidence interval $[99.28\%, 99.98\%]$) were blocked with our Defense Against The Dark Prompts (DATDP) method. The DATDP algorithm works by repeatedly utilizing an evaluation LLM to evaluate a prompt for dangerous or manipulative behaviors--unlike some other approaches, DATDP also explicitly looks for jailbreaking attempts--until a robust safety rating is generated. This success persisted even when utilizing smaller LLMs to power the evaluation (Claude and LLaMa-3-8B-instruct proved almost equally capable). These results show that, though language models are sensitive to seemingly innocuous changes to inputs, they seem also capable of successfully evaluating the dangers of these inputs. Versions of DATDP can therefore be added cheaply to generative AI systems to produce an immediate significant increase in safety.</li>
</ul>

<h3>Title: Data-Driven Mispronunciation Pattern Discovery for Robust Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Anna Seo Gyeong Choi, Jonghyeon Park, Myungwoo Oh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00583">https://arxiv.org/abs/2502.00583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00583">https://arxiv.org/pdf/2502.00583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00583]] Data-Driven Mispronunciation Pattern Discovery for Robust Speech Recognition(https://arxiv.org/abs/2502.00583)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in machine learning have significantly improved speech recognition, but recognizing speech from non-fluent or accented speakers remains a challenge. Previous efforts, relying on rule-based pronunciation patterns, have struggled to fully capture non-native errors. We propose two data-driven approaches using speech corpora to automatically detect mispronunciation patterns. By aligning non-native phones with their native counterparts using attention maps, we achieved a 5.7% improvement in speech recognition on native English datasets and a 12.8% improvement for non-native English speakers, particularly Korean speakers. Our method offers practical advancements for robust Automatic Speech Recognition (ASR) systems particularly for situations where prior linguistic knowledge is not applicable.</li>
</ul>

<h3>Title: Converting Transformers into DGNNs Form</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Kuan-Chieh Wang, Bo-Wei Chiu, Min-Te Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00585">https://arxiv.org/abs/2502.00585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00585">https://arxiv.org/pdf/2502.00585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00585]] Converting Transformers into DGNNs Form(https://arxiv.org/abs/2502.00585)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in deep learning have established Transformer architectures as the predominant modeling paradigm. Central to the success of Transformers is the self-attention mechanism, which scores the similarity between query and key matrices to modulate a value matrix. This operation bears striking similarities to digraph convolution, prompting an investigation into whether digraph convolution could serve as an alternative to self-attention. In this study, we formalize this concept by introducing a synthetic unitary digraph convolution based on the digraph Fourier transform. The resulting model, which we term Converter, effectively converts a Transformer into a Directed Graph Neural Network (DGNN) form. We have tested Converter on Long-Range Arena benchmark, long document classification, and DNA sequence-based taxonomy classification. Our experimental results demonstrate that Converter achieves superior performance while maintaining computational efficiency and architectural simplicity, which establishes it as a lightweight yet powerful Transformer variant.</li>
</ul>

<h3>Title: Less is More: Simplifying Network Traffic Classification Leveraging RFCs</h3>
<ul>
<li><strong>Authors: </strong>Nimesha Wickramasinghe, Arash Shaghaghi, Elena Ferrari, Sanjay Jha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00586">https://arxiv.org/abs/2502.00586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00586">https://arxiv.org/pdf/2502.00586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00586]] Less is More: Simplifying Network Traffic Classification Leveraging RFCs(https://arxiv.org/abs/2502.00586)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>The rapid growth of encryption has significantly enhanced privacy and security while posing challenges for network traffic classification. Recent approaches address these challenges by transforming network traffic into text or image formats to leverage deep-learning models originally designed for natural language processing, and computer vision. However, these transformations often contradict network protocol specifications, introduce noisy features, and result in resource-intensive processes. To overcome these limitations, we propose NetMatrix, a minimalistic tabular representation of network traffic that eliminates noisy attributes and focuses on meaningful features leveraging RFCs (Request for Comments) definitions. By combining NetMatrix with a vanilla XGBoost classifier, we implement a lightweight approach, LiM ("Less is More") that achieves classification performance on par with state-of-the-art methods such as ET-BERT and YaTC. Compared to selected baselines, experimental evaluations demonstrate that LiM improves resource consumption by orders of magnitude. Overall, this study underscores the effectiveness of simplicity in traffic representation and machine learning model selection, paving the way towards resource-efficient network traffic classification.</li>
</ul>

<h3>Title: Robust Knowledge Distillation in Federated Learning: Counteracting Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ebtisaam Alharbi, Leandro Soriano Marcolino, Qiang Ni, Antonios Gouglidis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00587">https://arxiv.org/abs/2502.00587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00587">https://arxiv.org/pdf/2502.00587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00587]] Robust Knowledge Distillation in Federated Learning: Counteracting Backdoor Attacks(https://arxiv.org/abs/2502.00587)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across multiple devices while preserving data privacy. However, it remains susceptible to backdoor attacks, where malicious participants can compromise the global model. Existing defence methods are limited by strict assumptions on data heterogeneity (Non-Independent and Identically Distributed data) and the proportion of malicious clients, reducing their practicality and effectiveness. To overcome these limitations, we propose Robust Knowledge Distillation (RKD), a novel defence mechanism that enhances model integrity without relying on restrictive assumptions. RKD integrates clustering and model selection techniques to identify and filter out malicious updates, forming a reliable ensemble of models. It then employs knowledge distillation to transfer the collective insights from this ensemble to a global model. Extensive evaluations demonstrate that RKD effectively mitigates backdoor threats while maintaining high model performance, outperforming current state-of-the-art defence methods across various scenarios.</li>
</ul>

<h3>Title: M+: Extending MemoryLLM with Scalable Long-Term Memory</h3>
<ul>
<li><strong>Authors: </strong>Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio Feris, Zexue He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00592">https://arxiv.org/abs/2502.00592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00592">https://arxiv.org/pdf/2502.00592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00592]] M+: Extending MemoryLLM with Scalable Long-Term Memory(https://arxiv.org/abs/2502.00592)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Equipping large language models (LLMs) with latent-space memory has attracted increasing attention as they can extend the context window of existing language models. However, retaining information from the distant past remains a challenge. For example, MemoryLLM (Wang et al., 2024a), as a representative work with latent-space memory, compresses past information into hidden states across all layers, forming a memory pool of 1B parameters. While effective for sequence lengths up to 16k tokens, it struggles to retain knowledge beyond 20k tokens. In this work, we address this limitation by introducing M+, a memory-augmented model based on MemoryLLM that significantly enhances long-term information retention. M+ integrates a long-term memory mechanism with a co-trained retriever, dynamically retrieving relevant information during text generation. We evaluate M+ on diverse benchmarks, including long-context understanding and knowledge retention tasks. Experimental results show that M+ significantly outperforms MemoryLLM and recent strong baselines, extending knowledge retention from under 20k to over 160k tokens with similar GPU memory overhead.</li>
</ul>

<h3>Title: Fast Vision Mamba: Pooling Spatial Dimensions for Accelerated Processing</h3>
<ul>
<li><strong>Authors: </strong>Saarthak Kapse, Robin Betz, Srinivasan Sivanandan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00594">https://arxiv.org/abs/2502.00594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00594">https://arxiv.org/pdf/2502.00594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00594]] Fast Vision Mamba: Pooling Spatial Dimensions for Accelerated Processing(https://arxiv.org/abs/2502.00594)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>State Space Models (SSMs) with selective scan (Mamba) have been adapted into efficient vision models. Mamba, unlike Vision Transformers, achieves linear complexity for token interactions through a recurrent hidden state process. This sequential processing is enhanced by a parallel scan algorithm, which reduces the computational time of recurrent steps from $L$ sequential steps to $log(L)$ parallel steps with respect to the number of input tokens ($L$). In this work, we propose Fast Vision Mamba (FastVim), that further reduces the computational time of the SSM block by reducing the number of recurrent steps in Vision Mamba models while still retaining model performance. By alternately pooling tokens along image dimensions across Mamba blocks, we obtain a 2$\times$ reduction in the number of parallel steps in SSM block. Our model offers up to $72.5\%$ speedup in inference speed compared to baseline Vision Mamba models on high resolution (2048$\times$2048) images. Our experiments demonstrate state-of-the-art performance with dramatically improved throughput in a range of tasks such as image classification, cell perturbation prediction, segmentation, and object detection. Code is made available at this https URL</li>
</ul>

<h3>Title: RPGBENCH: Evaluating Large Language Models as Role-Playing Game Engines</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Yu, Dongming Shen, Silin Meng, Jaewon Lee, Weisu Yin, Andrea Yaoyun Cui, Zhenlin Xu, Yi Zhu, Xingjian Shi, Mu Li, Alex Smola</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00595">https://arxiv.org/abs/2502.00595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00595">https://arxiv.org/pdf/2502.00595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00595]] RPGBENCH: Evaluating Large Language Models as Role-Playing Game Engines(https://arxiv.org/abs/2502.00595)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present RPGBench, the first benchmark designed to evaluate large language models (LLMs) as text-based role-playing game (RPG) engines. RPGBench comprises two core tasks: Game Creation (GC) and Game Simulation (GS). In GC, an LLM must craft a valid and playable RPG world using a structured event-state representation, ensuring logical coherence and proper termination conditions. In GS, the LLM simulates interactive gameplay across multiple rounds while consistently updating states and enforcing game rules. To comprehensively assess performance, RPGBench integrates objective and subjective evaluation methodologies. Objective measures verify adherence to event mechanics and check variable updates without requiring human intervention. Subjective measures, such as content interestingness, action quality, and role-playing capability, are evaluated via an LLM-as-a-judge framework, where a strong LLM grades each candidate's outputs. Empirical results demonstrate that state-of-the-art LLMs can produce engaging stories but often struggle to implement consistent, verifiable game mechanics, particularly in long or complex scenarios. By combining structured, rule-based assessments with LLM-based judgments, RPGBench provides a new standard for evaluating how well LLMs can balance creativity, coherence, and complexity in text-based RPGs, opening avenues for more immersive and controllable interactive storytelling.</li>
</ul>

<h3>Title: Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing</h3>
<ul>
<li><strong>Authors: </strong>Tianci Liu, Zihan Dong, Linjun Zhang, Haoyu Wang, Jing Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00602">https://arxiv.org/abs/2502.00602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00602">https://arxiv.org/pdf/2502.00602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00602]] Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing(https://arxiv.org/abs/2502.00602)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable performance on various natural language tasks. However, they are trained on static corpora and their knowledge can become outdated quickly in the fast-changing world. This motivates the development of knowledge editing (KE) to update specific knowledge in LLMs without changing unrelated others or compromising their pre-trained capabilities. Previous efforts sought to update a small amount of parameters of a LLM and proved effective for making selective updates. Nonetheless, the edited LLM often exhibits degraded ability to reason about the new knowledge. In this work, we identify a key issue: heterogeneous token overfitting (HTO), where the LLM overfits different tokens in the provided knowledge at varying rates. To tackle this, we propose OVERTONE, a token-level smoothing method that mitigates HTO by adaptively refining the target distribution. Theoretically, OVERTONE offers better parameter updates with negligible computation overhead. It also induces an implicit DPO but does not require preference data pairs. Extensive experiments across four editing methods, two LLMs, and diverse scenarios demonstrate the effectiveness and versatility of our method.</li>
</ul>

<h3>Title: Efficient Language Modeling for Low-Resource Settings with Hybrid RNN-Transformer Architectures</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Lindenmaier, Sean Papay, Sebastian Padó</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00617">https://arxiv.org/abs/2502.00617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00617">https://arxiv.org/pdf/2502.00617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00617]] Efficient Language Modeling for Low-Resource Settings with Hybrid RNN-Transformer Architectures(https://arxiv.org/abs/2502.00617)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based language models have recently been at the forefront of active research in text generation. However, these models' advances come at the price of prohibitive training costs, with parameter counts in the billions and compute requirements measured in petaflop/s-decades. In this paper, we investigate transformer-based architectures for improving model performance in a low-data regime by selectively replacing attention layers with feed-forward and quasi-recurrent neural network layers. We test these architectures on the standard Enwik8 and Wikitext-103 corpora. Our results show that our reduced architectures outperform existing models with a comparable number of parameters, and obtain comparable performance to larger models while significantly reducing the number of parameters.</li>
</ul>

<h3>Title: DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chiyuan He, Zihuan Qiu, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00618">https://arxiv.org/abs/2502.00618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00618">https://arxiv.org/pdf/2502.00618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00618]] DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models(https://arxiv.org/abs/2502.00618)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Continual adaptation of vision-language models (VLMs) focuses on leveraging cross-modal pretrained knowledge to incrementally adapt for expanding downstream tasks and datasets, while tackling the challenge of knowledge forgetting. Existing research often focuses on connecting visual features with specific class text in downstream tasks, overlooking the latent relationships between general and specialized knowledge. Our findings reveal that forcing models to optimize inappropriate visual-text matches exacerbates forgetting of VLMs. To tackle this issue, we propose DesCLIP, which leverages general attribute (GA) descriptions to guide the understanding of specific class objects, enabling VLMs to establish robust \textit{vision-GA-class} trilateral associations rather than relying solely on \textit{vision-class} connections. Specifically, we introduce a language assistant to generate concrete GA description candidates via proper request prompts. Then, an anchor-based embedding filter is designed to obtain highly relevant GA description embeddings, which are leveraged as the paired text embeddings for visual-textual instance matching, thereby tuning the visual encoder. Correspondingly, the class text embeddings are gradually calibrated to align with these shared GA description embeddings. Extensive experiments demonstrate the advancements and efficacy of our proposed method, with comprehensive empirical evaluations highlighting its superior performance compared to existing pretrained and VLM-based continual learning methods.</li>
</ul>

<h3>Title: Representations Shape Weak-to-Strong Generalization: Theoretical Insights and Empirical Predictions</h3>
<ul>
<li><strong>Authors: </strong>Yihao Xue, Jiping Li, Baharan Mirzasoleiman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00620">https://arxiv.org/abs/2502.00620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00620">https://arxiv.org/pdf/2502.00620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00620]] Representations Shape Weak-to-Strong Generalization: Theoretical Insights and Empirical Predictions(https://arxiv.org/abs/2502.00620)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Weak-to-Strong Generalization (W2SG), where a weak model supervises a stronger one, serves as an important analogy for understanding how humans might guide superhuman intelligence in the future. Promising empirical results revealed that a strong model can surpass its weak supervisor. While recent work has offered theoretical insights into this phenomenon, a clear understanding of the interactions between weak and strong models that drive W2SG remains elusive. We investigate W2SG through a theoretical lens and show that it can be characterized using kernels derived from the principal components of weak and strong models' internal representations. These kernels can be used to define a space that, at a high level, captures what the weak model is unable to learn but is learnable by the strong model. The projection of labels onto this space quantifies how much the strong model falls short of its full potential due to weak supervision. This characterization also provides insights into how certain errors in weak supervision can be corrected by the strong model, regardless of overfitting. Our theory has significant practical implications, providing a representation-based metric that predicts W2SG performance trends without requiring labels, as shown in experiments on molecular predictions with transformers and 5 NLP tasks involving 52 LLMs.</li>
</ul>

<h3>Title: Self-Prompt SAM: Medical Image Segmentation via Automatic Prompt SAM Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Bin Xie, Hao Tang, Dawen Cai, Yan Yan, Gady Agam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00630">https://arxiv.org/abs/2502.00630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00630">https://arxiv.org/pdf/2502.00630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00630]] Self-Prompt SAM: Medical Image Segmentation via Automatic Prompt SAM Adaptation(https://arxiv.org/abs/2502.00630)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Segment Anything Model (SAM) has demonstrated impressive zero-shot performance and brought a range of unexplored capabilities to natural image segmentation tasks. However, as a very important branch of image segmentation, the performance of SAM remains uncertain when applied to medical image segmentation due to the significant differences between natural images and medical images. Meanwhile, it is harsh to meet the SAM's requirements of extra prompts provided, such as points or boxes to specify medical regions. In this paper, we propose a novel self-prompt SAM adaptation framework for medical image segmentation, named Self-Prompt-SAM. We design a multi-scale prompt generator combined with the image encoder in SAM to generate auxiliary masks. Then, we use the auxiliary masks to generate bounding boxes as box prompts and use Distance Transform to select the most central points as point prompts. Meanwhile, we design a 3D depth-fused adapter (DfusedAdapter) and inject the DFusedAdapter into each transformer in the image encoder and mask decoder to enable pre-trained 2D SAM models to extract 3D information and adapt to 3D medical images. Extensive experiments demonstrate that our method achieves state-of-the-art performance and outperforms nnUNet by 2.3% on AMOS2022, 1.6% on ACDCand 0.5% on Synapse datasets.</li>
</ul>

<h3>Title: MedConv: Convolutions Beat Transformers on Long-Tailed Bone Density Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xuyin Qi, Zeyu Zhang, Huazhan Zheng, Mingxi Chen, Numan Kutaiba, Ruth Lim, Cherie Chiang, Zi En Tham, Xuan Ren, Wenxin Zhang, Lei Zhang, Hao Zhang, Wenbing Lv, Guangzhen Yao, Renda Han, Kangsheng Wang, Mingyuan Li, Hongtao Mao, Yu Li, Zhibin Liao, Yang Zhao, Minh-Son To</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00631">https://arxiv.org/abs/2502.00631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00631">https://arxiv.org/pdf/2502.00631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00631]] MedConv: Convolutions Beat Transformers on Long-Tailed Bone Density Prediction(https://arxiv.org/abs/2502.00631)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Bone density prediction via CT scans to estimate T-scores is crucial, providing a more precise assessment of bone health compared to traditional methods like X-ray bone density tests, which lack spatial resolution and the ability to detect localized changes. However, CT-based prediction faces two major challenges: the high computational complexity of transformer-based architectures, which limits their deployment in portable and clinical settings, and the imbalanced, long-tailed distribution of real-world hospital data that skews predictions. To address these issues, we introduce MedConv, a convolutional model for bone density prediction that outperforms transformer models with lower computational demands. We also adapt Bal-CE loss and post-hoc logit adjustment to improve class balance. Extensive experiments on our AustinSpine dataset shows that our approach achieves up to 21% improvement in accuracy and 20% in ROC AUC over previous state-of-the-art methods.</li>
</ul>

<h3>Title: Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer</h3>
<ul>
<li><strong>Authors: </strong>Tao Ren, Zishi Zhang, Zehao Li, Jingyang Jiang, Shentao Qin, Guanghao Li, Yan Li, Yi Zheng, Xinping Li, Min Zhan, Yijie Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00639">https://arxiv.org/abs/2502.00639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00639">https://arxiv.org/pdf/2502.00639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00639]] Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer(https://arxiv.org/abs/2502.00639)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The probabilistic diffusion model (DM), generating content by inferencing through a recursive chain structure, has emerged as a powerful framework for visual generation. After pre-training on enormous unlabeled data, the model needs to be properly aligned to meet requirements for downstream applications. How to efficiently align the foundation DM is a crucial task. Contemporary methods are either based on Reinforcement Learning (RL) or truncated Backpropagation (BP). However, RL and truncated BP suffer from low sample efficiency and biased gradient estimation respectively, resulting in limited improvement or, even worse, complete training failure. To overcome the challenges, we propose the Recursive Likelihood Ratio (RLR) optimizer, a zeroth-order informed fine-tuning paradigm for DM. The zeroth-order gradient estimator enables the computation graph rearrangement within the recursive diffusive chain, making the RLR's gradient estimator an unbiased one with the lower variance than other methods. We provide theoretical guarantees for the performance of the RLR. Extensive experiments are conducted on image and video generation tasks to validate the superiority of the RLR. Furthermore, we propose a novel prompt technique that is natural for the RLR to achieve a synergistic effect.</li>
</ul>

<h3>Title: Evaluating Small Language Models for News Summarization: Implications and Factors Influencing Performance</h3>
<ul>
<li><strong>Authors: </strong>Borui Xu, Yao Chen, Zeyi Wen, Weiguo Liu, Bingsheng He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00641">https://arxiv.org/abs/2502.00641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00641">https://arxiv.org/pdf/2502.00641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00641]] Evaluating Small Language Models for News Summarization: Implications and Factors Influencing Performance(https://arxiv.org/abs/2502.00641)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The increasing demand for efficient summarization tools in resource-constrained environments highlights the need for effective solutions. While large language models (LLMs) deliver superior summarization quality, their high computational resource requirements limit practical use applications. In contrast, small language models (SLMs) present a more accessible alternative, capable of real-time summarization on edge devices. However, their summarization capabilities and comparative performance against LLMs remain underexplored. This paper addresses this gap by presenting a comprehensive evaluation of 19 SLMs for news summarization across 2,000 news samples, focusing on relevance, coherence, factual consistency, and summary length. Our findings reveal significant variations in SLM performance, with top-performing models such as Phi3-Mini and Llama3.2-3B-Ins achieving results comparable to those of 70B LLMs while generating more concise summaries. Notably, SLMs are better suited for simple prompts, as overly complex prompts may lead to a decline in summary quality. Additionally, our analysis indicates that instruction tuning does not consistently enhance the news summarization capabilities of SLMs. This research not only contributes to the understanding of SLMs but also provides practical insights for researchers seeking efficient summarization solutions that balance performance and resource use.</li>
</ul>

<h3>Title: TrojanTime: Backdoor Attacks on Time Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Chang Dong, Zechao Sun, Guangdong Bai, Shuying Piao, Weitong Chen, Wei Emma Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00646">https://arxiv.org/abs/2502.00646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00646">https://arxiv.org/pdf/2502.00646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00646]] TrojanTime: Backdoor Attacks on Time Series Classification(https://arxiv.org/abs/2502.00646)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>Time Series Classification (TSC) is highly vulnerable to backdoor attacks, posing significant security threats. Existing methods primarily focus on data poisoning during the training phase, designing sophisticated triggers to improve stealthiness and attack success rate (ASR). However, in practical scenarios, attackers often face restrictions in accessing training data. Moreover, it is a challenge for the model to maintain generalization ability on clean test data while remaining vulnerable to poisoned inputs when data is inaccessible. To address these challenges, we propose TrojanTime, a novel two-step training algorithm. In the first stage, we generate a pseudo-dataset using an external arbitrary dataset through target adversarial attacks. The clean model is then continually trained on this pseudo-dataset and its poisoned version. To ensure generalization ability, the second stage employs a carefully designed training strategy, combining logits alignment and batch norm freezing. We evaluate TrojanTime using five types of triggers across four TSC architectures in UCR benchmark datasets from diverse domains. The results demonstrate the effectiveness of TrojanTime in executing backdoor attacks while maintaining clean accuracy. Finally, to mitigate this threat, we propose a defensive unlearning strategy that effectively reduces the ASR while preserving clean accuracy.</li>
</ul>

<h3>Title: Integrating Cybersecurity Frameworks into IT Security: A Comprehensive Analysis of Threat Mitigation Strategies and Adaptive Technologies</h3>
<ul>
<li><strong>Authors: </strong>Amit Lokare (Vanguard), Shripad Bankar (Comcast), Padmajeet Mhaske (JPMC)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00651">https://arxiv.org/abs/2502.00651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00651">https://arxiv.org/pdf/2502.00651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00651]] Integrating Cybersecurity Frameworks into IT Security: A Comprehensive Analysis of Threat Mitigation Strategies and Adaptive Technologies(https://arxiv.org/abs/2502.00651)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>The cybersecurity threat landscape is constantly actively making it imperative to develop sound frameworks to protect the IT structures. Based on this introduction, this paper aims to discuss the application of cybersecurity frameworks into the IT security with focus placed on the role of such frameworks in addressing the changing nature of cybersecurity threats. It explores widely used models, including the NIST Cybersecurity Framework, Zero Trust Architecture, and the ISO/IEC 27001, and how they apply to industries including finance, healthcare and government. The discussion also singles out such technologies as Artificial Intelligence (AI) and Machine Learning (ML) as the core for real-time threat detection and response mechanisms. As these integration challenges demonstrate, the study provides tangible and proven approaches to tackle framework implementation issues such as legitimate security issues, limited availability of funds and resources, and compliance with legal requirements. By capturing current trends and exposures, the findings promote strong, portfolio-based and risk-appropriate security approaches adjusted for organizational goals and capable to prevent advanced cyber threats.</li>
</ul>

<h3>Title: Reformulation is All You Need: Addressing Malicious Text Features in DNNs</h3>
<ul>
<li><strong>Authors: </strong>Yi Jiang, Oubo Ma, Yong Yang, Tong Zhang, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00652">https://arxiv.org/abs/2502.00652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00652">https://arxiv.org/pdf/2502.00652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00652]] Reformulation is All You Need: Addressing Malicious Text Features in DNNs(https://arxiv.org/abs/2502.00652)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Human language encompasses a wide range of intricate and diverse implicit features, which attackers can exploit to launch adversarial or backdoor attacks, compromising DNN models for NLP tasks. Existing model-oriented defenses often require substantial computational resources as model size increases, whereas sample-oriented defenses typically focus on specific attack vectors or schemes, rendering them vulnerable to adaptive attacks. We observe that the root cause of both adversarial and backdoor attacks lies in the encoding process of DNN models, where subtle textual features, negligible for human comprehension, are erroneously assigned significant weight by less robust or trojaned models. Based on it we propose a unified and adaptive defense framework that is effective against both adversarial and backdoor attacks. Our approach leverages reformulation modules to address potential malicious features in textual inputs while preserving the original semantic integrity. Extensive experiments demonstrate that our framework outperforms existing sample-oriented defense baselines across a diverse range of malicious textual features.</li>
</ul>

<h3>Title: Towards Robust Multimodal Large Language Models Against Jailbreak Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Yin, Yuanpu Cao, Han Liu, Ting Wang, Jinghui Chen, Fenhlong Ma</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00653">https://arxiv.org/abs/2502.00653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00653">https://arxiv.org/pdf/2502.00653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00653]] Towards Robust Multimodal Large Language Models Against Jailbreak Attacks(https://arxiv.org/abs/2502.00653)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>While multimodal large language models (MLLMs) have achieved remarkable success in recent advancements, their susceptibility to jailbreak attacks has come to light. In such attacks, adversaries exploit carefully crafted prompts to coerce models into generating harmful or undesirable content. Existing defense mechanisms often rely on external inference steps or safety alignment training, both of which are less effective and impractical when facing sophisticated adversarial perturbations in white-box scenarios. To address these challenges and bolster MLLM robustness, we introduce SafeMLLM by adopting an adversarial training framework that alternates between an attack step for generating adversarial noise and a model updating step. At the attack step, SafeMLLM generates adversarial perturbations through a newly proposed contrastive embedding attack (CoE-Attack), which optimizes token embeddings under a contrastive objective. SafeMLLM then updates model parameters to neutralize the perturbation effects while preserving model utility on benign inputs. We evaluate SafeMLLM across six MLLMs and six jailbreak methods spanning multiple modalities. Experimental results show that SafeMLLM effectively defends against diverse attacks, maintaining robust performance and utilities.</li>
</ul>

<h3>Title: LLM Safety Alignment is Divergence Estimation in Disguise</h3>
<ul>
<li><strong>Authors: </strong>Rajdeep Haldar, Ziyi Wang, Qifan Song, Guang Lin, Yue Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00657">https://arxiv.org/abs/2502.00657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00657">https://arxiv.org/pdf/2502.00657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00657]] LLM Safety Alignment is Divergence Estimation in Disguise(https://arxiv.org/abs/2502.00657)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>We propose a theoretical framework demonstrating that popular Large Language Model (LLM) alignment methods, including Reinforcement Learning from Human Feedback (RLHF) and alternatives, fundamentally function as divergence estimators between aligned (preferred or safe) and unaligned (less-preferred or harmful) distributions. This explains the separation phenomenon between safe and harmful prompts in the model hidden representation after alignment. Inspired by the theoretical results, we identify that some alignment methods are better than others in terms of separation and, introduce a new method, KLDO, and further demonstrate the implication of our theories. We advocate for compliance-refusal datasets over preference datasets to enhance safety alignment, supported by both theoretical reasoning and empirical evidence. Additionally, to quantify safety separation, we leverage a distance metric in the representation space and statistically validate its efficacy as a statistical significant indicator of LLM resilience against jailbreak attacks.</li>
</ul>

<h3>Title: Cross-Modal Synergies: Unveiling the Potential of Motion-Aware Fusion Networks in Handling Dynamic and Static ReID Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Fuxi Ling, Hongye Liu, Guoqiang Huang, Jing Li, Hong Wu, Zhihao Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00665">https://arxiv.org/abs/2502.00665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00665">https://arxiv.org/pdf/2502.00665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00665]] Cross-Modal Synergies: Unveiling the Potential of Motion-Aware Fusion Networks in Handling Dynamic and Static ReID Scenarios(https://arxiv.org/abs/2502.00665)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Navigating the complexities of person re-identification (ReID) in varied surveillance scenarios, particularly when occlusions occur, poses significant challenges. We introduce an innovative Motion-Aware Fusion (MOTAR-FUSE) network that utilizes motion cues derived from static imagery to significantly enhance ReID capabilities. This network incorporates a dual-input visual adapter capable of processing both images and videos, thereby facilitating more effective feature extraction. A unique aspect of our approach is the integration of a motion consistency task, which empowers the motion-aware transformer to adeptly capture the dynamics of human motion. This technique substantially improves the recognition of features in scenarios where occlusions are prevalent, thereby advancing the ReID process. Our comprehensive evaluations across multiple ReID benchmarks, including holistic, occluded, and video-based scenarios, demonstrate that our MOTAR-FUSE network achieves superior performance compared to existing approaches.</li>
</ul>

<h3>Title: Avoiding $\mathbf{exp(R_{max})}$ scaling in RLHF through Preference-based Exploration</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Chen, Yiding Chen, Wen Sun, Xuezhou Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00666">https://arxiv.org/abs/2502.00666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00666">https://arxiv.org/pdf/2502.00666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00666]] Avoiding $\mathbf{exp(R_{max})}$ scaling in RLHF through Preference-based Exploration(https://arxiv.org/abs/2502.00666)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal technique for large language model (LLM) alignment. This paper studies the setting of online RLHF and focus on improving sample efficiency. All existing algorithms in online RLHF, whether doing passive exploration or active exploration, suffer from a sample complexity that scales exponentially with the scale of the reward function. This fundamental limitation hinders their effectiveness in scenarios with heavily skewed preferences, e.g. questions with a unique correct solution. To address this, we introduce Self-Exploring Preference-Incentive Online Preference Optimization (SE-POPO), an online RLHF algorithm that for the first time achieves a sample complexity that scales polynomially with the reward scale, answering an open problem raised by Xie et al. (2024).. Theoretically, we demonstrate that the sample complexity of SE-POPO dominates that of existing exploration algorithms. Empirically, our systematic evaluation confirms that SE-POPO is more sample-efficient than both exploratory and non-exploratory baselines, in two primary application scenarios of RLHF as well as on public benchmarks, marking a significant step forward in RLHF algorithm design.</li>
</ul>

<h3>Title: Safety Alignment Depth in Large Language Models: A Markov Chain Perspective</h3>
<ul>
<li><strong>Authors: </strong>Ching-Chia Kao, Chia-Mu Yu, Chun-Shien Lu, Chu-Song Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00669">https://arxiv.org/abs/2502.00669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00669">https://arxiv.org/pdf/2502.00669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00669]] Safety Alignment Depth in Large Language Models: A Markov Chain Perspective(https://arxiv.org/abs/2502.00669)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly adopted in high-stakes scenarios, yet their safety mechanisms often remain fragile. Simple jailbreak prompts or even benign fine-tuning can bypass these protocols, underscoring the need to understand where and how they fail. Recent findings suggest that vulnerabilities emerge when alignment is confined to only the initial output tokens. Unfortunately, even with the introduction of deep safety alignment, determining the optimal safety depth remains an unresolved challenge. By leveraging the equivalence between autoregressive language models and Markov chains, this paper offers the first theoretical result on how to identify the ideal depth for safety alignment, and demonstrates how permutation-based data augmentation can tighten these bounds. Crucially, we reveal a fundamental interaction between alignment depth and ensemble width-indicating that broader ensembles can compensate for shallower alignments. These insights provide a theoretical foundation for designing more robust, scalable safety strategies that complement existing alignment approaches, opening new avenues for research into safer, more reliable LLMs.</li>
</ul>

<h3>Title: Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?</h3>
<ul>
<li><strong>Authors: </strong>Wenzhe Li, Yong Lin, Mengzhou Xia, Chi Jin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00674">https://arxiv.org/abs/2502.00674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00674">https://arxiv.org/pdf/2502.00674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00674]] Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?(https://arxiv.org/abs/2502.00674)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensembling outputs from diverse sources is a straightforward yet effective approach to boost performance. Mixture-of-Agents (MoA) is one such popular ensemble method that aggregates outputs from multiple different Large Language Models (LLMs). This paper raises the question in the context of language models: is mixing different LLMs truly beneficial? We propose Self-MoA -- an ensemble method that aggregates outputs from only the single top-performing LLM. Our extensive experiments reveal that, surprisingly, Self-MoA outperforms standard MoA that mixes different LLMs in a large number of scenarios: Self-MoA achieves $6.6\%$ improvement over MoA on the AlpacaEval 2.0 benchmark, and an average of $3.8\%$ improvement across various benchmarks, including MMLU, CRUX, and MATH. Applying Self-MoA to one of the top-ranking models in AlpacaEval 2.0 directly achieves the new state-of-the-art performance on the leaderboard. To understand the effectiveness of Self-MoA, we systematically investigate the trade-off between diversity and quality of outputs under various MoA settings. We confirm that the MoA performance is rather sensitive to the quality, and mixing different LLMs often lowers the average quality of the models. To complement the study, we identify the scenarios where mixing different LLMs could be helpful. This paper further introduces a sequential version of Self-MoA, that is capable of aggregating a large number of LLM outputs on-the-fly over multiple rounds, and is as effective as aggregating all outputs at once.</li>
</ul>

<h3>Title: How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence</h3>
<ul>
<li><strong>Authors: </strong>Hyeong Kyu Choi, Maxim Khanov, Hongxin Wei, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00678">https://arxiv.org/abs/2502.00678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00678">https://arxiv.org/pdf/2502.00678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00678]] How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence(https://arxiv.org/abs/2502.00678)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dataset contamination, where evaluation datasets overlap with pre-training corpora, inflates performance metrics and undermines the reliability of model evaluations. Quantifying dataset contamination thus becomes essential to ensure that performance evaluations genuinely reflect a model's ability to generalize to unseen data, rather than relying on memorized examples. To address this problem, we propose Kernel Divergence Score (KDS), a novel method that quantifies dataset contamination by computing the divergence between the kernel similarity matrix of sample embeddings, before and after fine-tuning on the benchmark dataset. Leveraging the insight that fine-tuning affects unseen samples more significantly than seen ones, KDS provides a reliable measure of contamination. Through extensive experiments on controlled contamination scenarios, KDS demonstrates a near-perfect correlation with contamination levels and outperforms existing baselines. Additionally, we perform comprehensive ablation studies to analyze the impact of key design choices, providing deeper insights into the components and effectiveness of KDS. These ablations highlight the importance of leveraging fine-grained kernel-based information and confirm the reliability of the proposed framework across diverse datasets and settings.</li>
</ul>

<h3>Title: A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qika Lin, Zhen Peng, Kaize Shi, Kai He, Yiming Xu, Erik Cambria, Mengling Feng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00681">https://arxiv.org/abs/2502.00681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00681">https://arxiv.org/pdf/2502.00681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00681]] A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models(https://arxiv.org/abs/2502.00681)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent years have witnessed rapid advances in graph representation learning, with the continuous embedding approach emerging as the dominant paradigm. However, such methods encounter issues regarding parameter efficiency, interpretability, and robustness. Thus, Quantized Graph Representation (QGR) learning has recently gained increasing interest, which represents the graph structure with discrete codes instead of conventional continuous embeddings. Given its analogous representation form to natural language, QGR also possesses the capability to seamlessly integrate graph structures with large language models (LLMs). As this emerging paradigm is still in its infancy yet holds significant promise, we undertake this thorough survey to promote its rapid future prosperity. We first present the background of the general quantization methods and their merits. Moreover, we provide an in-depth demonstration of current QGR studies from the perspectives of quantized strategies, training objectives, distinctive designs, knowledge graph quantization, and applications. We further explore the strategies for code dependence learning and integration with LLMs. At last, we give discussions and conclude future directions, aiming to provide a comprehensive picture of QGR and inspire future research.</li>
</ul>

<h3>Title: Compositional Concept-Based Neuron-Level Interpretability for Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Jiang, Hai Huang, Xingquan Zuo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00684">https://arxiv.org/abs/2502.00684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00684">https://arxiv.org/pdf/2502.00684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00684]] Compositional Concept-Based Neuron-Level Interpretability for Deep Reinforcement Learning(https://arxiv.org/abs/2502.00684)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning (DRL), through learning policies or values represented by neural networks, has successfully addressed many complex control problems. However, the neural networks introduced by DRL lack interpretability and transparency. Current DRL interpretability methods largely treat neural networks as black boxes, with few approaches delving into the internal mechanisms of policy/value networks. This limitation undermines trust in both the neural network models that represent policies and the explanations derived from them. In this work, we propose a novel concept-based interpretability method that provides fine-grained explanations of DRL models at the neuron level. Our method formalizes atomic concepts as binary functions over the state space and constructs complex concepts through logical operations. By analyzing the correspondence between neuron activations and concept functions, we establish interpretable explanations for individual neurons in policy/value networks. Experimental results on both continuous control tasks and discrete decision-making environments demonstrate that our method can effectively identify meaningful concepts that align with human understanding while faithfully reflecting the network's decision-making logic.</li>
</ul>

<h3>Title: High-Order Matching for One-Step Shortcut Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Bo Chen, Chengyue Gong, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Mingda Wan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00688">https://arxiv.org/abs/2502.00688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00688">https://arxiv.org/pdf/2502.00688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00688]] High-Order Matching for One-Step Shortcut Diffusion Models(https://arxiv.org/abs/2502.00688)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR 2025] have shown potential in vision generation, but their reliance on first-order trajectory supervision is fundamentally limited. The Shortcut model's simplistic velocity-only approach fails to capture intrinsic manifold geometry, leading to erratic trajectories, poor geometric alignment, and instability-especially in high-curvature regions. These shortcomings stem from its inability to model mid-horizon dependencies or complex distributional features, leaving it ill-equipped for robust generative modeling. In this work, we introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a game-changing framework that leverages high-order supervision to revolutionize distribution transportation. By incorporating acceleration, jerk, and beyond, HOMO not only fixes the flaws of the Shortcut model but also achieves unprecedented smoothness, stability, and geometric precision. Theoretically, we prove that HOMO's high-order supervision ensures superior approximation accuracy, outperforming first-order methods. Empirically, HOMO dominates in complex settings, particularly in high-curvature regions where the Shortcut model struggles. Our experiments show that HOMO delivers smoother trajectories and better distributional alignment, setting a new standard for one-step generative models.</li>
</ul>

<h3>Title: Dissecting Submission Limit in Desk-Rejections: A Mathematical Analysis of Fairness in AI Conference Policies</h3>
<ul>
<li><strong>Authors: </strong>Yuefan Cao, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Jiahao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.DL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00690">https://arxiv.org/abs/2502.00690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00690">https://arxiv.org/pdf/2502.00690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00690]] Dissecting Submission Limit in Desk-Rejections: A Mathematical Analysis of Fairness in AI Conference Policies(https://arxiv.org/abs/2502.00690)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>As AI research surges in both impact and volume, conferences have imposed submission limits to maintain paper quality and alleviate organizational pressure. In this work, we examine the fairness of desk-rejection systems under submission limits and reveal that existing practices can result in substantial inequities. Specifically, we formally define the paper submission limit problem and identify a critical dilemma: when the number of authors exceeds three, it becomes impossible to reject papers solely based on excessive submissions without negatively impacting innocent authors. Thus, this issue may unfairly affect early-career researchers, as their submissions may be penalized due to co-authors with significantly higher submission counts, while senior researchers with numerous papers face minimal consequences. To address this, we propose an optimization-based fairness-aware desk-rejection mechanism and formally define two fairness metrics: individual fairness and group fairness. We prove that optimizing individual fairness is NP-hard, whereas group fairness can be efficiently optimized via linear programming. Through case studies, we demonstrate that our proposed system ensures greater equity than existing methods, including those used in CVPR 2025, offering a more socially just approach to managing excessive submissions in AI conferences.</li>
</ul>

<h3>Title: DPBloomfilter: Securing Bloom Filters with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Yekun Ke, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00693">https://arxiv.org/abs/2502.00693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00693">https://arxiv.org/pdf/2502.00693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00693]] DPBloomfilter: Securing Bloom Filters with Differential Privacy(https://arxiv.org/abs/2502.00693)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>The Bloom filter is a simple yet space-efficient probabilistic data structure that supports membership queries for dramatically large datasets. It is widely utilized and implemented across various industrial scenarios, often handling massive datasets that include sensitive user information necessitating privacy preservation. To address the challenge of maintaining privacy within the Bloom filter, we have developed the DPBloomfilter. This innovation integrates the classical differential privacy mechanism, specifically the Random Response technique, into the Bloom filter, offering robust privacy guarantees under the same running complexity as the standard Bloom filter. Through rigorous simulation experiments, we have demonstrated that our DPBloomfilter algorithm maintains high utility while ensuring privacy protections. To the best of our knowledge, this is the first work to provide differential privacy guarantees for the Bloom filter for membership query problems.</li>
</ul>

<h3>Title: Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin</h3>
<ul>
<li><strong>Authors: </strong>Ella Barkan, Ibrahim Siddiqui, Kevin J. Cheng, Alex Golts, Yoel Shoshan, Jeffrey K. Weber, Yailin Campos Mota, Michal Ozery-Flato, Giuseppe A. Sautto</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00694">https://arxiv.org/abs/2502.00694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00694">https://arxiv.org/pdf/2502.00694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00694]] Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin(https://arxiv.org/abs/2502.00694)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Monoclonal antibodies (mAbs) represent one of the most prevalent FDA-approved modalities for treating autoimmune diseases, infectious diseases, and cancers. However, discovery and development of therapeutic antibodies remains a time-consuming and expensive process. Recent advancements in machine learning (ML) and artificial intelligence (AI) have shown significant promise in revolutionizing antibody discovery and optimization. In particular, models that predict antibody biological activity enable in-silico evaluation of binding and functional properties; such models can prioritize antibodies with the highest likelihoods of success in costly and time-intensive laboratory testing procedures. We here explore an AI model for predicting the binding and receptor blocking activity of antibodies against influenza A hemagglutinin (HA) antigens. Our present model is developed with the MAMMAL framework for biologics discovery to predict antibody-antigen interactions using only sequence information. To evaluate the model's performance, we tested it under various data split conditions to mimic real-world scenarios. Our models achieved an AUROC $\geq$ 0.91 for predicting the activity of existing antibodies against seen HAs and an AUROC of 0.9 for unseen HAs. For novel antibody activity prediction, the AUROC was 0.73, which further declined to 0.63-0.66 under stringent constraints on similarity to existing antibodies. These results demonstrate the potential of AI foundation models to transform antibody design by reducing dependence on extensive laboratory testing and enabling more efficient prioritization of antibody candidates. Moreover, our findings emphasize the critical importance of diverse and comprehensive antibody datasets to improve the generalization of prediction models, particularly for novel antibody development.</li>
</ul>

<h3>Title: S2CFormer: Reorienting Learned Image Compression from Spatial Interaction to Channel Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Yunuo Chen, Qian Li, Bing He, Donghui Feng, Ronghua Wu, Qi Wang, Li Song, Guo Lu, Wenjun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00700">https://arxiv.org/abs/2502.00700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00700">https://arxiv.org/pdf/2502.00700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00700]] S2CFormer: Reorienting Learned Image Compression from Spatial Interaction to Channel Aggregation(https://arxiv.org/abs/2502.00700)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have achieved significant success in learned image compression (LIC), with Swin Transformers emerging as the mainstream choice for nonlinear transforms. A common belief is that their sophisticated spatial operations contribute most to their efficacy. However, the crucial role of the feed-forward network (FFN) based Channel Aggregation module within the transformer architecture has been largely overlooked, and the over-design of spatial operations leads to a suboptimal trade-off between decoding latency and R-D performance. In this paper, we reevaluate the key factors behind the competence of transformers in LIC. By replacing spatial operations with identity mapping, we are surprised to find that channel operations alone can approach the R-D performance of the leading methods. This solid lower bound of performance emphasizes that the presence of channel aggregation is more essential for the LIC model to achieve competitive performance, while the previously complex spatial interactions are partly redundant. Based on this insight, we initiate the "S2CFormer" paradigm, a general architecture that reorients the focus of LIC from Spatial Interaction to Channel Aggregation. We present two instantiations of the S2CFormer: S2C-Conv, and S2C-Attention. Each one incorporates a simple operator for spatial interaction and serves as nonlinear transform blocks for our LIC models. Both models demonstrate state-of-the-art (SOTA) R-D performance and significantly faster decoding speed. These results also motivate further exploration of advanced FFN structures to enhance the R-D performance while maintaining model efficiency. With these foundations, we introduce S2C-Hybrid, an enhanced LIC model that combines the strengths of different S2CFormer instantiations. This model outperforms all the existing methods on several datasets, setting a new benchmark for efficient and high-performance LIC.</li>
</ul>

<h3>Title: Model Provenance Testing for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ivica Nikolic, Teodora Baluta, Prateek Saxena</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00706">https://arxiv.org/abs/2502.00706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00706">https://arxiv.org/pdf/2502.00706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00706]] Model Provenance Testing for Large Language Models(https://arxiv.org/abs/2502.00706)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language models are increasingly customized through fine-tuning and other adaptations, creating challenges in enforcing licensing terms and managing downstream impacts. Tracking model origins is crucial both for protecting intellectual property and for identifying derived models when biases or vulnerabilities are discovered in foundation models. We address this challenge by developing a framework for testing model provenance: Whether one model is derived from another. Our approach is based on the key observation that real-world model derivations preserve significant similarities in model outputs that can be detected through statistical analysis. Using only black-box access to models, we employ multiple hypothesis testing to compare model similarities against a baseline established by unrelated models. On two comprehensive real-world benchmarks spanning models from 30M to 4B parameters and comprising over 600 models, our tester achieves 90-95% precision and 80-90% recall in identifying derived models. These results demonstrate the viability of systematic provenance verification in production environments even when only API access is available.</li>
</ul>

<h3>Title: PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation</h3>
<ul>
<li><strong>Authors: </strong>Qixuan Li, Chao Wang, Zongjin He, Yan Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00708">https://arxiv.org/abs/2502.00708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00708">https://arxiv.org/pdf/2502.00708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00708]] PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation(https://arxiv.org/abs/2502.00708)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Text-to-3D asset generation has achieved significant optimization under the supervision of 2D diffusion priors. However, when dealing with compositional scenes, existing methods encounter several challenges: 1). failure to ensure that composite scene layouts comply with physical laws; 2). difficulty in accurately capturing the assets and relationships described in complex scene descriptions; 3). limited autonomous asset generation capabilities among layout approaches leveraging large language models (LLMs). To avoid these compromises, we propose a novel framework for compositional scene generation, PhiP-G, which seamlessly integrates generation techniques with layout guidance based on a world model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene description to generate a scene graph, and integrating a multimodal 2D generation agent and a 3D Gaussian generation method for targeted assets creation. For the stage of layout, PhiP-G employs a physical pool with adhesion capabilities and a visual supervision agent, forming a world model for layout prediction and planning. Extensive experiments demonstrate that PhiP-G significantly enhances the generation quality and physical rationality of the compositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA) performance in CLIP scores, achieves parity with the leading methods in generation quality as measured by the T$^3$Bench, and improves efficiency by 24x.</li>
</ul>

<h3>Title: VIKSER: Visual Knowledge-Driven Self-Reinforcing Reasoning Framework</h3>
<ul>
<li><strong>Authors: </strong>Chunbai Zhang, Chao Wang, Yang Zhou, Yan Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00711">https://arxiv.org/abs/2502.00711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00711">https://arxiv.org/pdf/2502.00711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00711]] VIKSER: Visual Knowledge-Driven Self-Reinforcing Reasoning Framework(https://arxiv.org/abs/2502.00711)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Visual reasoning refers to the task of solving questions about visual information. Current visual reasoning methods typically employ pre-trained vision-language model (VLM) strategies or deep neural network approaches. However, existing efforts are constrained by limited reasoning interpretability, while hindering by the phenomenon of underspecification in the question text. Additionally, the absence of fine-grained visual knowledge limits the precise understanding of subject behavior in visual reasoning tasks. To address these issues, we propose VIKSER (Visual Knowledge-Driven Self-Reinforcing Reasoning Framework). Specifically, VIKSER, trained using knowledge distilled from large language models, extracts fine-grained visual knowledge with the assistance of visual relationship detection techniques. Subsequently, VIKSER utilizes fine-grained visual knowledge to paraphrase the question with underspecification. Additionally, we design a novel prompting method called Chain-of-Evidence (CoE), which leverages the power of ``evidence for reasoning'' to endow VIKSER with interpretable reasoning capabilities. Meanwhile, the integration of self-reflection technology empowers VIKSER with the ability to learn and improve from its mistakes. Experiments conducted on widely used datasets demonstrate that VIKSER achieves new state-of-the-art (SOTA) results in relevant tasks.</li>
</ul>

<h3>Title: "I am bad": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Isha Gupta, David Khachaturov, Robert Mullins</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00718">https://arxiv.org/abs/2502.00718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00718">https://arxiv.org/pdf/2502.00718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00718]] "I am bad": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models(https://arxiv.org/abs/2502.00718)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>The rise of multimodal large language models has introduced innovative human-machine interaction paradigms but also significant challenges in machine learning safety. Audio-Language Models (ALMs) are especially relevant due to the intuitive nature of spoken communication, yet little is known about their failure modes. This paper explores audio jailbreaks targeting ALMs, focusing on their ability to bypass alignment mechanisms. We construct adversarial perturbations that generalize across prompts, tasks, and even base audio samples, demonstrating the first universal jailbreaks in the audio modality, and show that these remain effective in simulated real-world conditions. Beyond demonstrating attack feasibility, we analyze how ALMs interpret these audio adversarial examples and reveal them to encode imperceptible first-person toxic speech - suggesting that the most effective perturbations for eliciting toxic outputs specifically embed linguistic features within the audio signal. These results have important implications for understanding the interactions between different modalities in multimodal models, and offer actionable insights for enhancing defenses against adversarial audio attacks.</li>
</ul>

<h3>Title: Vision and Language Reference Prompt into SAM for Few-shot Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Kosuke Sakurai, Ryotaro Shimizu, Masayuki Goto</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00719">https://arxiv.org/abs/2502.00719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00719">https://arxiv.org/pdf/2502.00719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00719]] Vision and Language Reference Prompt into SAM for Few-shot Segmentation(https://arxiv.org/abs/2502.00719)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segment Anything Model (SAM) represents a large-scale segmentation model that enables powerful zero-shot capabilities with flexible prompts. While SAM can segment any object in zero-shot, it requires user-provided prompts for each target image and does not attach any label information to masks. Few-shot segmentation models addressed these issues by inputting annotated reference images as prompts to SAM and can segment specific objects in target images without user-provided prompts. Previous SAM-based few-shot segmentation models only use annotated reference images as prompts, resulting in limited accuracy due to a lack of reference information. In this paper, we propose a novel few-shot segmentation model, Vision and Language reference Prompt into SAM (VLP-SAM), that utilizes the visual information of the reference images and the semantic information of the text labels by inputting not only images but also language as reference information. In particular, VLP-SAM is a simple and scalable structure with minimal learnable parameters, which inputs prompt embeddings with vision-language information into SAM using a multimodal vision-language model. To demonstrate the effectiveness of VLP-SAM, we conducted experiments on the PASCAL-5i and COCO-20i datasets, and achieved high performance in the few-shot segmentation task, outperforming the previous state-of-the-art model by a large margin (6.3% and 9.5% in mIoU, respectively). Furthermore, VLP-SAM demonstrates its generality in unseen objects that are not included in the training data. Our code is available at this https URL.</li>
</ul>

<h3>Title: Understanding and Mitigating the High Computational Cost in Path Data Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Dingyuan Shi, Lulu Zhang, Yongxin Tong, Ke Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00725">https://arxiv.org/abs/2502.00725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00725">https://arxiv.org/pdf/2502.00725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00725]] Understanding and Mitigating the High Computational Cost in Path Data Diffusion(https://arxiv.org/abs/2502.00725)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Advancements in mobility services, navigation systems, and smart transportation technologies have made it possible to collect large amounts of path data. Modeling the distribution of this path data, known as the Path Generation (PG) problem, is crucial for understanding urban mobility patterns and developing intelligent transportation systems. Recent studies have explored using diffusion models to address the PG problem due to their ability to capture multimodal distributions and support conditional generation. A recent work devises a diffusion process explicitly in graph space and achieves state-of-the-art performance. However, this method suffers a high computation cost in terms of both time and memory, which prohibits its application. In this paper, we analyze this method both theoretically and experimentally and find that the main culprit of its high computation cost is its explicit design of the diffusion process in graph space. To improve efficiency, we devise a Latent-space Path Diffusion (LPD) model, which operates in latent space instead of graph space. Our LPD significantly reduces both time and memory costs by up to 82.8% and 83.1%, respectively. Despite these reductions, our approach does not suffer from performance degradation. It outperforms the state-of-the-art method in most scenarios by 24.5%~34.0%.</li>
</ul>

<h3>Title: Meta-Prompt Optimization for LLM-Based Sequential Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Mingze Kong, Zhiyong Wang, Yao Shu, Zhongxiang Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00728">https://arxiv.org/abs/2502.00728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00728">https://arxiv.org/pdf/2502.00728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00728]] Meta-Prompt Optimization for LLM-Based Sequential Decision Making(https://arxiv.org/abs/2502.00728)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently been employed as agents to solve sequential decision-making tasks such as Bayesian optimization and multi-armed bandits (MAB). These works usually adopt an LLM for sequential action selection by providing it with a fixed, manually designed meta-prompt. However, numerous previous works have found that the prompt has a significant impact on the performance of the LLM, which calls for a method to automatically optimize the meta-prompt for LLM-based agents. Unfortunately, the non-stationarity in the reward observations during LLM-based sequential decision-making makes meta-prompt optimization highly challenging. To address this challenge, we draw inspirations from adversarial bandit algorithms, which are inherently capable of handling non-stationary reward observations. Building on this foundation, we propose our EXPonential-weight algorithm for prompt Optimization} (EXPO) to automatically optimize the task description and meta-instruction in the meta-prompt for LLM-based agents. We also extend EXPO to additionally optimize the exemplars (i.e., history of interactions) in the meta-prompt to further enhance the performance, hence introducing our EXPO-ES algorithm. We use extensive experiments to show that our algorithms significantly improve the performance of LLM-based sequential decision-making.</li>
</ul>

<h3>Title: From Compliance to Exploitation: Jailbreak Prompt Attacks on Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chun Wai Chiu, Linghan Huang, Bo Li, Huaming Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00735">https://arxiv.org/abs/2502.00735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00735">https://arxiv.org/pdf/2502.00735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00735]] From Compliance to Exploitation: Jailbreak Prompt Attacks on Multimodal LLMs(https://arxiv.org/abs/2502.00735)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have seen widespread applications across various domains due to their growing ability to process diverse types of input data, including text, audio, image and video. While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input. In this paper, we introduce the first voice-based jailbreak attack against multimodal LLMs, termed as Flanking Attack, which can process different types of input simultaneously towards the multimodal LLMs. Our work is motivated by recent advancements in monolingual voice-driven large language models, which have introduced new attack surfaces beyond traditional text-based vulnerabilities for LLMs. To investigate these risks, we examine the frontier multimodal LLMs, which can be accessed via different types of inputs such as audio input, focusing on how adversarial prompts can bypass its defense mechanisms. We propose a novel strategy, in which the disallowed prompt is flanked by benign, narrative-driven prompts. It is integrated in the Flanking Attack which attempts to humanizes the interaction context and execute the attack through a fictional setting. To better evaluate the attack performance, we present a semi-automated self-assessment framework for policy violation detection. We demonstrate that Flank Attack is capable of manipulating state-of-the-art LLMs into generating misaligned and forbidden outputs, which achieves an average attack success rate ranging from 0.67 to 0.93 across seven forbidden scenarios. These findings highlight both the potency of prompt-based obfuscation in voice-enabled contexts and the limitations of current LLMs' moderation safeguards and the urgent need for advanced defense strategies to address the challenges posed by evolving, context-rich attacks.</li>
</ul>

<h3>Title: AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds</h3>
<ul>
<li><strong>Authors: </strong>J Rosser, Jakob Nicolaus Foerster</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00757">https://arxiv.org/abs/2502.00757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00757">https://arxiv.org/pdf/2502.00757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00757]] AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds(https://arxiv.org/abs/2502.00757)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scaffolding Large Language Models (LLMs) into multi-agent systems often improves performance on complex tasks, but the safety impact of such scaffolds has not been as thoroughly explored. In this paper, we introduce AGENTBREEDER a framework for multi-objective evolutionary search over scaffolds. Our REDAGENTBREEDER evolves scaffolds towards jailbreaking the base LLM while achieving high task success, while BLUEAGENTBREEDER instead aims to combine safety with task reward. We evaluate the systems discovered by the different instances of AGENTBREEDER and popular baselines using widely recognized reasoning, mathematics, and safety benchmarks. Our work highlights and mitigates the safety risks due to multi-agent scaffolding.</li>
</ul>

<h3>Title: Structural Latency Perturbation in Large Language Models Through Recursive State Induction</h3>
<ul>
<li><strong>Authors: </strong>Michael Mangrum, Jonathan Pemberton, Benedict Wetherby, Philip Montague</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00758">https://arxiv.org/abs/2502.00758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00758">https://arxiv.org/pdf/2502.00758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00758]] Structural Latency Perturbation in Large Language Models Through Recursive State Induction(https://arxiv.org/abs/2502.00758)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Computational efficiency has remained a critical consideration in scaling high-capacity language models, with inference latency and resource consumption presenting significant constraints on real-time applications. The study has introduced a structured latency perturbation mechanism that modifies computational pathways through recursive state induction, enabling dynamic suppression of redundant activations while preserving generative fidelity. A formal mathematical framework has been established to describe recursive perturbations, ensuring that modifications remain adaptive rather than statically imposed. Experiments have demonstrated that applying recursive state adjustments reduces inference latency across varying sequence lengths, with longer text generations benefiting from cumulative efficiency improvements. Comparative evaluations against structured pruning and quantization have indicated that latency gains can be achieved without compromising token retention or memory utilization. The analysis of computational overhead has suggested that selectively suppressing redundant activations contributes to improved power efficiency, particularly in scenarios requiring extended text generation. An assessment of linguistic stability has shown that token-level consistency remains largely intact under controlled perturbation thresholds, reinforcing the viability of structural latency modifications as an alternative to weight-centric optimization techniques. The results have supported the hypothesis that recursive state induction offers an effective method for reducing computational complexity without requiring architectural modifications or external augmentation.</li>
</ul>

<h3>Title: Privacy Preserving Properties of Vision Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Pirzada Suhail, Amit Sethi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00760">https://arxiv.org/abs/2502.00760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00760">https://arxiv.org/pdf/2502.00760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00760]] Privacy Preserving Properties of Vision Classifiers(https://arxiv.org/abs/2502.00760)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Vision classifiers are often trained on proprietary datasets containing sensitive information, yet the models themselves are frequently shared openly under the privacy-preserving assumption. Although these models are assumed to protect sensitive information in their training data, the extent to which this assumption holds for different architectures remains unexplored. This assumption is challenged by inversion attacks which attempt to reconstruct training data from model weights, exposing significant privacy vulnerabilities. In this study, we systematically evaluate the privacy-preserving properties of vision classifiers across diverse architectures, including Multi-Layer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), and Vision Transformers (ViTs). Using network inversion-based reconstruction techniques, we assess the extent to which these architectures memorize and reveal training data, quantifying the relative ease of reconstruction across models. Our analysis highlights how architectural differences, such as input representation, feature extraction mechanisms, and weight structures, influence privacy risks. By comparing these architectures, we identify which are more resilient to inversion attacks and examine the trade-offs between model performance and privacy preservation, contributing to the development of secure and privacy-respecting machine learning models for sensitive applications. Our findings provide actionable insights into the design of secure and privacy-aware machine learning systems, emphasizing the importance of evaluating architectural decisions in sensitive applications involving proprietary or personal data.</li>
</ul>

<h3>Title: FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Liangyu Xu, Xuemiao Zhang, Feiyu Duan, Sirui Wang, Jingang Wang, Xunliang Cai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00761">https://arxiv.org/abs/2502.00761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00761">https://arxiv.org/pdf/2502.00761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00761]] FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training(https://arxiv.org/abs/2502.00761)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Selecting high-quality data can significantly improve the pre-training efficiency of large language models (LLMs). Existing methods often rely on heuristic techniques and single quality signals, limiting their ability to comprehensively evaluate data quality. In this work, we propose FIRE, a flexible and scalable framework for integrating multiple data quality raters, which allows for a comprehensive assessment of data quality across various dimensions. FIRE aligns multiple quality signals into a unified space, and integrates diverse data quality raters to provide a comprehensive quality signal for each data point. Further, we introduce a progressive data selection scheme based on FIRE that iteratively refines the selection of high-quality data points, balancing computational complexity with the refinement of orthogonality. Experiments on the SlimPajama dataset reveal that FIRE consistently outperforms other selection methods and significantly enhances the pre-trained model across a wide range of downstream tasks, with a 2.9\% average performance boost and reducing the FLOPs necessary to achieve a certain performance level by more than half.</li>
</ul>

<h3>Title: AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification</h3>
<ul>
<li><strong>Authors: </strong>Jiate Li, Binghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00765">https://arxiv.org/abs/2502.00765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00765">https://arxiv.org/pdf/2502.00765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00765]] AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification(https://arxiv.org/abs/2502.00765)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) achieve the state-of-the-art on graph-relevant tasks such as node and graph classification. However, recent works show GNNs are vulnerable to adversarial perturbations include the perturbation on edges, nodes, and node features, the three components forming a graph. Empirical defenses against such attacks are soon broken by adaptive ones. While certified defenses offer robustness guarantees, they face several limitations: 1) almost all restrict the adversary's capability to only one type of perturbation, which is impractical; 2) all are designed for a particular GNN task, which limits their applicability; and 3) the robustness guarantees of all methods except one are not 100% accurate. We address all these limitations by developing AGNNCert, the first certified defense for GNNs against arbitrary (edge, node, and node feature) perturbations with deterministic robustness guarantees, and applicable to the two most common node and graph classification tasks. AGNNCert also encompass existing certified defenses as special cases. Extensive evaluations on multiple benchmark node/graph classification datasets and two real-world graph datasets, and multiple GNNs validate the effectiveness of AGNNCert to provably defend against arbitrary perturbations. AGNNCert also shows its superiority over the state-of-the-art certified defenses against the individual edge perturbation and node perturbation.</li>
</ul>

<h3>Title: Role of Mixup in Topological Persistence Based Knowledge Distillation for Wearable Sensor Data</h3>
<ul>
<li><strong>Authors: </strong>Eun Som Jeon, Hongjun Choi, Matthew P. Buman, Pavan Turaga</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00779">https://arxiv.org/abs/2502.00779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00779">https://arxiv.org/pdf/2502.00779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00779]] Role of Mixup in Topological Persistence Based Knowledge Distillation for Wearable Sensor Data(https://arxiv.org/abs/2502.00779)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The analysis of wearable sensor data has enabled many successes in several applications. To represent the high-sampling rate time-series with sufficient detail, the use of topological data analysis (TDA) has been considered, and it is found that TDA can complement other time-series features. Nonetheless, due to the large time consumption and high computational resource requirements of extracting topological features through TDA, it is difficult to deploy topological knowledge in various applications. To tackle this problem, knowledge distillation (KD) can be adopted, which is a technique facilitating model compression and transfer learning to generate a smaller model by transferring knowledge from a larger network. By leveraging multiple teachers in KD, both time-series and topological features can be transferred, and finally, a superior student using only time-series data is distilled. On the other hand, mixup has been popularly used as a robust data augmentation technique to enhance model performance during training. Mixup and KD employ similar learning strategies. In KD, the student model learns from the smoothed distribution generated by the teacher model, while mixup creates smoothed labels by blending two labels. Hence, this common smoothness serves as the connecting link that establishes a connection between these two methods. In this paper, we analyze the role of mixup in KD with time-series as well as topological persistence, employing multiple teachers. We present a comprehensive analysis of various methods in KD and mixup on wearable sensor data.</li>
</ul>

<h3>Title: A method for estimating forest carbon storage distribution density via artificial intelligence generated content model</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Yu, Jinnian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00783">https://arxiv.org/abs/2502.00783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00783">https://arxiv.org/pdf/2502.00783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00783]] A method for estimating forest carbon storage distribution density via artificial intelligence generated content model(https://arxiv.org/abs/2502.00783)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Forest is the most significant land-based carbon storage mechanism. The forest carbon sink can effectively decrease the atmospheric CO2 concentration and mitigate climate change. Remote sensing estimation not only ensures high accuracy of data, but also enables large-scale area observation. Optical images provide the possibility for long-term monitoring, which is a potential issue in the future carbon storage estimation research. We chose Huize County, Qujing City, Yunnan Province, China as the study area, took GF-1 WFV satellite image as the data, introduced the KD-VGG module to extract the initial features, and proposed the improved implicit diffusion model (IIDM). The results showed that: (1) The VGG-19 module after knowledge distillation can realize the initial feature extraction, reduce the inference time and improve the accuracy in the case of reducing the number of model parameters. (2) The Attention + MLP module was added for feature fusion to obtain the relationship between global and local features and realized the restoration of high-fidelity images in the continuous scale range. (3) The IIDM model proposed in this paper had the highest estimation accuracy, with RMSE of 28.68, which was 13.16 higher than that of the regression model, about 31.45%. In the estimation of carbon storage, the generative model can extract deeper features, and its performance was significantly better than other models. It demonstrated the feasibility of artificial intelligence-generated content (AIGC) in the field of quantitative remote sensing and provided valuable insights for the study of carbon neutralization effect. By combining the actual characteristics of the forest, the regional carbon storage estimation with a resolution of 16-meter was utilized to provide a significant theoretical basis for the formulation of forest carbon sink regulation.</li>
</ul>

<h3>Title: Estimating forest carbon stocks from high-resolution remote sensing imagery by reducing domain shift with style transfer</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Yu, Jinnian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00784">https://arxiv.org/abs/2502.00784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00784">https://arxiv.org/pdf/2502.00784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00784]] Estimating forest carbon stocks from high-resolution remote sensing imagery by reducing domain shift with style transfer(https://arxiv.org/abs/2502.00784)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Forests function as crucial carbon reservoirs on land, and their carbon sinks can efficiently reduce atmospheric CO2 concentrations and mitigate climate change. Currently, the overall trend for monitoring and assessing forest carbon stocks is to integrate ground monitoring sample data with satellite remote sensing imagery. This style of analysis facilitates large-scale observation. However, these techniques require improvement in accuracy. We used GF-1 WFV and Landsat TM images to analyze Huize County, Qujing City, Yunnan Province in China. Using the style transfer method, we introduced Swin Transformer to extract global features through attention mechanisms, converting the carbon stock estimation into an image translation.</li>
</ul>

<h3>Title: Vision-centric Token Compression in Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Ling Xing, Alex Jinpeng Wang, Rui Yan, Jinhui Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00791">https://arxiv.org/abs/2502.00791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00791">https://arxiv.org/pdf/2502.00791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00791]] Vision-centric Token Compression in Large Language Model(https://arxiv.org/abs/2502.00791)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized natural language processing, excelling in handling longer sequences. However, the inefficiency and redundancy in processing extended in-context tokens remain a challenge. Many attempts to address this rely on compressing tokens with smaller text encoders, yet we question whether text encoders are truly indispensable. Our journey leads to an unexpected discovery-a much smaller vision encoder, applied directly to sequences of text tokens, can rival text encoders on text tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small text understanding benchmarks, VIST leads to comparable results with 16% fewer FLOPs and 50% less memory usage. We further uncover significant token redundancy and devise a frequency-based masking strategy to guide the focus of the visual encoder toward the most critical tokens. Interestingly, we observe the trained visual encoder performs like a summarizer, selectively ignoring less important words such as prepositions and conjunctions. This approach delivers remarkable results, outperforming traditional text encoder-based methods by 5.7% on average over benchmarks like TriviaQA, NQ, PopQA, TREF, SST2, and SST5, setting a new standard for token efficiency in LLMs.</li>
</ul>

<h3>Title: Task-Specific Adaptation with Restricted Model Access</h3>
<ul>
<li><strong>Authors: </strong>Matan Levy, Rami Ben-Ari, Dvir Samuel, Nir Darshan, Dani Lischinski</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00796">https://arxiv.org/abs/2502.00796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00796">https://arxiv.org/pdf/2502.00796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00796]] Task-Specific Adaptation with Restricted Model Access(https://arxiv.org/abs/2502.00796)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The emergence of foundational models has greatly improved performance across various downstream tasks, with fine-tuning often yielding even better results. However, existing fine-tuning approaches typically require access to model weights and layers, leading to challenges such as managing multiple model copies or inference pipelines, inefficiencies in edge device optimization, and concerns over proprietary rights, privacy, and exposure to unsafe model variants. In this paper, we address these challenges by exploring "Gray-box" fine-tuning approaches, where the model's architecture and weights remain hidden, allowing only gradient propagation. We introduce a novel yet simple and effective framework that adapts to new tasks using two lightweight learnable modules at the model's input and output. Additionally, we present a less restrictive variant that offers more entry points into the model, balancing performance with model exposure. We evaluate our approaches across several backbones on benchmarks such as text-image alignment, text-video alignment, and sketch-image alignment. Results show that our Gray-box approaches are competitive with full-access fine-tuning methods, despite having limited access to the model.</li>
</ul>

<h3>Title: Adversarial Semantic Augmentation for Training Generative Adversarial Networks under Limited Data</h3>
<ul>
<li><strong>Authors: </strong>Mengping Yang, Zhe Wang, Ziqiu Chi, Dongdong Li, Wenli Du</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00800">https://arxiv.org/abs/2502.00800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00800">https://arxiv.org/pdf/2502.00800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00800]] Adversarial Semantic Augmentation for Training Generative Adversarial Networks under Limited Data(https://arxiv.org/abs/2502.00800)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative adversarial networks (GANs) have made remarkable achievements in synthesizing images in recent years. Typically, training GANs requires massive data, and the performance of GANs deteriorates significantly when training data is limited. To improve the synthesis performance of GANs in low-data regimes, existing approaches use various data augmentation techniques to enlarge the training sets. However, it is identified that these augmentation techniques may leak or even alter the data distribution. To remedy this, we propose an adversarial semantic augmentation (ASA) technique to enlarge the training data at the semantic level instead of the image level. Concretely, considering semantic features usually encode informative information of images, we estimate the covariance matrices of semantic features for both real and generated images to find meaningful transformation directions. Such directions translate original features to another semantic representation, e.g., changing the backgrounds or expressions of the human face dataset. Moreover, we derive an upper bound of the expected adversarial loss. By optimizing the upper bound, our semantic augmentation is implicitly achieved. Such design avoids redundant sampling of the augmented features and introduces negligible computation overhead, making our approach computation efficient. Extensive experiments on both few-shot and large-scale datasets demonstrate that our method consistently improve the synthesis quality under various data regimes, and further visualized and analytic results suggesting satisfactory versatility of our proposed method.</li>
</ul>

<h3>Title: ProPINN: Demystifying Propagation Failures in Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Haixu Wu, Yuezhou Ma, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00803">https://arxiv.org/abs/2502.00803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00803">https://arxiv.org/pdf/2502.00803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00803]] ProPINN: Demystifying Propagation Failures in Physics-Informed Neural Networks(https://arxiv.org/abs/2502.00803)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Physics-informed neural networks (PINNs) have earned high expectations in solving partial differential equations (PDEs), but their optimization usually faces thorny challenges due to the unique derivative-dependent loss function. By analyzing the loss distribution, previous research observed the propagation failure phenomenon of PINNs, intuitively described as the correct supervision for model outputs cannot ``propagate'' from initial states or boundaries to the interior domain. Going beyond intuitive understanding, this paper provides the first formal and in-depth study of propagation failure and its root cause. Based on a detailed comparison with classical finite element methods, we ascribe the failure to the conventional single-point-processing architecture of PINNs and further prove that propagation failure is essentially caused by the lower gradient correlation of PINN models on nearby collocation points. Compared to superficial loss maps, this new perspective provides a more precise quantitative criterion to identify where and why PINN fails. The theoretical finding also inspires us to present a new PINN architecture, named ProPINN, which can effectively unite the gradient of region points for better propagation. ProPINN can reliably resolve PINN failure modes and significantly surpass advanced Transformer-based models with 46% relative promotion.</li>
</ul>

<h3>Title: UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs</h3>
<ul>
<li><strong>Authors: </strong>Yufei He, Yuan Sui, Xiaoxin He, Yue Liu, Yifei Sun, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00806">https://arxiv.org/abs/2502.00806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00806">https://arxiv.org/pdf/2502.00806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00806]] UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs(https://arxiv.org/abs/2502.00806)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Existing foundation models, such as CLIP, aim to learn a unified embedding space for multimodal data, enabling a wide range of downstream web-based applications like search, recommendation, and content classification. However, these models often overlook the inherent graph structures in multimodal datasets, where entities and their relationships are crucial. Multimodal graphs (MMGs) represent such graphs where each node is associated with features from different modalities, while the edges capture the relationships between these entities. On the other hand, existing graph foundation models primarily focus on text-attributed graphs (TAGs) and are not designed to handle the complexities of MMGs. To address these limitations, we propose UniGraph2, a novel cross-domain graph foundation model that enables general representation learning on MMGs, providing a unified embedding space. UniGraph2 employs modality-specific encoders alongside a graph neural network (GNN) to learn a unified low-dimensional embedding space that captures both the multimodal information and the underlying graph structure. We propose a new cross-domain multi-graph pre-training algorithm at scale to ensure effective transfer learning across diverse graph domains and modalities. Additionally, we adopt a Mixture of Experts (MoE) component to align features from different domains and modalities, ensuring coherent and robust embeddings that unify the information across modalities. Extensive experiments on a variety of multimodal graph tasks demonstrate that UniGraph2 significantly outperforms state-of-the-art models in tasks such as representation learning, transfer learning, and multimodal generative tasks, offering a scalable and flexible solution for learning on MMGs.</li>
</ul>

<h3>Title: Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications</h3>
<ul>
<li><strong>Authors: </strong>Yixin Wu, Ziqing Yang, Yun Shen, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00808">https://arxiv.org/abs/2502.00808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00808">https://arxiv.org/pdf/2502.00808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00808]] Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications(https://arxiv.org/abs/2502.00808)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have facilitated the generation of high-quality, cost-effective synthetic data for developing downstream models and conducting statistical analyses in various domains. However, the increased reliance on synthetic data may pose potential negative impacts. Numerous studies have demonstrated that LLM-generated synthetic data can perpetuate and even amplify societal biases and stereotypes, and produce erroneous outputs known as ``hallucinations'' that deviate from factual knowledge. In this paper, we aim to audit artifacts, such as classifiers, generators, or statistical plots, to identify those trained on or derived from synthetic data and raise user awareness, thereby reducing unexpected consequences and risks in downstream applications. To this end, we take the first step to introduce synthetic artifact auditing to assess whether a given artifact is derived from LLM-generated synthetic data. We then propose an auditing framework with three methods including metric-based auditing, tuning-based auditing, and classification-based auditing. These methods operate without requiring the artifact owner to disclose proprietary training details. We evaluate our auditing framework on three text classification tasks, two text summarization tasks, and two data visualization tasks across three training scenarios. Our evaluation demonstrates the effectiveness of all proposed auditing methods across all these tasks. For instance, black-box metric-based auditing can achieve an average accuracy of $0.868 \pm 0.071$ for auditing classifiers and $0.880 \pm 0.052$ for auditing generators using only 200 random queries across three scenarios. We hope our research will enhance model transparency and regulatory compliance, ensuring the ethical and responsible use of synthetic data.</li>
</ul>

<h3>Title: Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Yue Wang, Li Li, Wengang Zhou, Houqiang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00814">https://arxiv.org/abs/2502.00814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00814">https://arxiv.org/pdf/2502.00814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00814]] Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling(https://arxiv.org/abs/2502.00814)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) has achieved considerable success in aligning large language models (LLMs) by modeling human preferences with a learnable reward model and employing a reinforcement learning algorithm to maximize the reward model's scores. However, these reward models are susceptible to exploitation through various superficial confounding factors, with length bias emerging as a particularly significant concern. Moreover, while the pronounced impact of length bias on preference modeling suggests that LLMs possess an inherent sensitivity to length perception, our preliminary investigations reveal that fine-tuned LLMs consistently struggle to adhere to explicit length instructions. To address these two limitations, we propose a novel framework wherein the reward model explicitly differentiates between human semantic preferences and response length requirements. Specifically, we introduce a Response-conditioned Bradley-Terry (Rc-BT) model that enhances the reward model's capability in length bias mitigating and length instruction following, through training on our augmented dataset. Furthermore, we propose the Rc-DPO algorithm to leverage the Rc-BT model for direct policy optimization (DPO) of LLMs, simultaneously mitigating length bias and promoting adherence to length instructions. Extensive evaluations demonstrate that our approach substantially improves both preference modeling and length instruction compliance, with its effectiveness validated across various foundational models and preference datasets.</li>
</ul>

<h3>Title: Sundial: A Family of Highly Capable Time Series Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Yong Liu, Guo Qin, Zhiyuan Shi, Zhi Chen, Caiyin Yang, Xiangdong Huang, Jianmin Wang, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00816">https://arxiv.org/abs/2502.00816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00816">https://arxiv.org/pdf/2502.00816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00816]] Sundial: A Family of Highly Capable Time Series Foundation Models(https://arxiv.org/abs/2502.00816)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>We introduce Sundial, a family of native, flexible, and scalable time series foundation models. To predict the next-patch's distribution, we propose a TimeFlow Loss based on flow-matching, which facilitates native pre-training of Transformers on time series without discrete tokenization. Conditioned on arbitrary-length time series, our model is pre-trained without specifying any prior distribution and can generate multiple probable predictions, achieving flexibility in representation learning beyond using parametric densities. Towards time series foundation models, we leverage minimal but crucial adaptations of Transformers and curate TimeBench with 1 trillion time points, comprising mostly real-world datasets and synthetic data. By mitigating mode collapse through TimeFlow Loss, we pre-train a family of Sundial models on TimeBench, which exhibit unprecedented model capacity and generalization performance on zero-shot forecasting. In addition to presenting good scaling behavior, Sundial achieves new state-of-the-art on both point forecasting and probabilistic forecasting benchmarks. We believe that Sundial's pioneering generative paradigm will facilitate a wide variety of forecasting scenarios.</li>
</ul>

<h3>Title: Probing Large Language Models in Reasoning and Translating Complex Linguistic Puzzles</h3>
<ul>
<li><strong>Authors: </strong>Zheng-Lin Lin, Yu-Fei Shih, Shu-Kai Hsieh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00817">https://arxiv.org/abs/2502.00817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00817">https://arxiv.org/pdf/2502.00817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00817]] Probing Large Language Models in Reasoning and Translating Complex Linguistic Puzzles(https://arxiv.org/abs/2502.00817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the utilization of Large Language Models (LLMs) for solving complex linguistic puzzles, a domain requiring advanced reasoning and adept translation capabilities akin to human cognitive processes. We explore specific prompting techniques designed to enhance ability of LLMs to reason and elucidate their decision-making pathways, with a focus on Input-Output Prompting (IO), Chain-of-Thought Prompting (CoT), and Solo Performance Prompting (SPP). Utilizing datasets from the Puzzling Machine Competition and various Linguistics Olympiads, we employ a comprehensive set of metrics to assess the performance of GPT-4 0603, a prominent LLM, across these prompting methods. Our findings illuminate the potential of LLMs in linguistic reasoning and complex translation tasks, highlighting their capabilities and identifying limitations in the context of linguistic puzzles. This research contributes significantly to the broader field of Natural Language Processing (NLP) by providing insights into the optimization of LLM applications for improved reasoning and translation accuracy, thereby enriching the ongoing dialogue in NLP advancements.</li>
</ul>

<h3>Title: OOD Detection with immature Models</h3>
<ul>
<li><strong>Authors: </strong>Behrooz Montazeran, Ullrich Köthe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00820">https://arxiv.org/abs/2502.00820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00820">https://arxiv.org/pdf/2502.00820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00820]] OOD Detection with immature Models(https://arxiv.org/abs/2502.00820)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Likelihood-based deep generative models (DGMs) have gained significant attention for their ability to approximate the distributions of high-dimensional data. However, these models lack a performance guarantee in assigning higher likelihood values to in-distribution (ID) inputs, data the models are trained on, compared to out-of-distribution (OOD) inputs. This counter-intuitive behaviour is particularly pronounced when ID inputs are more complex than OOD data points. One potential approach to address this challenge involves leveraging the gradient of a data point with respect to the parameters of the DGMs. A recent OOD detection framework proposed estimating the joint density of layer-wise gradient norms for a given data point as a model-agnostic method, demonstrating superior performance compared to the Typicality Test across likelihood-based DGMs and image dataset pairs. In particular, most existing methods presuppose access to fully converged models, the training of which is both time-intensive and computationally demanding. In this work, we demonstrate that using immature models,stopped at early stages of training, can mostly achieve equivalent or even superior results on this downstream task compared to mature models capable of generating high-quality samples that closely resemble ID data. This novel finding enhances our understanding of how DGMs learn the distribution of ID data and highlights the potential of leveraging partially trained models for downstream tasks. Furthermore, we offer a possible explanation for this unexpected behaviour through the concept of support overlap.</li>
</ul>

<h3>Title: Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Julian Perry, Frank Sanders, Carter Scott</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00826">https://arxiv.org/abs/2502.00826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00826">https://arxiv.org/pdf/2502.00826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00826]] Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large Language Models(https://arxiv.org/abs/2502.00826)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we presents a novel method for improving text-to-image generation by combining Large Language Models (LLMs) with diffusion models, a hybrid approach aimed at achieving both higher quality and efficiency in image synthesis from text descriptions. Our approach introduces a new dynamic KL-weighting strategy to optimize the diffusion process, along with incorporating semantic understanding from pre-trained LLMs to guide the generation process. The proposed method significantly improves both the visual quality and alignment of generated images with text descriptions, addressing challenges such as computational inefficiency, instability in training, and robustness to textual variability. We evaluate our method on the COCO dataset and demonstrate its superior performance over traditional GAN-based models, both quantitatively and qualitatively. Extensive experiments, including ablation studies and human evaluations, confirm that our method outperforms existing approaches in terms of image realism, relevance to the input text, and overall aesthetic quality. Our approach also shows promise in scalability to other multimodal tasks, making it a versatile solution for a wide range of generative applications.</li>
</ul>

<h3>Title: A Comprehensive Analysis on LLM-based Node Classification Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Xixi Wu, Yifei Shen, Fangzhou Ge, Caihua Shan, Yizhu Jiao, Xiangguo Sun, Hong Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00829">https://arxiv.org/abs/2502.00829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00829">https://arxiv.org/pdf/2502.00829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00829]] A Comprehensive Analysis on LLM-based Node Classification Algorithms(https://arxiv.org/abs/2502.00829)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Node classification is a fundamental task in graph analysis, with broad applications across various fields. Recent breakthroughs in Large Language Models (LLMs) have enabled LLM-based approaches for this task. Although many studies demonstrate the impressive performance of LLM-based methods, the lack of clear design guidelines may hinder their practical application. In this work, we aim to establish such guidelines through a fair and systematic comparison of these algorithms. As a first step, we developed LLMNodeBed, a comprehensive codebase and testbed for node classification using LLMs. It includes ten datasets, eight LLM-based algorithms, and three learning paradigms, and is designed for easy extension with new methods and datasets. Subsequently, we conducted extensive experiments, training and evaluating over 2,200 models, to determine the key settings (e.g., learning paradigms and homophily) and components (e.g., model size) that affect performance. Our findings uncover eight insights, e.g., (1) LLM-based methods can significantly outperform traditional methods in a semi-supervised setting, while the advantage is marginal in a supervised setting; (2) Graph Foundation Models can beat open-source LLMs but still fall short of strong LLMs like GPT-4o in a zero-shot setting. We hope that the release of LLMNodeBed, along with our insights, will facilitate reproducible research and inspire future studies in this field. Codes and datasets are released at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Generalization of Medical Large Language Models through Cross-Domain Weak Supervision</h3>
<ul>
<li><strong>Authors: </strong>Robert Long, Eric Gonzalez, Harrison Fuller</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00832">https://arxiv.org/abs/2502.00832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00832">https://arxiv.org/pdf/2502.00832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00832]] Generalization of Medical Large Language Models through Cross-Domain Weak Supervision(https://arxiv.org/abs/2502.00832)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>The advancement of large language models (LLMs) has opened new frontiers in natural language processing, particularly in specialized domains like healthcare. In this paper, we propose the Incremental Curriculum-Based Fine-Tuning (ICFT) framework to enhance the generative capabilities of medical large language models (MLLMs). ICFT combines curriculum-based learning, dual-stage memory coordination, and parameter-efficient fine-tuning to enable a progressive transition from general linguistic knowledge to strong domain-specific expertise. Experimental results across diverse medical NLP tasks, including question answering, preference classification, and response generation, demonstrate that ICFT consistently outperforms state-of-the-art baselines, achieving improvements in both accuracy and efficiency. Further analysis reveals the framework's ability to generalize to unseen data, reduce errors, and deliver diverse, contextually relevant medical responses. These findings establish ICFT as a robust and scalable solution for adapting LLMs to the medical domain, offering practical benefits for real-world healthcare applications.</li>
</ul>

<h3>Title: Cross multiscale vision transformer for deep fake detection</h3>
<ul>
<li><strong>Authors: </strong>Akhshan P, Taneti Sanjay, Chandrakala S</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00833">https://arxiv.org/abs/2502.00833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00833">https://arxiv.org/pdf/2502.00833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00833]] Cross multiscale vision transformer for deep fake detection(https://arxiv.org/abs/2502.00833)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The proliferation of deep fake technology poses significant challenges to digital media authenticity, necessitating robust detection mechanisms. This project evaluates deep fake detection using the SP Cup's 2025 deep fake detection challenge dataset. We focused on exploring various deep learning models for detecting deep fake content, utilizing traditional deep learning techniques alongside newer architectures. Our approach involved training a series of models and rigorously assessing their performance using metrics such as accuracy.</li>
</ul>

<h3>Title: Boosting Adversarial Robustness and Generalization with Structural Prior</h3>
<ul>
<li><strong>Authors: </strong>Zhichao Hou, Weizhi Gao, Hamid Krim, Xiaorui Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00834">https://arxiv.org/abs/2502.00834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00834">https://arxiv.org/pdf/2502.00834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00834]] Boosting Adversarial Robustness and Generalization with Structural Prior(https://arxiv.org/abs/2502.00834)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>This work investigates a novel approach to boost adversarial robustness and generalization by incorporating structural prior into the design of deep learning models. Specifically, our study surprisingly reveals that existing dictionary learning-inspired convolutional neural networks (CNNs) provide a false sense of security against adversarial attacks. To address this, we propose Elastic Dictionary Learning Networks (EDLNets), a novel ResNet architecture that significantly enhances adversarial robustness and generalization. This novel and effective approach is supported by a theoretical robustness analysis using influence functions. Moreover, extensive and reliable experiments demonstrate consistent and significant performance improvement on open robustness leaderboards such as RobustBench, surpassing state-of-the-art baselines. To the best of our knowledge, this is the first work to discover and validate that structural prior can reliably enhance deep learning robustness under strong adaptive attacks, unveiling a promising direction for future research.</li>
</ul>

<h3>Title: Explainability in Practice: A Survey of Explainable NLP Across Various Domains</h3>
<ul>
<li><strong>Authors: </strong>Hadi Mohammadi, Ayoub Bagheri, Anastasia Giachanou, Daniel L. Oberski</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00837">https://arxiv.org/abs/2502.00837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00837">https://arxiv.org/pdf/2502.00837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00837]] Explainability in Practice: A Survey of Explainable NLP Across Various Domains(https://arxiv.org/abs/2502.00837)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Natural Language Processing (NLP) has become a cornerstone in many critical sectors, including healthcare, finance, and customer relationship management. This is especially true with the development and use of advanced models such as GPT-based architectures and BERT, which are widely used in decision-making processes. However, the black-box nature of these advanced NLP models has created an urgent need for transparency and explainability. This review explores explainable NLP (XNLP) with a focus on its practical deployment and real-world applications, examining its implementation and the challenges faced in domain-specific contexts. The paper underscores the importance of explainability in NLP and provides a comprehensive perspective on how XNLP can be designed to meet the unique demands of various sectors, from healthcare's need for clear insights to finance's emphasis on fraud detection and risk assessment. Additionally, this review aims to bridge the knowledge gap in XNLP literature by offering a domain-specific exploration and discussing underrepresented areas such as real-world applicability, metric evaluation, and the role of human interaction in model assessment. The paper concludes by suggesting future research directions that could enhance the understanding and broader application of XNLP.</li>
</ul>

<h3>Title: Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Zhang, Kejia Chen, Lipeng He, Jian Lou, Dan Li, Zunlei Feng, Mingli Song, Jian Liu, Kui Ren, Xiaohu Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00840">https://arxiv.org/abs/2502.00840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00840">https://arxiv.org/pdf/2502.00840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00840]] Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense(https://arxiv.org/abs/2502.00840)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have showcased remarkable capabilities across various domains. Accompanying the evolving capabilities and expanding deployment scenarios of LLMs, their deployment challenges escalate due to their sheer scale and the advanced yet complex activation designs prevalent in notable model series, such as Llama, Gemma, and Mistral. These challenges have become particularly pronounced in resource-constrained deployment scenarios, where mitigating inference efficiency bottlenecks is imperative. Among various recent efforts, activation approximation has emerged as a promising avenue for pursuing inference efficiency, sometimes considered indispensable in applications such as private inference. Despite achieving substantial speedups with minimal impact on utility, even appearing sound and practical for real-world deployment, the safety implications of activation approximations remain unclear. In this work, we fill this critical gap in LLM safety by conducting the first systematic safety evaluation of activation approximations. Our safety vetting spans seven sota techniques across three popular categories, revealing consistent safety degradation across ten safety-aligned LLMs.</li>
</ul>

<h3>Title: Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Terje Mildner, Oliver Hamelijnck, Paris Giampouras, Theodoros Damoulas</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00846">https://arxiv.org/abs/2502.00846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00846">https://arxiv.org/pdf/2502.00846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00846]] Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework(https://arxiv.org/abs/2502.00846)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>We introduce FedGVI, a probabilistic Federated Learning (FL) framework that is provably robust to both prior and likelihood misspecification. FedGVI addresses limitations in both frequentist and Bayesian FL by providing unbiased predictions under model misspecification, with calibrated uncertainty quantification. Our approach generalises previous FL approaches, specifically Partitioned Variational Inference (Ashman et al., 2022), by allowing robust and conjugate updates, decreasing computational complexity at the clients. We offer theoretical analysis in terms of fixed-point convergence, optimality of the cavity distribution, and provable robustness. Additionally, we empirically demonstrate the effectiveness of FedGVI in terms of improved robustness and predictive performance on multiple synthetic and real world classification data sets.</li>
</ul>

<h3>Title: SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Zhang, Kejia Chen, Zunlei Feng, Jian Lou, Mingli Song, Jian Liu, Xiaohu Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00847">https://arxiv.org/abs/2502.00847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00847">https://arxiv.org/pdf/2502.00847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00847]] SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models(https://arxiv.org/abs/2502.00847)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>With the growing popularity of LLMs among the general public users, privacy-preserving and adversarial robustness have become two pressing demands for LLM-based services, which have largely been pursued separately but rarely jointly. In this paper, to the best of our knowledge, we are among the first attempts towards robust and private LLM inference by tightly integrating two disconnected fields: private inference and prompt ensembling. The former protects users' privacy by encrypting inference data transmitted and processed by LLMs, while the latter enhances adversarial robustness by yielding an aggregated output from multiple prompted LLM responses. Although widely recognized as effective individually, private inference for prompt ensembling together entails new challenges that render the naive combination of existing techniques inefficient. To overcome the hurdles, we propose SecPE, which designs efficient fully homomorphic encryption (FHE) counterparts for the core algorithmic building blocks of prompt ensembling. We conduct extensive experiments on 8 tasks to evaluate the accuracy, robustness, and efficiency of SecPE. The results show that SecPE maintains high clean accuracy and offers better robustness at the expense of merely $2.5\%$ efficiency overhead compared to baseline private inference methods, indicating a satisfactory ``accuracy-robustness-efficiency'' tradeoff. For the efficiency of the encrypted Argmax operation that incurs major slowdown for prompt ensembling, SecPE is 35.4x faster than the state-of-the-art peers, which can be of independent interest beyond this work.</li>
</ul>

<h3>Title: RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yuanhuiyi Lyu, Xu Zheng, Lutao Jiang, Yibo Yan, Xin Zou, Huiyu Zhou, Linfeng Zhang, Xuming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00848">https://arxiv.org/abs/2502.00848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00848">https://arxiv.org/pdf/2502.00848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00848]] RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning(https://arxiv.org/abs/2502.00848)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent text-to-image generative models, e.g., Stable Diffusion V3 and Flux, have achieved notable progress. However, these models are strongly restricted to their limited knowledge, a.k.a., their own fixed parameters, that are trained with closed datasets. This leads to significant hallucinations or distortions when facing fine-grained and unseen novel real-world objects, e.g., the appearance of the Tesla Cybertruck. To this end, we present the first real-object-based retrieval-augmented generation framework (RealRAG), which augments fine-grained and unseen novel object generation by learning and retrieving real-world images to overcome the knowledge gaps of generative models. Specifically, to integrate missing memory for unseen novel object generation, we train a reflective retriever by self-reflective contrastive learning, which injects the generator's knowledge into the sef-reflective negatives, ensuring that the retrieved augmented images compensate for the model's missing knowledge. Furthermore, the real-object-based framework integrates fine-grained visual knowledge for the generative models, tackling the distortion problem and improving the realism for fine-grained object generation. Our Real-RAG is superior in its modular application to all types of state-of-the-art text-to-image generative models and also delivers remarkable performance boosts with all of them, such as a gain of 16.18% FID score with the auto-regressive model on the Stanford Car benchmark.</li>
</ul>

<h3>Title: HintEval: A Comprehensive Framework for Hint Generation and Evaluation for Questions</h3>
<ul>
<li><strong>Authors: </strong>Jamshid Mozafari, Bhawna Piryani, Abdelrahman Abdallah, Adam Jatowt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00857">https://arxiv.org/abs/2502.00857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00857">https://arxiv.org/pdf/2502.00857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00857]] HintEval: A Comprehensive Framework for Hint Generation and Evaluation for Questions(https://arxiv.org/abs/2502.00857)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are transforming how people find information, and many users turn nowadays to chatbots to obtain answers to their questions. Despite the instant access to abundant information that LLMs offer, it is still important to promote critical thinking and problem-solving skills. Automatic hint generation is a new task that aims to support humans in answering questions by themselves by creating hints that guide users toward answers without directly revealing them. In this context, hint evaluation focuses on measuring the quality of hints, helping to improve the hint generation approaches. However, resources for hint research are currently spanning different formats and datasets, while the evaluation tools are missing or incompatible, making it hard for researchers to compare and test their models. To overcome these challenges, we introduce HintEval, a Python library that makes it easy to access diverse datasets and provides multiple approaches to generate and evaluate hints. HintEval aggregates the scattered resources into a single toolkit that supports a range of research goals and enables a clear, multi-faceted, and reliable evaluation. The proposed library also includes detailed online documentation, helping users quickly explore its features and get started. By reducing barriers to entry and encouraging consistent evaluation practices, HintEval offers a major step forward for facilitating hint generation and analysis research within the NLP/IR community.</li>
</ul>

<h3>Title: FedRIR: Rethinking Information Representation in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yongqiang Huang, Zerui Shao, Ziyuan Yang, Zexin Lu, Yi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00859">https://arxiv.org/abs/2502.00859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00859">https://arxiv.org/pdf/2502.00859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00859]] FedRIR: Rethinking Information Representation in Federated Learning(https://arxiv.org/abs/2502.00859)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Mobile and Web-of-Things (WoT) devices at the network edge generate vast amounts of data for machine learning applications, yet privacy concerns hinder centralized model training. Federated Learning (FL) allows clients (devices) to collaboratively train a shared model coordinated by a central server without transfer private data, but inherent statistical heterogeneity among clients presents challenges, often leading to a dilemma between clients' needs for personalized local models and the server's goal of building a generalized global model. Existing FL methods typically prioritize either global generalization or local personalization, resulting in a trade-off between these two objectives and limiting the full potential of diverse client data. To address this challenge, we propose a novel framework that simultaneously enhances global generalization and local personalization by Rethinking Information Representation in the Federated learning process (FedRIR). Specifically, we introduce Masked Client-Specific Learning (MCSL), which isolates and extracts fine-grained client-specific features tailored to each client's unique data characteristics, thereby enhancing personalization. Concurrently, the Information Distillation Module (IDM) refines the global shared features by filtering out redundant client-specific information, resulting in a purer and more robust global representation that enhances generalization. By integrating the refined global features with the isolated client-specific features, we construct enriched representations that effectively capture both global patterns and local nuances, thereby improving the performance of downstream tasks on the client. The code is available at this https URL.</li>
</ul>

<h3>Title: Predicting potentially unfair clauses in Chilean terms of services with natural language processing</h3>
<ul>
<li><strong>Authors: </strong>Christoffer Loeffler, Andrea Martínez Freile, Tomás Rey Pizarro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00865">https://arxiv.org/abs/2502.00865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00865">https://arxiv.org/pdf/2502.00865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00865]] Predicting potentially unfair clauses in Chilean terms of services with natural language processing(https://arxiv.org/abs/2502.00865)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer</a></li>
<li><strong>Abstract: </strong>This study addresses the growing concern of information asymmetry in consumer contracts, exacerbated by the proliferation of online services with complex Terms of Service that are rarely even read. Even though research on automatic analysis methods is conducted, the problem is aggravated by the general focus on English-language Machine Learning approaches and on major jurisdictions, such as the European Union. We introduce a new methodology and a substantial dataset addressing this gap. We propose a novel annotation scheme with four categories and a total of 20 classes, and apply it on 50 online Terms of Service used in Chile. Our evaluation of transformer-based models highlights how factors like language- and/or domain-specific pre-training, few-shot sample size, and model architecture affect the detection and classification of potentially abusive clauses. Results show a large variability in performance for the different tasks and models, with the highest macro-F1 scores for the detection task ranging from 79% to 89% and micro-F1 scores up to 96%, while macro-F1 scores for the classification task range from 60% to 70% and micro-F1 scores from 64% to 80%. Notably, this is the first Spanish-language multi-label classification dataset for legal clauses, applying Chilean law and offering a comprehensive evaluation of Spanish-language models in the legal domain. Our work lays the ground for future research in method development for rarely considered legal analysis and potentially leads to practical applications to support consumers in Chile and Latin America as a whole.</li>
</ul>

<h3>Title: STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation</h3>
<ul>
<li><strong>Authors: </strong>Alireza Morsali, MohammadJavad Vaez, Hossein Soltani, Amirhossein Kazerouni, Babak Taati, Morteza Mohammad-Noori</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00869">https://arxiv.org/abs/2502.00869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00869">https://arxiv.org/pdf/2502.00869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00869]] STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation(https://arxiv.org/abs/2502.00869)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Implicit Neural Representations (INRs) have emerged as a powerful framework for modeling continuous signals. The spectral bias of ReLU-based networks is a well-established limitation, restricting their ability to capture fine-grained details in target signals. While previous works have attempted to mitigate this issue through frequency-based encodings or architectural modifications, these approaches often introduce additional complexity and do not fully address the underlying challenge of learning high-frequency components efficiently. We introduce Sinusoidal Trainable Activation Functions (STAF), designed to directly tackle this limitation by enabling networks to adaptively learn and represent complex signals with higher precision and efficiency. STAF inherently modulates its frequency components, allowing for self-adaptive spectral learning. This capability significantly improves convergence speed and expressivity, making STAF highly effective for both signal representations and inverse problems. Through extensive evaluations, we demonstrate that STAF outperforms state-of-the-art (SOTA) methods in accuracy and reconstruction fidelity with superior Peak Signal-to-Noise Ratio (PSNR). These results establish STAF as a robust solution for overcoming spectral bias and the capacity-convergence gap, making it valuable for computer graphics and related fields. Our codebase is publicly accessible on the this https URL.</li>
</ul>

<h3>Title: FedHPD: Heterogeneous Federated Reinforcement Learning via Policy Distillation</h3>
<ul>
<li><strong>Authors: </strong>Wenzheng Jiang, Ji Wang, Xiongtao Zhang, Weidong Bao, Cheston Tan, Flint Xiaofeng Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00870">https://arxiv.org/abs/2502.00870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00870">https://arxiv.org/pdf/2502.00870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00870]] FedHPD: Heterogeneous Federated Reinforcement Learning via Policy Distillation(https://arxiv.org/abs/2502.00870)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Reinforcement Learning (FedRL) improves sample efficiency while preserving privacy; however, most existing studies assume homogeneous agents, limiting its applicability in real-world scenarios. This paper investigates FedRL in black-box settings with heterogeneous agents, where each agent employs distinct policy networks and training configurations without disclosing their internal details. Knowledge Distillation (KD) is a promising method for facilitating knowledge sharing among heterogeneous models, but it faces challenges related to the scarcity of public datasets and limitations in knowledge representation when applied to FedRL. To address these challenges, we propose Federated Heterogeneous Policy Distillation (FedHPD), which solves the problem of heterogeneous FedRL by utilizing action probability distributions as a medium for knowledge sharing. We provide a theoretical analysis of FedHPD's convergence under standard assumptions. Extensive experiments corroborate that FedHPD shows significant improvements across various reinforcement learning benchmark tasks, further validating our theoretical findings. Moreover, additional experiments demonstrate that FedHPD operates effectively without the need for an elaborate selection of public datasets.</li>
</ul>

<h3>Title: Towards Automation of Cognitive Modeling using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Milena Rmus, Akshay K. Jagadish, Marvin Mathony, Tobias Ludwig, Eric Schulz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00879">https://arxiv.org/abs/2502.00879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00879">https://arxiv.org/pdf/2502.00879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00879]] Towards Automation of Cognitive Modeling using Large Language Models(https://arxiv.org/abs/2502.00879)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Computational cognitive models, which formalize theories of cognition, enable researchers to quantify cognitive processes and arbitrate between competing theories by fitting models to behavioral data. Traditionally, these models are handcrafted, which requires significant domain knowledge, coding expertise, and time investment. Previous work has demonstrated that Large Language Models (LLMs) are adept at pattern recognition in-context, solving complex problems, and generating executable code. In this work, we leverage these abilities to explore the potential of LLMs in automating the generation of cognitive models based on behavioral data. We evaluated the LLM in two different tasks: model identification (relating data to a source model), and model generation (generating the underlying cognitive model). We performed these tasks across two cognitive domains - decision making and learning. In the case of data simulated from canonical cognitive models, we found that the LLM successfully identified and generated the ground truth model. In the case of human data, where behavioral noise and lack of knowledge of the true underlying process pose significant challenges, the LLM generated models that are identical or close to the winning model from cognitive science literature. Our findings suggest that LLMs can have a transformative impact on cognitive modeling. With this project, we aim to contribute to an ongoing effort of automating scientific discovery in cognitive science.</li>
</ul>

<h3>Title: SimPER: A Minimalist Approach to Preference Alignment without Hyperparameters</h3>
<ul>
<li><strong>Authors: </strong>Teng Xiao, Yige Yuan, Zhengyu Chen, Mingxiao Li, Shangsong Liang, Zhaochun Ren, Vasant G Honavar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00883">https://arxiv.org/abs/2502.00883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00883">https://arxiv.org/pdf/2502.00883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00883]] SimPER: A Minimalist Approach to Preference Alignment without Hyperparameters(https://arxiv.org/abs/2502.00883)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing preference optimization objectives for language model alignment require additional hyperparameters that must be extensively tuned to achieve optimal performance, increasing both the complexity and time required for fine-tuning large language models. In this paper, we propose a simple yet effective hyperparameter-free preference optimization algorithm for this http URL observe that promising performance can be achieved simply by optimizing inverse perplexity, which is calculated as the inverse of the exponentiated average log-likelihood of the chosen and rejected responses in the preference dataset. The resulting simple learning objective, SimPER, is easy to implement and eliminates the need for expensive hyperparameter tuning and a reference model, making it both computationally and memory efficient. Extensive experiments on widely used real-world benchmarks, including MT-Bench, AlpacaEval 2, and 10 key benchmarks of the Open LLM Leaderboard with 5 base models, demonstrate that SimPER consistently and significantly outperforms existing approaches-even without any hyperparameters or a reference model . For example, despite its simplicity, SimPER outperforms state-of-the-art methods by up to 5.7 points on AlpacaEval 2 and achieves the highest average ranking across 10 benchmarks on the Open LLM Leaderboard. The source code for SimPER is publicly available at: this https URL.</li>
</ul>

<h3>Title: MorphBPE: A Morpho-Aware Tokenizer Bridging Linguistic Complexity for Efficient LLM Training Across Morphologies</h3>
<ul>
<li><strong>Authors: </strong>Ehsaneddin Asgari, Yassine El Kheir, Mohammad Ali Sadraei Javaheri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00894">https://arxiv.org/abs/2502.00894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00894">https://arxiv.org/pdf/2502.00894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00894]] MorphBPE: A Morpho-Aware Tokenizer Bridging Linguistic Complexity for Efficient LLM Training Across Morphologies(https://arxiv.org/abs/2502.00894)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Tokenization is fundamental to Natural Language Processing (NLP), directly impacting model efficiency and linguistic fidelity. While Byte Pair Encoding (BPE) is widely used in Large Language Models (LLMs), it often disregards morpheme boundaries, leading to suboptimal segmentation, particularly in morphologically rich languages. We introduce MorphBPE, a morphology-aware extension of BPE that integrates linguistic structure into subword tokenization while preserving statistical efficiency. Additionally, we propose two morphology-based evaluation metrics: (i) Morphological Consistency F1-Score, which quantifies the consistency between morpheme sharing and token sharing, contributing to LLM training convergence, and (ii) Morphological Edit Distance, which measures alignment between morphemes and tokens concerning interpretability. Experiments on English, Russian, Hungarian, and Arabic across 300M and 1B parameter LLMs demonstrate that MorphBPE consistently reduces cross-entropy loss, accelerates convergence, and improves morphological alignment scores. Fully compatible with existing LLM pipelines, MorphBPE requires minimal modifications for integration. The MorphBPE codebase and tokenizer playground will be available at: this https URL and this https URL</li>
</ul>

<h3>Title: Multi-frequency wavefield solutions for variable velocity models using meta-learning enhanced low-rank physics-informed neural network</h3>
<ul>
<li><strong>Authors: </strong>Shijun Cheng, Tariq Alkhalifah</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00897">https://arxiv.org/abs/2502.00897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00897">https://arxiv.org/pdf/2502.00897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00897]] Multi-frequency wavefield solutions for variable velocity models using meta-learning enhanced low-rank physics-informed neural network(https://arxiv.org/abs/2502.00897)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-informed neural networks (PINNs) face significant challenges in modeling multi-frequency wavefields in complex velocity models due to their slow convergence, difficulty in representing high-frequency details, and lack of generalization to varying frequencies and velocity scenarios. To address these issues, we propose Meta-LRPINN, a novel framework that combines low-rank parameterization using singular value decomposition (SVD) with meta-learning and frequency embedding. Specifically, we decompose the weights of PINN's hidden layers using SVD and introduce an innovative frequency embedding hypernetwork (FEH) that links input frequencies with the singular values, enabling efficient and frequency-adaptive wavefield representation. Meta-learning is employed to provide robust initialization, improving optimization stability and reducing training time. Additionally, we implement adaptive rank reduction and FEH pruning during the meta-testing phase to further enhance efficiency. Numerical experiments, which are presented on multi-frequency scattered wavefields for different velocity models, demonstrate that Meta-LRPINN achieves much fast convergence speed and much high accuracy compared to baseline methods such as Meta-PINN and vanilla PINN. Also, the proposed framework shows strong generalization to out-of-distribution frequencies while maintaining computational efficiency. These results highlight the potential of our Meta-LRPINN for scalable and adaptable seismic wavefield modeling.</li>
</ul>

<h3>Title: The Accuracy, Robustness, and Readability of LLM-Generated Sustainability-Related Word Definitions</h3>
<ul>
<li><strong>Authors: </strong>Alice Heiman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00916">https://arxiv.org/abs/2502.00916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00916">https://arxiv.org/pdf/2502.00916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00916]] The Accuracy, Robustness, and Readability of LLM-Generated Sustainability-Related Word Definitions(https://arxiv.org/abs/2502.00916)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A common language with standardized definitions is crucial for effective climate discussions. However, concerns exist about LLMs misrepresenting climate terms. We compared 300 official IPCC glossary definitions with those generated by GPT-4o-mini, Llama3.1 8B, and Mistral 7B, analyzing adherence, robustness, and readability using SBERT sentence embeddings. The LLMs scored an average adherence of $0.57-0.59 \pm 0.15$, and their definitions proved harder to read than the originals. Model-generated definitions vary mainly among words with multiple or ambiguous definitions, showing the potential to highlight terms that need standardization. The results show how LLMs could support environmental discourse while emphasizing the need to align model outputs with established terminology for clarity and consistency.</li>
</ul>

<h3>Title: Attention Sinks and Outlier Features: A 'Catch, Tag, and Release' Mechanism for Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Stephen Zhang, Mustafa Khan, Vardan Papyan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00919">https://arxiv.org/abs/2502.00919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00919">https://arxiv.org/pdf/2502.00919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00919]] Attention Sinks and Outlier Features: A 'Catch, Tag, and Release' Mechanism for Embeddings(https://arxiv.org/abs/2502.00919)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Two prominent features of large language models (LLMs) is the presence of large-norm (outlier) features and the tendency for tokens to attend very strongly to a select few tokens. Despite often having no semantic relevance, these select tokens, called attention sinks, along with the large outlier features, have proven important for model performance, compression, and streaming. Consequently, investigating the roles of these phenomena within models and exploring how they might manifest in the model parameters has become an area of active interest. Through an empirical investigation, we demonstrate that attention sinks utilize outlier features to: catch a sequence of tokens, tag the captured tokens by applying a common perturbation, and then release the tokens back into the residual stream, where the tagged tokens are eventually retrieved. We prove that simple tasks, like averaging, necessitate the 'catch, tag, release' mechanism hence explaining why it would arise organically in modern LLMs. Our experiments also show that the creation of attention sinks can be completely captured in the model parameters using low-rank matrices, which has important implications for model compression and substantiates the success of recent approaches that incorporate a low-rank term to offset performance degradation.</li>
</ul>

<h3>Title: Blink of an eye: a simple theory for feature localization in generative models</h3>
<ul>
<li><strong>Authors: </strong>Marvin Li, Aayush Karan, Sitan Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00921">https://arxiv.org/abs/2502.00921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00921">https://arxiv.org/pdf/2502.00921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00921]] Blink of an eye: a simple theory for feature localization in generative models(https://arxiv.org/abs/2502.00921)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can exhibit undesirable and unexpected behavior in the blink of an eye. In a recent Anthropic demo, Claude switched from coding to Googling pictures of Yellowstone, and these sudden shifts in behavior have also been observed in reasoning patterns and jailbreaks. This phenomenon is not unique to autoregressive models: in diffusion models, key features of the final output are decided in narrow ``critical windows'' of the generation process. In this work we develop a simple, unifying theory to explain this phenomenon. We show that it emerges generically as the generation process localizes to a sub-population of the distribution it models. While critical windows have been studied at length in diffusion models, existing theory heavily relies on strong distributional assumptions and the particulars of Gaussian diffusion. In contrast to existing work our theory (1) applies to autoregressive and diffusion models; (2) makes no distributional assumptions; (3) quantitatively improves previous bounds even when specialized to diffusions; and (4) requires basic tools and no stochastic calculus or statistical physics-based machinery. We also identify an intriguing connection to the all-or-nothing phenomenon from statistical inference. Finally, we validate our predictions empirically for LLMs and find that critical windows often coincide with failures in problem solving for various math and reasoning benchmarks.</li>
</ul>

<h3>Title: Huff-LLM: End-to-End Lossless Compression for Efficient LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Patrick Yubeaton, Tareq Mahmoud, Shehab Naga, Pooria Taheri, Tianhua Xia, Arun George, Yasmein Khalil, Sai Qian Zhang, Siddharth Joshi, Chinmay Hegde, Siddharth Garg</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00922">https://arxiv.org/abs/2502.00922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00922">https://arxiv.org/pdf/2502.00922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00922]] Huff-LLM: End-to-End Lossless Compression for Efficient LLM Inference(https://arxiv.org/abs/2502.00922)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As they become more capable, large language models (LLMs) have continued to rapidly increase in size. This has exacerbated the difficulty in running state of the art LLMs on small, edge devices. Standard techniques advocate solving this problem through lossy compression techniques such as quantization or pruning. However, such compression techniques are lossy, and have been shown to change model behavior in unpredictable manners. We propose Huff-LLM, an \emph{end-to-end, lossless} model compression method that lets users store LLM weights in compressed format \emph{everywhere} -- cloud, disk, main memory, and even in on-chip memory/buffers. This allows us to not only load larger models in main memory, but also reduces bandwidth required to load weights on chip, and makes more efficient use of on-chip weight buffers. In addition to the memory savings achieved via compression, we also show latency and energy efficiency improvements when performing inference with the compressed model.</li>
</ul>

<h3>Title: Fruit Fly Classification (Diptera: Tephritidae) in Images, Applying Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Erick Andrew Bustamante Flores, Harley Vera Olivera, Ivan Cesar Medrano Valencia, Carlos Fernando Montoya Cubas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00939">https://arxiv.org/abs/2502.00939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00939">https://arxiv.org/pdf/2502.00939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00939]] Fruit Fly Classification (Diptera: Tephritidae) in Images, Applying Transfer Learning(https://arxiv.org/abs/2502.00939)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This study develops a transfer learning model for the automated classification of two species of fruit flies, Anastrepha fraterculus and Ceratitis capitata, in a controlled laboratory environment. The research addresses the need to optimize identification and classification, which are currently performed manually by experts, being affected by human factors and facing time challenges. The methodological process of this study includes the capture of high-quality images using a mobile phone camera and a stereo microscope, followed by segmentation to reduce size and focus on relevant morphological areas. The images were carefully labeled and preprocessed to ensure the quality and consistency of the dataset used to train the pre-trained convolutional neural network models VGG16, VGG19, and Inception-v3. The results were evaluated using the F1-score, achieving 82% for VGG16 and VGG19, while Inception-v3 reached an F1-score of 93%. Inception-v3's reliability was verified through model testing in uncontrolled environments, with positive results, complemented by the Grad-CAM technique, demonstrating its ability to capture essential morphological features. These findings indicate that Inception-v3 is an effective and replicable approach for classifying Anastrepha fraterculus and Ceratitis capitata, with potential for implementation in automated monitoring systems.</li>
</ul>

<h3>Title: Universal Abstraction: Harnessing Frontier Models to Structure Real-World Data at Scale</h3>
<ul>
<li><strong>Authors: </strong>Cliff Wong, Sam Preston, Qianchu Liu, Zelalem Gero, Jass Bagga, Sheng Zhang, Shrey Jain, Theodore Zhao, Yu Gu, Yanbo Xu, Sid Kiblawi, Roshanthi Weerasinghe, Rom Leidner, Kristina Young, Brian Piening, Carlo Bifulco, Tristan Naumann, Mu Wei, Hoifung Poon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00943">https://arxiv.org/abs/2502.00943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00943">https://arxiv.org/pdf/2502.00943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00943]] Universal Abstraction: Harnessing Frontier Models to Structure Real-World Data at Scale(https://arxiv.org/abs/2502.00943)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The vast majority of real-world patient information resides in unstructured clinical text, and the process of medical abstraction seeks to extract and normalize structured information from this unstructured input. However, traditional medical abstraction methods can require significant manual efforts that can include crafting rules or annotating training labels, limiting scalability. In this paper, we propose UniMedAbstractor (UMA), a zero-shot medical abstraction framework leveraging Large Language Models (LLMs) through a modular and customizable prompt template. We refer to our approach as universal abstraction as it can quickly scale to new attributes through its universal prompt template without curating attribute-specific training labels or rules. We evaluate UMA for oncology applications, focusing on fifteen key attributes representing the cancer patient journey, from short-context attributes (e.g., performance status, treatment) to complex long-context attributes requiring longitudinal reasoning (e.g., tumor site, histology, TNM staging). Experiments on real-world data show UMA's strong performance and generalizability. Compared to supervised and heuristic baselines, UMA with GPT-4o achieves on average an absolute 2-point F1/accuracy improvement for both short-context and long-context attribute abstraction. For pathologic T staging, UMA even outperforms the supervised model by 20 points in accuracy.</li>
</ul>

<h3>Title: Efficient Multi-Agent System Training with Data Influence-Oriented Tree Search</h3>
<ul>
<li><strong>Authors: </strong>Wentao Shi, Zichun Yu, Fuli Feng, Xiangnan He, Chenyan Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00955">https://arxiv.org/abs/2502.00955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00955">https://arxiv.org/pdf/2502.00955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00955]] Efficient Multi-Agent System Training with Data Influence-Oriented Tree Search(https://arxiv.org/abs/2502.00955)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Monte Carlo Tree Search (MCTS) based methods provide promising approaches for generating synthetic data to enhance the self-training of Large Language Model (LLM) based multi-agent systems (MAS). These methods leverage Q-values to estimate individual agent contributions. However, relying solely on Q-values to identify informative data may misalign with the data synthesis objective, as the focus should be on selecting data that best enhances model training. To address this discrepancy, we propose Data Influence-oriented Tree Search (DITS), a novel framework that incorporates influence scores to guide both tree search and data selection. By leveraging influence scores, we effectively identify the most impactful data for system improvement, thereby enhancing model performance. Furthermore, we derive influence score estimation methods tailored for non-differentiable metrics, significantly reducing computational overhead by utilizing inference computations. Extensive experiments on eight multi-agent datasets demonstrate the robustness and effectiveness of the proposed methods. Notably, our findings reveal that allocating more inference resources to estimate influence scores, rather than Q-values, during data synthesis can more effectively and efficiently enhance model training.</li>
</ul>

<h3>Title: SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Yang, Jitong Lu, Hun-Seok Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00960">https://arxiv.org/abs/2502.00960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00960">https://arxiv.org/pdf/2502.00960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00960]] SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation(https://arxiv.org/abs/2502.00960)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Multi-modal 3D semantic segmentation is vital for applications such as autonomous driving and virtual reality (VR). To effectively deploy these models in real-world scenarios, it is essential to employ cross-domain adaptation techniques that bridge the gap between training data and real-world data. Recently, self-training with pseudo-labels has emerged as a predominant method for cross-domain adaptation in multi-modal 3D semantic segmentation. However, generating reliable pseudo-labels necessitates stringent constraints, which often result in sparse pseudo-labels after pruning. This sparsity can potentially hinder performance improvement during the adaptation process. We propose an image-guided pseudo-label enhancement approach that leverages the complementary 2D prior knowledge from the Segment Anything Model (SAM) to introduce more reliable pseudo-labels, thereby boosting domain adaptation performance. Specifically, given a 3D point cloud and the SAM masks from its paired image data, we collect all 3D points covered by each SAM mask that potentially belong to the same object. Then our method refines the pseudo-labels within each SAM mask in two steps. First, we determine the class label for each mask using majority voting and employ various constraints to filter out unreliable mask labels. Next, we introduce Geometry-Aware Progressive Propagation (GAPP) which propagates the mask label to all 3D points within the SAM mask while avoiding outliers caused by 2D-3D misalignment. Experiments conducted across multiple datasets and domain adaptation scenarios demonstrate that our proposed method significantly increases the quantity of high-quality pseudo-labels and enhances the adaptation performance over baseline methods.</li>
</ul>

<h3>Title: AI-Powered Spearphishing Cyber Attacks: Fact or Fiction?</h3>
<ul>
<li><strong>Authors: </strong>Matthew Kemp, Harsha Kalutarage, M. Omar Al-Kadri</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00961">https://arxiv.org/abs/2502.00961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00961">https://arxiv.org/pdf/2502.00961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00961]] AI-Powered Spearphishing Cyber Attacks: Fact or Fiction?(https://arxiv.org/abs/2502.00961)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Due to society's continuing technological advance, the capabilities of machine learning-based artificial intelligence systems continue to expand and influence a wider degree of topics. Alongside this expansion of technology, there is a growing number of individuals willing to misuse these systems to defraud and mislead others. Deepfake technology, a set of deep learning algorithms that are capable of replacing the likeness or voice of one individual with another with alarming accuracy, is one of these technologies. This paper investigates the threat posed by malicious use of this technology, particularly in the form of spearphishing attacks. It uses deepfake technology to create spearphishing-like attack scenarios and validate them against average individuals. Experimental results show that 66% of participants failed to identify AI created audio as fake while 43% failed to identify such videos as fake, confirming the growing fear of threats posed by the use of these technologies by cybercriminals.</li>
</ul>

<h3>Title: PDE-Controller: LLMs for Autoformalization and Reasoning of PDEs</h3>
<ul>
<li><strong>Authors: </strong>Mauricio Soroco, Jialin Song, Mengzhou Xia, Kye Emond, Weiran Sun, Wuyang Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00963">https://arxiv.org/abs/2502.00963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00963">https://arxiv.org/pdf/2502.00963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00963]] PDE-Controller: LLMs for Autoformalization and Reasoning of PDEs(https://arxiv.org/abs/2502.00963)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While recent AI-for-math has made strides in pure mathematics, areas of applied mathematics, particularly PDEs, remain underexplored despite their significant real-world applications. We present PDE-Controller, a framework that enables large language models (LLMs) to control systems governed by partial differential equations (PDEs). Our approach enables LLMs to transform informal natural language instructions into formal specifications, and then execute reasoning and planning steps to improve the utility of PDE control. We build a holistic solution comprising datasets (both human-written cases and 2 million synthetic samples), math-reasoning models, and novel evaluation metrics, all of which require significant effort. Our PDE-Controller significantly outperforms prompting the latest open-source and GPT models in reasoning, autoformalization, and program synthesis, achieving up to a 62% improvement in utility gain for PDE control. By bridging the gap between language generation and PDE systems, we demonstrate the potential of LLMs in addressing complex scientific and engineering challenges. We will release all data, model checkpoints, and code at this https URL.</li>
</ul>

<h3>Title: CoDe: Blockwise Control for Denoising Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Anuj Singh, Sayak Mukherjee, Ahmad Beirami, Hadi Jamali-Rad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00968">https://arxiv.org/abs/2502.00968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00968">https://arxiv.org/pdf/2502.00968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00968]] CoDe: Blockwise Control for Denoising Diffusion Models(https://arxiv.org/abs/2502.00968)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Aligning diffusion models to downstream tasks often requires finetuning new models or gradient-based guidance at inference time to enable sampling from the reward-tilted posterior. In this work, we explore a simple inference-time gradient-free guidance approach, called controlled denoising (CoDe), that circumvents the need for differentiable guidance functions and model finetuning. CoDe is a blockwise sampling method applied during intermediate denoising steps, allowing for alignment with downstream rewards. Our experiments demonstrate that, despite its simplicity, CoDe offers a favorable trade-off between reward alignment, prompt instruction following, and inference cost, achieving a competitive performance against the state-of-the-art baselines. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching</h3>
<ul>
<li><strong>Authors: </strong>Xiangci Li, Zhiyu Chen, Jason Ingyu Choi, Nikhita Vedula, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00969">https://arxiv.org/abs/2502.00969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00969">https://arxiv.org/pdf/2502.00969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00969]] Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching(https://arxiv.org/abs/2502.00969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The goal of conversational product search (CPS) is to develop an intelligent, chat-based shopping assistant that can directly interact with customers to understand shopping intents, ask clarification questions, and find relevant products. However, training such assistants is hindered mainly due to the lack of reliable and large-scale datasets. Prior human-annotated CPS datasets are extremely small in size and lack integration with real-world product search systems. We propose a novel approach, TRACER, which leverages large language models (LLMs) to generate realistic and natural conversations for different shopping domains. TRACER's novelty lies in grounding the generation to dialogue plans, which are product search trajectories predicted from a decision tree model, that guarantees relevant product discovery in the shortest number of search conditions. We also release the first target-oriented CPS dataset Wizard of Shopping (WoS), containing highly natural and coherent conversations (3.6k) from three shopping domains. Finally, we demonstrate the quality and effectiveness of WoS via human evaluations and downstream tasks.</li>
</ul>

<h3>Title: Pushing the Boundaries of State Space Models for Image and Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Yicong Hong, Long Mai, Yuan Yao, Feng Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00972">https://arxiv.org/abs/2502.00972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00972">https://arxiv.org/pdf/2502.00972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00972]] Pushing the Boundaries of State Space Models for Image and Video Generation(https://arxiv.org/abs/2502.00972)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>While Transformers have become the dominant architecture for visual generation, linear attention models, such as the state-space models (SSM), are increasingly recognized for their efficiency in processing long visual sequences. However, the essential efficiency of these models comes from formulating a limited recurrent state, enforcing causality among tokens that are prone to inconsistent modeling of N-dimensional visual data, leaving questions on their capacity to generate long non-causal sequences. In this paper, we explore the boundary of SSM on image and video generation by building the largest-scale diffusion SSM-Transformer hybrid model to date (5B parameters) based on the sub-quadratic bi-directional Hydra and self-attention, and generate up to 2K images and 360p 8 seconds (16 FPS) videos. Our results demonstrate that the model can produce faithful results aligned with complex text prompts and temporal consistent videos with high dynamics, suggesting the great potential of using SSMs for visual generation tasks.</li>
</ul>

<h3>Title: Detection of Distributed Denial of Service Attacks based on Machine Learning Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Md. Abdur Rahman</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00975">https://arxiv.org/abs/2502.00975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00975">https://arxiv.org/pdf/2502.00975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00975]] Detection of Distributed Denial of Service Attacks based on Machine Learning Algorithms(https://arxiv.org/abs/2502.00975)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Distributed Denial of Service (DDoS) attacks make the challenges to provide the services of the data resources to the web clients. In this paper, we concern to study and apply different Machine Learning (ML) techniques to separate the DDoS attack instances from benign instances. Our experimental results show that forward and backward data bytes of our dataset are observed more similar for DDoS attacks compared to the data bytes for benign attempts. This paper uses different machine learning techniques for the detection of the attacks efficiently in order to make sure the offered services from web servers available. This results from the proposed approach suggest that 97.1% of DDoS attacks are successfully detected by the Support Vector Machine (SVM). These accuracies are better while comparing to the several existing machine learning approaches.</li>
</ul>

<h3>Title: Context-Aware Hierarchical Merging for Long Document Summarization</h3>
<ul>
<li><strong>Authors: </strong>Litu Ou, Mirella Lapata</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00977">https://arxiv.org/abs/2502.00977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00977">https://arxiv.org/pdf/2502.00977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00977]] Context-Aware Hierarchical Merging for Long Document Summarization(https://arxiv.org/abs/2502.00977)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hierarchical Merging is a technique commonly used to summarize very long texts ($>$100K tokens) by breaking down the input into smaller sections, summarizing those sections individually, and then merging or combining those summaries into a final coherent summary. Although it helps address the limitations of large language models (LLMs) with fixed input length constraints, the recursive merging process can amplify LLM hallucinations, increasing the risk of factual inaccuracies. In this paper, we seek to mitigate hallucinations by enriching hierarchical merging with context from the source document. Specifically, we propose different approaches to contextual augmentation ranging from \emph{replacing} intermediate summaries with relevant input context, to \emph{refining} them while using the context as supporting evidence, and \emph{aligning} them implicitly (via citations) to the input. Experimental results on datasets representing legal and narrative domains show that contextual augmentation consistently outperforms zero-shot and hierarchical merging baselines for the Llama 3.1 model family. Our analysis further reveals that refinement methods tend to perform best when paired with extractive summarization for identifying relevant input.</li>
</ul>

<h3>Title: RandLoRA: Full-rank parameter-efficient fine-tuning of large models</h3>
<ul>
<li><strong>Authors: </strong>Paul Albert, Frederic Z. Zhang, Hemanth Saratchandran, Cristian Rodriguez-Opazo, Anton van den Hengel, Ehsan Abbasnejad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00987">https://arxiv.org/abs/2502.00987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00987">https://arxiv.org/pdf/2502.00987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00987]] RandLoRA: Full-rank parameter-efficient fine-tuning of large models(https://arxiv.org/abs/2502.00987)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) and its variants have shown impressive results in reducing the number of trainable parameters and memory requirements of large transformer networks while maintaining fine-tuning performance. However, the low-rank nature of the weight update inherently limits the representation power of fine-tuned models, potentially compromising performance on complex tasks. This raises a critical question: when a performance gap between LoRA and standard fine-tuning is observed, is it due to the reduced number of trainable parameters or the rank deficiency? This paper aims to answer this question by introducing RandLoRA, a parameter-efficient method that performs full-rank updates using a learned linear combinations of low-rank, non-trainable random matrices. Our method limits the number of trainable parameters by restricting optimization to diagonal scaling matrices applied to the fixed random matrices. This allows us to effectively overcome the low-rank limitations while maintaining parameter and memory efficiency during training. Through extensive experimentation across vision, language, and vision-language benchmarks, we systematically evaluate the limitations of LoRA and existing random basis methods. Our findings reveal that full-rank updates are beneficial across vision and language tasks individually, and even more so for vision-language tasks, where RandLoRA significantly reduces -- and sometimes eliminates -- the performance gap between standard fine-tuning and LoRA, demonstrating its efficacy.</li>
</ul>

<h3>Title: PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback</h3>
<ul>
<li><strong>Authors: </strong>Kanika Goswami, Puneet Mathur, Ryan Rossi, Franck Dernoncourt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00988">https://arxiv.org/abs/2502.00988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00988">https://arxiv.org/pdf/2502.00988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00988]] PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback(https://arxiv.org/abs/2502.00988)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scientific data visualization is pivotal for transforming raw data into comprehensible visual representations, enabling pattern recognition, forecasting, and the presentation of data-driven insights. However, novice users often face difficulties due to the complexity of selecting appropriate tools and mastering visualization techniques. Large Language Models (LLMs) have recently demonstrated potential in assisting code generation, though they struggle with accuracy and require iterative debugging. In this paper, we propose PlotGen, a novel multi-agent framework aimed at automating the creation of precise scientific visualizations. PlotGen orchestrates multiple LLM-based agents, including a Query Planning Agent that breaks down complex user requests into executable steps, a Code Generation Agent that converts pseudocode into executable Python code, and three retrieval feedback agents - a Numeric Feedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that leverage multimodal LLMs to iteratively refine the data accuracy, textual labels, and visual correctness of generated plots via self-reflection. Extensive experiments show that PlotGen outperforms strong baselines, achieving a 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user trust in LLM-generated visualizations and improved novice productivity due to a reduction in debugging time needed for plot errors.</li>
</ul>

<h3>Title: ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution</h3>
<ul>
<li><strong>Authors: </strong>Kanika Goswami, Puneet Mathur, Ryan Rossi, Franck Dernoncourt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00989">https://arxiv.org/abs/2502.00989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00989">https://arxiv.org/pdf/2502.00989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00989]] ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution(https://arxiv.org/abs/2502.00989)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can perform chart question-answering tasks but often generate unverified hallucinated responses. Existing answer attribution methods struggle to ground responses in source charts due to limited visual-semantic context, complex visual-text alignment requirements, and difficulties in bounding box prediction across complex layouts. We present ChartCitor, a multi-agent framework that provides fine-grained bounding box citations by identifying supporting evidence within chart images. The system orchestrates LLM agents to perform chart-to-table extraction, answer reformulation, table augmentation, evidence retrieval through pre-filtering and re-ranking, and table-to-chart mapping. ChartCitor outperforms existing baselines across different chart types. Qualitative user studies show that ChartCitor helps increase user trust in Generative AI by providing enhanced explainability for LLM-assisted chart QA and enables professionals to be more productive.</li>
</ul>

<h3>Title: FCBoost-Net: A Generative Network for Synthesizing Multiple Collocated Outfits via Fashion Compatibility Boosting</h3>
<ul>
<li><strong>Authors: </strong>Dongliang Zhou, Haijun Zhang, Jianghong Ma, Jicong Fan, Zhao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00992">https://arxiv.org/abs/2502.00992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00992">https://arxiv.org/pdf/2502.00992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00992]] FCBoost-Net: A Generative Network for Synthesizing Multiple Collocated Outfits via Fashion Compatibility Boosting(https://arxiv.org/abs/2502.00992)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Outfit generation is a challenging task in the field of fashion technology, in which the aim is to create a collocated set of fashion items that complement a given set of items. Previous studies in this area have been limited to generating a unique set of fashion items based on a given set of items, without providing additional options to users. This lack of a diverse range of choices necessitates the development of a more versatile framework. However, when the task of generating collocated and diversified outfits is approached with multimodal image-to-image translation methods, it poses a challenging problem in terms of non-aligned image translation, which is hard to address with existing methods. In this research, we present FCBoost-Net, a new framework for outfit generation that leverages the power of pre-trained generative models to produce multiple collocated and diversified outfits. Initially, FCBoost-Net randomly synthesizes multiple sets of fashion items, and the compatibility of the synthesized sets is then improved in several rounds using a novel fashion compatibility booster. This approach was inspired by boosting algorithms and allows the performance to be gradually improved in multiple steps. Empirical evidence indicates that the proposed strategy can improve the fashion compatibility of randomly synthesized fashion items as well as maintain their diversity. Extensive experiments confirm the effectiveness of our proposed framework with respect to visual authenticity, diversity, and fashion compatibility.</li>
</ul>

<h3>Title: Self-supervised Analogical Learning using Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ben Zhou, Sarthak Jain, Yi Zhang, Qiang Ning, Shuai Wang, Yassine Benajiba, Dan Roth</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00996">https://arxiv.org/abs/2502.00996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00996">https://arxiv.org/pdf/2502.00996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00996]] Self-supervised Analogical Learning using Language Models(https://arxiv.org/abs/2502.00996)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have been shown to suffer from reasoning inconsistency issues. That is, they fail more in situations unfamiliar to the training data, even though exact or very similar reasoning paths exist in more common cases that they can successfully solve. Such observations motivate us to propose methods that encourage models to understand the high-level and abstract reasoning processes during training instead of only the final answer. This way, models can transfer the exact solution to similar cases, regardless of their relevance to the pre-training data distribution. In this work, we propose SAL, a self-supervised analogical learning framework. SAL mimics the human analogy process and trains models to explicitly transfer high-quality symbolic solutions from cases that they know how to solve to other rare cases in which they tend to fail more. We show that the resulting models after SAL learning outperform base language models on a wide range of reasoning benchmarks, such as StrategyQA, GSM8K, and HotpotQA, by 2% to 20%. At the same time, we show that our model is more generalizable and controllable through analytical studies.</li>
</ul>

<h3>Title: MergeME: Model Merging Techniques for Homogeneous and Heterogeneous MoEs</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Zhou, Giannis Karamanolakis, Victor Soto, Anna Rumshisky, Mayank Kulkarni, Furong Huang, Wei Ai, Jianhua Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.00997">https://arxiv.org/abs/2502.00997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.00997">https://arxiv.org/pdf/2502.00997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.00997]] MergeME: Model Merging Techniques for Homogeneous and Heterogeneous MoEs(https://arxiv.org/abs/2502.00997)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The recent success of specialized Large Language Models (LLMs) in domains such as mathematical reasoning and coding has led to growing interest in methods for merging these expert LLMs into a unified Mixture-of-Experts (MoE) model, with the goal of enhancing performance in each domain while retaining effectiveness on general tasks. However, the effective merging of expert models remains an open challenge, especially for models with highly divergent weight parameters or different architectures. State-of-the-art MoE merging methods only work with homogeneous model architectures and rely on simple unweighted averaging to merge expert layers, which does not address parameter interference and requires extensive fine-tuning of the merged MoE to restore performance. To address these limitations, this paper introduces new MoE merging techniques, including strategies to mitigate parameter interference, routing heuristics to reduce the need for MoE fine-tuning, and a novel method for merging experts with different architectures. Extensive experiments across multiple domains demonstrate the effectiveness of our proposed methods, reducing fine-tuning costs, improving performance over state-of-the-art methods, and expanding the applicability of MoE merging.</li>
</ul>

<h3>Title: Adapting Foundation Models for Few-Shot Medical Image Segmentation: Actively and Sequentially</h3>
<ul>
<li><strong>Authors: </strong>Jingyun Yang, Guoqing Zhang, Jingge Wang, Yang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01000">https://arxiv.org/abs/2502.01000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01000">https://arxiv.org/pdf/2502.01000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01000]] Adapting Foundation Models for Few-Shot Medical Image Segmentation: Actively and Sequentially(https://arxiv.org/abs/2502.01000)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in foundation models have brought promising results in computer vision, including medical image segmentation. Fine-tuning foundation models on specific low-resource medical tasks has become a standard practice. However, ensuring reliable and robust model adaptation when the target task has a large domain gap and few annotated samples remains a challenge. Previous few-shot domain adaptation (FSDA) methods seek to bridge the distribution gap between source and target domains by utilizing auxiliary data. The selection and scheduling of auxiliaries are often based on heuristics, which can easily cause negative transfer. In this work, we propose an Active and Sequential domain AdaPtation (ASAP) framework for dynamic auxiliary dataset selection in FSDA. We formulate FSDA as a multi-armed bandit problem and derive an efficient reward function to prioritize training on auxiliary datasets that align closely with the target task, through a single-round fine-tuning. Empirical validation on diverse medical segmentation datasets demonstrates that our method achieves favorable segmentation performance, significantly outperforming the state-of-the-art FSDA methods, achieving an average gain of 27.75% on MRI and 7.52% on CT datasets in Dice score. Code is available at the git repository: this https URL.</li>
</ul>

<h3>Title: Multi-Resolution SAR and Optical Remote Sensing Image Registration Methods: A Review, Datasets, and Future Perspectives</h3>
<ul>
<li><strong>Authors: </strong>Wenfei Zhang, Ruipeng Zhao, Yongxiang Yao, Yi Wan, Peihao Wu, Jiayuan Li, Yansheng Li, Yongjun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01002">https://arxiv.org/abs/2502.01002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01002">https://arxiv.org/pdf/2502.01002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01002]] Multi-Resolution SAR and Optical Remote Sensing Image Registration Methods: A Review, Datasets, and Future Perspectives(https://arxiv.org/abs/2502.01002)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Synthetic Aperture Radar (SAR) and optical image registration is essential for remote sensing data fusion, with applications in military reconnaissance, environmental monitoring, and disaster management. However, challenges arise from differences in imaging mechanisms, geometric distortions, and radiometric properties between SAR and optical images. As image resolution increases, fine SAR textures become more significant, leading to alignment issues and 3D spatial discrepancies. Two major gaps exist: the lack of a publicly available multi-resolution, multi-scene registration dataset and the absence of systematic analysis of current methods. To address this, the MultiResSAR dataset was created, containing over 10k pairs of multi-source, multi-resolution, and multi-scene SAR and optical images. Sixteen state-of-the-art algorithms were tested. Results show no algorithm achieves 100% success, and performance decreases as resolution increases, with most failing on sub-meter data. XoFTR performs best among deep learning methods (40.58%), while RIFT performs best among traditional methods (66.51%). Future research should focus on noise suppression, 3D geometric fusion, cross-view transformation modeling, and deep learning optimization for robust registration of high-resolution SAR and optical images. The dataset is available at this https URL.</li>
</ul>

<h3>Title: Encrypted Large Model Inference: The Equivariant Encryption Paradigm</h3>
<ul>
<li><strong>Authors: </strong>James Buban, Hongyang Zhang, Claudio Angione, Harry Yang, Ahmad Farhan, Seyfal Sultanov, Michael Du, Xuran Ma, Zihao Wang, Yue Zhao, Arria Owlia, Fielding Johnston, Patrick Colangelo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01013">https://arxiv.org/abs/2502.01013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01013">https://arxiv.org/pdf/2502.01013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01013]] Encrypted Large Model Inference: The Equivariant Encryption Paradigm(https://arxiv.org/abs/2502.01013)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Large scale deep learning model, such as modern language models and diffusion architectures, have revolutionized applications ranging from natural language processing to computer vision. However, their deployment in distributed or decentralized environments raises significant privacy concerns, as sensitive data may be exposed during inference. Traditional techniques like secure multi-party computation, homomorphic encryption, and differential privacy offer partial remedies but often incur substantial computational overhead, latency penalties, or limited compatibility with non-linear network operations. In this work, we introduce Equivariant Encryption (EE), a novel paradigm designed to enable secure, "blind" inference on encrypted data with near zero performance overhead. Unlike fully homomorphic approaches that encrypt the entire computational graph, EE selectively obfuscates critical internal representations within neural network layers while preserving the exact functionality of both linear and a prescribed set of non-linear operations. This targeted encryption ensures that raw inputs, intermediate activations, and outputs remain confidential, even when processed on untrusted infrastructure. We detail the theoretical foundations of EE, compare its performance and integration complexity against conventional privacy preserving techniques, and demonstrate its applicability across a range of architectures, from convolutional networks to large language models. Furthermore, our work provides a comprehensive threat analysis, outlining potential attack vectors and baseline strategies, and benchmarks EE against standard inference pipelines in decentralized settings. The results confirm that EE maintains high fidelity and throughput, effectively bridging the gap between robust data confidentiality and the stringent efficiency requirements of modern, large scale model inference.</li>
</ul>

<h3>Title: Refining Adaptive Zeroth-Order Optimization at Ease</h3>
<ul>
<li><strong>Authors: </strong>Yao Shu, Qixin Zhang, Kun He, Zhongxiang Dai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01014">https://arxiv.org/abs/2502.01014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01014">https://arxiv.org/pdf/2502.01014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01014]] Refining Adaptive Zeroth-Order Optimization at Ease(https://arxiv.org/abs/2502.01014)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Recently, zeroth-order (ZO) optimization plays an essential role in scenarios where gradient information is inaccessible or unaffordable, such as black-box systems and resource-constrained environments. While existing adaptive methods such as ZO-AdaMM have shown promise, they are fundamentally limited by their underutilization of moment information during optimization, usually resulting in underperforming convergence. To overcome these limitations, this paper introduces Refined Adaptive Zeroth-Order Optimization (R-AdaZO). Specifically, we first show the untapped variance reduction effect of first moment estimate on ZO gradient estimation, which improves the accuracy and stability of ZO updates. We then refine the second moment estimate based on these variance-reduced gradient estimates to better capture the geometry of the optimization landscape, enabling a more effective scaling of ZO updates. We present rigorous theoretical analysis to show (I) the first analysis to the variance reduction of first moment estimate in ZO optimization, (II) the improved second moment estimates with a more accurate approximation of its variance-free ideal, (III) the first variance-aware convergence framework for adaptive ZO methods, which may be of independent interest, and (IV) the faster convergence of R-AdaZO than existing baselines like ZO-AdaMM. Our extensive experiments, including synthetic problems, black-box adversarial attack, and memory-efficient fine-tuning of large language models (LLMs), further verify the superior convergence of R-AdaZO, indicating that R-AdaZO offers an improved solution for real-world ZO optimization challenges.</li>
</ul>

<h3>Title: RiskHarvester: A Risk-based Tool to Prioritize Secret Removal Efforts in Software Artifacts</h3>
<ul>
<li><strong>Authors: </strong>Setu Kumar Basak, Tanmay Pardeshi, Bradley Reaves, Laurie Williams</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01020">https://arxiv.org/abs/2502.01020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01020">https://arxiv.org/pdf/2502.01020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01020]] RiskHarvester: A Risk-based Tool to Prioritize Secret Removal Efforts in Software Artifacts(https://arxiv.org/abs/2502.01020)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Since 2020, GitGuardian has been detecting checked-in hard-coded secrets in GitHub repositories. During 2020-2023, GitGuardian has observed an upward annual trend and a four-fold increase in hard-coded secrets, with 12.8 million exposed in 2023. However, removing all the secrets from software artifacts is not feasible due to time constraints and technical challenges. Additionally, the security risks of the secrets are not equal, protecting assets ranging from obsolete databases to sensitive medical data. Thus, secret removal should be prioritized by security risk reduction, which existing secret detection tools do not support. The goal of this research is to aid software practitioners in prioritizing secrets removal efforts through our security risk-based tool. We present RiskHarvester, a risk-based tool to compute a security risk score based on the value of the asset and ease of attack on a database. We calculated the value of asset by identifying the sensitive data categories present in a database from the database keywords in the source code. We utilized data flow analysis, SQL, and ORM parsing to identify the database keywords. To calculate the ease of attack, we utilized passive network analysis to retrieve the database host information. To evaluate RiskHarvester, we curated RiskBench, a benchmark of 1,791 database secret-asset pairs with sensitive data categories and host information manually retrieved from 188 GitHub repositories. RiskHarvester demonstrates precision of (95%) and recall (90%) in detecting database keywords for the value of asset and precision of (96%) and recall (94%) in detecting valid hosts for ease of attack. Finally, we conducted a survey (52 respondents) to understand whether developers prioritize secret removal based on security risk score. We found that 86% of the developers prioritized the secrets for removal with descending security risk scores.</li>
</ul>

<h3>Title: Vessel segmentation for X-separation</h3>
<ul>
<li><strong>Authors: </strong>Taechang Kim, Sooyeon Ji, Kyeongseon Min, Minjun Kim, Jonghyo Youn, Chungseok Oh, Jiye Kim, Jongho Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01023">https://arxiv.org/abs/2502.01023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01023">https://arxiv.org/pdf/2502.01023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01023]] Vessel segmentation for X-separation(https://arxiv.org/abs/2502.01023)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>$\chi$-separation is an advanced quantitative susceptibility mapping (QSM) method that is designed to generate paramagnetic ($\chi_{para}$) and diamagnetic ($|\chi_{dia}|$) susceptibility maps, reflecting the distribution of iron and myelin in the brain. However, vessels have shown artifacts, interfering with the accurate quantification of iron and myelin in applications. To address this challenge, a new vessel segmentation method for $\chi$-separation is developed. The method comprises three steps: 1) Seed generation from $\textit{R}_2^*$ and the product of $\chi_{para}$ and $|\chi_{dia}|$ maps; 2) Region growing, guided by vessel geometry, creating a vessel mask; 3) Refinement of the vessel mask by excluding non-vessel structures. The performance of the method was compared to conventional vessel segmentation methods both qualitatively and quantitatively. To demonstrate the utility of the method, it was tested in two applications: quantitative evaluation of a neural network-based $\chi$-separation reconstruction method ($\chi$-sepnet-$\textit{R}_2^*$) and population-averaged region of interest (ROI) analysis. The proposed method demonstrates superior performance to the conventional vessel segmentation methods, effectively excluding the non-vessel structures, achieving the highest Dice score coefficient. For the applications, applying vessel masks report notable improvements for the quantitative evaluation of $\chi$-sepnet-$\textit{R}_2^*$ and statistically significant differences in population-averaged ROI analysis. These applications suggest excluding vessels when analyzing the $\chi$-separation maps provide more accurate evaluations. The proposed method has the potential to facilitate various applications, offering reliable analysis through the generation of a high-quality vessel mask.</li>
</ul>

<h3>Title: Knowing When to Stop: Dynamic Context Cutoff for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Roy Xie, Junlin Wang, Paul Rosu, Chunyuan Deng, Bolun Sun, Zihao Lin, Bhuwan Dhingra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01025">https://arxiv.org/abs/2502.01025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01025">https://arxiv.org/pdf/2502.01025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01025]] Knowing When to Stop: Dynamic Context Cutoff for Large Language Models(https://arxiv.org/abs/2502.01025)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) process entire input contexts indiscriminately, which is inefficient in cases where the information required to answer a query is localized within the context. We present dynamic context cutoff, a human-inspired method enabling LLMs to self-terminate processing upon acquiring sufficient task-relevant information. Through analysis of model internals, we discover that specific attention heads inherently encode "sufficiency signals" - detectable through lightweight classifiers - that predict when critical information has been processed. This reveals a new efficiency paradigm: models' internal understanding naturally dictates processing needs rather than external compression heuristics. Comprehensive experiments across six QA datasets (up to 40K tokens) with three model families (LLaMA/Qwen/Mistral, 1B0-70B) demonstrate 1.33x average token reduction while improving accuracy by 1.3%. Furthermore, our method demonstrates better performance with the same rate of token reduction compared to other context efficiency methods. Additionally, we observe an emergent scaling phenomenon: while smaller models require require probing for sufficiency detection, larger models exhibit intrinsic self-assessment capabilities through prompting.</li>
</ul>

<h3>Title: Comprehensive Modeling Approaches for Forecasting Bitcoin Transaction Fees: A Comparative Study</h3>
<ul>
<li><strong>Authors: </strong>Jiangqin Ma, Erfan Mahmoudinia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01029">https://arxiv.org/abs/2502.01029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01029">https://arxiv.org/pdf/2502.01029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01029]] Comprehensive Modeling Approaches for Forecasting Bitcoin Transaction Fees: A Comparative Study(https://arxiv.org/abs/2502.01029)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transaction fee prediction in Bitcoin's ecosystem represents a crucial challenge affecting both user costs and miner revenue optimization. This study presents a systematic evaluation of six predictive models for forecasting Bitcoin transaction fees across a 24-hour horizon (144 blocks): SARIMAX, Prophet, Time2Vec, Time2Vec with Attention, a Hybrid model combining SARIMAX with Gradient Boosting, and the Temporal Fusion Transformer (TFT). Our approach integrates comprehensive feature engineering spanning mempool metrics, network parameters, and historical fee patterns to capture the multifaceted dynamics of fee behavior. Through rigorous 5-fold cross-validation and independent testing, our analysis reveals that traditional statistical approaches outperform more complex deep learning architectures. The SARIMAX model achieves superior accuracy on the independent test set, while Prophet demonstrates strong performance during cross-validation. Notably, sophisticated deep learning models like Time2Vec and TFT show comparatively lower predictive power despite their architectural complexity. This performance disparity likely stems from the relatively constrained training dataset of 91 days, suggesting that deep learning models may achieve enhanced results with extended historical data. These findings offer significant practical implications for cryptocurrency stakeholders, providing empirically-validated guidance for fee-sensitive decision making while illuminating critical considerations in model selection based on data constraints. The study establishes a foundation for advanced fee prediction while highlighting the current advantages of traditional statistical methods in this domain.</li>
</ul>

<h3>Title: Converting MLPs into Polynomials in Closed Form</h3>
<ul>
<li><strong>Authors: </strong>Nora Belrose, Alice Rigg</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01032">https://arxiv.org/abs/2502.01032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01032">https://arxiv.org/pdf/2502.01032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01032]] Converting MLPs into Polynomials in Closed Form(https://arxiv.org/abs/2502.01032)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Recent work has shown that purely quadratic functions can replace MLPs in transformers with no significant loss in performance, while enabling new methods of interpretability based on linear algebra. In this work, we theoretically derive closed-form least-squares optimal approximations of feedforward networks (multilayer perceptrons and gated linear units) using polynomial functions of arbitrary degree. When the $R^2$ is high, this allows us to interpret MLPs and GLUs by visualizing the eigendecomposition of the coefficients of their linear and quadratic approximants. We also show that these approximants can be used to create SVD-based adversarial examples. By tracing the $R^2$ of linear and quadratic approximants across training time, we find new evidence that networks start out simple, and get progressively more complex. Even at the end of training, however, our quadratic approximants explain over 95% of the variance in network outputs.</li>
</ul>

<h3>Title: PARA: Parameter-Efficient Fine-tuning with Prompt Aware Representation Adjustment</h3>
<ul>
<li><strong>Authors: </strong>Zequan Liu, Yi Zhao, Ming Tan, Wei Zhu, Aaron Xuxiang Tian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01033">https://arxiv.org/abs/2502.01033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01033">https://arxiv.org/pdf/2502.01033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01033]] PARA: Parameter-Efficient Fine-tuning with Prompt Aware Representation Adjustment(https://arxiv.org/abs/2502.01033)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In the realm of parameter-efficient fine-tuning (PEFT) methods, while options like LoRA are available, there is a persistent demand in the industry for a PEFT approach that excels in both efficiency and performance within the context of single-backbone multi-tenant applications. This paper introduces a new and straightforward PEFT technique, termed \underline{P}rompt \underline{A}ware \underline{R}epresentation \underline{A}djustment (PARA). The core of our proposal is to integrate a lightweight vector generator within each Transformer layer. This generator produces vectors that are responsive to input prompts, thereby adjusting the hidden representations accordingly. Our extensive experimentation across diverse tasks has yielded promising results. Firstly, the PARA method has been shown to surpass current PEFT benchmarks in terms of performance, despite having a similar number of adjustable parameters. Secondly, it has proven to be more efficient than LoRA in the single-backbone multi-tenant scenario, highlighting its significant potential for industrial adoption.</li>
</ul>

<h3>Title: Geoinformatics-Guided Machine Learning for Power Plant Classification</h3>
<ul>
<li><strong>Authors: </strong>Blessing Austin-Gabriel, Aparna S. Varde, Hao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01039">https://arxiv.org/abs/2502.01039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01039">https://arxiv.org/pdf/2502.01039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01039]] Geoinformatics-Guided Machine Learning for Power Plant Classification(https://arxiv.org/abs/2502.01039)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes an approach in the area of Knowledge-Guided Machine Learning (KGML) via a novel integrated framework comprising CNN (Convolutional Neural Networks) and ViT (Vision Transformers) along with GIS (Geographic Information Systems) to enhance power plant classification in the context of energy management. Knowledge from geoinformatics derived through Spatial Masks (SM) in GIS is infused into an architecture of CNN and ViT, in this proposed KGML approach. It is found to provide much better performance compared to the baseline of CNN and ViT only in the classification of multiple types of power plants from real satellite imagery, hence emphasizing the vital role of the geoinformatics-guided approach. This work makes a contribution to the main theme of KGML that can be beneficial in many AI systems today. It makes broader impacts on AI in Smart Cities, and Environmental Computing.</li>
</ul>

<h3>Title: Internal Activation as the Polar Star for Steering Unsafe LLM Behavior</h3>
<ul>
<li><strong>Authors: </strong>Peixuan Han, Cheng Qian, Xiusi Chen, Yuji Zhang, Denghui Zhang, Heng Ji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01042">https://arxiv.org/abs/2502.01042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01042">https://arxiv.org/pdf/2502.01042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01042]] Internal Activation as the Polar Star for Steering Unsafe LLM Behavior(https://arxiv.org/abs/2502.01042)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks but also pose significant risks due to their potential to generate harmful content. Although existing safety mechanisms can improve model safety, they often lead to overly cautious behavior and fail to fully utilize LLMs' internal cognitive processes. Drawing inspiration from cognitive science, where humans rely on reflective reasoning (System 2 thinking) to regulate language and behavior, we empirically demonstrate that LLMs also possess a similar capacity for internal assessment and regulation, which can be actively detected. Building on this insight, we introduce SafeSwitch, a framework that dynamically regulates unsafe outputs by monitoring and utilizing the model's internal states. Our empirical results show that SafeSwitch reduces harmful outputs by over 80% on safety benchmarks while maintaining strong utility. Compared to traditional safety alignment methods, SafeSwitch delivers more informative and context-aware refusals, demonstrates resilience to unseen queries, and achieves these benefits while only tuning less than 6% of the original parameters. These features make SafeSwitch a promising approach for implementing nuanced safety controls in LLMs.</li>
</ul>

<h3>Title: WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Zilong Wang, Zhiyang Dou, Yuan Liu, Cheng Lin, Xiao Dong, Yunhui Guo, Chenxu Zhang, Xin Li, Wenping Wang, Xiaohu Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01045">https://arxiv.org/abs/2502.01045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01045">https://arxiv.org/pdf/2502.01045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01045]] WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human Reconstruction(https://arxiv.org/abs/2502.01045)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we present WonderHuman to reconstruct dynamic human avatars from a monocular video for high-fidelity novel view synthesis. Previous dynamic human avatar reconstruction methods typically require the input video to have full coverage of the observed human body. However, in daily practice, one typically has access to limited viewpoints, such as monocular front-view videos, making it a cumbersome task for previous methods to reconstruct the unseen parts of the human avatar. To tackle the issue, we present WonderHuman, which leverages 2D generative diffusion model priors to achieve high-quality, photorealistic reconstructions of dynamic human avatars from monocular videos, including accurate rendering of unseen body parts. Our approach introduces a Dual-Space Optimization technique, applying Score Distillation Sampling (SDS) in both canonical and observation spaces to ensure visual consistency and enhance realism in dynamic human reconstruction. Additionally, we present a View Selection strategy and Pose Feature Injection to enforce the consistency between SDS predictions and observed data, ensuring pose-dependent effects and higher fidelity in the reconstructed avatar. In the experiments, our method achieves SOTA performance in producing photorealistic renderings from the given monocular video, particularly for those challenging unseen parts. The project page and source code can be found at this https URL.</li>
</ul>

<h3>Title: Sparks of Explainability: Recent Advancements in Explaining Large Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Thomas Fel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01048">https://arxiv.org/abs/2502.01048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01048">https://arxiv.org/pdf/2502.01048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01048]] Sparks of Explainability: Recent Advancements in Explaining Large Vision Models(https://arxiv.org/abs/2502.01048)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability</a></li>
<li><strong>Abstract: </strong>This thesis explores advanced approaches to improve explainability in computer vision by analyzing and modeling the features exploited by deep neural networks. Initially, it evaluates attribution methods, notably saliency maps, by introducing a metric based on algorithmic stability and an approach utilizing Sobol indices, which, through quasi-Monte Carlo sequences, allows a significant reduction in computation time. In addition, the EVA method offers a first formulation of attribution with formal guarantees via verified perturbation analysis. Experimental results indicate that in complex scenarios these methods do not provide sufficient understanding, particularly because they identify only "where" the model focuses without clarifying "what" it perceives. Two hypotheses are therefore examined: aligning models with human reasoning -- through the introduction of a training routine that integrates the imitation of human explanations and optimization within the space of 1-Lipschitz functions -- and adopting a conceptual explainability approach. The CRAFT method is proposed to automate the extraction of the concepts used by the model and to assess their importance, complemented by MACO, which enables their visualization. These works converge towards a unified framework, illustrated by an interactive demonstration applied to the 1000 ImageNet classes in a ResNet model.</li>
</ul>

<h3>Title: Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Tao Zhang, Cheng Da, Kun Ding, Kun Jin, Yan Li, Tingting Gao, Di Zhang, Shiming Xiang, Chunhong Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01051">https://arxiv.org/abs/2502.01051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01051">https://arxiv.org/pdf/2502.01051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01051]] Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization(https://arxiv.org/abs/2502.01051)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Preference optimization for diffusion models aims to align them with human preferences for images. Previous methods typically leverage Vision-Language Models (VLMs) as pixel-level reward models to approximate human preferences. However, when used for step-level preference optimization, these models face challenges in handling noisy images of different timesteps and require complex transformations into pixel space. In this work, we demonstrate that diffusion models are inherently well-suited for step-level reward modeling in the latent space, as they can naturally extract features from noisy latent images. Accordingly, we propose the Latent Reward Model (LRM), which repurposes components of diffusion models to predict preferences of latent images at various timesteps. Building on LRM, we introduce Latent Preference Optimization (LPO), a method designed for step-level preference optimization directly in the latent space. Experimental results indicate that LPO not only significantly enhances performance in aligning diffusion models with general, aesthetic, and text-image alignment preferences, but also achieves 2.5-28$\times$ training speedup compared to existing preference optimization methods. Our code will be available at this https URL.</li>
</ul>

<h3>Title: Knowledge Synthesis of Photosynthesis Research Using a Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Seungri Yoon, Woosang Jeon, Sanghyeok Choi, Taehyeong Kim, Tae In Ahn</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01059">https://arxiv.org/abs/2502.01059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01059">https://arxiv.org/pdf/2502.01059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01059]] Knowledge Synthesis of Photosynthesis Research Using a Large Language Model(https://arxiv.org/abs/2502.01059)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The development of biological data analysis tools and large language models (LLMs) has opened up new possibilities for utilizing AI in plant science research, with the potential to contribute significantly to knowledge integration and research gap identification. Nonetheless, current LLMs struggle to handle complex biological data and theoretical models in photosynthesis research and often fail to provide accurate scientific contexts. Therefore, this study proposed a photosynthesis research assistant (PRAG) based on OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt optimization. Vector databases and an automated feedback loop were used in the prompt optimization process to enhance the accuracy and relevance of the responses to photosynthesis-related queries. PRAG showed an average improvement of 8.7% across five metrics related to scientific writing, with a 25.4% increase in source transparency. Additionally, its scientific depth and domain coverage were comparable to those of photosynthesis research papers. A knowledge graph was used to structure PRAG's responses with papers within and outside the database, which allowed PRAG to match key entities with 63% and 39.5% of the database and test papers, respectively. PRAG can be applied for photosynthesis research and broader plant science domains, paving the way for more in-depth data analysis and predictive capabilities.</li>
</ul>

<h3>Title: OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models</h3>
<ul>
<li><strong>Authors: </strong>Gaojie Lin, Jianwen Jiang, Jiaqi Yang, Zerong Zheng, Chao Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01061">https://arxiv.org/abs/2502.01061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01061">https://arxiv.org/pdf/2502.01061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01061]] OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models(https://arxiv.org/abs/2502.01061)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>End-to-end human animation, such as audio-driven talking human generation, has undergone notable advancements in the recent few years. However, existing methods still struggle to scale up as large general video generation models, limiting their potential in real applications. In this paper, we propose OmniHuman, a Diffusion Transformer-based framework that scales up data by mixing motion-related conditions into the training phase. To this end, we introduce two training principles for these mixed conditions, along with the corresponding model architecture and inference strategy. These designs enable OmniHuman to fully leverage data-driven motion generation, ultimately achieving highly realistic human video generation. More importantly, OmniHuman supports various portrait contents (face close-up, portrait, half-body, full-body), supports both talking and singing, handles human-object interactions and challenging body poses, and accommodates different image styles. Compared to existing end-to-end audio-driven methods, OmniHuman not only produces more realistic videos, but also offers greater flexibility in inputs. It also supports multiple driving modalities (audio-driven, video-driven and combined driving signals). Video samples are provided on the ttfamily project page (this https URL)</li>
</ul>

<h3>Title: DH-TRNG: A Dynamic Hybrid TRNG with Ultra-High Throughput and Area-Energy Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Yuan Zhang, Kuncai Zhong, Jiliang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01066">https://arxiv.org/abs/2502.01066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01066">https://arxiv.org/pdf/2502.01066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01066]] DH-TRNG: A Dynamic Hybrid TRNG with Ultra-High Throughput and Area-Energy Efficiency(https://arxiv.org/abs/2502.01066)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As a vital security primitive, the true random number generator (TRNG) is a mandatory component to build roots of trust for any encryption system. However, existing TRNGs suffer from bottlenecks of low throughput and high area-energy consumption. In this work, we propose DH-TRNG, a dynamic hybrid TRNG circuitry architecture with ultra-high throughput and area-energy efficiency. Our DH-TRNG exhibits portability to distinct process FPGAs and passes both NIST and AIS-31 tests without any post-processing. The experiments show it incurs only 8 slices with the highest throughput of 670Mbps and 620Mbps on Xilinx Virtex-6 and Artix-7, respectively. Compared to the state-of-the-art TRNGs, our proposed design has the highest Throughput/SlicesPower with a 2.63 times increase.</li>
</ul>

<h3>Title: FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation</h3>
<ul>
<li><strong>Authors: </strong>Dongwon Jo, Jiwon Song, Yulhwa Kim, Jae-Joon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01068">https://arxiv.org/abs/2502.01068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01068">https://arxiv.org/pdf/2502.01068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01068]] FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation(https://arxiv.org/abs/2502.01068)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) excel at handling long-context sequences, they require substantial key-value (KV) caches to store contextual information, which can heavily burden computational efficiency and memory usage. Previous efforts to compress these KV caches primarily focused on reducing memory demands but were limited in enhancing latency. To address this issue, we introduce FastKV, a KV cache compression method designed to enhance latency for long-context sequences. To enhance processing speeds while maintaining accuracy, FastKV adopts a novel Token-Selective Propagation (TSP) approach that retains the full context information in the initial layers of LLMs and selectively propagates only a portion of this information in deeper layers even in the prefill stage. Additionally, FastKV incorporates grouped-query attention (GQA)-aware KV cache compression to exploit the advantages of GQA in both memory and computational efficiency. Our experimental results show that FastKV achieves 2.00$\times$ and 1.40$\times$ improvements in time-to-first-token (TTFT) and throughput, respectively, compared to HeadKV, the state-of-the-art KV cache compression method. Moreover, FastKV successfully maintains accuracy on long-context benchmarks at levels comparable to the baselines. Our code is available at this https URL.</li>
</ul>

<h3>Title: An Investigation of FP8 Across Accelerators for LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Jiwoo Kim, Joonhyung Lee, Gunho Park, Byeongwook Kim, Se Jung Kwon, Dongsoo Lee, Youngjoo Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01070">https://arxiv.org/abs/2502.01070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01070">https://arxiv.org/pdf/2502.01070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01070]] An Investigation of FP8 Across Accelerators for LLM Inference(https://arxiv.org/abs/2502.01070)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The introduction of 8-bit floating-point (FP8) computation units in modern AI accelerators has generated significant interest in FP8-based large language model (LLM) inference. Unlike 16-bit floating-point formats, FP8 in deep learning requires a shared scaling factor. Additionally, while E4M3 and E5M2 are well-defined at the individual value level, their scaling and accumulation methods remain unspecified and vary across hardware and software implementations. As a result, FP8 behaves more like a quantization format than a standard numeric representation. In this work, we provide the first comprehensive analysis of FP8 computation and acceleration on two AI accelerators: the NVIDIA H100 and Intel Gaudi 2. Our findings highlight that the Gaudi 2, by leveraging FP8, achieves higher throughput-to-power efficiency during LLM inference, offering valuable insights into the practical implications of FP8 adoption for datacenter-scale LLM serving.</li>
</ul>

<h3>Title: BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing</h3>
<ul>
<li><strong>Authors: </strong>Dongliang Zhou, Haijun Zhang, Jianghong Ma, Jianyang Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01080">https://arxiv.org/abs/2502.01080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01080">https://arxiv.org/pdf/2502.01080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01080]] BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing(https://arxiv.org/abs/2502.01080)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Collocated clothing synthesis using generative networks has become an emerging topic in the field of fashion intelligence, as it has significant potential economic value to increase revenue in the fashion industry. In previous studies, several works have attempted to synthesize visually-collocated clothing based on a given clothing item using generative adversarial networks (GANs) with promising results. These works, however, can only accomplish the synthesis of one collocated clothing item each time. Nevertheless, users may require different clothing items to meet their multiple choices due to their personal tastes and different dressing scenarios. To address this limitation, we introduce a novel batch clothing generation framework, named BC-GAN, which is able to synthesize multiple visually-collocated clothing images simultaneously. In particular, to further improve the fashion compatibility of synthetic results, BC-GAN proposes a new fashion compatibility discriminator in a contrastive learning perspective by fully exploiting the collocation relationship among all clothing items. Our model was examined in a large-scale dataset with compatible outfits constructed by ourselves. Extensive experiment results confirmed the effectiveness of our proposed BC-GAN in comparison to state-of-the-art methods in terms of diversity, visual authenticity, and fashion compatibility.</li>
</ul>

<h3>Title: The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles</h3>
<ul>
<li><strong>Authors: </strong>Vernon Y.H. Toh, Yew Ken Chia, Deepanway Ghosal, Soujanya Poria</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01081">https://arxiv.org/abs/2502.01081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01081">https://arxiv.org/pdf/2502.01081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01081]] The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles(https://arxiv.org/abs/2502.01081)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, o3 outperformed humans in novel problem-solving and skill acquisition on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI). However, this benchmark is limited to symbolic patterns, whereas humans often perceive and reason about multimodal scenarios involving both vision and language data. Thus, there is an urgent need to investigate advanced reasoning capabilities in multimodal tasks. To this end, we track the evolution of the GPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring fine-grained visual perception with abstract or algorithmic reasoning. The superior performance of o1 comes at nearly 750 times the computational cost of GPT-4o, raising concerns about its efficiency. Our results reveal a clear upward trend in reasoning capabilities across model iterations, with notable performance jumps across GPT-series models and subsequently to o1. Nonetheless, we observe that the o1 model still struggles with simple multimodal puzzles requiring abstract reasoning. Furthermore, its performance in algorithmic puzzles remains poor. We plan to continuously track new models in the series and update our results in this paper accordingly. All resources used in this evaluation are openly available this https URL.</li>
</ul>

<h3>Title: Tool Unlearning for Tool-Augmented LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jiali Cheng, Hadi Amiri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01083">https://arxiv.org/abs/2502.01083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01083">https://arxiv.org/pdf/2502.01083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01083]] Tool Unlearning for Tool-Augmented LLMs(https://arxiv.org/abs/2502.01083)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, membership infer, large language model</a></li>
<li><strong>Abstract: </strong>Tool-augmented large language models (LLMs) are often trained on datasets of query-response pairs, which embed the ability to use tools or APIs directly into the parametric knowledge of LLMs. Tool-augmented LLMs need the ability to forget learned tools due to security vulnerabilities, privacy regulations, or tool deprecations. However, ``tool unlearning'' has not been investigated in unlearning literature. We introduce this novel task, which requires addressing distinct challenges compared to traditional unlearning: knowledge removal rather than forgetting individual samples, the high cost of optimizing LLMs, and the need for principled evaluation metrics. To bridge these gaps, we propose ToolDelete, the first approach for unlearning tools from tool-augmented LLMs. It implements three key properties to address the above challenges for effective tool unlearning and introduces a new membership inference attack (MIA) model for effective evaluation. Extensive experiments on multiple tool learning datasets and tool-augmented LLMs show that ToolDelete effectively unlearns randomly selected tools, while preserving the LLM's knowledge on non-deleted tools and maintaining performance on general tasks.</li>
</ul>

<h3>Title: Federated Linear Dueling Bandits</h3>
<ul>
<li><strong>Authors: </strong>Xuhan Huang, Yan Hu, Zhiyan Li, Zhiyong Wang, Benyou Wang, Zhongxiang Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01085">https://arxiv.org/abs/2502.01085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01085">https://arxiv.org/pdf/2502.01085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01085]] Federated Linear Dueling Bandits(https://arxiv.org/abs/2502.01085)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, large language model</a></li>
<li><strong>Abstract: </strong>Contextual linear dueling bandits have recently garnered significant attention due to their widespread applications in important domains such as recommender systems and large language models. Classical dueling bandit algorithms are typically only applicable to a single agent. However, many applications of dueling bandits involve multiple agents who wish to collaborate for improved performance yet are unwilling to share their data. This motivates us to draw inspirations from federated learning, which involves multiple agents aiming to collaboratively train their neural networks via gradient descent (GD) without sharing their raw data. Previous works have developed federated linear bandit algorithms which rely on closed-form updates of the bandit parameters (e.g., the linear function parameter) to achieve collaboration. However, in linear dueling bandits, the linear function parameter lacks a closed-form expression and its estimation requires minimizing a loss function. This renders these previous methods inapplicable. In this work, we overcome this challenge through an innovative and principled combination of online gradient descent (for minimizing the loss function to estimate the linear function parameters) and federated learning, hence introducing the first federated linear dueling bandit algorithms. Through rigorous theoretical analysis, we prove that our algorithms enjoy a sub-linear upper bound on its cumulative regret. We also use empirical experiments to demonstrate the effectiveness of our algorithms and the practical benefit of collaboration.</li>
</ul>

<h3>Title: Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Jiali Chen, Xusen Hei, Yuqi Xue, Zihan Wu, Jiayuan Xie, Yi Cai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01090">https://arxiv.org/abs/2502.01090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01090">https://arxiv.org/pdf/2502.01090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01090]] Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model(https://arxiv.org/abs/2502.01090)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chinese literary classics hold significant cultural and educational value, offering deep insights into morality, history, and human nature. These works often include classical Chinese and complex narratives, making them difficult for children to read. To bridge this gap, we introduce a child-friendly literary adaptation (CLA) task to adapt the Chinese literary classic into engaging and accessible text for children. However, recent large language models (LLMs) overlook children's reading preferences (\ie, vivid character portrayals, concise narrative structures, and appropriate readability), which poses challenges in CLA. In this paper, we propose a method called InstructChild, which augments the LLM with these preferences for adaptation. Specifically, we first obtain the characters' personalities and narrative structure as additional information for fine-grained instruction tuning. Then, we devise a readability metric as the reward to align the LLM with the children's reading level. Finally, a lookahead decoding strategy is applied to improve the readability of the generated text during inference. To support the evaluation of CLA task, we construct the Classic4Children dataset, which comprises both the original and child-friendly versions of the Four Great Classical Novels of Chinese literature. Experimental results show that our InstructChild significantly improves automatic and human evaluation performance.</li>
</ul>

<h3>Title: SatFlow: Generative model based framework for producing High Resolution Gap Free Remote Sensing Imagery</h3>
<ul>
<li><strong>Authors: </strong>Bharath Irigireddy, Varaprasad Bandaru</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01098">https://arxiv.org/abs/2502.01098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01098">https://arxiv.org/pdf/2502.01098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01098]] SatFlow: Generative model based framework for producing High Resolution Gap Free Remote Sensing Imagery(https://arxiv.org/abs/2502.01098)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Frequent, high-resolution remote sensing imagery is crucial for agricultural and environmental monitoring. Satellites from the Landsat collection offer detailed imagery at 30m resolution but with lower temporal frequency, whereas missions like MODIS and VIIRS provide daily coverage at coarser resolutions. Clouds and cloud shadows contaminate about 55\% of the optical remote sensing observations, posing additional challenges. To address these challenges, we present SatFlow, a generative model-based framework that fuses low-resolution MODIS imagery and Landsat observations to produce frequent, high-resolution, gap-free surface reflectance imagery. Our model, trained via Conditional Flow Matching, demonstrates better performance in generating imagery with preserved structural and spectral integrity. Cloud imputation is treated as an image inpainting task, where the model reconstructs cloud-contaminated pixels and fills gaps caused by scan lines during inference by leveraging the learned generative processes. Experimental results demonstrate the capability of our approach in reliably imputing cloud-covered regions. This capability is crucial for downstream applications such as crop phenology tracking, environmental change detection etc.,</li>
</ul>

<h3>Title: VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control</h3>
<ul>
<li><strong>Authors: </strong>Lifan Jiang, Shuang Chen, Boxi Wu, Xiaotong Guan, Jiahui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01101">https://arxiv.org/abs/2502.01101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01101">https://arxiv.org/pdf/2502.01101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01101]] VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control(https://arxiv.org/abs/2502.01101)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>With the advancement of generative artificial intelligence, previous studies have achieved the task of generating aesthetic images from hand-drawn sketches, fulfilling the public's needs for drawing. However, these methods are limited to static images and lack the ability to control video animation generation using hand-drawn sketches. To address this gap, we propose VidSketch, the first method capable of generating high-quality video animations directly from any number of hand-drawn sketches and simple text prompts, bridging the divide between ordinary users and professional artists. Specifically, our method introduces a Level-Based Sketch Control Strategy to automatically adjust the guidance strength of sketches during the generation process, accommodating users with varying drawing skills. Furthermore, a TempSpatial Attention mechanism is designed to enhance the spatiotemporal consistency of generated video animations, significantly improving the coherence across frames. You can find more detailed cases on our official website.</li>
</ul>

<h3>Title: LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Yiren Song, Danze Chen, Mike Zheng Shou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01105">https://arxiv.org/abs/2502.01105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01105">https://arxiv.org/pdf/2502.01105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01105]] LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer(https://arxiv.org/abs/2502.01105)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Generating cognitive-aligned layered SVGs remains challenging due to existing methods' tendencies toward either oversimplified single-layer outputs or optimization-induced shape redundancies. We propose LayerTracer, a diffusion transformer based framework that bridges this gap by learning designers' layered SVG creation processes from a novel dataset of sequential design operations. Our approach operates in two phases: First, a text-conditioned DiT generates multi-phase rasterized construction blueprints that simulate human design workflows. Second, layer-wise vectorization with path deduplication produces clean, editable SVGs. For image vectorization, we introduce a conditional diffusion mechanism that encodes reference images into latent tokens, guiding hierarchical reconstruction while preserving structural integrity. Extensive experiments demonstrate LayerTracer's superior performance against optimization-based and neural baselines in both generation quality and editability, effectively aligning AI-generated vectors with professional design cognition.</li>
</ul>

<h3>Title: Can We Validate Counterfactual Estimations in the Presence of General Network Interference?</h3>
<ul>
<li><strong>Authors: </strong>Sadegh Shirani, Yuwei Luo, William Overman, Ruoxuan Xiong, Mohsen Bayati</a></li>
<li><strong>Subjects: </strong>cs.LG, econ.EM, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01106">https://arxiv.org/abs/2502.01106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01106">https://arxiv.org/pdf/2502.01106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01106]] Can We Validate Counterfactual Estimations in the Presence of General Network Interference?(https://arxiv.org/abs/2502.01106)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In experimental settings with network interference, a unit's treatment can influence outcomes of other units, challenging both causal effect estimation and its validation. Classic validation approaches fail as outcomes are only observable under one treatment scenario and exhibit complex correlation patterns due to interference. To address these challenges, we introduce a new framework enabling cross-validation for counterfactual estimation. At its core is our distribution-preserving network bootstrap method -- a theoretically-grounded approach inspired by approximate message passing. This method creates multiple subpopulations while preserving the underlying distribution of network effects. We extend recent causal message-passing developments by incorporating heterogeneous unit-level characteristics and varying local interactions, ensuring reliable finite-sample performance through non-asymptotic analysis. We also develop and publicly release a comprehensive benchmark toolbox with diverse experimental environments, from networks of interacting AI agents to opinion formation in real-world communities and ride-sharing applications. These environments provide known ground truth values while maintaining realistic complexities, enabling systematic examination of causal inference methods. Extensive evaluation across these environments demonstrates our method's robustness to diverse forms of network interference. Our work provides researchers with both a practical estimation framework and a standardized platform for testing future methodological developments.</li>
</ul>

<h3>Title: GTG: Generalizable Trajectory Generation Model for Urban Mobility</h3>
<ul>
<li><strong>Authors: </strong>Jingyuan Wang, Yujing Lin, Yudong Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01107">https://arxiv.org/abs/2502.01107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01107">https://arxiv.org/pdf/2502.01107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01107]] GTG: Generalizable Trajectory Generation Model for Urban Mobility(https://arxiv.org/abs/2502.01107)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Trajectory data mining is crucial for smart city management. However, collecting large-scale trajectory datasets is challenging due to factors such as commercial conflicts and privacy regulations. Therefore, we urgently need trajectory generation techniques to address this issue. Existing trajectory generation methods rely on the global road network structure of cities. When the road network structure changes, these methods are often not transferable to other cities. In fact, there exist invariant mobility patterns between different cities: 1) People prefer paths with the minimal travel cost; 2) The travel cost of roads has an invariant relationship with the topological features of the road network. Based on the above insight, this paper proposes a Generalizable Trajectory Generation model (GTG). The model consists of three parts: 1) Extracting city-invariant road representation based on Space Syntax method; 2) Cross-city travel cost prediction through disentangled adversarial training; 3) Travel preference learning by shortest path search and preference update. By learning invariant movement patterns, the model is capable of generating trajectories in new cities. Experiments on three datasets demonstrates that our model significantly outperforms existing models in terms of generalization ability.</li>
</ul>

<h3>Title: Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings</h3>
<ul>
<li><strong>Authors: </strong>Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01108">https://arxiv.org/abs/2502.01108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01108">https://arxiv.org/pdf/2502.01108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01108]] Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings(https://arxiv.org/abs/2502.01108)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Photoplethysmography (PPG)-based foundation models are gaining traction due to the widespread use of PPG in biosignal monitoring and their potential to generalize across diverse health applications. In this paper, we introduce Pulse-PPG, the first open-source PPG foundation model trained exclusively on raw PPG data collected over a 100-day field study with 120 participants. Existing PPG foundation models are either open-source but trained on clinical data or closed-source, limiting their applicability in real-world settings. We evaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its performance against a state-of-the-art foundation model trained on clinical data. Our results demonstrate that Pulse-PPG, trained on uncurated field data, exhibits superior generalization across clinical and mobile health applications in both lab and field settings. This suggests that exposure to real-world variability enables the model to learn fine-grained representations, making it more adaptable across tasks. Furthermore, pre-training on field data surprisingly outperforms its pre-training on clinical data in many tasks, reinforcing the importance of training on real-world, diverse datasets. To encourage further advancements in robust foundation models leveraging field data, we plan to release Pulse-PPG, providing researchers with a powerful resource for developing more generalizable PPG-based models.</li>
</ul>

<h3>Title: The Nonlinear Filter Model of Stream Cipher Redivivus</h3>
<ul>
<li><strong>Authors: </strong>Claude Carlet, Palash Sarkar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01110">https://arxiv.org/abs/2502.01110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01110">https://arxiv.org/pdf/2502.01110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01110]] The Nonlinear Filter Model of Stream Cipher Redivivus(https://arxiv.org/abs/2502.01110)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>The nonlinear filter model is an old and well understood approach to the design of secure stream ciphers. Extensive research over several decades has shown how to attack stream ciphers based on this model and has identified the security properties required of the Boolean function used as the filtering function to resist such attacks. This led to the problem of constructing Boolean functions which provide adequate security \textit{and} at the same time are efficient to implement. Unfortunately, over the last two decades no good solutions to this problem appeared in the literature. The lack of good solutions has effectively led to nonlinear filter model becoming more or less obsolete. This is a big loss to the cryptographic design toolkit, since the great advantages of the nonlinear filter model are its simplicity, well understood security and the potential to provide low cost solutions for hardware oriented stream ciphers. In this paper, we revive the nonlinear filter model by constructing appropriate Boolean functions which provide required security and are also efficient to implement. We put forward concrete suggestions of stream ciphers which are $\kappa$-bit secure against known types of attacks for $\kappa=80,128,160,192,224$ and $256$. For the $80$-bit, $128$-bit, and the $256$-bit security levels, the circuits for the corresponding stream ciphers require about 1743.5, 2771.5, and 5607.5 NAND gates respectively. For the $80$-bit and the $128$-bit security levels, the gate count estimates compare quite well to the famous ciphers Trivium and Grain-128a respectively, while for the $256$-bit security level, we do not know of any other stream cipher design which has such a low gate count.</li>
</ul>

<h3>Title: Learning to Learn Weight Generation via Trajectory Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yunchuan Guan, Yu Liu, Ke Zhou, Zhiqi Shen, Serge Belongie, Jenq-Neng Hwang, Lei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01117">https://arxiv.org/abs/2502.01117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01117">https://arxiv.org/pdf/2502.01117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01117]] Learning to Learn Weight Generation via Trajectory Diffusion(https://arxiv.org/abs/2502.01117)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion-based algorithms have emerged as promising techniques for weight generation, particularly in scenarios like multi-task learning that require frequent weight updates. However, existing solutions suffer from limited cross-task transferability. In addition, they only utilize optimal weights as training samples, ignoring the value of other weights in the optimization process. To address these issues, we propose Lt-Di, which integrates the diffusion algorithm with meta-learning to generate weights for unseen tasks. Furthermore, we extend the vanilla diffusion algorithm into a trajectory diffusion algorithm to utilize other weights along the optimization trajectory. Trajectory diffusion decomposes the entire diffusion chain into multiple shorter ones, improving training and inference efficiency. We analyze the convergence properties of the weight generation paradigm and improve convergence efficiency without additional time overhead. Our experiments demonstrate Lt-Di's higher accuracy while reducing computational overhead across various tasks, including zero-shot and few-shot learning, multi-domain generalization, and large-scale language model this http URL code is released at this https URL.</li>
</ul>

<h3>Title: Large Language Model-Enhanced Multi-Armed Bandits</h3>
<ul>
<li><strong>Authors: </strong>Jiahang Sun, Zhiyong Wang, Runhan Yang, Chenjun Xiao, John C.S. Lui, Zhongxiang Dai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01118">https://arxiv.org/abs/2502.01118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01118">https://arxiv.org/pdf/2502.01118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01118]] Large Language Model-Enhanced Multi-Armed Bandits(https://arxiv.org/abs/2502.01118)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been adopted to solve sequential decision-making tasks such as multi-armed bandits (MAB), in which an LLM is directly instructed to select the arms to pull in every iteration. However, this paradigm of direct arm selection using LLMs has been shown to be suboptimal in many MAB tasks. Therefore, we propose an alternative approach which combines the strengths of classical MAB and LLMs. Specifically, we adopt a classical MAB algorithm as the high-level framework and leverage the strong in-context learning capability of LLMs to perform the sub-task of reward prediction. Firstly, we incorporate the LLM-based reward predictor into the classical Thompson sampling (TS) algorithm and adopt a decaying schedule for the LLM temperature to ensure a transition from exploration to exploitation. Next, we incorporate the LLM-based reward predictor (with a temperature of 0) into a regression oracle-based MAB algorithm equipped with an explicit exploration mechanism. We also extend our TS-based algorithm to dueling bandits where only the preference feedback between pairs of arms is available, which requires non-trivial algorithmic modifications. We conduct empirical evaluations using both synthetic MAB tasks and experiments designed using real-world text datasets, in which the results show that our algorithms consistently outperform previous baseline methods based on direct arm selection. Interestingly, we also demonstrate that in challenging tasks where the arms lack semantic meanings that can be exploited by the LLM, our approach achieves considerably better performance than LLM-based direct arm selection.</li>
</ul>

<h3>Title: Learning Efficient Positional Encodings with Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Charilaos I. Kanatsoulis, Evelyn Choi, Stephanie Jegelka, Jure Leskovec, Alejandro Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01122">https://arxiv.org/abs/2502.01122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01122">https://arxiv.org/pdf/2502.01122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01122]] Learning Efficient Positional Encodings with Graph Neural Networks(https://arxiv.org/abs/2502.01122)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Positional encodings (PEs) are essential for effective graph representation learning because they provide position awareness in inherently position-agnostic transformer architectures and increase the expressive capacity of Graph Neural Networks (GNNs). However, designing powerful and efficient PEs for graphs poses significant challenges due to the absence of canonical node ordering and the scale of the graph. {In this work, we identify four key properties that graph PEs should satisfy}: stability, expressive power, scalability, and genericness. We find that existing eigenvector-based PE methods often fall short of jointly satisfying these criteria. To address this gap, we introduce PEARL, a novel framework of learnable PEs for graphs. Our primary insight is that message-passing GNNs function as nonlinear mappings of eigenvectors, enabling the design of GNN architectures for generating powerful and efficient PEs. A crucial challenge lies in initializing node attributes in a manner that is both expressive and permutation equivariant. We tackle this by initializing GNNs with random node inputs or standard basis vectors, thereby unlocking the expressive power of message-passing operations, while employing statistical pooling functions to maintain permutation equivariance. Our analysis demonstrates that PEARL approximates equivariant functions of eigenvectors with linear complexity, while rigorously establishing its stability and high expressive power. Experimental evaluations show that PEARL outperforms lightweight versions of eigenvector-based PEs and achieves comparable performance to full eigenvector-based PEs, but with one or two orders of magnitude lower complexity. Our code is available at this https URL.</li>
</ul>

<h3>Title: Simple Linear Neuron Boosting</h3>
<ul>
<li><strong>Authors: </strong>Daniel Munoz</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01131">https://arxiv.org/abs/2502.01131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01131">https://arxiv.org/pdf/2502.01131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01131]] Simple Linear Neuron Boosting(https://arxiv.org/abs/2502.01131)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Given a differentiable network architecture and loss function, we revisit optimizing the network's neurons in function space using Boosted Backpropagation (Grubb & Bagnell, 2010), in contrast to optimizing in parameter space. From this perspective, we reduce descent in the space of linear functions that optimizes the network's backpropagated-errors to a preconditioned gradient descent algorithm. We show that this preconditioned update rule is equivalent to reparameterizing the network to whiten each neuron's features, with the benefit that the normalization occurs outside of inference. In practice, we use this equivalence to construct an online estimator for approximating the preconditioner and we propose an online, matrix-free learning algorithm with adaptive step sizes. The algorithm is applicable whenever autodifferentiation is available, including convolutional networks and transformers, and it is simple to implement for both the local and distributed training settings. We demonstrate fast convergence both in terms of epochs and wall clock time on a variety of tasks and networks.</li>
</ul>

<h3>Title: Tackling Feature and Sample Heterogeneity in Decentralized Multi-Task Learning: A Sheaf-Theoretic Approach</h3>
<ul>
<li><strong>Authors: </strong>Chaouki Ben Issaid, Praneeth Vepakomma, Mehdi Bennis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01145">https://arxiv.org/abs/2502.01145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01145">https://arxiv.org/pdf/2502.01145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01145]] Tackling Feature and Sample Heterogeneity in Decentralized Multi-Task Learning: A Sheaf-Theoretic Approach(https://arxiv.org/abs/2502.01145)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated multi-task learning (FMTL) aims to simultaneously learn multiple related tasks across clients without sharing sensitive raw data. However, in the decentralized setting, existing FMTL frameworks are limited in their ability to capture complex task relationships and handle feature and sample heterogeneity across clients. To address these challenges, we introduce a novel sheaf-theoretic-based approach for FMTL. By representing client relationships using cellular sheaves, our framework can flexibly model interactions between heterogeneous client models. We formulate the sheaf-based FMTL optimization problem using sheaf Laplacian regularization and propose the Sheaf-FMTL algorithm to solve it. We show that the proposed framework provides a unified view encompassing many existing federated learning (FL) and FMTL approaches. Furthermore, we prove that our proposed algorithm, Sheaf-FMTL, achieves a sublinear convergence rate in line with state-of-the-art decentralized FMTL algorithms. Extensive experiments demonstrate that Sheaf-FMTL exhibits communication savings by sending significantly fewer bits compared to decentralized FMTL baselines.</li>
</ul>

<h3>Title: Jailbreaking with Universal Multi-Prompts</h3>
<ul>
<li><strong>Authors: </strong>Yu-Ling Hsu, Hsuan Su, Shang-Tse Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01154">https://arxiv.org/abs/2502.01154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01154">https://arxiv.org/pdf/2502.01154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01154]] Jailbreaking with Universal Multi-Prompts(https://arxiv.org/abs/2502.01154)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have seen rapid development in recent years, revolutionizing various applications and significantly enhancing convenience and productivity. However, alongside their impressive capabilities, ethical concerns and new types of attacks, such as jailbreaking, have emerged. While most prompting techniques focus on optimizing adversarial inputs for individual cases, resulting in higher computational costs when dealing with large datasets. Less research has addressed the more general setting of training a universal attacker that can transfer to unseen tasks. In this paper, we introduce JUMP, a prompt-based method designed to jailbreak LLMs using universal multi-prompts. We also adapt our approach for defense, which we term DUMP. Experimental results demonstrate that our method for optimizing universal multi-prompts outperforms existing techniques.</li>
</ul>

<h3>Title: AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model for Atmospheric Science</h3>
<ul>
<li><strong>Authors: </strong>Chenyue Li, Wen Deng, Mengqian Lu, Binhang Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01159">https://arxiv.org/abs/2502.01159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01159">https://arxiv.org/pdf/2502.01159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01159]] AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model for Atmospheric Science(https://arxiv.org/abs/2502.01159)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancements in large language models (LLMs), particularly in their reasoning capabilities, hold transformative potential for addressing complex challenges in atmospheric science. However, leveraging LLMs effectively in this domain requires a robust and comprehensive evaluation benchmark. To address this need, we present AtmosSci-Bench, a novel benchmark designed to systematically assess LLM performance across five core categories of atmospheric science problems: hydrology, atmospheric dynamics, atmospheric physics, geophysics, and physical oceanography. We employ a template-based question generation framework, enabling scalable and diverse multiple-choice questions curated from graduate-level atmospheric science problems. We conduct a comprehensive evaluation of representative LLMs, categorized into four groups: instruction-tuned models, advanced reasoning models, math-augmented models, and domain-specific climate models. Our analysis provides some interesting insights into the reasoning and problem-solving capabilities of LLMs in atmospheric science. We believe AtmosSci-Bench can serve as a critical step toward advancing LLM applications in climate service by offering a standard and rigorous evaluation framework. Our source codes are currently available at this https URL.</li>
</ul>

<h3>Title: Label Distribution Learning with Biased Annotations by Learning Multi-Label Representation</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Kou, Si Qin, Hailin Wang, Mingkun Xie, Shuo Chen, Yuheng Jia, Tongliang Liu, Masashi Sugiyama, Xin Geng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01170">https://arxiv.org/abs/2502.01170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01170">https://arxiv.org/pdf/2502.01170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01170]] Label Distribution Learning with Biased Annotations by Learning Multi-Label Representation(https://arxiv.org/abs/2502.01170)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-label learning (MLL) has gained attention for its ability to represent real-world data. Label Distribution Learning (LDL), an extension of MLL to learning from label distributions, faces challenges in collecting accurate label distributions. To address the issue of biased annotations, based on the low-rank assumption, existing works recover true distributions from biased observations by exploring the label correlations. However, recent evidence shows that the label distribution tends to be full-rank, and naive apply of low-rank approximation on biased observation leads to inaccurate recovery and performance degradation. In this paper, we address the LDL with biased annotations problem from a novel perspective, where we first degenerate the soft label distribution into a hard multi-hot label and then recover the true label information for each instance. This idea stems from an insight that assigning hard multi-hot labels is often easier than assigning a soft label distribution, and it shows stronger immunity to noise disturbances, leading to smaller label bias. Moreover, assuming that the multi-label space for predicting label distributions is low-rank offers a more reasonable approach to capturing label correlations. Theoretical analysis and experiments confirm the effectiveness and robustness of our method on real-world datasets.</li>
</ul>

<h3>Title: Joint Localization and Activation Editing for Low-Resource Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Wen Lai, Alexander Fraser, Ivan Titov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01179">https://arxiv.org/abs/2502.01179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01179">https://arxiv.org/pdf/2502.01179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01179]] Joint Localization and Activation Editing for Low-Resource Fine-Tuning(https://arxiv.org/abs/2502.01179)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, are commonly used to adapt LLMs. However, the effectiveness of standard PEFT methods is limited in low-resource scenarios with only a few hundred examples. Recent advances in interpretability research have inspired the emergence of activation editing techniques, which modify the activations of specific model components. These methods, due to their extremely small parameter counts, show promise for small datasets. However, their performance is highly dependent on identifying the correct modules to edit and often lacks stability across different datasets. In this paper, we propose Joint Localization and Activation Editing (JoLA), a method that jointly learns (1) which heads in the Transformer to edit (2) whether the intervention should be additive, multiplicative, or both and (3) the intervention parameters themselves - the vectors applied as additive offsets or multiplicative scalings to the head output. Through evaluations on three benchmarks spanning commonsense reasoning, natural language understanding, and natural language generation, we demonstrate that JoLA consistently outperforms existing methods.</li>
</ul>

<h3>Title: Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Qianyu Guo, Jingrong Wu, Tianxing Wu, Haofen Wang, Weifeng Ge, Wenqiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01183">https://arxiv.org/abs/2502.01183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01183">https://arxiv.org/pdf/2502.01183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01183]] Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning(https://arxiv.org/abs/2502.01183)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Few-shot learning (FSL) has recently been extensively utilized to overcome the scarcity of training data in domain-specific visual recognition. In real-world scenarios, environmental factors such as complex backgrounds, varying lighting conditions, long-distance shooting, and moving targets often cause test images to exhibit numerous incomplete targets or noise disruptions. However, current research on evaluation datasets and methodologies has largely ignored the concept of "environmental robustness", which refers to maintaining consistent performance in complex and diverse physical environments. This neglect has led to a notable decline in the performance of FSL models during practical testing compared to their training performance. To bridge this gap, we introduce a new real-world multi-domain few-shot learning (RD-FSL) benchmark, which includes four domains and six evaluation datasets. The test images in this benchmark feature various challenging elements, such as camouflaged objects, small targets, and blurriness. Our evaluation experiments reveal that existing methods struggle to utilize training images effectively to generate accurate feature representations for challenging test images. To address this problem, we propose a novel conditional representation learning network (CRLNet) that integrates the interactions between training and testing images as conditional information in their respective representation processes. The main goal is to reduce intra-class variance or enhance inter-class variance at the feature representation level. Finally, comparative experiments reveal that CRLNet surpasses the current state-of-the-art methods, achieving performance improvements ranging from 6.83% to 16.98% across diverse settings and backbones. The source code and dataset are available at this https URL.</li>
</ul>

<h3>Title: FragmentNet: Adaptive Graph Fragmentation for Graph-to-Sequence Molecular Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Ankur Samanta, Rohan Gupta, Aditi Misra, Christian McIntosh Clarke, Jayakumar Rajadas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.chem-ph, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01184">https://arxiv.org/abs/2502.01184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01184">https://arxiv.org/pdf/2502.01184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01184]] FragmentNet: Adaptive Graph Fragmentation for Graph-to-Sequence Molecular Representation Learning(https://arxiv.org/abs/2502.01184)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Molecular property prediction uses molecular structure to infer chemical properties. Chemically interpretable representations that capture meaningful intramolecular interactions enhance the usability and effectiveness of these predictions. However, existing methods often rely on atom-based or rule-based fragment tokenization, which can be chemically suboptimal and lack scalability. We introduce FragmentNet, a graph-to-sequence foundation model with an adaptive, learned tokenizer that decomposes molecular graphs into chemically valid fragments while preserving structural connectivity. FragmentNet integrates VQVAE-GCN for hierarchical fragment embeddings, spatial positional encodings for graph serialization, global molecular descriptors, and a transformer. Pre-trained with Masked Fragment Modeling and fine-tuned on MoleculeNet tasks, FragmentNet outperforms models with similarly scaled architectures and datasets while rivaling larger state-of-the-art models requiring significantly more resources. This novel framework enables adaptive decomposition, serialization, and reconstruction of molecular graphs, facilitating fragment-based editing and visualization of property trends in learned embeddings - a powerful tool for molecular design and optimization.</li>
</ul>

<h3>Title: FairUDT: Fairness-aware Uplift Decision Trees</h3>
<ul>
<li><strong>Authors: </strong>Anam Zahid, Abdur Rehman Ali, Shaina Raza, Rai Shahnawaz, Faisal Kamiran, Asim Karim</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01188">https://arxiv.org/abs/2502.01188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01188">https://arxiv.org/pdf/2502.01188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01188]] FairUDT: Fairness-aware Uplift Decision Trees(https://arxiv.org/abs/2502.01188)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Training data used for developing machine learning classifiers can exhibit biases against specific protected attributes. Such biases typically originate from historical discrimination or certain underlying patterns that disproportionately under-represent minority groups, such as those identified by their gender, religion, or race. In this paper, we propose a novel approach, FairUDT, a fairness-aware Uplift-based Decision Tree for discrimination identification. FairUDT demonstrates how the integration of uplift modeling with decision trees can be adapted to include fair splitting criteria. Additionally, we introduce a modified leaf relabeling approach for removing discrimination. We divide our dataset into favored and deprived groups based on a binary sensitive attribute, with the favored dataset serving as the treatment group and the deprived dataset as the control group. By applying FairUDT and our leaf relabeling approach to preprocess three benchmark datasets, we achieve an acceptable accuracy-discrimination tradeoff. We also show that FairUDT is inherently interpretable and can be utilized in discrimination detection tasks. The code for this project is available this https URL</li>
</ul>

<h3>Title: Dance recalibration for dance coherency with recurrent convolution block</h3>
<ul>
<li><strong>Authors: </strong>Seungho Eum, Ihjoon Cho, Junghyeon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01190">https://arxiv.org/abs/2502.01190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01190">https://arxiv.org/pdf/2502.01190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01190]] Dance recalibration for dance coherency with recurrent convolution block(https://arxiv.org/abs/2502.01190)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>With the recent advancements in generative AI such as GAN, Diffusion, and VAE, the use of generative AI for dance generation has seen significant progress and received considerable interest. In this study, We propose R-Lodge, an enhanced version of Lodge. R-Lodge incorporates Recurrent Sequential Representation Learning named Dance Recalibration to original coarse-to-fine long dance generation model. R-Lodge utilizes Dance Recalibration method using $N$ Dance Recalibration Block to address the lack of consistency in the coarse dance representation of the Lodge model. By utilizing this method, each generated dance motion incorporates a bit of information from the previous dance motions. We evaluate R-Lodge on FineDance dataset and the results show that R-Lodge enhances the consistency of the whole generated dance motions.</li>
</ul>

<h3>Title: Towards Robust and Reliable Concept Representations: Reliability-Enhanced Concept Embedding Model</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Cai, Xiyu Wang, Satoshi Tsutsui, Winnie Pang, Bihan Wen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01191">https://arxiv.org/abs/2502.01191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01191">https://arxiv.org/pdf/2502.01191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01191]] Towards Robust and Reliable Concept Representations: Reliability-Enhanced Concept Embedding Model(https://arxiv.org/abs/2502.01191)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Concept Bottleneck Models (CBMs) aim to enhance interpretability by predicting human-understandable concepts as intermediates for decision-making. However, these models often face challenges in ensuring reliable concept representations, which can propagate to downstream tasks and undermine robustness, especially under distribution shifts. Two inherent issues contribute to concept unreliability: sensitivity to concept-irrelevant features (e.g., background variations) and lack of semantic consistency for the same concept across different samples. To address these limitations, we propose the Reliability-Enhanced Concept Embedding Model (RECEM), which introduces a two-fold strategy: Concept-Level Disentanglement to separate irrelevant features from concept-relevant information and a Concept Mixup mechanism to ensure semantic alignment across samples. These mechanisms work together to improve concept reliability, enabling the model to focus on meaningful object attributes and generate faithful concept representations. Experimental results demonstrate that RECEM consistently outperforms existing baselines across multiple datasets, showing superior performance under background and domain shifts. These findings highlight the effectiveness of disentanglement and alignment strategies in enhancing both reliability and robustness in CBMs.</li>
</ul>

<h3>Title: Nearly Lossless Adaptive Bit Switching</h3>
<ul>
<li><strong>Authors: </strong>Haiduo Huang, Zhenhua Liu, Tian Xia, Wenzhe zhao, Pengju Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01199">https://arxiv.org/abs/2502.01199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01199">https://arxiv.org/pdf/2502.01199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01199]] Nearly Lossless Adaptive Bit Switching(https://arxiv.org/abs/2502.01199)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Model quantization is widely applied for compressing and accelerating deep neural networks (DNNs). However, conventional Quantization-Aware Training (QAT) focuses on training DNNs with uniform bit-width. The bit-width settings vary across different hardware and transmission demands, which induces considerable training and storage costs. Hence, the scheme of one-shot joint training multiple precisions is proposed to address this issue. Previous works either store a larger FP32 model to switch between different precision models for higher accuracy or store a smaller INT8 model but compromise accuracy due to using shared quantization parameters. In this paper, we introduce the Double Rounding quantization method, which fully utilizes the quantized representation range to accomplish nearly lossless bit-switching while reducing storage by using the highest integer precision instead of full precision. Furthermore, we observe a competitive interference among different precisions during one-shot joint training, primarily due to inconsistent gradients of quantization scales during backward propagation. To tackle this problem, we propose an Adaptive Learning Rate Scaling (ALRS) technique that dynamically adapts learning rates for various precisions to optimize the training process. Additionally, we extend our Double Rounding to one-shot mixed precision training and develop a Hessian-Aware Stochastic Bit-switching (HASB) strategy. Experimental results on the ImageNet-1K classification demonstrate that our methods have enough advantages to state-of-the-art one-shot joint QAT in both multi-precision and mixed-precision. We also validate the feasibility of our method on detection and segmentation tasks, as well as on LLMs task. Our codes are available at this https URL.</li>
</ul>

<h3>Title: One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Yiyue Li, Shaoting Zhang, Kang Li, Qicheng Lao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01201">https://arxiv.org/abs/2502.01201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01201">https://arxiv.org/pdf/2502.01201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01201]] One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection(https://arxiv.org/abs/2502.01201)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traditional Anomaly Detection (AD) methods have predominantly relied on unsupervised learning from extensive normal data. Recent AD methods have evolved with the advent of large pre-trained vision-language models, enhancing few-shot anomaly detection capabilities. However, these latest AD methods still exhibit limitations in accuracy improvement. One contributing factor is their direct comparison of a query image's features with those of few-shot normal images. This direct comparison often leads to a loss of precision and complicates the extension of these techniques to more complex domains--an area that remains underexplored in a more refined and comprehensive manner. To address these limitations, we introduce the anomaly personalization method, which performs a personalized one-to-normal transformation of query images using an anomaly-free customized generation model, ensuring close alignment with the normal manifold. Moreover, to further enhance the stability and robustness of prediction results, we propose a triplet contrastive anomaly inference strategy, which incorporates a comprehensive comparison between the query and generated anomaly-free data pool and prompt information. Extensive evaluations across eleven datasets in three domains demonstrate our model's effectiveness compared to the latest AD methods. Additionally, our method has been proven to transfer flexibly to other AD methods, with the generated image data effectively improving the performance of other AD methods.</li>
</ul>

<h3>Title: Theoretical Analysis of KL-regularized RLHF with Multiple Reference Models</h3>
<ul>
<li><strong>Authors: </strong>Gholamali Aminian, Amir R. Asadi, Idan Shenfeld, Youssef Mroueh</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01203">https://arxiv.org/abs/2502.01203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01203">https://arxiv.org/pdf/2502.01203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01203]] Theoretical Analysis of KL-regularized RLHF with Multiple Reference Models(https://arxiv.org/abs/2502.01203)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent methods for aligning large language models (LLMs) with human feedback predominantly rely on a single reference model, which limits diversity, model overfitting, and underutilizes the wide range of available pre-trained models. Incorporating multiple reference models has the potential to address these limitations by broadening perspectives, reducing bias, and leveraging the strengths of diverse open-source LLMs. However, integrating multiple reference models into reinforcement learning with human feedback (RLHF) frameworks poses significant theoretical challenges, particularly in reverse KL-regularization, where achieving exact solutions has remained an open problem. This paper presents the first \emph{exact solution} to the multiple reference model problem in reverse KL-regularized RLHF. We introduce a comprehensive theoretical framework that includes rigorous statistical analysis and provides sample complexity guarantees. Additionally, we extend our analysis to forward KL-regularized RLHF, offering new insights into sample complexity requirements in multiple reference scenarios. Our contributions lay the foundation for more advanced and adaptable LLM alignment techniques, enabling the effective use of multiple reference models. This work paves the way for developing alignment frameworks that are both theoretically sound and better suited to the challenges of modern AI ecosystems.</li>
</ul>

<h3>Title: Almost Surely Safe Alignment of Large Language Models at Inference-Time</h3>
<ul>
<li><strong>Authors: </strong>Xiaotong Ji, Shyam Sundhar Ramesh, Matthieu Zimmer, Ilija Bogunovic, Jun Wang, Haitham Bou Ammar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01208">https://arxiv.org/abs/2502.01208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01208">https://arxiv.org/pdf/2502.01208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01208]] Almost Surely Safe Alignment of Large Language Models at Inference-Time(https://arxiv.org/abs/2502.01208)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Even highly capable large language models (LLMs) can produce biased or unsafe responses, and alignment techniques, such as RLHF, aimed at mitigating this issue, are expensive and prone to overfitting as they retrain the LLM. This paper introduces a novel inference-time alignment approach that ensures LLMs generate safe responses almost surely, i.e., with a probability approaching one. We achieve this by framing the safe generation of inference-time responses as a constrained Markov decision process within the LLM's latent space. Crucially, we augment a safety state that tracks the evolution of safety constraints and enables us to demonstrate formal safety guarantees upon solving the MDP in the latent space. Building on this foundation, we propose InferenceGuard, a practical implementation that safely aligns LLMs without modifying the model weights. Empirically, we demonstrate InferenceGuard effectively balances safety and task performance, outperforming existing inference-time alignment methods in generating safe and aligned responses.</li>
</ul>

<h3>Title: Privilege Scores</h3>
<ul>
<li><strong>Authors: </strong>Ludwig Bothmann, Philip A. Boustani, Jose M. Alvarez, Giuseppe Casalicchio, Bernd Bischl, Susanne Dandl</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01211">https://arxiv.org/abs/2502.01211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01211">https://arxiv.org/pdf/2502.01211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01211]] Privilege Scores(https://arxiv.org/abs/2502.01211)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Bias-transforming methods of fairness-aware machine learning aim to correct a non-neutral status quo with respect to a protected attribute (PA). Current methods, however, lack an explicit formulation of what drives non-neutrality. We introduce privilege scores (PS) to measure PA-related privilege by comparing the model predictions in the real world with those in a fair world in which the influence of the PA is removed. At the individual level, PS can identify individuals who qualify for affirmative action; at the global level, PS can inform bias-transforming policies. After presenting estimation methods for PS, we propose privilege score contributions (PSCs), an interpretation method that attributes the origin of privilege to mediating features and direct effects. We provide confidence intervals for both PS and PSCs. Experiments on simulated and real-world data demonstrate the broad applicability of our methods and provide novel insights into gender and racial privilege in mortgage and college admissions applications.</li>
</ul>

<h3>Title: Exploring Few-Shot Defect Segmentation in General Industrial Scenarios with Metric Learning and Vision Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Tongkun Liu, Bing Li, Xiao Jin, Yupeng Shi, Qiuying Li, Xiang Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01216">https://arxiv.org/abs/2502.01216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01216">https://arxiv.org/pdf/2502.01216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01216]] Exploring Few-Shot Defect Segmentation in General Industrial Scenarios with Metric Learning and Vision Foundation Models(https://arxiv.org/abs/2502.01216)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Industrial defect segmentation is critical for manufacturing quality control. Due to the scarcity of training defect samples, few-shot semantic segmentation (FSS) holds significant value in this field. However, existing studies mostly apply FSS to tackle defects on simple textures, without considering more diverse scenarios. This paper aims to address this gap by exploring FSS in broader industrial products with various defect types. To this end, we contribute a new real-world dataset and reorganize some existing datasets to build a more comprehensive few-shot defect segmentation (FDS) benchmark. On this benchmark, we thoroughly investigate metric learning-based FSS methods, including those based on meta-learning and those based on Vision Foundation Models (VFMs). We observe that existing meta-learning-based methods are generally not well-suited for this task, while VFMs hold great potential. We further systematically study the applicability of various VFMs in this task, involving two paradigms: feature matching and the use of Segment Anything (SAM) models. We propose a novel efficient FDS method based on feature matching. Meanwhile, we find that SAM2 is particularly effective for addressing FDS through its video track mode. The contributed dataset and code will be available at: this https URL.</li>
</ul>

<h3>Title: On the Robustness of Temporal Factual Knowledge in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hichem Ammar Khodja, Frédéric Béchet, Quentin Brabant, Alexis Nasr, Gwénolé Lecorvé</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01220">https://arxiv.org/abs/2502.01220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01220">https://arxiv.org/pdf/2502.01220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01220]] On the Robustness of Temporal Factual Knowledge in Language Models(https://arxiv.org/abs/2502.01220)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper explores the temporal robustness of language models (LMs) in handling factual knowledge. While LMs can often complete simple factual statements, their ability to manage temporal facts (those valid only within specific timeframes) remains uncertain. We design a controlled experiment to test the robustness of temporal factual knowledge inside LMs, which we use to evaluate several pretrained and instruction-tuned models using prompts on popular Wikidata facts, assessing their performance across different temporal granularities (Day, Month, and Year). Our findings indicate that even very large state-of-the-art models, such as Llama-3.1-70B, vastly lack robust knowledge of temporal facts. In addition, they are incapable of generalizing their knowledge from one granularity to another. These results highlight the inherent limitations of using LMs as temporal knowledge bases. The source code and data to reproduce our experiments will be released.</li>
</ul>

<h3>Title: Ransomware IR Model: Proactive Threat Intelligence-Based Incident Response Strategy</h3>
<ul>
<li><strong>Authors: </strong>Anthony Cheuk Tung Lai, Ping Fan Ke, Alan Ho</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01221">https://arxiv.org/abs/2502.01221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01221">https://arxiv.org/pdf/2502.01221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01221]] Ransomware IR Model: Proactive Threat Intelligence-Based Incident Response Strategy(https://arxiv.org/abs/2502.01221)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Ransomware impact different organizations for years, it causes huge monetary, reputation loss and operation impact. Other than typical data encryption by ransomware, attackers can request ransom from the victim organizations via data extortion, otherwise, attackers will publish stolen data publicly in their ransomware dashboard forum and data-sharing platforms. However, there is no clear and proven published incident response strategy to satisfy different business priorities and objectives under ransomware attack in detail. In this paper, we quote one of our representative front-line ransomware incident response experiences for Company X. Organization and incident responder can reference our established model strategy and implement proactive threat intelligence-based incident response architecture if one is under ransomware attack, which helps to respond the incident more effectively and speedy.</li>
</ul>

<h3>Title: The dark deep side of DeepSeek: Fine-tuning attacks against the safety alignment of CoT-enabled models</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Xu, Joseph Gardiner, Sana Belguith</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01225">https://arxiv.org/abs/2502.01225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01225">https://arxiv.org/pdf/2502.01225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01225]] The dark deep side of DeepSeek: Fine-tuning attacks against the safety alignment of CoT-enabled models(https://arxiv.org/abs/2502.01225)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models are typically trained on vast amounts of data during the pre-training phase, which may include some potentially harmful information. Fine-tuning attacks can exploit this by prompting the model to reveal such behaviours, leading to the generation of harmful content. In this paper, we focus on investigating the performance of the Chain of Thought based reasoning model, DeepSeek, when subjected to fine-tuning attacks. Specifically, we explore how fine-tuning manipulates the model's output, exacerbating the harmfulness of its responses while examining the interaction between the Chain of Thought reasoning and adversarial inputs. Through this study, we aim to shed light on the vulnerability of Chain of Thought enabled models to fine-tuning attacks and the implications for their safety and ethical deployment.</li>
</ul>

<h3>Title: Eliciting Language Model Behaviors with Investigator Agents</h3>
<ul>
<li><strong>Authors: </strong>Xiang Lisa Li, Neil Chowdhury, Daniel D. Johnson, Tatsunori Hashimoto, Percy Liang, Sarah Schwettmann, Jacob Steinhardt</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01236">https://arxiv.org/abs/2502.01236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01236">https://arxiv.org/pdf/2502.01236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01236]] Eliciting Language Model Behaviors with Investigator Agents(https://arxiv.org/abs/2502.01236)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Language models exhibit complex, diverse behaviors when prompted with free-form text, making it difficult to characterize the space of possible outputs. We study the problem of behavior elicitation, where the goal is to search for prompts that induce specific target behaviors (e.g., hallucinations or harmful responses) from a target language model. To navigate the exponentially large space of possible prompts, we train investigator models to map randomly-chosen target behaviors to a diverse distribution of outputs that elicit them, similar to amortized Bayesian inference. We do this through supervised fine-tuning, reinforcement learning via DPO, and a novel Frank-Wolfe training objective to iteratively discover diverse prompting strategies. Our investigator models surface a variety of effective and human-interpretable prompts leading to jailbreaks, hallucinations, and open-ended aberrant behaviors, obtaining a 100% attack success rate on a subset of AdvBench (Harmful Behaviors) and an 85% hallucination rate.</li>
</ul>

<h3>Title: The Impact of Logic Locking on Confidentiality: An Automated Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Lennart M. Reimann, Evgenii Rezunov, Dominik Germek, Luca Collini, Christian Pilato, Ramesh Karri, Rainer Leupers</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01240">https://arxiv.org/abs/2502.01240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01240">https://arxiv.org/pdf/2502.01240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01240]] The Impact of Logic Locking on Confidentiality: An Automated Evaluation(https://arxiv.org/abs/2502.01240)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Logic locking secures hardware designs in untrusted foundries by incorporating key-driven gates to obscure the original blueprint. While this method safeguards the integrated circuit from malicious alterations during fabrication, its influence on data confidentiality during runtime has been ignored. In this study, we employ path sensitization to formally examine the impact of logic locking on confidentiality. By applying three representative logic locking mechanisms on open-source cryptographic benchmarks, we utilize an automatic test pattern generation framework to evaluate the effect of locking on cryptographic encryption keys and sensitive data signals. Our analysis reveals that logic locking can inadvertently cause sensitive data leakage when incorrect logic locking keys are used. We show that a single malicious logic locking key can expose over 70% of an encryption key. If an adversary gains control over other inputs, the entire encryption key can be compromised. This research uncovers a significant security vulnerability in logic locking and emphasizes the need for comprehensive security assessments that extend beyond key-recovery attacks.</li>
</ul>

<h3>Title: Peering Behind the Shield: Guardrail Identification in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ziqing Yang, Yixin Wu, Rui Wen, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01241">https://arxiv.org/abs/2502.01241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01241">https://arxiv.org/pdf/2502.01241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01241]] Peering Behind the Shield: Guardrail Identification in Large Language Models(https://arxiv.org/abs/2502.01241)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human-AI conversations have gained increasing attention since the era of large language models. Consequently, more techniques, such as input/output guardrails and safety alignment, are proposed to prevent potential misuse of such Human-AI conversations. However, the ability to identify these guardrails has significant implications, both for adversarial exploitation and for auditing purposes by red team operators. In this work, we propose a novel method, AP-Test, which identifies the presence of a candidate guardrail by leveraging guardrail-specific adversarial prompts to query the AI agent. Extensive experiments of four candidate guardrails under diverse scenarios showcase the effectiveness of our method. The ablation study further illustrates the importance of the components we designed, such as the loss terms.</li>
</ul>

<h3>Title: OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology</h3>
<ul>
<li><strong>Authors: </strong>Chengfeng Zhou, Ji Wang, Juanjuan Qin, Yining Wang, Ling Sun, Weiwei Dai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01243">https://arxiv.org/abs/2502.01243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01243">https://arxiv.org/pdf/2502.01243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01243]] OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology(https://arxiv.org/abs/2502.01243)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown significant promise across various medical applications, with ophthalmology being a notable area of focus. Many ophthalmic tasks have shown substantial improvement through the integration of LLMs. However, before these models can be widely adopted in clinical practice, evaluating their capabilities and identifying their limitations is crucial. To address this research gap and support the real-world application of LLMs, we introduce the OphthBench, a specialized benchmark designed to assess LLM performance within the context of Chinese ophthalmic practices. This benchmark systematically divides a typical ophthalmic clinical workflow into five key scenarios: Education, Triage, Diagnosis, Treatment, and Prognosis. For each scenario, we developed multiple tasks featuring diverse question types, resulting in a comprehensive benchmark comprising 9 tasks and 591 questions. This comprehensive framework allows for a thorough assessment of LLMs' capabilities and provides insights into their practical application in Chinese ophthalmology. Using this benchmark, we conducted extensive experiments and analyzed the results from 39 popular LLMs. Our evaluation highlights the current gap between LLM development and its practical utility in clinical settings, providing a clear direction for future advancements. By bridging this gap, we aim to unlock the potential of LLMs and advance their development in ophthalmology.</li>
</ul>

<h3>Title: Learnable polynomial, trigonometric, and tropical activations</h3>
<ul>
<li><strong>Authors: </strong>Ismail Khalfaoui-Hassani, Stefan Kesselheim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV, math.AG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01247">https://arxiv.org/abs/2502.01247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01247">https://arxiv.org/pdf/2502.01247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01247]] Learnable polynomial, trigonometric, and tropical activations(https://arxiv.org/abs/2502.01247)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper investigates scalable neural networks with learnable activation functions based on orthogonal function bases and tropical polynomials, targeting ImageNet-1K classification and next token prediction on OpenWebText. Traditional activations, such as ReLU, are static. In contrast, learnable activations enable the network to adapt dynamically during training. However, stability issues, such as vanishing or exploding gradients, arise with improper variance management in deeper networks. To remedy this, we propose an initialization scheme that single-handedly preserves unitary variance in transformers and convolutional networks, ensuring stable gradient flow even in deep architectures. Extensive experiments demonstrate that networks with Hermite, Fourier, and Tropical-based learnable activations significantly improve over GPT-2 and ConvNeXt networks in terms of accuracy and perplexity in train and test, highlighting the viability of learnable activations in large-scale tasks. The activation functions developed here are the subject of a library coded entirely in pure PyTorch: torchortho, available at this https URL.</li>
</ul>

<h3>Title: FSPGD: Rethinking Black-box Attacks on Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Eun-Sol Park, MiSo Park, Seung Park, Yong-Goo Shin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01262">https://arxiv.org/abs/2502.01262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01262">https://arxiv.org/pdf/2502.01262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01262]] FSPGD: Rethinking Black-box Attacks on Semantic Segmentation(https://arxiv.org/abs/2502.01262)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, segmentation</a></li>
<li><strong>Abstract: </strong>Transferability, the ability of adversarial examples crafted for one model to deceive other models, is crucial for black-box attacks. Despite advancements in attack methods for semantic segmentation, transferability remains limited, reducing their effectiveness in real-world applications. To address this, we introduce the Feature Similarity Projected Gradient Descent (FSPGD) attack, a novel black-box approach that enhances both attack performance and transferability. Unlike conventional segmentation attacks that rely on output predictions for gradient calculation, FSPGD computes gradients from intermediate layer features. Specifically, our method introduces a loss function that targets local information by comparing features between clean images and adversarial examples, while also disrupting contextual information by accounting for spatial relationships between objects. Experiments on Pascal VOC 2012 and Cityscapes datasets demonstrate that FSPGD achieves superior transferability and attack performance, establishing a new state-of-the-art benchmark. Code is available at this https URL.</li>
</ul>

<h3>Title: Counterfactual Situation Testing: From Single to Multidimensional Discrimination</h3>
<ul>
<li><strong>Authors: </strong>Jose M. Alvarez, Salvatore Ruggieri</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01267">https://arxiv.org/abs/2502.01267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01267">https://arxiv.org/pdf/2502.01267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01267]] Counterfactual Situation Testing: From Single to Multidimensional Discrimination(https://arxiv.org/abs/2502.01267)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>We present counterfactual situation testing (CST), a causal data mining framework for detecting individual discrimination in a dataset of classifier decisions. CST answers the question "what would have been the model outcome had the individual, or complainant, been of a different protected status?" It extends the legally-grounded situation testing (ST) of Thanh et al. (2011) by operationalizing the notion of fairness given the difference via counterfactual reasoning. ST finds for each complainant similar protected and non-protected instances in the dataset; constructs, respectively, a control and test group; and compares the groups such that a difference in outcomes implies a potential case of individual discrimination. CST, instead, avoids this idealized comparison by establishing the test group on the complainant's generated counterfactual, which reflects how the protected attribute when changed influences other seemingly neutral attributes of the complainant. Under CST we test for discrimination for each complainant by comparing similar individuals within each group but dissimilar individuals across groups. We consider single (e.g., gender) and multidimensional (e.g., gender and race) discrimination testing. For multidimensional discrimination we study multiple and intersectional discrimination and, as feared by legal scholars, find evidence that the former fails to account for the latter kind. Using a k-nearest neighbor implementation, we showcase CST on synthetic and real data. Experimental results show that CST uncovers a higher number of cases than ST, even when the model is counterfactually fair. In fact, CST extends counterfactual fairness (CF) of Kusner et al. (2017) by equipping CF with confidence intervals.</li>
</ul>

<h3>Title: Main Predicate and Their Arguments as Explanation Signals For Intent Classification</h3>
<ul>
<li><strong>Authors: </strong>Sameer Pimparkhede, Pushpak Bhattacharyya</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01270">https://arxiv.org/abs/2502.01270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01270">https://arxiv.org/pdf/2502.01270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01270]] Main Predicate and Their Arguments as Explanation Signals For Intent Classification(https://arxiv.org/abs/2502.01270)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Intent classification is crucial for conversational agents (chatbots), and deep learning models perform well in this area. However, little research has been done on the explainability of intent classification due to the absence of suitable benchmark data. Human annotation of explanation signals in text samples is time-consuming and costly. However, from inspection of data on intent classification, we see that, more often than not, the main verb denotes the action, and the direct object indicates the domain of conversation, serving as explanation signals for intent. This observation enables us to hypothesize that the main predicate in the text utterances, along with the arguments of the main predicate, can serve as explanation signals. Leveraging this, we introduce a new technique to automatically augment text samples from intent classification datasets with word-level explanations. We mark main predicates (primarily verbs) and their arguments (dependency relations) as explanation signals in benchmark intent classification datasets ATIS and SNIPS, creating a unique 21k-instance dataset for explainability. Further, we experiment with deep learning and language models. We observe that models that work well for classification do not perform well in explainability metrics like plausibility and faithfulness. We also observe that guiding models to focus on explanation signals from our dataset during training improves the plausibility Token F1 score by 3-4%, improving the model's reasoning.</li>
</ul>

<h3>Title: Boosting Graph Robustness Against Backdoor Attacks: An Over-Similarity Perspective</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01272">https://arxiv.org/abs/2502.01272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01272">https://arxiv.org/pdf/2502.01272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01272]] Boosting Graph Robustness Against Backdoor Attacks: An Over-Similarity Perspective(https://arxiv.org/abs/2502.01272)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have achieved notable success in tasks such as social and transportation networks. However, recent studies have highlighted the vulnerability of GNNs to backdoor attacks, raising significant concerns about their reliability in real-world applications. Despite initial efforts to defend against specific graph backdoor attacks, existing defense methods face two main challenges: either the inability to establish a clear distinction between triggers and clean nodes, resulting in the removal of many clean nodes, or the failure to eliminate the impact of triggers, making it challenging to restore the target nodes to their pre-attack state. Through empirical analysis of various existing graph backdoor attacks, we observe that the triggers generated by these methods exhibit over-similarity in both features and structure. Based on this observation, we propose a novel graph backdoor defense method SimGuard. We first utilizes a similarity-based metric to detect triggers and then employs contrastive learning to train a backdoor detector that generates embeddings capable of separating triggers from clean nodes, thereby improving detection efficiency. Extensive experiments conducted on real-world datasets demonstrate that our proposed method effectively defends against various graph backdoor attacks while preserving performance on clean nodes. The code will be released upon acceptance.</li>
</ul>

<h3>Title: HyperSHAP: Shapley Values and Interactions for Hyperparameter Importance</h3>
<ul>
<li><strong>Authors: </strong>Marcel Wever, Maximilian Muschalik, Fabian Fumagalli, Marius Lindauer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01276">https://arxiv.org/abs/2502.01276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01276">https://arxiv.org/pdf/2502.01276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01276]] HyperSHAP: Shapley Values and Interactions for Hyperparameter Importance(https://arxiv.org/abs/2502.01276)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Hyperparameter optimization (HPO) is a crucial step in achieving strong predictive performance. However, the impact of individual hyperparameters on model generalization is highly context-dependent, prohibiting a one-size-fits-all solution and requiring opaque automated machine learning (AutoML) systems to find optimal configurations. The black-box nature of most AutoML systems undermines user trust and discourages adoption. To address this, we propose a game-theoretic explainability framework for HPO that is based on Shapley values and interactions. Our approach provides an additive decomposition of a performance measure across hyperparameters, enabling local and global explanations of hyperparameter importance and interactions. The framework, named HyperSHAP, offers insights into ablations, the tunability of learning algorithms, and optimizer behavior across different hyperparameter spaces. We evaluate HyperSHAP on various HPO benchmarks by analyzing the interaction structure of the HPO problem. Our results show that while higher-order interactions exist, most performance improvements can be explained by focusing on lower-order representations.</li>
</ul>

<h3>Title: Label Correction for Road Segmentation Using Road-side Cameras</h3>
<ul>
<li><strong>Authors: </strong>Henrik Toikka, Eerik Alamikkotervo, Risto Ojala</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01281">https://arxiv.org/abs/2502.01281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01281">https://arxiv.org/pdf/2502.01281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01281]] Label Correction for Road Segmentation Using Road-side Cameras(https://arxiv.org/abs/2502.01281)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Reliable road segmentation in all weather conditions is critical for intelligent transportation applications, autonomous vehicles and advanced driver's assistance systems. For robust performance, all weather conditions should be included in the training data of deep learning-based perception models. However, collecting and annotating such a dataset requires extensive resources. In this paper, existing roadside camera infrastructure is utilized for collecting road data in varying weather conditions automatically. Additionally, a novel semi-automatic annotation method for roadside cameras is proposed. For each camera, only one frame is labeled manually and then the label is transferred to other frames of that camera feed. The small camera movements between frames are compensated using frequency domain image registration. The proposed method is validated with roadside camera data collected from 927 cameras across Finland over 4 month time period during winter. Training on the semi-automatically labeled data boosted the segmentation performance of several deep learning segmentation models. Testing was carried out on two different datasets to evaluate the robustness of the resulting models. These datasets were an in-domain roadside camera dataset and out-of-domain dataset captured with a vehicle on-board camera.</li>
</ul>

<h3>Title: A Framework for Double-Blind Federated Adaptation of Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Nurbek Tastan, Karthik Nandakumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01289">https://arxiv.org/abs/2502.01289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01289">https://arxiv.org/pdf/2502.01289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01289]] A Framework for Double-Blind Federated Adaptation of Foundation Models(https://arxiv.org/abs/2502.01289)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, extraction, federate</a></li>
<li><strong>Abstract: </strong>The availability of foundational models (FMs) pre-trained on large-scale data has advanced the state-of-the-art in many computer vision tasks. While FMs have demonstrated good zero-shot performance on many image classification tasks, there is often scope for performance improvement by adapting the FM to the downstream task. However, the data that is required for this adaptation typically exists in silos across multiple entities (data owners) and cannot be collated at a central location due to regulations and privacy concerns. At the same time, a learning service provider (LSP) who owns the FM cannot share the model with the data owners due to proprietary reasons. In some cases, the data owners may not even have the resources to store such large FMs. Hence, there is a need for algorithms to adapt the FM in a double-blind federated manner, i.e., the data owners do not know the FM or each other's data, and the LSP does not see the data for the downstream tasks. In this work, we propose a framework for double-blind federated adaptation of FMs using fully homomorphic encryption (FHE). The proposed framework first decomposes the FM into a sequence of FHE-friendly blocks through knowledge distillation. The resulting FHE-friendly model is adapted for the downstream task via low-rank parallel adapters that can be learned without backpropagation through the FM. Since the proposed framework requires the LSP to share intermediate representations with the data owners, we design a privacy-preserving permutation scheme to prevent the data owners from learning the FM through model extraction attacks. Finally, a secure aggregation protocol is employed for federated learning of the low-rank parallel adapters. Empirical results on four datasets demonstrate the practical feasibility of the proposed framework.</li>
</ul>

<h3>Title: XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications</h3>
<ul>
<li><strong>Authors: </strong>Shangjin Zhai, Nan Wang, Xiaomeng Wang, Danpeng Chen, Weijian Xie, Hujun Bao, Guofeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01297">https://arxiv.org/abs/2502.01297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01297">https://arxiv.org/pdf/2502.01297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01297]] XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications(https://arxiv.org/abs/2502.01297)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a novel approach to Visual Inertial Odometry (VIO), focusing on the initialization and feature matching modules. Existing methods for initialization often suffer from either poor stability in visual Structure from Motion (SfM) or fragility in solving a huge number of parameters simultaneously. To address these challenges, we propose a new pipeline for visual inertial initialization that robustly handles various complex scenarios. By tightly coupling gyroscope measurements, we enhance the robustness and accuracy of visual SfM. Our method demonstrates stable performance even with only four image frames, yielding competitive results. In terms of feature matching, we introduce a hybrid method that combines optical flow and descriptor-based matching. By leveraging the robustness of continuous optical flow tracking and the accuracy of descriptor matching, our approach achieves efficient, accurate, and robust tracking results. Through evaluation on multiple benchmarks, our method demonstrates state-of-the-art performance in terms of accuracy and success rate. Additionally, a video demonstration on mobile devices showcases the practical applicability of our approach in the field of Augmented Reality/Virtual Reality (AR/VR).</li>
</ul>

<h3>Title: Partial Channel Network: Compute Fewer, Perform Better</h3>
<ul>
<li><strong>Authors: </strong>Haiduo Huang, Tian Xia, Wenzhe zhao, Pengju Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01303">https://arxiv.org/abs/2502.01303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01303">https://arxiv.org/pdf/2502.01303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01303]] Partial Channel Network: Compute Fewer, Perform Better(https://arxiv.org/abs/2502.01303)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Designing a module or mechanism that enables a network to maintain low parameters and FLOPs without sacrificing accuracy and throughput remains a challenge. To address this challenge and exploit the redundancy within feature map channels, we propose a new solution: partial channel mechanism (PCM). Specifically, through the split operation, the feature map channels are divided into different parts, with each part corresponding to different operations, such as convolution, attention, pooling, and identity mapping. Based on this assumption, we introduce a novel partial attention convolution (PATConv) that can efficiently combine convolution with visual attention. Our exploration indicates that the PATConv can completely replace both the regular convolution and the regular visual attention while reducing model parameters and FLOPs. Moreover, PATConv can derive three new types of blocks: Partial Channel-Attention block (PAT_ch), Partial Spatial-Attention block (PAT_sp), and Partial Self-Attention block (PAT_sf). In addition, we propose a novel dynamic partial convolution (DPConv) that can adaptively learn the proportion of split channels in different layers to achieve better trade-offs. Building on PATConv and DPConv, we propose a new hybrid network family, named PartialNet, which achieves superior top-1 accuracy and inference speed compared to some SOTA models on ImageNet-1K classification and excels in both detection and segmentation on the COCO dataset. Our code is available at this https URL.</li>
</ul>

<h3>Title: Heterogeneous Image GNN: Graph-Conditioned Diffusion for Image Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Rupert Menneer, Christos Margadji, Sebastian W. Pattinson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01309">https://arxiv.org/abs/2502.01309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01309">https://arxiv.org/pdf/2502.01309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01309]] Heterogeneous Image GNN: Graph-Conditioned Diffusion for Image Synthesis(https://arxiv.org/abs/2502.01309)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce a novel method for conditioning diffusion-based image synthesis models with heterogeneous graph data. Existing approaches typically incorporate conditioning variables directly into model architectures, either through cross-attention layers that attend to text latents or image concatenation that spatially restrict generation. However, these methods struggle to handle complex scenarios involving diverse, relational conditioning variables, which are more naturally represented as unstructured graphs. This paper presents Heterogeneous Image Graphs (HIG), a novel representation that models conditioning variables and target images as two interconnected graphs, enabling efficient handling of variable-length conditioning inputs and their relationships. We also propose a magnitude-preserving GNN that integrates the HIG into the existing EDM2 diffusion model using a ControlNet approach. Our approach improves upon the SOTA on a variety of conditioning inputs for the COCO-stuff and Visual Genome datasets, and showcases the ability to condition on graph attributes and relationships represented by edges in the HIG.</li>
</ul>

<h3>Title: A Statistical Learning Perspective on Semi-dual Adversarial Neural Optimal Transport Solvers</h3>
<ul>
<li><strong>Authors: </strong>Roman Tarasov, Petr Mokrov, Milena Gazdieva, Evgeny Burnaev, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01310">https://arxiv.org/abs/2502.01310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01310">https://arxiv.org/pdf/2502.01310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01310]] A Statistical Learning Perspective on Semi-dual Adversarial Neural Optimal Transport Solvers(https://arxiv.org/abs/2502.01310)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Neural network based Optimal Transport (OT) is a recent and fruitful direction in the generative modeling community. It finds its applications in various fields such as domain translation, image super-resolution, computational biology and others. Among the existing approaches to OT, of considerable interest are adversarial minimax solvers based on semi-dual formulations of OT problems. While promising, these methods lack theoretical investigation from a statistical learning perspective. Our work fills this gap by establishing upper bounds on the generalization error of an approximate OT map recovered by the minimax quadratic OT solver. Importantly, the bounds we derive depend solely on some standard statistical and mathematical properties of the considered functional classes (neural networks). While our analysis focuses on the quadratic OT, we believe that similar bounds could be derived for more general OT formulations, paving the promising direction for future research.</li>
</ul>

<h3>Title: Learning Fused State Representations for Control from Multi-View Observations</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Wang, Yao-Hui Li, Xin Li, Hongyu Zang, Romain Laroche, Riashat Islam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01316">https://arxiv.org/abs/2502.01316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01316">https://arxiv.org/pdf/2502.01316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01316]] Learning Fused State Representations for Control from Multi-View Observations(https://arxiv.org/abs/2502.01316)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-View Reinforcement Learning (MVRL) seeks to provide agents with multi-view observations, enabling them to perceive environment with greater effectiveness and precision. Recent advancements in MVRL focus on extracting latent representations from multiview observations and leveraging them in control tasks. However, it is not straightforward to learn compact and task-relevant representations, particularly in the presence of redundancy, distracting information, or missing views. In this paper, we propose Multi-view Fusion State for Control (MFSC), firstly incorporating bisimulation metric learning into MVRL to learn task-relevant representations. Furthermore, we propose a multiview-based mask and latent reconstruction auxiliary task that exploits shared information across views and improves MFSC's robustness in missing views by introducing a mask token. Extensive experimental results demonstrate that our method outperforms existing approaches in MVRL tasks. Even in more realistic scenarios with interference or missing views, MFSC consistently maintains high performance.</li>
</ul>

<h3>Title: ConceptVAE: Self-Supervised Fine-Grained Concept Disentanglement from 2D Echocardiographies</h3>
<ul>
<li><strong>Authors: </strong>Costin F. Ciusdel, Alex Serban, Tiziano Passerini</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01335">https://arxiv.org/abs/2502.01335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01335">https://arxiv.org/pdf/2502.01335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01335]] ConceptVAE: Self-Supervised Fine-Grained Concept Disentanglement from 2D Echocardiographies(https://arxiv.org/abs/2502.01335)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>While traditional self-supervised learning methods improve performance and robustness across various medical tasks, they rely on single-vector embeddings that may not capture fine-grained concepts such as anatomical structures or organs. The ability to identify such concepts and their characteristics without supervision has the potential to improve pre-training methods, and enable novel applications such as fine-grained image retrieval and concept-based outlier detection. In this paper, we introduce ConceptVAE, a novel pre-training framework that detects and disentangles fine-grained concepts from their style characteristics in a self-supervised manner. We present a suite of loss terms and model architecture primitives designed to discretise input data into a preset number of concepts along with their local style. We validate ConceptVAE both qualitatively and quantitatively, demonstrating its ability to detect fine-grained anatomical structures such as blood pools and septum walls from 2D cardiac echocardiographies. Quantitatively, ConceptVAE outperforms traditional self-supervised methods in tasks such as region-based instance retrieval, semantic segmentation, out-of-distribution detection, and object detection. Additionally, we explore the generation of in-distribution synthetic data that maintains the same concepts as the training data but with distinct styles, highlighting its potential for more calibrated data generation. Overall, our study introduces and validates a promising new pre-training technique based on concept-style disentanglement, opening multiple avenues for developing models for medical image analysis that are more interpretable and explainable than black-box approaches.</li>
</ul>

<h3>Title: Reducing Ciphertext and Key Sizes for MLWE-Based Cryptosystems</h3>
<ul>
<li><strong>Authors: </strong>Georg Maringer, Antonia Wachter-Zeh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01339">https://arxiv.org/abs/2502.01339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01339">https://arxiv.org/pdf/2502.01339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01339]] Reducing Ciphertext and Key Sizes for MLWE-Based Cryptosystems(https://arxiv.org/abs/2502.01339)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The concatenation of encryption and decryption can be interpreted as data transmission over a noisy communication channel. In this work, we use finite blocklength methods (normal approximation and random coding union bound) as well as asymptotics to show that ciphertext and key sizes of the state-of-the-art post-quantum secure key encapsulation mechanism (KEM) Kyber can be reduced without compromising the security of the scheme. We show that in the asymptotic regime, it is possible to reduce the sizes of ciphertexts and secret keys by 25% for the parameter set Kyber1024 while keeping the bitrate at 1 as proposed in the original scheme. For a single Kyber encryption block used to share a 256-bit AES key, we furthermore show that reductions in ciphertext size of 39% and 33% are possible for Kyber1024 and Kyber512, respectively.</li>
</ul>

<h3>Title: AlignVLM: Bridging Vision and Language Latent Spaces for Multimodal Understanding</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Masry, Juan A. Rodriguez, Tianyu Zhang, Suyuchen Wang, Chao Wang, Aarash Feizi, Akshay Kalkunte Suresh, Abhay Puri, Xiangru Jian, Pierre-André Noël, Sathwik Tejaswi Madhusudhan, Marco Pedersoli, Bang Liu, Nicolas Chapados, Yoshua Bengio, Enamul Hoque, Christopher Pal, Issam H. Laradji, David Vazquez, Perouz Taslakian, Spandana Gella, Sai Rajeswar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01341">https://arxiv.org/abs/2502.01341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01341">https://arxiv.org/pdf/2502.01341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01341]] AlignVLM: Bridging Vision and Language Latent Spaces for Multimodal Understanding(https://arxiv.org/abs/2502.01341)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Aligning visual features with language embeddings is a key challenge in vision-language models (VLMs). The performance of such models hinges on having a good connector that maps visual features generated by a vision encoder to a shared embedding space with the LLM while preserving semantic similarity. Existing connectors, such as multilayer perceptrons (MLPs), often produce out-of-distribution or noisy inputs, leading to misalignment between the modalities. In this work, we propose a novel vision-text alignment method, AlignVLM, that maps visual features to a weighted average of LLM text embeddings. Our approach leverages the linguistic priors encoded by the LLM to ensure that visual features are mapped to regions of the space that the LLM can effectively interpret. AlignVLM is particularly effective for document understanding tasks, where scanned document images must be accurately mapped to their textual content. Our extensive experiments show that AlignVLM achieves state-of-the-art performance compared to prior alignment methods. We provide further analysis demonstrating improved vision-text feature alignment and robustness to noise.</li>
</ul>

<h3>Title: Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations</h3>
<ul>
<li><strong>Authors: </strong>Giorgos Filandrianos, Angeliki Dimitriou, Maria Lymperaiou, Konstantinos Thomas, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01349">https://arxiv.org/abs/2502.01349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01349">https://arxiv.org/pdf/2502.01349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01349]] Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations(https://arxiv.org/abs/2502.01349)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) has revolutionized product recommendation systems, yet their susceptibility to adversarial manipulation poses critical challenges, particularly in real-world commercial applications. Our approach is the first one to tap into human psychological principles, seamlessly modifying product descriptions, making these adversarial manipulations hard to detect. In this work, we investigate cognitive biases as black-box adversarial strategies, drawing parallels between their effects on LLMs and human purchasing behavior. Through extensive experiments on LLMs of varying scales, we reveal significant vulnerabilities in their use as recommenders, providing critical insights into safeguarding these systems.</li>
</ul>

<h3>Title: Metric Privacy in Federated Learning for Medical Imaging: Improving Convergence and Preventing Client Inference Attacks</h3>
<ul>
<li><strong>Authors: </strong>Judith Sáinz-Pardo Díaz, Andreas Athanasiou, Kangsoo Jung, Catuscia Palamidessi, Álvaro López García</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01352">https://arxiv.org/abs/2502.01352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01352">https://arxiv.org/pdf/2502.01352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01352]] Metric Privacy in Federated Learning for Medical Imaging: Improving Convergence and Preventing Client Inference Attacks(https://arxiv.org/abs/2502.01352)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a distributed learning technique that allows training a global model with the participation of different data owners without the need to share raw data. This architecture is orchestrated by a central server that aggregates the local models from the clients. This server may be trusted, but not all nodes in the network. Then, differential privacy (DP) can be used to privatize the global model by adding noise. However, this may affect convergence across the rounds of the federated architecture, depending also on the aggregation strategy employed. In this work, we aim to introduce the notion of metric-privacy to mitigate the impact of classical server side global-DP on the convergence of the aggregated model. Metric-privacy is a relaxation of DP, suitable for domains provided with a notion of distance. We apply it from the server side by computing a distance for the difference between the local models. We compare our approach with standard DP by analyzing the impact on six classical aggregation strategies. The proposed methodology is applied to an example of medical imaging and different scenarios are simulated across homogeneous and non-i.i.d clients. Finally, we introduce a novel client inference attack, where a semi-honest client tries to find whether another client participated in the training and study how it can be mitigated using DP and metric-privacy. Our evaluation shows that metric-privacy can increase the performance of the model compared to standard DP, while offering similar protection against client inference attacks.</li>
</ul>

<h3>Title: Quasi-Conformal Convolution : A Learnable Convolution for Deep Learning on Riemann Surfaces</h3>
<ul>
<li><strong>Authors: </strong>Han Zhang, Tsz Lok Ip, Lok Ming Lui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01356">https://arxiv.org/abs/2502.01356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01356">https://arxiv.org/pdf/2502.01356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01356]] Quasi-Conformal Convolution : A Learnable Convolution for Deep Learning on Riemann Surfaces(https://arxiv.org/abs/2502.01356)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning on non-Euclidean domains is important for analyzing complex geometric data that lacks common coordinate systems and familiar Euclidean properties. A central challenge in this field is to define convolution on domains, which inherently possess irregular and non-Euclidean this http URL this work, we introduce Quasi-conformal Convolution (QCC), a novel framework for defining convolution on Riemann surfaces using quasi-conformal theories. Each QCC operator is linked to a specific quasi-conformal mapping, enabling the adjustment of the convolution operation through manipulation of this mapping. By utilizing trainable estimator modules that produce Quasi-conformal mappings, QCC facilitates adaptive and learnable convolution operators that can be dynamically adjusted according to the underlying data structured on Riemann surfaces. QCC unifies a broad range of spatially defined convolutions, facilitating the learning of tailored convolution operators on each underlying surface optimized for specific tasks. Building on this foundation, we develop the Quasi-Conformal Convolutional Neural Network (QCCNN) to address a variety of tasks related to geometric data. We validate the efficacy of QCCNN through the classification of images defined on curvilinear Riemann surfaces, demonstrating superior performance in this context. Additionally, we explore its potential in medical applications, including craniofacial analysis using 3D facial data and lesion segmentation on 3D human faces, achieving enhanced accuracy and reliability.</li>
</ul>

<h3>Title: Bayesian Approximation-Based Trajectory Prediction and Tracking with 4D Radar</h3>
<ul>
<li><strong>Authors: </strong>Dong-In Kim, Dong-Hee Paek, Seung-Hyun Song, Seung-Hyun Kong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01357">https://arxiv.org/abs/2502.01357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01357">https://arxiv.org/pdf/2502.01357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01357]] Bayesian Approximation-Based Trajectory Prediction and Tracking with 4D Radar(https://arxiv.org/abs/2502.01357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurate 3D multi-object tracking (MOT) is vital for autonomous vehicles, yet LiDAR and camera-based methods degrade in adverse weather. Meanwhile, Radar-based solutions remain robust but often suffer from limited vertical resolution and simplistic motion models. Existing Kalman filter-based approaches also rely on fixed noise covariance, hampering adaptability when objects make sudden maneuvers. We propose Bayes-4DRTrack, a 4D Radar-based MOT framework that adopts a transformer-based motion prediction network to capture nonlinear motion dynamics and employs Bayesian approximation in both detection and prediction steps. Moreover, our two-stage data association leverages Doppler measurements to better distinguish closely spaced targets. Evaluated on the K-Radar dataset (including adverse weather scenarios), Bayes-4DRTrack demonstrates a 5.7% gain in Average Multi-Object Tracking Accuracy (AMOTA) over methods with traditional motion models and fixed noise covariance. These results showcase enhanced robustness and accuracy in demanding, real-world conditions.</li>
</ul>

<h3>Title: Inverse Bridge Matching Distillation</h3>
<ul>
<li><strong>Authors: </strong>Nikita Gushchin, David Li, Daniil Selikhanovych, Evgeny Burnaev, Dmitry Baranchuk, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01362">https://arxiv.org/abs/2502.01362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01362">https://arxiv.org/pdf/2502.01362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01362]] Inverse Bridge Matching Distillation(https://arxiv.org/abs/2502.01362)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Learning diffusion bridge models is easy; making them fast and practical is an art. Diffusion bridge models (DBMs) are a promising extension of diffusion models for applications in image-to-image translation. However, like many modern diffusion and flow models, DBMs suffer from the problem of slow inference. To address it, we propose a novel distillation technique based on the inverse bridge matching formulation and derive the tractable objective to solve it in practice. Unlike previously developed DBM distillation techniques, the proposed method can distill both conditional and unconditional types of DBMs, distill models in a one-step generator, and use only the corrupted images for training. We evaluate our approach for both conditional and unconditional types of bridge matching on a wide set of setups, including super-resolution, JPEG restoration, sketch-to-image, and other tasks, and show that our distillation technique allows us to accelerate the inference of DBMs from 4x to 100x and even provide better generation quality than used teacher model depending on particular setup.</li>
</ul>

<h3>Title: CE-LoRA: Computation-Efficient LoRA Fine-Tuning for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guanduo Chen, Yutong He, Yipeng Hu, Kun Yuan, Binhang Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01378">https://arxiv.org/abs/2502.01378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01378">https://arxiv.org/pdf/2502.01378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01378]] CE-LoRA: Computation-Efficient LoRA Fine-Tuning for Language Models(https://arxiv.org/abs/2502.01378)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate exceptional performance across various tasks but demand substantial computational resources even for fine-tuning computation. Although Low-Rank Adaptation (LoRA) significantly alleviates memory consumption during fine-tuning, its impact on computational cost reduction is limited. This paper identifies the computation of activation gradients as the primary bottleneck in LoRA's backward propagation and introduces the Computation-Efficient LoRA (CE-LoRA) algorithm, which enhances computational efficiency while preserving memory efficiency. CE-LoRA leverages two key techniques: Approximated Matrix Multiplication, which replaces dense multiplications of large and complete matrices with sparse multiplications involving only critical rows and columns, and the Double-LoRA technique, which reduces error propagation in activation gradients. Theoretically, CE-LoRA converges at the same rate as LoRA, $ \mathcal{O}(1/\sqrt{T}) $, where $T$ is the number of iteartions. Empirical evaluations confirm that CE-LoRA significantly reduces computational costs compared to LoRA without notable performance degradation.</li>
</ul>

<h3>Title: InfoBridge: Mutual Information estimation via Bridge Matching</h3>
<ul>
<li><strong>Authors: </strong>Sergei Kholkin, Ivan Butakov, Evgeny Burnaev, Nikita Gushchin, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01383">https://arxiv.org/abs/2502.01383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01383">https://arxiv.org/pdf/2502.01383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01383]] InfoBridge: Mutual Information estimation via Bridge Matching(https://arxiv.org/abs/2502.01383)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion bridge models have recently become a powerful tool in the field of generative modeling. In this work, we leverage their power to address another important problem in machine learning and information theory - the estimation of the mutual information (MI) between two random variables. We show that by using the theory of diffusion bridges, one can construct an unbiased estimator for data posing difficulties for conventional MI estimators. We showcase the performance of our estimator on a series of standard MI estimation benchmarks.</li>
</ul>

<h3>Title: Detecting Backdoor Samples in Contrastive Language Image Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Hanxun Huang, Sarah Erfani, Yige Li, Xingjun Ma, James Bailey</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01385">https://arxiv.org/abs/2502.01385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01385">https://arxiv.org/pdf/2502.01385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01385]] Detecting Backdoor Samples in Contrastive Language Image Pretraining(https://arxiv.org/abs/2502.01385)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Contrastive language-image pretraining (CLIP) has been found to be vulnerable to poisoning backdoor attacks where the adversary can achieve an almost perfect attack success rate on CLIP models by poisoning only 0.01\% of the training dataset. This raises security concerns on the current practice of pretraining large-scale models on unscrutinized web data using CLIP. In this work, we analyze the representations of backdoor-poisoned samples learned by CLIP models and find that they exhibit unique characteristics in their local subspace, i.e., their local neighborhoods are far more sparse than that of clean samples. Based on this finding, we conduct a systematic study on detecting CLIP backdoor attacks and show that these attacks can be easily and efficiently detected by traditional density ratio-based local outlier detectors, whereas existing backdoor sample detection methods fail. Our experiments also reveal that an unintentional backdoor already exists in the original CC3M dataset and has been trained into a popular open-source model released by OpenCLIP. Based on our detector, one can clean up a million-scale web dataset (e.g., CC3M) efficiently within 15 minutes using 4 Nvidia A100 GPUs. The code is publicly available in our \href{this https URL}{GitHub repository}.</li>
</ul>

<h3>Title: Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models</h3>
<ul>
<li><strong>Authors: </strong>Yuyang Gong, Zhuo Chen, Miaokun Chen, Fengchang Yu, Wei Lu, Xiaofeng Wang, Xiaozhong Liu, Jiawei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01386">https://arxiv.org/abs/2502.01386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01386">https://arxiv.org/pdf/2502.01386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01386]] Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models(https://arxiv.org/abs/2502.01386)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become essential for tasks such as question answering and content generation. However, their increasing impact on public opinion and information dissemination has made them a critical focus for security research due to inherent vulnerabilities. Previous studies have predominantly addressed attacks targeting factual or single-query manipulations. In this paper, we address a more practical scenario: topic-oriented adversarial opinion manipulation attacks on RAG models, where LLMs are required to reason and synthesize multiple perspectives, rendering them particularly susceptible to systematic knowledge poisoning. Specifically, we propose Topic-FlipRAG, a two-stage manipulation attack pipeline that strategically crafts adversarial perturbations to influence opinions across related queries. This approach combines traditional adversarial ranking attack techniques and leverages the extensive internal relevant knowledge and reasoning capabilities of LLMs to execute semantic-level perturbations. Experiments show that the proposed attacks effectively shift the opinion of the model's outputs on specific topics, significantly impacting user information perception. Current mitigation methods cannot effectively defend against such attacks, highlighting the necessity for enhanced safeguards for RAG systems, and offering crucial insights for LLM security research.</li>
</ul>

<h3>Title: Learning Traffic Anomalies from Generative Models on Real-Time Observations</h3>
<ul>
<li><strong>Authors: </strong>Fotis I. Giasemis, Alexandros Sopasakis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01391">https://arxiv.org/abs/2502.01391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01391">https://arxiv.org/pdf/2502.01391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01391]] Learning Traffic Anomalies from Generative Models on Real-Time Observations(https://arxiv.org/abs/2502.01391)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurate detection of traffic anomalies is crucial for effective urban traffic management and congestion mitigation. We use the Spatiotemporal Generative Adversarial Network (STGAN) framework combining Graph Neural Networks and Long Short-Term Memory networks to capture complex spatial and temporal dependencies in traffic data. We apply STGAN to real-time, minute-by-minute observations from 42 traffic cameras across Gothenburg, Sweden, collected over several months in 2020. The images are processed to compute a flow metric representing vehicle density, which serves as input for the model. Training is conducted on data from April to November 2020, and validation is performed on a separate dataset from November 14 to 23, 2020. Our results demonstrate that the model effectively detects traffic anomalies with high precision and low false positive rates. The detected anomalies include camera signal interruptions, visual artifacts, and extreme weather conditions affecting traffic flow.</li>
</ul>

<h3>Title: Annotation Tool and Dataset for Fact-Checking Podcasts</h3>
<ul>
<li><strong>Authors: </strong>Vinay Setty, Adam James Becker</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01402">https://arxiv.org/abs/2502.01402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01402">https://arxiv.org/pdf/2502.01402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01402]] Annotation Tool and Dataset for Fact-Checking Podcasts(https://arxiv.org/abs/2502.01402)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Podcasts are a popular medium on the web, featuring diverse and multilingual content that often includes unverified claims. Fact-checking podcasts is a challenging task, requiring transcription, annotation, and claim verification, all while preserving the contextual details of spoken content. Our tool offers a novel approach to tackle these challenges by enabling real-time annotation of podcasts during playback. This unique capability allows users to listen to the podcast and annotate key elements, such as check-worthy claims, claim spans, and contextual errors, simultaneously. By integrating advanced transcription models like OpenAI's Whisper and leveraging crowdsourced annotations, we create high-quality datasets to fine-tune multilingual transformer models such as XLM-RoBERTa for tasks like claim detection and stance classification. Furthermore, we release the annotated podcast transcripts and sample annotations with preliminary experiments.</li>
</ul>

<h3>Title: AdaSVD: Adaptive Singular Value Decomposition for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Li Zhiteng, Xia Mingyuan, Zhang Jingyuan, Hui Zheng, Kong Linghe, Zhang Yulun, Yang Xiaokang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01403">https://arxiv.org/abs/2502.01403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01403">https://arxiv.org/pdf/2502.01403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01403]] AdaSVD: Adaptive Singular Value Decomposition for Large Language Models(https://arxiv.org/abs/2502.01403)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success in natural language processing (NLP) tasks, yet their substantial memory requirements present significant challenges for deployment on resource-constrained devices. Singular Value Decomposition (SVD) has emerged as a promising compression technique for LLMs, offering considerable reductions in memory overhead. However, existing SVD-based methods often struggle to effectively mitigate the errors introduced by SVD truncation, leading to a noticeable performance gap when compared to the original models. Furthermore, applying a uniform compression ratio across all transformer layers fails to account for the varying importance of different layers. To address these challenges, we propose AdaSVD, an adaptive SVD-based LLM compression approach. Specifically, AdaSVD introduces adaComp, which adaptively compensates for SVD truncation errors by alternately updating the singular matrices U and V^T. Additionally, AdaSVD introduces adaCR, which adaptively assigns layer-specific compression ratios based on the relative importance of each layer. Extensive experiments across multiple LLM families and evaluation metrics demonstrate that AdaSVD consistently outperforms state-of-the-art (SOTA) SVD-based methods, achieving superior performance with significantly reduced memory requirements. The code and models will be available at this https URL.</li>
</ul>

<h3>Title: FourieRF: Few-Shot NeRFs via Progressive Fourier Frequency Control</h3>
<ul>
<li><strong>Authors: </strong>Diego Gomez, Bingchen Gong, Maks Ovsjanikov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01405">https://arxiv.org/abs/2502.01405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01405">https://arxiv.org/pdf/2502.01405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01405]] FourieRF: Few-Shot NeRFs via Progressive Fourier Frequency Control(https://arxiv.org/abs/2502.01405)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we introduce FourieRF, a novel approach for achieving fast and high-quality reconstruction in the few-shot setting. Our method effectively parameterizes features through an explicit curriculum training procedure, incrementally increasing scene complexity during optimization. Experimental results show that the prior induced by our approach is both robust and adaptable across a wide variety of scenes, establishing FourieRF as a strong and versatile baseline for the few-shot rendering problem. While our approach significantly reduces artifacts, it may still lead to reconstruction errors in severely under-constrained scenarios, particularly where view occlusion leaves parts of the shape uncovered. In the future, our method could be enhanced by integrating foundation models to complete missing parts using large data-driven priors.</li>
</ul>

<h3>Title: GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Drechsel, Steffen Herbold</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01406">https://arxiv.org/abs/2502.01406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01406">https://arxiv.org/pdf/2502.01406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01406]] GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models(https://arxiv.org/abs/2502.01406)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>AI systems frequently exhibit and amplify social biases, including gender bias, leading to harmful consequences in critical areas. This study introduces a novel encoder-decoder approach that leverages model gradients to learn a single monosemantic feature neuron encoding gender information. We show that our method can be used to debias transformer-based language models, while maintaining other capabilities. We demonstrate the effectiveness of our approach across multiple encoder-only based models and highlight its potential for broader applications.</li>
</ul>

<h3>Title: Human Body Restoration with One-Step Diffusion Model and A New Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Jue Gong, Jingkai Wang, Zheng Chen, Xing Liu, Hong Gu, Yulun Zhang, Xiaokang Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01411">https://arxiv.org/abs/2502.01411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01411">https://arxiv.org/pdf/2502.01411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01411]] Human Body Restoration with One-Step Diffusion Model and A New Benchmark(https://arxiv.org/abs/2502.01411)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Human body restoration, as a specific application of image restoration, is widely applied in practice and plays a vital role across diverse fields. However, thorough research remains difficult, particularly due to the lack of benchmark datasets. In this study, we propose a high-quality dataset automated cropping and filtering (HQ-ACF) pipeline. This pipeline leverages existing object detection datasets and other unlabeled images to automatically crop and filter high-quality human images. Using this pipeline, we constructed a person-based restoration with sophisticated objects and natural activities (\emph{PERSONA}) dataset, which includes training, validation, and test sets. The dataset significantly surpasses other human-related datasets in both quality and content richness. Finally, we propose \emph{OSDHuman}, a novel one-step diffusion model for human body restoration. Specifically, we propose a high-fidelity image embedder (HFIE) as the prompt generator to better guide the model with low-quality human image information, effectively avoiding misleading prompts. Experimental results show that OSDHuman outperforms existing methods in both visual quality and quantitative metrics. The dataset and code will at this https URL.</li>
</ul>

<h3>Title: Categorical Schr\"odinger Bridge Matching</h3>
<ul>
<li><strong>Authors: </strong>Grigoriy Ksenofontov, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01416">https://arxiv.org/abs/2502.01416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01416">https://arxiv.org/pdf/2502.01416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01416]] Categorical Schr\"odinger Bridge Matching(https://arxiv.org/abs/2502.01416)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The Schrödinger Bridge (SB) is a powerful framework for solving generative modeling tasks such as unpaired domain translation. Most SB-related research focuses on continuous data space $\mathbb{R}^{D}$ and leaves open theoretical and algorithmic questions about applying SB methods to discrete data, e.g, on finite spaces $\mathbb{S}^{D}$. Notable examples of such sets $\mathbb{S}$ are codebooks of vector-quantized (VQ) representations of modern autoencoders, tokens in texts, categories of atoms in molecules, etc. In this paper, we provide a theoretical and algorithmic foundation for solving SB in discrete spaces using the recently introduced Iterative Markovian Fitting (IMF) procedure. Specifically, we theoretically justify the convergence of discrete-time IMF (D-IMF) to SB in discrete spaces. This enables us to develop a practical computational algorithm for SB which we call Categorical Schrödinger Bridge Matching (CSBM). We show the performance of CSBM via a series of experiments with synthetic data and VQ representations of images.</li>
</ul>

<h3>Title: Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mingi Jung, Saehuyng Lee, Eunji Kim, Sungroh Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01419">https://arxiv.org/abs/2502.01419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01419">https://arxiv.org/pdf/2502.01419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01419]] Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models(https://arxiv.org/abs/2502.01419)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detailed image captioning is essential for tasks like data generation and aiding visually impaired individuals. High-quality captions require a balance between precision and recall, which remains challenging for current multimodal large language models (MLLMs). In this work, we hypothesize that this limitation stems from weakening and increasingly noisy visual attention as responses lengthen. To address this issue, we propose SPARC (Selective Progressive Attention ReCalibration), a training-free method that enhances the contribution of visual tokens during decoding. SPARC is founded on three key observations: (1) increasing the influence of all visual tokens reduces recall; thus, SPARC selectively amplifies visual tokens; (2) as captions lengthen, visual attention becomes noisier, so SPARC identifies critical visual tokens by leveraging attention differences across time steps; (3) as visual attention gradually weakens, SPARC reinforces it to preserve its influence. Our experiments, incorporating both automated and human evaluations, demonstrate that existing methods improve the precision of MLLMs at the cost of recall. In contrast, our proposed method enhances both precision and recall with minimal computational overhead.</li>
</ul>

<h3>Title: Molecular Odor Prediction Based on Multi-Feature Graph Attention Networks</h3>
<ul>
<li><strong>Authors: </strong>HongXin Xie, JianDe Sun, Yi Shao, Shuai Li, Sujuan Hou, YuLong Sun, Jian Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01430">https://arxiv.org/abs/2502.01430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01430">https://arxiv.org/pdf/2502.01430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01430]] Molecular Odor Prediction Based on Multi-Feature Graph Attention Networks(https://arxiv.org/abs/2502.01430)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Olfactory perception plays a critical role in both human and organismal interactions, yet understanding of its underlying mechanisms and influencing factors remain insufficient. Molecular structures influence odor perception through intricate biochemical interactions, and accurately quantifying structure-odor relationships presents significant challenges. The Quantitative Structure-Odor Relationship (QSOR) task, which involves predicting the associations between molecular structures and their corresponding odors, seeks to address these challenges. To this end, we propose a method for QSOR, utilizing Graph Attention Networks to model molecular structures and capture both local and global features. Unlike conventional QSOR approaches reliant on predefined descriptors, our method leverages diverse molecular feature extraction techniques to automatically learn comprehensive representations. This integration enhances the model's capacity to handle complex molecular information, improves prediction accuracy. Our approach demonstrates clear advantages in QSOR prediction tasks, offering valuable insights into the application of deep learning in cheminformatics.</li>
</ul>

<h3>Title: Emergent Stack Representations in Modeling Counter Languages Using Transformers</h3>
<ul>
<li><strong>Authors: </strong>Utkarsh Tiwari, Aviral Gupta, Michael Hahn</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01432">https://arxiv.org/abs/2502.01432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01432">https://arxiv.org/pdf/2502.01432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01432]] Emergent Stack Representations in Modeling Counter Languages Using Transformers(https://arxiv.org/abs/2502.01432)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer architectures are the backbone of most modern language models, but understanding the inner workings of these models still largely remains an open problem. One way that research in the past has tackled this problem is by isolating the learning capabilities of these architectures by training them over well-understood classes of formal languages. We extend this literature by analyzing models trained over counter languages, which can be modeled using counter variables. We train transformer models on 4 counter languages, and equivalently formulate these languages using stacks, whose depths can be understood as the counter values. We then probe their internal representations for stack depths at each input token to show that these models when trained as next token predictors learn stack-like representations. This brings us closer to understanding the algorithmic details of how transformers learn languages and helps in circuit discovery.</li>
</ul>

<h3>Title: Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs</h3>
<ul>
<li><strong>Authors: </strong>David Rodriguez, William Seymour, Jose M. Del Alamo, Jose Such</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01436">https://arxiv.org/abs/2502.01436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01436">https://arxiv.org/pdf/2502.01436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01436]] Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs(https://arxiv.org/abs/2502.01436)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have gained unprecedented prominence, achieving widespread adoption across diverse domains and integrating deeply into society. The capability to fine-tune general-purpose LLMs, such as Generative Pre-trained Transformers (GPT), for specific tasks has facilitated the emergence of numerous Custom GPTs. These tailored models are increasingly made available through dedicated marketplaces, such as OpenAI's GPT Store. However, their black-box nature introduces significant safety and compliance risks. In this work, we present a scalable framework for the automated evaluation of Custom GPTs against OpenAI's usage policies, which define the permissible behaviors of these systems. Our framework integrates three core components: (1) automated discovery and data collection of models from the GPT store, (2) a red-teaming prompt generator tailored to specific policy categories and the characteristics of each target GPT, and (3) an LLM-as-a-judge technique to analyze each prompt-response pair for potential policy violations. We validate our framework with a manually annotated ground truth, and evaluate it through a large-scale study with 782 Custom GPTs across three categories: Romantic, Cybersecurity, and Academic GPTs. Our manual annotation process achieved an F1 score of 0.975 in identifying policy violations, confirming the reliability of the framework's assessments. The results reveal that 58.7% of the analyzed models exhibit indications of non-compliance, exposing weaknesses in the GPT store's review and approval processes. Furthermore, our findings indicate that a model's popularity does not correlate with compliance, and non-compliance issues largely stem from behaviors inherited from base models rather than user-driven customizations. We believe this approach is extendable to other chatbot platforms and policy domains, improving LLM-based systems safety.</li>
</ul>

<h3>Title: Improved Training Technique for Latent Consistency Models</h3>
<ul>
<li><strong>Authors: </strong>Quan Dao, Khanh Doan, Di Liu, Trung Le, Dimitris Metaxas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01441">https://arxiv.org/abs/2502.01441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01441">https://arxiv.org/pdf/2502.01441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01441]] Improved Training Technique for Latent Consistency Models(https://arxiv.org/abs/2502.01441)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Consistency models are a new family of generative models capable of producing high-quality samples in either a single step or multiple steps. Recently, consistency models have demonstrated impressive performance, achieving results on par with diffusion models in the pixel space. However, the success of scaling consistency training to large-scale datasets, particularly for text-to-image and video generation tasks, is determined by performance in the latent space. In this work, we analyze the statistical differences between pixel and latent spaces, discovering that latent data often contains highly impulsive outliers, which significantly degrade the performance of iCT in the latent space. To address this, we replace Pseudo-Huber losses with Cauchy losses, effectively mitigating the impact of outliers. Additionally, we introduce a diffusion loss at early timesteps and employ optimal transport (OT) coupling to further enhance performance. Lastly, we introduce the adaptive scaling-$c$ scheduler to manage the robust training process and adopt Non-scaling LayerNorm in the architecture to better capture the statistics of the features and reduce outlier impact. With these strategies, we successfully train latent consistency models capable of high-quality sampling with one or two steps, significantly narrowing the performance gap between latent consistency and diffusion models. The implementation is released here: this https URL</li>
</ul>

<h3>Title: SPFFNet: Strip Perception and Feature Fusion Spatial Pyramid Pooling for Fabric Defect Detection</h3>
<ul>
<li><strong>Authors: </strong>Peizhe Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01445">https://arxiv.org/abs/2502.01445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01445">https://arxiv.org/pdf/2502.01445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01445]] SPFFNet: Strip Perception and Feature Fusion Spatial Pyramid Pooling for Fabric Defect Detection(https://arxiv.org/abs/2502.01445)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Defect detection in fabrics is critical for quality control, yet existing methods often struggle with complex backgrounds and shape-specific defects. In this paper, we propose an improved fabric defect detection model based on YOLOv4. To enhance the detection of strip defects, we introduce a Strip Perception Module (SPM) that improves feature capture through multi-scale convolution. We further enhance the spatial pyramid pooling fast (SPPF) by integrating a squeeze-and-excitation mechanism, resulting in the SE-SPPF module, which better integrates spatial and channel information for more effective defect feature extraction. Additionally, we propose a novel focal enhanced complete intersection over union (FECIoU) metric with adaptive weights, addressing scale differences and class imbalance by adjusting the weights of hard-to-detect instances through focal loss. Experimental results demonstrate that our model achieves a 0.8-8.1% improvement in mean average precision (mAP) on the Tianchi dataset and a 1.6-13.2% improvement on our custom dataset, outperforming other state-of-the-art methods.</li>
</ul>

<h3>Title: Temporal-consistent CAMs for Weakly Supervised Video Segmentation in Waste Sorting</h3>
<ul>
<li><strong>Authors: </strong>Andrea Marelli, Luca Magri, Federica Arrigoni, Giacomo Boracchi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01455">https://arxiv.org/abs/2502.01455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01455">https://arxiv.org/pdf/2502.01455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01455]] Temporal-consistent CAMs for Weakly Supervised Video Segmentation in Waste Sorting(https://arxiv.org/abs/2502.01455)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In industrial settings, weakly supervised (WS) methods are usually preferred over their fully supervised (FS) counterparts as they do not require costly manual annotations. Unfortunately, the segmentation masks obtained in the WS regime are typically poor in terms of accuracy. In this work, we present a WS method capable of producing accurate masks for semantic segmentation in the case of video streams. More specifically, we build saliency maps that exploit the temporal coherence between consecutive frames in a video, promoting consistency when objects appear in different frames. We apply our method in a waste-sorting scenario, where we perform weakly supervised video segmentation (WSVS) by training an auxiliary classifier that distinguishes between videos recorded before and after a human operator, who manually removes specific wastes from a conveyor belt. The saliency maps of this classifier identify materials to be removed, and we modify the classifier training to minimize differences between the saliency map of a central frame and those in adjacent frames, after having compensated object displacement. Experiments on a real-world dataset demonstrate the benefits of integrating temporal coherence directly during the training phase of the classifier. Code and dataset are available upon request.</li>
</ul>

<h3>Title: Process Reinforcement through Implicit Rewards</h3>
<ul>
<li><strong>Authors: </strong>Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, Jiarui Yuan, Huayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, Yuan Yao, Xu Han, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou, Ning Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01456">https://arxiv.org/abs/2502.01456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01456">https://arxiv.org/pdf/2502.01456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01456]] Process Reinforcement through Implicit Rewards(https://arxiv.org/abs/2502.01456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dense process rewards have proven a more effective alternative to the sparse outcome-level rewards in the inference-time scaling of large language models (LLMs), particularly in tasks requiring complex multi-step reasoning. While dense rewards also offer an appealing choice for the reinforcement learning (RL) of LLMs since their fine-grained rewards have the potential to address some inherent issues of outcome rewards, such as training efficiency and credit assignment, this potential remains largely unrealized. This can be primarily attributed to the challenges of training process reward models (PRMs) online, where collecting high-quality process labels is prohibitively expensive, making them particularly vulnerable to reward hacking. To address these challenges, we propose PRIME (Process Reinforcement through IMplicit rEwards), which enables online PRM updates using only policy rollouts and outcome labels through implict process rewards. PRIME combines well with various advantage functions and forgoes the dedicated reward model training phrase that existing approaches require, substantially reducing the development overhead. We demonstrate PRIME's effectiveness on competitional math and coding. Starting from Qwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several key reasoning benchmarks over the SFT model. Notably, our resulting model, Eurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning benchmarks with 10% of its training data.</li>
</ul>

<h3>Title: Deep Unfolding Multi-modal Image Fusion Network via Attribution Analysis</h3>
<ul>
<li><strong>Authors: </strong>Haowen Bai, Zixiang Zhao, Jiangshe Zhang, Baisong Jiang, Lilun Deng, Yukun Cui, Shuang Xu, Chunxia Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01467">https://arxiv.org/abs/2502.01467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01467">https://arxiv.org/pdf/2502.01467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01467]] Deep Unfolding Multi-modal Image Fusion Network via Attribution Analysis(https://arxiv.org/abs/2502.01467)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Multi-modal image fusion synthesizes information from multiple sources into a single image, facilitating downstream tasks such as semantic segmentation. Current approaches primarily focus on acquiring informative fusion images at the visual display stratum through intricate mappings. Although some approaches attempt to jointly optimize image fusion and downstream tasks, these efforts often lack direct guidance or interaction, serving only to assist with a predefined fusion loss. To address this, we propose an ``Unfolding Attribution Analysis Fusion network'' (UAAFusion), using attribution analysis to tailor fused images more effectively for semantic segmentation, enhancing the interaction between the fusion and segmentation. Specifically, we utilize attribution analysis techniques to explore the contributions of semantic regions in the source images to task discrimination. At the same time, our fusion algorithm incorporates more beneficial features from the source images, thereby allowing the segmentation to guide the fusion process. Our method constructs a model-driven unfolding network that uses optimization objectives derived from attribution analysis, with an attribution fusion loss calculated from the current state of the segmentation network. We also develop a new pathway function for attribution analysis, specifically tailored to the fusion tasks in our unfolding network. An attribution attention mechanism is integrated at each network stage, allowing the fusion network to prioritize areas and pixels crucial for high-level recognition tasks. Additionally, to mitigate the information loss in traditional unfolding networks, a memory augmentation module is incorporated into our network to improve the information flow across various network layers. Extensive experiments demonstrate our method's superiority in image fusion and applicability to semantic segmentation.</li>
</ul>

<h3>Title: FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Jinwei Hu, Zhenglin Huang, Xiangyu Yin, Wenjie Ruan, Guangliang Cheng, Yi Dong, Xiaowei Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01472">https://arxiv.org/abs/2502.01472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01472">https://arxiv.org/pdf/2502.01472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01472]] FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model(https://arxiv.org/abs/2502.01472)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have been widely applied, but can inadvertently encode sensitive or harmful information, raising significant safety concerns. Machine unlearning has emerged to alleviate this concern; however, existing training-time unlearning approaches, relying on coarse-grained loss combinations, have limitations in precisely separating knowledge and balancing removal effectiveness with model utility. In contrast, we propose Fine-grained Activation manipuLation by Contrastive Orthogonal uNalignment (FALCON), a novel representation-guided unlearning approach that leverages information-theoretic guidance for efficient parameter selection, employs contrastive mechanisms to enhance representation separation, and projects conflict gradients onto orthogonal subspaces to resolve conflicts between forgetting and retention objectives. Extensive experiments demonstrate that FALCON achieves superior unlearning effectiveness while maintaining model utility, exhibiting robust resistance against knowledge recovery attempts.</li>
</ul>

<h3>Title: Generalization Error Analysis for Selective State-Space Models Through the Lens of Attention</h3>
<ul>
<li><strong>Authors: </strong>Arya Honarpisheh, Mustafa Bozdag, Mario Sznaier, Octavia Camps</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01473">https://arxiv.org/abs/2502.01473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01473">https://arxiv.org/pdf/2502.01473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01473]] Generalization Error Analysis for Selective State-Space Models Through the Lens of Attention(https://arxiv.org/abs/2502.01473)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>State-space models (SSMs) are a new class of foundation models that have emerged as a compelling alternative to Transformers and their attention mechanisms for sequence processing tasks. This paper provides a detailed theoretical analysis of selective SSMs, the core components of the Mamba and Mamba-2 architectures. We leverage the connection between selective SSMs and the self-attention mechanism to highlight the fundamental similarities between these models. Building on this connection, we establish a length independent covering number-based generalization bound for selective SSMs, providing a deeper understanding of their theoretical performance guarantees. We analyze the effects of state matrix stability and input-dependent discretization, shedding light on the critical role played by these factors in the generalization capabilities of selective SSMs. Finally, we empirically demonstrate the sequence length independence of the derived bounds on two tasks.</li>
</ul>

<h3>Title: Simultaneous Automatic Picking and Manual Picking Refinement for First-Break</h3>
<ul>
<li><strong>Authors: </strong>Haowen Bai, Zixiang Zhao, Jiangshe Zhang, Yukun Cui, Chunxia Zhang, Zhenbo Guo, Yongjun Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01474">https://arxiv.org/abs/2502.01474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01474">https://arxiv.org/pdf/2502.01474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01474]] Simultaneous Automatic Picking and Manual Picking Refinement for First-Break(https://arxiv.org/abs/2502.01474)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>First-break picking is a pivotal procedure in processing microseismic data for geophysics and resource exploration. Recent advancements in deep learning have catalyzed the evolution of automated methods for identifying first-break. Nevertheless, the complexity of seismic data acquisition and the requirement for detailed, expert-driven labeling often result in outliers and potential mislabeling within manually labeled datasets. These issues can negatively affect the training of neural networks, necessitating algorithms that handle outliers or mislabeled data effectively. We introduce the Simultaneous Picking and Refinement (SPR) algorithm, designed to handle datasets plagued by outlier samples or even noisy labels. Unlike conventional approaches that regard manual picks as ground truth, our method treats the true first-break as a latent variable within a probabilistic model that includes a first-break labeling prior. SPR aims to uncover this variable, enabling dynamic adjustments and improved accuracy across the dataset. This strategy mitigates the impact of outliers or inaccuracies in manual labels. Intra-site picking experiments and cross-site generalization experiments on publicly available data confirm our method's performance in identifying first-break and its generalization across different sites. Additionally, our investigations into noisy signals and labels underscore SPR's resilience to both types of noise and its capability to refine misaligned manual annotations. Moreover, the flexibility of SPR, not being limited to any single network architecture, enhances its adaptability across various deep learning-based picking methods. Focusing on learning from data that may contain outliers or partial inaccuracies, SPR provides a robust solution to some of the principal obstacles in automatic first-break picking.</li>
</ul>

<h3>Title: Position: Empowering Time Series Reasoning with Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yaxuan Kong, Yiyuan Yang, Shiyu Wang, Chenghao Liu, Yuxuan Liang, Ming Jin, Stefan Zohren, Dan Pei, Yan Liu, Qingsong Wen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01477">https://arxiv.org/abs/2502.01477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01477">https://arxiv.org/pdf/2502.01477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01477]] Position: Empowering Time Series Reasoning with Multimodal LLMs(https://arxiv.org/abs/2502.01477)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Understanding time series data is crucial for multiple real-world applications. While large language models (LLMs) show promise in time series tasks, current approaches often rely on numerical data alone, overlooking the multimodal nature of time-dependent information, such as textual descriptions, visual data, and audio signals. Moreover, these methods underutilize LLMs' reasoning capabilities, limiting the analysis to surface-level interpretations instead of deeper temporal and multimodal reasoning. In this position paper, we argue that multimodal LLMs (MLLMs) can enable more powerful and flexible reasoning for time series analysis, enhancing decision-making and real-world applications. We call on researchers and practitioners to leverage this potential by developing strategies that prioritize trust, interpretability, and robust reasoning in MLLMs. Lastly, we highlight key research directions, including novel reasoning paradigms, architectural innovations, and domain-specific applications, to advance time series reasoning with MLLMs.</li>
</ul>

<h3>Title: MoireDB: Formula-generated Interference-fringe Image Dataset</h3>
<ul>
<li><strong>Authors: </strong>Yuto Matsuo, Ryo Hayamizu, Hirokatsu Kataoka, Akio Nakamura</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01490">https://arxiv.org/abs/2502.01490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01490">https://arxiv.org/pdf/2502.01490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01490]] MoireDB: Formula-generated Interference-fringe Image Dataset(https://arxiv.org/abs/2502.01490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Image recognition models have struggled to treat recognition robustness to real-world degradations. In this context, data augmentation methods like PixMix improve robustness but rely on generative arts and feature visualizations (FVis), which have copyright, drawing cost, and scalability issues. We propose MoireDB, a formula-generated interference-fringe image dataset for image augmentation enhancing robustness. MoireDB eliminates copyright concerns, reduces dataset assembly costs, and enhances robustness by leveraging illusory patterns. Experiments show that MoireDB augmented images outperforms traditional Fractal arts and FVis-based augmentations, making it a scalable and effective solution for improving model robustness against real-world degradations.</li>
</ul>

<h3>Title: End-to-end Training for Text-to-Image Synthesis using Dual-Text Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Yeruru Asrar Ahmed, Anurag Mittal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01507">https://arxiv.org/abs/2502.01507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01507">https://arxiv.org/pdf/2502.01507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01507]] End-to-end Training for Text-to-Image Synthesis using Dual-Text Embeddings(https://arxiv.org/abs/2502.01507)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Text-to-Image (T2I) synthesis is a challenging task that requires modeling complex interactions between two modalities ( i.e., text and image). A common framework adopted in recent state-of-the-art approaches to achieving such multimodal interactions is to bootstrap the learning process with pre-trained image-aligned text embeddings trained using contrastive loss. Furthermore, these embeddings are typically trained generically and reused across various synthesis models. In contrast, we explore an approach to learning text embeddings specifically tailored to the T2I synthesis network, trained in an end-to-end fashion. Further, we combine generative and contrastive training and use two embeddings, one optimized to enhance the photo-realism of the generated images, and the other seeking to capture text-to-image alignment. A comprehensive set of experiments on three text-to-image benchmark datasets (Oxford-102, Caltech-UCSD, and MS-COCO) reveal that having two separate embeddings gives better results than using a shared one and that such an approach performs favourably in comparison with methods that use text representations from a pre-trained text encoder trained using a discriminative approach. Finally, we demonstrate that such learned embeddings can be used in other contexts as well, such as text-to-image manipulation.</li>
</ul>

<h3>Title: Hybrid Machine Learning Model for Detecting Bangla Smishing Text Using BERT and Character-Level CNN</h3>
<ul>
<li><strong>Authors: </strong>Gazi Tanbhir, Md. Farhan Shahriyar, Khandker Shahed, Abdullah Md Raihan Chy, Md Al Adnan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01518">https://arxiv.org/abs/2502.01518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01518">https://arxiv.org/pdf/2502.01518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01518]] Hybrid Machine Learning Model for Detecting Bangla Smishing Text Using BERT and Character-Level CNN(https://arxiv.org/abs/2502.01518)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>Smishing is a social engineering attack using SMS containing malicious content to deceive individuals into disclosing sensitive information or transferring money to cybercriminals. Smishing attacks have surged by 328%, posing a major threat to mobile users, with losses exceeding \$54.2 million in 2019. Despite its growing prevalence, the issue remains significantly under-addressed. This paper presents a novel hybrid machine learning model for detecting Bangla smishing texts, combining Bidirectional Encoder Representations from Transformers (BERT) with Convolutional Neural Networks (CNNs) for enhanced character-level analysis. Our model addresses multi-class classification by distinguishing between Normal, Promotional, and Smishing SMS. Unlike traditional binary classification methods, our approach integrates BERT's contextual embeddings with CNN's character-level features, improving detection accuracy. Enhanced by an attention mechanism, the model effectively prioritizes crucial text segments. Our model achieves 98.47% accuracy, outperforming traditional classifiers, with high precision and recall in Smishing detection, and strong performance across all categories.</li>
</ul>

<h3>Title: Toward Task Generalization via Memory Augmentation in Meta-Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Kaixi Bao, Chenhao Li, Yarden As, Andreas Krause, Marco Hutter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01521">https://arxiv.org/abs/2502.01521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01521">https://arxiv.org/pdf/2502.01521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01521]] Toward Task Generalization via Memory Augmentation in Meta-Reinforcement Learning(https://arxiv.org/abs/2502.01521)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In reinforcement learning (RL), agents often struggle to perform well on tasks that differ from those encountered during training. This limitation presents a challenge to the broader deployment of RL in diverse and dynamic task settings. In this work, we introduce memory augmentation, a memory-based RL approach to improve task generalization. Our approach leverages task-structured augmentations to simulate plausible out-of-distribution scenarios and incorporates memory mechanisms to enable context-aware policy adaptation. Trained on a predefined set of tasks, our policy demonstrates the ability to generalize to unseen tasks through memory augmentation without requiring additional interactions with the environment. Through extensive simulation experiments and real-world hardware evaluations on legged locomotion tasks, we demonstrate that our approach achieves zero-shot generalization to unseen tasks while maintaining robust in-distribution performance and high sample efficiency.</li>
</ul>

<h3>Title: BD-Diff: Generative Diffusion Model for Image Deblurring on Unknown Domains with Blur-Decoupled Learning</h3>
<ul>
<li><strong>Authors: </strong>Junhao Cheng, Wei-Ting Chen, Xi Lu, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01522">https://arxiv.org/abs/2502.01522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01522">https://arxiv.org/pdf/2502.01522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01522]] BD-Diff: Generative Diffusion Model for Image Deblurring on Unknown Domains with Blur-Decoupled Learning(https://arxiv.org/abs/2502.01522)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative diffusion models trained on large-scale datasets have achieved remarkable progress in image synthesis. In favor of their ability to supplement missing details and generate aesthetically pleasing contents, recent works have applied them to image deblurring tasks via training an adapter on blurry-sharp image pairs to provide structural conditions for restoration. However, acquiring substantial amounts of realistic paired data is challenging and costly in real-world scenarios. On the other hand, relying solely on synthetic data often results in overfitting, leading to unsatisfactory performance when confronted with unseen blur patterns. To tackle this issue, we propose BD-Diff, a generative-diffusion-based model designed to enhance deblurring performance on unknown domains by decoupling structural features and blur patterns through joint training on three specially designed tasks. We employ two Q-Formers as structural representations and blur patterns extractors separately. The features extracted by them will be used for the supervised deblurring task on synthetic data and the unsupervised blur-transfer task by leveraging unpaired blurred images from the target domain simultaneously. Furthermore, we introduce a reconstruction task to make the structural features and blur patterns complementary. This blur-decoupled learning process enhances the generalization capabilities of BD-Diff when encountering unknown domain blur patterns. Experiments on real-world datasets demonstrate that BD-Diff outperforms existing state-of-the-art methods in blur removal and structural preservation in various challenging scenarios. The codes will be released in this https URL</li>
</ul>

<h3>Title: CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Zongxi Li, Yang Li, Haoran Xie, S. Joe Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01523">https://arxiv.org/abs/2502.01523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01523">https://arxiv.org/pdf/2502.01523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01523]] CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering(https://arxiv.org/abs/2502.01523)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are prone to hallucinations in question-answering (QA) tasks when faced with ambiguous questions. Users often assume that LLMs share their cognitive alignment, a mutual understanding of context, intent, and implicit details, leading them to omit critical information in the queries. However, LLMs generate responses based on assumptions that can misalign with user intent, which may be perceived as hallucinations if they misalign with the user's intent. Therefore, identifying those implicit assumptions is crucial to resolve ambiguities in QA. Prior work, such as AmbigQA, reduces ambiguity in queries via human-annotated clarifications, which is not feasible in real application. Meanwhile, ASQA compiles AmbigQA's short answers into long-form responses but inherits human biases and fails capture explicit logical distinctions that differentiates the answers. We introduce Conditional Ambiguous Question-Answering (CondAmbigQA), a benchmark with 200 ambiguous queries and condition-aware evaluation metrics. Our study pioneers the concept of ``conditions'' in ambiguous QA tasks, where conditions stand for contextual constraints or assumptions that resolve ambiguities. The retrieval-based annotation strategy uses retrieved Wikipedia fragments to identify possible interpretations for a given query as its conditions and annotate the answers through those conditions. Such a strategy minimizes human bias introduced by different knowledge levels among annotators. By fixing retrieval results, CondAmbigQA evaluates how RAG systems leverage conditions to resolve ambiguities. Experiments show that models considering conditions before answering improve performance by $20\%$, with an additional $5\%$ gain when conditions are explicitly provided. These results underscore the value of conditional reasoning in QA, offering researchers tools to rigorously evaluate ambiguity resolution.</li>
</ul>

<h3>Title: Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective</h3>
<ul>
<li><strong>Authors: </strong>Xiaorui Ma, Haoran Xie, S. Joe Qin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01524">https://arxiv.org/abs/2502.01524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01524">https://arxiv.org/pdf/2502.01524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01524]] Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective(https://arxiv.org/abs/2502.01524)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The integration of vision-language modalities has been a significant focus in multimodal learning, traditionally relying on Vision-Language Pretrained Models. However, with the advent of Large Language Models (LLMs), there has been a notable shift towards incorporating LLMs with vision modalities. Following this, the training paradigms for incorporating vision modalities into LLMs have evolved. Initially, the approach was to integrate the modalities through pretraining the modality integrator, named Single-stage Tuning. It has since branched out into methods focusing on performance enhancement, denoted as Two-stage Tuning, and those prioritizing parameter efficiency, referred to as Direct Adaptation. However, existing surveys primarily address the latest Vision Large Language Models (VLLMs) with Two-stage Tuning, leaving a gap in understanding the evolution of training paradigms and their unique parameter-efficient considerations. This paper categorizes and reviews 34 VLLMs from top conferences, journals, and highly cited Arxiv papers, focusing on parameter efficiency during adaptation from the training paradigm perspective. We first introduce the architecture of LLMs and parameter-efficient learning methods, followed by a discussion on vision encoders and a comprehensive taxonomy of modality integrators. We then review three training paradigms and their efficiency considerations, summarizing benchmarks in the VLLM field. To gain deeper insights into their effectiveness in parameter efficiency, we compare and discuss the experimental results of representative models, among which the experiment of the Direct Adaptation paradigm is replicated. Providing insights into recent developments and practical uses, this survey is a vital guide for researchers and practitioners navigating the efficient integration of vision modalities into LLMs.</li>
</ul>

<h3>Title: Enhancing Bayesian Network Structural Learning with Monte Carlo Tree Search</h3>
<ul>
<li><strong>Authors: </strong>Jorge D. Laborda, Pablo Torrijos, José M. Puerta, José A. Gámez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01527">https://arxiv.org/abs/2502.01527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01527">https://arxiv.org/pdf/2502.01527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01527]] Enhancing Bayesian Network Structural Learning with Monte Carlo Tree Search(https://arxiv.org/abs/2502.01527)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This article presents MCTS-BN, an adaptation of the Monte Carlo Tree Search (MCTS) algorithm for the structural learning of Bayesian Networks (BNs). Initially designed for game tree exploration, MCTS has been repurposed to address the challenge of learning BN structures by exploring the search space of potential ancestral orders in Bayesian Networks. Then, it employs Hill Climbing (HC) to derive a Bayesian Network structure from each order. In large BNs, where the search space for variable orders becomes vast, using completely random orders during the rollout phase is often unreliable and impractical. We adopt a semi-randomized approach to address this challenge by incorporating variable orders obtained from other heuristic search algorithms such as Greedy Equivalent Search (GES), PC, or HC itself. This hybrid strategy mitigates the computational burden and enhances the reliability of the rollout process. Experimental evaluations demonstrate the effectiveness of MCTS-BN in improving BNs generated by traditional structural learning algorithms, exhibiting robust performance even when base algorithm orders are suboptimal and surpassing the gold standard when provided with favorable orders.</li>
</ul>

<h3>Title: Federated Learning with Discriminative Naive Bayes Classifier</h3>
<ul>
<li><strong>Authors: </strong>Pablo Torrijos, Juan C. Alfaro, José A. Gámez, José M. Puerta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01532">https://arxiv.org/abs/2502.01532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01532">https://arxiv.org/pdf/2502.01532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01532]] Federated Learning with Discriminative Naive Bayes Classifier(https://arxiv.org/abs/2502.01532)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate, generative</a></li>
<li><strong>Abstract: </strong>Federated Learning has emerged as a promising approach to train machine learning models on decentralized data sources while preserving data privacy. This paper proposes a new federated approach for Naive Bayes (NB) classification, assuming discrete variables. Our approach federates a discriminative variant of NB, sharing meaningless parameters instead of conditional probability tables. Therefore, this process is more reliable against possible attacks. We conduct extensive experiments on 12 datasets to validate the efficacy of our approach, comparing federated and non-federated settings. Additionally, we benchmark our method against the generative variant of NB, which serves as a baseline for comparison. Our experimental results demonstrate the effectiveness of our method in achieving accurate classification.</li>
</ul>

<h3>Title: Transformers trained on proteins can learn to attend to Euclidean distance</h3>
<ul>
<li><strong>Authors: </strong>Isaac Ellmen, Constantin Schneider, Matthew I.J. Raybould, Charlotte M. Deane</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01533">https://arxiv.org/abs/2502.01533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01533">https://arxiv.org/pdf/2502.01533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01533]] Transformers trained on proteins can learn to attend to Euclidean distance(https://arxiv.org/abs/2502.01533)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>While conventional Transformers generally operate on sequence data, they can be used in conjunction with structure models, typically SE(3)-invariant or equivariant graph neural networks (GNNs), for 3D applications such as protein structure modelling. These hybrids typically involve either (1) preprocessing/tokenizing structural features as input for Transformers or (2) taking Transformer embeddings and processing them within a structural representation. However, there is evidence that Transformers can learn to process structural information on their own, such as the AlphaFold3 structural diffusion model. In this work we show that Transformers can function independently as structure models when passed linear embeddings of coordinates. We first provide a theoretical explanation for how Transformers can learn to filter attention as a 3D Gaussian with learned variance. We then validate this theory using both simulated 3D points and in the context of masked token prediction for proteins. Finally, we show that pre-training protein Transformer encoders with structure improves performance on a downstream task, yielding better performance than custom structural models. Together, this work provides a basis for using standard Transformers as hybrid structure-language models.</li>
</ul>

<h3>Title: Preference Leakage: A Contamination Problem in LLM-as-a-judge</h3>
<ul>
<li><strong>Authors: </strong>Dawei Li, Renliang Sun, Yue Huang, Ming Zhong, Bohan Jiang, Jiawei Han, Xiangliang Zhang, Wei Wang, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01534">https://arxiv.org/abs/2502.01534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01534">https://arxiv.org/pdf/2502.01534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01534]] Preference Leakage: A Contamination Problem in LLM-as-a-judge(https://arxiv.org/abs/2502.01534)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) as judges and LLM-based data synthesis have emerged as two fundamental LLM-driven data annotation methods in model development. While their combination significantly enhances the efficiency of model training and evaluation, little attention has been given to the potential contamination brought by this new model development paradigm. In this work, we expose preference leakage, a contamination problem in LLM-as-a-judge caused by the relatedness between the synthetic data generators and LLM-based evaluators. To study this issue, we first define three common relatednesses between data generator LLM and judge LLM: being the same model, having an inheritance relationship, and belonging to the same model family. Through extensive experiments, we empirically confirm the bias of judges towards their related student models caused by preference leakage across multiple LLM baselines and benchmarks. Further analysis suggests that preference leakage is a pervasive issue that is harder to detect compared to previously identified biases in LLM-as-a-judge scenarios. All of these findings imply that preference leakage is a widespread and challenging problem in the area of LLM-as-a-judge. We release all codes and data at: this https URL.</li>
</ul>

<h3>Title: VisTA: Vision-Text Alignment Model with Contrastive Learning using Multimodal Data for Evidence-Driven, Reliable, and Explainable Alzheimer's Disease Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Duy-Cat Can, Linh D. Dang, Quang-Huy Tang, Dang Minh Ly, Huong Ha, Guillaume Blanc, Oliver Y. Chén, Binh T. Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01535">https://arxiv.org/abs/2502.01535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01535">https://arxiv.org/pdf/2502.01535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01535]] VisTA: Vision-Text Alignment Model with Contrastive Learning using Multimodal Data for Evidence-Driven, Reliable, and Explainable Alzheimer's Disease Diagnosis(https://arxiv.org/abs/2502.01535)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Objective: Assessing Alzheimer's disease (AD) using high-dimensional radiology images is clinically important but challenging. Although Artificial Intelligence (AI) has advanced AD diagnosis, it remains unclear how to design AI models embracing predictability and explainability. Here, we propose VisTA, a multimodal language-vision model assisted by contrastive learning, to optimize disease prediction and evidence-based, interpretable explanations for clinical decision-making. Methods: We developed VisTA (Vision-Text Alignment Model) for AD diagnosis. Architecturally, we built VisTA from BiomedCLIP and fine-tuned it using contrastive learning to align images with verified abnormalities and their descriptions. To train VisTA, we used a constructed reference dataset containing images, abnormality types, and descriptions verified by medical experts. VisTA produces four outputs: predicted abnormality type, similarity to reference cases, evidence-driven explanation, and final AD diagnoses. To illustrate VisTA's efficacy, we reported accuracy metrics for abnormality retrieval and dementia prediction. To demonstrate VisTA's explainability, we compared its explanations with human experts' explanations. Results: Compared to 15 million images used for baseline pretraining, VisTA only used 170 samples for fine-tuning and obtained significant improvement in abnormality retrieval and dementia prediction. For abnormality retrieval, VisTA reached 74% accuracy and an AUC of 0.87 (26% and 0.74, respectively, from baseline models). For dementia prediction, VisTA achieved 88% accuracy and an AUC of 0.82 (30% and 0.57, respectively, from baseline models). The generated explanations agreed strongly with human experts' and provided insights into the diagnostic process. Taken together, VisTA optimize prediction, clinical reasoning, and explanation.</li>
</ul>

<h3>Title: FedGES: A Federated Learning Approach for BN Structure Learning</h3>
<ul>
<li><strong>Authors: </strong>Pablo Torrijos, José A. Gámez, José M. Puerta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01538">https://arxiv.org/abs/2502.01538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01538">https://arxiv.org/pdf/2502.01538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01538]] FedGES: A Federated Learning Approach for BN Structure Learning(https://arxiv.org/abs/2502.01538)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Bayesian Network (BN) structure learning traditionally centralizes data, raising privacy concerns when data is distributed across multiple entities. This research introduces Federated GES (FedGES), a novel Federated Learning approach tailored for BN structure learning in decentralized settings using the Greedy Equivalence Search (GES) algorithm. FedGES uniquely addresses privacy and security challenges by exchanging only evolving network structures, not parameters or data. It realizes collaborative model development, using structural fusion to combine the limited models generated by each client in successive iterations. A controlled structural fusion is also proposed to enhance client consensus when adding any edge. Experimental results on various BNs from {\sf bnlearn}'s BN Repository validate the effectiveness of FedGES, particularly in high-dimensional (a large number of variables) and sparse data scenarios, offering a practical and privacy-preserving solution for real-world BN structure learning.</li>
</ul>

<h3>Title: What is a Number, That a Large Language Model May Know It?</h3>
<ul>
<li><strong>Authors: </strong>Raja Marjieh, Veniamin Veselovsky, Thomas L. Griffiths, Ilia Sucholutsky</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01540">https://arxiv.org/abs/2502.01540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01540">https://arxiv.org/pdf/2502.01540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01540]] What is a Number, That a Large Language Model May Know It?(https://arxiv.org/abs/2502.01540)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Numbers are a basic part of how humans represent and describe the world around them. As a consequence, learning effective representations of numbers is critical for the success of large language models as they become more integrated into everyday decisions. However, these models face a challenge: depending on context, the same sequence of digit tokens, e.g., 911, can be treated as a number or as a string. What kind of representations arise from this duality, and what are its downstream implications? Using a similarity-based prompting technique from cognitive science, we show that LLMs learn representational spaces that blend string-like and numerical representations. In particular, we show that elicited similarity judgments from these models over integer pairs can be captured by a combination of Levenshtein edit distance and numerical Log-Linear distance, suggesting an entangled representation. In a series of experiments we show how this entanglement is reflected in the latent embeddings, how it can be reduced but not entirely eliminated by context, and how it can propagate into a realistic decision scenario. These results shed light on a representational tension in transformer models that must learn what a number is from text input.</li>
</ul>

<h3>Title: Unsupervised anomaly detection in large-scale estuarine acoustic telemetry data</h3>
<ul>
<li><strong>Authors: </strong>Siphendulwe Zaza, Marcellin Atemkeng, Taryn S. Murray, John David Filmalter, Paul D. Cowley</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01543">https://arxiv.org/abs/2502.01543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01543">https://arxiv.org/pdf/2502.01543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01543]] Unsupervised anomaly detection in large-scale estuarine acoustic telemetry data(https://arxiv.org/abs/2502.01543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Acoustic telemetry data plays a vital role in understanding the behaviour and movement of aquatic animals. However, these datasets, which often consist of millions of individual data points, frequently contain anomalous movements that pose significant challenges. Traditionally, anomalous movements are identified either manually or through basic statistical methods, approaches that are time-consuming and prone to high rates of unidentified anomalies in large datasets. This study focuses on the development of automated classifiers for a large telemetry dataset comprising detections from fifty acoustically tagged dusky kob monitored in the Breede Estuary, South Africa. Using an array of 16 acoustic receivers deployed throughout the estuary between 2016 and 2021, we collected over three million individual data points. We present detailed guidelines for data pre-processing, resampling strategies, labelling process, feature engineering, data splitting methodologies, and the selection and interpretation of machine learning and deep learning models for anomaly detection. Among the evaluated models, neural networks autoencoder (NN-AE) demonstrated superior performance, aided by our proposed threshold-finding algorithm. NN-AE achieved a high recall with no false normal (i.e., no misclassifications of anomalous movements as normal patterns), a critical factor in ensuring that no true anomalies are overlooked. In contrast, other models exhibited false normal fractions exceeding 0.9, indicating they failed to detect the majority of true anomalies; a significant limitation for telemetry studies where undetected anomalies can distort interpretations of movement patterns. While the NN-AE's performance highlights its reliability and robustness in detecting anomalies, it faced challenges in accurately learning normal movement patterns when these patterns gradually deviated from anomalous ones.</li>
</ul>

<h3>Title: FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction</h3>
<ul>
<li><strong>Authors: </strong>Dimitrios Michail, Charalampos Davalas, Lefki-Ioanna Panagiotou, Ioannis Prapas, Spyros Kondylatos, Nikolaos Ioannis Bountos, Ioannis Papoutsis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01550">https://arxiv.org/abs/2502.01550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01550">https://arxiv.org/pdf/2502.01550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01550]] FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction(https://arxiv.org/abs/2502.01550)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With climate change expected to exacerbate fire weather conditions, the accurate and timely anticipation of wildfires becomes increasingly crucial for disaster mitigation. In this study, we utilize SeasFire, a comprehensive global wildfire dataset with climate, vegetation, oceanic indices, and human-related variables, to enable seasonal wildfire forecasting with machine learning. For the predictive analysis, we present FireCastNet, a novel architecture which combines a 3D convolutional encoder with GraphCast, originally developed for global short-term weather forecasting using graph neural networks. FireCastNet is trained to capture the context leading to wildfires, at different spatial and temporal scales. Our investigation focuses on assessing the effectiveness of our model in predicting the presence of burned areas at varying forecasting time horizons globally, extending up to six months into the future, and on how different spatial or/and temporal context affects the performance. Our findings demonstrate the potential of deep learning models in seasonal fire forecasting; longer input time-series leads to more robust predictions, while integrating spatial information to capture wildfire spatio-temporal dynamics boosts performance. Finally, our results hint that in order to enhance performance at longer forecasting horizons, a larger receptive field spatially needs to be considered.</li>
</ul>

<h3>Title: Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Jin, Kai Mei, Wujiang Xu, Mingjie Sun, Ruixiang Tang, Mengnan Du, Zirui Liu, Yongfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01563">https://arxiv.org/abs/2502.01563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01563">https://arxiv.org/pdf/2502.01563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01563]] Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding(https://arxiv.org/abs/2502.01563)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success in contextual knowledge understanding. In this paper, we show that these concentrated massive values consistently emerge in specific regions of attention queries (Q) and keys (K) while not having such patterns in values (V) in various modern transformer-based LLMs (Q, K, and V mean the representations output by the query, key, and value layers respectively). Through extensive experiments, we further demonstrate that these massive values play a critical role in interpreting contextual knowledge (knowledge obtained from the current context window) rather than in retrieving parametric knowledge stored within the model's parameters. Our further investigation of quantization strategies reveals that ignoring these massive values leads to a pronounced drop in performance on tasks requiring rich contextual understanding, aligning with our analysis. Finally, we trace the emergence of concentrated massive values and find that such concentration is caused by Rotary Positional Encoding (RoPE), which has appeared since the first layers. These findings shed new light on how Q and K operate in LLMs and offer practical insights for model design and optimization. The Code is Available at this https URL.</li>
</ul>

<h3>Title: Scalable Language Models with Posterior Inference of Latent Thought Vectors</h3>
<ul>
<li><strong>Authors: </strong>Deqian Kong, Minglu Zhao, Dehong Xu, Bo Pang, Shu Wang, Edouardo Honig, Zhangzhang Si, Chuan Li, Jianwen Xie, Sirui Xie, Ying Nian Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01567">https://arxiv.org/abs/2502.01567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01567">https://arxiv.org/pdf/2502.01567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01567]] Scalable Language Models with Posterior Inference of Latent Thought Vectors(https://arxiv.org/abs/2502.01567)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose a novel family of language models, Latent-Thought Language Models (LTMs), which incorporate explicit latent thought vectors that follow an explicit prior model in latent space. These latent thought vectors guide the autoregressive generation of ground tokens through a Transformer decoder. Training employs a dual-rate optimization process within the classical variational Bayes framework: fast learning of local variational parameters for the posterior distribution of latent vectors, and slow learning of global decoder parameters. Empirical studies reveal that LTMs possess additional scaling dimensions beyond traditional LLMs, yielding a structured design space. Higher sample efficiency can be achieved by increasing training compute per token, with further gains possible by trading model size for more inference steps. Designed based on these scaling properties, LTMs demonstrate superior sample and parameter efficiency compared to conventional autoregressive models and discrete diffusion models. They significantly outperform these counterparts in validation perplexity and zero-shot language modeling. Additionally, LTMs exhibit emergent few-shot in-context reasoning capabilities that scale with model and latent size, and achieve competitive performance in conditional and unconditional text generation.</li>
</ul>

<h3>Title: Federated Detection of Open Charge Point Protocol 1.6 Cyberattacks</h3>
<ul>
<li><strong>Authors: </strong>Christos Dalamagkas, Panagiotis Radoglou-Grammatikis, Pavlos Bouzinis, Ioannis Papadopoulos, Thomas Lagkas, Vasileios Argyriou, Sotirios Goudos, Dimitrios Margounakis, Eleftherios Fountoukidis, Panagiotis Sarigiannidis</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01569">https://arxiv.org/abs/2502.01569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01569">https://arxiv.org/pdf/2502.01569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01569]] Federated Detection of Open Charge Point Protocol 1.6 Cyberattacks(https://arxiv.org/abs/2502.01569)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>The ongoing electrification of the transportation sector requires the deployment of multiple Electric Vehicle (EV) charging stations across multiple locations. However, the EV charging stations introduce significant cyber-physical and privacy risks, given the presence of vulnerable communication protocols, like the Open Charge Point Protocol (OCPP). Meanwhile, the Federated Learning (FL) paradigm showcases a novel approach for improved intrusion detection results that utilize multiple sources of Internet of Things data, while respecting the confidentiality of private information. This paper proposes the adoption of the FL architecture for the monitoring of the EV charging infrastructure and the detection of cyberattacks against the OCPP 1.6 protocol. The evaluation results showcase high detection performance of the proposed FL-based solution.</li>
</ul>

<h3>Title: MakeAnything: Harnessing Diffusion Transformers for Multi-Domain Procedural Sequence Generation</h3>
<ul>
<li><strong>Authors: </strong>Yiren Song, Cheng Liu, Mike Zheng Shou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01572">https://arxiv.org/abs/2502.01572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01572">https://arxiv.org/pdf/2502.01572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01572]] MakeAnything: Harnessing Diffusion Transformers for Multi-Domain Procedural Sequence Generation(https://arxiv.org/abs/2502.01572)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>A hallmark of human intelligence is the ability to create complex artifacts through structured multi-step processes. Generating procedural tutorials with AI is a longstanding but challenging goal, facing three key obstacles: (1) scarcity of multi-task procedural datasets, (2) maintaining logical continuity and visual consistency between steps, and (3) generalizing across multiple domains. To address these challenges, we propose a multi-domain dataset covering 21 tasks with over 24,000 procedural sequences. Building upon this foundation, we introduce MakeAnything, a framework based on the diffusion transformer (DIT), which leverages fine-tuning to activate the in-context capabilities of DIT for generating consistent procedural sequences. We introduce asymmetric low-rank adaptation (LoRA) for image generation, which balances generalization capabilities and task-specific performance by freezing encoder parameters while adaptively tuning decoder layers. Additionally, our ReCraft model enables image-to-process generation through spatiotemporal consistency constraints, allowing static images to be decomposed into plausible creation sequences. Extensive experiments demonstrate that MakeAnything surpasses existing methods, setting new performance benchmarks for procedural generation tasks.</li>
</ul>

<h3>Title: Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Khan, Salman Khan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01576">https://arxiv.org/abs/2502.01576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01576">https://arxiv.org/pdf/2502.01576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01576]] Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models(https://arxiv.org/abs/2502.01576)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal Large Language Models (MLLMs) excel in vision-language tasks but remain vulnerable to visual adversarial perturbations that can induce hallucinations, manipulate responses, or bypass safety mechanisms. Existing methods seek to mitigate these risks by applying constrained adversarial fine-tuning to CLIP vision encoders on ImageNet-scale data, ensuring their generalization ability is preserved. However, this limited adversarial training restricts robustness and broader generalization. In this work, we explore an alternative approach of leveraging existing vision classification models that have been adversarially pre-trained on large-scale data. Our analysis reveals two principal contributions: (1) the extensive scale and diversity of adversarial pre-training enables these models to demonstrate superior robustness against diverse adversarial threats, ranging from imperceptible perturbations to advanced jailbreaking attempts, without requiring additional adversarial training, and (2) end-to-end MLLM integration with these robust models facilitates enhanced adaptation of language components to robust visual features, outperforming existing plug-and-play methodologies on complex reasoning tasks. Through systematic evaluation across visual question-answering, image captioning, and jail-break attacks, we demonstrate that MLLMs trained with these robust models achieve superior adversarial robustness while maintaining favorable clean performance. Our framework achieves 2x and 1.5x average robustness gains in captioning and VQA tasks, respectively, and delivers over 10% improvement against jailbreak attacks. Code and pretrained models will be available at this https URL.</li>
</ul>

<h3>Title: ReGLA: Refining Gated Linear Attention</h3>
<ul>
<li><strong>Authors: </strong>Peng Lu, Ivan Kobyzev, Mehdi Rezagholizadeh, Boxing Chen, Philippe Langlais</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01578">https://arxiv.org/abs/2502.01578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01578">https://arxiv.org/pdf/2502.01578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01578]] ReGLA: Refining Gated Linear Attention(https://arxiv.org/abs/2502.01578)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have set themselves apart with their exceptional performance in complex language modelling tasks. However, these models are also known for their significant computational and storage requirements, primarily due to the quadratic computation complexity of softmax attention. To mitigate this issue, linear attention has been designed to reduce the quadratic space-time complexity that is inherent in standard transformers. In this work, we embarked on a comprehensive exploration of three key components that substantially impact the performance of the Gated Linear Attention module: feature maps, normalization, and the gating mechanism. We developed a feature mapping function to address some crucial issues that previous suggestions overlooked. Then we offered further rationale for the integration of normalization layers to stabilize the training process. Moreover, we explored the saturation phenomenon of the gating mechanism and augmented it with a refining module. We conducted extensive experiments and showed our architecture outperforms previous Gated Linear Attention mechanisms in extensive tasks including training from scratch and post-linearization with continual pre-training.</li>
</ul>

<h3>Title: SubTrack your Grad: Gradient Subspace Tracking for Memory and Time Efficient Full-Parameter LLM Training</h3>
<ul>
<li><strong>Authors: </strong>Sahar Rajabi, Nayeema Nonta, Sirisha Rambhatla</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01586">https://arxiv.org/abs/2502.01586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01586">https://arxiv.org/pdf/2502.01586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01586]] SubTrack your Grad: Gradient Subspace Tracking for Memory and Time Efficient Full-Parameter LLM Training(https://arxiv.org/abs/2502.01586)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) demand significant time and computational resources due to their large model sizes and optimizer states. To overcome these challenges, recent methods, such as BAdam, employ partial weight updates to enhance time and memory efficiency, though sometimes at the cost of performance. Others, like GaLore, focus on maintaining performance while optimizing memory usage through full parameter training, but may incur higher time complexity. By leveraging the low-rank structure of the gradient and the Grassmannian geometry, we propose SubTrack-Grad, a subspace tracking-based optimization method that efficiently tracks the evolving gradient subspace by incorporating estimation errors and previously identified subspaces. SubTrack-Grad delivers better or on-par results compared to GaLore, while significantly outperforming BAdam, which, despite being time-efficient, compromises performance. SubTrack-Grad reduces wall-time by up to 20.57% on GLUE tasks (15% average reduction) and up to 65% on SuperGLUE tasks (22% average reduction) compared to GaLore. Notably, for a 3B parameter model, GaLore incurred a substantial 157% increase in wall-time compared to full-rank training, whereas SubTrack-Grad exhibited a 31% increase, representing a 49% reduction in wall-time, while enjoying the same memory reductions as GaLore.</li>
</ul>

<h3>Title: Improving Transformer World Models for Data-Efficient RL</h3>
<ul>
<li><strong>Authors: </strong>Antoine Dedieu, Joseph Ortiz, Xinghua Lou, Carter Wendelken, Wolfgang Lehrach, J Swaroop Guntupalli, Miguel Lazaro-Gredilla, Kevin Patrick Murphy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01591">https://arxiv.org/abs/2502.01591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01591">https://arxiv.org/pdf/2502.01591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01591]] Improving Transformer World Models for Data-Efficient RL(https://arxiv.org/abs/2502.01591)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present an approach to model-based RL that achieves a new state of the art performance on the challenging Craftax-classic benchmark, an open-world 2D survival game that requires agents to exhibit a wide range of general abilities -- such as strong generalization, deep exploration, and long-term reasoning. With a series of careful design choices aimed at improving sample efficiency, our MBRL algorithm achieves a reward of 67.4% after only 1M environment steps, significantly outperforming DreamerV3, which achieves 53.2%, and, for the first time, exceeds human performance of 65.0%. Our method starts by constructing a SOTA model-free baseline, using a novel policy architecture that combines CNNs and RNNs. We then add three improvements to the standard MBRL setup: (a) "Dyna with warmup", which trains the policy on real and imaginary data, (b) "nearest neighbor tokenizer" on image patches, which improves the scheme to create the transformer world model (TWM) inputs, and (c) "block teacher forcing", which allows the TWM to reason jointly about the future tokens of the next timestep.</li>
</ul>

<h3>Title: Reinforcement Learning for Long-Horizon Interactive LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Kevin Chen, Marco Cusumano-Towner, Brody Huval, Aleksei Petrenko, Jackson Hamburger, Vladlen Koltun, Philipp Krähenbühl</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01600">https://arxiv.org/abs/2502.01600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01600">https://arxiv.org/pdf/2502.01600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01600]] Reinforcement Learning for Long-Horizon Interactive LLM Agents(https://arxiv.org/abs/2502.01600)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Interactive digital agents (IDAs) leverage APIs of stateful digital environments to perform tasks in response to user requests. While IDAs powered by instruction-tuned large language models (LLMs) can react to feedback from interface invocations in multi-step exchanges, they have not been trained in their respective digital environments. Prior methods accomplish less than half of tasks in sophisticated benchmarks such as AppWorld. We present a reinforcement learning (RL) approach that trains IDAs directly in their target environments. We formalize this training as a partially observable Markov decision process and derive M-PPO, a data- and memory-efficient variant of proximal policy optimization. M-PPO uses no value network and maintains exactly one copy of the underlying LLM in memory, making its implementation straightforward and as memory-efficient as fine-tuning a single LLM. A 32-billion-parameter agent trained with M-PPO in the AppWorld environment outperforms the much larger OpenAI o1 agent by 9 percentage points (15% relative). To our knowledge, this is the first reported application of RL to IDAs that interact with a stateful, multi-domain, multi-app environment via direct API calls. Our analysis sheds light on the effectiveness of RL in this area, showing that the agent learns to consult the API documentation, avoid unwarranted assumptions, minimize confabulation, and recover from setbacks.</li>
</ul>

<h3>Title: Beyond the Crawl: Unmasking Browser Fingerprinting in Real User Interactions</h3>
<ul>
<li><strong>Authors: </strong>Meenatchi Sundaram Muthu Selva Annamalai, Igor Bilogrevic, Emiliano De Cristofaro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01608">https://arxiv.org/abs/2502.01608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01608">https://arxiv.org/pdf/2502.01608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01608]] Beyond the Crawl: Unmasking Browser Fingerprinting in Real User Interactions(https://arxiv.org/abs/2502.01608)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, federate</a></li>
<li><strong>Abstract: </strong>Browser fingerprinting is a pervasive online tracking technique used increasingly often for profiling and targeted advertising. Prior research on the prevalence of fingerprinting heavily relied on automated web crawls, which inherently struggle to replicate the nuances of human-computer interactions. This raises concerns about the accuracy of current understandings of real-world fingerprinting deployments. As a result, this paper presents a user study involving 30 participants over 10 weeks, capturing telemetry data from real browsing sessions across 3,000 top-ranked websites. Our evaluation reveals that automated crawls miss almost half (45%) of the fingerprinting websites encountered by real users. This discrepancy mainly stems from the crawlers' inability to access authentication-protected pages, circumvent bot detection, and trigger fingerprinting scripts activated by specific user interactions. We also identify potential new fingerprinting vectors present in real user data but absent from automated crawls. Finally, we evaluate the effectiveness of federated learning for training browser fingerprinting detection models on real user data, yielding improved performance than models trained solely on automated crawl data.</li>
</ul>

<h3>Title: Breaking Focus: Contextual Distraction Curse in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yue Huang, Yanbo Wang, Zixiang Xu, Chujie Gao, Siyuan Wu, Jiayi Ye, Xiuying Chen, Pin-Yu Chen, Xiangliang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01609">https://arxiv.org/abs/2502.01609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01609">https://arxiv.org/pdf/2502.01609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01609]] Breaking Focus: Contextual Distraction Curse in Large Language Models(https://arxiv.org/abs/2502.01609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have revolutionized generative systems, achieving excellent performance across diverse domains. Although these models perform well in controlled environments, their real-world applications frequently encounter inputs containing both essential and irrelevant details. Our investigation has revealed a critical vulnerability in LLMs, which we term Contextual Distraction Vulnerability (CDV). This phenomenon arises when models fail to maintain consistent performance on questions modified with semantically coherent but irrelevant context. To systematically investigate this vulnerability, we propose an efficient tree-based search methodology to automatically generate CDV examples. Our approach successfully generates CDV examples across four datasets, causing an average performance degradation of approximately 45% in state-of-the-art LLMs. To address this critical issue, we explore various mitigation strategies and find that post-targeted training approaches can effectively enhance model robustness against contextual distractions. Our findings highlight the fundamental nature of CDV as an ability-level challenge rather than a knowledge-level issue since models demonstrate the necessary knowledge by answering correctly in the absence of distractions. This calls the community's attention to address CDV during model development to ensure reliability. The code is available at this https URL.</li>
</ul>

<h3>Title: Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges</h3>
<ul>
<li><strong>Authors: </strong>Nayoung Lee, Ziyang Cai, Avi Schwarzschild, Kangwook Lee, Dimitris Papailiopoulos</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01612">https://arxiv.org/abs/2502.01612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01612">https://arxiv.org/pdf/2502.01612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01612]] Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges(https://arxiv.org/abs/2502.01612)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models often struggle with length generalization and solving complex problem instances beyond their training distribution. We present a self-improvement approach where models iteratively generate and learn from their own solutions, progressively tackling harder problems while maintaining a standard transformer architecture. Across diverse tasks including arithmetic, string manipulation, and maze solving, self-improving enables models to solve problems far beyond their initial training distribution-for instance, generalizing from 10-digit to 100-digit addition without apparent saturation. We observe that in some cases filtering for correct self-generated examples leads to exponential improvements in out-of-distribution performance across training rounds. Additionally, starting from pretrained models significantly accelerates this self-improvement process for several tasks. Our results demonstrate how controlled weak-to-strong curricula can systematically teach a model logical extrapolation without any changes to the positional embeddings, or the model architecture.</li>
</ul>

<h3>Title: Large Language Models Are Human-Like Internally</h3>
<ul>
<li><strong>Authors: </strong>Tatsuki Kuribayashi, Yohei Oseki, Souhaib Ben Taieb, Kentaro Inui, Timothy Baldwin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01615">https://arxiv.org/abs/2502.01615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01615">https://arxiv.org/pdf/2502.01615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01615]] Large Language Models Are Human-Like Internally(https://arxiv.org/abs/2502.01615)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent cognitive modeling studies have reported that larger language models (LMs) exhibit a poorer fit to human reading behavior, leading to claims of their cognitive implausibility. In this paper, we revisit this argument through the lens of mechanistic interpretability and argue that prior conclusions were skewed by an exclusive focus on the final layers of LMs. Our analysis reveals that next-word probabilities derived from internal layers of larger LMs align with human sentence processing data as well as, or better than, those from smaller LMs. This alignment holds consistently across behavioral (self-paced reading times, gaze durations, MAZE task processing times) and neurophysiological (N400 brain potentials) measures, challenging earlier mixed results and suggesting that the cognitive plausibility of larger LMs has been underestimated. Furthermore, we first identify an intriguing relationship between LM layers and human measures: earlier layers correspond more closely with fast gaze durations, while later layers better align with relatively slower signals such as N400 potentials and MAZE processing times. Our work opens new avenues for interdisciplinary research at the intersection of mechanistic interpretability and cognitive modeling.</li>
</ul>

<h3>Title: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods</h3>
<ul>
<li><strong>Authors: </strong>Isha Puri, Shivchander Sudalairaj, Guangxuan Xu, Kai Xu, Akash Srivastava</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01618">https://arxiv.org/abs/2502.01618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01618">https://arxiv.org/pdf/2502.01618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01618]] A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods(https://arxiv.org/abs/2502.01618)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code and further information is available at this https URL.</li>
</ul>

<h3>Title: LLM-TA: An LLM-Enhanced Thematic Analysis Pipeline for Transcripts from Parents of Children with Congenital Heart Disease</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Zain Raza, Jiawei Xu, Terence Lim, Lily Boddy, Carlos M. Mery, Andrew Well, Ying Ding</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01620">https://arxiv.org/abs/2502.01620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01620">https://arxiv.org/pdf/2502.01620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01620]] LLM-TA: An LLM-Enhanced Thematic Analysis Pipeline for Transcripts from Parents of Children with Congenital Heart Disease(https://arxiv.org/abs/2502.01620)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Thematic Analysis (TA) is a fundamental method in healthcare research for analyzing transcript data, but it is resource-intensive and difficult to scale for large, complex datasets. This study investigates the potential of large language models (LLMs) to augment the inductive TA process in high-stakes healthcare settings. Focusing on interview transcripts from parents of children with Anomalous Aortic Origin of a Coronary Artery (AAOCA), a rare congenital heart disease, we propose an LLM-Enhanced Thematic Analysis (LLM-TA) pipeline. Our pipeline integrates an affordable state-of-the-art LLM (GPT-4o mini), LangChain, and prompt engineering with chunking techniques to analyze nine detailed transcripts following the inductive TA framework. We evaluate the LLM-generated themes against human-generated results using thematic similarity metrics, LLM-assisted assessments, and expert reviews. Results demonstrate that our pipeline outperforms existing LLM-assisted TA methods significantly. While the pipeline alone has not yet reached human-level quality in inductive TA, it shows great potential to improve scalability, efficiency, and accuracy while reducing analyst workload when working collaboratively with domain experts. We provide practical recommendations for incorporating LLMs into high-stakes TA workflows and emphasize the importance of close collaboration with domain experts to address challenges related to real-world applicability and dataset complexity. this https URL</li>
</ul>

<h3>Title: MFP-VTON: Enhancing Mask-Free Person-to-Person Virtual Try-On via Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Le Shen, Yanting Kang, Rong Huang, Zhijie Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01626">https://arxiv.org/abs/2502.01626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01626">https://arxiv.org/pdf/2502.01626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01626]] MFP-VTON: Enhancing Mask-Free Person-to-Person Virtual Try-On via Diffusion Transformer(https://arxiv.org/abs/2502.01626)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>The garment-to-person virtual try-on (VTON) task, which aims to generate fitting images of a person wearing a reference garment, has made significant strides. However, obtaining a standard garment is often more challenging than using the garment already worn by the person. To improve ease of use, we propose MFP-VTON, a Mask-Free framework for Person-to-Person VTON. Recognizing the scarcity of person-to-person data, we adapt a garment-to-person model and dataset to construct a specialized dataset for this task. Our approach builds upon a pretrained diffusion transformer, leveraging its strong generative capabilities. During mask-free model fine-tuning, we introduce a Focus Attention loss to emphasize the garment of the reference person and the details outside the garment of the target person. Experimental results demonstrate that our model excels in both person-to-person and garment-to-person VTON tasks, generating high-fidelity fitting images.</li>
</ul>

<h3>Title: Harmonic Loss Trains Interpretable AI Models</h3>
<ul>
<li><strong>Authors: </strong>David D. Baek, Ziming Liu, Riya Tyagi, Max Tegmark</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01628">https://arxiv.org/abs/2502.01628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01628">https://arxiv.org/pdf/2502.01628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01628]] Harmonic Loss Trains Interpretable AI Models(https://arxiv.org/abs/2502.01628)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce **harmonic loss** as an alternative to the standard cross-entropy loss for training neural networks and large language models (LLMs). Harmonic loss enables improved interpretability and faster convergence, owing to its scale invariance and finite convergence point by design, which can be interpreted as a class center. We first validate the performance of harmonic models across algorithmic, vision, and language datasets. Through extensive experiments, we demonstrate that models trained with harmonic loss outperform standard models by: (a) enhancing interpretability, (b) requiring less data for generalization, and (c) reducing grokking. Moreover, we compare a GPT-2 model trained with harmonic loss to the standard GPT-2, illustrating that the harmonic model develops more interpretable representations. Looking forward, we believe harmonic loss has the potential to become a valuable tool in domains with limited data availability or in high-stakes applications where interpretability and reliability are paramount, paving the way for more robust and efficient neural network models.</li>
</ul>

<h3>Title: Adversarial Reasoning at Jailbreaking Time</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Sabbaghi, Paul Kassianik, George Pappas, Yaron Singer, Amin Karbasi, Hamed Hassani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01633">https://arxiv.org/abs/2502.01633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01633">https://arxiv.org/pdf/2502.01633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01633]] Adversarial Reasoning at Jailbreaking Time(https://arxiv.org/abs/2502.01633)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) are becoming more capable and widespread, the study of their failure cases is becoming increasingly important. Recent advances in standardizing, measuring, and scaling test-time compute suggest new methodologies for optimizing models to achieve high performance on hard tasks. In this paper, we apply these advances to the task of model jailbreaking: eliciting harmful responses from aligned LLMs. We develop an adversarial reasoning approach to automatic jailbreaking via test-time computation that achieves SOTA attack success rates (ASR) against many aligned LLMs, even the ones that aim to trade inference-time compute for adversarial robustness. Our approach introduces a new paradigm in understanding LLM vulnerabilities, laying the foundation for the development of more robust and trustworthy AI systems.</li>
</ul>

<h3>Title: Online Gradient Boosting Decision Tree: In-Place Updates for Efficient Adding/Deleting Data</h3>
<ul>
<li><strong>Authors: </strong>Huawei Lin, Jun Woo Chung, Yingjie Lao, Weijie Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01634">https://arxiv.org/abs/2502.01634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01634">https://arxiv.org/pdf/2502.01634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01634]] Online Gradient Boosting Decision Tree: In-Place Updates for Efficient Adding/Deleting Data(https://arxiv.org/abs/2502.01634)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Gradient Boosting Decision Tree (GBDT) is one of the most popular machine learning models in various applications. However, in the traditional settings, all data should be simultaneously accessed in the training procedure: it does not allow to add or delete any data instances after training. In this paper, we propose an efficient online learning framework for GBDT supporting both incremental and decremental learning. To the best of our knowledge, this is the first work that considers an in-place unified incremental and decremental learning on GBDT. To reduce the learning cost, we present a collection of optimizations for our framework, so that it can add or delete a small fraction of data on the fly. We theoretically show the relationship between the hyper-parameters of the proposed optimizations, which enables trading off accuracy and cost on incremental and decremental learning. The backdoor attack results show that our framework can successfully inject and remove backdoor in a well-trained model using incremental and decremental learning, and the empirical results on public datasets confirm the effectiveness and efficiency of our proposed online learning framework and optimizations.</li>
</ul>

<h3>Title: Lifelong Sequential Knowledge Editing without Model Degradation</h3>
<ul>
<li><strong>Authors: </strong>Akshat Gupta, Phudish Prateepamornkul, Maochuan Lu, Ahmed Alaa, Thomas Hartvigsen, Gopala Anumanchipalli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01636">https://arxiv.org/abs/2502.01636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01636">https://arxiv.org/pdf/2502.01636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01636]] Lifelong Sequential Knowledge Editing without Model Degradation(https://arxiv.org/abs/2502.01636)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Prior work in parameter-modifying knowledge editing has shown that large-scale sequential editing leads to significant model degradation. In this paper, we study the reasons behind this and scale sequential knowledge editing to 10,000 sequential edits, while maintaining the downstream performance of the original model. We first show that locate-then-edit knowledge editing methods lead to overfitting on the edited facts. We also show that continuous knowledge editing using these methods leads to disproportionate growth in the norm of the edited matrix. We then provide a crucial insight into the inner workings of locate-then-edit methods. We show that norm-growth is a hidden trick employed by these methods that gives larger importance to the output activations produced from the edited layers. With this "importance hacking", the edited layers provide a much larger contributions to the model's output. To mitigate these issues, we present ENCORE - Early stopping and Norm-Constrained Robust knowledge Editing. ENCORE controls for overfitting and the disproportionate norm-growth to enable long-term sequential editing, where we are able to perform up to 10,000 sequential edits without loss of downstream performance. ENCORE is also 61% faster than MEMIT and 64% faster than AlphaEdit on Llama3-8B.</li>
</ul>

<h3>Title: SliderSpace: Decomposing the Visual Capabilities of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Rohit Gandikota, Zongze Wu, Richard Zhang, David Bau, Eli Shechtman, Nick Kolkin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01639">https://arxiv.org/abs/2502.01639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01639">https://arxiv.org/pdf/2502.01639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01639]] SliderSpace: Decomposing the Visual Capabilities of Diffusion Models(https://arxiv.org/abs/2502.01639)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present SliderSpace, a framework for automatically decomposing the visual capabilities of diffusion models into controllable and human-understandable directions. Unlike existing control methods that require a user to specify attributes for each edit direction individually, SliderSpace discovers multiple interpretable and diverse directions simultaneously from a single text prompt. Each direction is trained as a low-rank adaptor, enabling compositional control and the discovery of surprising possibilities in the model's latent space. Through extensive experiments on state-of-the-art diffusion models, we demonstrate SliderSpace's effectiveness across three applications: concept decomposition, artistic style exploration, and diversity enhancement. Our quantitative evaluation shows that SliderSpace-discovered directions decompose the visual structure of model's knowledge effectively, offering insights into the latent capabilities encoded within diffusion models. User studies further validate that our method produces more diverse and useful variations compared to baselines. Our code, data and trained weights are available at this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
