<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-11-06</h1>
<h3>Title: Quantum-Classical Hybrid Encryption Framework Based on Simulated BB84 and AES-256: Design and Experimental Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Hector E Mozo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02836">https://arxiv.org/abs/2511.02836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02836">https://arxiv.org/pdf/2511.02836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02836]] Quantum-Classical Hybrid Encryption Framework Based on Simulated BB84 and AES-256: Design and Experimental Evaluation(https://arxiv.org/abs/2511.02836)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>This paper presents the design, implementation, and evaluation of a hybrid encryption framework that combines quantum key distribution, specifically a simulated BB84 protocol, with AES-256 encryption. The system enables secure file encryption by leveraging quantum principles for key generation and classical cryptography for data protection. It introduces integrity validation mechanisms, including HMAC verification and optional post-quantum digital signatures, ensuring robustness even in the presence of quantum-capable adversaries. The entire architecture is implemented in Python, with modular components simulating quantum key exchange, encryption, and secure packaging. Experimental results include visual testing of various attack scenarios, such as key tampering, HMAC failure, and file corruption, demonstrating the effectiveness and resilience of the approach. The proposed solution serves as a practical foundation for quantum-aware cybersecurity systems.</li>
</ul>

<h3>Title: AI Agents with Decentralized Identifiers and Verifiable Credentials</h3>
<ul>
<li><strong>Authors: </strong>Sandro Rodriguez Garzon, Awid Vaziry, Enis Mert Kuzu, Dennis Enrique Gehrmann, Buse Varkan, Alexander Gaballa, Axel Küpper</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02841">https://arxiv.org/abs/2511.02841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02841">https://arxiv.org/pdf/2511.02841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02841]] AI Agents with Decentralized Identifiers and Verifiable Credentials(https://arxiv.org/abs/2511.02841)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>LLM-based AI agents still lack the technical means to automatically build nuanced and differentiated trust in other agents at the beginning of an agent-to-agent dialogue. But autonomous and interoperable trust establishing becomes a fundamental prerequisite once agents start to operate beyond isolated environments and engage in dialogues across individual or organizational boundaries. A promising way to fill this gap in Agentic AI is to equip agents with long-lived digital identities and introduce tamper-proof and flexible identity-bound attestations of agents, provisioned by commonly trusted third parties and designed for cross-domain verifiability. This article presents a conceptual framework and a prototypical multi-agent system, where each agent is endowed with a self-sovereign digital identity. It combines a unique and ledger-anchored Decentralized Identifier (DID) of an agent with a set of third-party issued Verifiable Credentials (VCs). This enables agents at the start of a dialog to prove ownership of their self-controlled DIDs for authentication purposes and to establish various cross-domain trust relationships through the spontaneous exchange of their self-hosted DID-bound VCs. A comprehensive evaluation of the prototypical implementation demonstrates technical feasibility but also reveals limitations once an agent's LLM is in sole charge to control the respective security procedures.</li>
</ul>

<h3>Title: FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels</h3>
<ul>
<li><strong>Authors: </strong>Jiedong Jiang, Wanyi He, Yuefeng Wang, Guoxiong Gao, Yongle Hu, Jingting Wang, Nailing Guan, Peihao Wu, Chunbo Dai, Liang Xiao, Bin Dong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.FL, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02872">https://arxiv.org/abs/2511.02872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02872">https://arxiv.org/pdf/2511.02872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02872]] FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels(https://arxiv.org/abs/2511.02872)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have demonstrated impressive capabilities in formal theorem proving, particularly on contest-based mathematical benchmarks like the IMO. However, these contests do not reflect the depth, breadth, and abstraction of modern mathematical research. To bridge this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new benchmark series in formal algebra designed to chart a course toward advanced mathematical reasoning. We present two new components, FATE-H and FATE-X, each with 100 problems in abstract and commutative algebra. The FATE series spans a difficulty spectrum from undergraduate exercises to problems exceeding PhD qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both PhD-level exam difficulty and the coverage of the Mathlib library. Our evaluations of state-of-the-art LLM provers on this new benchmark reveal a stark performance gap compared to contest math: the best model achieves only 3% (pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals that models' natural-language reasoning is notably more accurate than their ability to formalize this reasoning. We systematically classify the common errors that arise during this formalization process. Furthermore, a comparative study shows that a specialized prover can exhibit less effective reflection than general-purpose models, reducing its accuracy at the natural-language stage. We believe FATE provides a robust and challenging benchmark that establishes essential checkpoints on the path toward research-level formal mathematical reasoning.</li>
</ul>

<h3>Title: Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>W.K.M Mithsara, Ning Yang, Ahmed Imteaj, Hussein Zangoti, Abdur R. Shahid</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02894">https://arxiv.org/abs/2511.02894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02894">https://arxiv.org/pdf/2511.02894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02894]] Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models(https://arxiv.org/abs/2511.02894)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The widespread integration of wearable sensing devices in Internet of Things (IoT) ecosystems, particularly in healthcare, smart homes, and industrial applications, has required robust human activity recognition (HAR) techniques to improve functionality and user experience. Although machine learning models have advanced HAR, they are increasingly susceptible to data poisoning attacks that compromise the data integrity and reliability of these systems. Conventional approaches to defending against such attacks often require extensive task-specific training with large, labeled datasets, which limits adaptability in dynamic IoT environments. This work proposes a novel framework that uses large language models (LLMs) to perform poisoning detection and sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot learning paradigms. Our approach incorporates \textit{role play} prompting, whereby the LLM assumes the role of expert to contextualize and evaluate sensor anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer poisoning indicators in the raw sensor data and plausible clean alternatives. These strategies minimize reliance on curation of extensive datasets and enable robust, adaptable defense mechanisms in real-time. We perform an extensive evaluation of the framework, quantifying detection accuracy, sanitization quality, latency, and communication cost, thus demonstrating the practicality and effectiveness of LLMs in improving the security and reliability of wearable IoT systems.</li>
</ul>

<h3>Title: Designing Proportionate Cybersecurity Frameworks for European Micro-Enterprises: Lessons from the Squad 2025 Case</h3>
<ul>
<li><strong>Authors: </strong>Roberto Garrone</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02898">https://arxiv.org/abs/2511.02898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02898">https://arxiv.org/pdf/2511.02898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02898]] Designing Proportionate Cybersecurity Frameworks for European Micro-Enterprises: Lessons from the Squad 2025 Case(https://arxiv.org/abs/2511.02898)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Micro and small enterprises (SMEs) account for most European businesses yet remain highly vulnerable to cyber threats. This paper analyses the design logic of a recent European policy initiative -- the Squad 2025 Playbook on Cybersecurity Awareness for Micro-SMEs -- to extract general principles for proportionate, resource-aware cybersecurity governance. The author participated in the Squad 2025 team and originally proposed the seven-step preventive structure that later shaped the Playbook's design, subsequently refined collaboratively within the project. The framework was guided by the author's design premise that raising cybersecurity awareness among micro- and small-enterprise actors represents the most efficient short-term lever for increasing sensitivity to cybercrime and promoting protective behaviours. Without reproducing any proprietary material, the paper reconstructs the conceptual architecture of that approach within the broader context of ENISA guidance, ISO 27005, and the NIS2 Directive. It proposes a generic seven-dimension preventive model suitable for micro-enterprise adoption and discusses implications for policy transfer, awareness training, and maturity assessment.</li>
</ul>

<h3>Title: Cache Mechanism for Agent RAG Systems</h3>
<ul>
<li><strong>Authors: </strong>Shuhang Lin, Zhencan Peng, Lingyao Li, Xiao Lin, Xi Zhu, Yongfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02919">https://arxiv.org/abs/2511.02919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02919">https://arxiv.org/pdf/2511.02919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02919]] Cache Mechanism for Agent RAG Systems(https://arxiv.org/abs/2511.02919)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Model (LLM)-based agents have been propelled by Retrieval-Augmented Generation (RAG), which grants the models access to vast external knowledge bases. Despite RAG's success in improving agent performance, agent-level cache management, particularly constructing, maintaining, and updating a compact, relevant corpus dynamically tailored to each agent's need, remains underexplored. Therefore, we introduce ARC (Agent RAG Cache Mechanism), a novel, annotation-free caching framework that dynamically manages small, high-value corpora for each agent. By synthesizing historical query distribution patterns with the intrinsic geometry of cached items in the embedding space, ARC automatically maintains a high-relevance cache. With comprehensive experiments on three retrieval datasets, our experimental results demonstrate that ARC reduces storage requirements to 0.015% of the original corpus while offering up to 79.8% has-answer rate and reducing average retrieval latency by 80%. Our results demonstrate that ARC can drastically enhance efficiency and effectiveness in RAG-powered LLM agents.</li>
</ul>

<h3>Title: Lightweight Session-Key Rekeying Framework for Secure IoT-Edge Communication</h3>
<ul>
<li><strong>Authors: </strong>Haranath Rakshit, Rajkumar Bhandari, Subhasis Banerjee</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02924">https://arxiv.org/abs/2511.02924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02924">https://arxiv.org/pdf/2511.02924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02924]] Lightweight Session-Key Rekeying Framework for Secure IoT-Edge Communication(https://arxiv.org/abs/2511.02924)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>The proliferation of Internet of Things (IoT) networks demands security mechanisms that protect constrained devices without the computational cost of public-key cryptography. Conventional Pre-Shared Key (PSK) encryption, while efficient, remains vulnerable due to static key reuse, replay attacks, and the lack of forward secrecy. This paper presents the Dynamic Session Enhanced Key Protocol (DSEKP) - a lightweight session-key rekeying framework, a fully symmetric extension to PSK that derives per-session AES-GCM keys using the HMAC-based Key Derivation Function (HKDF-SHA256) and authenticates session establishment through an HMAC proof in a single init-ack exchange. DSEKP was implemented on an ESP32 IoT sensor node and a Raspberry Pi 5 edge server communicating through a Mosquitto MQTT broker, and benchmarked against a static PSK baseline over more than 6,500 encrypted packets per configuration. The results demonstrate nearly identical throughput and reliability, with moderate overhead - mean latency increased by 27% and payload size by 10% - while delivering per-session forward secrecy and built-in replay protection. These findings confirm that dynamic symmetric rekeying can substantially strengthen IoT-Edge links with minimal computational and bandwidth cost, offering a practical migration path from static PSK to session-aware, scalable, and reproducible IoT security.</li>
</ul>

<h3>Title: Generative Hints</h3>
<ul>
<li><strong>Authors: </strong>Andy Dimnaku, Abdullah Yusuf Kavranoğlu, Yaser Abu-Mostafa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02933">https://arxiv.org/abs/2511.02933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02933">https://arxiv.org/pdf/2511.02933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02933]] Generative Hints(https://arxiv.org/abs/2511.02933)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Data augmentation is widely used in vision to introduce variation and mitigate overfitting, through enabling models to learn invariant properties, such as spatial invariance. However, these properties are not fully captured by data augmentation alone, since it attempts to learn the property on transformations of the training data only. We propose generative hints, a training methodology that directly enforces known invariances in the entire input space. Our approach leverages a generative model trained on the training set to approximate the input distribution and generate unlabeled images, which we refer to as virtual examples. These virtual examples are used to enforce functional properties known as hints. In generative hints, although the training dataset is fully labeled, the model is trained in a semi-supervised manner on both the classification and hint objectives, using the unlabeled virtual examples to guide the model in learning the desired hint. Across datasets, architectures, and loss functions, generative hints consistently outperform standard data augmentation when learning the same property. On popular fine-grained visual classification benchmarks, we achieved up to 1.78% top-1 accuracy improvement (0.63% on average) over fine-tuned models with data augmentation and an average performance boost of 1.286% on the CheXpert X-ray dataset.</li>
</ul>

<h3>Title: Zero-shot data citation function classification using transformer-based large language models (LLMs)</h3>
<ul>
<li><strong>Authors: </strong>Neil Byers, Ali Zaidi, Valerie Skye, Chris Beecroft, Kjiersten Fagnan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02936">https://arxiv.org/abs/2511.02936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02936">https://arxiv.org/pdf/2511.02936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02936]] Zero-shot data citation function classification using transformer-based large language models (LLMs)(https://arxiv.org/abs/2511.02936)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Efforts have increased in recent years to identify associations between specific datasets and the scientific literature that incorporates them. Knowing that a given publication cites a given dataset, the next logical step is to explore how or why that data was used. Advances in recent years with pretrained, transformer-based large language models (LLMs) offer potential means for scaling the description of data use cases in the published literature. This avoids expensive manual labeling and the development of training datasets for classical machine-learning (ML) systems. In this work we apply an open-source LLM, Llama 3.1-405B, to generate structured data use case labels for publications known to incorporate specific genomic datasets. We also introduce a novel evaluation framework for determining the efficacy of our methods. Our results demonstrate that the stock model can achieve an F1 score of .674 on a zero-shot data citation classification task with no previously defined categories. While promising, our results are qualified by barriers related to data availability, prompt overfitting, computational infrastructure, and the expense required to conduct responsible performance evaluation.</li>
</ul>

<h3>Title: EvtSlowTV - A Large and Diverse Dataset for Event-Based Depth Estimation</h3>
<ul>
<li><strong>Authors: </strong>Sadiq Layi Macaulay, Nimet Kaygusuz, Simon Hadfield</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02953">https://arxiv.org/abs/2511.02953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02953">https://arxiv.org/pdf/2511.02953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02953]] EvtSlowTV - A Large and Diverse Dataset for Event-Based Depth Estimation(https://arxiv.org/abs/2511.02953)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Event cameras, with their high dynamic range (HDR) and low latency, offer a promising alternative for robust depth estimation in challenging environments. However, many event-based depth estimation approaches are constrained by small-scale annotated datasets, limiting their generalizability to real-world scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event camera dataset curated from publicly available YouTube footage, which contains more than 13B events across various environmental conditions and motions, including seasonal hiking, flying, scenic driving, and underwater exploration. EvtSlowTV is an order of magnitude larger than existing event datasets, providing an unconstrained, naturalistic setting for event-based depth learning. This work shows the suitability of EvtSlowTV for a self-supervised learning framework to capitalise on the HDR potential of raw event streams. We further demonstrate that training with EvtSlowTV enhances the model's ability to generalise to complex scenes and motions. Our approach removes the need for frame-based annotations and preserves the asynchronous nature of event data.</li>
</ul>

<h3>Title: Inference-Time Personalized Alignment with a Few User Preference Queries</h3>
<ul>
<li><strong>Authors: </strong>Victor-Alexandru Pădurean, Parameswaran Kamalaruban, Nachiket Kotalwar, Alkis Gotovos, Adish Singla</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02966">https://arxiv.org/abs/2511.02966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02966">https://arxiv.org/pdf/2511.02966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02966]] Inference-Time Personalized Alignment with a Few User Preference Queries(https://arxiv.org/abs/2511.02966)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We study the problem of aligning a generative model's response with a user's preferences. Recent works have proposed several different formulations for personalized alignment; however, they either require a large amount of user preference queries or require that the preference be explicitly specified as a text input. In this paper, we propose a novel inference-time personalized alignment method, UserAlign, that elicits the user's preferences with a few queries as pairwise response comparisons. In particular, UserAlign builds on the theoretical framework of best-arm identification in logistic bandits and selects a personalized response from a fixed pool of the model's generated responses. The key idea is to consider the user's feedback consistent and noise-free, and incorporate it into the theoretical framework to identify the best response quickly. Experimental results across several tasks, involving personalized text and image generation, showcase the effectiveness of UserAlign in achieving personalized alignment.</li>
</ul>

<h3>Title: Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Mikhael Djajapermana, Moritz Reiber, Daniel Mueller-Gritschneder, Ulf Schlichtmann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02992">https://arxiv.org/abs/2511.02992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02992">https://arxiv.org/pdf/2511.02992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02992]] Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification(https://arxiv.org/abs/2511.02992)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT) have outperformed pure CNN or ViT architecture. However, since these architectures require large parameters and incur large computational costs, they are unsuitable for tinyML deployment. This paper introduces a new hybrid CNN-ViT search space for Neural Architecture Search (NAS) to find efficient hybrid architectures for image classification. The search space covers hybrid CNN and ViT blocks to learn local and global information, as well as the novel Pooling block of searchable pooling layers for efficient feature map reduction. Experimental results on the CIFAR10 dataset show that our proposed search space can produce hybrid CNN-ViT architectures with superior accuracy and inference speed to ResNet-based tinyML models under tight model size constraints.</li>
</ul>

<h3>Title: PrivyWave: Privacy-Aware Wireless Sensing of Heartbeat</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Gao, Tanvir Ahmed, Zekun Chang, Thijs Roumen, Rajalakshmi Nandakumar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.HC, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02993">https://arxiv.org/abs/2511.02993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02993">https://arxiv.org/pdf/2511.02993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02993]] PrivyWave: Privacy-Aware Wireless Sensing of Heartbeat(https://arxiv.org/abs/2511.02993)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Wireless sensing technologies can now detect heartbeats using radio frequency and acoustic signals, raising significant privacy concerns. Existing privacy solutions either protect from all sensing systems indiscriminately preventing any utility or operate post-data collection, failing to enable selective access where authorized devices can monitor while unauthorized ones cannot. We present a key-based physical obfuscation system, PrivyWave, that addresses this challenge by generating controlled decoy heartbeat signals at cryptographically-determined frequencies. Unauthorized sensors receive a mixture of real and decoy signals that are indistinguishable without the secret key, while authorized sensors use the key to filter out decoys and recover accurate measurements. Our evaluation with 13 participants demonstrates effective protection across both sensing modalities: for mmWave radar, unauthorized sensors show 21.3 BPM mean absolute error while authorized sensors maintain a much smaller 5.8 BPM; for acoustic sensing, unauthorized error increases to 42.0 BPM while authorized sensors achieve 9.7 BPM. The system operates across multiple sensing modalities without per-modality customization and provides cryptographic obfuscation guarantees. Performance benchmarks show robust protection across different distances (30-150 cm), orientations (120° field of view), and diverse indoor environments, establishing physical-layer obfuscation as a viable approach for selective privacy in pervasive health monitoring.</li>
</ul>

<h3>Title: LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Gyeom Hwangbo, Hyungjoo Chae, Minseok Kang, Hyeonjong Ju, Soohyun Oh, Jinyoung Yeo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03001">https://arxiv.org/abs/2511.03001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03001">https://arxiv.org/pdf/2511.03001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03001]] LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation(https://arxiv.org/abs/2511.03001)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite recent progress in using Large Language Models (LLMs) for automatically generating 3D scenes, generated scenes often lack realistic spatial layouts and object attributes found in real-world environments. As this problem stems from insufficiently detailed, coarse-grained instructions, advancing 3D scene synthesis guided by more detailed, fine-grained instructions that reflect real-world environments becomes crucial. Without such realistic scenes, training embodied agents in unrealistic environments can lead them to learn priors that diverge significantly from real-world physics and semantics, degrading their performance when deployed. Thus, verifying the alignment between the fine-grained instruction and the generated scene is essential for effective learning. However, current evaluation methods, such as CLIPScore and vision-language models (VLMs), often fail to reliably assess such alignment. This shortcoming arises primarily from their shallow understanding of 3D scenes, which often leads to improperly grounded scene components. To address this, we introduce LEGO-Eval, an evaluation framework equipped with diverse tools designed to explicitly ground scene components, enabling more accurate alignment assessments. We also present LEGO-Bench, a benchmark of detailed instructions that specify complex layouts and attributes of real-world environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with LEGO-Bench reveals significant limitations in current generation methods. Across all evaluated approaches, success rates reached at most 10% in generating scenes that fully align with fine-grained instructions.</li>
</ul>

<h3>Title: Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning</h3>
<ul>
<li><strong>Authors: </strong>Dakota Hester, Vitor S. Martins, Lucas B. Ferreira, Thainara M. A. Lima</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03004">https://arxiv.org/abs/2511.03004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03004">https://arxiv.org/pdf/2511.03004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03004]] Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning(https://arxiv.org/abs/2511.03004)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning semantic segmentation methods have shown promising performance for very high 1-m resolution land cover classification, but the challenge of collecting large volumes of representative training data creates a significant barrier to widespread adoption of such models for meter-scale land cover mapping over large areas. In this study, we present a novel label-efficient approach for statewide 1-m land cover classification using only 1,000 annotated reference image patches with self-supervised deep learning. We use the "Bootstrap Your Own Latent" pre-training strategy with a large amount of unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to pre-train a ResNet-101 convolutional encoder. The learned encoder weights were subsequently transferred into multiple deep semantic segmentation architectures (FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then fine-tuned using very small training dataset sizes with cross-validation (250, 500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall accuracy and 75.58% macro F1 score using an ensemble of the best performing U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more than 123 billion pixels over the state of Mississippi, USA. Detailed qualitative and quantitative analysis revealed accurate mapping of open water and forested areas, while highlighting challenges in accurate delineation between cropland, herbaceous, and barren land cover types. These results show that self-supervised learning is an effective strategy for reducing the need for large volumes of manually annotated data, directly addressing a major limitation to high spatial resolution land cover mapping at scale.</li>
</ul>

<h3>Title: Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT</h3>
<ul>
<li><strong>Authors: </strong>Hee-Jin Lee, Zhen Guo, Luchao Jin, Morteza Moazami Goudarzi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03005">https://arxiv.org/abs/2511.03005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03005">https://arxiv.org/pdf/2511.03005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03005]] Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT(https://arxiv.org/abs/2511.03005)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller open-source language models (LLMs) to surpass substantially larger proprietary models in customer service summarization tasks. The pipeline first analyzes and categorizes common errors in summaries produced by a teacher model (GPT-3.5), then performs a targeted revision using a compact editor model (Llama 3.1 70B) to generate high-quality, refined training data. Fine-tuning a smaller student model (Llama 3.1 8B) on this refined data resulted in superior summarization performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and data privacy while maintaining competitive accuracy, illustrating a generalizable framework for enhancing open-source LLMs across diverse downstream applications.</li>
</ul>

<h3>Title: A Foundation Model for Brain MRI with Dynamic Modality Integration</h3>
<ul>
<li><strong>Authors: </strong>Minh Sao Khue Luu, Bair N. Tuchinov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03014">https://arxiv.org/abs/2511.03014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03014">https://arxiv.org/pdf/2511.03014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03014]] A Foundation Model for Brain MRI with Dynamic Modality Integration(https://arxiv.org/abs/2511.03014)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>We present a foundation model for brain MRI that can work with different combinations of imaging sequences. The model uses one encoder with learnable modality embeddings, conditional layer normalization, and a masked autoencoding objective that accounts for missing modalities. A variance-covariance regularizer is applied to stabilize feature learning and improve representation diversity. This design removes the need for separate models for each modality and allows the network to adapt when some sequences are missing or unseen. It is trained on about 60,000 multi-center MRIs using self-supervised reconstruction and modality imputation to learn flexible representations. A learnable modality embedding guides feature extraction so the encoder can adjust to different inputs. We describe our planned evaluation on brain tumor and multiple sclerosis segmentation, as well as lesion classification, under various modality settings. Preliminary results show that the method works feasibly, and further experiments are planned to study its performance in more detail. All code and pretrained models are available at this https URL</li>
</ul>

<h3>Title: Discrete Bayesian Sample Inference for Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Ole Petersen, Marcel Kollovieh, Marten Lienen, Stephan Günnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03015">https://arxiv.org/abs/2511.03015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03015">https://arxiv.org/pdf/2511.03015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03015]] Discrete Bayesian Sample Inference for Graph Generation(https://arxiv.org/abs/2511.03015)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generating graph-structured data is crucial in applications such as molecular generation, knowledge graphs, and network analysis. However, their discrete, unordered nature makes them difficult for traditional generative models, leading to the rise of discrete diffusion and flow matching models. In this work, we introduce GraphBSI, a novel one-shot graph generative model based on Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI iteratively refines a belief over graphs in the continuous space of distribution parameters, naturally handling discrete structures. Further, we state BSI as a stochastic differential equation (SDE) and derive a noise-controlled family of SDEs that preserves the marginal distributions via an approximation of the score function. Our theoretical analysis further reveals the connection to Bayesian Flow Networks and Diffusion models. Finally, in our empirical evaluation, we demonstrate state-of-the-art performance on molecular and synthetic graph generation, outperforming existing one-shot graph generative models on the standard benchmarks Moses and GuacaMol.</li>
</ul>

<h3>Title: Exploratory Analysis of Cyberattack Patterns on E-Commerce Platforms Using Statistical Methods</h3>
<ul>
<li><strong>Authors: </strong>Fatimo Adenike Adeniya (York St John University, London Campus, London, United Kingdom)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03020">https://arxiv.org/abs/2511.03020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03020">https://arxiv.org/pdf/2511.03020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03020]] Exploratory Analysis of Cyberattack Patterns on E-Commerce Platforms Using Statistical Methods(https://arxiv.org/abs/2511.03020)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Cyberattacks on e-commerce platforms have grown in sophistication, threatening consumer trust and operational continuity. This research presents a hybrid analytical framework that integrates statistical modelling and machine learning for detecting and forecasting cyberattack patterns in the e-commerce domain. Using the Verizon Community Data Breach (VCDB) dataset, the study applies Auto ARIMA for temporal forecasting and significance testing, including a Mann-Whitney U test (U = 2579981.5, p = 0.0121), which confirmed that holiday shopping events experienced significantly more severe cyberattacks than non-holiday periods. ANOVA was also used to examine seasonal variation in threat severity, while ensemble machine learning models (XGBoost, LightGBM, and CatBoost) were employed for predictive classification. Results reveal recurrent attack spikes during high-risk periods such as Black Friday and holiday seasons, with breaches involving Personally Identifiable Information (PII) exhibiting elevated threat indicators. Among the models, CatBoost achieved the highest performance (accuracy = 85.29%, F1 score = 0.2254, ROC AUC = 0.8247). The framework uniquely combines seasonal forecasting with interpretable ensemble learning, enabling temporal risk anticipation and breach-type classification. Ethical considerations, including responsible use of sensitive data and bias assessment, were incorporated. Despite class imbalance and reliance on historical data, the study provides insights for proactive cybersecurity resource allocation and outlines directions for future real-time threat detection research.</li>
</ul>

<h3>Title: Leveraging Discrete Function Decomposability for Scientific Design</h3>
<ul>
<li><strong>Authors: </strong>James C. Bowden, Sergey Levine, Jennifer Listgarten</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03032">https://arxiv.org/abs/2511.03032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03032">https://arxiv.org/pdf/2511.03032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03032]] Leveraging Discrete Function Decomposability for Scientific Design(https://arxiv.org/abs/2511.03032)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In the era of AI-driven science and engineering, we often want to design discrete objects in silico according to user-specified properties. For example, we may wish to design a protein to bind its target, arrange components within a circuit to minimize latency, or find materials with certain properties. Given a property predictive model, in silico design typically involves training a generative model over the design space (e.g., protein sequence space) to concentrate on designs with the desired properties. Distributional optimization -- which can be formalized as an estimation of distribution algorithm or as reinforcement learning policy optimization -- finds the generative model that maximizes an objective function in expectation. Optimizing a distribution over discrete-valued designs is in general challenging because of the combinatorial nature of the design space. However, many property predictors in scientific applications are decomposable in the sense that they can be factorized over design variables in a way that could in principle enable more effective optimization. For example, amino acids at a catalytic site of a protein may only loosely interact with amino acids of the rest of the protein to achieve maximal catalytic activity. Current distributional optimization algorithms are unable to make use of such decomposability structure. Herein, we propose and demonstrate use of a new distributional optimization algorithm, Decomposition-Aware Distributional Optimization (DADO), that can leverage any decomposability defined by a junction tree on the design variables, to make optimization more efficient. At its core, DADO employs a soft-factorized "search distribution" -- a learned generative model -- for efficient navigation of the search space, invoking graph message-passing to coordinate optimization across linked factors.</li>
</ul>

<h3>Title: Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yan Cathy Hua, Paul Denny, Jörg Wicker, Katerina Taškova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03034">https://arxiv.org/abs/2511.03034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03034">https://arxiv.org/pdf/2511.03034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03034]] Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis(https://arxiv.org/abs/2511.03034)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, data-free, generative</a></li>
<li><strong>Abstract: </strong>Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining approach that identifies and classifies opinions associated with specific entities (aspects) or their categories within a sentence. Despite its rapid growth and broad potential, ABSA research and resources remain concentrated in commercial domains, leaving analytical needs unmet in high-demand yet low-resource areas such as education and healthcare. Domain adaptation challenges and most existing methods' reliance on resource-intensive in-training knowledge injection further hinder progress in these areas. Moreover, traditional evaluation methods based on exact matches are overly rigid for ABSA tasks, penalising any boundary variations which may misrepresent the performance of generative models. This work addresses these gaps through three contributions: 1) We propose a novel evaluation method, Flexible Text Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates realistic extraction boundary variations while maintaining strong correlation with traditional metrics and offering fine-grained diagnostics. 2) We present the first ABSA study of small decoder-only generative language models (SLMs; <7B parameters), examining resource lower bounds via a case study in education review ABSA. We systematically explore data-free (in-context learning and weight merging) and data-light fine-tuning methods, and propose a multitask fine-tuning strategy that significantly enhances SLM performance, enabling 1.5-3.8 B models to surpass proprietary large models and approach benchmark results with only 200-1,000 examples on a single GPU. 3) We release the first public set of education review ABSA resources to support future research in low-resource domains.</li>
</ul>

<h3>Title: Data-Efficient Realized Volatility Forecasting with Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Emi Soroka, Artem Arzyn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03046">https://arxiv.org/abs/2511.03046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03046">https://arxiv.org/pdf/2511.03046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03046]] Data-Efficient Realized Volatility Forecasting with Vision Transformers(https://arxiv.org/abs/2511.03046)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent work in financial machine learning has shown the virtue of complexity: the phenomenon by which deep learning methods capable of learning highly nonlinear relationships outperform simpler approaches in financial forecasting. While transformer architectures like Informer have shown promise for financial time series forecasting, the application of transformer models for options data remains largely unexplored. We conduct preliminary studies towards the development of a transformer model for options data by training the Vision Transformer (ViT) architecture, typically used in modern image recognition and classification systems, to predict the realized volatility of an asset over the next 30 days from its implied volatility surface (augmented with date information) for a single day. We show that the ViT can learn seasonal patterns and nonlinear features from the IV surface, suggesting a promising direction for model development.</li>
</ul>

<h3>Title: Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions</h3>
<ul>
<li><strong>Authors: </strong>Emi Soroka, Tanmay Chopra, Krish Desai, Sanjay Lall</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03047">https://arxiv.org/abs/2511.03047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03047">https://arxiv.org/pdf/2511.03047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03047]] Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions(https://arxiv.org/abs/2511.03047)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have seen increasing popularity in enterprise applications where AI agents and humans engage in objective-driven interactions. However, these systems are difficult to evaluate: data may be complex and unlabeled; human annotation is often impractical at scale; custom metrics can monitor for specific errors, but not previously-undetected ones; and LLM judges can produce unreliable results. We introduce the first set of unsupervised metrics for objective-driven interactions, leveraging statistical properties of unlabeled interaction data and using fine-tuned LLMs to adapt to distributional shifts. We develop metrics for labeling user goals, measuring goal completion, and quantifying LLM uncertainty without grounding evaluations in human-generated ideal responses. Our approach is validated on open-domain and task-specific interaction data.</li>
</ul>

<h3>Title: ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment</h3>
<ul>
<li><strong>Authors: </strong>Anthony Hevia, Sanjana Chintalapati, Veronica Ka Wai Lai, Thanh Tam Nguyen, Wai-Tat Wong, Terry Klassen, Lucy Lu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03048">https://arxiv.org/abs/2511.03048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03048">https://arxiv.org/pdf/2511.03048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03048]] ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment(https://arxiv.org/abs/2511.03048)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present ROBOTO2, an open-source, web-based platform for large language model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2 streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process via an interactive interface that combines PDF parsing, retrieval-augmented LLM prompting, and human-in-the-loop review. Users can upload clinical trial reports, receive preliminary answers and supporting evidence for ROB2 signaling questions, and provide real-time feedback or corrections to system suggestions. ROBOTO2 is publicly available at this https URL, with code and data released to foster reproducibility and adoption. We construct and release a dataset of 521 pediatric clinical trial reports (8954 signaling questions with 1202 evidence passages), annotated using both manually and LLM-assisted methods, serving as a benchmark and enabling future research. Using this dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into current model capabilities and ongoing challenges in automating this critical aspect of systematic review.</li>
</ul>

<h3>Title: From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Xu, Olaf Wysocki, Christoph Holst</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03053">https://arxiv.org/abs/2511.03053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03053">https://arxiv.org/pdf/2511.03053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03053]] From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth(https://arxiv.org/abs/2511.03053)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning (MLS) point clouds in many high-precision applications such as Scan-to-BIM, deformation analysis, and 3D modeling. However, obtaining the ground truth (GT) for evaluation is often costly and infeasible in many real-world applications. To reduce this long-standing reliance on GT in uncertainty evaluation research, this study presents a learning-based framework for MLS point clouds that integrates optimal neighborhood estimation with geometric feature extraction. Experiments on a real-world dataset show that the proposed framework is feasible and the XGBoost model delivers fully comparable accuracy to Random Forest while achieving substantially higher efficiency (about 3 times faster), providing initial evidence that geometric features can be used to predict point-level uncertainty quantified by the C2C distance. In summary, this study shows that MLS point clouds' uncertainty is learnable, offering a novel learning-based viewpoint towards uncertainty evaluation research.</li>
</ul>

<h3>Title: Reading Between the Lines: The One-Sided Conversation Problem</h3>
<ul>
<li><strong>Authors: </strong>Victoria Ebert, Rishabh Singh, Tuochao Chen, Noah A. Smith, Shyamnath Gollakota</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03056">https://arxiv.org/abs/2511.03056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03056">https://arxiv.org/pdf/2511.03056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03056]] Reading Between the Lines: The One-Sided Conversation Problem(https://arxiv.org/abs/2511.03056)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Conversational AI is constrained in many real-world settings where only one side of a dialogue can be recorded, such as telemedicine, call centers, and smart glasses. We formalize this as the one-sided conversation problem (1SC): inferring and learning from one side of a conversation. We study two tasks: (1) reconstructing the missing speaker's turns for real-time use cases, and (2) generating summaries from one-sided transcripts. Evaluating prompting and finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B testing and LLM-as-a-judge metrics, we find that access to one future turn and information about utterance length improves reconstruction, placeholder prompting helps to mitigate hallucination, and while large models generate promising reconstructions with prompting, smaller models require finetuning. Further, high-quality summaries can be generated without reconstructing missing turns. We present 1SC as a novel challenge and report promising results that mark a step toward privacy-aware conversational AI.</li>
</ul>

<h3>Title: The Curved Spacetime of Transformer Architectures</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Di Sipio, Jairo Diaz-Rodriguez, Luis Serrano</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, math.DG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03060">https://arxiv.org/abs/2511.03060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03060">https://arxiv.org/pdf/2511.03060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03060]] The Curved Spacetime of Transformer Architectures(https://arxiv.org/abs/2511.03060)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a geometric framework for understanding Transformer-based language models, drawing an explicit analogy to General Relativity. Queries and keys induce an effective metric on representation space, and attention acts as a discrete connection that implements parallel transport of value vectors across tokens. Stacked layers provide discrete time-slices through which token representations evolve on this curved manifold, while backpropagation plays the role of a least-action principle that shapes loss-minimizing trajectories in parameter space. If this analogy is correct, token embeddings should not traverse straight paths in feature space; instead, their layer-wise steps should bend and reorient as interactions mediated by embedding space curvature. To test this prediction, we design experiments that expose both the presence and the consequences of curvature: (i) we visualize a curvature landscape for a full paragraph, revealing how local turning angles vary across tokens and layers; (ii) we show through simulations that excess counts of sharp/flat angles and longer length-to-chord ratios are not explainable by dimensionality or chance; and (iii) inspired by Einstein's eclipse experiment, we probe deflection under controlled context edits, demonstrating measurable, meaning-consistent bends in embedding trajectories that confirm attention-induced curvature.</li>
</ul>

<h3>Title: Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Ghaffari, Siddarth Sitaraman, Xutong Liu, Xuchuang Wang, Mohammad Hajiesmaili</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03074">https://arxiv.org/abs/2511.03074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03074">https://arxiv.org/pdf/2511.03074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03074]] Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach(https://arxiv.org/abs/2511.03074)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Online learning to rank (OLTR) studies how to recommend a short ranked list of items from a large pool and improves future rankings based on user clicks. This setting is commonly modeled as cascading bandits, where the objective is to maximize the likelihood that the user clicks on at least one of the presented items across as many timesteps as possible. However, such systems are vulnerable to click fraud and other manipulations (i.e., corruption), where bots or paid click farms inject corrupted feedback that misleads the learning process and degrades user experience. In this paper, we propose MSUCB, a robust algorithm that incorporates a novel mean-of-medians estimator, which to our knowledge is applied to bandits with corruption setting for the first time. This estimator behaves like a standard mean in the absence of corruption, so no cost is paid for robustness. Under corruption, the median step filters out outliers and corrupted samples, keeping the estimate close to its true value. Updating this estimate at every round further accelerates empirical convergence in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence of corruption and degrades gracefully under corruptions, with regret increasing only by an additive term tied to the total corruption. Comprehensive and extensive experiments on real-world datasets further demonstrate that our approach consistently outperforms prior methods while maintaining strong robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret improvement over two state-of-the-art methods.</li>
</ul>

<h3>Title: PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech</h3>
<ul>
<li><strong>Authors: </strong>Michel Wong, Ali Alshehri, Sophia Kao, Haotian He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03080">https://arxiv.org/abs/2511.03080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03080">https://arxiv.org/pdf/2511.03080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03080]] PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech(https://arxiv.org/abs/2511.03080)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</li>
</ul>

<h3>Title: A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Yi Gong, Xinyuan Zhang, Jichen Chai, Yichen Ding, Yifei Lou</a></li>
<li><strong>Subjects: </strong>cs.CV, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03093">https://arxiv.org/abs/2511.03093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03093">https://arxiv.org/pdf/2511.03093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03093]] A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction(https://arxiv.org/abs/2511.03093)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cardiac contraction is a rapid, coordinated process that unfolds across three-dimensional tissue on millisecond timescales. Traditional optical imaging is often inadequate for capturing dynamic cellular structure in the beating heart because of a fundamental trade-off between spatial and temporal resolution. To overcome these limitations, we propose a high-performance computational imaging framework that integrates Compressive Sensing (CS) with Light-Sheet Microscopy (LSM) for efficient, low-phototoxic cardiac imaging. The system performs compressed acquisition of fluorescence signals via random binary mask coding using a Digital Micromirror Device (DMD). We propose a Plug-and-Play (PnP) framework, solved using the alternating direction method of multipliers (ADMM), which flexibly incorporates advanced denoisers, including Tikhonov, Total Variation (TV), and BM3D. To preserve structural continuity in dynamic imaging, we further introduce temporal regularization enforcing smoothness between adjacent z-slices. Experimental results on zebrafish heart imaging under high compression ratios demonstrate that the proposed method successfully reconstructs cellular structures with excellent denoising performance and image clarity, validating the effectiveness and robustness of our algorithm in real-world high-speed, low-light biological imaging scenarios.</li>
</ul>

<h3>Title: Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies</h3>
<ul>
<li><strong>Authors: </strong>Gaia Grosso, Sai Sumedh R. Hindupur, Thomas Fel, Samuel Bright-Thonney, Philip Harris, Demba Ba</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03095">https://arxiv.org/abs/2511.03095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03095">https://arxiv.org/pdf/2511.03095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03095]] Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies(https://arxiv.org/abs/2511.03095)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Modern artificial intelligence has revolutionized our ability to extract rich and versatile data representations across scientific disciplines. Yet, the statistical properties of these representations remain poorly controlled, causing misspecified anomaly detection (AD) methods to falter. Weak or rare signals can remain hidden within the apparent regularity of normal data, creating a gap in our ability to detect and interpret anomalies. We examine this gap and identify a set of structural desiderata for detection methods operating under minimal prior information: sparsity, to enforce parsimony; locality, to preserve geometric sensitivity; and competition, to promote efficient allocation of model capacity. These principles define a class of self-organizing local kernels that adaptively partition the representation space around regions of statistical imbalance. As an instantiation of these principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained within a semi-supervised Neyman--Pearson framework to locally model the likelihood ratio between a sample that may contain anomalies and a nominal, anomaly-free reference. We provide theoretical insights into the mechanisms that drive detection and self-organization in the proposed model, and demonstrate the effectiveness of this approach on realistic high-dimensional problems of scientific discovery, open-world novelty detection, intrusion detection, and generative-model validation. Our applications span both the natural- and computer-science domains. We demonstrate that ensembles containing only a handful of kernels can identify statistically significant anomalous locations within representation spaces of thousands of dimensions, underscoring both the interpretability, efficiency and scalability of the proposed approach.</li>
</ul>

<h3>Title: ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly</h3>
<ul>
<li><strong>Authors: </strong>Miftahur Rahman, Samuel Adebayo, Dorian A. Acevedo-Mejia, David Hester, Daniel McPolin, Karen Rafferty, Debra F. Laefer</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03098">https://arxiv.org/abs/2511.03098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03098">https://arxiv.org/pdf/2511.03098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03098]] ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly(https://arxiv.org/abs/2511.03098)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The Intermeshed Steel Connection (ISC) system, when paired with robotic manipulators, can accelerate steel-frame assembly and improve worker safety by eliminating manual assembly. Dependable perception is one of the initial stages for ISC-aware robots. However, this is hampered by the absence of a dedicated image corpus, as collecting photographs on active construction sites is logistically difficult and raises safety and privacy concerns. In response, we introduce ISC-Perception, the first hybrid dataset expressly designed for ISC component detection. It blends procedurally rendered CAD images, game-engine photorealistic scenes, and a limited, curated set of real photographs, enabling fully automatic labelling of the synthetic portion. We explicitly account for all human effort to produce the dataset, including simulation engine and scene setup, asset preparation, post-processing scripts and quality checks; our total human time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for manual labelling at 60,s per image (-81.7%). A manual pilot on a representative image with five instances of ISC members took 60,s (maximum 80,s), anchoring the manual baseline. Detectors trained on ISC-Perception achieved a mean Average Precision at IoU 0.50 of 0.756, substantially surpassing models trained on synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we report mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for construction-robotics perception, ISC-Perception facilitates rapid development of custom object detectors and is freely available for research and industrial use upon request.</li>
</ul>

<h3>Title: Scaling Multi-Agent Environment Co-Design with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Xiang Li, Michael Amir, Amanda Prorok</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03100">https://arxiv.org/abs/2511.03100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03100">https://arxiv.org/pdf/2511.03100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03100]] Scaling Multi-Agent Environment Co-Design with Diffusion Models(https://arxiv.org/abs/2511.03100)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The agent-environment co-design paradigm jointly optimises agent policies and environment configurations in search of improved system performance. With application domains ranging from warehouse logistics to windfarm management, co-design promises to fundamentally change how we deploy multi-agent systems. However, current co-design methods struggle to scale. They collapse under high-dimensional environment design spaces and suffer from sample inefficiency when addressing moving targets inherent to joint optimisation. We address these challenges by developing Diffusion Co-Design (DiCoDe), a scalable and sample-efficient co-design framework pushing co-design towards practically relevant settings. DiCoDe incorporates two core innovations. First, we introduce Projected Universal Guidance (PUG), a sampling technique that enables DiCoDe to explore a distribution of reward-maximising environments while satisfying hard constraints such as spatial separation between obstacles. Second, we devise a critic distillation mechanism to share knowledge from the reinforcement learning critic, ensuring that the guided diffusion model adapts to evolving agent policies using a dense and up-to-date learning signal. Together, these improvements lead to superior environment-policy pairs when validated on challenging multi-agent environment co-design benchmarks including warehouse automation, multi-agent pathfinding and wind farm optimisation. Our method consistently exceeds the state-of-the-art, achieving, for example, 39% higher rewards in the warehouse setting with 66% fewer simulation samples. This sets a new standard in agent-environment co-design, and is a stepping stone towards reaping the rewards of co-design in real world domains.</li>
</ul>

<h3>Title: CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic</h3>
<ul>
<li><strong>Authors: </strong>Saad Mankarious, Ayah Zirikly</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03102">https://arxiv.org/abs/2511.03102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03102">https://arxiv.org/pdf/2511.03102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03102]] CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic(https://arxiv.org/abs/2511.03102)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mental health disorders affect millions worldwide, yet early detection remains a major challenge, particularly for Arabic-speaking populations where resources are limited and mental health discourse is often discouraged due to cultural stigma. While substantial research has focused on English-language mental health detection, Arabic remains significantly underexplored, partly due to the scarcity of annotated datasets. We present CARMA, the first automatically annotated large-scale dataset of Arabic Reddit posts. The dataset encompasses six mental health conditions, such as Anxiety, Autism, and Depression, and a control group. CARMA surpasses existing resources in both scale and diversity. We conduct qualitative and quantitative analyses of lexical and semantic differences between users, providing insights into the linguistic markers of specific mental health conditions. To demonstrate the dataset's potential for further mental health analysis, we perform classification experiments using a range of models, from shallow classifiers to large language models. Our results highlight the promise of advancing mental health detection in underrepresented languages such as Arabic.</li>
</ul>

<h3>Title: FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation</h3>
<ul>
<li><strong>Authors: </strong>Jiameng Chen, Yida Xiong, Kun Li, Hongzhi Zhang, Xiantao Cai, Wenbin Hu, Jia Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03113">https://arxiv.org/abs/2511.03113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03113">https://arxiv.org/pdf/2511.03113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03113]] FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation(https://arxiv.org/abs/2511.03113)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Computational antibody design holds immense promise for therapeutic discovery, yet existing generative models are fundamentally limited by two core challenges: (i) a lack of dynamical consistency, which yields physically implausible structures, and (ii) poor generalization due to data scarcity and structural bias. We introduce FP-AbDiff, the first antibody generator to enforce Fokker-Planck Equation (FPE) physics along the entire generative trajectory. Our method minimizes a novel FPE residual loss over the mixed manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising scores to assemble into a globally coherent probability flow. This physics-informed regularizer is synergistically integrated with deep biological priors within a state-of-the-art SE(3)-equivariant diffusion framework. Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean Square Deviation of 0.99 Å when superposing on the variable region, a 25% improvement over the previous state-of-the-art model, AbX, and the highest reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored in the more challenging six-CDR co-design task, where our model delivers consistently superior geometric precision, cutting the average full-chain Root Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By aligning generative dynamics with physical laws, FP-AbDiff enhances robustness and generalizability, establishing a principled approach for physically faithful and functionally viable antibody design.</li>
</ul>

<h3>Title: Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Botong.Zhao, Xubin.Wang, Shujing.Lyu, Yue.Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03120">https://arxiv.org/abs/2511.03120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03120">https://arxiv.org/pdf/2511.03120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03120]] Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning(https://arxiv.org/abs/2511.03120)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Integrated circuit manufacturing is highly complex, comprising hundreds of process steps. Defects can arise at any stage, causing yield loss and ultimately degrading product reliability. Supervised methods require extensive human annotation and struggle with emergent categories and rare, data scarce defects. Clustering-based unsupervised methods often exhibit unstable performance due to missing priors. We propose IC DefectNCD, a support set free framework that leverages Image Intrinsic Priors in IC SEM images for defect detection and novel class discovery. We first develop Self Normal Information Guided IC Defect Detection, aggregating representative normal features via a learnable normal information extractor and using reconstruction residuals to coarsely localize defect regions. To handle saliency variations across defects, we introduce an adaptive binarization strategy that produces stable subimages focused on core defective areas. Finally, we design Self Defect Information Guided IC Defect Classification, which incorporates a soft mask guided attention mechanism to inject spatial defect priors into the teacher student model. This enhances sensitivity to defective regions, suppresses background interference, and enables recognition and classification of unseen defects. We validate the approach on a real world dataset spanning three key fabrication stages and covering 15 defect types. Experiments demonstrate robust performance on both defect detection and unseen defect classification.</li>
</ul>

<h3>Title: Control Barrier Function for Aligning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuya Miyaoka, Masaki Inoue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03121">https://arxiv.org/abs/2511.03121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03121">https://arxiv.org/pdf/2511.03121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03121]] Control Barrier Function for Aligning Large Language Models(https://arxiv.org/abs/2511.03121)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper proposes a control-based framework for aligning large language models (LLMs) by leveraging a control barrier function (CBF) to ensure user-desirable text generation. The presented framework applies the CBF safety filter to the predicted token generated from the baseline LLM, to intervene in the generated text. The safety filter includes two significant advantages: this safety filter is an add-on type, allowing it to be used for alignment purposes without fine-tuning the baseline LLM, and if there is an evaluation model regarding the desired alignment, it can be directly applied to the filter design. The overall text-generation system is implemented with open-source language models, aiming to generate positive text.</li>
</ul>

<h3>Title: Accelerating Physical Property Reasoning for Augmented Visual Cognition</h3>
<ul>
<li><strong>Authors: </strong>Hongbo Lan, Zhenlin An, Haoyu Li, Vaibhav Singh, Longfei Shangguan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03126">https://arxiv.org/abs/2511.03126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03126">https://arxiv.org/pdf/2511.03126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03126]] Accelerating Physical Property Reasoning for Augmented Visual Cognition(https://arxiv.org/abs/2511.03126)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>This paper introduces \sysname, a system that accelerates vision-guided physical property reasoning to enable augmented visual cognition. \sysname minimizes the run-time latency of this reasoning pipeline through a combination of both algorithmic and systematic optimizations, including rapid geometric 3D reconstruction, efficient semantic feature fusion, and parallel view encoding. Through these simple yet effective optimizations, \sysname reduces the end-to-end latency of this reasoning pipeline from 10--20 minutes to less than 6 seconds. A head-to-head comparison on the ABO dataset shows that \sysname achieves this 62.9$\times$--287.2$\times$ speedup while not only reaching on-par (and sometimes slightly better) object-level physical property estimation accuracy(e.g. mass), but also demonstrating superior performance in material segmentation and voxel-level inference than two SOTA baselines. We further combine gaze-tracking with \sysname to localize the object of interest in cluttered, real-world environments, streamlining the physical property reasoning on smart glasses. The case study with Meta Aria Glasses conducted at an IKEA furniture store demonstrates that \sysname achives consistently high performance compared to controlled captures, providing robust property estimations even with fewer views in real-world scenarios.</li>
</ul>

<h3>Title: From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Najrin Sultana, Md Rafi Ur Rashid, Kang Gu, Shagufta Mehnaz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03128">https://arxiv.org/abs/2511.03128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03128">https://arxiv.org/pdf/2511.03128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03128]] From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation(https://arxiv.org/abs/2511.03128)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>LLMs can provide substantial zero-shot performance on diverse tasks using a simple task prompt, eliminating the need for training or fine-tuning. However, when applying these models to sensitive tasks, it is crucial to thoroughly assess their robustness against adversarial inputs. In this work, we introduce Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack frameworks designed to systematically generate dynamic and adaptive adversarial examples by leveraging the understanding of the LLMs. We produce subtle and natural-looking adversarial inputs that preserve semantic similarity to the original text while effectively deceiving the target LLM. By utilizing an automated, LLM-driven pipeline, we eliminate the dependence on external heuristics. Our attacks evolve with the advancements in LLMs and demonstrate strong transferability across models unknown to the attacker. Overall, this work provides a systematic approach for the self-assessment of an LLM's robustness. We release our code and data at this https URL.</li>
</ul>

<h3>Title: MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity</h3>
<ul>
<li><strong>Authors: </strong>Kaiyuan Zhang, Chenghao Yang, Zhoufutu Wen, Sihang Yuan, Qiuyue Wang, Chaoyi Huang, Guosheng Zhu, He Wang, Huawenyu Lu, Jianing Wen, Jianpeng Jiao, Lishu Luo, Longxiang Liu, Sijin Wu, Xiaolei Zhu, Xuanliang Zhang, Ge Zhang, Yi Lin, Guang Shi, Chaoyou Fu, Wenhao Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03146">https://arxiv.org/abs/2511.03146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03146">https://arxiv.org/pdf/2511.03146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03146]] MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity(https://arxiv.org/abs/2511.03146)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>As reasoning models scale rapidly, the essential role of multimodality in human cognition has come into sharp relief, driving a growing need to probe vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either overemphasize textual reasoning or fall short of systematically capturing vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs insufficiently assessed. To address this limitation, we introduce MME-CC (Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded benchmark that organizes 11 representative reasoning tasks into three fundamental categories of visual information: spatial, geometric, and knowledge-based reasoning, and provides fine-grained analyses of MLLMs' cognitive capacity across these dimensions. Based on MME-CC, we conduct extensive experiments over 16 representative MLLMs. Our study reveals that closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs. 30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak (less than or equal to 30%). We further identify common error patterns, including orientation mistakes, fragile cross-view identity persistence, and poor adherence to counterfactual instructions, and observe that Chain-of-Thought typically follows a three-stage process (extract -> reason -> verify) with heavy reliance on visual extraction. We hope this work catalyzes a shift toward treating the cognitive capacity of MLLMs as central to both evaluation and model design.</li>
</ul>

<h3>Title: Test Time Adaptation Using Adaptive Quantile Recalibration</h3>
<ul>
<li><strong>Authors: </strong>Paria Mehrbod, Pedro Vianna, Geraldin Nanfack, Guy Wolf, Eugene Belilovsky</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03148">https://arxiv.org/abs/2511.03148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03148">https://arxiv.org/pdf/2511.03148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03148]] Test Time Adaptation Using Adaptive Quantile Recalibration(https://arxiv.org/abs/2511.03148)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Domain adaptation is a key strategy for enhancing the generalizability of deep learning models in real-world scenarios, where test distributions often diverge significantly from the training domain. However, conventional approaches typically rely on prior knowledge of the target domain or require model retraining, limiting their practicality in dynamic or resource-constrained environments. Recent test-time adaptation methods based on batch normalization statistic updates allow for unsupervised adaptation, but they often fail to capture complex activation distributions and are constrained to specific normalization layers. We propose Adaptive Quantile Recalibration (AQR), a test-time adaptation technique that modifies pre-activation distributions by aligning quantiles on a channel-wise basis. AQR captures the full shape of activation distributions and generalizes across architectures employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of estimating distribution tails under varying batch sizes, AQR incorporates a robust tail calibration strategy that improves stability and precision. Our method leverages source-domain statistics computed at training time, enabling unsupervised adaptation without retraining models. Experiments on CIFAR-10-C, CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR achieves robust adaptation across diverse settings, outperforming existing test-time adaptation baselines. These results highlight AQR's potential for deployment in real-world scenarios with dynamic and unpredictable data distributions.</li>
</ul>

<h3>Title: Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction</h3>
<ul>
<li><strong>Authors: </strong>Atif Hassan, Tarun Kumar, Ashish Mishra, Sergey Serebryakov, Satish Kumar Mopur, Phanidhar Koganti, Murthy Chelankuri, Ramanagopal Vogety, Suparna Bhattacharya, Martin Foltin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03149">https://arxiv.org/abs/2511.03149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03149">https://arxiv.org/pdf/2511.03149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03149]] Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction(https://arxiv.org/abs/2511.03149)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Forecasting anomalies (anomaly prediction) in multivariate time series from different real-world, dynamic, and complex systems is vital for preempting critical failures, leading to a substantial minimization in operational costs and human labor. Yet, existing methods are limited to specific systems while failing to generalize to evolving anomaly patterns over time. In contrast, pretrained Time Series Foundation Models (TSFMs) have recently demonstrated strong generalization and zero-shot forecasting capabilities. However, their potential remains untapped for anomaly prediction, a task fundamentally different from forecasting normal behavior. Thus, we present Forecast2Anomaly (F2A), a novel framework that empowers TSFMs with anomaly prediction abilities through two key innovations. First, we propose a joint forecast-anomaly loss that fine-tunes TSFMs to accurately forecast future signals even at anomalous time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module that retrieves historically relevant horizons and conditions predictions on them. This component dynamically adapts to distributional shifts at inference time, enabling F2A to track evolving anomalies without requiring model updates. By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap between robust TSFM zero-shot forecasting and zero-shot anomaly prediction. Extensive experiments across 16 diverse datasets and multiple TSFM backbones show that F2A consistently outperforms state-of-the-art methods, offering a scalable, zero-shot anomaly prediction solution for real-world applications.</li>
</ul>

<h3>Title: Finetuning-Free Personalization of Text to Image Generation via Hypernetworks</h3>
<ul>
<li><strong>Authors: </strong>Sagar Shrestha, Gopal Sharma, Luowei Zhou, Suren Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03156">https://arxiv.org/abs/2511.03156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03156">https://arxiv.org/pdf/2511.03156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03156]] Finetuning-Free Personalization of Text to Image Generation via Hypernetworks(https://arxiv.org/abs/2511.03156)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Personalizing text-to-image diffusion models has traditionally relied on subject-specific fine-tuning approaches such as DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and slow at inference. Recent adapter- and encoder-based methods attempt to reduce this overhead but still depend on additional fine-tuning or large backbone models for satisfactory results. In this work, we revisit an orthogonal direction: fine-tuning-free personalization via Hypernetworks that predict LoRA-adapted weights directly from subject images. Prior hypernetwork-based approaches, however, suffer from costly data generation or unstable attempts to mimic base model optimization trajectories. We address these limitations with an end-to-end training objective, stabilized by a simple output regularization, yielding reliable and effective hypernetworks. Our method removes the need for per-subject optimization at test time while preserving both subject fidelity and prompt alignment. To further enhance compositional generalization at inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG), which combines the compositional strengths of the base diffusion model with the subject fidelity of personalized models during sampling. Extensive experiments on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves strong personalization performance and highlights the promise of hypernetworks as a scalable and effective direction for open-category personalization.</li>
</ul>

<h3>Title: Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yun-Chen Lin, Jiayuan Huang, Hanyuan Zhang, Sergi Kavtaradze, Matthew J. Clarkson, Mobarak I. Hoque</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03163">https://arxiv.org/abs/2511.03163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03163">https://arxiv.org/pdf/2511.03163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03163]] Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation(https://arxiv.org/abs/2511.03163)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate detection and delineation of anatomical structures in medical imaging are critical for computer-assisted interventions, particularly in laparoscopic liver surgery where 2D video streams limit depth perception and complicate landmark localization. While recent works have leveraged monocular depth cues for enhanced landmark detection, challenges remain in fusing RGB and depth features and in efficiently adapting large-scale vision models to surgical domains. We propose a depth-guided liver landmark segmentation framework integrating semantic and geometric cues via vision foundation encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB features and Depth Anything V2 (DA2) encoder to extract depth-aware features. To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient projection method that replaces the computationally expensive SVD with a Subsampled Randomized Fourier Transform (SRFT). This enables efficient fine-tuning of high-dimensional attention layers without sacrificing representational power. A cross-attention fusion module further integrates RGB and depth cues. To assess cross-dataset generalization, we also construct a new Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark. On the public L3D dataset, our method achieves a 4.85% improvement in Dice Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface Distance compared to the D2GPLand. To further assess generalization capability, we evaluate our model on LLSD dataset. Our model maintains competitive performance and significantly outperforms SAM-based baselines, demonstrating strong cross-dataset robustness and adaptability to unseen surgical environments. These results demonstrate that our SRFT-GaLore-enhanced dual-encoder framework enables scalable and precise segmentation under real-time, depth-constrained surgical settings.</li>
</ul>

<h3>Title: Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks</h3>
<ul>
<li><strong>Authors: </strong>Kevin Wang, Subre Abdoul Moktar, Jia Li, Kangshuo Li, Feng Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03166">https://arxiv.org/abs/2511.03166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03166">https://arxiv.org/pdf/2511.03166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03166]] Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks(https://arxiv.org/abs/2511.03166)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have become increasingly pervasive, finding applications across many industries and disciplines. Ensuring the trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE) plays a key role. In this work, a comprehensive empirical study is conducted to examine the robustness and effectiveness of diverse UE measures regarding aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE methods and four generation quality metrics including LLMScore from LLM criticizers to evaluate the uncertainty of LLM-generated answers in Question-Answering (QA) tasks on both in-distribution (ID) and out-of-distribution (OOD) datasets. Our analysis reveals that information-based methods, which leverage token and sequence probabilities, perform exceptionally well in ID settings due to their alignment with the model's understanding of the data. Conversely, density-based methods and the P(True) metric exhibit superior performance in OOD contexts, highlighting their effectiveness in capturing the model's epistemic uncertainty. Semantic consistency methods, which assess variability in generated answers, show reliable performance across different datasets and generation metrics. These methods generally perform well but may not be optimal for every situation.</li>
</ul>

<h3>Title: SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention</h3>
<ul>
<li><strong>Authors: </strong>Shreyas C. Dhake, Jiayuan Huang, Runlong He, Danyal Z. Khan, Evangelos B. Mazomenos, Sophia Bano, Hani J. Marcus, Danail Stoyanov, Matthew J. Clarkson, Mobarak I. Hoque</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03178">https://arxiv.org/abs/2511.03178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03178">https://arxiv.org/pdf/2511.03178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03178]] SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention(https://arxiv.org/abs/2511.03178)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Anticipating forthcoming surgical events is vital for real-time assistance in endonasal transsphenoidal pituitary surgery, where visibility is limited and workflow changes rapidly. Most visual question answering (VQA) systems reason on isolated frames with static vision language alignment, providing little support for forecasting next steps or instrument needs. Existing surgical VQA datasets likewise center on the current scene rather than the near future. We introduce PitVQA-Anticipation, the first VQA dataset designed for forward looking surgical reasoning. It comprises 33.5 hours of operative video and 734,769 question answer pairs built from temporally grouped clips and expert annotations across four tasks: predicting the future phase, next step, upcoming instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video language model that adapts a large language model using a GRU Gated Temporal Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics, while an adaptive gate injects visual context into the language stream at the token level. Parameter efficient fine tuning customizes the language backbone to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and EndoVis datasets, surpassing strong image and video based baselines. Ablations show that temporal recurrence and gated fusion drive most of the gains. A frame budget study indicates a trade-off: 8 frames maximize fluency, whereas 32 frames slightly reduce BLEU but improve numeric time estimation. By pairing a temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA advances surgical VQA from retrospective description to proactive anticipation. PitVQA-Anticipation offers a comprehensive benchmark for this setting and highlights the importance of targeted temporal modeling for reliable, future aware surgical assistance.</li>
</ul>

<h3>Title: BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture</h3>
<ul>
<li><strong>Authors: </strong>Shahriyar Zaman Ridoy, Azmine Toushik Wasi, Koushik Ahamed Tonmoy</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03180">https://arxiv.org/abs/2511.03180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03180">https://arxiv.org/pdf/2511.03180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03180]] BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture(https://arxiv.org/abs/2511.03180)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>As multilingual Large Language Models (LLMs) gain traction across South Asia, their alignment with local ethical norms, particularly for Bengali, which is spoken by over 285 million people and ranked 6th globally, remains underexplored. Existing ethics benchmarks are largely English-centric and shaped by Western frameworks, overlooking cultural nuances critical for real-world deployment. To address this, we introduce BengaliMoralBench, the first large-scale ethics benchmark for the Bengali language and socio-cultural contexts. It covers five moral domains, Daily Activities, Habits, Parenting, Family Relationships, and Religious Activities, subdivided into 50 culturally relevant subtopics. Each scenario is annotated via native-speaker consensus using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct systematic zero-shot evaluation of prominent multilingual LLMs, including Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and standard metrics. Performance varies widely (50-91% accuracy), with qualitative analysis revealing consistent weaknesses in cultural grounding, commonsense reasoning, and moral fairness. BengaliMoralBench provides a foundation for responsible localization, enabling culturally aligned evaluation and supporting the deployment of ethically robust AI in diverse, low-resource multilingual settings such as Bangladesh.</li>
</ul>

<h3>Title: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies</h3>
<ul>
<li><strong>Authors: </strong>Hassan Wasswa, Hussein Abbass, Timothy Lynar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03201">https://arxiv.org/abs/2511.03201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03201">https://arxiv.org/pdf/2511.03201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03201]] A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies(https://arxiv.org/abs/2511.03201)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In an effort to counter the increasing IoT botnet-based attacks, state-of-the-art deep learning methods have been proposed and have achieved impressive detection accuracy. However, their computational intensity restricts deployment on resource-constrained IoT devices, creating a critical need for lightweight detection models. A common solution to this challenge is model compression via quantization. This study proposes a VAE-MLP model framework where an MLP-based classifier is trained on 8-dimensional latent vectors derived from the high-dimensional train data using the encoder component of a pretrained variational autoencoder (VAE). Two widely used quantization strategies--Quantization-Aware Training (QAT) and Post-Training Quantization (PTQ)--are then systematically evaluated in terms of their impact on detection performance, storage efficiency, and inference latency using two benchmark IoT botnet datasets--N-BaIoT and CICIoT2022. The results revealed that, with respect to detection accuracy, the QAT strategy experienced a more noticeable decline,whereas PTQ incurred only a marginal reduction compared to the original unquantized model. Furthermore, PTQ yielded a 6x speedup and 21x reduction in size, while QAT achieved a 3x speedup and 24x compression, demonstrating the practicality of quantization for device-level IoT botnet detection.</li>
</ul>

<h3>Title: QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Kuei-Chun Kao, Hsu Tzu-Yin, Yunqi Hong, Ruochen Wang, Cho-Jui Hsieh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03206">https://arxiv.org/abs/2511.03206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03206">https://arxiv.org/pdf/2511.03206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03206]] QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models(https://arxiv.org/abs/2511.03206)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recently, Multimodal Large Language Models (MLLMs) encounter two key issues in multi-image contexts: (1) a lack of fine-grained perception across disparate images, and (2) a diminished capability to effectively reason over and synthesize information from multiple visual inputs. However, while various prompting methods aim to describe visual content, many existing studies focus primarily on single-image settings or specific, constrained scenarios. This leaves a critical gap in understanding and addressing how MLLMs tackle more general and complex multi-image reasoning tasks. Thus, we first extensively investigate how current prompting methods perceive fine-grained visual details and process visual information when dealing with multiple images. Our findings reveal that existing prompting methods fall short in attending to needed clues and seamlessly integrating perception and reasoning. Inspired by the findings, we propose a new zero-shot prompting method, Question-Guided Chain-of-Captions (QG-CoC), a generalized prompting approach that effectively handles problems with an arbitrary number of images. We evaluate our method on various open-source and closed-source MLLMs for multi-image and single-image benchmarks. Experimental results indicate that QG-CoC demonstrates competitive performance across tasks and exhibits robust improvements in the challenging scenarios where existing prompting methods fail.</li>
</ul>

<h3>Title: MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ruting Cheng, Boyuan Feng, Yijiang Zheng, Chuhui Qiu, Aizierjiang Aiersilan, Joaquin A. Calderon, Wentao Zhao, Qing Pan, James K. Hahn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03212">https://arxiv.org/abs/2511.03212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03212">https://arxiv.org/pdf/2511.03212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03212]] MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction(https://arxiv.org/abs/2511.03212)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurately assessing the risk of cesarean section (CS) delivery is critical, especially in settings with limited medical resources, where access to healthcare is often restricted. Early and reliable risk prediction allows better-informed prenatal care decisions and can improve maternal and neonatal outcomes. However, most existing predictive models are tailored for in-hospital use during labor and rely on parameters that are often unavailable in resource-limited or home-based settings. In this study, we conduct a pilot investigation to examine the feasibility of using 3D body shape for CS risk assessment for future applications with more affordable general devices. We propose a novel multi-view-based Transformer network, MvBody, which predicts CS risk using only self-reported medical data and 3D optical body scans obtained between the 31st and 38th weeks of gestation. To enhance training efficiency and model generalizability in data-scarce environments, we incorporate a metric learning loss into the network. Compared to widely used machine learning models and the latest advanced 3D analysis methods, our method demonstrates superior performance, achieving an accuracy of 84.62% and an Area Under the Receiver Operating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set. To improve transparency and trust in the model's predictions, we apply the Integrated Gradients algorithm to provide theoretically grounded explanations of the model's decision-making process. Our results indicate that pre-pregnancy weight, maternal age, obstetric history, previous CS history, and body shape, particularly around the head and shoulders, are key contributors to CS risk prediction.</li>
</ul>

<h3>Title: Bayesian Advantage of Re-Identification Attack in the Shuffle Model</h3>
<ul>
<li><strong>Authors: </strong>Pengcheng Su, Haibo Cheng, Ping Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03213">https://arxiv.org/abs/2511.03213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03213">https://arxiv.org/pdf/2511.03213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03213]] Bayesian Advantage of Re-Identification Attack in the Shuffle Model(https://arxiv.org/abs/2511.03213)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>The shuffle model, which anonymizes data by randomly permuting user messages, has been widely adopted in both cryptography and differential privacy. In this work, we present the first systematic study of the Bayesian advantage in re-identifying a user's message under the shuffle model. We begin with a basic setting: one sample is drawn from a distribution $P$, and $n - 1$ samples are drawn from a distribution $Q$, after which all $n$ samples are randomly shuffled. We define $\beta_n(P, Q)$ as the success probability of a Bayes-optimal adversary in identifying the sample from $P$, and define the additive and multiplicative Bayesian advantages as $\mathsf{Adv}_n^{+}(P, Q) = \beta_n(P,Q) - \frac{1}{n}$ and $\mathsf{Adv}_n^{\times}(P, Q) = n \cdot \beta_n(P,Q)$, respectively. We derive exact analytical expressions and asymptotic characterizations of $\beta_n(P, Q)$, along with evaluations in several representative scenarios. Furthermore, we establish (nearly) tight mutual bounds between the additive Bayesian advantage and the total variation distance. Finally, we extend our analysis beyond the basic setting and present, for the first time, an upper bound on the success probability of Bayesian attacks in shuffle differential privacy. Specifically, when the outputs of $n$ users--each processed through an $\varepsilon$-differentially private local randomizer--are shuffled, the probability that an attacker successfully re-identifies any target user's message is at most $e^{\varepsilon}/n$.</li>
</ul>

<h3>Title: LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Wenchang Lei, Ping Zou, Yue Wang, Feng Sun, Lei Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03214">https://arxiv.org/abs/2511.03214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03214">https://arxiv.org/pdf/2511.03214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03214]] LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval(https://arxiv.org/abs/2511.03214)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit strong semantic understanding, yet struggle when user instructions involve ambiguous or conceptually misaligned terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity by extracting meta-relations-inheritance, alias, and composition-from natural language. The model further employs a reflection mechanism to validate these meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these relations and related descriptions are dynamically supplied to the LLM, improving its ability to interpret concepts and generate accurate responses. Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely on extended context windows, our method enables large language models to process texts of any length without the need for truncation. Experiments on standard benchmarks demonstrate that the LGM consistently outperforms existing RAG baselines.</li>
</ul>

<h3>Title: Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification</h3>
<ul>
<li><strong>Authors: </strong>Shaghayegh Kolli, Richard Rosenbaum, Timo Cavelius, Lasse Strothe, Andrii Lata, Jana Diesner</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03217">https://arxiv.org/abs/2511.03217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03217">https://arxiv.org/pdf/2511.03217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03217]] Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification(https://arxiv.org/abs/2511.03217)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel in generating fluent utterances but can lack reliable grounding in verified information. At the same time, knowledge-graph-based fact-checkers deliver precise and interpretable evidence, yet suffer from limited coverage or latency. By integrating LLMs with knowledge graphs and real-time search agents, we introduce a hybrid fact-checking approach that leverages the individual strengths of each component. Our system comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid one - hop lookups in DBpedia, 2) an LM-based classification guided by a task-specific labeling prompt, producing outputs with internal rule-based logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient. Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the Supported/Refuted split without task- specific fine - tuning. To address Not enough information cases, we conduct a targeted reannotation study showing that our approach frequently uncovers valid evidence for claims originally labeled as Not Enough Information (NEI), as confirmed by both expert annotators and LLM reviewers. With this paper, we present a modular, opensource fact-checking pipeline with fallback strategies and generalization across datasets.</li>
</ul>

<h3>Title: Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Jie, Wanquan Liu, Rui He, Yihui Wen, Deyu Meng, Chenqiang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03219">https://arxiv.org/abs/2511.03219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03219">https://arxiv.org/pdf/2511.03219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03219]] Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation(https://arxiv.org/abs/2511.03219)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Augmentation for dense prediction typically relies on either sample mixing or generative synthesis. Mixing improves robustness but misaligned masks yield soft label ambiguity. Diffusion synthesis increases apparent diversity but, when trained as common samples, overlooks the structural benefit of mask conditioning and introduces synthetic-real domain shift. We propose a paired, diffusion-guided paradigm that fuses the strengths of both. For each real image, a synthetic counterpart is generated under the same mask and the pair is used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which mixes only image appearance while supervision always uses the original hard mask. This produces a continuous family of intermediate samples that smoothly bridges synthetic and real appearances under shared geometry, enlarging diversity without compromising pixel-level semantics. To keep learning aligned with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the mixing strength and the loss weight of mixed samples over training, gradually re-anchoring optimization to real data and mitigating distributional bias. Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC 2017, the approach achieves state-of-the-art segmentation performance and consistent gains over baselines. The results show that combining label-preserving mixing with diffusion-driven diversity, together with adaptive re-anchoring, yields robust and generalizable endoscopic segmentation.</li>
</ul>

<h3>Title: Smartphone User Fingerprinting on Wireless Traffic</h3>
<ul>
<li><strong>Authors: </strong>Yong Huang, Zhibo Dong, Xiaoguang Yang, Dalong Zhang, Qingxian Wang, Zhihua Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03229">https://arxiv.org/abs/2511.03229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03229">https://arxiv.org/pdf/2511.03229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03229]] Smartphone User Fingerprinting on Wireless Traffic(https://arxiv.org/abs/2511.03229)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>Due to the openness of the wireless medium, smartphone users are susceptible to user privacy attacks, where user privacy information is inferred from encrypted Wi-Fi wireless traffic. Existing attacks are limited to recognizing mobile apps and their actions and cannot infer the smartphone user identity, a fundamental part of user privacy. To overcome this limitation, we propose U-Print, a novel attack system that can passively recognize smartphone apps, actions, and users from over-the-air MAC-layer frames. We observe that smartphone users usually prefer different add-on apps and in-app actions, yielding different changing patterns in Wi-Fi traffic. U-Print first extracts multi-level traffic features and exploits customized temporal convolutional networks to recognize smartphone apps and actions, thus producing users' behavior sequences. Then, it leverages the silhouette coefficient method to determine the number of users and applies the k-means clustering to profile and identify smartphone users. We implement U-Print using a laptop with a Kali dual-band wireless network card and evaluate it in three real-world environments. U-Print achieves an overall accuracy of 98.4% and an F1 score of 0.983 for user inference. Moreover, it can correctly recognize up to 96% of apps and actions in the closed world and more than 86% in the open world.</li>
</ul>

<h3>Title: Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Sichen Guo, Wenjie Li, Yuanyang Liu, Guangwei Gao, Jian Yang, Chia-Wen Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03232">https://arxiv.org/abs/2511.03232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03232">https://arxiv.org/pdf/2511.03232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03232]] Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution(https://arxiv.org/abs/2511.03232)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently, Mamba-based super-resolution (SR) methods have demonstrated the ability to capture global receptive fields with linear complexity, addressing the quadratic computational cost of Transformer-based SR approaches. However, existing Mamba-based methods lack fine-grained transitions across different modeling scales, which limits the efficiency of feature representation. In this paper, we propose T-PMambaSR, a lightweight SR framework that integrates window-based self-attention with Progressive Mamba. By enabling interactions among receptive fields of different scales, our method establishes a fine-grained modeling paradigm that progressively enhances feature representation with linear complexity. Furthermore, we introduce an Adaptive High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost during Transformer and Mamba processing. Extensive experiments demonstrate that T-PMambaSR progressively enhances the model's receptive field and expressiveness, yielding better performance than recent Transformer- or Mamba-based methods while incurring lower computational cost. Our codes will be released after acceptance.</li>
</ul>

<h3>Title: IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs</h3>
<ul>
<li><strong>Authors: </strong>Souvik Rana, Arul Menezes, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03237">https://arxiv.org/abs/2511.03237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03237">https://arxiv.org/pdf/2511.03237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03237]] IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs(https://arxiv.org/abs/2511.03237)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Tokenizers play a crucial role in determining the performance, training efficiency, and the inference cost of Large Language Models (LLMs). Designing effective tokenizers for multilingual LLMs is particularly challenging due to diverse scripts and rich morphological variation. While subword methods such as Byte Pair Encoding (BPE) are widely adopted, their effectiveness in multilingual settings remains underexplored. We present IndicSuperTokenizer, a tokenizer for Indic multilingual LLMs, that combines both subword and multi-word tokenization, along with language-specific pre-tokenization, leading to more linguistically aligned tokens and achieving a new state-of-the-art in fertility score. Evaluated across English, 22 Indian languages and code data, our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by 18% over Sutra (the current best). This translates to 44% improvement in inference throughput over LLaMA4 while maintaining comparable performance on English and Indic benchmarks. We also present detailed ablations across tokenizer training data size, vocabulary size, merging techniques, and pre-tokenization strategies, demonstrating the robustness of our design choices.</li>
</ul>

<h3>Title: A unified physics-informed generative operator framework for general inverse problems</h3>
<ul>
<li><strong>Authors: </strong>Gang Bao, Yaohua Zang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03241">https://arxiv.org/abs/2511.03241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03241">https://arxiv.org/pdf/2511.03241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03241]] A unified physics-informed generative operator framework for general inverse problems(https://arxiv.org/abs/2511.03241)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Solving inverse problems governed by partial differential equations (PDEs) is central to science and engineering, yet remains challenging when measurements are sparse, noisy, or when the underlying coefficients are high-dimensional or discontinuous. Existing deep learning approaches either require extensive labeled datasets or are limited to specific measurement types, often leading to failure in such regimes and restricting their practical applicability. Here, a novel generative neural operator framework, IGNO, is introduced to overcome these limitations. IGNO unifies the solution of inverse problems from both point measurements and operator-valued data without labeled training pairs. This framework encodes high-dimensional, potentially discontinuous coefficient fields into a low-dimensional latent space, which drives neural operator decoders to reconstruct both coefficients and PDE solutions. Training relies purely on physics constraints through PDE residuals, while inversion proceeds via efficient gradient-based optimization in latent space, accelerated by an a priori normalizing flow model. Across a diverse set of challenging inverse problems, including recovery of discontinuous coefficients from solution-based measurements and the EIT problem with operator-based measurements, IGNO consistently achieves accurate, stable, and scalable inversion even under severe noise. It consistently outperforms the state-of-the-art method under varying noise levels and demonstrates strong generalization to out-of-distribution targets. These results establish IGNO as a unified and powerful framework for tackling challenging inverse problems across computational science domains.</li>
</ul>

<h3>Title: Death by a Thousand Prompts: Open Model Vulnerability Analysis</h3>
<ul>
<li><strong>Authors: </strong>Amy Chang, Nicholas Conley, Harish Santhanalakshmi Ganesan, Adam Swanda</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03247">https://arxiv.org/abs/2511.03247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03247">https://arxiv.org/pdf/2511.03247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03247]] Death by a Thousand Prompts: Open Model Vulnerability Analysis(https://arxiv.org/abs/2511.03247)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>Open-weight models provide researchers and developers with accessible foundations for diverse downstream applications. We tested the safety and security postures of eight open-weight large language models (LLMs) to identify vulnerabilities that may impact subsequent fine-tuning and deployment. Using automated adversarial testing, we measured each model's resilience against single-turn and multi-turn prompt injection and jailbreak attacks. Our findings reveal pervasive vulnerabilities across all tested models, with multi-turn attacks achieving success rates between 25.86\% and 92.78\% -- representing a $2\times$ to $10\times$ increase over single-turn baselines. These results underscore a systemic inability of current open-weight models to maintain safety guardrails across extended interactions. We assess that alignment strategies and lab priorities significantly influence resilience: capability-focused models such as Llama 3.3 and Qwen 3 demonstrate higher multi-turn susceptibility, whereas safety-oriented designs such as Google Gemma 3 exhibit more balanced performance. The analysis concludes that open-weight models, while crucial for innovation, pose tangible operational and ethical risks when deployed without layered security controls. These findings are intended to inform practitioners and developers of the potential risks and the value of professional AI security solutions to mitigate exposure. Addressing multi-turn vulnerabilities is essential to ensure the safe, reliable, and responsible deployment of open-weight LLMs in enterprise and public domains. We recommend adopting a security-first design philosophy and layered protections to ensure resilient deployments of open-weight models.</li>
</ul>

<h3>Title: Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation Framework</h3>
<ul>
<li><strong>Authors: </strong>Junhao Li, Jiahao Chen, Zhou Feng, Chunyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03248">https://arxiv.org/abs/2511.03248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03248">https://arxiv.org/pdf/2511.03248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03248]] Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation Framework(https://arxiv.org/abs/2511.03248)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in multi-modal Large Language Models (M-LLMs) have demonstrated a powerful ability to synthesize implicit information from disparate sources, including images and text. These resourceful data from social media also introduce a significant and underexplored privacy risk: the inference of sensitive personal attributes from seemingly daily media content. However, the lack of benchmarks and comprehensive evaluations of state-of-the-art M-LLM capabilities hinders the research of private attribute profiling on social media. Accordingly, we propose (1) PRISM, the first multi-modal, multi-dimensional and fine-grained synthesized dataset incorporating a comprehensive privacy landscape and dynamic user history; (2) an Efficient evaluation framework that measures the cross-modal privacy inference capabilities of advanced M-LLM. Specifically, PRISM is a large-scale synthetic benchmark designed to evaluate cross-modal privacy risks. Its key feature is 12 sensitive attribute labels across a diverse set of multi-modal profiles, which enables targeted privacy analysis. These profiles are generated via a sophisticated LLM agentic workflow, governed by a prior distribution to ensure they realistically mimic social media users. Additionally, we propose a Multi-Agent Inference Framework that leverages a pipeline of specialized LLMs to enhance evaluation capabilities. We evaluate the inference capabilities of six leading M-LLMs (Qwen, Gemini, GPT-4o, GLM, Doubao, and Grok) on PRISM. The comparison with human performance reveals that these MLLMs significantly outperform in accuracy and efficiency, highlighting the threat of potential privacy risks and the urgent need for robust defenses.</li>
</ul>

<h3>Title: Generative deep learning for foundational video translation in ultrasound</h3>
<ul>
<li><strong>Authors: </strong>Nikolina Tomic Roshni Bhatnagar, Sarthak Jain, Connor Lau, Tien-Yu Liu, Laura Gambini, Rima Arnaout</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03255">https://arxiv.org/abs/2511.03255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03255">https://arxiv.org/pdf/2511.03255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03255]] Generative deep learning for foundational video translation in ultrasound(https://arxiv.org/abs/2511.03255)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning (DL) has the potential to revolutionize image acquisition and interpretation across medicine, however, attention to data imbalance and missingness is required. Ultrasound data presents a particular challenge because in addition to different views and structures, it includes several sub-modalities-such as greyscale and color flow doppler (CFD)-that are often imbalanced in clinical studies. Image translation can help balance datasets but is challenging for ultrasound sub-modalities to date. Here, we present a generative method for ultrasound CFD-greyscale video translation, trained on 54,975 videos and tested on 8,368. The method developed leveraged pixel-wise, adversarial, and perceptual loses and utilized two networks: one for reconstructing anatomic structures and one for denoising to achieve realistic ultrasound imaging. Average pairwise SSIM between synthetic videos and ground truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real ones in DL classification and segmentation tasks and when evaluated by blinded clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice score between real and synthetic segmentation was 0.97. Overall clinician accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%), indicating realistic synthetic videos. Although trained only on heart videos, the model worked well on ultrasound spanning several clinical domains (average SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data expand the utility of retrospectively collected imaging and augment the dataset design toolbox for medical imaging.</li>
</ul>

<h3>Title: Enhancing Medical Image Segmentation via Heat Conduction Equation</h3>
<ul>
<li><strong>Authors: </strong>Rong Wu, Yim-Sang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03260">https://arxiv.org/abs/2511.03260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03260">https://arxiv.org/pdf/2511.03260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03260]] Enhancing Medical Image Segmentation via Heat Conduction Equation(https://arxiv.org/abs/2511.03260)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation has been significantly advanced by deep learning architectures, notably U-Net variants. However, existing models struggle to achieve efficient global context modeling and long-range dependency reasoning under practical computational budgets simultaneously. In this work, we propose a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation. Our model combines Mamba-based state-space modules for efficient long-range reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers, simulating frequency-domain thermal diffusion for enhanced semantic abstraction. Experimental results on multimodal abdominal CT and MRI datasets demonstrate that the proposed model consistently outperforms strong baselines, validating its effectiveness and generalizability. It suggest that blending state-space dynamics with heat-based global diffusion offers a scalable and interpretable solution for medical segmentation tasks.</li>
</ul>

<h3>Title: Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature</h3>
<ul>
<li><strong>Authors: </strong>Ranul Dayarathne, Uvini Ranaweera, Upeksha Ganegoda</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03261">https://arxiv.org/abs/2511.03261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03261">https://arxiv.org/pdf/2511.03261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03261]] Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature(https://arxiv.org/abs/2511.03261)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) is emerging as a powerful technique to enhance the capabilities of Generative AI models by reducing hallucination. Thus, the increasing prominence of RAG alongside Large Language Models (LLMs) has sparked interest in comparing the performance of different LLMs in question-answering (QA) in diverse domains. This study compares the performance of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA tasks within the computer science literature leveraging RAG support. Evaluation metrics employed in the study include accuracy and precision for binary questions and ranking by a human expert, ranking by Google's AI model Gemini, alongside cosine similarity for long-answer questions. GPT-3.5, when paired with RAG, effectively answers binary and long-answer questions, reaffirming its status as an advanced LLM. Regarding open-source LLMs, Mistral AI's Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b reports the shortest average latency in generating responses, whereas LLaMa2-7b-chat by Meta reports the highest average latency. This research underscores the fact that open-source LLMs, too, can go hand in hand with proprietary models like GPT-3.5 with better infrastructure.</li>
</ul>

<h3>Title: IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Bingyang Guo, Hongjie Li, Ruiyun Yu, Hanzhe Liang, Jinbao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03267">https://arxiv.org/abs/2511.03267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03267">https://arxiv.org/pdf/2511.03267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03267]] IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection(https://arxiv.org/abs/2511.03267)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>3D anomaly detection (3D-AD) plays a critical role in industrial manufacturing, particularly in ensuring the reliability and safety of core equipment components. Although existing 3D datasets like Real3D-AD and MVTec 3D-AD offer broad application support, they fall short in capturing the complexities and subtle defects found in real industrial environments. This limitation hampers precise anomaly detection research, especially for industrial equipment components (IEC) such as bearings, rings, and bolts. To address this challenge, we have developed a point cloud anomaly detection dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is directly collected from actual production lines, ensuring high fidelity and relevance. Compared to existing datasets, IEC3D-AD features significantly improved point cloud resolution and defect annotation granularity, facilitating more demanding anomaly detection tasks. Furthermore, inspired by generative 2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This paradigm generates synthetic point cloud samples based on geometric morphological analysis, then reduces the margin and increases the overlap between normal and abnormal point-level features through spatial discrepancy optimization. Extensive experiments demonstrate the effectiveness of our method on both IEC3D-AD and other datasets.</li>
</ul>

<h3>Title: SCALE: Upscaled Continual Learning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jin-woo Lee, Junhwa Choi, Bongkyu Hwang, Jinho Choo, Bogun Kim, JeongSeon Yi, Joonseok Lee, DongYoung Jung, Jaeseon Park, Kyoungwon Park, Suk-hoon Jung</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03270">https://arxiv.org/abs/2511.03270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03270">https://arxiv.org/pdf/2511.03270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03270]] SCALE: Upscaled Continual Learning of Large Language Models(https://arxiv.org/abs/2511.03270)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We revisit continual pre-training for large language models and argue that progress now depends more on scaling the right structure than on scaling parameters alone. We introduce SCALE, a width upscaling architecture that inserts lightweight expansion into linear modules while freezing all pre-trained parameters. This preserves the residual and attention topologies and increases capacity without perturbing the base model's original functionality. SCALE is guided by two principles: Persistent Preservation, which maintains the base model's behavior via preservation-oriented initialization and freezing of the pre-trained weights, and Collaborative Adaptation, which selectively trains a subset of expansion components to acquire new knowledge with minimal interference. We instantiate these ideas as SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and SCALE-Route, an optional routing extension that performs token-level routing between preservation and adaptation heads. On a controlled synthetic biography benchmark, SCALE mitigates the severe forgetting observed with depth expansion while still acquiring new knowledge. In continual pre-training on a Korean corpus, SCALE variants achieve less forgetting on English evaluations and competitive gains on Korean benchmarks, with these variants offering the best overall stability-plasticity trade-off. Accompanying analysis clarifies when preservation provably holds and why the interplay between preservation and adaptation stabilizes optimization compared to standard continual learning setups.</li>
</ul>

<h3>Title: Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yize Liu, Yunyun Hou, Aina Sui</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03271">https://arxiv.org/abs/2511.03271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03271">https://arxiv.org/pdf/2511.03271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03271]] Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs(https://arxiv.org/abs/2511.03271)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been widely deployed across various applications, yet their potential security and ethical risks have raised increasing concerns. Existing research employs red teaming evaluations, utilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs. However, these approaches often lack exploration of successful dialogue trajectories within the attack space, and they tend to overlook the considerable overhead associated with the attack process. To address these limitations, this paper first introduces a theoretical model based on dynamically weighted graph topology, abstracting the multi-turn attack process as a path planning problem. Based on this framework, we propose ABC, an enhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a collaborative search mechanism with employed, onlooker, and scout bees. This algorithm significantly improves the efficiency of optimal attack path search while substantially reducing the average number of queries required. Empirical evaluations on three open-source and two proprietary language models demonstrate the effectiveness of our approach, achieving attack success rates above 90\% across the board, with a peak of 98\% on GPT-3.5-Turbo, and outperforming existing baselines. Furthermore, it achieves comparable success with only 26 queries on average, significantly reducing red teaming overhead and highlighting its superior efficiency.</li>
</ul>

<h3>Title: Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising</h3>
<ul>
<li><strong>Authors: </strong>Shuangquan Lyu, Steven Mao, Yue Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03272">https://arxiv.org/abs/2511.03272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03272">https://arxiv.org/pdf/2511.03272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03272]] Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising(https://arxiv.org/abs/2511.03272)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating long videos remains a fundamental challenge, and achieving high controllability in video inpainting and outpainting is particularly demanding. To address both of these challenges simultaneously and achieve controllable video inpainting and outpainting for long video clips, we introduce a novel and unified approach for long video inpainting and outpainting that extends text-to-video diffusion models to generate arbitrarily long, spatially edited videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked region video synthesis, and employs an overlap-and-blend temporal co-denoising strategy with high-order solvers to maintain consistency across long sequences. In contrast to prior work that struggles with fixed-length clips or exhibits stitching artifacts, our system enables arbitrarily long video generation and editing without noticeable seams or drift. We validate our approach on challenging inpainting/outpainting tasks including editing or adding objects over hundreds of frames and demonstrate superior performance to baseline methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and perceptual realism (LPIPS). Our method enables practical long-range video editing with minimal overhead, achieved a balance between parameter efficient and superior performance.</li>
</ul>

<h3>Title: Diffusion Language Models are Super Data Learners</h3>
<ul>
<li><strong>Authors: </strong>Jinjie Ni, Qian Liu, Longxu Dou, Chao Du, Zili Wang, Hang Yan, Tianyu Pang, Michael Qizhe Shieh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03276">https://arxiv.org/abs/2511.03276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03276">https://arxiv.org/pdf/2511.03276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03276]] Diffusion Language Models are Super Data Learners(https://arxiv.org/abs/2511.03276)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Under strictly controlled pre-training settings, we observe a Crossover: when unique data is limited, diffusion language models (DLMs) consistently surpass autoregressive (AR) models by training for more epochs. The crossover shifts later with more or higher-quality data, earlier with larger models, and persists across dense and sparse architectures. We attribute the gains to three compounding factors: (1) any-order modeling, (2) super-dense compute from iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation; input or parameter noise improves AR under data constraint but cannot close the gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B unique Python tokens overtakes an AR coder trained with strictly matched settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag and > 33% on MMLU using only 1B tokens, without any special tricks, just by repeating standard pre-training data. We also show that rising validation cross-entropy does not imply degraded downstream performance in this regime.</li>
</ul>

<h3>Title: How to Evaluate Speech Translation with Source-Aware Neural MT Metrics</h3>
<ul>
<li><strong>Authors: </strong>Mauro Cettolo, Marco Gaido, Matteo Negri, Sara Papi, Luisa Bentivogli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03295">https://arxiv.org/abs/2511.03295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03295">https://arxiv.org/pdf/2511.03295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03295]] How to Evaluate Speech Translation with Source-Aware Neural MT Metrics(https://arxiv.org/abs/2511.03295)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Automatic evaluation of speech-to-text translation (ST) systems is typically performed by comparing translation hypotheses with one or more reference translations. While effective to some extent, this approach inherits the limitation of reference-based evaluation that ignores valuable information from the source input. In machine translation (MT), recent progress has shown that neural metrics incorporating the source text achieve stronger correlation with human judgments. Extending this idea to ST, however, is not trivial because the source is audio rather than text, and reliable transcripts or alignments between source and references are often unavailable. In this work, we conduct the first systematic study of source-aware metrics for ST, with a particular focus on real-world operating conditions where source transcripts are not available. We explore two complementary strategies for generating textual proxies of the input audio, automatic speech recognition (ASR) transcripts, and back-translations of the reference translation, and introduce a novel two-step cross-lingual re-segmentation algorithm to address the alignment mismatch between synthetic sources and reference translations. Our experiments, carried out on two ST benchmarks covering 79 language pairs and six ST systems with diverse architectures and performance levels, show that ASR transcripts constitute a more reliable synthetic source than back-translations when word error rate is below 20%, while back-translations always represent a computationally cheaper but still effective alternative. Furthermore, our cross-lingual re-segmentation algorithm enables robust use of source-aware MT metrics in ST evaluation, paving the way toward more accurate and principled evaluation methodologies for speech translation.</li>
</ul>

<h3>Title: Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods</h3>
<ul>
<li><strong>Authors: </strong>Felix Störck, Fabian Hinder, Barbara Hammer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03304">https://arxiv.org/abs/2511.03304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03304">https://arxiv.org/pdf/2511.03304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03304]] Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods(https://arxiv.org/abs/2511.03304)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>With the on-going integration of machine learning systems into the everyday social life of millions the notion of fairness becomes an ever increasing priority in their development. Fairness notions commonly rely on protected attributes to assess potential biases. Here, the majority of literature focuses on discrete setups regarding both target and protected attributes. The literature on continuous attributes especially in conjunction with regression -- we refer to this as \emph{continuous fairness} -- is scarce. A common strategy is iterative null-space projection which as of now has only been explored for linear models or embeddings such as obtained by a non-linear encoder. We improve on this by generalizing to kernel methods, significantly extending the scope. This yields a model and fairness-score agnostic method for kernel embeddings applicable to continuous protected attributes. We demonstrate that our novel approach in conjunction with Support Vector Regression (SVR) provides competitive or improved performance across multiple datasets in comparisons to other contemporary methods.</li>
</ul>

<h3>Title: Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Minghao Fu, Guo-Hua Wang, Tianyu Cui, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03317">https://arxiv.org/abs/2511.03317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03317">https://arxiv.org/pdf/2511.03317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03317]] Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models(https://arxiv.org/abs/2511.03317)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models deliver high-quality images, yet aligning them with human preferences remains challenging. We revisit diffusion-based Direct Preference Optimization (DPO) for these models and identify a critical pathology: enlarging the preference margin does not necessarily improve generation quality. In particular, the standard Diffusion-DPO objective can increase the reconstruction error of both winner and loser branches. Consequently, degradation of the less-preferred outputs can become sufficiently severe that the preferred branch is also adversely affected even as the margin grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule that preserves the winner by adaptively scaling the loser gradient according to its alignment with the winner gradient. A first-order analysis yields a closed-form scaling coefficient that guarantees the error of the preferred output is non-increasing at each optimization step. Our method is simple, model-agnostic, broadly compatible with existing DPO-style alignment frameworks and adds only marginal computational overhead. Across standard text-to-image benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning baselines on automated preference, aesthetic, and prompt alignment metrics. Code is publicly available at this https URL.</li>
</ul>

<h3>Title: Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles</h3>
<ul>
<li><strong>Authors: </strong>Giulio Caldarelli, Massimiliano Ornaghi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.IR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03319">https://arxiv.org/abs/2511.03319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03319">https://arxiv.org/pdf/2511.03319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03319]] Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles(https://arxiv.org/abs/2511.03319)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>The oracle problem refers to the inability of an agent to know if the information coming from an oracle is authentic and unbiased. In ancient times, philosophers and historians debated on how to evaluate, increase, and secure the reliability of oracle predictions, particularly those from Delphi, which pertained to matters of state. Today, we refer to data carriers for automatic machines as oracles, but establishing a secure channel between these oracles and the real world still represents a challenge. Despite numerous efforts, this problem remains mostly unsolved, and the recent advent of blockchain oracles has added a layer of complexity because of the decentralization of blockchains. This paper conceptually connects Delphic and modern blockchain oracles, developing a comparative framework. Leveraging blockchain oracle taxonomy, lexical analysis is also performed on 167 Delphic queries to shed light on the relationship between oracle answer quality and question type. The presented framework aims first at revealing commonalities between classical and computational oracles and then at enriching the oracle analysis within each field. This study contributes to the computer science literature by proposing strategies to improve the reliability of blockchain oracles based on insights from Delphi and to classical literature by introducing a framework that can also be applied to interpret and classify other ancient oracular mechanisms.</li>
</ul>

<h3>Title: SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Mauro Orazio Drago, Luca Carlini, Pelinsu Celebi Balyemez, Dennis Pierantozzi, Chiara Lena, Cesare Hassan, Danail Stoyanov, Elena De Momi, Sophia Bano, Mobarak I. Hoque</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03325">https://arxiv.org/abs/2511.03325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03325">https://arxiv.org/pdf/2511.03325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03325]] SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding(https://arxiv.org/abs/2511.03325)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Video Question Answering (VideoQA) in the surgical domain aims to enhance intraoperative understanding by enabling AI models to reason over temporally coherent events rather than isolated frames. Current approaches are limited to static image features, and available datasets often lack temporal annotations, ignoring the dynamics critical for accurate procedural interpretation. We propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder to fuse video and question features, capturing temporal cues such as motion and tool--tissue interactions, which a fine-tuned large language model (LLM) then decodes into coherent answers. To evaluate its performance, we curated REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related questions and diagnostic attributes, as well as out-of-template questions with rephrased or semantically altered formulations to assess model robustness. Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset shows that SurgViVQA outperforms existing image-based VQA benchmark models, particularly in keyword accuracy, improving over PitVQA by +11\% on REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions further confirms improved generalizability and robustness to variations in question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework for temporally-aware understanding in surgical VideoQA, enabling AI models to interpret dynamic procedural contexts more effectively. Code and dataset available at this https URL.</li>
</ul>

<h3>Title: Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jindong Hong, Tianjie Chen, Lingjie Luo, Chuanyang Zheng, Ting Xu, Haibao Yu, Jianing Qiu, Qianzhong Chen, Suning Huang, Yan Xu, Yong Gui, Yijun He, Jiankai Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03328">https://arxiv.org/abs/2511.03328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03328">https://arxiv.org/pdf/2511.03328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03328]] Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks(https://arxiv.org/abs/2511.03328)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A recent advancement in Multimodal Large Language Models (MLLMs) research is the emergence of "reasoning MLLMs" that offer explicit control over their internal thinking processes (normally referred as the "thinking mode") alongside the standard "non-thinking mode". This capability allows these models to engage in a step-by-step process of internal deliberation before generating a final response. With the rapid transition to and adoption of these "dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning processes of these MLLMs impact model performance and reliability in clinical tasks. This paper evaluates the active "thinking mode" capabilities of two leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We assessed their performance on four visual medical tasks using VQA-RAD and ROCOv2 datasets. Our findings reveal that the improvement from activating the thinking mode remains marginal compared to the standard non-thinking mode for the majority of the tasks. Their performance on complex medical tasks such as open-ended VQA and medical image interpretation remains suboptimal, highlighting the need for domain-specific medical data and more advanced methods for medical knowledge integration.</li>
</ul>

<h3>Title: Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge</h3>
<ul>
<li><strong>Authors: </strong>Yi Yang, Yiming Xu, Timo Kaiser, Hao Cheng, Bodo Rosenhahn, Michael Ying Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03332">https://arxiv.org/abs/2511.03332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03332">https://arxiv.org/pdf/2511.03332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03332]] Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge(https://arxiv.org/abs/2511.03332)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this report, we present our solution to the MOT25-Spatiotemporal Action Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately localize and track multiple objects that match specific and free-form language queries, using video data of complex real-world scenes as input. We model the underlying task as a video retrieval problem and present a two-stage, zero-shot approach, combining the advantages of the SOTA tracking model FastTracker and Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which won second place in the challenge.</li>
</ul>

<h3>Title: UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions</h3>
<ul>
<li><strong>Authors: </strong>Guozhen Zhang, Zixiang Zhou, Teng Hu, Ziqiao Peng, Youliang Zhang, Yi Chen, Yuan Zhou, Qinglin Lu, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03334">https://arxiv.org/abs/2511.03334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03334">https://arxiv.org/pdf/2511.03334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03334]] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions(https://arxiv.org/abs/2511.03334)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Due to the lack of effective cross-modal modeling, existing open-source audio-video generation methods often exhibit compromised lip synchronization and insufficient semantic consistency. To mitigate these drawbacks, we propose UniAVGen, a unified framework for joint audio and video generation. UniAVGen is anchored in a dual-branch joint synthesis architecture, incorporating two parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which enables bidirectional, temporally aligned cross-attention, thus ensuring precise spatiotemporal synchronization and semantic consistency. Furthermore, this cross-modal interaction is augmented by a Face-Aware Modulation module, which dynamically prioritizes salient regions in the interaction process. To enhance generative fidelity during inference, we additionally introduce Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint synthesis design enables seamless unification of pivotal audio-video tasks within a single model, such as joint audio-video generation and continuation, video-to-audio dubbing, and audio-driven video synthesis. Comprehensive experiments validate that, with far fewer training samples (1.3M vs. 30.1M), UniAVGen delivers overall advantages in audio-video synchronization, timbre consistency, and emotion consistency.</li>
</ul>

<h3>Title: LaMoS: Enabling Efficient Large Number Modular Multiplication through SRAM-based CiM Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Haomin Li, Fangxin Liu, Chenyang Guan, Zongwu Wang, Li Jiang, Haibing Guan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03341">https://arxiv.org/abs/2511.03341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03341">https://arxiv.org/pdf/2511.03341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03341]] LaMoS: Enabling Efficient Large Number Modular Multiplication through SRAM-based CiM Acceleration(https://arxiv.org/abs/2511.03341)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Barrett's algorithm is one of the most widely used methods for performing modular multiplication, a critical nonlinear operation in modern privacy computing techniques such as homomorphic encryption (HE) and zero-knowledge proofs (ZKP). Since modular multiplication dominates the processing time in these applications, computational complexity and memory limitations significantly impact performance. Computing-in-Memory (CiM) is a promising approach to tackle this problem. However, existing schemes currently suffer from two main problems: 1) Most works focus on low bit-width modular multiplication, which is inadequate for mainstream cryptographic algorithms such as elliptic curve cryptography (ECC) and the RSA algorithm, both of which require high bit-width operations; 2) Recent efforts targeting large number modular multiplication rely on inefficient in-memory logic operations, resulting in high scaling costs for larger bit-widths and increased latency. To address these issues, we propose LaMoS, an efficient SRAM-based CiM design for large-number modular multiplication, offering high scalability and area efficiency. First, we analyze the Barrett's modular multiplication method and map the workload onto SRAM CiM macros for high bit-width cases. Additionally, we develop an efficient CiM architecture and dataflow to optimize large-number modular multiplication. Finally, we refine the mapping scheme for better scalability in high bit-width scenarios using workload grouping. Experimental results show that LaMoS achieves a $7.02\times$ speedup and reduces high bit-width scaling costs compared to existing SRAM-based CiM designs.</li>
</ul>

<h3>Title: SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration</h3>
<ul>
<li><strong>Authors: </strong>Elif Arslan, Jacobus G. M. van der Linden, Serge Hoogendoorn, Marco Rinaldi, Emir Demirović</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03344">https://arxiv.org/abs/2511.03344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03344">https://arxiv.org/pdf/2511.03344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03344]] SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration(https://arxiv.org/abs/2511.03344)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Sparse decision tree learning provides accurate and interpretable predictive models that are ideal for high-stakes applications by finding the single most accurate tree within a (soft) size limit. Rather than relying on a single "best" tree, Rashomon sets-trees with similar performance but varying structures-can be used to enhance variable importance analysis, enrich explanations, and enable users to choose simpler trees or those that satisfy stakeholder preferences (e.g., fairness) without hard-coding such criteria into the objective function. However, because finding the optimal tree is NP-hard, enumerating the Rashomon set is inherently challenging. Therefore, we introduce SORTD, a novel framework that improves scalability and enumerates trees in the Rashomon set in order of the objective value, thus offering anytime behavior. Our experiments show that SORTD reduces runtime by up to two orders of magnitude compared with the state of the art. Moreover, SORTD can compute Rashomon sets for any separable and totally ordered objective and supports post-evaluating the set using other separable (and partially ordered) objectives. Together, these advances make exploring Rashomon sets more practical in real-world applications.</li>
</ul>

<h3>Title: Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances</h3>
<ul>
<li><strong>Authors: </strong>Riasad Alvi, Sayeem Been Zaman, Wasimul Karim, Arefin Ittesafun Abian, Mohaimenul Azam Khan Raiaan, Saddam Mukta, Md Rafi Ur Rashid, Md Rafiqul Islam, Yakub Sebastian, Sami Azam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03354">https://arxiv.org/abs/2511.03354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03354">https://arxiv.org/pdf/2511.03354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03354]] Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances(https://arxiv.org/abs/2511.03354)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative artificial intelligence (GenAI) has become a transformative approach in bioinformatics that often enables advancements in genomics, proteomics, transcriptomics, structural biology, and drug discovery. To systematically identify and evaluate these growing developments, this review proposed six research questions (RQs), according to the preferred reporting items for systematic reviews and meta-analysis methods. The objective is to evaluate impactful GenAI strategies in methodological advancement, predictive performance, and specialization, and to identify promising approaches for advanced modeling, data-intensive discovery, and integrative biological analysis. RQ1 highlights diverse applications across multiple bioinformatics subfields (sequence analysis, molecular design, and integrative data modeling), which demonstrate superior performance over traditional methods through pattern recognition and output generation. RQ2 reveals that adapted specialized model architectures outperformed general-purpose models, an advantage attributed to targeted pretraining and context-aware strategies. RQ3 identifies significant benefits in the bioinformatics domains, focusing on molecular analysis and data integration, which improves accuracy and reduces errors in complex analysis. RQ4 indicates improvements in structural modeling, functional prediction, and synthetic data generation, validated by established benchmarks. RQ5 suggests the main constraints, such as the lack of scalability and biases in data that impact generalizability, and proposes future directions focused on robust evaluation and biologically grounded modeling. RQ6 examines that molecular datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly support the training and generalization of GenAI models.</li>
</ul>

<h3>Title: A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications</h3>
<ul>
<li><strong>Authors: </strong>Xiaocai Zhang, Hur Lim, Ke Wang, Zhe Xiao, Jing Wang, Kelvin Lee, Xiuju Fu, Zheng Qin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03363">https://arxiv.org/abs/2511.03363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03363">https://arxiv.org/pdf/2511.03363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03363]] A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications(https://arxiv.org/abs/2511.03363)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free, large language model</a></li>
<li><strong>Abstract: </strong>In this study, a modular, data-free pipeline for multi-label intention recognition is proposed for agentic AI applications in transportation. Unlike traditional intent recognition systems that depend on large, annotated corpora and often struggle with fine-grained, multi-label discrimination, our approach eliminates the need for costly data collection while enhancing the accuracy of multi-label intention understanding. Specifically, the overall pipeline, named DMTC, consists of three steps: 1) using prompt engineering to guide large language models (LLMs) to generate diverse synthetic queries in different transport scenarios; 2) encoding each textual query with a Sentence-T5 model to obtain compact semantic embeddings; 3) training a lightweight classifier using a novel online focal-contrastive (OFC) loss that emphasizes hard samples and maximizes inter-class separability. The applicability of the proposed pipeline is demonstrated in an agentic AI application in the maritime transportation context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35% and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that Sentence-T5 embeddings improve subset accuracy by at least 3.29% over alternative encoders, and integrating the OFC loss yields an additional 0.98% gain compared to standard contrastive objectives. In conclusion, our system seamlessly routes user queries to task-specific modules (e.g., ETA information, traffic risk evaluation, and other typical scenarios in the transportation domain), laying the groundwork for fully autonomous, intention-aware agents without costly manual labelling.</li>
</ul>

<h3>Title: TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets</h3>
<ul>
<li><strong>Authors: </strong>Hongrun Ren, Yun Xiong, Lei You, Yingying Wang, Haixu Xiong, Yangyong Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03368">https://arxiv.org/abs/2511.03368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03368">https://arxiv.org/pdf/2511.03368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03368]] TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets(https://arxiv.org/abs/2511.03368)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The rise of the machine learning (ML) model economy has intertwined markets for training datasets and pre-trained models. However, most pricing approaches still separate data and model transactions or rely on broker-centric pipelines that favor one side. Recent studies of data markets with externalities capture buyer interactions but do not yield a simultaneous and symmetric mechanism across data sellers, model producers, and model buyers. We propose a unified data-model coupled market that treats dataset and model trading as a single system. A supply-side mapping transforms dataset payments into buyer-visible model quotations, while a demand-side mapping propagates buyer prices back to datasets through Shapley-based allocation. Together, they form a closed loop that links four interactions: supply-demand propagation in both directions and mutual coupling among buyers and among sellers. We prove that the joint operator is a standard interference function (SIF), guaranteeing existence, uniqueness, and global convergence of equilibrium prices. Experiments demonstrate efficient convergence and improved fairness compared with broker-centric and one-sided baselines. The code is available on this https URL.</li>
</ul>

<h3>Title: Silenced Biases: The Dark Side LLMs Learned to Refuse</h3>
<ul>
<li><strong>Authors: </strong>Rom Himelstein, Amit LeVi, Brit Youngmann, Yaniv Nemcovsky, Avi Mendelson</a></li>
<li><strong>Subjects: </strong>cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03369">https://arxiv.org/abs/2511.03369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03369">https://arxiv.org/pdf/2511.03369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03369]] Silenced Biases: The Dark Side LLMs Learned to Refuse(https://arxiv.org/abs/2511.03369)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Safety-aligned large language models (LLMs) are becoming increasingly widespread, especially in sensitive applications where fairness is essential and biased outputs can cause significant harm. However, evaluating the fairness of models is a complex challenge, and approaches that do so typically utilize standard question-answer (QA) styled schemes. Such methods often overlook deeper issues by interpreting the model's refusal responses as positive fairness measurements, which creates a false sense of fairness. In this work, we introduce the concept of silenced biases, which are unfair preferences encoded within models' latent space and are effectively concealed by safety-alignment. Previous approaches that considered similar indirect biases often relied on prompt manipulation or handcrafted implicit queries, which present limited scalability and risk contaminating the evaluation process with additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to uncover these biases by employing activation steering to reduce model refusals during QA. SBB supports easy expansion to new demographic groups and subjects, presenting a fairness evaluation framework that encourages the future development of fair models and tools beyond the masking effects of alignment training. We demonstrate our approach over multiple LLMs, where our findings expose an alarming distinction between models' direct responses and their underlying fairness issues.</li>
</ul>

<h3>Title: EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation</h3>
<ul>
<li><strong>Authors: </strong>Yunbo Long, Yuhan Liu, Alexandra Brintrup</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03370">https://arxiv.org/abs/2511.03370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03370">https://arxiv.org/pdf/2511.03370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03370]] EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation(https://arxiv.org/abs/2511.03370)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>The deployment of large language models (LLMs) in automated negotiation has set a high performance benchmark, but their computational cost and data privacy requirements render them unsuitable for many privacy-sensitive, on-device applications such as mobile assistants, embodied AI agents or private client interactions. While small language models (SLMs) offer a practical alternative, they suffer from a significant performance gap compared to LLMs in playing emotionally charged complex personas, especially for credit negotiation. This paper introduces EQ-Negotiator, a novel framework that bridges this capability gap using emotional personas. Its core is a reasoning system that integrates game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional states online, without pre-training. This allows EQ-Negotiator to equip SLMs with the strategic intelligence to counter manipulation while de-escalating conflict and upholding ethical standards. Through extensive agent-to-agent simulations across diverse credit negotiation scenarios, including adversarial debtor strategies like cheating, threatening, and playing the victim, we show that a 7B parameter language model with EQ-Negotiator achieves better debt recovery and negotiation efficiency than baseline LLMs more than 10 times its size. This work advances persona modeling from descriptive character profiles to dynamic emotional architectures that operate within privacy constraints. Besides, this paper establishes that strategic emotional intelligence, not raw model scale, is the critical factor for success in automated negotiation, paving the way for effective, ethical, and privacy-preserving AI negotiators that can operate on the edge.</li>
</ul>

<h3>Title: LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Shenghao Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03372">https://arxiv.org/abs/2511.03372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03372">https://arxiv.org/pdf/2511.03372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03372]] LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning(https://arxiv.org/abs/2511.03372)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>For complex logical data augmentation, heavy reliance on human annotation is costly, whereas direct generation with large language models yields uninterpretable and logically homogeneous examples. To address this, we present LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to propositional expressions, a compact rule library is compiled, and a bounded state-space search systematically discovers valid formulas that are then verbalized back into natural-language questions, ensuring both diversity and logical rigor under propositional logic. Experiments on ReClor and LogiQA show significant improvements in the logical-reasoning accuracy of pretrained models, confirming the effectiveness of LFC-DA for LLM-guided logical data augmentation.</li>
</ul>

<h3>Title: Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance</h3>
<ul>
<li><strong>Authors: </strong>Saumitra Yadav, Manish Shrivastava</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03383">https://arxiv.org/abs/2511.03383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03383">https://arxiv.org/pdf/2511.03383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03383]] Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance(https://arxiv.org/abs/2511.03383)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Existing Machine Translation (MT) research often suggests a single, fixed set of hyperparameters for word segmentation models, symmetric Byte Pair Encoding (BPE), which applies the same number of merge operations (NMO) to train tokenizers for both source and target languages. However, we demonstrate that this uniform approach doesn't guarantee optimal MT performance across different language pairs and data sizes. This work investigates BPE segmentation recipes across various data volumes and language pairs to evaluate MT system performance. We find that utilizing asymmetric BPE, where the source and target languages have different NMOs, significantly improves results over the symmetric approach, especially in low-resource settings (50K, 100K, and 500K sentence pairs). Specifically, asymmetric BPE yield statistically significant ($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in low-resource setups. We validated this trend across six additional language pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut), observing statistically significant improvement in 10 out of 12 systems compared to symmetric BPE. Our findings indicate a high NMO for the source (4K to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results, particularly benefiting low-resource MT.</li>
</ul>

<h3>Title: Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties</h3>
<ul>
<li><strong>Authors: </strong>Célian Ringwald, Fabien Gandon, Catherine Faron, Franck Michel, Hanna Abi Akl</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03407">https://arxiv.org/abs/2511.03407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03407">https://arxiv.org/pdf/2511.03407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03407]] Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties(https://arxiv.org/abs/2511.03407)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Small language models (SLMs) have shown promises for relation extraction (RE) when extracting RDF triples guided by SHACL shapes focused on common datatype properties. This paper investigates how SLMs handle both datatype and object properties for a complete RDF graph extraction. We show that the key bottleneck is related to long-tail distribution of rare properties. To solve this issue, we evaluate several strategies: stratified sampling, weighted loss, dataset scaling, and template-based synthetic data augmentation. We show that the best strategy to perform equally well over unbalanced target properties is to build a training set where the number of occurrences of each property exceeds a given threshold. To enable reproducibility, we publicly released our datasets, experimental results and code. Our findings offer practical guidance for training shape-aware SLMs and highlight promising directions for future work in semantic RE.</li>
</ul>

<h3>Title: Efficient Reasoning via Thought-Training and Thought-Free Inference</h3>
<ul>
<li><strong>Authors: </strong>Canhui Wu, Qiong Cao, Chao Xue, Wei Xi, Xiaodong He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03408">https://arxiv.org/abs/2511.03408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03408">https://arxiv.org/pdf/2511.03408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03408]] Efficient Reasoning via Thought-Training and Thought-Free Inference(https://arxiv.org/abs/2511.03408)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have leveraged explicit Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most existing methods primarily compress verbose reasoning outputs. These Long-to-Short transformations aim to improve efficiency, but still rely on explicit reasoning during inference. In this work, we introduce \textbf{3TF} (\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree inference), a framework for efficient reasoning that takes a Short-to-Long perspective. We first train a hybrid model that can operate in both reasoning and non-reasoning modes, and then further train it on CoT-annotated data to internalize structured reasoning, while enforcing concise, thought-free outputs at inference time using the no-reasoning mode. Unlike compression-based approaches, 3TF improves the reasoning quality of non-reasoning outputs, enabling models to perform rich internal reasoning implicitly while keeping external outputs short. Empirically, 3TF-trained models obtain large improvements on reasoning benchmarks under thought-free inference, demonstrating that high quality reasoning can be learned and executed implicitly without explicit step-by-step generation.</li>
</ul>

<h3>Title: Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG</h3>
<ul>
<li><strong>Authors: </strong>Longpeng Qiu, Ting Li, Shuai Mao, Nan Yang, Xiaohui Yan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03410">https://arxiv.org/abs/2511.03410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03410">https://arxiv.org/pdf/2511.03410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03410]] Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG(https://arxiv.org/abs/2511.03410)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Input errors in question-answering (QA) systems often lead to incorrect responses. Large language models (LLMs) struggle with this task, frequently failing to interpret user intent (misinterpretation) or unnecessarily altering the original question's structure (over-correction). We propose QuestionRAG, a framework that tackles these problems. To address misinterpretation, it enriches the input with external knowledge (e.g., search results, related entities). To prevent over-correction, it uses reinforcement learning (RL) to align the model's objective with precise correction, not just paraphrasing. Our results demonstrate that knowledge augmentation is critical for understanding faulty questions. Furthermore, RL-based alignment proves significantly more effective than traditional supervised fine-tuning (SFT), boosting the model's ability to follow instructions and generalize. By integrating these two strategies, QuestionRAG unlocks the full potential of LLMs for the question correction task.</li>
</ul>

<h3>Title: Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort</h3>
<ul>
<li><strong>Authors: </strong>Nikolai Herrmann, Marcella C. Zijta, Stefan Klein, Régine P.M. Steegers-Theunissen, Rene M.H. Wijnen, Bernadette S. de Bakker, Melek Rousian, Wietske A.P. Bastiaansen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03416">https://arxiv.org/abs/2511.03416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03416">https://arxiv.org/pdf/2511.03416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03416]] Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort(https://arxiv.org/abs/2511.03416)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Standardized alignment of the embryo in three-dimensional (3D) ultrasound images aids prenatal growth monitoring by facilitating standard plane detection, improving visualization of landmarks and accentuating differences between different scans. In this work, we propose an automated method for standardizing this alignment. Given a segmentation mask of the embryo, Principal Component Analysis (PCA) is applied to the mask extracting the embryo's principal axes, from which four candidate orientations are derived. The candidate in standard orientation is selected using one of three strategies: a heuristic based on Pearson's correlation assessing shape, image matching to an atlas through normalized cross-correlation, and a Random Forest classifier. We tested our method on 2166 images longitudinally acquired 3D ultrasound scans from 1043 pregnancies from the Rotterdam Periconceptional Cohort, ranging from 7+0 to 12+6 weeks of gestational age. In 99.0% of images, PCA correctly extracted the principal axes of the embryo. The correct candidate was selected by the Pearson Heuristic, Atlas-based and Random Forest in 97.4%, 95.8%, and 98.4% of images, respectively. A Majority Vote of these selection methods resulted in an accuracy of 98.5%. The high accuracy of this pipeline enables consistent embryonic alignment in the first trimester, enabling scalable analysis in both clinical and research settings. The code is publicly available at: this https URL.</li>
</ul>

<h3>Title: CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field</h3>
<ul>
<li><strong>Authors: </strong>Doria Bonzi, Alexandre Guiggi, Frédéric Béchet, Carlos Ramisch, Benoit Favre</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03441">https://arxiv.org/abs/2511.03441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03441">https://arxiv.org/pdf/2511.03441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03441]] CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field(https://arxiv.org/abs/2511.03441)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Critical appraisal of scientific literature is an essential skill in the biomedical field. While large language models (LLMs) can offer promising support in this task, their reliability remains limited, particularly for critical reasoning in specialized domains. We introduce CareMedEval, an original dataset designed to evaluate LLMs on biomedical critical appraisal and reasoning tasks. Derived from authentic exams taken by French medical students, the dataset contains 534 questions based on 37 scientific articles. Unlike existing benchmarks, CareMedEval explicitly evaluates critical reading and reasoning grounded in scientific papers. Benchmarking state-of-the-art generalist and biomedical-specialized LLMs under various context conditions reveals the difficulty of the task: open and commercial models fail to exceed an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens considerably improves the results. Yet, models remain challenged especially on questions about study limitations and statistical analysis. CareMedEval provides a challenging benchmark for grounded reasoning, exposing current LLM limitations and paving the way for future development of automated support for critical appraisal.</li>
</ul>

<h3>Title: Generalizing Shape-from-Template to Topological Changes</h3>
<ul>
<li><strong>Authors: </strong>Kevin Manogue, Tomasz M Schang, Dilara Kuş, Jonas Müller, Stefan Zachow, Agniva Sengupta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03459">https://arxiv.org/abs/2511.03459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03459">https://arxiv.org/pdf/2511.03459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03459]] Generalizing Shape-from-Template to Topological Changes(https://arxiv.org/abs/2511.03459)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reconstructing the surfaces of deformable objects from correspondences between a 3D template and a 2D image is well studied under Shape-from-Template (SfT) methods; however, existing approaches break down when topological changes accompany the deformation. We propose a principled extension of SfT that enables reconstruction in the presence of such changes. Our approach is initialized with a classical SfT solution and iteratively adapts the template by partitioning its spatial domain so as to minimize an energy functional that jointly encodes physical plausibility and reprojection consistency. We demonstrate that the method robustly captures a wide range of practically relevant topological events including tears and cuts on bounded 2D surfaces, thereby establishing the first general framework for topological-change-aware SfT. Experiments on both synthetic and real data confirm that our approach consistently outperforms baseline methods.</li>
</ul>

<h3>Title: POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding</h3>
<ul>
<li><strong>Authors: </strong>Mihriban Kocak Balik, Pekka Marttinen, Negar Safinianaini</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03464">https://arxiv.org/abs/2511.03464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03464">https://arxiv.org/pdf/2511.03464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03464]] POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding(https://arxiv.org/abs/2511.03464)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Integrating different molecular layers, i.e., multiomics data, is crucial for unraveling the complexity of diseases; yet, most deep generative models either prioritize predictive performance at the expense of interpretability or enforce interpretability by linearizing the decoder, thereby weakening the network's nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS: Product Of Experts for Interpretable Multiomics Integration using Sparse Decoding, an unsupervised probabilistic framework that preserves predictive performance while providing interpretability. POEMS provides interpretability without linearizing any part of the network by 1) mapping features to latent factors using sparse connections, which directly translates to biomarker discovery, 2) allowing for cross-omic associations through a shared latent space using product of experts model, and 3) reporting contributions of each omic by a gating network that adaptively computes their influence in the representation learning. Additionally, we present an efficient sparse decoder. In a cancer subtyping case study, POEMS achieves competitive clustering and classification performance while offering our novel set of interpretations, demonstrating that biomarker based insight and predictive accuracy can coexist in multiomics representation learning.</li>
</ul>

<h3>Title: Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction</h3>
<ul>
<li><strong>Authors: </strong>Ringwald Celian, Gandon Fabien, Faron Catherine, Michel Franck, Abi Akl Hanna</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03466">https://arxiv.org/abs/2511.03466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03466">https://arxiv.org/pdf/2511.03466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03466]] Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction(https://arxiv.org/abs/2511.03466)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>RDF pattern-based extraction is a compelling approach for fine-tuning small language models (SLMs) by focusing a relation extraction task on a specified SHACL shape. This technique enables the development of efficient models trained on limited text and RDF data. In this article, we introduce Kastor, a framework that advances this approach to meet the demands for completing and refining knowledge bases in specialized domains. Kastor reformulates the traditional validation task, shifting from single SHACL shape validation to evaluating all possible combinations of properties derived from the shape. By selecting the optimal combination for each training example, the framework significantly enhances model generalization and performance. Additionally, Kastor employs an iterative learning process to refine noisy knowledge bases, enabling the creation of robust models capable of uncovering new, relevant facts</li>
</ul>

<h3>Title: RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse</h3>
<ul>
<li><strong>Authors: </strong>Yinsicheng Jiang, Yeqi Huang, Liang Cheng, Cheng Deng, Xuan Sun, Luo Mai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03475">https://arxiv.org/abs/2511.03475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03475">https://arxiv.org/pdf/2511.03475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03475]] RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse(https://arxiv.org/abs/2511.03475)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) enhances large language models (LLMs) with retrieved context but often suffers from downgraded prefill performance as modern applications demand longer and more complex inputs. Existing caching techniques either preserve accuracy with low cache reuse or improve reuse at the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG system that achieves high cache reuse without sacrificing accuracy through accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items across concurrent sessions and multi-turn interactions, using efficient context indexing, ordering, and de-duplication to maximize reuse, while lightweight contextual hints maintain reasoning fidelity. It integrates seamlessly with existing LLM inference engines and improves their prefill performance by 1.5-3X over state-of-the-art methods, while preserving or even enhancing reasoning accuracy across diverse RAG and agentic AI workloads. Our code is released at: this https URL.</li>
</ul>

<h3>Title: Federated Anonymous Blocklisting across Service Providers and its Application to Group Messaging</h3>
<ul>
<li><strong>Authors: </strong>David Soler, Carlos Dafonte, Manuel Fernández-Veiga, Ana Fernández Vilas, Francisco J. Nóvoa</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03486">https://arxiv.org/abs/2511.03486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03486">https://arxiv.org/pdf/2511.03486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03486]] Federated Anonymous Blocklisting across Service Providers and its Application to Group Messaging(https://arxiv.org/abs/2511.03486)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Instant messaging has become one of the most used methods of communication online, which has attracted significant attention to its underlying cryptographic protocols and security guarantees. Techniques to increase privacy such as End-to-End Encryption and pseudonyms have been introduced. However, online spaces such as messaging groups still require moderation to prevent misbehaving users from participating in them, particularly in anonymous contexts.. In Anonymous Blocklisting (AB) schemes, users must prove during authentication that none of their previous pseudonyms has been blocked, preventing misbehaving users from creating new pseudonyms. In this work we propose an alternative \textit{Federated Anonymous Blocklisting} (FAB) in which the centralised Service Provider is replaced by small distributed Realms, each with its own blocklist. Realms can establish trust relationships between each other, such that when users authenticate to a realm, they must prove that they are not banned in any of its trusted realms. We provide an implementation of our proposed scheme; unlike existing AB constructions, the performance of ours does not depend on the current size of the blocklist nor requires processing new additions to the blocklist. We also demonstrate its applicability to real-world messaging groups by integrating our FAB scheme into the Messaging Layer Security protocol.</li>
</ul>

<h3>Title: BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation</h3>
<ul>
<li><strong>Authors: </strong>Kazi Reyazul Hasan, Mubasshira Musarrat, A. B. M. Alim Al Islam, Muhammad Abdullah Adnan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03498">https://arxiv.org/abs/2511.03498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03498">https://arxiv.org/pdf/2511.03498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03498]] BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation(https://arxiv.org/abs/2511.03498)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models work well for technical problem solving in English but perform poorly when the same questions are asked in Bangla. A simple solution would be to translate Bangla questions into English first and then use these models. However, existing Bangla-English translation systems struggle with technical terms. They often mistranslate specialized vocabulary, which changes the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM fields including computer science, mathematics, physics, chemistry, and biology. We generated over 12,000 translations using language models and then used human evaluators to select the highest quality pairs that preserve technical terminology correctly. We train a T5-based translation model on BanglaSTEM and test it on two tasks: generating code and solving math problems. Our results show significant improvements in translation accuracy for technical content, making it easier for Bangla speakers to use English-focused language models effectively. Both the BanglaSTEM dataset and the trained translation model are publicly released at this https URL.</li>
</ul>

<h3>Title: HaluMem: Evaluating Hallucinations in Memory Systems of Agents</h3>
<ul>
<li><strong>Authors: </strong>Ding Chen, Simin Niu, Kehang Li, Peng Liu, Xiangping Zheng, Bo Tang, Xinchi Li, Feiyu Xiong, Zhiyu Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03506">https://arxiv.org/abs/2511.03506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03506">https://arxiv.org/pdf/2511.03506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03506]] HaluMem: Evaluating Hallucinations in Memory Systems of Agents(https://arxiv.org/abs/2511.03506)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Memory systems are key components that enable AI systems such as LLMs and AI agents to achieve long-term learning and sustained interaction. However, during memory storage and retrieval, these systems frequently exhibit memory hallucinations, including fabrication, errors, conflicts, and omissions. Existing evaluations of memory hallucinations are primarily end-to-end question answering, which makes it difficult to localize the operational stage within the memory system where hallucinations arise. To address this, we introduce the Hallucination in Memory Benchmark (HaluMem), the first operation level hallucination evaluation benchmark tailored to memory systems. HaluMem defines three evaluation tasks (memory extraction, memory updating, and memory question answering) to comprehensively reveal hallucination behaviors across different operational stages of interaction. To support evaluation, we construct user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and HaluMem-Long. Both include about 15k memory points and 3.5k multi-type questions. The average dialogue length per user reaches 1.5k and 2.6k turns, with context lengths exceeding 1M tokens, enabling evaluation of hallucinations across different context scales and task complexities. Empirical studies based on HaluMem show that existing memory systems tend to generate and accumulate hallucinations during the extraction and updating stages, which subsequently propagate errors to the question answering stage. Future research should focus on developing interpretable and constrained memory operation mechanisms that systematically suppress hallucinations and improve memory reliability.</li>
</ul>

<h3>Title: One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework</h3>
<ul>
<li><strong>Authors: </strong>Qi Jia, Kaiwei Zhang, Xiujie Song, Ye Shen, Xiangyang Zhu, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03508">https://arxiv.org/abs/2511.03508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03508">https://arxiv.org/pdf/2511.03508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03508]] One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework(https://arxiv.org/abs/2511.03508)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Understanding how well large language models can follow users' instructions throughout a dialogue spanning multiple topics is of great importance for data-intensive conversational applications. Existing benchmarks are often limited to a fixed number of turns, making them susceptible to saturation and failing to account for the user's interactive experience. In this work, we propose an extensible framework for assessing multi-turn instruction-following ability. At its core, our framework decouples linguistic surface forms from user intent simulation through a three-layer mechanism that tracks constraints, instructions, and topics. This framework mimics User-LLM interaction by enabling the dynamic construction of benchmarks with state changes and tracebacks, terminating a conversation only when the model exhausts a simulated user's patience. We define a suite of metrics capturing the quality of the interaction process. Using this framework, we construct EvolIF, an evolving instruction-following benchmark incorporating nine distinct constraint types. Our results indicate that GPT-5 exhibits superior instruction-following performance. It sustains an average of 18.54 conversational turns and demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant margin of 11.41%, while other models lag far behind. All of the data and code will be made publicly available online.</li>
</ul>

<h3>Title: Byzantine-Robust Federated Learning with Learnable Aggregation Weights</h3>
<ul>
<li><strong>Authors: </strong>Javad Parsa, Amir Hossein Daghestani, André M. H. Teixeira, Mikael Johansson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03529">https://arxiv.org/abs/2511.03529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03529">https://arxiv.org/pdf/2511.03529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03529]] Byzantine-Robust Federated Learning with Learnable Aggregation Weights(https://arxiv.org/abs/2511.03529)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables clients to collaboratively train a global model without sharing their private data. However, the presence of malicious (Byzantine) clients poses significant challenges to the robustness of FL, particularly when data distributions across clients are heterogeneous. In this paper, we propose a novel Byzantine-robust FL optimization problem that incorporates adaptive weighting into the aggregation process. Unlike conventional approaches, our formulation treats aggregation weights as learnable parameters, jointly optimizing them alongside the global model parameters. To solve this optimization problem, we develop an alternating minimization algorithm with strong convergence guarantees under adversarial attack. We analyze the Byzantine resilience of the proposed objective. We evaluate the performance of our algorithm against state-of-the-art Byzantine-robust FL approaches across various datasets and attack scenarios. Experimental results demonstrate that our method consistently outperforms existing approaches, particularly in settings with highly heterogeneous data and a large proportion of malicious clients.</li>
</ul>

<h3>Title: Efficient Neural Networks with Discrete Cosine Transform Activations</h3>
<ul>
<li><strong>Authors: </strong>Marc Martinez-Gost, Sara Pepe, Ana Pérez-Neira, Miguel Ángel Lagunas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03531">https://arxiv.org/abs/2511.03531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03531">https://arxiv.org/pdf/2511.03531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03531]] Efficient Neural Networks with Discrete Cosine Transform Activations(https://arxiv.org/abs/2511.03531)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In this paper, we extend our previous work on the Expressive Neural Network (ENN), a multilayer perceptron with adaptive activation functions parametrized using the Discrete Cosine Transform (DCT). Building upon previous work that demonstrated the strong expressiveness of ENNs with compact architectures, we now emphasize their efficiency, interpretability and pruning capabilities. The DCT-based parameterization provides a structured and decorrelated representation that reveals the functional role of each neuron and allows direct identification of redundant components. Leveraging this property, we propose an efficient pruning strategy that removes unnecessary DCT coefficients with negligible or no loss in performance. Experimental results across classification and implicit neural representation tasks confirm that ENNs achieve state-of-the-art accuracy while maintaining a low number of parameters. Furthermore, up to 40% of the activation coefficients can be safely pruned, thanks to the orthogonality and bounded nature of the DCT basis. Overall, these findings demonstrate that the ENN framework offers a principled integration of signal processing concepts into neural network design, achieving a balanced trade-off between expressiveness, compactness, and interpretability.</li>
</ul>

<h3>Title: Security and Privacy Management of IoT Using Quantum Computing</h3>
<ul>
<li><strong>Authors: </strong>Jaydip Sen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03538">https://arxiv.org/abs/2511.03538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03538">https://arxiv.org/pdf/2511.03538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03538]] Security and Privacy Management of IoT Using Quantum Computing(https://arxiv.org/abs/2511.03538)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust</a></li>
<li><strong>Abstract: </strong>The convergence of the Internet of Things (IoT) and quantum computing is redefining the security paradigm of interconnected digital systems. Classical cryptographic algorithms such as RSA, Elliptic Curve Cryptography (ECC), and Advanced Encryption Standard (AES) have long provided the foundation for securing IoT communication. However, the emergence of quantum algorithms such as Shor's and Grover's threatens to render these techniques vulnerable, necessitating the development of quantum-resilient alternatives. This chapter examines the implications of quantum computing for IoT security and explores strategies for building cryptographically robust systems in the post-quantum era. It presents an overview of Post-Quantum Cryptographic (PQC) families, including lattice-based, code-based, hash-based, and multivariate approaches, analyzing their potential for deployment in resource-constrained IoT environments. In addition, quantum-based methods such as Quantum Key Distribution (QKD) and Quantum Random Number Generators (QRNGs) are discussed for their ability to enhance confidentiality and privacy through physics-based security guarantees. The chapter also highlights issues of privacy management, regulatory compliance, and standardization, emphasizing the need for collaborative efforts across academia, industry, and governance. Overall, it provides a comprehensive perspective on security IoT ecosystems against quantum threats and ensures resilience in the next generation of intelligent networks.</li>
</ul>

<h3>Title: SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties</h3>
<ul>
<li><strong>Authors: </strong>Roberta Di Marino, Giovanni Dioguardi, Antonio Romano, Giuseppe Riccio, Mariano Barone, Marco Postiglione, Flora Amato, Vincenzo Moscato</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03542">https://arxiv.org/abs/2511.03542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03542">https://arxiv.org/pdf/2511.03542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03542]] SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties(https://arxiv.org/abs/2511.03542)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Medical question answering systems face deployment challenges including hallucinations, bias, computational demands, privacy concerns, and the need for specialized expertise across diverse domains. Here, we present SOLVE-Med, a multi-agent architecture combining domain-specialized small language models for complex medical queries. The system employs a Router Agent for dynamic specialist selection, ten specialized models (1B parameters each) fine-tuned on specific medical domains, and an Orchestrator Agent that synthesizes responses. Evaluated on Italian medical forum data across ten specialties, SOLVE-Med achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697, outperforming standalone models up to 14B parameters while enabling local deployment. Our code is publicly available on GitHub: this https URL.</li>
</ul>

<h3>Title: Bearing Syntactic Fruit with Stack-Augmented Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Brian DuSell, Ryan Cotterell</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03547">https://arxiv.org/abs/2511.03547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03547">https://arxiv.org/pdf/2511.03547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03547]] Bearing Syntactic Fruit with Stack-Augmented Neural Networks(https://arxiv.org/abs/2511.03547)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Any finite set of training data is consistent with an infinite number of hypothetical algorithms that could have generated it. Studies have shown that when human children learn language, they consistently favor hypotheses based on hierarchical syntactic rules without ever encountering disambiguating examples. A recent line of work has inquired as to whether common neural network architectures share this bias, finding that they do so only under special conditions: when syntactically supervised, when pre-trained on massive corpora, or when trained long past convergence. In this paper, we demonstrate, for the first time, neural network architectures that are able to generalize in human-like fashion without any of the aforementioned requirements: stack-augmented neural networks. We test three base architectures (transformer, simple RNN, LSTM) augmented with two styles of stack: the superposition stack of Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed by DuSell & Chiang (2023). We find that transformers with nondeterministic stacks generalize best out of these architectures on a classical question formation task. We also propose a modification to the stack RNN architecture that improves hierarchical generalization. These results suggest that stack-augmented neural networks may be more accurate models of human language acquisition than standard architectures, serving as useful objects of psycholinguistic study. Our code is publicly available.</li>
</ul>

<h3>Title: MultiZebraLogic: A Multilingual Logical Reasoning Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Sofie Helene Bruun, Dan Saattrup Smart</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03553">https://arxiv.org/abs/2511.03553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03553">https://arxiv.org/pdf/2511.03553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03553]] MultiZebraLogic: A Multilingual Logical Reasoning Benchmark(https://arxiv.org/abs/2511.03553)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Measuring the full abilities of large language models (LLMs) requires benchmarks representing multiple tasks. We aim to create large, high-quality datasets for comparison of logical reasoning skills across several languages and of suitable difficulty for LLMs of various reasoning ability. We explore multiple ways of increasing difficulty. We generate zebra puzzles in multiple languages, themes, sizes and including 14 different clue types and 8 red herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a reasoning model), respectively. Including 5 red herrings decreases o3-mini puzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5 puzzles are not significantly affected by use of English vs. Danish or the common houses theme vs. the country-specific smoerrebroed theme. We find no correlation between difficulty and the selected clue types. Datasets of 128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic languages for sizes 2x3 and 4x5. We publish code for puzzle generation, designed for adaptablity into more languages and themes.</li>
</ul>

<h3>Title: AILA--First Experiments with Localist Language Models</h3>
<ul>
<li><strong>Authors: </strong>Joachim Diederich</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03559">https://arxiv.org/abs/2511.03559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03559">https://arxiv.org/pdf/2511.03559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03559]] AILA--First Experiments with Localist Language Models(https://arxiv.org/abs/2511.03559)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents the first empirical demonstration of controllable locality in transformer language models, a novel architectural framework that enables continuous control over the degree of representation localization through a tunable locality dial parameter. Unlike traditional language models that rely exclusively on distributed representations, our approach allows dynamic interpolation between highly interpretable localist encodings and efficient distributed representations without requiring model retraining. We conducted experiments on the WikiText corpus using a two-layer transformer architecture, systematically varying the locality parameter {\lambda} across the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our results demonstrate that localist configurations achieve dramatically lower attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18 bits at {\lambda} = 0.0, while maintaining substantially higher pointer fidelity scores reflecting stronger alignment with rule-specified targets. Prediction experiments reveal that intermediate locality values optimize the tradeoff between interpretability and performance, with {\lambda} = 0.6 achieving test perplexity of 4.65 and accuracy of 84.7%. These findings establish that localist language models provide a practical framework for applications in regulated domains requiring both transparency and capability, offering precise mathematical control over the interpretability-performance spectrum through explicit penalty thresholds and information-theoretic design principles.</li>
</ul>

<h3>Title: ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation</h3>
<ul>
<li><strong>Authors: </strong>One Octadion, Bondan Sapta Prakoso, Nanang Yudi Setiawan, Novanto Yudistira</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03563">https://arxiv.org/abs/2511.03563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03563">https://arxiv.org/pdf/2511.03563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03563]] ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation(https://arxiv.org/abs/2511.03563)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this study, we explore the fine-tuning of Large Language Models (LLMs) to better support policymakers in their crucial work of understanding, analyzing, and crafting legal regulations. To equip the model with a deep understanding of legal texts, we curated a supervised dataset tailored to the specific needs of the legal domain. Additionally, we integrated the Retrieval-Augmented Generation (RAG) method, enabling the LLM to access and incorporate up-to-date legal knowledge from external sources. This combination of fine-tuning and RAG-based augmentation results in a tool that not only processes legal information but actively assists policymakers in interpreting regulations and drafting new ones that align with current needs. The results demonstrate that this approach can significantly enhance the effectiveness of legal research and regulation development, offering a valuable resource in the ever-evolving field of law.</li>
</ul>

<h3>Title: Step-Audio-EditX Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Chao Yan, Boyong Wu, Peng Yang, Pengfei Tan, Guoqiang Hu, Yuxin Zhang, Xiangyu (Tony)Zhang, Fei Tian, Xuerui Yang, Xiangyu Zhang, Daxin Jiang, Gang Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03601">https://arxiv.org/abs/2511.03601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03601">https://arxiv.org/pdf/2511.03601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03601]] Step-Audio-EditX Technical Report(https://arxiv.org/abs/2511.03601)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present Step-Audio-EditX, the first open-source LLM-based audio model excelling at expressive and iterative audio editing encompassing emotion, speaking style, and paralinguistics alongside robust zero-shot text-to-speech (TTS) this http URL core innovation lies in leveraging only large-margin synthetic data, which circumvents the need for embedding-based priors or auxiliary modules. This large-margin learning approach enables both iterative control and high expressivity across voices, and represents a fundamental pivot from the conventional focus on representation-level disentanglement. Evaluation results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.</li>
</ul>

<h3>Title: A systematic review of relation extraction task since the emergence of Transformers</h3>
<ul>
<li><strong>Authors: </strong>Ringwald Celian, Gandon, Fabien, Faron Catherine, Michel Franck, Abi Akl Hanna</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03610">https://arxiv.org/abs/2511.03610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03610">https://arxiv.org/pdf/2511.03610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03610]] A systematic review of relation extraction task since the emergence of Transformers(https://arxiv.org/abs/2511.03610)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This article presents a systematic review of relation extraction (RE) research since the advent of Transformer-based models. Using an automated framework to collect and annotate publications, we analyze 34 surveys, 64 datasets, and 104 models published between 2019 and 2024. The review highlights methodological advances, benchmark resources, and the integration of semantic web technologies. By consolidating results across multiple dimensions, the study identifies current trends, limitations, and open challenges, offering researchers and practitioners a comprehensive reference for understanding the evolution and future directions of RE.</li>
</ul>

<h3>Title: Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Iason Chrysomallis, Georgios Chalkiadakis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03616">https://arxiv.org/abs/2511.03616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03616">https://arxiv.org/pdf/2511.03616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03616]] Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning(https://arxiv.org/abs/2511.03616)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Imitation learning traditionally requires complete state-action demonstrations from optimal or near-optimal experts. These requirements severely limit practical applicability, as many real-world scenarios provide only state observations without corresponding actions and expert performance is often suboptimal. In this paper we introduce a deep implicit imitation reinforcement learning framework that addresses both limitations by combining deep reinforcement learning with implicit imitation learning from observation-only datasets. Our main algorithm, Deep Implicit Imitation Q-Network (DIIQN), employs an action inference mechanism that reconstructs expert actions through online exploration and integrates a dynamic confidence mechanism that adaptively balances expert-guided and self-directed learning. This enables the agent to leverage expert guidance for accelerated training while maintaining capacity to surpass suboptimal expert performance. We further extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to tackle scenarios where expert and agent possess different action sets, a challenge previously unaddressed in the implicit imitation learning literature. HA-DIIQN introduces an infeasibility detection mechanism and a bridging procedure identifying alternative pathways connecting agent capabilities to expert guidance when direct action replication is impossible. Our experimental results demonstrate that DIIQN achieves up to 130% higher episodic returns compared to standard DQN, while consistently outperforming existing implicit imitation methods that cannot exceed expert performance. In heterogeneous action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging expert datasets unusable by conventional approaches. Extensive parameter sensitivity analysis reveals the framework's robustness across varying dataset sizes and hyperparameter configurations.</li>
</ul>

<h3>Title: Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Apoorva Upadhyaya, Wolfgang Nejdl, Marco Fisichella</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03635">https://arxiv.org/abs/2511.03635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03635">https://arxiv.org/pdf/2511.03635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03635]] Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability(https://arxiv.org/abs/2511.03635)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward unseen targets. Existing research using contrastive, meta-learning, or data augmentation suffers from generalizability issues or lack of coherence between text and target. Recent works leveraging large language models (LLMs) for ZSSD focus either on improving unseen target-specific knowledge or generating explanations for stance analysis. However, most of these works are limited by their over-reliance on explicit reasoning, provide coarse explanations that lack nuance, and do not explicitly model the reasoning process, making it difficult to interpret the model's predictions. To address these issues, in our study, we develop a novel interpretable ZSSD framework, IRIS. We provide an interpretable understanding of the attitude of the input towards the target implicitly based on sequences within the text (implicit rationales) and explicitly based on linguistic measures (explicit rationales). IRIS considers stance detection as an information retrieval ranking task, understanding the relevance of implicit rationales for different stances to guide the model towards correct predictions without requiring the ground-truth of rationales, thus providing inherent interpretability. In addition, explicit rationales based on communicative features help decode the emotional and cognitive dimensions of stance, offering an interpretable understanding of the author's attitude towards the given target. Extensive experiments on the benchmark datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10% training data prove the generalizability of our model, benefiting from the proposed architecture and interpretable design.</li>
</ul>

<h3>Title: Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology</h3>
<ul>
<li><strong>Authors: </strong>Thomas Souverain</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03641">https://arxiv.org/abs/2511.03641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03641">https://arxiv.org/pdf/2511.03641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03641]] Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology(https://arxiv.org/abs/2511.03641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>To foster trustworthy Artificial Intelligence (AI) within the European Union, the AI Act requires providers to mark and detect the outputs of their general-purpose models. The Article 50 and Recital 133 call for marking methods that are ''sufficiently reliable, interoperable, effective and robust''. Yet, the rapidly evolving and heterogeneous landscape of watermarks for Large Language Models (LLMs) makes it difficult to determine how these four standards can be translated into concrete and measurable evaluations. Our paper addresses this challenge, anchoring the normativity of European requirements in the multiplicity of watermarking techniques. Introducing clear and distinct concepts on LLM watermarking, our contribution is threefold. (1) Watermarking Categorisation: We propose an accessible taxonomy of watermarking methods according to the stage of the LLM lifecycle at which they are applied - before, during, or after training, and during next-token distribution or sampling. (2) Watermarking Evaluation: We interpret the EU AI Act's requirements by mapping each criterion with state-of-the-art evaluations on robustness and detectability of the watermark, and of quality of the LLM. Since interoperability remains largely untheorised in LLM watermarking research, we propose three normative dimensions to frame its assessment. (3) Watermarking Comparison: We compare current watermarking methods for LLMs against the operationalised European criteria and show that no approach yet satisfies all four standards. Encouraged by emerging empirical tests, we recommend further research into watermarking directly embedded within the low-level architecture of LLMs.</li>
</ul>

<h3>Title: ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03656">https://arxiv.org/abs/2511.03656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03656">https://arxiv.org/pdf/2511.03656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03656]] ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation(https://arxiv.org/abs/2511.03656)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of natural language processing (NLP) technologies, the demand for high-quality Chinese document question-answering datasets is steadily growing. To address this issue, we present the Chinese Multi-Document Question Answering Dataset(ChiMDQA), specifically designed for downstream business scenarios across prevalent domains including academic, education, finance, law, medical treatment, and news. ChiMDQA encompasses long-form documents from six distinct fields, consisting of 6,068 rigorously curated, high-quality question-answer (QA) pairs further classified into ten fine-grained categories. Through meticulous document screening and a systematic question-design methodology, the dataset guarantees both diversity and high quality, rendering it applicable to various NLP tasks such as document comprehension, knowledge extraction, and intelligent QA systems. Additionally, this paper offers a comprehensive overview of the dataset's design objectives, construction methodologies, and fine-grained evaluation system, supplying a substantial foundation for future research and practical applications in Chinese QA. The code and data are available at: this https URL.</li>
</ul>

<h3>Title: SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Mahek Desai, Apoorva Rumale, Marjan Asadinia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03661">https://arxiv.org/abs/2511.03661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03661">https://arxiv.org/pdf/2511.03661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03661]] SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection(https://arxiv.org/abs/2511.03661)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, generative</a></li>
<li><strong>Abstract: </strong>The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.</li>
</ul>

<h3>Title: A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Sefidgar Dilmaghani, Francis Fowley, Peter Corcoran</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03665">https://arxiv.org/abs/2511.03665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03665">https://arxiv.org/pdf/2511.03665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03665]] A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential(https://arxiv.org/abs/2511.03665)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper presents a lightweight three-dimensional convolutional neural network (3DCNN) for human activity recognition (HAR) using event-based vision data. Privacy preservation is a key challenge in human monitoring systems, as conventional frame-based cameras capture identifiable personal information. In contrast, event cameras record only changes in pixel intensity, providing an inherently privacy-preserving sensing modality. The proposed network effectively models both spatial and temporal dynamics while maintaining a compact design suitable for edge deployment. To address class imbalance and enhance generalization, focal loss with class reweighting and targeted data augmentation strategies are employed. The model is trained and evaluated on a composite dataset derived from the Toyota Smart Home and ETRI datasets. Experimental results demonstrate an F1-score of 0.9415 and an overall accuracy of 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D, and MC3_18 by up to 3%. These results highlight the potential of event-based deep learning for developing accurate, efficient, and privacy-aware human action recognition systems suitable for real-world edge applications.</li>
</ul>

<h3>Title: DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay</h3>
<ul>
<li><strong>Authors: </strong>Daniel Perkins, Oscar J. Escobar, Luke Green</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03670">https://arxiv.org/abs/2511.03670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03670">https://arxiv.org/pdf/2511.03670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03670]] DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay(https://arxiv.org/abs/2511.03670)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a detailed study of Deep Q-Networks in finite environments, emphasizing the impact of epsilon-greedy exploration schedules and prioritized experience replay. Through systematic experimentation, we evaluate how variations in epsilon decay schedules affect learning efficiency, convergence behavior, and reward optimization. We investigate how prioritized experience replay leads to faster convergence and higher returns and show empirical results comparing uniform, no replay, and prioritized strategies across multiple simulations. Our findings illuminate the trade-offs and interactions between exploration strategies and memory management in DQN training, offering practical recommendations for robust reinforcement learning in resource-constrained settings.</li>
</ul>

<h3>Title: Whisper Leak: a side-channel attack on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Geoff McDonald, Jonathan Bar Or</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03675">https://arxiv.org/abs/2511.03675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03675">https://arxiv.org/pdf/2511.03675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03675]] Whisper Leak: a side-channel attack on Large Language Models(https://arxiv.org/abs/2511.03675)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in sensitive domains including healthcare, legal services, and confidential communications, where privacy is paramount. This paper introduces Whisper Leak, a side-channel attack that infers user prompt topics from encrypted LLM traffic by analyzing packet size and timing patterns in streaming responses. Despite TLS encryption protecting content, these metadata patterns leak sufficient information to enable topic classification. We demonstrate the attack across 28 popular LLMs from major providers, achieving near-perfect classification (often >98% AUPRC) and high precision even at extreme class imbalance (10,000:1 noise-to-target ratio). For many models, we achieve 100% precision in identifying sensitive topics like "money laundering" while recovering 5-20% of target conversations. This industry-wide vulnerability poses significant risks for users under network surveillance by ISPs, governments, or local adversaries. We evaluate three mitigation strategies - random padding, token batching, and packet injection - finding that while each reduces attack effectiveness, none provides complete protection. Through responsible disclosure, we have collaborated with providers to implement initial countermeasures. Our findings underscore the need for LLM providers to address metadata leakage as AI systems handle increasingly sensitive information.</li>
</ul>

<h3>Title: Structured Matrix Scaling for Multi-Class Calibration</h3>
<ul>
<li><strong>Authors: </strong>Eugène Berta, David Holzmüller, Michael I. Jordan, Francis Bach</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03685">https://arxiv.org/abs/2511.03685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03685">https://arxiv.org/pdf/2511.03685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03685]] Structured Matrix Scaling for Multi-Class Calibration(https://arxiv.org/abs/2511.03685)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Post-hoc recalibration methods are widely used to ensure that classifiers provide faithful probability estimates. We argue that parametric recalibration functions based on logistic regression can be motivated from a simple theoretical setting for both binary and multiclass classification. This insight motivates the use of more expressive calibration methods beyond standard temperature scaling. For multi-class calibration however, a key challenge lies in the increasing number of parameters introduced by more complex models, often coupled with limited calibration data, which can lead to overfitting. Through extensive experiments, we demonstrate that the resulting bias-variance tradeoff can be effectively managed by structured regularization, robust preprocessing and efficient optimization. The resulting methods lead to substantial gains over existing logistic-based calibration techniques. We provide efficient and easy-to-use open-source implementations of our methods, making them an attractive alternative to common temperature, vector, and matrix scaling implementations.</li>
</ul>

<h3>Title: Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL</h3>
<ul>
<li><strong>Authors: </strong>Lipeng Zu, Hansong Zhou, Xiaonan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03695">https://arxiv.org/abs/2511.03695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03695">https://arxiv.org/pdf/2511.03695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03695]] Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL(https://arxiv.org/abs/2511.03695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) enables training from fixed data without online interaction, but policies learned offline often struggle when deployed in dynamic environments due to distributional shift and unreliable value estimates on unseen state-action pairs. We introduce Behavior-Adaptive Q-Learning (BAQ), a framework designed to enable a smooth and reliable transition from offline to online RL. The key idea is to leverage an implicit behavioral model derived from offline data to provide a behavior-consistency signal during online fine-tuning. BAQ incorporates a dual-objective loss that (i) aligns the online policy toward the offline behavior when uncertainty is high, and (ii) gradually relaxes this constraint as more confident online experience is accumulated. This adaptive mechanism reduces error propagation from out-of-distribution estimates, stabilizes early online updates, and accelerates adaptation to new scenarios. Across standard benchmarks, BAQ consistently outperforms prior offline-to-online RL approaches, achieving faster recovery, improved robustness, and higher overall performance. Our results demonstrate that implicit behavior adaptation is a principled and practical solution for reliable real-world policy deployment.</li>
</ul>

<h3>Title: AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing</h3>
<ul>
<li><strong>Authors: </strong>Mohsen Ahmadzadeh, Kaichang Chen, Georges Gielen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03697">https://arxiv.org/abs/2511.03697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03697">https://arxiv.org/pdf/2511.03697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03697]] AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing(https://arxiv.org/abs/2511.03697)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.</li>
</ul>

<h3>Title: Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Francesco Corso, Francesco Pierri, Gianmarco De Francisci Morales</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03699">https://arxiv.org/abs/2511.03699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03699">https://arxiv.org/pdf/2511.03699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03699]] Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models(https://arxiv.org/abs/2511.03699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we investigate whether Large Language Models (LLMs) exhibit conspiratorial tendencies, whether they display sociodemographic biases in this domain, and how easily they can be conditioned into adopting conspiratorial perspectives. Conspiracy beliefs play a central role in the spread of misinformation and in shaping distrust toward institutions, making them a critical testbed for evaluating the social fidelity of LLMs. LLMs are increasingly used as proxies for studying human behavior, yet little is known about whether they reproduce higher-order psychological constructs such as a conspiratorial mindset. To bridge this research gap, we administer validated psychometric surveys measuring conspiracy mindset to multiple models under different prompting and conditioning strategies. Our findings reveal that LLMs show partial agreement with elements of conspiracy belief, and conditioning with socio-demographic attributes produces uneven effects, exposing latent demographic biases. Moreover, targeted prompts can easily shift model responses toward conspiratorial directions, underscoring both the susceptibility of LLMs to manipulation and the potential risks of their deployment in sensitive contexts. These results highlight the importance of critically evaluating the psychological dimensions embedded in LLMs, both to advance computational social science and to inform possible mitigation strategies against harmful uses.</li>
</ul>

<h3>Title: Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Jongseo Lee, Wooil Lee, Gyeong-Moon Park, Seong Tae Kim, Jinwoo Choi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03725">https://arxiv.org/abs/2511.03725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03725">https://arxiv.org/pdf/2511.03725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03725]] Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition(https://arxiv.org/abs/2511.03725)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Effective explanations of video action recognition models should disentangle how movements unfold over time from the surrounding spatial context. However, existing methods based on saliency produce entangled explanations, making it unclear whether predictions rely on motion or spatial context. Language-based approaches offer structure but often fail to explain motions due to their tacit nature -- intuitively understood but difficult to verbalize. To address these challenges, we propose Disentangled Action aNd Context concept-based Explainable (DANCE) video action recognition, a framework that predicts actions through disentangled concept types: motion dynamics, objects, and scenes. We define motion dynamics concepts as human pose sequences. We employ a large language model to automatically extract object and scene concepts. Built on an ante-hoc concept bottleneck design, DANCE enforces prediction through these concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101 -- demonstrate that DANCE significantly improves explanation clarity with competitive performance. We validate the superior interpretability of DANCE through a user study. Experimental results also show that DANCE is beneficial for model debugging, editing, and failure analysis.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
