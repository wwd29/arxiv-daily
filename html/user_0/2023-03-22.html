<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: A Post-Quantum Key Agreement Protocol Based on a Modified Matrix-Power Function over a Rectangular Matrices Semiring. (arXiv:2303.11972v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11972">http://arxiv.org/abs/2303.11972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11972] A Post-Quantum Key Agreement Protocol Based on a Modified Matrix-Power Function over a Rectangular Matrices Semiring](http://arxiv.org/abs/2303.11972) #secure</code></li>
<li>Summary: <p>We present an improved post-quantum version of Sakalauskas matrix power
function key-agreement protocol, using rectangular matrices instead the
original square ones. Sakalauskas matrix power function is an efficient and
secure way to generate a shared secret key, and using rectangular matrices can
provide additional flexibility and security in some applications. This method
reduces the computational complexity by allowing smaller random integers
matrices while maintaining equal security. Another advantage of using the
rank-deficient rectangular matrices over key agreement protocols is that it
provides more protection against several linearization attacks.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Propagate And Calibrate: Real-time Passive Non-line-of-sight Tracking. (arXiv:2303.11791v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11791">http://arxiv.org/abs/2303.11791</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11791] Propagate And Calibrate: Real-time Passive Non-line-of-sight Tracking](http://arxiv.org/abs/2303.11791) #security</code></li>
<li>Summary: <p>Non-line-of-sight (NLOS) tracking has drawn increasing attention in recent
years, due to its ability to detect object motion out of sight. Most previous
works on NLOS tracking rely on active illumination, e.g., laser, and suffer
from high cost and elaborate experimental conditions. Besides, these techniques
are still far from practical application due to oversimplified settings. In
contrast, we propose a purely passive method to track a person walking in an
invisible room by only observing a relay wall, which is more in line with real
application scenarios, e.g., security. To excavate imperceptible changes in
videos of the relay wall, we introduce difference frames as an essential
carrier of temporal-local motion messages. In addition, we propose PAC-Net,
which consists of alternating propagation and calibration, making it capable of
leveraging both dynamic and static messages on a frame-level granularity. To
evaluate the proposed method, we build and publish the first dynamic passive
NLOS tracking dataset, NLOS-Track, which fills the vacuum of realistic NLOS
datasets. NLOS-Track contains thousands of NLOS video clips and corresponding
trajectories. Both real-shot and synthetic data are included.
</p></li>
</ul>

<h3>Title: TSNZeek: An Open-source Intrusion Detection System for IEEE 802.1 Time-sensitive Networking. (arXiv:2303.11492v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11492">http://arxiv.org/abs/2303.11492</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11492] TSNZeek: An Open-source Intrusion Detection System for IEEE 802](http://arxiv.org/abs/2303.11492) #security</code></li>
<li>Summary: <p>IEEE 802.1 Time-sensitive Networking~(TSN) standards are envisioned to
replace legacy network protocols in critical domains to ensure reliable and
deterministic communication over off-the-shelf Ethernet equipment. However,
they lack security countermeasures and can even impose new attack vectors that
may lead to hazardous consequences. This paper presents the first open-source
security monitoring and intrusion detection mechanism, TSNZeek, for IEEE 802.1
TSN protocols. We extend an existing monitoring tool, Zeek, with a new packet
parsing grammar to process TSN data traffic and a rule-based attack detection
engine for TSN-specific threats. We also discuss various security-related
configuration and design aspects for IEEE 802.1 TSN monitoring. Our experiments
show that TSNZeek causes only ~5% CPU overhead on top of Zeek and successfully
detects various threats in a real TSN testbed.
</p></li>
</ul>

<h3>Title: "I Want the Payment Process to be Cool'': Understanding How Interaction Factors into Security and Privacy Perception of Authentication in Virtual Reality. (arXiv:2303.11575v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11575">http://arxiv.org/abs/2303.11575</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11575] "I Want the Payment Process to be Cool'': Understanding How Interaction Factors into Security and Privacy Perception of Authentication in Virtual Reality](http://arxiv.org/abs/2303.11575) #security</code></li>
<li>Summary: <p>Users embrace the rapid development of virtual reality (VR) technology. We
are witnessing a widespread adoption of VR technology in more routine settings,
such as gaming, social interactions, shopping, and commerce. VR systems access
sensitive user data and assets when handling these routine activities,
including payment, which raises the need for user authentication in VR.
However, there is a limited understanding of how users perceive user
authentication in VR, in particular, how users' interaction experiences factor
into their perception of security and privacy. Our work adopts a ``technology
probe'' approach to understand this question. We design technology probes of
authentication in VR based on existing authentication interactions in both VR
and the physical world. Further, we embed these probes in the routine payment
of a VR game. Our qualitative analysis reveals that users face unique usability
challenges in VR authentication, e.g., in motion control. Such challenges also
hinder users from accessing security and privacy accurately in VR
authentication. Users' expectations for VR authentication mainly center on
improvements in interaction. However, their expectations could appear
nonspecific and conflicting. We provide recommendations to accommodate users'
expectations and resolve conflicts between usability and security.
</p></li>
</ul>

<h3>Title: Generative AI for Cyber Threat-Hunting in 6G-enabled IoT Networks. (arXiv:2303.11751v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11751">http://arxiv.org/abs/2303.11751</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11751] Generative AI for Cyber Threat-Hunting in 6G-enabled IoT Networks](http://arxiv.org/abs/2303.11751) #security</code></li>
<li>Summary: <p>The next generation of cellular technology, 6G, is being developed to enable
a wide range of new applications and services for the Internet of Things (IoT).
One of 6G's main advantages for IoT applications is its ability to support much
higher data rates and bandwidth as well as to support ultra-low latency.
However, with this increased connectivity will come to an increased risk of
cyber threats, as attackers will be able to exploit the large network of
connected devices. Generative Artificial Intelligence (AI) can be used to
detect and prevent cyber attacks by continuously learning and adapting to new
threats and vulnerabilities. In this paper, we discuss the use of generative AI
for cyber threat-hunting (CTH) in 6G-enabled IoT networks. Then, we propose a
new generative adversarial network (GAN) and Transformer-based model for CTH in
6G-enabled IoT Networks. The experimental analysis results with a new cyber
security dataset demonstrate that the Transformer-based security model for CTH
can detect IoT attacks with a high overall accuracy of 95%. We examine the
challenges and opportunities and conclude by highlighting the potential of
generative AI in enhancing the security of 6G-enabled IoT networks and call for
further research to be conducted in this area.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Boundary Unlearning. (arXiv:2303.11570v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11570">http://arxiv.org/abs/2303.11570</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11570] Boundary Unlearning](http://arxiv.org/abs/2303.11570) #privacy</code></li>
<li>Summary: <p>The practical needs of the ``right to be forgotten'' and poisoned data
removal call for efficient \textit{machine unlearning} techniques, which enable
machine learning models to unlearn, or to forget a fraction of training data
and its lineage. Recent studies on machine unlearning for deep neural networks
(DNNs) attempt to destroy the influence of the forgetting data by scrubbing the
model parameters. However, it is prohibitively expensive due to the large
dimension of the parameter space. In this paper, we refocus our attention from
the parameter space to the decision space of the DNN model, and propose
Boundary Unlearning, a rapid yet effective way to unlearn an entire class from
a trained DNN model. The key idea is to shift the decision boundary of the
original DNN model to imitate the decision behavior of the model retrained from
scratch. We develop two novel boundary shift methods, namely Boundary Shrink
and Boundary Expanding, both of which can rapidly achieve the utility and
privacy guarantees. We extensively evaluate Boundary Unlearning on CIFAR-10 and
Vggface2 datasets, and the results show that Boundary Unlearning can
effectively forget the forgetting class on image classification and face
recognition tasks, with an expected speed-up of $17\times$ and $19\times$,
respectively, compared with retraining from the scratch.
</p></li>
</ul>

<h3>Title: Model Robustness Meets Data Privacy: Adversarial Robustness Distillation without Original Data. (arXiv:2303.11611v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11611">http://arxiv.org/abs/2303.11611</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11611] Model Robustness Meets Data Privacy: Adversarial Robustness Distillation without Original Data](http://arxiv.org/abs/2303.11611) #privacy</code></li>
<li>Summary: <p>Large-scale deep learning models have achieved great performance based on
large-scale datasets. Moreover, the existing Adversarial Training (AT) can
further improve the robustness of these large models. However, these large
models are difficult to deploy to mobile devices, and the effect of AT on small
models is very limited. In addition, the data privacy issue (e.g., face data
and diagnosis report) may lead to the original data being unavailable, which
relies on data-free knowledge distillation technology for training. To tackle
these issues, we propose a challenging novel task called Data-Free Adversarial
Robustness Distillation (DFARD), which tries to train small, easily deployable,
robust models without relying on the original data. We find the combination of
existing techniques resulted in degraded model performance due to fixed
training objectives and scarce information content. First, an interactive
strategy is designed for more efficient knowledge transfer to find more
suitable training objectives at each epoch. Then, we explore an adaptive
balance method to suppress information loss and obtain more data information
than previous methods. Experiments show that our method improves baseline
performance on the novel task.
</p></li>
</ul>

<h3>Title: Information-containing Adversarial Perturbation for Combating Facial Manipulation Systems. (arXiv:2303.11625v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11625">http://arxiv.org/abs/2303.11625</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11625] Information-containing Adversarial Perturbation for Combating Facial Manipulation Systems](http://arxiv.org/abs/2303.11625) #privacy</code></li>
<li>Summary: <p>With the development of deep learning technology, the facial manipulation
system has become powerful and easy to use. Such systems can modify the
attributes of the given facial images, such as hair color, gender, and age.
Malicious applications of such systems pose a serious threat to individuals'
privacy and reputation. Existing studies have proposed various approaches to
protect images against facial manipulations. Passive defense methods aim to
detect whether the face is real or fake, which works for posterior forensics
but can not prevent malicious manipulation. Initiative defense methods protect
images upfront by injecting adversarial perturbations into images to disrupt
facial manipulation systems but can not identify whether the image is fake. To
address the limitation of existing methods, we propose a novel two-tier
protection method named Information-containing Adversarial Perturbation (IAP),
which provides more comprehensive protection for {facial images}. We use an
encoder to map a facial image and its identity message to a cross-model
adversarial example which can disrupt multiple facial manipulation systems to
achieve initiative protection. Recovering the message in adversarial examples
with a decoder serves passive protection, contributing to provenance tracking
and fake image detection. We introduce a feature-level correlation measurement
that is more suitable to measure the difference between the facial images than
the commonly used mean squared error. Moreover, we propose a spectral diffusion
method to spread messages to different frequency channels, thereby improving
the robustness of the message against facial manipulation. Extensive
experimental results demonstrate that our proposed IAP can recover the messages
from the adversarial examples with high average accuracy and effectively
disrupt the facial manipulation systems.
</p></li>
</ul>

<h3>Title: Solving Oscillation Problem in Post-Training Quantization Through a Theoretical Perspective. (arXiv:2303.11906v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11906">http://arxiv.org/abs/2303.11906</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11906] Solving Oscillation Problem in Post-Training Quantization Through a Theoretical Perspective](http://arxiv.org/abs/2303.11906) #privacy</code></li>
<li>Summary: <p>Post-training quantization (PTQ) is widely regarded as one of the most
efficient compression methods practically, benefitting from its data privacy
and low computation costs. We argue that an overlooked problem of oscillation
is in the PTQ methods. In this paper, we take the initiative to explore and
present a theoretical proof to explain why such a problem is essential in PTQ.
And then, we try to solve this problem by introducing a principled and
generalized framework theoretically. In particular, we first formulate the
oscillation in PTQ and prove the problem is caused by the difference in module
capacity. To this end, we define the module capacity (ModCap) under
data-dependent and data-free scenarios, where the differentials between
adjacent modules are used to measure the degree of oscillation. The problem is
then solved by selecting top-k differentials, in which the corresponding
modules are jointly optimized and quantized. Extensive experiments demonstrate
that our method successfully reduces the performance drop and is generalized to
different neural networks and PTQ methods. For example, with 2/4 bit ResNet-50
quantization, our method surpasses the previous state-of-the-art method by
1.9%. It becomes more significant on small model quantization, e.g. surpasses
BRECQ method by 6.61% on MobileNetV2*0.5.
</p></li>
</ul>

<h3>Title: What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring. (arXiv:2303.11341v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11341">http://arxiv.org/abs/2303.11341</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11341] What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring](http://arxiv.org/abs/2303.11341) #privacy</code></li>
<li>Summary: <p>As advanced machine learning systems' capabilities begin to play a
significant role in geopolitics and societal order, it may become imperative
that (1) governments be able to enforce rules on the development of advanced ML
systems within their borders, and (2) countries be able to verify each other's
compliance with potential future international agreements on advanced ML
development. This work analyzes one mechanism to achieve this, by monitoring
the computing hardware used for large-scale NN training. The framework's
primary goal is to provide governments high confidence that no actor uses large
quantities of specialized ML chips to execute a training run in violation of
agreed rules. At the same time, the system does not curtail the use of consumer
computing devices, and maintains the privacy and confidentiality of ML
practitioners' models, data, and hyperparameters. The system consists of
interventions at three stages: (1) using on-chip firmware to occasionally save
snapshots of the the neural network weights stored in device memory, in a form
that an inspector could later retrieve; (2) saving sufficient information about
each training run to prove to inspectors the details of the training run that
had resulted in the snapshotted weights; and (3) monitoring the chip supply
chain to ensure that no actor can avoid discovery by amassing a large quantity
of un-tracked chips. The proposed design decomposes the ML training rule
verification problem into a series of narrow technical challenges, including a
new variant of the Proof-of-Learning problem [Jia et al. '21].
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Protective Self-Adaptive Pruning to Better Compress DNNs. (arXiv:2303.11881v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11881">http://arxiv.org/abs/2303.11881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11881] Protective Self-Adaptive Pruning to Better Compress DNNs](http://arxiv.org/abs/2303.11881) #protect</code></li>
<li>Summary: <p>Adaptive network pruning approach has recently drawn significant attention
due to its excellent capability to identify the importance and redundancy of
layers and filters and customize a suitable pruning solution. However, it
remains unsatisfactory since current adaptive pruning methods rely mostly on an
additional monitor to score layer and filter importance, and thus faces high
complexity and weak interpretability. To tackle these issues, we have deeply
researched the weight reconstruction process in iterative prune-train process
and propose a Protective Self-Adaptive Pruning (PSAP) method. First of all,
PSAP can utilize its own information, weight sparsity ratio, to adaptively
adjust pruning ratio of layers before each pruning step. Moreover, we propose a
protective reconstruction mechanism to prevent important filters from being
pruned through supervising gradients and to avoid unrecoverable information
loss as well. Our PSAP is handy and explicit because it merely depends on
weights and gradients of model itself, instead of requiring an additional
monitor as in early works. Experiments on ImageNet and CIFAR-10 also
demonstrate its superiority to current works in both accuracy and compression
ratio, especially for compressing with a high ratio or pruning from scratch.
</p></li>
</ul>

<h3>Title: Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking. (arXiv:2303.11470v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11470">http://arxiv.org/abs/2303.11470</a></li>
<li>Code URL: <a href="https://github.com/anonymous-authors-repo/watermark_dataset">https://github.com/anonymous-authors-repo/watermark_dataset</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11470] Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking](http://arxiv.org/abs/2303.11470) #protect</code></li>
<li>Summary: <p>The huge supporting training data on the Internet has been a key factor in
the success of deep learning models. However, this abundance of
public-available data also raises concerns about the unauthorized exploitation
of datasets for commercial purposes, which is forbidden by dataset licenses. In
this paper, we propose a backdoor-based watermarking approach that serves as a
general framework for safeguarding public-available data. By inserting a small
number of watermarking samples into the dataset, our approach enables the
learning model to implicitly learn a secret function set by defenders. This
hidden function can then be used as a watermark to track down third-party
models that use the dataset illegally. Unfortunately, existing backdoor
insertion methods often entail adding arbitrary and mislabeled data to the
training set, leading to a significant drop in performance and easy detection
by anomaly detection algorithms. To overcome this challenge, we introduce a
clean-label backdoor watermarking framework that uses imperceptible
perturbations to replace mislabeled samples. As a result, the watermarking
samples remain consistent with the original labels, making them difficult to
detect. Our experiments on text, image, and audio datasets demonstrate that the
proposed framework effectively safeguards datasets with minimal impact on
original task performance. We also show that adding just 1% of watermarking
samples can inject a traceable watermarking function and that our watermarking
samples are stealthy and look benign upon visual inspection.
</p></li>
</ul>

<h3>Title: Effective Ambiguity Attack Against Passport-based DNN Intellectual Property Protection Schemes through Fully Connected Layer Substitution. (arXiv:2303.11595v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11595">http://arxiv.org/abs/2303.11595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11595] Effective Ambiguity Attack Against Passport-based DNN Intellectual Property Protection Schemes through Fully Connected Layer Substitution](http://arxiv.org/abs/2303.11595) #protect</code></li>
<li>Summary: <p>Since training a deep neural network (DNN) is costly, the well-trained deep
models can be regarded as valuable intellectual property (IP) assets. The IP
protection associated with deep models has been receiving increasing attentions
in recent years. Passport-based method, which replaces normalization layers
with passport layers, has been one of the few protection solutions that are
claimed to be secure against advanced attacks. In this work, we tackle the
issue of evaluating the security of passport-based IP protection methods. We
propose a novel and effective ambiguity attack against passport-based method,
capable of successfully forging multiple valid passports with a small training
dataset. This is accomplished by inserting a specially designed accessory block
ahead of the passport parameters. Using less than 10% of training data, with
the forged passport, the model exhibits almost indistinguishable performance
difference (less than 2%) compared with that of the authorized passport. In
addition, it is shown that our attack strategy can be readily generalized to
attack other IP protection methods based on watermark embedding. Directions for
potential remedy solutions are also given.
</p></li>
</ul>

<h3>Title: Assessor-Guided Learning for Continual Environments. (arXiv:2303.11624v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11624">http://arxiv.org/abs/2303.11624</a></li>
<li>Code URL: <a href="https://github.com/anwarmaxsum/agla">https://github.com/anwarmaxsum/agla</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11624] Assessor-Guided Learning for Continual Environments](http://arxiv.org/abs/2303.11624) #protect</code></li>
<li>Summary: <p>This paper proposes an assessor-guided learning strategy for continual
learning where an assessor guides the learning process of a base learner by
controlling the direction and pace of the learning process thus allowing an
efficient learning of new environments while protecting against the
catastrophic interference problem. The assessor is trained in a meta-learning
manner with a meta-objective to boost the learning process of the base learner.
It performs a soft-weighting mechanism of every sample accepting positive
samples while rejecting negative samples. The training objective of a base
learner is to minimize a meta-weighted combination of the cross entropy loss
function, the dark experience replay (DER) loss function and the knowledge
distillation loss function whose interactions are controlled in such a way to
attain an improved performance. A compensated over-sampling (COS) strategy is
developed to overcome the class imbalanced problem of the episodic memory due
to limited memory budgets. Our approach, Assessor-Guided Learning Approach
(AGLA), has been evaluated in the class-incremental and task-incremental
learning problems. AGLA achieves improved performances compared to its
competitors while the theoretical analysis of the COS strategy is offered.
Source codes of AGLA, baseline algorithms and experimental logs are shared
publicly in \url{https://github.com/anwarmaxsum/AGLA} for further study.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Efficient Decision-based Black-box Patch Attacks on Video Recognition. (arXiv:2303.11917v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11917">http://arxiv.org/abs/2303.11917</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11917] Efficient Decision-based Black-box Patch Attacks on Video Recognition](http://arxiv.org/abs/2303.11917) #attack</code></li>
<li>Summary: <p>Although Deep Neural Networks (DNNs) have demonstrated excellent performance,
they are vulnerable to adversarial patches that introduce perceptible and
localized perturbations to the input. Generating adversarial patches on images
has received much attention, while adversarial patches on videos have not been
well investigated. Further, decision-based attacks, where attackers only access
the predicted hard labels by querying threat models, have not been well
explored on video models either, even if they are practical in real-world video
recognition scenes. The absence of such studies leads to a huge gap in the
robustness assessment for video models. To bridge this gap, this work first
explores decision-based patch attacks on video models. We analyze that the huge
parameter space brought by videos and the minimal information returned by
decision-based models both greatly increase the attack difficulty and query
burden. To achieve a query-efficient attack, we propose a spatial-temporal
differential evolution (STDE) framework. First, STDE introduces target videos
as patch textures and only adds patches on keyframes that are adaptively
selected by temporal difference. Second, STDE takes minimizing the patch area
as the optimization objective and adopts spatialtemporal mutation and crossover
to search for the global optimum without falling into the local optimum.
Experiments show STDE has demonstrated state-of-the-art performance in terms of
threat, efficiency and imperceptibility. Hence, STDE has the potential to be a
powerful tool for evaluating the robustness of video recognition models.
</p></li>
</ul>

<h3>Title: Influencer Backdoor Attack on Semantic Segmentation. (arXiv:2303.12054v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12054">http://arxiv.org/abs/2303.12054</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12054] Influencer Backdoor Attack on Semantic Segmentation](http://arxiv.org/abs/2303.12054) #attack</code></li>
<li>Summary: <p>When a small number of poisoned samples are injected into the training
dataset of a deep neural network, the network can be induced to exhibit
malicious behavior during inferences, which poses potential threats to
real-world applications. While they have been intensively studied in
classification, backdoor attacks on semantic segmentation have been largely
overlooked. Unlike classification, semantic segmentation aims to classify every
pixel within a given image. In this work, we explore backdoor attacks on
segmentation models to misclassify all pixels of a victim class by injecting a
specific trigger on non-victim pixels during inferences, which is dubbed
Influencer Backdoor Attack (IBA). IBA is expected to maintain the
classification accuracy of non-victim pixels and misleads classifications of
all victim pixels in every single inference. Specifically, we consider two
types of IBA scenarios, i.e., 1) Free-position IBA: the trigger can be
positioned freely except for pixels of the victim class, and 2) Long-distance
IBA: the trigger can only be positioned somewhere far from victim pixels, given
the possible practical constraint. Based on the context aggregation ability of
segmentation models, we propose techniques to improve IBA for the scenarios.
Concretely, for free-position IBA, we propose a simple, yet effective Nearest
Neighbor trigger injection strategy for poisoned sample creation. For
long-distance IBA, we propose a novel Pixel Random Labeling strategy. Our
extensive experiments reveal that current segmentation models do suffer from
backdoor attacks, and verify that our proposed techniques can further increase
attack performance.
</p></li>
</ul>

<h3>Title: Manipulating Transfer Learning for Property Inference. (arXiv:2303.11643v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11643">http://arxiv.org/abs/2303.11643</a></li>
<li>Code URL: <a href="https://github.com/yulongt23/transfer-inference">https://github.com/yulongt23/transfer-inference</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11643] Manipulating Transfer Learning for Property Inference](http://arxiv.org/abs/2303.11643) #attack</code></li>
<li>Summary: <p>Transfer learning is a popular method for tuning pretrained (upstream) models
for different downstream tasks using limited data and computational resources.
We study how an adversary with control over an upstream model used in transfer
learning can conduct property inference attacks on a victim's tuned downstream
model. For example, to infer the presence of images of a specific individual in
the downstream training set. We demonstrate attacks in which an adversary can
manipulate the upstream model to conduct highly effective and specific property
inference attacks (AUC score $> 0.9$), without incurring significant
performance loss on the main task. The main idea of the manipulation is to make
the upstream model generate activations (intermediate features) with different
distributions for samples with and without a target property, thus enabling the
adversary to distinguish easily between downstream models trained with and
without training examples that have the target property. Our code is available
at https://github.com/yulongt23/Transfer-Inference.
</p></li>
</ul>

<h3>Title: Poisoning Attacks in Federated Edge Learning for Digital Twin 6G-enabled IoTs: An Anticipatory Study. (arXiv:2303.11745v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11745">http://arxiv.org/abs/2303.11745</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11745] Poisoning Attacks in Federated Edge Learning for Digital Twin 6G-enabled IoTs: An Anticipatory Study](http://arxiv.org/abs/2303.11745) #attack</code></li>
<li>Summary: <p>Federated edge learning can be essential in supporting privacy-preserving,
artificial intelligence (AI)-enabled activities in digital twin 6G-enabled
Internet of Things (IoT) environments. However, we need to also consider the
potential of attacks targeting the underlying AI systems (e.g., adversaries
seek to corrupt data on the IoT devices during local updates or corrupt the
model updates); hence, in this article, we propose an anticipatory study for
poisoning attacks in federated edge learning for digital twin 6G-enabled IoT
environments. Specifically, we study the influence of adversaries on the
training and development of federated learning models in digital twin
6G-enabled IoT environments. We demonstrate that attackers can carry out
poisoning attacks in two different learning settings, namely: centralized
learning and federated learning, and successful attacks can severely reduce the
model's accuracy. We comprehensively evaluate the attacks on a new cyber
security dataset designed for IoT applications with three deep neural networks
under the non-independent and identically distributed (Non-IID) data and the
independent and identically distributed (IID) data. The poisoning attacks, on
an attack classification problem, can lead to a decrease in accuracy from
94.93% to 85.98% with IID data and from 94.18% to 30.04% with Non-IID.
</p></li>
</ul>

<h3>Title: Real-Time Cyberattack Detection with Offline and Online Learning. (arXiv:2303.11760v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11760">http://arxiv.org/abs/2303.11760</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11760] Real-Time Cyberattack Detection with Offline and Online Learning](http://arxiv.org/abs/2303.11760) #attack</code></li>
<li>Summary: <p>This paper presents several novel algorithms for real-time cyberattack
detection using the Auto-Associative Deep Random Neural Network, which were
developed in the HORIZON 2020 IoTAC Project. Some of these algorithms require
offline learning, while others require the algorithm to learn during its normal
operation while it is also testing the flow of incoming traffic to detect
possible attacks. Most of the methods we present are designed to be used at a
single node, while one specific method collects data from multiple network
ports to detect and monitor the spread of a Botnet. The evaluation of the
accuracy of all the methods is carried out with real attack traces. These novel
methods are also compared with other state-of-the-art approaches, showing that
they offer better or equal performance, at lower computational learning and
shorter detection times as compared to the existing approaches.
</p></li>
</ul>

<h3>Title: GNN-Ensemble: Towards Random Decision Graph Neural Networks. (arXiv:2303.11376v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11376">http://arxiv.org/abs/2303.11376</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11376] GNN-Ensemble: Towards Random Decision Graph Neural Networks](http://arxiv.org/abs/2303.11376) #attack</code></li>
<li>Summary: <p>Graph Neural Networks (GNNs) have enjoyed wide spread applications in
graph-structured data. However, existing graph based applications commonly lack
annotated data. GNNs are required to learn latent patterns from a limited
amount of training data to perform inferences on a vast amount of test data.
The increased complexity of GNNs, as well as a single point of model parameter
initialization, usually lead to overfitting and sub-optimal performance. In
addition, it is known that GNNs are vulnerable to adversarial attacks. In this
paper, we push one step forward on the ensemble learning of GNNs with improved
accuracy, generalization, and adversarial robustness. Following the principles
of stochastic modeling, we propose a new method called GNN-Ensemble to
construct an ensemble of random decision graph neural networks whose capacity
can be arbitrarily expanded for improvement in performance. The essence of the
method is to build multiple GNNs in randomly selected substructures in the
topological space and subfeatures in the feature space, and then combine them
for final decision making. These GNNs in different substructure and subfeature
spaces generalize their classification in complementary ways. Consequently,
their combined classification performance can be improved and overfitting on
the training data can be effectively reduced. In the meantime, we show that
GNN-Ensemble can significantly improve the adversarial robustness against
attacks on GNNs.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: DehazeNeRF: Multiple Image Haze Removal and 3D Shape Reconstruction using Neural Radiance Fields. (arXiv:2303.11364v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11364">http://arxiv.org/abs/2303.11364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11364] DehazeNeRF: Multiple Image Haze Removal and 3D Shape Reconstruction using Neural Radiance Fields](http://arxiv.org/abs/2303.11364) #robust</code></li>
<li>Summary: <p>Neural radiance fields (NeRFs) have demonstrated state-of-the-art performance
for 3D computer vision tasks, including novel view synthesis and 3D shape
reconstruction. However, these methods fail in adverse weather conditions. To
address this challenge, we introduce DehazeNeRF as a framework that robustly
operates in hazy conditions. DehazeNeRF extends the volume rendering equation
by adding physically realistic terms that model atmospheric scattering. By
parameterizing these terms using suitable networks that match the physical
properties, we introduce effective inductive biases, which, together with the
proposed regularizations, allow DehazeNeRF to demonstrate successful multi-view
haze removal, novel view synthesis, and 3D shape reconstruction where existing
approaches fail.
</p></li>
</ul>

<h3>Title: EPiC: Ensemble of Partial Point Clouds for Robust Classification. (arXiv:2303.11419v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11419">http://arxiv.org/abs/2303.11419</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11419] EPiC: Ensemble of Partial Point Clouds for Robust Classification](http://arxiv.org/abs/2303.11419) #robust</code></li>
<li>Summary: <p>Robust point cloud classification is crucial for real-world applications, as
consumer-type 3D sensors often yield partial and noisy data, degraded by
various artifacts. In this work we propose a general ensemble framework, based
on partial point cloud sampling. Each ensemble member is exposed to only
partial input data. Three sampling strategies are used jointly, two local ones,
based on patches and curves, and a global one of random sampling. We
demonstrate the robustness of our method to various local and global
degradations. We show that our framework significantly improves the robustness
of top classification netowrks by a large margin. Our experimental setting uses
the recently introduced ModelNet-C database by Ren et al.[24], where we reach
SOTA both on unaugmented and on augmented data. Our unaugmented mean Corruption
Error (mCE) is 0.64 (current SOTA is 0.86) and 0.50 for augmented data (current
SOTA is 0.57). We analyze and explain these remarkable results through
diversity analysis.
</p></li>
</ul>

<h3>Title: Boosting Verified Training for Robust Image Classifications via Abstraction. (arXiv:2303.11552v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11552">http://arxiv.org/abs/2303.11552</a></li>
<li>Code URL: <a href="https://github.com/zhangzhaodi233/abscert">https://github.com/zhangzhaodi233/abscert</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11552] Boosting Verified Training for Robust Image Classifications via Abstraction](http://arxiv.org/abs/2303.11552) #robust</code></li>
<li>Summary: <p>This paper proposes a novel, abstraction-based, certified training method for
robust image classifiers. Via abstraction, all perturbed images are mapped into
intervals before feeding into neural networks for training. By training on
intervals, all the perturbed images that are mapped to the same interval are
classified as the same label, rendering the variance of training sets to be
small and the loss landscape of the models to be smooth. Consequently, our
approach significantly improves the robustness of trained models. For the
abstraction, our training method also enables a sound and complete black-box
verification approach, which is orthogonal and scalable to arbitrary types of
neural networks regardless of their sizes and architectures. We evaluate our
method on a wide range of benchmarks in different scales. The experimental
results show that our method outperforms state of the art by (i) reducing the
verified errors of trained models up to 95.64%; (ii) totally achieving up to
602.50x speedup; and (iii) scaling up to larger models with up to 138 million
trainable parameters. The demo is available at
https://github.com/zhangzhaodi233/ABSCERT.git.
</p></li>
</ul>

<h3>Title: Smart-Tree: Neural Medial Axis Approximation of Point Clouds for 3D Tree Skeletonization. (arXiv:2303.11560v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11560">http://arxiv.org/abs/2303.11560</a></li>
<li>Code URL: <a href="https://github.com/uc-vision/synthetic-trees">https://github.com/uc-vision/synthetic-trees</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11560] Smart-Tree: Neural Medial Axis Approximation of Point Clouds for 3D Tree Skeletonization](http://arxiv.org/abs/2303.11560) #robust</code></li>
<li>Summary: <p>In this paper, we present Smart-Tree, a supervised method for approximating
the medial axes of branch skeletons from a tree's point cloud. A sparse voxel
convolutional neural network extracts each input point's radius and direction
towards the medial axis. A greedy algorithm performs robust skeletonization
using the estimated medial axis. The proposed method provides robustness to
complex tree structures and improves fidelity when dealing with
self-occlusions, complex geometry, touching branches, and varying point
densities. We train and test the method using a multi-species synthetic tree
data set and perform qualitative analysis on a real-life tree point cloud.
Experimentation with synthetic and real-world datasets demonstrates the
robustness of our approach over the current state-of-the-art method. Further
research will focus on training the method on a broader range of tree species
and improving robustness to point cloud gaps. The details to obtain the dataset
are at https://github.com/uc-vision/synthetic-trees.
</p></li>
</ul>

<h3>Title: Robust Table Structure Recognition with Dynamic Queries Enhanced Detection Transformer. (arXiv:2303.11615v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11615">http://arxiv.org/abs/2303.11615</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11615] Robust Table Structure Recognition with Dynamic Queries Enhanced Detection Transformer](http://arxiv.org/abs/2303.11615) #robust</code></li>
<li>Summary: <p>We present a new table structure recognition (TSR) approach, called
TSRFormer, to robustly recognizing the structures of complex tables with
geometrical distortions from various table images. Unlike previous methods, we
formulate table separation line prediction as a line regression problem instead
of an image segmentation problem and propose a new two-stage dynamic queries
enhanced DETR based separation line regression approach, named DQ-DETR, to
predict separation lines from table images directly. Compared to Vallina DETR,
we propose three improvements in DQ-DETR to make the two-stage DETR framework
work efficiently and effectively for the separation line prediction task: 1) A
new query design, named Dynamic Query, to decouple single line query into
separable point queries which could intuitively improve the localization
accuracy for regression tasks; 2) A dynamic queries based progressive line
regression approach to progressively regressing points on the line which
further enhances localization accuracy for distorted tables; 3) A
prior-enhanced matching strategy to solve the slow convergence issue of DETR.
After separation line prediction, a simple relation network based cell merging
module is used to recover spanning cells. With these new techniques, our
TSRFormer achieves state-of-the-art performance on several benchmark datasets,
including SciTSR, PubTabNet, WTW and FinTabNet. Furthermore, we have validated
the robustness and high localization accuracy of our approach to tables with
complex structures, borderless cells, large blank spaces, empty or spanning
cells as well as distorted or even curved shapes on a more challenging
real-world in-house dataset.
</p></li>
</ul>

<h3>Title: Visibility Constrained Wide-band Illumination Spectrum Design for Seeing-in-the-Dark. (arXiv:2303.11642v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11642">http://arxiv.org/abs/2303.11642</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11642] Visibility Constrained Wide-band Illumination Spectrum Design for Seeing-in-the-Dark](http://arxiv.org/abs/2303.11642) #robust</code></li>
<li>Summary: <p>Seeing-in-the-dark is one of the most important and challenging computer
vision tasks due to its wide applications and extreme complexities of
in-the-wild scenarios. Existing arts can be mainly divided into two threads: 1)
RGB-dependent methods restore information using degraded RGB inputs only (\eg,
low-light enhancement), 2) RGB-independent methods translate images captured
under auxiliary near-infrared (NIR) illuminants into RGB domain (\eg, NIR2RGB
translation). The latter is very attractive since it works in complete darkness
and the illuminants are visually friendly to naked eyes, but tends to be
unstable due to its intrinsic ambiguities. In this paper, we try to robustify
NIR2RGB translation by designing the optimal spectrum of auxiliary illumination
in the wide-band VIS-NIR range, while keeping visual friendliness. Our core
idea is to quantify the visibility constraint implied by the human vision
system and incorporate it into the design pipeline. By modeling the formation
process of images in the VIS-NIR range, the optimal multiplexing of a wide
range of LEDs is automatically designed in a fully differentiable manner,
within the feasible region defined by the visibility constraint. We also
collect a substantially expanded VIS-NIR hyperspectral image dataset for
experiments by using a customized 50-band filter wheel. Experimental results
show that the task can be significantly improved by using the optimized
wide-band illumination than using NIR only. Codes Available:
https://github.com/MyNiuuu/VCSD.
</p></li>
</ul>

<h3>Title: Implicit Neural Representation for Cooperative Low-light Image Enhancement. (arXiv:2303.11722v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11722">http://arxiv.org/abs/2303.11722</a></li>
<li>Code URL: <a href="https://github.com/ysz2022/nerco">https://github.com/ysz2022/nerco</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11722] Implicit Neural Representation for Cooperative Low-light Image Enhancement](http://arxiv.org/abs/2303.11722) #robust</code></li>
<li>Summary: <p>The following three factors restrict the application of existing low-light
image enhancement methods: unpredictable brightness degradation and noise,
inherent gap between metric-favorable and visual-friendly versions, and the
limited paired training data. To address these limitations, we propose an
implicit Neural Representation method for Cooperative low-light image
enhancement, dubbed NeRCo. It robustly recovers perceptual-friendly results in
an unsupervised manner. Concretely, NeRCo unifies the diverse degradation
factors of real-world scenes with a controllable fitting function, leading to
better robustness. In addition, for the output results, we introduce
semantic-orientated supervision with priors from the pre-trained
vision-language model. Instead of merely following reference images, it
encourages results to meet subjective expectations, finding more
visual-friendly solutions. Further, to ease the reliance on paired data and
reduce solution space, we develop a dual-closed-loop constrained enhancement
module. It is trained cooperatively with other affiliated modules in a
self-supervised manner. Finally, extensive experiments demonstrate the
robustness and superior effectiveness of our proposed NeRCo. Our code is
available at https://github.com/Ysz2022/NeRCo.
</p></li>
</ul>

<h3>Title: OTJR: Optimal Transport Meets Optimal Jacobian Regularization for Adversarial Robustness. (arXiv:2303.11793v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11793">http://arxiv.org/abs/2303.11793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11793] OTJR: Optimal Transport Meets Optimal Jacobian Regularization for Adversarial Robustness](http://arxiv.org/abs/2303.11793) #robust</code></li>
<li>Summary: <p>Deep neural networks are widely recognized as being vulnerable to adversarial
perturbation. To overcome this challenge, developing a robust classifier is
crucial. So far, two well-known defenses have been adopted to improve the
learning of robust classifiers, namely adversarial training (AT) and Jacobian
regularization. However, each approach behaves differently against adversarial
perturbations. First, our work carefully analyzes and characterizes these two
schools of approaches, both theoretically and empirically, to demonstrate how
each approach impacts the robust learning of a classifier. Next, we propose our
novel Optimal Transport with Jacobian regularization method, dubbed OTJR,
jointly incorporating the input-output Jacobian regularization into the AT by
leveraging the optimal transport theory. In particular, we employ the Sliced
Wasserstein (SW) distance that can efficiently push the adversarial samples'
representations closer to those of clean samples, regardless of the number of
classes within the dataset. The SW distance provides the adversarial samples'
movement directions, which are much more informative and powerful for the
Jacobian regularization. Our extensive experiments demonstrate the
effectiveness of our proposed method, which jointly incorporates Jacobian
regularization into AT. Furthermore, we demonstrate that our proposed method
consistently enhances the model's robustness with CIFAR-100 dataset under
various adversarial attack settings, achieving up to 28.49% under AutoAttack.
</p></li>
</ul>

<h3>Title: Recursive Euclidean Distance Based Robust Aggregation Technique For Federated Learning. (arXiv:2303.11337v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11337">http://arxiv.org/abs/2303.11337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11337] Recursive Euclidean Distance Based Robust Aggregation Technique For Federated Learning](http://arxiv.org/abs/2303.11337) #robust</code></li>
<li>Summary: <p>Federated learning has gained popularity as a solution to data availability
and privacy challenges in machine learning. However, the aggregation process of
local model updates to obtain a global model in federated learning is
susceptible to malicious attacks, such as backdoor poisoning, label-flipping,
and membership inference. Malicious users aim to sabotage the collaborative
learning process by training the local model with malicious data. In this
paper, we propose a novel robust aggregation approach based on recursive
Euclidean distance calculation. Our approach measures the distance of the local
models from the previous global model and assigns weights accordingly. Local
models far away from the global model are assigned smaller weights to minimize
the data poisoning effect during aggregation. Our experiments demonstrate that
the proposed algorithm outperforms state-of-the-art algorithms by at least
$5\%$ in accuracy while reducing time complexity by less than $55\%$. Our
contribution is significant as it addresses the critical issue of malicious
attacks in federated learning while improving the accuracy of the global model.
</p></li>
</ul>

<h3>Title: Dynamic-Aware Loss for Learning with Label Noise. (arXiv:2303.11562v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11562">http://arxiv.org/abs/2303.11562</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11562] Dynamic-Aware Loss for Learning with Label Noise](http://arxiv.org/abs/2303.11562) #robust</code></li>
<li>Summary: <p>Label noise poses a serious threat to deep neural networks (DNNs). Employing
robust loss function which reconciles fitting ability with robustness is a
simple but effective strategy to handle this problem. However, the widely-used
static trade-off between these two factors contradicts the dynamic nature of
DNNs learning with label noise, leading to inferior performance. Therefore, we
propose a dynamics-aware loss (DAL) to solve this problem. Considering that
DNNs tend to first learn generalized patterns, then gradually overfit label
noise, DAL strengthens the fitting ability initially, then gradually increases
the weight of robustness. Moreover, at the later stage, we let DNNs put more
emphasis on easy examples which are more likely to be correctly labeled than
hard ones and introduce a bootstrapping term to further reduce the negative
impact of label noise. Both the detailed theoretical analyses and extensive
experimental results demonstrate the superiority of our method.
</p></li>
</ul>

<h3>Title: Skeleton Regression: A Graph-Based Approach to Estimation with Manifold Structure. (arXiv:2303.11786v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11786">http://arxiv.org/abs/2303.11786</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11786] Skeleton Regression: A Graph-Based Approach to Estimation with Manifold Structure](http://arxiv.org/abs/2303.11786) #robust</code></li>
<li>Summary: <p>We introduce a new regression framework designed to deal with large-scale,
complex data that lies around a low-dimensional manifold. Our approach first
constructs a graph representation, referred to as the skeleton, to capture the
underlying geometric structure. We then define metrics on the skeleton graph
and apply nonparametric regression techniques, along with feature
transformations based on the graph, to estimate the regression function. In
addition to the included nonparametric methods, we also discuss the limitations
of some nonparametric regressors with respect to the general metric space such
as the skeleton graph. The proposed regression framework allows us to bypass
the curse of dimensionality and provides additional advantages that it can
handle the union of multiple manifolds and is robust to additive noise and
noisy observations. We provide statistical guarantees for the proposed method
and demonstrate its effectiveness through simulations and real data examples.
</p></li>
</ul>

<h3>Title: Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian. (arXiv:2303.11835v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11835">http://arxiv.org/abs/2303.11835</a></li>
<li>Code URL: <a href="https://github.com/ppauli/1d-lipcnns">https://github.com/ppauli/1d-lipcnns</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11835] Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian](http://arxiv.org/abs/2303.11835) #robust</code></li>
<li>Summary: <p>We establish a layer-wise parameterization for 1D convolutional neural
networks (CNNs) with built-in end-to-end robustness guarantees. Herein, we use
the Lipschitz constant of the input-output mapping characterized by a CNN as a
robustness measure. We base our parameterization on the Cayley transform that
parameterizes orthogonal matrices and the controllability Gramian for the state
space representation of the convolutional layers. The proposed parameterization
by design fulfills linear matrix inequalities that are sufficient for Lipschitz
continuity of the CNN, which further enables unconstrained training of
Lipschitz-bounded 1D CNNs. Finally, we train Lipschitz-bounded 1D CNNs for the
classification of heart arrythmia data and show their improved robustness.
</p></li>
</ul>

<h3>Title: Time Series Contrastive Learning with Information-Aware Augmentations. (arXiv:2303.11911v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11911">http://arxiv.org/abs/2303.11911</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11911] Time Series Contrastive Learning with Information-Aware Augmentations](http://arxiv.org/abs/2303.11911) #robust</code></li>
<li>Summary: <p>Various contrastive learning approaches have been proposed in recent years
and achieve significant empirical success. While effective and prevalent,
contrastive learning has been less explored for time series data. A key
component of contrastive learning is to select appropriate augmentations
imposing some priors to construct feasible positive samples, such that an
encoder can be trained to learn robust and discriminative representations.
Unlike image and language domains where ``desired'' augmented samples can be
generated with the rule of thumb guided by prefabricated human priors, the
ad-hoc manual selection of time series augmentations is hindered by their
diverse and human-unrecognizable temporal structures. How to find the desired
augmentations of time series data that are meaningful for given contrastive
learning tasks and datasets remains an open question. In this work, we address
the problem by encouraging both high \textit{fidelity} and \textit{variety}
based upon information theory. A theoretical analysis leads to the criteria for
selecting feasible data augmentations. On top of that, we propose a new
contrastive learning approach with information-aware augmentations, InfoTS,
that adaptively selects optimal augmentations for time series representation
learning. Experiments on various datasets show highly competitive performance
with up to 12.0\% reduction in MSE on forecasting tasks and up to 3.7\%
relative improvement in accuracy on classification tasks over the leading
baselines.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: BigSmall: Efficient Multi-Task Learning for Disparate Spatial and Temporal Physiological Measurements. (arXiv:2303.11573v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11573">http://arxiv.org/abs/2303.11573</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11573] BigSmall: Efficient Multi-Task Learning for Disparate Spatial and Temporal Physiological Measurements](http://arxiv.org/abs/2303.11573) #extraction</code></li>
<li>Summary: <p>Understanding of human visual perception has historically inspired the design
of computer vision architectures. As an example, perception occurs at different
scales both spatially and temporally, suggesting that the extraction of salient
visual information may be made more effective by paying attention to specific
features at varying scales. Visual changes in the body due to physiological
processes also occur at different scales and with modality-specific
characteristic properties. Inspired by this, we present BigSmall, an efficient
architecture for physiological and behavioral measurement. We present the first
joint camera-based facial action, cardiac, and pulmonary measurement model. We
propose a multi-branch network with wrapping temporal shift modules that yields
both accuracy and efficiency gains. We observe that fusing low-level features
leads to suboptimal performance, but that fusing high level features enables
efficiency gains with negligible loss in accuracy. Experimental results
demonstrate that BigSmall significantly reduces the computational costs.
Furthermore, compared to existing task-specific models, BigSmall achieves
comparable or better results on multiple physiological measurement tasks
simultaneously with a unified model.
</p></li>
</ul>

<h3>Title: An Embarrassingly Simple Approach for Wafer Feature Extraction and Defect Pattern Recognition. (arXiv:2303.11632v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11632">http://arxiv.org/abs/2303.11632</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11632] An Embarrassingly Simple Approach for Wafer Feature Extraction and Defect Pattern Recognition](http://arxiv.org/abs/2303.11632) #extraction</code></li>
<li>Summary: <p>Identifying defect patterns in a wafer map during manufacturing is crucial to
find the root cause of the underlying issue and provides valuable insights on
improving yield in the foundry. Currently used methods use deep neural networks
to identify the defects. These methods are generally very huge and have
significant inference time. They also require GPU support to efficiently
operate. All these issues make these models not fit for on-line prediction in
the manufacturing foundry. In this paper, we propose an extremely simple yet
effective technique to extract features from wafer images. The proposed method
is extremely fast, intuitive, and non-parametric while being explainable. The
experiment results show that the proposed pipeline outperforms conventional
deep learning models. Our feature extraction requires no training or
fine-tuning while preserving the relative shape and location of data points as
revealed by our interpretability analysis.
</p></li>
</ul>

<h3>Title: Style Miner: Find Significant and Stable Explanatory Factors in Time Series with Constrained Reinforcement Learning. (arXiv:2303.11716v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11716">http://arxiv.org/abs/2303.11716</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11716] Style Miner: Find Significant and Stable Explanatory Factors in Time Series with Constrained Reinforcement Learning](http://arxiv.org/abs/2303.11716) #extraction</code></li>
<li>Summary: <p>In high-dimensional time-series analysis, it is essential to have a set of
key factors (namely, the style factors) that explain the change of the observed
variable. For example, volatility modeling in finance relies on a set of risk
factors, and climate change studies in climatology rely on a set of causal
factors. The ideal low-dimensional style factors should balance significance
(with high explanatory power) and stability (consistent, no significant
fluctuations). However, previous supervised and unsupervised feature extraction
methods can hardly address the tradeoff. In this paper, we propose Style Miner,
a reinforcement learning method to generate style factors. We first formulate
the problem as a Constrained Markov Decision Process with explanatory power as
the return and stability as the constraint. Then, we design fine-grained
immediate rewards and costs and use a Lagrangian heuristic to balance them
adaptively. Experiments on real-world financial data sets show that Style Miner
outperforms existing learning-based methods by a large margin and achieves a
relatively 10% gain in R-squared explanatory power compared to the
industry-renowned factors proposed by human experts.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: STDLens: Model Hijacking-resilient Federated Learning for Object Detection. (arXiv:2303.11511v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11511">http://arxiv.org/abs/2303.11511</a></li>
<li>Code URL: <a href="https://github.com/git-disl/stdlens">https://github.com/git-disl/stdlens</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11511] STDLens: Model Hijacking-resilient Federated Learning for Object Detection](http://arxiv.org/abs/2303.11511) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) has been gaining popularity as a collaborative
learning framework to train deep learning-based object detection models over a
distributed population of clients. Despite its advantages, FL is vulnerable to
model hijacking. The attacker can control how the object detection system
should misbehave by implanting Trojaned gradients using only a small number of
compromised clients in the collaborative learning process. This paper
introduces STDLens, a principled approach to safeguarding FL against such
attacks. We first investigate existing mitigation mechanisms and analyze their
failures caused by the inherent errors in spatial clustering analysis on
gradients. Based on the insights, we introduce a three-tier forensic framework
to identify and expel Trojaned gradients and reclaim the performance over the
course of FL. We consider three types of adaptive attacks and demonstrate the
robustness of STDLens against advanced adversaries. Extensive experiments show
that STDLens can protect FL against different model hijacking attacks and
outperform existing methods in identifying and removing Trojaned gradients with
significantly higher precision and much lower false-positive rates.
</p></li>
</ul>

<h3>Title: FedMAE: Federated Self-Supervised Learning with One-Block Masked Auto-Encoder. (arXiv:2303.11339v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11339">http://arxiv.org/abs/2303.11339</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11339] FedMAE: Federated Self-Supervised Learning with One-Block Masked Auto-Encoder](http://arxiv.org/abs/2303.11339) #federate</code></li>
<li>Summary: <p>Latest federated learning (FL) methods started to focus on how to use
unlabeled data in clients for training due to users' privacy concerns, high
labeling costs, or lack of expertise. However, current Federated
Semi-Supervised/Self-Supervised Learning (FSSL) approaches fail to learn
large-scale images because of the limited computing resources of local clients.
In this paper, we introduce a new framework FedMAE, which stands for Federated
Masked AutoEncoder, to address the problem of how to utilize unlabeled
large-scale images for FL. Specifically, FedMAE can pre-train one-block Masked
AutoEncoder (MAE) using large images in lightweight client devices, and then
cascades multiple pre-trained one-block MAEs in the server to build a
multi-block ViT backbone for downstream tasks. Theoretical analysis and
experimental results on image reconstruction and classification show that our
FedMAE achieves superior performance compared to the state-of-the-art FSSL
methods.
</p></li>
</ul>

<h3>Title: A Survey on Class Imbalance in Federated Learning. (arXiv:2303.11673v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11673">http://arxiv.org/abs/2303.11673</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11673] A Survey on Class Imbalance in Federated Learning](http://arxiv.org/abs/2303.11673) #federate</code></li>
<li>Summary: <p>Federated learning, which allows multiple client devices in a network to
jointly train a machine learning model without direct exposure of clients'
data, is an emerging distributed learning technique due to its nature of
privacy preservation. However, it has been found that models trained with
federated learning usually have worse performance than their counterparts
trained in the standard centralized learning mode, especially when the training
data is imbalanced. In the context of federated learning, data imbalance may
occur either locally one one client device, or globally across many devices.
The complexity of different types of data imbalance has posed challenges to the
development of federated learning technique, especially considering the need of
relieving data imbalance issue and preserving data privacy at the same time.
Therefore, in the literature, many attempts have been made to handle class
imbalance in federated learning. In this paper, we present a detailed review of
recent advancements along this line. We first introduce various types of class
imbalance in federated learning, after which we review existing methods for
estimating the extent of class imbalance without the need of knowing the actual
data to preserve data privacy. After that, we discuss existing methods for
handling class imbalance in FL, where the advantages and disadvantages of the
these approaches are discussed. We also summarize common evaluation metrics for
class imbalanced tasks, and point out potential future directions.
</p></li>
</ul>

<h3>Title: Addressing Class Variable Imbalance in Federated Semi-supervised Learning. (arXiv:2303.11809v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11809">http://arxiv.org/abs/2303.11809</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11809] Addressing Class Variable Imbalance in Federated Semi-supervised Learning](http://arxiv.org/abs/2303.11809) #federate</code></li>
<li>Summary: <p>Federated Semi-supervised Learning (FSSL) combines techniques from both
fields of federated and semi-supervised learning to improve the accuracy and
performance of models in a distributed environment by using a small fraction of
labeled data and a large amount of unlabeled data. Without the need to
centralize all data in one place for training, it collect updates of model
training after devices train models at local, and thus can protect the privacy
of user data. However, during the federal training process, some of the devices
fail to collect enough data for local training, while new devices will be
included to the group training. This leads to an unbalanced global data
distribution and thus affect the performance of the global model training. Most
of the current research is focusing on class imbalance with a fixed number of
classes, while little attention is paid to data imbalance with a variable
number of classes. Therefore, in this paper, we propose Federated
Semi-supervised Learning for Class Variable Imbalance (FCVI) to solve class
variable imbalance. The class-variable learning algorithm is used to mitigate
the data imbalance due to changes of the number of classes. Our scheme is
proved to be significantly better than baseline methods, while maintaining
client privacy.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Bias mitigation techniques in image classification: fair machine learning in human heritage collections. (arXiv:2303.11449v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11449">http://arxiv.org/abs/2303.11449</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11449] Bias mitigation techniques in image classification: fair machine learning in human heritage collections](http://arxiv.org/abs/2303.11449) #fair</code></li>
<li>Summary: <p>A major problem with using automated classification systems is that if they
are not engineered correctly and with fairness considerations, they could be
detrimental to certain populations. Furthermore, while engineers have developed
cutting-edge technologies for image classification, there is still a gap in the
application of these models in human heritage collections, where data sets
usually consist of low-quality pictures of people with diverse ethnicity,
gender, and age. In this work, we evaluate three bias mitigation techniques
using two state-of-the-art neural networks, Xception and EfficientNet, for
gender classification. Moreover, we explore the use of transfer learning using
a fair data set to overcome the training data scarcity. We evaluated the
effectiveness of the bias mitigation pipeline on a cultural heritage collection
of photographs from the 19th and 20th centuries, and we used the FairFace data
set for the transfer learning experiments. After the evaluation, we found that
transfer learning is a good technique that allows better performance when
working with a small data set. Moreover, the fairest classifier was found to be
accomplished using transfer learning, threshold change, re-weighting and image
augmentation as bias mitigation methods.
</p></li>
</ul>

<h3>Title: Better Understanding Differences in Attribution Methods via Systematic Evaluations. (arXiv:2303.11884v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11884">http://arxiv.org/abs/2303.11884</a></li>
<li>Code URL: <a href="https://github.com/sukrutrao/attribution-evaluation">https://github.com/sukrutrao/attribution-evaluation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11884] Better Understanding Differences in Attribution Methods via Systematic Evaluations](http://arxiv.org/abs/2303.11884) #fair</code></li>
<li>Summary: <p>Deep neural networks are very successful on many vision tasks, but hard to
interpret due to their black box nature. To overcome this, various post-hoc
attribution methods have been proposed to identify image regions most
influential to the models' decisions. Evaluating such methods is challenging
since no ground truth attributions exist. We thus propose three novel
evaluation schemes to more reliably measure the faithfulness of those methods,
to make comparisons between them more fair, and to make visual inspection more
systematic. To address faithfulness, we propose a novel evaluation setting
(DiFull) in which we carefully control which parts of the input can influence
the output in order to distinguish possible from impossible attributions. To
address fairness, we note that different methods are applied at different
layers, which skews any comparison, and so evaluate all methods on the same
layers (ML-Att) and discuss how this impacts their performance on quantitative
metrics. For more systematic visualizations, we propose a scheme (AggAtt) to
qualitatively evaluate the methods on complete datasets. We use these
evaluation schemes to study strengths and shortcomings of some widely used
attribution methods over a wide range of models. Finally, we propose a
post-processing smoothing step that significantly improves the performance of
some attribution methods, and discuss its applicability.
</p></li>
</ul>

<h3>Title: How (Implicit) Regularization of ReLU Neural Networks Characterizes the Learned Function -- Part II: the Multi-D Case of Two Layers with Random First Layer. (arXiv:2303.11454v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11454">http://arxiv.org/abs/2303.11454</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11454] How (Implicit) Regularization of ReLU Neural Networks Characterizes the Learned Function -- Part II: the Multi-D Case of Two Layers with Random First Layer](http://arxiv.org/abs/2303.11454) #fair</code></li>
<li>Summary: <p>Randomized neural networks (randomized NNs), where only the terminal layer's
weights are optimized constitute a powerful model class to reduce computational
time in training the neural network model. At the same time, these models
generalize surprisingly well in various regression and classification tasks. In
this paper, we give an exact macroscopic characterization (i.e., a
characterization in function space) of the generalization behavior of
randomized, shallow NNs with ReLU activation (RSNs). We show that RSNs
correspond to a generalized additive model (GAM)-typed regression in which
infinitely many directions are considered: the infinite generalized additive
model (IGAM). The IGAM is formalized as solution to an optimization problem in
function space for a specific regularization functional and a fairly general
loss. This work is an extension to multivariate NNs of prior work, where we
showed how wide RSNs with ReLU activation behave like spline regression under
certain conditions and if the input is one-dimensional.
</p></li>
</ul>

<h3>Title: Fairness-Aware Graph Filter Design. (arXiv:2303.11459v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11459">http://arxiv.org/abs/2303.11459</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11459] Fairness-Aware Graph Filter Design](http://arxiv.org/abs/2303.11459) #fair</code></li>
<li>Summary: <p>Graphs are mathematical tools that can be used to represent complex
real-world systems, such as financial markets and social networks. Hence,
machine learning (ML) over graphs has attracted significant attention recently.
However, it has been demonstrated that ML over graphs amplifies the already
existing bias towards certain under-represented groups in various
decision-making problems due to the information aggregation over biased graph
structures. Faced with this challenge, in this paper, we design a fair graph
filter that can be employed in a versatile manner for graph-based learning
tasks. The design of the proposed filter is based on a bias analysis and its
optimality in mitigating bias compared to its fairness-agnostic counterpart is
established. Experiments on real-world networks for node classification
demonstrate the efficacy of the proposed filter design in mitigating bias,
while attaining similar utility and better stability compared to baseline
algorithms.
</p></li>
</ul>

<h3>Title: Counterfactually Fair Regression with Double Machine Learning. (arXiv:2303.11529v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11529">http://arxiv.org/abs/2303.11529</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11529] Counterfactually Fair Regression with Double Machine Learning](http://arxiv.org/abs/2303.11529) #fair</code></li>
<li>Summary: <p>Counterfactual fairness is an approach to AI fairness that tries to make
decisions based on the outcomes that an individual with some kind of sensitive
status would have had without this status. This paper proposes Double Machine
Learning (DML) Fairness which analogises this problem of counterfactual
fairness in regression problems to that of estimating counterfactual outcomes
in causal inference under the Potential Outcomes framework. It uses arbitrary
machine learning methods to partial out the effect of sensitive variables on
nonsensitive variables and outcomes. Assuming that the effects of the two sets
of variables are additively separable, outcomes will be approximately equalised
and individual-level outcomes will be counterfactually fair. This paper
demonstrates the approach in a simulation study pertaining to discrimination in
workplace hiring and an application on real data estimating the GPAs of law
school students. It then discusses when it is appropriate to apply such a
method to problems of real-world discrimination where constructs are
conceptually complex and finally, whether DML Fairness can achieve justice in
these settings.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Deep trip generation with graph neural networks for bike sharing system expansion. (arXiv:2303.11977v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11977">http://arxiv.org/abs/2303.11977</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11977] Deep trip generation with graph neural networks for bike sharing system expansion](http://arxiv.org/abs/2303.11977) #interpretability</code></li>
<li>Summary: <p>Bike sharing is emerging globally as an active, convenient, and sustainable
mode of transportation. To plan successful bike-sharing systems (BSSs), many
cities start from a small-scale pilot and gradually expand the system to cover
more areas. For station-based BSSs, this means planning new stations based on
existing ones over time, which requires prediction of the number of trips
generated by these new stations across the whole system. Previous studies
typically rely on relatively simple regression or machine learning models,
which are limited in capturing complex spatial relationships. Despite the
growing literature in deep learning methods for travel demand prediction, they
are mostly developed for short-term prediction based on time series data,
assuming no structural changes to the system. In this study, we focus on the
trip generation problem for BSS expansion, and propose a graph neural network
(GNN) approach to predicting the station-level demand based on multi-source
urban built environment data. Specifically, it constructs multiple localized
graphs centered on each target station and uses attention mechanisms to learn
the correlation weights between stations. We further illustrate that the
proposed approach can be regarded as a generalized spatial regression model,
indicating the commonalities between spatial regression and GNNs. The model is
evaluated based on realistic experiments using multi-year BSS data from New
York City, and the results validate the superior performance of our approach
compared to existing methods. We also demonstrate the interpretability of the
model for uncovering the effects of built environment features and spatial
interactions between stations, which can provide strategic guidance for BSS
station location selection and capacity planning.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Explain To Me: Salience-Based Explainability for Synthetic Face Detection Models. (arXiv:2303.11969v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11969">http://arxiv.org/abs/2303.11969</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11969] Explain To Me: Salience-Based Explainability for Synthetic Face Detection Models](http://arxiv.org/abs/2303.11969) #explainability</code></li>
<li>Summary: <p>The performance of convolutional neural networks has continued to improve
over the last decade. At the same time, as model complexity grows, it becomes
increasingly more difficult to explain model decisions. Such explanations may
be of critical importance for reliable operation of human-machine pairing
setups, or for model selection when the "best" model among many
equally-accurate models must be established. Saliency maps represent one
popular way of explaining model decisions by highlighting image regions models
deem important when making a prediction. However, examining salience maps at
scale is not practical. In this paper, we propose five novel methods of
leveraging model salience to explain a model behavior at scale. These methods
ask: (a) what is the average entropy for a model's salience maps, (b) how does
model salience change when fed out-of-set samples, (c) how closely does model
salience follow geometrical transformations, (d) what is the stability of model
salience across independent training runs, and (e) how does model salience
react to salience-guided image degradations. To assess the proposed measures on
a concrete and topical problem, we conducted a series of experiments for the
task of synthetic face detection with two types of models: those trained
traditionally with cross-entropy loss, and those guided by human salience when
training to increase model generalizability. These two types of models are
characterized by different, interpretable properties of their salience maps,
which allows for the evaluation of the correctness of the proposed measures. We
offer source codes for each measure along with this paper.
</p></li>
</ul>

<h3>Title: Unlocking Layer-wise Relevance Propagation for Autoencoders. (arXiv:2303.11734v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11734">http://arxiv.org/abs/2303.11734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11734] Unlocking Layer-wise Relevance Propagation for Autoencoders](http://arxiv.org/abs/2303.11734) #explainability</code></li>
<li>Summary: <p>Autoencoders are a powerful and versatile tool often used for various
problems such as anomaly detection, image processing and machine translation.
However, their reconstructions are not always trivial to explain. Therefore, we
propose a fast explainability solution by extending the Layer-wise Relevance
Propagation method with the help of Deep Taylor Decomposition framework.
Furthermore, we introduce a novel validation technique for comparing our
explainability approach with baseline methods in the case of missing
ground-truth data. Our results highlight computational as well as qualitative
advantages of the proposed explainability solution with respect to existing
methods.
</p></li>
</ul>

<h3>Title: Do intermediate feature coalitions aid explainability of black-box models?. (arXiv:2303.11920v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11920">http://arxiv.org/abs/2303.11920</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11920] Do intermediate feature coalitions aid explainability of black-box models?](http://arxiv.org/abs/2303.11920) #explainability</code></li>
<li>Summary: <p>This work introduces the notion of intermediate concepts based on levels
structure to aid explainability for black-box models. The levels structure is a
hierarchical structure in which each level corresponds to features of a dataset
(i.e., a player-set partition). The level of coarseness increases from the
trivial set, which only comprises singletons, to the set, which only contains
the grand coalition. In addition, it is possible to establish meronomies, i.e.,
part-whole relationships, via a domain expert that can be utilised to generate
explanations at an abstract level. We illustrate the usability of this approach
in a real-world car model example and the Titanic dataset, where intermediate
concepts aid in explainability at different levels of abstraction.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Text2Tex: Text-driven Texture Synthesis via Diffusion Models. (arXiv:2303.11396v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11396">http://arxiv.org/abs/2303.11396</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11396] Text2Tex: Text-driven Texture Synthesis via Diffusion Models](http://arxiv.org/abs/2303.11396) #diffusion</code></li>
<li>Summary: <p>We present Text2Tex, a novel method for generating high-quality textures for
3D meshes from the given text prompts. Our method incorporates inpainting into
a pre-trained depth-aware image diffusion model to progressively synthesize
high resolution partial textures from multiple viewpoints. To avoid
accumulating inconsistent and stretched artifacts across views, we dynamically
segment the rendered view into a generation mask, which represents the
generation status of each visible texel. This partitioned view representation
guides the depth-aware inpainting model to generate and update partial textures
for the corresponding regions. Furthermore, we propose an automatic view
sequence generation scheme to determine the next best view for updating the
partial texture. Extensive experiments demonstrate that our method
significantly outperforms the existing text-driven approaches and GAN-based
methods.
</p></li>
</ul>

<h3>Title: Aerial Diffusion: Text Guided Ground-to-Aerial View Translation from a Single Image using Diffusion Models. (arXiv:2303.11444v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11444">http://arxiv.org/abs/2303.11444</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11444] Aerial Diffusion: Text Guided Ground-to-Aerial View Translation from a Single Image using Diffusion Models](http://arxiv.org/abs/2303.11444) #diffusion</code></li>
<li>Summary: <p>We present a novel method, Aerial Diffusion, for generating aerial views from
a single ground-view image using text guidance. Aerial Diffusion leverages a
pretrained text-image diffusion model for prior knowledge. We address two main
challenges corresponding to domain gap between the ground-view and the aerial
view and the two views being far apart in the text-image embedding manifold.
Our approach uses a homography inspired by inverse perspective mapping prior to
finetuning the pretrained diffusion model. Additionally, using the text
corresponding to the ground-view to finetune the model helps us capture the
details in the ground-view image at a relatively low bias towards the
ground-view image. Aerial Diffusion uses an alternating sampling strategy to
compute the optimal solution on complex high-dimensional manifold and generate
a high-fidelity (w.r.t. ground view) aerial image. We demonstrate the quality
and versatility of Aerial Diffusion on a plethora of images from various
domains including nature, human actions, indoor scenes, etc. We qualitatively
prove the effectiveness of our method with extensive ablations and comparisons.
To the best of our knowledge, Aerial Diffusion is the first approach that
performs ground-to-aerial translation in an unsupervised manner.
</p></li>
</ul>

<h3>Title: Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation. (arXiv:2303.11579v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11579">http://arxiv.org/abs/2303.11579</a></li>
<li>Code URL: <a href="https://github.com/patrick-swk/d3dp">https://github.com/patrick-swk/d3dp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11579] Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation](http://arxiv.org/abs/2303.11579) #diffusion</code></li>
<li>Summary: <p>In this paper, a novel Diffusion-based 3D Pose estimation (D3DP) method with
Joint-wise reProjection-based Multi-hypothesis Aggregation (JPMA) is proposed
for probabilistic 3D human pose estimation. On the one hand, D3DP generates
multiple possible 3D pose hypotheses for a single 2D observation. It gradually
diffuses the ground truth 3D poses to a random distribution, and learns a
denoiser conditioned on 2D keypoints to recover the uncontaminated 3D poses.
The proposed D3DP is compatible with existing 3D pose estimators and supports
users to balance efficiency and accuracy during inference through two
customizable parameters. On the other hand, JPMA is proposed to assemble
multiple hypotheses generated by D3DP into a single 3D pose for practical use.
It reprojects 3D pose hypotheses to the 2D camera plane, selects the best
hypothesis joint-by-joint based on the reprojection errors, and combines the
selected joints into the final pose. The proposed JPMA conducts aggregation at
the joint level and makes use of the 2D prior information, both of which have
been overlooked by previous approaches. Extensive experiments on Human3.6M and
MPI-INF-3DHP datasets show that our method outperforms the state-of-the-art
deterministic and probabilistic approaches by 1.5% and 8.9%, respectively. Code
is available at https://github.com/paTRICK-swk/D3DP.
</p></li>
</ul>

<h3>Title: LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models. (arXiv:2303.11589v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11589">http://arxiv.org/abs/2303.11589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11589] LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models](http://arxiv.org/abs/2303.11589) #diffusion</code></li>
<li>Summary: <p>Creating graphic layouts is a fundamental step in graphic designs. In this
work, we present a novel generative model named LayoutDiffusion for automatic
layout generation. As layout is typically represented as a sequence of discrete
tokens, LayoutDiffusion models layout generation as a discrete denoising
diffusion process. It learns to reverse a mild forward process, in which
layouts become increasingly chaotic with the growth of forward steps and
layouts in the neighboring steps do not differ too much. Designing such a mild
forward process is however very challenging as layout has both categorical
attributes and ordinal attributes. To tackle the challenge, we summarize three
critical factors for achieving a mild forward process for the layout, i.e.,
legality, coordinate proximity and type disruption. Based on the factors, we
propose a block-wise transition matrix coupled with a piece-wise linear noise
schedule. Experiments on RICO and PubLayNet datasets show that LayoutDiffusion
outperforms state-of-the-art approaches significantly. Moreover, it enables two
conditional layout generation tasks in a plug-and-play manner without
re-training and achieves better performance than existing methods.
</p></li>
</ul>

<h3>Title: DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models. (arXiv:2303.11681v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11681">http://arxiv.org/abs/2303.11681</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11681] DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models](http://arxiv.org/abs/2303.11681) #diffusion</code></li>
<li>Summary: <p>Collecting and annotating images with pixel-wise labels is time-consuming and
laborious. In contrast, synthetic data can be freely available using a
generative model (e.g., DALL-E, Stable Diffusion). In this paper, we show that
it is possible to automatically obtain accurate semantic masks of synthetic
images generated by the Off-the-shelf Stable Diffusion model, which uses only
text-image pairs during training. Our approach, called DiffuMask, exploits the
potential of the cross-attention map between text and image, which is natural
and seamless to extend the text-driven image synthesis to semantic mask
generation. DiffuMask uses text-guided cross-attention information to localize
class/word-specific regions, which are combined with practical techniques to
create a novel high-resolution and class-discriminative pixel-wise mask. The
methods help to reduce data collection and annotation costs obviously.
Experiments demonstrate that the existing segmentation methods trained on
synthetic data of DiffuMask can achieve a competitive performance over the
counterpart of real data (VOC 2012, Cityscapes). For some classes (e.g., bird),
DiffuMask presents promising performance, close to the stateof-the-art result
of real data (within 3% mIoU gap). Moreover, in the open-vocabulary
segmentation (zero-shot) setting, DiffuMask achieves a new SOTA result on
Unseen class of VOC 2012. The project website can be found at
https://weijiawu.github.io/DiffusionMask/.
</p></li>
</ul>

<h3>Title: CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion. (arXiv:2303.11916v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11916">http://arxiv.org/abs/2303.11916</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11916] CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion](http://arxiv.org/abs/2303.11916) #diffusion</code></li>
<li>Summary: <p>This paper proposes a novel diffusion-based model, CompoDiff, for solving
Composed Image Retrieval (CIR) with latent diffusion and presents a newly
created dataset of 18 million reference images, conditions, and corresponding
target image triplets to train the model. CompoDiff not only achieves a new
zero-shot state-of-the-art on a CIR benchmark such as FashionIQ but also
enables a more versatile CIR by accepting various conditions, such as negative
text and image mask conditions, which are unavailable with existing CIR
methods. In addition, the CompoDiff features are on the intact CLIP embedding
space so that they can be directly used for all existing models exploiting the
CLIP space. The code and dataset used for the training, and the pre-trained
weights are available at https://github.com/navervision/CompoDiff
</p></li>
</ul>

<h3>Title: 3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion. (arXiv:2303.11938v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.11938">http://arxiv.org/abs/2303.11938</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.11938] 3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion](http://arxiv.org/abs/2303.11938) #diffusion</code></li>
<li>Summary: <p>We tackle the task of text-to-3D creation with pre-trained latent-based NeRFs
(NeRFs that generate 3D objects given input latent code). Recent works such as
DreamFusion and Magic3D have shown great success in generating 3D content using
NeRFs and text prompts, but the current approach of optimizing a NeRF for every
text prompt is 1) extremely time-consuming and 2) often leads to low-resolution
outputs. To address these challenges, we propose a novel method named
3D-CLFusion which leverages the pre-trained latent-based NeRFs and performs
fast 3D content creation in less than a minute. In particular, we introduce a
latent diffusion prior network for learning the w latent from the input CLIP
text/image embeddings. This pipeline allows us to produce the w latent without
further optimization during inference and the pre-trained NeRF is able to
perform multi-view high-resolution 3D synthesis based on the latent. We note
that the novelty of our model lies in that we introduce contrastive learning
during training the diffusion prior which enables the generation of the valid
view-invariant latent code. We demonstrate through experiments the
effectiveness of our proposed view-invariant diffusion process for fast
text-to-3D creation, e.g., 100 times faster than DreamFusion. We note that our
model is able to serve as the role of a plug-and-play tool for text-to-3D with
pre-trained NeRFs.
</p></li>
</ul>

<h3>Title: Semantic Latent Space Regression of Diffusion Autoencoders for Vertebral Fracture Grading. (arXiv:2303.12031v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12031">http://arxiv.org/abs/2303.12031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12031] Semantic Latent Space Regression of Diffusion Autoencoders for Vertebral Fracture Grading](http://arxiv.org/abs/2303.12031) #diffusion</code></li>
<li>Summary: <p>Vertebral fractures are a consequence of osteoporosis, with significant
health implications for affected patients. Unfortunately, grading their
severity using CT exams is hard and subjective, motivating automated grading
methods. However, current approaches are hindered by imbalance and scarcity of
data and a lack of interpretability. To address these challenges, this paper
proposes a novel approach that leverages unlabelled data to train a generative
Diffusion Autoencoder (DAE) model as an unsupervised feature extractor. We
model fracture grading as a continuous regression, which is more reflective of
the smooth progression of fractures. Specifically, we use a binary, supervised
fracture classifier to construct a hyperplane in the DAE's latent space. We
then regress the severity of the fracture as a function of the distance to this
hyperplane, calibrating the results to the Genant scale. Importantly, the
generative nature of our method allows us to visualize different grades of a
given vertebra, providing interpretability and insight into the features that
contribute to automated grading.
</p></li>
</ul>

<h3>Title: Vox-E: Text-guided Voxel Editing of 3D Objects. (arXiv:2303.12048v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12048">http://arxiv.org/abs/2303.12048</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12048] Vox-E: Text-guided Voxel Editing of 3D Objects](http://arxiv.org/abs/2303.12048) #diffusion</code></li>
<li>Summary: <p>Large scale text-guided diffusion models have garnered significant attention
due to their ability to synthesize diverse images that convey complex visual
concepts. This generative power has more recently been leveraged to perform
text-to-3D synthesis. In this work, we present a technique that harnesses the
power of latent diffusion models for editing existing 3D objects. Our method
takes oriented 2D images of a 3D object as input and learns a grid-based
volumetric representation of it. To guide the volumetric representation to
conform to a target text prompt, we follow unconditional text-to-3D methods and
optimize a Score Distillation Sampling (SDS) loss. However, we observe that
combining this diffusion-guided loss with an image-based regularization loss
that encourages the representation not to deviate too strongly from the input
object is challenging, as it requires achieving two conflicting goals while
viewing only structure-and-appearance coupled 2D projections. Thus, we
introduce a novel volumetric regularization loss that operates directly in 3D
space, utilizing the explicit nature of our 3D representation to enforce
correlation between the global structure of the original and edited object.
Furthermore, we present a technique that optimizes cross-attention volumetric
grids to refine the spatial extent of the edits. Extensive experiments and
comparisons demonstrate the effectiveness of our approach in creating a myriad
of edits which cannot be achieved by prior works.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
