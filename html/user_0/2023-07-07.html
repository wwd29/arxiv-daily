<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: How accurate are existing land cover maps for agriculture in Sub-Saharan Africa?. (arXiv:2307.02575v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02575">http://arxiv.org/abs/2307.02575</a></li>
<li>Code URL: <a href="https://github.com/nasaharvest/crop-mask">https://github.com/nasaharvest/crop-mask</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02575] How accurate are existing land cover maps for agriculture in Sub-Saharan Africa?](http://arxiv.org/abs/2307.02575) #security</code></li>
<li>Summary: <p>Satellite Earth observations (EO) can provide affordable and timely
information for assessing crop conditions and food production. Such monitoring
systems are essential in Africa, where there is high food insecurity and sparse
agricultural statistics. EO-based monitoring systems require accurate cropland
maps to provide information about croplands, but there is a lack of data to
determine which of the many available land cover maps most accurately identify
cropland in African countries. This study provides a quantitative evaluation
and intercomparison of 11 publicly available land cover maps to assess their
suitability for cropland classification and EO-based agriculture monitoring in
Africa using statistically rigorous reference datasets from 8 countries. We
hope the results of this study will help users determine the most suitable map
for their needs and encourage future work to focus on resolving inconsistencies
between maps and improving accuracy in low-accuracy regions.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications. (arXiv:2307.02984v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02984">http://arxiv.org/abs/2307.02984</a></li>
<li>Code URL: <a href="https://github.com/perceivelab/plan">https://github.com/perceivelab/plan</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02984] A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications](http://arxiv.org/abs/2307.02984) #privacy</code></li>
<li>Summary: <p>Generative Adversarial Networks (GANs) have demonstrated their ability to
generate synthetic samples that match a target distribution. However, from a
privacy perspective, using GANs as a proxy for data sharing is not a safe
solution, as they tend to embed near-duplicates of real samples in the latent
space. Recent works, inspired by k-anonymity principles, address this issue
through sample aggregation in the latent space, with the drawback of reducing
the dataset by a factor of k. Our work aims to mitigate this problem by
proposing a latent space navigation strategy able to generate diverse synthetic
samples that may support effective training of deep models, while addressing
privacy concerns in a principled way. Our approach leverages an auxiliary
identity classifier as a guide to non-linearly walk between points in the
latent space, minimizing the risk of collision with near-duplicates of real
samples. We empirically demonstrate that, given any random pair of points in
the latent space, our walking strategy is safer than linear interpolation. We
then test our path-finding strategy combined to k-same methods and demonstrate,
on two benchmarks for tuberculosis and diabetic retinopathy classification,
that training a model using samples generated by our approach mitigate drops in
performance, while keeping privacy preservation.
</p></li>
</ul>

<h3>Title: Smartphones in a Microwave: Formal and Experimental Feasibility Study on Fingerprinting the Corona-Warn-App. (arXiv:2307.02931v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02931">http://arxiv.org/abs/2307.02931</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02931] Smartphones in a Microwave: Formal and Experimental Feasibility Study on Fingerprinting the Corona-Warn-App](http://arxiv.org/abs/2307.02931) #privacy</code></li>
<li>Summary: <p>Contact Tracing Apps (CTAs) have been developed to contain the coronavirus
disease 19 (COVID-19) spread. By design, such apps invade their users' privacy
by recording data about their health, contacts, and partially location. Many
CTAs frequently broadcast pseudorandom numbers via Bluetooth to detect
encounters. These numbers are changed regularly to prevent individual
smartphones from being trivially trackable. However, the effectiveness of this
procedure has been little studied. We measured real smartphones and observed
that the German Corona-Warn-App (CWA) exhibits a device-specific latency
between two subsequent broadcasts. These timing differences provide a potential
attack vector for fingerprinting smartphones by passively recording Bluetooth
messages. This could conceivably lead to the tracking of users' trajectories
and, ultimately, the re-identification of users.
</p></li>
</ul>

<h3>Title: DPM: Clustering Sensitive Data through Separation. (arXiv:2307.02969v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02969">http://arxiv.org/abs/2307.02969</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02969] DPM: Clustering Sensitive Data through Separation](http://arxiv.org/abs/2307.02969) #privacy</code></li>
<li>Summary: <p>Privacy-preserving clustering groups data points in an unsupervised manner
whilst ensuring that sensitive information remains protected. Previous
privacy-preserving clustering focused on identifying concentration of point
clouds. In this paper, we take another path and focus on identifying
appropriate separators that split a data set. We introduce the novel
differentially private clustering algorithm DPM that searches for accurate data
point separators in a differentially private manner. DPM addresses two key
challenges for finding accurate separators: identifying separators that are
large gaps between clusters instead of small gaps within a cluster and, to
efficiently spend the privacy budget, prioritising separators that split the
data into large subparts. Using the differentially private Exponential
Mechanism, DPM randomly chooses cluster separators with provably high utility:
For a data set $D$, if there is a wide low-density separator in the central
$60\%$ quantile, DPM finds that separator with probability $1 -
\exp(-\sqrt{|D|})$. Our experimental evaluation demonstrates that DPM achieves
significant improvements in terms of the clustering metric inertia. With the
inertia results of the non-private KMeans++ as a baseline, for $\varepsilon =
1$ and $\delta=10^{-5}$ DPM improves upon the difference to the baseline by up
to $50\%$ for a synthetic data set and by up to $62\%$ for a real-world data
set compared to a state-of-the-art clustering algorithm by Chang and Kamath.
</p></li>
</ul>

<h3>Title: FREEDOM: Target Label &amp; Source Data &amp; Domain Information-Free Multi-Source Domain Adaptation for Unsupervised Personalization. (arXiv:2307.02493v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02493">http://arxiv.org/abs/2307.02493</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02493] FREEDOM: Target Label &amp; Source Data &amp; Domain Information-Free Multi-Source Domain Adaptation for Unsupervised Personalization](http://arxiv.org/abs/2307.02493) #privacy</code></li>
<li>Summary: <p>From a service perspective, Multi-Source Domain Adaptation (MSDA) is a
promising scenario to adapt a deployed model to a client's dataset. It can
provide adaptation without a target label and support the case where a source
dataset is constructed from multiple domains. However, it is impractical,
wherein its training heavily relies on prior domain information of the
multi-source dataset -- how many domains exist and the domain label of each
data sample. Moreover, MSDA requires both source and target datasets
simultaneously (physically), causing storage limitations on the client device
or data privacy issues by transferring client data to a server. For a more
practical scenario of model adaptation from a service provider's point of view,
we relax these constraints and present a novel problem scenario of Three-Free
Domain Adaptation, namely TFDA, where 1) target labels, 2) source dataset, and
mostly 3) source domain information (domain labels + the number of domains) are
unavailable. Under the problem scenario, we propose a practical adaptation
framework called FREEDOM. It leverages the power of the generative model,
disentangling data into class and style aspects, where the style is defined as
the class-independent information from the source data and designed with a
nonparametric Bayesian approach. In the adaptation stage, FREEDOM aims to match
the source class distribution with the target's under the philosophy that class
distribution is consistent even if the style is different; after then, only
part of the classification model is deployed as a personalized network. As a
result, FREEDOM achieves state-of-the-art or comparable performance even
without domain information, with reduced final model size on the target side,
independent of the number of source domains.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations. (arXiv:2307.02672v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02672">http://arxiv.org/abs/2307.02672</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02672] GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations](http://arxiv.org/abs/2307.02672) #attack</code></li>
<li>Summary: <p>Deep neural networks tend to make overconfident predictions and often require
additional detectors for misclassifications, particularly for safety-critical
applications. Existing detection methods usually only focus on adversarial
attacks or out-of-distribution samples as reasons for false predictions.
However, generalization errors occur due to diverse reasons often related to
poorly learning relevant invariances. We therefore propose GIT, a holistic
approach for the detection of generalization errors that combines the usage of
gradient information and invariance transformations. The invariance
transformations are designed to shift misclassified samples back into the
generalization area of the neural network, while the gradient information
measures the contradiction between the initial prediction and the corresponding
inherent computations of the neural network using the transformed sample. Our
experiments demonstrate the superior performance of GIT compared to the
state-of-the-art on a variety of network architectures, problem setups and
perturbation types.
</p></li>
</ul>

<h3>Title: MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection. (arXiv:2307.02733v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02733">http://arxiv.org/abs/2307.02733</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02733] MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection](http://arxiv.org/abs/2307.02733) #attack</code></li>
<li>Summary: <p>Advanced manipulation techniques have provided criminals with opportunities
to make social panic or gain illicit profits through the generation of
deceptive media, such as forged face images. In response, various deepfake
detection methods have been proposed to assess image authenticity. Sequential
deepfake detection, which is an extension of deepfake detection, aims to
identify forged facial regions with the correct sequence for recovery.
Nonetheless, due to the different combinations of spatial and sequential
manipulations, forged face images exhibit substantial discrepancies that
severely impact detection performance. Additionally, the recovery of forged
images requires knowledge of the manipulation model to implement inverse
transformations, which is difficult to ascertain as relevant techniques are
often concealed by attackers. To address these issues, we propose
Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various
spatial scales and sequential permutations in forged face images and achieve
recovery without requiring knowledge of the corresponding manipulation method.
Furthermore, existing evaluation metrics only consider detection accuracy at a
single inferring step, without accounting for the matching degree with
ground-truth under continuous multiple steps. To overcome this limitation, we
propose a novel evaluation metric called Complete Sequence Matching (CSM),
which considers the detection accuracy at multiple inferring steps, reflecting
the ability to detect integrally forged sequences. Extensive experiments on
several typical datasets demonstrate that MMNet achieves state-of-the-art
detection performance and independent recovery performance.
</p></li>
</ul>

<h3>Title: Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks. (arXiv:2307.02828v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02828">http://arxiv.org/abs/2307.02828</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02828] Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks](http://arxiv.org/abs/2307.02828) #attack</code></li>
<li>Summary: <p>Deep neural networks are known to be vulnerable to adversarial examples
crafted by adding human-imperceptible perturbations to the benign input. After
achieving nearly 100% attack success rates in white-box setting, more focus is
shifted to black-box attacks, of which the transferability of adversarial
examples has gained significant attention. In either case, the common
gradient-based methods generally use the sign function to generate
perturbations on the gradient update, that offers a roughly correct direction
and has gained great success. But little work pays attention to its possible
limitation. In this work, we observe that the deviation between the original
gradient and the generated noise may lead to inaccurate gradient update
estimation and suboptimal solutions for adversarial transferability. To this
end, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM).
Specifically, we use data rescaling to substitute the sign function without
extra computational cost. We further propose a Depth First Sampling method to
eliminate the fluctuation of rescaling and stabilize the gradient update. Our
method could be used in any gradient-based attacks and is extensible to be
integrated with various input transformation or ensemble methods to further
improve the adversarial transferability. Extensive experiments on the standard
ImageNet dataset show that our method could significantly boost the
transferability of gradient-based attacks and outperform the state-of-the-art
baselines.
</p></li>
</ul>

<h3>Title: Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing. (arXiv:2307.02858v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02858">http://arxiv.org/abs/2307.02858</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02858] Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing](http://arxiv.org/abs/2307.02858) #attack</code></li>
<li>Summary: <p>Face presentation attacks, also known as spoofing attacks, pose a significant
threat to biometric systems that rely on facial recognition systems, such as
access control systems, mobile payments, and identity verification systems. To
prevent spoofing, several video-based methods have been presented in the
literature that analyze facial motion in successive video frames. However,
estimating the motion between adjacent frames is a challenging task and
requires high computational cost. In this paper, we reformulate the face
anti-spoofing task as a motion prediction problem and introduce a deep ensemble
learning model with a frame skipping mechanism. The proposed frame skipping is
based on a uniform sampling approach where the original video is divided into
fixed size video clips. In this way, every nth frame of the clip is selected to
ensure that the temporal patterns can easily be perceived during the training
of three different recurrent neural networks (RNNs). Motivated by the
performance of each RNNs, a meta-model is developed to improve the overall
recognition performance by combining the predictions of the individual RNNs.
Extensive experiments were conducted on four datasets, and state-of-the-art
performance is reported for MSU-MFSD (3.12\%), Replay-Attack (11.19\%), and
OULU-NPU (12.23\%) using half total error rate (HTER) in the most challenging
cross-dataset test scenario.
</p></li>
</ul>

<h3>Title: Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications. (arXiv:2307.02881v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02881">http://arxiv.org/abs/2307.02881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02881] Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications](http://arxiv.org/abs/2307.02881) #attack</code></li>
<li>Summary: <p>This paper begins with a description of methods for estimating probability
density functions for images that reflects the observation that such data is
usually constrained to lie in restricted regions of the high-dimensional image
space - not every pattern of pixels is an image. It is common to say that
images lie on a lower-dimensional manifold in the high-dimensional space.
However, although images may lie on such lower-dimensional manifolds, it is not
the case that all points on the manifold have an equal probability of being
images. Images are unevenly distributed on the manifold, and our task is to
devise ways to model this distribution as a probability distribution. In
pursuing this goal, we consider generative models that are popular in AI and
computer vision community. For our purposes, generative/probabilistic models
should have the properties of 1) sample generation: it should be possible to
sample from this distribution according to the modelled density function, and
2) probability computation: given a previously unseen sample from the dataset
of interest, one should be able to compute the probability of the sample, at
least up to a normalising constant. To this end, we investigate the use of
methods such as normalising flow and diffusion models. We then show that such
probabilistic descriptions can be used to construct defences against
adversarial attacks. In addition to describing the manifold in terms of
density, we also consider how semantic interpretations can be used to describe
points on the manifold. To this end, we consider an emergent language framework
which makes use of variational encoders to produce a disentangled
representation of points that reside on a given manifold. Trajectories between
points on a manifold can then be described in terms of evolving semantic
descriptions.
</p></li>
</ul>

<h3>Title: NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic. (arXiv:2307.02849v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02849">http://arxiv.org/abs/2307.02849</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02849] NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic](http://arxiv.org/abs/2307.02849) #attack</code></li>
<li>Summary: <p>Reasoning has been a central topic in artificial intelligence from the
beginning. The recent progress made on distributed representation and neural
networks continues to improve the state-of-the-art performance of natural
language inference. However, it remains an open question whether the models
perform real reasoning to reach their conclusions or rely on spurious
correlations. Adversarial attacks have proven to be an important tool to help
evaluate the Achilles' heel of the victim models. In this study, we explore the
fundamental problem of developing attack models based on logic formalism. We
propose NatLogAttack to perform systematic attacks centring around natural
logic, a classical logic formalism that is traceable back to Aristotle's
syllogism and has been closely developed for natural language inference. The
proposed framework renders both label-preserving and label-flipping attacks. We
show that compared to the existing attack models, NatLogAttack generates better
adversarial examples with fewer visits to the victim models. The victim models
are found to be more vulnerable under the label-flipping setting. NatLogAttack
provides a tool to probe the existing and future NLI models' capacity from a
key viewpoint and we hope more logic-based attacks will be further explored for
understanding the desired property of reasoning.
</p></li>
</ul>

<h3>Title: Securing Cloud FPGAs Against Power Side-Channel Attacks: A Case Study on Iterative AES. (arXiv:2307.02569v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02569">http://arxiv.org/abs/2307.02569</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02569] Securing Cloud FPGAs Against Power Side-Channel Attacks: A Case Study on Iterative AES](http://arxiv.org/abs/2307.02569) #attack</code></li>
<li>Summary: <p>The various benefits of multi-tenanting, such as higher device utilization
and increased profit margin, intrigue the cloud field-programmable gate array
(FPGA) servers to include multi-tenanting in their infrastructure. However,
this property makes these servers vulnerable to power side-channel (PSC)
attacks. Logic designs such as ring oscillator (RO) and time-to-digital
converter (TDC) are used to measure the power consumed by security critical
circuits, such as advanced encryption standard (AES). Firstly, the existing
works require higher minimum traces for disclosure (MTD). Hence, in this work,
we improve the sensitivity of the TDC-based sensors by manually placing the
FPGA primitives inferring these sensors. This enhancement helps to determine
the 128-bit AES key using 3.8K traces. Secondly, the existing defenses use ROs
to defend against PSC attacks. However, cloud servers such as Amazon Web
Services (AWS) block design with combinatorial loops. Hence, we propose a
placement-based defense. We study the impact of (i) primitive-level placement
on the AES design and (ii) additional logic that resides along with the AES on
the correlation power analysis (CPA) attack results. Our results showcase that
the AES along with filters and/or processors are sufficient to provide the same
level or better security than the existing defenses.
</p></li>
</ul>

<h3>Title: Information-Based Heavy Hitters for Real-Time DNS Data Exfiltration Detection and Prevention. (arXiv:2307.02614v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02614">http://arxiv.org/abs/2307.02614</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02614] Information-Based Heavy Hitters for Real-Time DNS Data Exfiltration Detection and Prevention](http://arxiv.org/abs/2307.02614) #attack</code></li>
<li>Summary: <p>Data exfiltration over the DNS protocol and its detection have been
researched extensively in recent years. Prior studies focused on offline
detection methods, which although capable of detecting attacks, allow a large
amount of data to be exfiltrated before the attack is detected and dealt with.
In this paper, we introduce Information-based Heavy Hitters (ibHH), a real-time
detection method which is based on live estimations of the amount of
information transmitted to registered domains. ibHH uses constant-size memory
and supports constant-time queries, which makes it suitable for deployment on
recursive DNS servers to further reduce detection and response time. In our
evaluation, we compared the performance of the proposed method to that of
leading state-of-the-art DNS exfiltration detection methods on real-world
datasets comprising over 250 billion DNS queries. The evaluation demonstrates
ibHH's ability to successfully detect exfiltration rates as slow as 0.7B/s,
with a false positive alert rate of less than 0.004, with significantly lower
resource consumption compared to other methods.
</p></li>
</ul>

<h3>Title: A Testbed To Study Adversarial Cyber-Attack Strategies in Enterprise Networks. (arXiv:2307.02794v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02794">http://arxiv.org/abs/2307.02794</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02794] A Testbed To Study Adversarial Cyber-Attack Strategies in Enterprise Networks](http://arxiv.org/abs/2307.02794) #attack</code></li>
<li>Summary: <p>In this work, we propose a testbed environment to capture the attack
strategies of an adversary carrying out a cyber-attack on an enterprise
network. The testbed contains nodes with known security vulnerabilities which
can be exploited by hackers. Participants can be invited to play the role of a
hacker (e.g., black-hat, hacktivist) and attack the testbed. The testbed is
designed such that there are multiple attack pathways available to hackers. We
describe the working of the testbed components and discuss its implementation
on a VMware ESXi server. Finally, we subject our testbed implementation to a
few well-known cyber-attack strategies, collect data during the process and
present our analysis of the data.
</p></li>
</ul>

<h3>Title: It's more than just money: The real-world harms from ransomware attacks. (arXiv:2307.02855v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02855">http://arxiv.org/abs/2307.02855</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02855] It's more than just money: The real-world harms from ransomware attacks](http://arxiv.org/abs/2307.02855) #attack</code></li>
<li>Summary: <p>As cyber-attacks continue to increase in frequency and sophistication,
organisations must be better prepared to face the reality of an incident. Any
organisational plan that intends to be successful at managing security risks
must clearly understand the harm (i.e., negative impact) and the various
parties affected in the aftermath of an attack. To this end, this article
conducts a novel exploration into the multitude of real-world harms that can
arise from cyber-attacks, with a particular focus on ransomware incidents given
their current prominence. This exploration also leads to the proposal of a new,
robust methodology for modelling harms from such incidents. We draw on
publicly-available case data on high-profile ransomware incidents to examine
the types of harm that emerge at various stages after a ransomware attack and
how harms (e.g., an offline enterprise server) may trigger other negative,
potentially more substantial impacts for stakeholders (e.g., the inability for
a customer to access their social welfare benefits or bank account). Prominent
findings from our analysis include the identification of a notable set of
social/human harms beyond the business itself (and beyond the financial payment
of a ransom) and a complex web of harms that emerge after attacks regardless of
the industry sector. We also observed that deciphering the full extent and
sequence of harms can be a challenging undertaking because of the lack of
complete data available. This paper consequently argues for more transparency
on ransomware harms, as it would lead to a better understanding of the
realities of these incidents to the benefit of organisations and society more
generally.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Interpretable Computer Vision Models through Adversarial Training: Unveiling the Robustness-Interpretability Connection. (arXiv:2307.02500v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02500">http://arxiv.org/abs/2307.02500</a></li>
<li>Code URL: <a href="https://github.com/delyan-boychev/pytorch_trainers_interpretability">https://github.com/delyan-boychev/pytorch_trainers_interpretability</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02500] Interpretable Computer Vision Models through Adversarial Training: Unveiling the Robustness-Interpretability Connection](http://arxiv.org/abs/2307.02500) #robust</code></li>
<li>Summary: <p>With the perpetual increase of complexity of the state-of-the-art deep neural
networks, it becomes a more and more challenging task to maintain their
interpretability. Our work aims to evaluate the effects of adversarial training
utilized to produce robust models - less vulnerable to adversarial attacks. It
has been shown to make computer vision models more interpretable.
Interpretability is as essential as robustness when we deploy the models to the
real world. To prove the correlation between these two problems, we extensively
examine the models using local feature-importance methods (SHAP, Integrated
Gradients) and feature visualization techniques (Representation Inversion,
Class Specific Image Generation). Standard models, compared to robust are more
susceptible to adversarial attacks, and their learned representations are less
meaningful to humans. Conversely, these models focus on distinctive regions of
the images which support their predictions. Moreover, the features learned by
the robust model are closer to the real ones.
</p></li>
</ul>

<h3>Title: Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency. (arXiv:2307.02516v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02516">http://arxiv.org/abs/2307.02516</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02516] Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency](http://arxiv.org/abs/2307.02516) #robust</code></li>
<li>Summary: <p>Independently trained machine learning models tend to learn similar features.
Given an ensemble of independently trained models, this results in correlated
predictions and common failure modes. Previous attempts focusing on
decorrelation of output predictions or logits yielded mixed results,
particularly due to their reduction in model accuracy caused by conflicting
optimization objectives. In this paper, we propose the novel idea of utilizing
methods of the representational similarity field to promote dissimilarity
during training instead of measuring similarity of trained models. To this end,
we promote intermediate representations to be dissimilar at different depths
between architectures, with the goal of learning robust ensembles with disjoint
failure modes. We show that highly dissimilar intermediate representations
result in less correlated output predictions and slightly lower error
consistency, resulting in higher ensemble accuracy. With this, we shine first
light on the connection between intermediate representations and their impact
on the output predictions.
</p></li>
</ul>

<h3>Title: Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment. (arXiv:2307.02682v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02682">http://arxiv.org/abs/2307.02682</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02682] Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment](http://arxiv.org/abs/2307.02682) #robust</code></li>
<li>Summary: <p>Dense video captioning, a task of localizing meaningful moments and
generating relevant captions for videos, often requires a large, expensive
corpus of annotated video segments paired with text. In an effort to minimize
the annotation cost, we propose ZeroTA, a novel method for dense video
captioning in a zero-shot manner. Our method does not require any videos or
annotations for training; instead, it localizes and describes events within
each input video at test time by optimizing solely on the input. This is
accomplished by introducing a soft moment mask that represents a temporal
segment in the video and jointly optimizing it with the prefix parameters of a
language model. This joint optimization aligns a frozen language generation
model (i.e., GPT-2) with a frozen vision-language contrastive model (i.e.,
CLIP) by maximizing the matching score between the generated text and a moment
within the video. We also introduce a pairwise temporal IoU loss to let a set
of soft moment masks capture multiple distinct events within the video. Our
method effectively discovers diverse significant events within the video, with
the resulting captions appropriately describing these events. The empirical
results demonstrate that ZeroTA surpasses zero-shot baselines and even
outperforms the state-of-the-art few-shot method on the widely-used benchmark
ActivityNet Captions. Moreover, our method shows greater robustness compared to
supervised methods when evaluated in out-of-domain scenarios. This research
provides insight into the potential of aligning widely-used models, such as
language generation models and vision-language models, to unlock a new
capability: understanding temporal aspects of videos.
</p></li>
</ul>

<h3>Title: Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning. (arXiv:2307.03007v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03007">http://arxiv.org/abs/2307.03007</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03007] Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning](http://arxiv.org/abs/2307.03007) #robust</code></li>
<li>Summary: <p>Manual assembly workers face increasing complexity in their work.
Human-centered assistance systems could help, but object recognition as an
enabling technology hinders sophisticated human-centered design of these
systems. At the same time, activity recognition based on hand poses suffers
from poor pose estimation in complex usage scenarios, such as wearing gloves.
This paper presents a self-supervised pipeline for adapting hand pose
estimation to specific use cases with minimal human interaction. This enables
cheap and robust hand posebased activity recognition. The pipeline consists of
a general machine learning model for hand pose estimation trained on a
generalized dataset, spatial and temporal filtering to account for anatomical
constraints of the hand, and a retraining step to improve the model. Different
parameter combinations are evaluated on a publicly available and annotated
dataset. The best parameter and model combination is then applied to unlabelled
videos from a manual assembly scenario. The effectiveness of the pipeline is
demonstrated by training an activity recognition as a downstream task in the
manual assembly scenario.
</p></li>
</ul>

<h3>Title: Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification. (arXiv:2307.03133v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03133">http://arxiv.org/abs/2307.03133</a></li>
<li>Code URL: <a href="https://github.com/yuyongcan/benchmark-tta">https://github.com/yuyongcan/benchmark-tta</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03133] Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification](http://arxiv.org/abs/2307.03133) #robust</code></li>
<li>Summary: <p>Test-time adaptation (TTA) is a technique aimed at enhancing the
generalization performance of models by leveraging unlabeled samples solely
during prediction. Given the need for robustness in neural network systems when
faced with distribution shifts, numerous TTA methods have recently been
proposed. However, evaluating these methods is often done under different
settings, such as varying distribution shifts, backbones, and designing
scenarios, leading to a lack of consistent and fair benchmarks to validate
their effectiveness. To address this issue, we present a benchmark that
systematically evaluates 13 prominent TTA methods and their variants on five
widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C,
DomainNet, and Office-Home. These methods encompass a wide range of adaptation
scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation
v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the
compatibility of different TTA methods with diverse network backbones. To
implement this benchmark, we have developed a unified framework in PyTorch,
which allows for consistent evaluation and comparison of the TTA methods across
the different datasets and network architectures. By establishing this
benchmark, we aim to provide researchers and practitioners with a reliable
means of assessing and comparing the effectiveness of TTA methods in improving
model robustness and generalization performance. Our code is available at
https://github.com/yuyongcan/Benchmark-TTA.
</p></li>
</ul>

<h3>Title: LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias. (arXiv:2307.02912v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02912">http://arxiv.org/abs/2307.02912</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02912] LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias](http://arxiv.org/abs/2307.02912) #robust</code></li>
<li>Summary: <p>Textual noise, such as typos or abbreviations, is a well-known issue that
penalizes vanilla Transformers for most downstream tasks. We show that this is
also the case for sentence similarity, a fundamental task in multiple domains,
e.g. matching, retrieval or paraphrasing. Sentence similarity can be approached
using cross-encoders, where the two sentences are concatenated in the input
allowing the model to exploit the inter-relations between them. Previous works
addressing the noise issue mainly rely on data augmentation strategies, showing
improved robustness when dealing with corrupted samples that are similar to the
ones used for training. However, all these methods still suffer from the token
distribution shift induced by typos. In this work, we propose to tackle textual
noise by equipping cross-encoders with a novel LExical-aware Attention module
(LEA) that incorporates lexical similarities between words in both sentences.
By using raw text similarities, our approach avoids the tokenization shift
problem obtaining improved robustness. We demonstrate that the attention bias
introduced by LEA helps cross-encoders to tackle complex scenarios with textual
noise, specially in domains with short-text descriptions and limited context.
Experiments using three popular Transformer encoders in five e-commerce
datasets for product matching show that LEA consistently boosts performance
under the presence of noise, while remaining competitive on the original
(clean) splits. We also evaluate our approach in two datasets for textual
entailment and paraphrasing showing that LEA is robust to typos in domains with
longer sentences and more natural context. Additionally, we thoroughly analyze
several design choices in our approach, providing insights about the impact of
the decisions made and fostering future research in cross-encoders dealing with
typos.
</p></li>
</ul>

<h3>Title: BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training. (arXiv:2307.03131v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03131">http://arxiv.org/abs/2307.03131</a></li>
<li>Code URL: <a href="https://github.com/powerpuffpomelo/fairseq_mrt">https://github.com/powerpuffpomelo/fairseq_mrt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03131] BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training](http://arxiv.org/abs/2307.03131) #robust</code></li>
<li>Summary: <p>Automatic metrics play a crucial role in machine translation. Despite the
widespread use of n-gram-based metrics, there has been a recent surge in the
development of pre-trained model-based metrics that focus on measuring sentence
semantics. However, these neural metrics, while achieving higher correlations
with human evaluations, are often considered to be black boxes with potential
biases that are difficult to detect. In this study, we systematically analyze
and compare various mainstream and cutting-edge automatic metrics from the
perspective of their guidance for training machine translation systems. Through
Minimum Risk Training (MRT), we find that certain metrics exhibit robustness
defects, such as the presence of universal adversarial translations in BLEURT
and BARTScore. In-depth analysis suggests two main causes of these robustness
deficits: distribution biases in the training datasets, and the tendency of the
metric paradigm. By incorporating token-level constraints, we enhance the
robustness of evaluation metrics, which in turn leads to an improvement in the
performance of machine translation systems. Codes are available at
\url{https://github.com/powerpuffpomelo/fairseq_mrt}.
</p></li>
</ul>

<h3>Title: Kernels, Data &amp; Physics. (arXiv:2307.02693v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02693">http://arxiv.org/abs/2307.02693</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02693] Kernels, Data &amp; Physics](http://arxiv.org/abs/2307.02693) #robust</code></li>
<li>Summary: <p>Lecture notes from the course given by Professor Julia Kempe at the summer
school "Statistical physics of Machine Learning" in Les Houches. The notes
discuss the so-called NTK approach to problems in machine learning, which
consists of gaining an understanding of generally unsolvable problems by
finding a tractable kernel formulation. The notes are mainly focused on
practical applications such as data distillation and adversarial robustness,
examples of inductive bias are also discussed.
</p></li>
</ul>

<h3>Title: Understanding Uncertainty Sampling. (arXiv:2307.02719v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02719">http://arxiv.org/abs/2307.02719</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02719] Understanding Uncertainty Sampling](http://arxiv.org/abs/2307.02719) #robust</code></li>
<li>Summary: <p>Uncertainty sampling is a prevalent active learning algorithm that queries
sequentially the annotations of data samples which the current prediction model
is uncertain about. However, the usage of uncertainty sampling has been largely
heuristic: (i) There is no consensus on the proper definition of "uncertainty"
for a specific task under a specific loss; (ii) There is no theoretical
guarantee that prescribes a standard protocol to implement the algorithm, for
example, how to handle the sequentially arrived annotated data under the
framework of optimization algorithms such as stochastic gradient descent. In
this work, we systematically examine uncertainty sampling algorithms under both
stream-based and pool-based active learning. We propose a notion of equivalent
loss which depends on the used uncertainty measure and the original loss
function and establish that an uncertainty sampling algorithm essentially
optimizes against such an equivalent loss. The perspective verifies the
properness of existing uncertainty measures from two aspects: surrogate
property and loss convexity. Furthermore, we propose a new notion for designing
uncertainty measures called \textit{loss as uncertainty}. The idea is to use
the conditional expected loss given the features as the uncertainty measure.
Such an uncertainty measure has nice analytical properties and generality to
cover both classification and regression problems, which enable us to provide
the first generalization bound for uncertainty sampling algorithms under both
stream-based and pool-based settings, in the full generality of the underlying
model and problem. Lastly, we establish connections between certain variants of
the uncertainty sampling algorithms with risk-sensitive objectives and
distributional robustness, which can partly explain the advantage of
uncertainty sampling algorithms when the sample size is small.
</p></li>
</ul>

<h3>Title: Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?. (arXiv:2307.02732v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02732">http://arxiv.org/abs/2307.02732</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02732] Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?](http://arxiv.org/abs/2307.02732) #robust</code></li>
<li>Summary: <p>Numerous benchmarks for Few-Shot Learning have been proposed in the last
decade. However all of these benchmarks focus on performance averaged over many
tasks, and the question of how to reliably evaluate and tune models trained for
individual tasks in this regime has not been addressed. This paper presents the
first investigation into task-level evaluation -- a fundamental step when
deploying a model. We measure the accuracy of performance estimators in the
few-shot setting, consider strategies for model selection, and examine the
reasons for the failure of evaluators usually thought of as being robust. We
conclude that cross-validation with a low number of folds is the best choice
for directly estimating the performance of a model, whereas using bootstrapping
or cross validation with a large number of folds is better for model selection
purposes. Overall, we find that existing benchmarks for few-shot learning are
not designed in such a way that one can get a reliable picture of how
effectively methods can be used on individual tasks.
</p></li>
</ul>

<h3>Title: Beyond Intuition, a Framework for Applying GPs to Real-World Data. (arXiv:2307.03093v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03093">http://arxiv.org/abs/2307.03093</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03093] Beyond Intuition, a Framework for Applying GPs to Real-World Data](http://arxiv.org/abs/2307.03093) #robust</code></li>
<li>Summary: <p>Gaussian Processes (GPs) offer an attractive method for regression over
small, structured and correlated datasets. However, their deployment is
hindered by computational costs and limited guidelines on how to apply GPs
beyond simple low-dimensional datasets. We propose a framework to identify the
suitability of GPs to a given problem and how to set up a robust and
well-specified GP model. The guidelines formalise the decisions of experienced
GP practitioners, with an emphasis on kernel design and options for
computational scalability. The framework is then applied to a case study of
glacier elevation change yielding more accurate results at test time.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image Enhancement for Gastrointestinal Visual Question Answering. (arXiv:2307.02783v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02783">http://arxiv.org/abs/2307.02783</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02783] UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image Enhancement for Gastrointestinal Visual Question Answering](http://arxiv.org/abs/2307.02783) #extraction</code></li>
<li>Summary: <p>In recent years, artificial intelligence has played an important role in
medicine and disease diagnosis, with many applications to be mentioned, one of
which is Medical Visual Question Answering (MedVQA). By combining computer
vision and natural language processing, MedVQA systems can assist experts in
extracting relevant information from medical image based on a given question
and providing precise diagnostic answers. The ImageCLEFmed-MEDVQA-GI-2023
challenge carried out visual question answering task in the gastrointestinal
domain, which includes gastroscopy and colonoscopy images. Our team approached
Task 1 of the challenge by proposing a multimodal learning method with image
enhancement to improve the VQA performance on gastrointestinal images. The
multimodal architecture is set up with BERT encoder and different pre-trained
vision models based on convolutional neural network (CNN) and Transformer
architecture for features extraction from question and endoscopy image. The
result of this study highlights the dominance of Transformer-based vision
models over the CNNs and demonstrates the effectiveness of the image
enhancement process, with six out of the eight vision models achieving better
F1-Score. Our best method, which takes advantages of BERT+BEiT fusion and image
enhancement, achieves up to 87.25% accuracy and 91.85% F1-Score on the
development test set, while also producing good result on the private test set
with accuracy of 82.01%.
</p></li>
</ul>

<h3>Title: Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data. (arXiv:2307.02975v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02975">http://arxiv.org/abs/2307.02975</a></li>
<li>Code URL: <a href="https://github.com/mattiacampana/transfer-learning-covid-19">https://github.com/mattiacampana/transfer-learning-covid-19</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02975] Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data](http://arxiv.org/abs/2307.02975) #extraction</code></li>
<li>Summary: <p>Disease detection from smartphone data represents an open research challenge
in mobile health (m-health) systems. COVID-19 and its respiratory symptoms are
an important case study in this area and their early detection is a potential
real instrument to counteract the pandemic situation. The efficacy of this
solution mainly depends on the performances of AI algorithms applied to the
collected data and their possible implementation directly on the users' mobile
devices. Considering these issues, and the limited amount of available data, in
this paper we present the experimental evaluation of 3 different deep learning
models, compared also with hand-crafted features, and of two main approaches of
transfer learning in the considered scenario: both feature extraction and
fine-tuning. Specifically, we considered VGGish, YAMNET, and
L\textsuperscript{3}-Net (including 12 different configurations) evaluated
through user-independent experiments on 4 different datasets (13,447 samples in
total). Results clearly show the advantages of L\textsuperscript{3}-Net in all
the experimental settings as it overcomes the other solutions by 12.3\% in
terms of Precision-Recall AUC as features extractor, and by 10\% when the model
is fine-tuned. Moreover, we note that to fine-tune only the fully-connected
layers of the pre-trained models generally leads to worse performances, with an
average drop of 6.6\% with respect to feature extraction. %highlighting the
need for further investigations. Finally, we evaluate the memory footprints of
the different models for their possible applications on commercial mobile
devices.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FLuID: Mitigating Stragglers in Federated Learning using Invariant Dropout. (arXiv:2307.02623v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02623">http://arxiv.org/abs/2307.02623</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02623] FLuID: Mitigating Stragglers in Federated Learning using Invariant Dropout](http://arxiv.org/abs/2307.02623) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) allows machine learning models to train locally on
individual mobile devices, synchronizing model updates via a shared server.
This approach safeguards user privacy; however, it also generates a
heterogeneous training environment due to the varying performance capabilities
across devices. As a result, straggler devices with lower performance often
dictate the overall training time in FL. In this work, we aim to alleviate this
performance bottleneck due to stragglers by dynamically balancing the training
load across the system. We introduce Invariant Dropout, a method that extracts
a sub-model based on the weight update threshold, thereby minimizing potential
impacts on accuracy. Building on this dropout technique, we develop an adaptive
training framework, Federated Learning using Invariant Dropout (FLuID). FLuID
offers a lightweight sub-model extraction to regulate computational intensity,
thereby reducing the load on straggler devices without affecting model quality.
Our method leverages neuron updates from non-straggler devices to construct a
tailored sub-model for each straggler based on client performance profiling.
Furthermore, FLuID can dynamically adapt to changes in stragglers as runtime
conditions shift. We evaluate FLuID using five real-world mobile clients. The
evaluations show that Invariant Dropout maintains baseline model efficiency
while alleviating the performance bottleneck of stragglers through a dynamic,
runtime approach.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: The Role of Subgroup Separability in Group-Fair Medical Image Classification. (arXiv:2307.02791v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02791">http://arxiv.org/abs/2307.02791</a></li>
<li>Code URL: <a href="https://github.com/biomedia-mira/subgroup-separability">https://github.com/biomedia-mira/subgroup-separability</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02791] The Role of Subgroup Separability in Group-Fair Medical Image Classification](http://arxiv.org/abs/2307.02791) #fair</code></li>
<li>Summary: <p>We investigate performance disparities in deep classifiers. We find that the
ability of classifiers to separate individuals into subgroups varies
substantially across medical imaging modalities and protected characteristics;
crucially, we show that this property is predictive of algorithmic bias.
Through theoretical analysis and extensive empirical evaluation, we find a
relationship between subgroup separability, subgroup disparities, and
performance degradation when models are trained on data with systematic bias
such as underdiagnosis. Our findings shed new light on the question of how
models become biased, providing important insights for the development of fair
medical imaging AI.
</p></li>
</ul>

<h3>Title: Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?. (arXiv:2307.03157v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03157">http://arxiv.org/abs/2307.03157</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03157] Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?](http://arxiv.org/abs/2307.03157) #fair</code></li>
<li>Summary: <p>Deep learning-based diagnostic system has demonstrated potential in
classifying skin cancer conditions when labeled training example are abundant.
However, skin lesion analysis often suffers from a scarcity of labeled data,
hindering the development of an accurate and reliable diagnostic system. In
this work, we leverage multiple skin lesion datasets and investigate the
feasibility of various unsupervised domain adaptation (UDA) methods in binary
and multi-class skin lesion classification. In particular, we assess three UDA
training schemes: single-, combined-, and multi-source. Our experiment results
show that UDA is effective in binary classification, with further improvement
being observed when imbalance is mitigated. In multi-class task, its
performance is less prominent, and imbalance problem again needs to be
addressed to achieve above-baseline accuracy. Through our quantitative
analysis, we find that the test error of multi-class tasks is strongly
correlated with label shift, and feature-level UDA methods have limitations
when handling imbalanced datasets. Finally, our study reveals that UDA can
effectively reduce bias against minority groups and promote fairness, even
without the explicit use of fairness-focused techniques.
</p></li>
</ul>

<h3>Title: BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables. (arXiv:2307.02891v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02891">http://arxiv.org/abs/2307.02891</a></li>
<li>Code URL: <a href="https://github.com/babe-algorithm/babe">https://github.com/babe-algorithm/babe</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02891] BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables](http://arxiv.org/abs/2307.02891) #fair</code></li>
<li>Summary: <p>We consider the problem of unfair discrimination between two groups and
propose a pre-processing method to achieve fairness. Corrective methods like
statistical parity usually lead to bad accuracy and do not really achieve
fairness in situations where there is a correlation between the sensitive
attribute S and the legitimate attribute E (explanatory variable) that should
determine the decision. To overcome these drawbacks, other notions of fairness
have been proposed, in particular, conditional statistical parity and equal
opportunity. However, E is often not directly observable in the data, i.e., it
is a latent variable. We may observe some other variable Z representing E, but
the problem is that Z may also be affected by S, hence Z itself can be biased.
To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an
approach based on a combination of Bayes inference and the
Expectation-Maximization method, to estimate the most likely value of E for a
given Z for each group. The decision can then be based directly on the
estimated E. We show, by experiments on synthetic and real data sets, that our
approach provides a good level of fairness as well as high accuracy.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Wasserstein Auto-Encoders of Merge Trees (and Persistence Diagrams). (arXiv:2307.02509v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02509">http://arxiv.org/abs/2307.02509</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02509] Wasserstein Auto-Encoders of Merge Trees (and Persistence Diagrams)](http://arxiv.org/abs/2307.02509) #interpretability</code></li>
<li>Summary: <p>This paper presents a computational framework for the Wasserstein
auto-encoding of merge trees (MT-WAE), a novel extension of the classical
auto-encoder neural network architecture to the Wasserstein metric space of
merge trees. In contrast to traditional auto-encoders which operate on
vectorized data, our formulation explicitly manipulates merge trees on their
associated metric space at each layer of the network, resulting in superior
accuracy and interpretability. Our novel neural network approach can be
interpreted as a non-linear generalization of previous linear attempts [65] at
merge tree encoding. It also trivially extends to persistence diagrams.
Extensive experiments on public ensembles demonstrate the efficiency of our
algorithms, with MT-WAE computations in the orders of minutes on average. We
show the utility of our contributions in two applications adapted from previous
work on merge tree encoding [65]. First, we apply MT-WAE to data reduction and
reliably compress merge trees by concisely representing them with their
coordinates in the final layer of our auto-encoder. Second, we document an
application to dimensionality reduction, by exploiting the latent space of our
auto-encoder, for the visual analysis of ensemble data. We illustrate the
versatility of our framework by introducing two penalty terms, to help preserve
in the latent space both the Wasserstein distances between merge trees, as well
as their clusters. In both applications, quantitative experiments assess the
relevance of our framework. Finally, we provide a C++ implementation that can
be used for reproducibility.
</p></li>
</ul>

<h3>Title: Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning. (arXiv:2307.02689v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02689">http://arxiv.org/abs/2307.02689</a></li>
<li>Code URL: <a href="https://github.com/ibm/loa">https://github.com/ibm/loa</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02689] Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning](http://arxiv.org/abs/2307.02689) #interpretability</code></li>
<li>Summary: <p>Text-based reinforcement learning agents have predominantly been neural
network-based models with embeddings-based representation, learning
uninterpretable policies that often do not generalize well to unseen games. On
the other hand, neuro-symbolic methods, specifically those that leverage an
intermediate formal representation, are gaining significant attention in
language understanding tasks. This is because of their advantages ranging from
inherent interpretability, the lesser requirement of training data, and being
generalizable in scenarios with unseen data. Therefore, in this paper, we
propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic
semantic parser with a rule induction system to learn abstract interpretable
rules as policies. Our experiments on established text-based game benchmarks
show that the proposed NESTA method outperforms deep reinforcement
learning-based techniques by achieving better generalization to unseen test
games and learning from fewer training interactions.
</p></li>
</ul>

<h3>Title: Generalizing Backpropagation for Gradient-Based Interpretability. (arXiv:2307.03056v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03056">http://arxiv.org/abs/2307.03056</a></li>
<li>Code URL: <a href="https://github.com/kdu4108/brunoflow">https://github.com/kdu4108/brunoflow</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03056] Generalizing Backpropagation for Gradient-Based Interpretability](http://arxiv.org/abs/2307.03056) #interpretability</code></li>
<li>Summary: <p>Many popular feature-attribution methods for interpreting deep neural
networks rely on computing the gradients of a model's output with respect to
its inputs. While these methods can indicate which input features may be
important for the model's prediction, they reveal little about the inner
workings of the model itself. In this paper, we observe that the gradient
computation of a model is a special case of a more general formulation using
semirings. This observation allows us to generalize the backpropagation
algorithm to efficiently compute other interpretable statistics about the
gradient graph of a neural network, such as the highest-weighted path and
entropy. We implement this generalized algorithm, evaluate it on synthetic
datasets to better understand the statistics it computes, and apply it to study
BERT's behavior on the subject-verb number agreement task (SVA). With this
method, we (a) validate that the amount of gradient flow through a component of
a model reflects its importance to a prediction and (b) for SVA, identify which
pathways of the self-attention mechanism are most important.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Origin-Destination Travel Time Oracle for Map-based Services. (arXiv:2307.03048v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03048">http://arxiv.org/abs/2307.03048</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03048] Origin-Destination Travel Time Oracle for Map-based Services](http://arxiv.org/abs/2307.03048) #explainability</code></li>
<li>Summary: <p>Given an origin (O), a destination (D), and a departure time (T), an
Origin-Destination (OD) travel time oracle~(ODT-Oracle) returns an estimate of
the time it takes to travel from O to D when departing at T. ODT-Oracles serve
important purposes in map-based services. To enable the construction of such
oracles, we provide a travel-time estimation (TTE) solution that leverages
historical trajectories to estimate time-varying travel times for OD pairs.
</p></li>
</ul>

<p>The problem is complicated by the fact that multiple historical trajectories
with different travel times may connect an OD pair, while trajectories may vary
from one another. To solve the problem, it is crucial to remove outlier
trajectories when doing travel time estimation for future queries.
</p>
<p>We propose a novel, two-stage framework called Diffusion-based
Origin-destination Travel Time Estimation (DOT), that solves the problem.
First, DOT employs a conditioned Pixelated Trajectories (PiT) denoiser that
enables building a diffusion-based PiT inference process by learning
correlations between OD pairs and historical trajectories. Specifically, given
an OD pair and a departure time, we aim to infer a PiT. Next, DOT encompasses a
Masked Vision Transformer~(MViT) that effectively and efficiently estimates a
travel time based on the inferred PiT. We report on extensive experiments on
two real-world datasets that offer evidence that DOT is capable of
outperforming baseline methods in terms of accuracy, scalability, and
explainability.
</p>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Applying a Color Palette with Local Control using Diffusion Models. (arXiv:2307.02698v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02698">http://arxiv.org/abs/2307.02698</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02698] Applying a Color Palette with Local Control using Diffusion Models](http://arxiv.org/abs/2307.02698) #diffusion</code></li>
<li>Summary: <p>We demonstrate two novel editing procedures in the context of fantasy card
art. Palette transfer applies a specified reference palette to a given card.
For fantasy art, the desired change in palette can be very large, leading to
huge changes in the "look" of the art. We demonstrate that a pipeline of vector
quantization; matching; and "vector dequantization" (using a diffusion model)
produces successful extreme palette transfers. Segment control allows an artist
to move one or more image segments, and to optionally specify the desired color
of the result. The combination of these two types of edit yields valuable
workflows, including: move a segment, then recolor; recolor, then force some
segments to take a prescribed color. We demonstrate our methods on the
challenging Yu-Gi-Oh card art dataset.
</p></li>
</ul>

<h3>Title: Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback. (arXiv:2307.02770v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02770">http://arxiv.org/abs/2307.02770</a></li>
<li>Code URL: <a href="https://github.com/tetrzim/diffusion-human-feedback">https://github.com/tetrzim/diffusion-human-feedback</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02770] Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback](http://arxiv.org/abs/2307.02770) #diffusion</code></li>
<li>Summary: <p>Diffusion models have recently shown remarkable success in high-quality image
generation. Sometimes, however, a pre-trained diffusion model exhibits partial
misalignment in the sense that the model can generate good images, but it
sometimes outputs undesirable images. If so, we simply need to prevent the
generation of the bad images, and we call this task censoring. In this work, we
present censored generation with a pre-trained diffusion model using a reward
model trained on minimal human feedback. We show that censoring can be
accomplished with extreme human feedback efficiency and that labels generated
with a mere few minutes of human feedback are sufficient. Code available at:
https://github.com/tetrzim/diffusion-human-feedback.
</p></li>
</ul>

<h3>Title: Single Image LDR to HDR Conversion using Conditional Diffusion. (arXiv:2307.02814v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02814">http://arxiv.org/abs/2307.02814</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02814] Single Image LDR to HDR Conversion using Conditional Diffusion](http://arxiv.org/abs/2307.02814) #diffusion</code></li>
<li>Summary: <p>Digital imaging aims to replicate realistic scenes, but Low Dynamic Range
(LDR) cameras cannot represent the wide dynamic range of real scenes, resulting
in under-/overexposed images. This paper presents a deep learning-based
approach for recovering intricate details from shadows and highlights while
reconstructing High Dynamic Range (HDR) images. We formulate the problem as an
image-to-image (I2I) translation task and propose a conditional Denoising
Diffusion Probabilistic Model (DDPM) based framework using classifier-free
guidance. We incorporate a deep CNN-based autoencoder in our proposed framework
to enhance the quality of the latent representation of the input LDR image used
for conditioning. Moreover, we introduce a new loss function for LDR-HDR
translation tasks, termed Exposure Loss. This loss helps direct gradients in
the opposite direction of the saturation, further improving the results'
quality. By conducting comprehensive quantitative and qualitative experiments,
we have effectively demonstrated the proficiency of our proposed method. The
results indicate that a simple conditional diffusion-based method can replace
the complex camera pipeline-based architectures.
</p></li>
</ul>

<h3>Title: Bundle-specific Tractogram Distribution Estimation Using Higher-order Streamline Differential Equation. (arXiv:2307.02825v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02825">http://arxiv.org/abs/2307.02825</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02825] Bundle-specific Tractogram Distribution Estimation Using Higher-order Streamline Differential Equation](http://arxiv.org/abs/2307.02825) #diffusion</code></li>
<li>Summary: <p>Tractography traces the peak directions extracted from fiber orientation
distribution (FOD) suffering from ambiguous spatial correspondences between
diffusion directions and fiber geometry, which is prone to producing erroneous
tracks while missing true positive connections. The peaks-based tractography
methods 'locally' reconstructed streamlines in 'single to single' manner, thus
lacking of global information about the trend of the whole fiber bundle. In
this work, we propose a novel tractography method based on a bundle-specific
tractogram distribution function by using a higher-order streamline
differential equation, which reconstructs the streamline bundles in 'cluster to
cluster' manner. A unified framework for any higher-order streamline
differential equation is presented to describe the fiber bundles with disjoint
streamlines defined based on the diffusion tensor vector field. At the global
level, the tractography process is simplified as the estimation of
bundle-specific tractogram distribution (BTD) coefficients by minimizing the
energy optimization model, and is used to characterize the relations between
BTD and diffusion tensor vector under the prior guidance by introducing the
tractogram bundle information to provide anatomic priors. Experiments are
performed on simulated Hough, Sine, Circle data, ISMRM 2015 Tractography
Challenge data, FiberCup data, and in vivo data from the Human Connectome
Project (HCP) data for qualitative and quantitative evaluation. The results
demonstrate that our approach can reconstruct the complex global fiber bundles
directly. BTD reduces the error deviation and accumulation at the local level
and shows better results in reconstructing long-range, twisting, and large
fanning tracts.
</p></li>
</ul>

<h3>Title: A Critical Look at the Current Usage of Foundation Model for Dense Recognition Task. (arXiv:2307.02862v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02862">http://arxiv.org/abs/2307.02862</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02862] A Critical Look at the Current Usage of Foundation Model for Dense Recognition Task](http://arxiv.org/abs/2307.02862) #diffusion</code></li>
<li>Summary: <p>In recent years large model trained on huge amount of cross-modality data,
which is usually be termed as foundation model, achieves conspicuous
accomplishment in many fields, such as image recognition and generation. Though
achieving great success in their original application case, it is still unclear
whether those foundation models can be applied to other different downstream
tasks. In this paper, we conduct a short survey on the current methods for
discriminative dense recognition tasks, which are built on the pretrained
foundation model. And we also provide some preliminary experimental analysis of
an existing open-vocabulary segmentation method based on Stable Diffusion,
which indicates the current way of deploying diffusion model for segmentation
is not optimal. This aims to provide insights for future research on adopting
foundation model for downstream task.
</p></li>
</ul>

<h3>Title: On the Cultural Gap in Text-to-Image Generation. (arXiv:2307.02971v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02971">http://arxiv.org/abs/2307.02971</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02971] On the Cultural Gap in Text-to-Image Generation](http://arxiv.org/abs/2307.02971) #diffusion</code></li>
<li>Summary: <p>One challenge in text-to-image (T2I) generation is the inadvertent reflection
of culture gaps present in the training data, which signifies the disparity in
generated image quality when the cultural elements of the input text are rarely
collected in the training set. Although various T2I models have shown
impressive but arbitrary examples, there is no benchmark to systematically
evaluate a T2I model's ability to generate cross-cultural images. To bridge the
gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive
evaluation criteria, which can assess how well-suited a model is to a target
culture. By analyzing the flawed images generated by the Stable Diffusion model
on the C3 benchmark, we find that the model often fails to generate certain
cultural objects. Accordingly, we propose a novel multi-modal metric that
considers object-text alignment to filter the fine-tuning data in the target
culture, which is used to fine-tune a T2I model to improve cross-cultural
generation. Experimental results show that our multi-modal metric provides
stronger data selection performance on the C3 benchmark than existing metrics,
in which the object-text alignment is crucial. We release the benchmark, data,
code, and generated images to facilitate future research on culturally diverse
T2I generation (https://github.com/longyuewangdcu/C3-Bench).
</p></li>
</ul>

<h3>Title: How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models. (arXiv:2307.03108v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03108">http://arxiv.org/abs/2307.03108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03108] How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models](http://arxiv.org/abs/2307.03108) #diffusion</code></li>
<li>Summary: <p>Recent text-to-image diffusion models have shown surprising performance in
generating high-quality images. However, concerns have arisen regarding the
unauthorized usage of data during the training process. One example is when a
model trainer collects a set of images created by a particular artist and
attempts to train a model capable of generating similar images without
obtaining permission from the artist. To address this issue, it becomes crucial
to detect unauthorized data usage. In this paper, we propose a method for
detecting such unauthorized data usage by planting injected memorization into
the text-to-image diffusion models trained on the protected dataset.
Specifically, we modify the protected image dataset by adding unique contents
on the images such as stealthy image wrapping functions that are imperceptible
to human vision but can be captured and memorized by diffusion models. By
analyzing whether the model has memorization for the injected content (i.e.,
whether the generated images are processed by the chosen post-processing
function), we can detect models that had illegally utilized the unauthorized
data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate
the effectiveness of the proposed method in detecting unauthorized data usages.
</p></li>
</ul>

<h3>Title: IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model. (arXiv:2307.03177v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03177">http://arxiv.org/abs/2307.03177</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03177] IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model](http://arxiv.org/abs/2307.03177) #diffusion</code></li>
<li>Summary: <p>Generating complete 360-degree panoramas from narrow field of view images is
ongoing research as omnidirectional RGB data is not readily available. Existing
GAN-based approaches face some barriers to achieving higher quality output, and
have poor generalization performance over different mask types. In this paper,
we present our 360-degree indoor RGB panorama outpainting model using latent
diffusion models (LDM), called IPO-LDM. We introduce a new bi-modal latent
diffusion structure that utilizes both RGB and depth panoramic data during
training, but works surprisingly well to outpaint normal depth-free RGB images
during inference. We further propose a novel technique of introducing
progressive camera rotations during each diffusion denoising step, which leads
to substantial improvement in achieving panorama wraparound consistency.
Results show that our IPO-LDM not only significantly outperforms
state-of-the-art methods on RGB panorama outpainting, but can also produce
multiple and diverse well-structured results for different types of masks.
</p></li>
</ul>

<h3>Title: Diffusion Models for Computational Design at the Example of Floor Plans. (arXiv:2307.02511v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02511">http://arxiv.org/abs/2307.02511</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02511] Diffusion Models for Computational Design at the Example of Floor Plans](http://arxiv.org/abs/2307.02511) #diffusion</code></li>
<li>Summary: <p>AI Image generators based on diffusion models are widely discussed recently
for their capability to create images from simple text prompts. But, for
practical use in civil engineering they need to be able to create specific
construction plans for given constraints. Within this paper we explore the
capabilities of those diffusion-based AI generators for computational design at
the example of floor plans and identify their current limitation. We explain
how the diffusion-models work and propose new diffusion models with improved
semantic encoding. In several experiments we show that we can improve validity
of generated floor plans from 6% to 90% and query performance for different
examples. We identify short comings and derive future research challenges of
those models and discuss the need to combine diffusion models with building
information modelling. With this we provide key insights into the current state
and future directions for diffusion models in civil engineering.
</p></li>
</ul>

<h3>Title: Towards Symmetry-Aware Generation of Periodic Materials. (arXiv:2307.02707v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02707">http://arxiv.org/abs/2307.02707</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02707] Towards Symmetry-Aware Generation of Periodic Materials](http://arxiv.org/abs/2307.02707) #diffusion</code></li>
<li>Summary: <p>We consider the problem of generating periodic materials with deep models.
While symmetry-aware molecule generation has been studied extensively, periodic
materials possess different symmetries, which have not been completely captured
by existing methods. In this work, we propose SyMat, a novel material
generation approach that can capture physical symmetries of periodic material
structures. SyMat generates atom types and lattices of materials through
generating atom type sets, lattice lengths and lattice angles with a
variational auto-encoder model. In addition, SyMat employs a score-based
diffusion model to generate atom coordinates of materials, in which a novel
symmetry-aware probabilistic model is used in the coordinate diffusion process.
We show that SyMat is theoretically invariant to all symmetry transformations
on materials and demonstrate that SyMat achieves promising performance on
random generation and property optimization tasks.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: ZJU ReLER Submission for EPIC-KITCHEN Challenge 2023: TREK-150 Single Object Tracking. (arXiv:2307.02508v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02508">http://arxiv.org/abs/2307.02508</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02508] ZJU ReLER Submission for EPIC-KITCHEN Challenge 2023: TREK-150 Single Object Tracking](http://arxiv.org/abs/2307.02508) #transformer</code></li>
<li>Summary: <p>The Associating Objects with Transformers (AOT) framework has exhibited
exceptional performance in a wide range of complex scenarios for video object
tracking and segmentation. In this study, we convert the bounding boxes to
masks in reference frames with the help of the Segment Anything Model (SAM) and
Alpha-Refine, and then propagate the masks to the current frame, transforming
the task from Video Object Tracking (VOT) to video object segmentation (VOS).
Furthermore, we introduce MSDeAOT, a variant of the AOT series that
incorporates transformers at multiple feature scales. MSDeAOT efficiently
propagates object masks from previous frames to the current frame using two
feature scales of 16 and 8. As a testament to the effectiveness of our design,
we achieved the 1st place in the EPIC-KITCHENS TREK-150 Object Tracking
Challenge.
</p></li>
</ul>

<h3>Title: DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning. (arXiv:2307.02935v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02935">http://arxiv.org/abs/2307.02935</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02935] DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning](http://arxiv.org/abs/2307.02935) #transformer</code></li>
<li>Summary: <p>Asymmetry is a crucial characteristic of bilateral mammograms (Bi-MG) when
abnormalities are developing. It is widely utilized by radiologists for
diagnosis. The question of 'what the symmetrical Bi-MG would look like when the
asymmetrical abnormalities have been removed ?' has not yet received strong
attention in the development of algorithms on mammograms. Addressing this
question could provide valuable insights into mammographic anatomy and aid in
diagnostic interpretation. Hence, we propose a novel framework, DisAsymNet,
which utilizes asymmetrical abnormality transformer guided self-adversarial
learning for disentangling abnormalities and symmetric Bi-MG. At the same time,
our proposed method is partially guided by randomly synthesized abnormalities.
We conduct experiments on three public and one in-house dataset, and
demonstrate that our method outperforms existing methods in abnormality
classification, segmentation, and localization tasks. Additionally,
reconstructed normal mammograms can provide insights toward better
interpretable visual cues for clinical diagnosis. The code will be accessible
to the public.
</p></li>
</ul>

<h3>Title: Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution. (arXiv:2307.02974v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02974">http://arxiv.org/abs/2307.02974</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02974] Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution](http://arxiv.org/abs/2307.02974) #transformer</code></li>
<li>Summary: <p>Remote sensing image super-resolution (RSISR) plays a vital role in enhancing
spatial detials and improving the quality of satellite imagery. Recently,
Transformer-based models have shown competitive performance in RSISR. To
mitigate the quadratic computational complexity resulting from global
self-attention, various methods constrain attention to a local window,
enhancing its efficiency. Consequently, the receptive fields in a single
attention layer are inadequate, leading to insufficient context modeling.
Furthermore, while most transform-based approaches reuse shallow features
through skip connections, relying solely on these connections treats shallow
and deep features equally, impeding the model's ability to characterize them.
To address these issues, we propose a novel transformer architecture called
Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based
Transformer Network (SPIFFNet) for RSISR. Our proposed model effectively
enhances global cognition and understanding of the entire image, facilitating
efficient integration of features cross-stages. The model incorporates
cross-spatial pixel integration attention (CSPIA) to introduce contextual
information into a local window, while cross-stage feature fusion attention
(CSFFA) adaptively fuses features from the previous stage to improve feature
expression in line with the requirements of the current stage. We conducted
comprehensive experiments on multiple benchmark datasets, demonstrating the
superior performance of our proposed SPIFFNet in terms of both quantitative
metrics and visual quality when compared to state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Art Authentication with Vision Transformers. (arXiv:2307.03039v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03039">http://arxiv.org/abs/2307.03039</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03039] Art Authentication with Vision Transformers](http://arxiv.org/abs/2307.03039) #transformer</code></li>
<li>Summary: <p>In recent years, Transformers, initially developed for language, have been
successfully applied to visual tasks. Vision Transformers have been shown to
push the state-of-the-art in a wide range of tasks, including image
classification, object detection, and semantic segmentation. While ample
research has shown promising results in art attribution and art authentication
tasks using Convolutional Neural Networks, this paper examines if the
superiority of Vision Transformers extends to art authentication, improving,
thus, the reliability of computer-based authentication of artworks. Using a
carefully compiled dataset of authentic paintings by Vincent van Gogh and two
contrast datasets, we compare the art authentication performances of Swin
Transformers with those of EfficientNet. Using a standard contrast set
containing imitations and proxies (works by painters with styles closely
related to van Gogh), we find that EfficientNet achieves the best performance
overall. With a contrast set that only consists of imitations, we find the Swin
Transformer to be superior to EfficientNet by achieving an authentication
accuracy of over 85%. These results lead us to conclude that Vision
Transformers represent a strong and promising contender in art authentication,
particularly in enhancing the computer-based ability to detect artistic
imitations.
</p></li>
</ul>

<h3>Title: Contrast Is All You Need. (arXiv:2307.02882v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02882">http://arxiv.org/abs/2307.02882</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02882] Contrast Is All You Need](http://arxiv.org/abs/2307.02882) #transformer</code></li>
<li>Summary: <p>In this study, we analyze data-scarce classification scenarios, where
available labeled legal data is small and imbalanced, potentially hurting the
quality of the results. We focused on two finetuning objectives; SetFit
(Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla
finetuning setup on a legal provision classification task. Additionally, we
compare the features that are extracted with LIME (Local Interpretable
Model-agnostic Explanations) to see which particular features contributed to
the model's classification decisions. The results show that a contrastive setup
with SetFit performed better than vanilla finetuning while using a fraction of
the training samples. LIME results show that the contrastive learning approach
helps boost both positive and negative features which are legally informative
and contribute to the classification results. Thus a model finetuned with a
contrastive objective seems to base its decisions more confidently on legally
informative features.
</p></li>
</ul>

<h3>Title: Agentivit`a e telicit`a in GilBERTo: implicazioni cognitive. (arXiv:2307.02910v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02910">http://arxiv.org/abs/2307.02910</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02910] Agentivit\</code>a e telicit`a in GilBERTo: implicazioni cognitive](http://arxiv.org/abs/2307.02910) #transformer`</li>
<li>Summary: <p>The goal of this study is to investigate whether a Transformer-based neural
language model infers lexical semantics and use this information for the
completion of morphosyntactic patterns. The semantic properties considered are
telicity (also combined with definiteness) and agentivity. Both act at the
interface between semantics and morphosyntax: they are semantically determined
and syntactically encoded. The tasks were submitted to both the computational
model and a group of Italian native speakers. The comparison between the two
groups of data allows us to investigate to what extent neural language models
capture significant aspects of human semantic competence.
</p></li>
</ul>

<h3>Title: Focused Transformer: Contrastive Training for Context Scaling. (arXiv:2307.03170v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03170">http://arxiv.org/abs/2307.03170</a></li>
<li>Code URL: <a href="https://github.com/cstankonrad/long_llama">https://github.com/cstankonrad/long_llama</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03170] Focused Transformer: Contrastive Training for Context Scaling](http://arxiv.org/abs/2307.03170) #transformer</code></li>
<li>Summary: <p>Large language models have an exceptional capability to incorporate new
information in a contextual manner. However, the full potential of such an
approach is often restrained due to a limitation in the effective context
length. One solution to this issue is to endow an attention layer with access
to an external memory, which comprises of (key, value) pairs. Yet, as the
number of documents increases, the proportion of relevant keys to irrelevant
ones decreases, leading the model to focus more on the irrelevant keys. We
identify a significant challenge, dubbed the distraction issue, where keys
linked to different semantic values might overlap, making them hard to
distinguish. To tackle this problem, we introduce the Focused Transformer
(FoT), a technique that employs a training process inspired by contrastive
learning. This novel approach enhances the structure of the (key, value) space,
enabling an extension of the context length. Our method allows for fine-tuning
pre-existing, large-scale models to lengthen their effective context. This is
demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The
resulting models, which we name LongLLaMA, exhibit advancements in tasks
requiring a long context. We further illustrate that our LongLLaMA models
adeptly manage a $256 k$ context length for passkey retrieval.
</p></li>
</ul>

<h3>Title: Multimodal Temporal Fusion Transformers Are Good Product Demand Forecasters. (arXiv:2307.02578v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02578">http://arxiv.org/abs/2307.02578</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02578] Multimodal Temporal Fusion Transformers Are Good Product Demand Forecasters](http://arxiv.org/abs/2307.02578) #transformer</code></li>
<li>Summary: <p>Multimodal demand forecasting aims at predicting product demand utilizing
visual, textual, and contextual information. This paper proposes a method for
multimodal product demand forecasting using convolutional, graph-based, and
transformer-based architectures. Traditional approaches to demand forecasting
rely on historical demand, product categories, and additional contextual
information such as seasonality and events. However, these approaches have
several shortcomings, such as the cold start problem making it difficult to
predict product demand until sufficient historical data is available for a
particular product, and their inability to properly deal with category
dynamics. By incorporating multimodal information, such as product images and
textual descriptions, our architecture aims to address the shortcomings of
traditional approaches and outperform them. The experiments conducted on a
large real-world dataset show that the proposed approach effectively predicts
demand for a wide range of products. The multimodal pipeline presented in this
work enhances the accuracy and reliability of the predictions, demonstrating
the potential of leveraging multimodal information in product demand
forecasting.
</p></li>
</ul>

<h3>Title: TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers. (arXiv:2307.02588v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02588">http://arxiv.org/abs/2307.02588</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02588] TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers](http://arxiv.org/abs/2307.02588) #transformer</code></li>
<li>Summary: <p>Dynamic graph embedding has emerged as a very effective technique for
addressing diverse temporal graph analytic tasks (i.e., link prediction, node
classification, recommender systems, anomaly detection, and graph generation)
in various applications. Such temporal graphs exhibit heterogeneous transient
dynamics, varying time intervals, and highly evolving node features throughout
their evolution. Hence, incorporating long-range dependencies from the
historical graph context plays a crucial role in accurately learning their
temporal dynamics. In this paper, we develop a graph embedding model with
uncertainty quantification, TransformerG2G, by exploiting the advanced
transformer encoder to first learn intermediate node representations from its
current state ($t$) and previous context (over timestamps [$t-1, t-l$], $l$ is
the length of context). Moreover, we employ two projection layers to generate
lower-dimensional multivariate Gaussian distributions as each node's latent
embedding at timestamp $t$. We consider diverse benchmarks with varying levels
of ``novelty" as measured by the TEA plots. Our experiments demonstrate that
the proposed TransformerG2G model outperforms conventional multi-step methods
and our prior work (DynG2G) in terms of both link prediction accuracy and
computational efficiency, especially for high degree of novelty. Furthermore,
the learned time-dependent attention weights across multiple graph snapshots
reveal the development of an automatic adaptive time stepping enabled by the
transformer. Importantly, by examining the attention weights, we can uncover
temporal dependencies, identify influential elements, and gain insights into
the complex interactions within the graph structure. For example, we identified
a strong correlation between attention weights and node degree at the various
stages of the graph topology evolution.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: MomentDiff: Generative Video Moment Retrieval from Random to Real. (arXiv:2307.02869v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02869">http://arxiv.org/abs/2307.02869</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02869] MomentDiff: Generative Video Moment Retrieval from Random to Real](http://arxiv.org/abs/2307.02869) #generative</code></li>
<li>Summary: <p>Video moment retrieval pursues an efficient and generalized solution to
identify the specific temporal segments within an untrimmed video that
correspond to a given language description. To achieve this goal, we provide a
generative diffusion-based framework called MomentDiff, which simulates a
typical human retrieval process from random browsing to gradual localization.
Specifically, we first diffuse the real span to random noise, and learn to
denoise the random noise to the original span with the guidance of similarity
between text and video. This allows the model to learn a mapping from arbitrary
random locations to real moments, enabling the ability to locate segments from
random initialization. Once trained, MomentDiff could sample random temporal
segments as initial guesses and iteratively refine them to generate an accurate
temporal boundary. Different from discriminative works (e.g., based on
learnable proposals or queries), MomentDiff with random initialized spans could
resist the temporal location biases from datasets. To evaluate the influence of
the temporal location biases, we propose two anti-bias datasets with location
distribution shifts, named Charades-STA-Len and Charades-STA-Mom. The
experimental results demonstrate that our efficient framework consistently
outperforms state-of-the-art methods on three public benchmarks, and exhibits
better generalization and robustness on the proposed anti-bias datasets. The
code, model, and anti-bias evaluation datasets are available at
https://github.com/IMCCretrieval/MomentDiff.
</p></li>
</ul>

<h3>Title: Multi-modal multi-class Parkinson disease classification using CNN and decision level fusion. (arXiv:2307.02978v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02978">http://arxiv.org/abs/2307.02978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02978] Multi-modal multi-class Parkinson disease classification using CNN and decision level fusion](http://arxiv.org/abs/2307.02978) #generative</code></li>
<li>Summary: <p>Parkinson disease is the second most common neurodegenerative disorder, as
reported by the World Health Organization. In this paper, we propose a direct
three-Class PD classification using two different modalities, namely, MRI and
DTI. The three classes used for classification are PD, Scans Without Evidence
of Dopamine Deficit and Healthy Control. We use white matter and gray matter
from the MRI and fractional anisotropy and mean diffusivity from the DTI to
achieve our goal. We train four separate CNNs on the above four types of data.
At the decision level, the outputs of the four CNN models are fused with an
optimal weighted average fusion technique. We achieve an accuracy of 95.53
percentage for the direct three class classification of PD, HC and SWEDD on the
publicly available PPMI database. Extensive comparisons including a series of
ablation studies clearly demonstrate the effectiveness of our proposed
solution.
</p></li>
</ul>

<h3>Title: Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting. (arXiv:2307.02830v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02830">http://arxiv.org/abs/2307.02830</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02830] Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting](http://arxiv.org/abs/2307.02830) #generative</code></li>
<li>Summary: <p>Zero-shot cross-domain slot filling aims to transfer knowledge from the
labeled source domain to the unlabeled target domain. Existing models either
encode slot descriptions and examples or design handcrafted question templates
using heuristic rules, suffering from poor generalization capability or
robustness. In this paper, we propose a generative zero-shot prompt learning
framework for cross-domain slot filling, both improving generalization and
robustness than previous work. Besides, we introduce a novel inverse prompting
strategy to distinguish different slot types to avoid the multiple prediction
problem, and an efficient prompt-tuning strategy to boost higher performance by
only training fewer prompt parameters. Experiments and analysis demonstrate the
effectiveness of our proposed framework, especially huge improvements (+13.44%
F1) on the unseen slots.
</p></li>
</ul>

<h3>Title: Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation. (arXiv:2307.02839v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02839">http://arxiv.org/abs/2307.02839</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02839] Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation](http://arxiv.org/abs/2307.02839) #generative</code></li>
<li>Summary: <p>News summary generation is an important task in the field of intelligence
analysis, which can provide accurate and comprehensive information to help
people better understand and respond to complex real-world events. However,
traditional news summary generation methods face some challenges, which are
limited by the model itself and the amount of training data, as well as the
influence of text noise, making it difficult to generate reliable information
accurately. In this paper, we propose a new paradigm for news summary
generation using LLM with powerful natural language understanding and
generative capabilities. We use LLM to extract multiple structured event
patterns from the events contained in news paragraphs, evolve the event pattern
population with genetic algorithm, and select the most adaptive event pattern
to input into the LLM to generate news summaries. A News Summary Generator
(NSG) is designed to select and evolve the event pattern populations and
generate news summaries. The experimental results show that the news summary
generator is able to generate accurate and reliable news summaries with some
generalization ability.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding. (arXiv:2307.02499v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02499">http://arxiv.org/abs/2307.02499</a></li>
<li>Code URL: <a href="https://github.com/x-plug/mplug-docowl">https://github.com/x-plug/mplug-docowl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02499] mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding](http://arxiv.org/abs/2307.02499) #large language model</code></li>
<li>Summary: <p>Document understanding refers to automatically extract, analyze and
comprehend information from various types of digital documents, such as a web
page. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl,
have demonstrated promising zero-shot capabilities in shallow OCR-free text
recognition, indicating their potential for OCR-free document understanding.
Nevertheless, without in-domain training, these models tend to ignore
fine-grained OCR features, such as sophisticated tables or large blocks of
text, which are essential for OCR-free document understanding. In this paper,
we propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding.
Specifically, we first construct a instruction tuning dataset featuring a wide
range of visual-text understanding tasks. Then, we strengthen the OCR-free
document understanding ability by jointly train the model on language-only,
general vision-and-language, and document instruction tuning dataset with our
unified instruction tuning strategy. We also build an OCR-free document
instruction understanding evaluation set LLMDoc to better compare models'
capabilities on instruct compliance and document understanding. Experimental
results show that our model outperforms existing multi-modal models,
demonstrating its strong ability of document understanding. Besides, without
specific fine-tuning, mPLUG-DocOwl generalizes well on various downstream
tasks. Our code, models, training data and evaluation set are available at
https://github.com/X-PLUG/mPLUG-DocOwl.
</p></li>
</ul>

<h3>Title: SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference. (arXiv:2307.02628v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02628">http://arxiv.org/abs/2307.02628</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02628] SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference](http://arxiv.org/abs/2307.02628) #large language model</code></li>
<li>Summary: <p>Autoregressive large language models (LLMs) have made remarkable progress in
various natural language generation tasks. However, they incur high computation
cost and latency resulting from the autoregressive token-by-token generation.
To address this issue, several approaches have been proposed to reduce
computational cost using early-exit strategies. These strategies enable faster
text generation using reduced computation without applying the full computation
graph to each token. While existing token-level early exit methods show
promising results for online inference, they cannot be readily applied for
batch inferencing and Key-Value caching. This is because they have to wait
until the last token in a batch exits before they can stop computing. This
severely limits the practical application of such techniques. In this paper, we
propose a simple and effective token-level early exit method, SkipDecode,
designed to work seamlessly with batch inferencing and KV caching. It overcomes
prior constraints by setting up a singular exit point for every token in a
batch at each sequence position. It also guarantees a monotonic decrease in
exit points, thereby eliminating the need to recompute KV Caches for preceding
tokens. Rather than terminating computation prematurely as in prior works, our
approach bypasses lower to middle layers, devoting most of the computational
resources to upper layers, allowing later tokens to benefit from the compute
expenditure by earlier tokens. Our experimental results show that SkipDecode
can obtain 2x to 5x inference speedups with negligible regression across a
variety of tasks. This is achieved using OPT models of 1.3 billion and 6.7
billion parameters, all the while being directly compatible with batching and
KV caching optimization techniques.
</p></li>
</ul>

<h3>Title: Scaling In-Context Demonstrations with Structured Attention. (arXiv:2307.02690v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02690">http://arxiv.org/abs/2307.02690</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02690] Scaling In-Context Demonstrations with Structured Attention](http://arxiv.org/abs/2307.02690) #large language model</code></li>
<li>Summary: <p>The recent surge of large language models (LLMs) highlights their ability to
perform in-context learning, i.e., "learning" to perform a task from a few
demonstrations in the context without any parameter updates. However, their
capabilities of in-context learning are limited by the model architecture: 1)
the use of demonstrations is constrained by a maximum sentence length due to
positional embeddings; 2) the quadratic complexity of attention hinders users
from using more demonstrations efficiently; 3) LLMs are shown to be sensitive
to the order of the demonstrations. In this work, we tackle these challenges by
proposing a better architectural design for in-context learning. We propose
SAICL (Structured Attention for In-Context Learning), which replaces the
full-attention by a structured attention mechanism designed for in-context
learning, and removes unnecessary dependencies between individual
demonstrations, while making the model invariant to the permutation of
demonstrations. We evaluate SAICL in a meta-training framework and show that
SAICL achieves comparable or better performance than full attention while
obtaining up to 3.4x inference speed-up. SAICL also consistently outperforms a
strong Fusion-in-Decoder (FiD) baseline which processes each demonstration
independently. Finally, thanks to its linear nature, we demonstrate that SAICL
can easily scale to hundreds of demonstrations with continuous performance
gains with scaling.
</p></li>
</ul>

<h3>Title: Text Alignment Is An Efficient Unified Model for Massive NLP Tasks. (arXiv:2307.02729v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02729">http://arxiv.org/abs/2307.02729</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02729] Text Alignment Is An Efficient Unified Model for Massive NLP Tasks](http://arxiv.org/abs/2307.02729) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs), typically designed as a function of next-word
prediction, have excelled across extensive NLP tasks. Despite the generality,
next-word prediction is often not an efficient formulation for many of the
tasks, demanding an extreme scale of model parameters (10s or 100s of billions)
and sometimes yielding suboptimal performance. In practice, it is often
desirable to build more efficient models -- despite being less versatile, they
still apply to a substantial subset of problems, delivering on par or even
superior performance with much smaller model sizes. In this paper, we propose
text alignment as an efficient unified model for a wide range of crucial tasks
involving text entailment, similarity, question answering (and answerability),
factual consistency, and so forth. Given a pair of texts, the model measures
the degree of alignment between their information. We instantiate an alignment
model (Align) through lightweight finetuning of RoBERTa (355M parameters) using
5.9M examples from 28 datasets. Despite its compact size, extensive experiments
show the model's efficiency and strong performance: (1) On over 20 datasets of
aforementioned diverse tasks, the model matches or surpasses FLAN-T5 models
that have around 2x or 10x more parameters; the single unified model also
outperforms task-specific models finetuned on individual datasets; (2) When
applied to evaluate factual consistency of language generation on 23 datasets,
our model improves over various baselines, including the much larger GPT-3.5
(ChatGPT) and sometimes even GPT-4; (3) The lightweight model can also serve as
an add-on component for LLMs such as GPT-3.5 in question answering tasks,
improving the average exact match (EM) score by 17.94 and F1 score by 15.05
through identifying unanswerable questions.
</p></li>
</ul>

<h3>Title: PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations. (arXiv:2307.02762v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02762">http://arxiv.org/abs/2307.02762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02762] PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations](http://arxiv.org/abs/2307.02762) #large language model</code></li>
<li>Summary: <p>Nowadays, the quality of responses generated by different modern large
language models (LLMs) are hard to evaluate and compare automatically. Recent
studies suggest and predominantly use LLMs as a reference-free metric for
open-ended question answering. More specifically, they use the recognized
"strongest" LLM as the evaluator, which conducts pairwise comparisons of
candidate models' answers and provides a ranking score. However, this intuitive
method has multiple problems, such as bringing in self-enhancement (favoring
its own answers) and positional bias. We draw insights and lessons from the
educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based
evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that
takes into account each peer LLM's pairwise preferences of all answer pairs,
and outputs a final ranking of models; and (2) peer discussion (PD), where we
prompt two LLMs to discuss and try to reach a mutual agreement on preferences
of two answers. We conduct experiments on two benchmark datasets. We find that
our approaches achieve higher accuracy and align better with human judgments,
respectively. Interestingly, PR can induce a relatively accurate self-ranking
of models under the anonymous setting, where each model's name is unrevealed.
Our work provides space to explore evaluating models that are hard to compare
for humans.
</p></li>
</ul>

<h3>Title: Style Over Substance: Evaluation Biases for Large Language Models. (arXiv:2307.03025v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03025">http://arxiv.org/abs/2307.03025</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03025] Style Over Substance: Evaluation Biases for Large Language Models](http://arxiv.org/abs/2307.03025) #large language model</code></li>
<li>Summary: <p>As large language models (LLMs) continue to advance, accurately and
comprehensively evaluating their performance becomes increasingly challenging.
Conventionally, human evaluations are considered the gold standard in natural
language generation. Recent advancements incorporate state-of-the-art LLMs as
proxies for human judges in evaluation processes. Nonetheless, the extent to
which humans and LLMs are capable evaluators remains uncertain. This study aims
to investigate the behavior of both crowd-sourced human and LLM-based judges
when comparing outputs from different models. To accomplish this, we curate a
dataset comprising intentionally flawed machine-generated answers. Our findings
indicate that despite the potentially greater danger posed by factual errors,
answers with factual errors were still rated more favorably compared to answers
that were too short or contained grammatical errors. This highlights a
concerning bias in the evaluation process. To address this issue, we propose to
independently evaluate machine-generated text across multiple dimensions,
rather than merging all the evaluation aspects into a single score. We
instantiate this idea with the Elo rating system, resulting in the Multi-Elo
Rating System. Empirical results from our study reveal that this proposed
approach significantly enhances the quality of LLM-based evaluations,
particularly in terms of factual accuracy. However, notable improvement is not
observed in crowd-sourced-based evaluations, suggesting the need for further
investigation and refinement.
</p></li>
</ul>

<h3>Title: Improving Retrieval-Augmented Large Language Models via Data Importance Learning. (arXiv:2307.03027v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03027">http://arxiv.org/abs/2307.03027</a></li>
<li>Code URL: <a href="https://github.com/amsterdata/ragbooster">https://github.com/amsterdata/ragbooster</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03027] Improving Retrieval-Augmented Large Language Models via Data Importance Learning](http://arxiv.org/abs/2307.03027) #large language model</code></li>
<li>Summary: <p>Retrieval augmentation enables large language models to take advantage of
external knowledge, for example on tasks like question answering and data
imputation. However, the performance of such retrieval-augmented models is
limited by the data quality of their underlying retrieval corpus. In this
paper, we propose an algorithm based on multilinear extension for evaluating
the data importance of retrieved data points. There are exponentially many
terms in the multilinear extension, and one key contribution of this paper is a
polynomial time algorithm that computes exactly, given a retrieval-augmented
model with an additive utility function and a validation set, the data
importance of data points in the retrieval corpus using the multilinear
extension of the model's utility function. We further proposed an even more
efficient ({\epsilon}, {\delta})-approximation algorithm. Our experimental
results illustrate that we can enhance the performance of large language models
by only pruning or reweighting the retrieval corpus, without requiring further
training. For some tasks, this even allows a small model (e.g., GPT-JT),
augmented with a search engine API, to outperform GPT-3.5 (without retrieval
augmentation). Moreover, we show that weights based on multilinear extension
can be computed efficiently in practice (e.g., in less than ten minutes for a
corpus with 100 million elements).
</p></li>
</ul>

<h3>Title: A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.03109">http://arxiv.org/abs/2307.03109</a></li>
<li>Code URL: <a href="https://github.com/mlgroupjlu/llm-eval-survey">https://github.com/mlgroupjlu/llm-eval-survey</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.03109] A Survey on Evaluation of Large Language Models](http://arxiv.org/abs/2307.03109) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the <code>where' and</code>how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: GNEP Based Dynamic Segmentation and Motion Estimation for Neuromorphic Imaging. (arXiv:2307.02595v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02595">http://arxiv.org/abs/2307.02595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02595] GNEP Based Dynamic Segmentation and Motion Estimation for Neuromorphic Imaging](http://arxiv.org/abs/2307.02595) #segmentation</code></li>
<li>Summary: <p>This paper explores the application of event-based cameras in the domains of
image segmentation and motion estimation. These cameras offer a groundbreaking
technology by capturing visual information as a continuous stream of
asynchronous events, departing from the conventional frame-based image
acquisition. We introduce a Generalized Nash Equilibrium based framework that
leverages the temporal and spatial information derived from the event stream to
carry out segmentation and velocity estimation. To establish the theoretical
foundations, we derive an existence criteria and propose a multi-level
optimization method for calculating equilibrium. The efficacy of this approach
is shown through a series of experiments.
</p></li>
</ul>

<h3>Title: Spherical Feature Pyramid Networks For Semantic Segmentation. (arXiv:2307.02658v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02658">http://arxiv.org/abs/2307.02658</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02658] Spherical Feature Pyramid Networks For Semantic Segmentation](http://arxiv.org/abs/2307.02658) #segmentation</code></li>
<li>Summary: <p>Semantic segmentation for spherical data is a challenging problem in machine
learning since conventional planar approaches require projecting the spherical
image to the Euclidean plane. Representing the signal on a fundamentally
different topology introduces edges and distortions which impact network
performance. Recently, graph-based approaches have bypassed these challenges to
attain significant improvements by representing the signal on a spherical mesh.
Current approaches to spherical segmentation exclusively use variants of the
UNet architecture, meaning more successful planar architectures remain
unexplored. Inspired by the success of feature pyramid networks (FPNs) in
planar image segmentation, we leverage the pyramidal hierarchy of graph-based
spherical CNNs to design spherical FPNs. Our spherical FPN models show
consistent improvements over spherical UNets, whilst using fewer parameters. On
the Stanford 2D-3D-S dataset, our models achieve state-of-the-art performance
with an mIOU of 48.75, an improvement of 3.75 IoU points over the previous best
spherical CNN.
</p></li>
</ul>

<h3>Title: Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning. (arXiv:2307.02798v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02798">http://arxiv.org/abs/2307.02798</a></li>
<li>Code URL: <a href="https://github.com/hritam-98/gfda-disentangled">https://github.com/hritam-98/gfda-disentangled</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02798] Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning](http://arxiv.org/abs/2307.02798) #segmentation</code></li>
<li>Summary: <p>Although unsupervised domain adaptation (UDA) is a promising direction to
alleviate domain shift, they fall short of their supervised counterparts. In
this work, we investigate relatively less explored semi-supervised domain
adaptation (SSDA) for medical image segmentation, where access to a few labeled
target samples can improve the adaptation performance substantially.
Specifically, we propose a two-stage training process. First, an encoder is
pre-trained in a self-learning paradigm using a novel domain-content
disentangled contrastive learning (CL) along with a pixel-level feature
consistency constraint. The proposed CL enforces the encoder to learn
discriminative content-specific but domain-invariant semantics on a global
scale from the source and target images, whereas consistency regularization
enforces the mining of local pixel-level information by maintaining spatial
sensitivity. This pre-trained encoder, along with a decoder, is further
fine-tuned for the downstream task, (i.e. pixel-level segmentation) using a
semi-supervised setting. Furthermore, we experimentally validate that our
proposed method can easily be extended for UDA settings, adding to the
superiority of the proposed strategy. Upon evaluation on two domain adaptive
image segmentation tasks, our proposed method outperforms the SoTA methods,
both in SSDA and UDA settings. Code is available at
https://github.com/hritam-98/GFDA-disentangled
</p></li>
</ul>

<h3>Title: Towards accurate instance segmentation in large-scale LiDAR point clouds. (arXiv:2307.02877v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.02877">http://arxiv.org/abs/2307.02877</a></li>
<li>Code URL: <a href="https://github.com/bxiang233/panopticsegforlargescalepointcloud">https://github.com/bxiang233/panopticsegforlargescalepointcloud</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.02877] Towards accurate instance segmentation in large-scale LiDAR point clouds](http://arxiv.org/abs/2307.02877) #segmentation</code></li>
<li>Summary: <p>Panoptic segmentation is the combination of semantic and instance
segmentation: assign the points in a 3D point cloud to semantic categories and
partition them into distinct object instances. It has many obvious applications
for outdoor scene understanding, from city mapping to forest management.
Existing methods struggle to segment nearby instances of the same semantic
category, like adjacent pieces of street furniture or neighbouring trees, which
limits their usability for inventory- or management-type applications that rely
on object instances. This study explores the steps of the panoptic segmentation
pipeline concerned with clustering points into object instances, with the goal
to alleviate that bottleneck. We find that a carefully designed clustering
strategy, which leverages multiple types of learned point embeddings,
significantly improves instance segmentation. Experiments on the NPM3D urban
mobile mapping dataset and the FOR-instance forest dataset demonstrate the
effectiveness and versatility of the proposed strategy.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
