<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Privacy Preserving Ultra-Short-term Wind Power Prediction Based on Secure Multi Party Computation. (arXiv:2301.13513v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13513">http://arxiv.org/abs/2301.13513</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13513] Privacy Preserving Ultra-Short-term Wind Power Prediction Based on Secure Multi Party Computation](http://arxiv.org/abs/2301.13513) #secure</code></li>
<li>Summary: <p>Mining the spatial and temporal correlation of wind farm output data is
beneficial for enhancing the precision of ultra-short-term wind power
prediction. However, if the wind farms are owned by separate entities, they may
be reluctant to share their data directly due to privacy concerns as well as
business management regulation policies. Although cryptographic approaches have
been designed to protect privacy in the process of data sharing, it is still a
challenging problem to encrypt the original data while extracting the nonlinear
relationship among multiple wind farms in the machine learning process. This
paper presents pwXGBoost, a technique based on the machine learning tree model
and secure multi-party computation (SMPC) that can successfully extract
complicated relationships while preserving data privacy. A maximum mean
discrepancy (MMD) based scheme is proposed to effectively choose adjacent
candidate wind farms to participate in the collaborative model training,
therefore improving the accuracy and reducing the burden of data acquisition.
The proposed method was evaluated on real world data collected from a cluster
of wind farms in Inner Mongolia, China, demonstrating that it is capable of
achieving considerable efficiency and performance improvements while preserving
privacy
</p></li>
</ul>

<h2>security</h2>
<h3>Title: A Survey on Digital Twins: Architecture, Enabling Technologies, Security and Privacy, and Future Prospects. (arXiv:2301.13350v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13350">http://arxiv.org/abs/2301.13350</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13350] A Survey on Digital Twins: Architecture, Enabling Technologies, Security and Privacy, and Future Prospects](http://arxiv.org/abs/2301.13350) #security</code></li>
<li>Summary: <p>By interacting, synchronizing, and cooperating with its physical counterpart
in real time, digital twin is promised to promote an intelligent, predictive,
and optimized modern city. Via interconnecting massive physical entities and
their virtual twins with inter-twin and intra-twin communications, the Internet
of digital twins (IoDT) enables free data exchange, dynamic mission
cooperation, and efficient information aggregation for composite insights
across vast physical/virtual entities. However, as IoDT incorporates various
cutting-edge technologies to spawn the new ecology, severe known/unknown
security flaws and privacy invasions of IoDT hinders its wide deployment.
Besides, the intrinsic characteristics of IoDT such as \emph{decentralized
structure}, \emph{information-centric routing} and \emph{semantic
communications} entail critical challenges for security service provisioning in
IoDT. To this end, this paper presents an in-depth review of the IoDT with
respect to system architecture, enabling technologies, and security/privacy
issues. Specifically, we first explore a novel distributed IoDT architecture
with cyber-physical interactions and discuss its key characteristics and
communication modes. Afterward, we investigate the taxonomy of security and
privacy threats in IoDT, discuss the key research challenges, and review the
state-of-the-art defense approaches. Finally, we point out the new trends and
open research directions related to IoDT.
</p></li>
</ul>

<h3>Title: MOAT: Towards Safe BPF Kernel Extension. (arXiv:2301.13421v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13421">http://arxiv.org/abs/2301.13421</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13421] MOAT: Towards Safe BPF Kernel Extension](http://arxiv.org/abs/2301.13421) #security</code></li>
<li>Summary: <p>The Linux kernel makes considerable use of Berkeley Packet Filter (BPF) to
allow user-written BPF applications to execute in the kernel space. BPF employs
a verifier to statically check the security of user-supplied BPF code. Recent
attacks show that BPF programs can evade security checks and gain unauthorized
access to kernel memory, indicating that the verification process is not
flawless. In this paper, we present MOAT, a system that isolates potentially
malicious BPF programs using Intel Memory Protection Keys (MPK). Enforcing BPF
program isolation with MPK is not straightforward; MOAT is carefully designed
to alleviate technical obstacles, such as limited hardware keys and supporting
a wide variety of kernel BPF helper functions. We have implemented MOAT in a
prototype kernel module, and our evaluation shows that MOAT delivers low-cost
isolation of BPF programs under various real-world usage scenarios, such as the
isolation of a packet-forwarding BPF program for the memcached database with an
average throughput loss of 6%.
</p></li>
</ul>

<h3>Title: Machine Learning and Port Scans: A Systematic Review. (arXiv:2301.13581v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13581">http://arxiv.org/abs/2301.13581</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13581] Machine Learning and Port Scans: A Systematic Review](http://arxiv.org/abs/2301.13581) #security</code></li>
<li>Summary: <p>Port scanning is the process of attempting to connect to various network
ports on a computing endpoint to determine which ports are open and which
services are running on them. It is a common method used by hackers to identify
vulnerabilities in a network or system. By determining which ports are open, an
attacker can identify which services and applications are running on a device
and potentially exploit any known vulnerabilities in those services.
Consequently, it is important to detect port scanning because it is often the
first step in a cyber attack. By identifying port scanning attempts,
cybersecurity professionals can take proactive measures to protect the systems
and networks before an attacker has a chance to exploit any vulnerabilities.
Against this background, researchers have worked for over a decade to develop
robust methods to detect port scanning. While there have been various surveys,
none have focused solely on machine learning based detection schemes specific
to port scans. Accordingly, we provide a systematic review of 15 papers
published between February 2021 and January 2023. We extract critical
information such as training dataset, algorithm used, technique, and model
accuracy. We also collect unresolved challenges and ideas for future work. The
outcomes are significant for researchers looking to step off from the latest
work and for practitioners interested in novel mechanisms to detect the early
stages of cyber attack.
</p></li>
</ul>

<h3>Title: HoRStify: Sound Security Analysis of Smart Contracts. (arXiv:2301.13769v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13769">http://arxiv.org/abs/2301.13769</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13769] HoRStify: Sound Security Analysis of Smart Contracts](http://arxiv.org/abs/2301.13769) #security</code></li>
<li>Summary: <p>The cryptocurrency Ethereum is the most widely used execution platform for
smart contracts. Smart contracts are distributed applications, which govern
financial assets and, hence, can implement advanced financial instruments, such
as decentralized exchanges or autonomous organizations (DAOs). Their financial
nature makes smart contracts an attractive attack target, as demonstrated by
numerous exploits on popular contracts resulting in financial damage of
millions of dollars. This omnipresent attack hazard motivates the need for
sound static analysis tools, which assist smart contract developers in
eliminating contract vulnerabilities a priori to deployment. Vulnerability
assessment that is sound and insightful for EVM contracts is a formidable
challenge because contracts execute low-level bytecode in a largely unknown and
potentially hostile execution environment. So far, there exists no provably
sound automated analyzer that allows for the verification of security
properties based on program dependencies, even though prevalent attack classes
fall into this category. In this work, we present HoRStify, the first automated
analyzer for dependency properties of Ethereum smart contracts based on sound
static analysis. HoRStify grounds its soundness proof on a formal proof
framework for static program slicing that we instantiate to the semantics of
EVM bytecode. We demonstrate that HoRStify is flexible enough to soundly verify
the absence of famous attack classes such as timestamp dependency and, at the
same time, performant enough to analyze real-world smart contracts.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition. (arXiv:2301.13384v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13384">http://arxiv.org/abs/2301.13384</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13384] GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition](http://arxiv.org/abs/2301.13384) #privacy</code></li>
<li>Summary: <p>mmWave radar-based gait recognition is a novel user identification method
that captures human gait biometrics from mmWave radar return signals. This
technology offers privacy protection and is resilient to weather and lighting
conditions. However, its generalization performance is yet unknown and limits
its practical deployment. To address this problem, in this paper, a
non-synthetic dataset is collected and analyzed to reveal the presence of
spatial and temporal domain shifts in mmWave gait biometric data, which
significantly impacts identification accuracy. To address this issue, a novel
self-aligned domain adaptation method called GaitSADA is proposed. GaitSADA
improves system generalization performance by using a two-stage semi-supervised
model training approach. The first stage uses semi-supervised contrastive
learning and the second stage uses semi-supervised consistency training with
centroid alignment. Extensive experiments show that GaitSADA outperforms
representative domain adaptation methods by an average of 15.41% in low data
regimes.
</p></li>
</ul>

<h3>Title: Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation. (arXiv:2301.13428v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13428">http://arxiv.org/abs/2301.13428</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13428] Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation](http://arxiv.org/abs/2301.13428) #privacy</code></li>
<li>Summary: <p>Domain adaptation has attracted a great deal of attention in the machine
learning community, but it requires access to source data, which often raises
concerns about data privacy. We are thus motivated to address these issues and
propose a simple yet efficient method. This work treats domain adaptation as an
unsupervised clustering problem and trains the target model without access to
the source data. Specifically, we propose a loss function called contrast and
clustering (CaC), where a positive pair term pulls neighbors belonging to the
same class together in the feature space to form clusters, while a negative
pair term pushes samples of different classes apart. In addition, extended
neighbors are taken into account by querying the nearest neighbor indexes in
the memory bank to mine for more valuable negative pairs. Extensive experiments
on three common benchmarks, VisDA, Office-Home and Office-31, demonstrate that
our method achieves state-of-the-art performance. The code will be made
publicly available at https://github.com/yukilulu/CaC.
</p></li>
</ul>

<h3>Title: The Fair Value of Data Under Heterogeneous Privacy Constraints. (arXiv:2301.13336v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13336">http://arxiv.org/abs/2301.13336</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13336] The Fair Value of Data Under Heterogeneous Privacy Constraints](http://arxiv.org/abs/2301.13336) #privacy</code></li>
<li>Summary: <p>Modern data aggregation often takes the form of a platform collecting data
from a network of users. More than ever, these users are now requesting that
the data they provide is protected with a guarantee of privacy. This has led to
the study of optimal data acquisition frameworks, where the optimality
criterion is typically the maximization of utility for the agent trying to
acquire the data. This involves determining how to allocate payments to users
for the purchase of their data at various privacy levels. The main goal of this
paper is to characterize a fair amount to pay users for their data at a given
privacy level. We propose an axiomatic definition of fairness, analogous to the
celebrated Shapley value. Two concepts for fairness are introduced. The first
treats the platform and users as members of a common coalition and provides a
complete description of how to divide the utility among the platform and users.
In the second concept, fairness is defined only among users, leading to a
potential fairness-constrained mechanism design problem for the platform. We
consider explicit examples involving private heterogeneous data and show how
these notions of fairness can be applied. To the best of our knowledge, these
are the first fairness concepts for data that explicitly consider privacy
constraints.
</p></li>
</ul>

<h3>Title: Tight Data Access Bounds for Private Top-$k$ Selection. (arXiv:2301.13347v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13347">http://arxiv.org/abs/2301.13347</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13347] Tight Data Access Bounds for Private Top-$k$ Selection](http://arxiv.org/abs/2301.13347) #privacy</code></li>
<li>Summary: <p>We study the top-$k$ selection problem under the differential privacy model:
$m$ items are rated according to votes of a set of clients. We consider a
setting in which algorithms can retrieve data via a sequence of accesses, each
either a random access or a sorted access; the goal is to minimize the total
number of data accesses. Our algorithm requires only $O(\sqrt{mk})$ expected
accesses: to our knowledge, this is the first sublinear data-access upper bound
for this problem. Accompanying this, we develop the first lower bounds for the
problem, in three settings: only random accesses; only sorted acceses; a
sequence of accesses of either kind. We show that, to avoid $\Omega(m)$ access
cost, supporting \emph{either} kind of access, i.e. the freedom to mix, is
necessary, and that in this case our algorithm's access cost is almost optimal.
</p></li>
</ul>

<h3>Title: Privacy-Preserving Online Sharing Charging Pile Scheme with Different Needs Matching. (arXiv:2301.13511v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13511">http://arxiv.org/abs/2301.13511</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13511] Privacy-Preserving Online Sharing Charging Pile Scheme with Different Needs Matching](http://arxiv.org/abs/2301.13511) #privacy</code></li>
<li>Summary: <p>With the development of electric vehicles, more and more electric vehicles
have difficulties in parking and charging. One of the reasons is that the
number of charging piles is difficult to support the energy supply of electric
vehicles, and a large number of private charging piles have a long idle time,
so the energy supply problem of electric vehicles can be solved by sharing
charging piles. The shared charging pile scheme uses Paillier encryption scheme
and improved scheme to effectively protect user data. The scheme has
homomorphism of addition and subtraction, and can process information without
decryption. However, considering that different users have different needs, the
matching is carried out after calculating the needs put forward by users. This
scheme can effectively protect users' privacy and provide matching mechanisms
with different requirements, so that users can better match the appropriate
charging piles. The final result shows that its efficiency is better than the
original Paillier scheme, and it can also meet the security requirements.
</p></li>
</ul>

<h3>Title: Differentially Private Kernel Inducing Points (DP-KIP) for Privacy-preserving Data Distillation. (arXiv:2301.13389v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13389">http://arxiv.org/abs/2301.13389</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13389] Differentially Private Kernel Inducing Points (DP-KIP) for Privacy-preserving Data Distillation](http://arxiv.org/abs/2301.13389) #privacy</code></li>
<li>Summary: <p>While it is tempting to believe that data distillation preserves privacy,
distilled data's empirical robustness against known attacks does not imply a
provable privacy guarantee. Here, we develop a provably privacy-preserving data
distillation algorithm, called differentially private kernel inducing points
(DP-KIP). DP-KIP is an instantiation of DP-SGD on kernel ridge regression
(KRR). Following a recent work, we use neural tangent kernels and minimize the
KRR loss to estimate the distilled datapoints (i.e., kernel inducing points).
We provide a computationally efficient JAX implementation of DP-KIP, which we
test on several popular image and tabular datasets to show its efficacy in data
distillation with differential privacy guarantees.
</p></li>
</ul>

<h3>Title: A Bayesian Generative Adversarial Network (GAN) to Generate Synthetic Time-Series Data, Application in Combined Sewer Flow Prediction. (arXiv:2301.13733v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13733">http://arxiv.org/abs/2301.13733</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13733] A Bayesian Generative Adversarial Network (GAN) to Generate Synthetic Time-Series Data, Application in Combined Sewer Flow Prediction](http://arxiv.org/abs/2301.13733) #privacy</code></li>
<li>Summary: <p>Despite various breakthroughs in machine learning and data analysis
techniques for improving smart operation and management of urban water
infrastructures, some key limitations obstruct this progress. Among these
shortcomings, the absence of freely available data due to data privacy or high
costs of data gathering and the nonexistence of adequate rare or extreme events
in the available data plays a crucial role. Here, Generative Adversarial
Networks (GANs) can help overcome these challenges. In machine learning,
generative models are a class of methods capable of learning data distribution
to generate artificial data. In this study, we developed a GAN model to
generate synthetic time series to balance our limited recorded time series data
and improve the accuracy of a data-driven model for combined sewer flow
prediction. We considered the sewer system of a small town in Germany as the
test case. Precipitation and inflow to the storage tanks are used for the
Data-Driven model development. The aim is to predict the flow using
precipitation data and examine the impact of data augmentation using synthetic
data in model performance. Results show that GAN can successfully generate
synthetic time series from real data distribution, which helps more accurate
peak flow prediction. However, the model without data augmentation works better
for dry weather prediction. Therefore, an ensemble model is suggested to
combine the advantages of both models.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression. (arXiv:2301.13838v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13838">http://arxiv.org/abs/2301.13838</a></li>
<li>Code URL: <a href="https://github.com/liuzrcc/ImageShortcutSqueezing">https://github.com/liuzrcc/ImageShortcutSqueezing</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13838] Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression](http://arxiv.org/abs/2301.13838) #defense</code></li>
<li>Summary: <p>Perturbative availability poisoning (PAP) adds small changes to images to
prevent their use for model training. Current research adopts the belief that
practical and effective approaches to countering such poisons do not exist. In
this paper, we argue that it is time to abandon this belief. We present
extensive experiments showing that 12 state-of-the-art PAP methods are
vulnerable to Image Shortcut Squeezing (ISS), which is based on simple
compression. For example, on average, ISS restores the CIFAR-10 model accuracy
to $81.73\%$, surpassing the previous best preprocessing-based countermeasures
by $37.97\%$ absolute. ISS also (slightly) outperforms adversarial training and
has higher generalizability to unseen perturbation norms and also higher
efficiency. Our investigation reveals that the property of PAP perturbations
depends on the type of surrogate model used for poison generation, and it
explains why a specific ISS compression yields the best performance for a
specific type of PAP perturbation. We further test stronger, adaptive
poisoning, and show it falls short of being an ideal defense against ISS.
Overall, our results demonstrate the importance of considering various (simple)
countermeasures to ensure the meaningfulness of analysis carried out during the
development of availability poisons.
</p></li>
</ul>

<h3>Title: Are Defenses for Graph Neural Networks Robust?. (arXiv:2301.13694v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13694">http://arxiv.org/abs/2301.13694</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13694] Are Defenses for Graph Neural Networks Robust?](http://arxiv.org/abs/2301.13694) #defense</code></li>
<li>Summary: <p>A cursory reading of the literature suggests that we have made a lot of
progress in designing effective adversarial defenses for Graph Neural Networks
(GNNs). Yet, the standard methodology has a serious flaw - virtually all of the
defenses are evaluated against non-adaptive attacks leading to overly
optimistic robustness estimates. We perform a thorough robustness analysis of 7
of the most popular defenses spanning the entire spectrum of strategies, i.e.,
aimed at improving the graph, the architecture, or the training. The results
are sobering - most defenses show no or only marginal improvement compared to
an undefended baseline. We advocate using custom adaptive attacks as a gold
standard and we outline the lessons we learned from successfully designing such
attacks. Moreover, our diverse collection of perturbed graphs forms a
(black-box) unit test offering a first glance at a model's robustness.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Inference Time Evidences of Adversarial Attacks for Forensic on Transformers. (arXiv:2301.13356v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13356">http://arxiv.org/abs/2301.13356</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13356] Inference Time Evidences of Adversarial Attacks for Forensic on Transformers](http://arxiv.org/abs/2301.13356) #attack</code></li>
<li>Summary: <p>Vision Transformers (ViTs) are becoming a very popular paradigm for vision
tasks as they achieve state-of-the-art performance on image classification.
However, although early works implied that this network structure had increased
robustness against adversarial attacks, some works argue ViTs are still
vulnerable. This paper presents our first attempt toward detecting adversarial
attacks during inference time using the network's input and outputs as well as
latent features. We design four quantifications (or derivatives) of input,
output, and latent vectors of ViT-based models that provide a signature of the
inference, which could be beneficial for the attack detection, and empirically
study their behavior over clean samples and adversarial samples. The results
demonstrate that the quantifications from input (images) and output (posterior
probabilities) are promising for distinguishing clean and adversarial samples,
while latent vectors offer less discriminative power, though they give some
insights on how adversarial perturbations work.
</p></li>
</ul>

<h3>Title: Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks. (arXiv:2301.13487v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13487">http://arxiv.org/abs/2301.13487</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13487] Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks](http://arxiv.org/abs/2301.13487) #attack</code></li>
<li>Summary: <p>Monocular Depth Estimation (MDE) is a critical component in applications such
as autonomous driving. There are various attacks against MDE networks. These
attacks, especially the physical ones, pose a great threat to the security of
such systems. Traditional adversarial training method requires ground-truth
labels hence cannot be directly applied to self-supervised MDE that does not
have ground-truth depth. Some self-supervised model hardening techniques (e.g.,
contrastive learning) ignore the domain knowledge of MDE and can hardly achieve
optimal performance. In this work, we propose a novel adversarial training
method for self-supervised MDE models based on view synthesis without using
ground-truth depth. We improve adversarial robustness against physical-world
attacks using L0-norm-bounded perturbation in training. We compare our method
with supervised learning based and contrastive learning based methods that are
tailored for MDE. Results on two representative MDE networks show that we
achieve better robustness against various adversarial attacks with nearly no
benign performance degradation.
</p></li>
</ul>

<h3>Title: Salient Conditional Diffusion for Defending Against Backdoor Attacks. (arXiv:2301.13862v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13862">http://arxiv.org/abs/2301.13862</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13862] Salient Conditional Diffusion for Defending Against Backdoor Attacks](http://arxiv.org/abs/2301.13862) #attack</code></li>
<li>Summary: <p>We propose a novel algorithm, Salient Conditional Diffusion (Sancdifi), a
state-of-the-art defense against backdoor attacks. Sancdifi uses a denoising
diffusion probabilistic model (DDPM) to degrade an image with noise and then
recover said image using the learned reverse diffusion. Critically, we compute
saliency map-based masks to condition our diffusion, allowing for stronger
diffusion on the most salient pixels by the DDPM. As a result, Sancdifi is
highly effective at diffusing out triggers in data poisoned by backdoor
attacks. At the same time, it reliably recovers salient features when applied
to clean data. This performance is achieved without requiring access to the
model parameters of the Trojan network, meaning Sancdifi operates as a
black-box defense.
</p></li>
</ul>

<h3>Title: DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using Classifiers Learned on Graphs. (arXiv:2301.13577v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13577">http://arxiv.org/abs/2301.13577</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13577] DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using Classifiers Learned on Graphs](http://arxiv.org/abs/2301.13577) #attack</code></li>
<li>Summary: <p>As Non-Fungible Tokens (NFTs) continue to grow in popularity, NFT users have
become targets of phishing attacks by cybercriminals, called NFT drainers. Over
the last year, \$100 million worth of NFTs were stolen by drainers, and their
presence remains as a serious threat to the NFT trading space. Since NFTs are
different from cryptocurrencies, existing work on detecting Ethereum phishers
is unsuitable to detect NFT drainers. Moreover, no work has yet comprehensively
investigated the behaviors of drainers in the NFT ecosystem.
</p></li>
</ul>

<p>In this paper, we present the first study on trading behavior of NFT drainers
and present the first dedicated NFT drainer detection system. We extract data
of 83M NFT transactions from the Ethereum blockchain and collect 742 drainer
accounts from five sources. We find drainers have significantly different
transaction context and social context compared to regular users. With the
insights gained from our analysis, we design an automatic drainer detection
system, DRAINCLoG, that uses graph neural networks to capture the complex
relationships in the NFT ecosystem. Our model effectively captures NFT
transaction contexts and social contexts using an NFT-User graph and a User
graph, respectively. Evaluated on real-world NFT transaction data, we prove the
model's effectiveness and robustness.
</p>

<h3>Title: Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow Interaction Graph Analysis. (arXiv:2301.13686v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13686">http://arxiv.org/abs/2301.13686</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13686] Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow Interaction Graph Analysis](http://arxiv.org/abs/2301.13686) #attack</code></li>
<li>Summary: <p>In this paper, we propose HyperVision, a realtime unsupervised machine
learning (ML) based malicious traffic detection system. Particularly,
HyperVision is able to detect unknown patterns of encrypted malicious traffic
by utilizing a compact inmemory graph built upon the traffic patterns. The
graph captures flow interaction patterns represented by the graph structural
features, instead of the features of specific known attacks. We develop an
unsupervised graph learning method to detect abnormal interaction patterns by
analyzing the connectivity, sparsity, and statistical features of the graph,
which allows HyperVision to detect various encrypted attack traffic without
requiring any labeled datasets of known attacks. Moreover, we establish an
information theory model to demonstrate that the information preserved by the
graph approaches the ideal theoretical bound. We show the performance of
HyperVision by real-world experiments with 92 datasets including 48 attacks
with encrypted malicious traffic. The experimental results illustrate that
HyperVision achieves at least 0.92 AUC and 0.86 F1, which significantly
outperform the state-of-the-art methods. In particular, more than 50% attacks
in our experiments can evade all these methods. Moreover, HyperVision achieves
at least 80.6 Gb/s detection throughput with the average detection latency of
0.83s.
</p></li>
</ul>

<h3>Title: EC-CFI: Control-Flow Integrity via Code Encryption Counteracting Fault Attacks. (arXiv:2301.13760v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13760">http://arxiv.org/abs/2301.13760</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13760] EC-CFI: Control-Flow Integrity via Code Encryption Counteracting Fault Attacks](http://arxiv.org/abs/2301.13760) #attack</code></li>
<li>Summary: <p>Fault attacks enable adversaries to manipulate the control-flow of
security-critical applications. By inducing targeted faults into the CPU, the
software's call graph can be escaped and the control-flow can be redirected to
arbitrary functions inside the program. To protect the control-flow from these
attacks, dedicated fault control-flow integrity (CFI) countermeasures are
commonly deployed. However, these schemes either have high detection latencies
or require intrusive hardware changes.
</p></li>
</ul>

<p>In this paper, we present EC-CFI, a software-based cryptographically enforced
CFI scheme with no detection latency utilizing hardware features of recent
Intel platforms. Our EC-CFI prototype is designed to prevent an adversary from
escaping the program's call graph using faults by encrypting each function with
a different key before execution. At runtime, the instrumented program
dynamically derives the decryption key, ensuring that the code only can be
successfully decrypted when the program follows the intended call graph. To
enable this level of protection on Intel commodity systems, we introduce
extended page table (EPT) aliasing allowing us to achieve function-granular
encryption by combing Intel's TME-MK and virtualization technology. We
open-source our custom LLVM-based toolchain automatically protecting arbitrary
programs with EC-CFI. Furthermore, we evaluate our EPT aliasing approach with
the SPEC CPU2017 and Embench-IoT benchmarks and discuss and evaluate potential
TME-MK hardware changes minimizing runtime overheads.
</p>

<h3>Title: Affinity Uncertainty-based Hard Negative Mining in Graph Contrastive Learning. (arXiv:2301.13340v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13340">http://arxiv.org/abs/2301.13340</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13340] Affinity Uncertainty-based Hard Negative Mining in Graph Contrastive Learning](http://arxiv.org/abs/2301.13340) #attack</code></li>
<li>Summary: <p>Hard negative mining has shown effective in enhancing self-supervised
contrastive learning (CL) on diverse data types, including graph contrastive
learning (GCL). Existing hardness-aware CL methods typically treat negative
instances that are most similar to the anchor instance as hard negatives, which
helps improve the CL performance, especially on image data. However, this
approach often fails to identify the hard negatives but leads to many false
negatives on graph data. This is mainly due to that the learned graph
representations are not sufficiently discriminative due to over-smooth
representations and/or non-i.i.d. issues in graph data. To tackle this problem,
this paper proposes a novel approach that builds a discriminative model on
collective affinity information (i.e, two sets of pairwise affinities between
the negative instances and the anchor instance) to mine hard negatives in GCL.
In particular, the proposed approach evaluates how confident/uncertain the
discriminative model is about the affinity of each negative instance to an
anchor instance to determine its hardness weight relative to the anchor
instance. This uncertainty information is then incorporated into existing GCL
loss functions via a weighting term to enhance their performance. The enhanced
GCL is theoretically grounded that the resulting GCL loss is equivalent to a
triplet loss with an adaptive margin being exponentially proportional to the
learned uncertainty of each negative instance. Extensive experiments on 10
graph datasets show that our approach i) consistently enhances different
state-of-the-art GCL methods in both graph and node classification tasks, and
ii) significantly improves their robustness against adversarial attacks.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: DAFD: Domain Adaptation via Feature Disentanglement for Image Classification. (arXiv:2301.13337v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13337">http://arxiv.org/abs/2301.13337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13337] DAFD: Domain Adaptation via Feature Disentanglement for Image Classification](http://arxiv.org/abs/2301.13337) #robust</code></li>
<li>Summary: <p>A good feature representation is the key to image classification. In
practice, image classifiers may be applied in scenarios different from what
they have been trained on. This so-called domain shift leads to a significant
performance drop in image classification. Unsupervised domain adaptation (UDA)
reduces the domain shift by transferring the knowledge learned from a labeled
source domain to an unlabeled target domain. We perform feature disentanglement
for UDA by distilling category-relevant features and excluding
category-irrelevant features from the global feature maps. This disentanglement
prevents the network from overfitting to category-irrelevant information and
makes it focus on information useful for classification. This reduces the
difficulty of domain alignment and improves the classification accuracy on the
target domain. We propose a coarse-to-fine domain adaptation method called
Domain Adaptation via Feature Disentanglement~(DAFD), which has two components:
(1)the Category-Relevant Feature Selection (CRFS) module, which disentangles
the category-relevant features from the category-irrelevant features, and
(2)the Dynamic Local Maximum Mean Discrepancy (DLMMD) module, which achieves
fine-grained alignment by reducing the discrepancy within the category-relevant
features from different domains. Combined with the CRFS, the DLMMD module can
align the category-relevant features properly. We conduct comprehensive
experiment on four standard datasets. Our results clearly demonstrate the
robustness and effectiveness of our approach in domain adaptive image
classification tasks and its competitiveness to the state of the art.
</p></li>
</ul>

<h3>Title: Few-Shot Object Detection via Variational Feature Aggregation. (arXiv:2301.13411v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13411">http://arxiv.org/abs/2301.13411</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13411] Few-Shot Object Detection via Variational Feature Aggregation](http://arxiv.org/abs/2301.13411) #robust</code></li>
<li>Summary: <p>As few-shot object detectors are often trained with abundant base samples and
fine-tuned on few-shot novel examples,the learned models are usually biased to
base classes and sensitive to the variance of novel examples. To address this
issue, we propose a meta-learning framework with two novel feature aggregation
schemes. More precisely, we first present a Class-Agnostic Aggregation (CAA)
method, where the query and support features can be aggregated regardless of
their categories. The interactions between different classes encourage
class-agnostic representations and reduce confusion between base and novel
classes. Based on the CAA, we then propose a Variational Feature Aggregation
(VFA) method, which encodes support examples into class-level support features
for robust feature aggregation. We use a variational autoencoder to estimate
class distributions and sample variational features from distributions that are
more robust to the variance of support examples. Besides, we decouple
classification and regression tasks so that VFA is performed on the
classification branch without affecting object localization. Extensive
experiments on PASCAL VOC and COCO demonstrate that our method significantly
outperforms a strong baseline (up to 16\%) and previous state-of-the-art
methods (4\% in average). Code will be available at:
\url{https://github.com/csuhan/VFA}
</p></li>
</ul>

<h3>Title: Fourier Sensitivity and Regularization of Computer Vision Models. (arXiv:2301.13514v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13514">http://arxiv.org/abs/2301.13514</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13514] Fourier Sensitivity and Regularization of Computer Vision Models](http://arxiv.org/abs/2301.13514) #robust</code></li>
<li>Summary: <p>Recent work has empirically shown that deep neural networks latch on to the
Fourier statistics of training data and show increased sensitivity to
Fourier-basis directions in the input. Understanding and modifying this
Fourier-sensitivity of computer vision models may help improve their
robustness. Hence, in this paper we study the frequency sensitivity
characteristics of deep neural networks using a principled approach. We first
propose a basis trick, proving that unitary transformations of the
input-gradient of a function can be used to compute its gradient in the basis
induced by the transformation. Using this result, we propose a general measure
of any differentiable model's Fourier-sensitivity using the unitary
Fourier-transform of its input-gradient. When applied to deep neural networks,
we find that computer vision models are consistently sensitive to particular
frequencies dependent on the dataset, training method and architecture. Based
on this measure, we further propose a Fourier-regularization framework to
modify the Fourier-sensitivities and frequency bias of models. Using our
proposed regularizer-family, we demonstrate that deep neural networks obtain
improved classification accuracy on robustness evaluations.
</p></li>
</ul>

<h3>Title: A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds. (arXiv:2301.13656v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13656">http://arxiv.org/abs/2301.13656</a></li>
<li>Code URL: <a href="https://github.com/raphaelsulzer/dsr-benchmark">https://github.com/raphaelsulzer/dsr-benchmark</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13656] A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds](http://arxiv.org/abs/2301.13656) #robust</code></li>
<li>Summary: <p>We survey and benchmark traditional and novel learning-based algorithms that
address the problem of surface reconstruction from point clouds. Surface
reconstruction from point clouds is particularly challenging when applied to
real-world acquisitions, due to noise, outliers, non-uniform sampling and
missing data. Traditionally, different handcrafted priors of the input points
or the output surface have been proposed to make the problem more tractable.
However, hyperparameter tuning for adjusting priors to different acquisition
defects can be a tedious task. To this end, the deep learning community has
recently addressed the surface reconstruction problem. In contrast to
traditional approaches, deep surface reconstruction methods can learn priors
directly from a training set of point clouds and corresponding true surfaces.
In our survey, we detail how different handcrafted and learned priors affect
the robustness of methods to defect-laden input and their capability to
generate geometric and topologically accurate reconstructions. In our
benchmark, we evaluate the reconstructions of several traditional and
learning-based methods on the same grounds. We show that learning-based methods
can generalize to unseen shape categories, but their training and test sets
must share the same point cloud characteristics. We also provide the code and
data to compete in our benchmark and to further stimulate the development of
learning-based surface reconstruction
https://github.com/raphaelsulzer/dsr-benchmark.
</p></li>
</ul>

<h3>Title: ZhichunRoad at Amazon KDD Cup 2022: MultiTask Pre-Training for E-Commerce Product Search. (arXiv:2301.13455v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13455">http://arxiv.org/abs/2301.13455</a></li>
<li>Code URL: <a href="https://github.com/cuixuage/KDDCup2022-ESCI">https://github.com/cuixuage/KDDCup2022-ESCI</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13455] ZhichunRoad at Amazon KDD Cup 2022: MultiTask Pre-Training for E-Commerce Product Search](http://arxiv.org/abs/2301.13455) #robust</code></li>
<li>Summary: <p>In this paper, we propose a robust multilingual model to improve the quality
of search results. Our model not only leverage the processed class-balanced
dataset, but also benefit from multitask pre-training that leads to more
general representations. In pre-training stage, we adopt mlm task,
classification task and contrastive learning task to achieve considerably
performance. In fine-tuning stage, we use confident learning, exponential
moving average method (EMA), adversarial training (FGM) and regularized dropout
strategy (R-Drop) to improve the model's generalization and robustness.
Moreover, we use a multi-granular semantic unit to discover the queries and
products textual metadata for enhancing the representation of the model. Our
approach obtained competitive results and ranked top-8 in three tasks. We
release the source code and pre-trained models associated with this work.
</p></li>
</ul>

<h3>Title: TopoBERT: Plug and Play Toponym Recognition Module Harnessing Fine-tuned BERT. (arXiv:2301.13631v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13631">http://arxiv.org/abs/2301.13631</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13631] TopoBERT: Plug and Play Toponym Recognition Module Harnessing Fine-tuned BERT](http://arxiv.org/abs/2301.13631) #robust</code></li>
<li>Summary: <p>Extracting precise geographical information from textual contents is crucial
in a plethora of applications. For example, during hazardous events, a robust
and unbiased toponym extraction framework can provide an avenue to tie the
location concerned to the topic discussed by news media posts and pinpoint
humanitarian help requests or damage reports from social media. Early studies
have leveraged rule-based, gazetteer-based, deep learning, and hybrid
approaches to address this problem. However, the performance of existing tools
is deficient in supporting operations like emergency rescue, which relies on
fine-grained, accurate geographic information. The emerging pretrained language
models can better capture the underlying characteristics of text information,
including place names, offering a promising pathway to optimize toponym
recognition to underpin practical applications. In this paper, TopoBERT, a
toponym recognition module based on a one dimensional Convolutional Neural
Network (CNN1D) and Bidirectional Encoder Representation from Transformers
(BERT), is proposed and fine-tuned. Three datasets (CoNLL2003-Train,
Wikipedia3000, WNUT2017) are leveraged to tune the hyperparameters, discover
the best training strategy, and train the model. Another two datasets
(CoNLL2003-Test and Harvey2017) are used to evaluate the performance. Three
distinguished classifiers, linear, multi-layer perceptron, and CNN1D, are
benchmarked to determine the optimal model architecture. TopoBERT achieves
state-of-the-art performance (f1-score=0.865) compared to the other five
baseline models and can be applied to diverse toponym recognition tasks without
additional training.
</p></li>
</ul>

<h3>Title: Dynamic Scheduled Sampling with Imitation Loss for Neural Text Generation. (arXiv:2301.13753v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13753">http://arxiv.org/abs/2301.13753</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13753] Dynamic Scheduled Sampling with Imitation Loss for Neural Text Generation](http://arxiv.org/abs/2301.13753) #robust</code></li>
<li>Summary: <p>State-of-the-art neural text generation models are typically trained to
maximize the likelihood of each token in the ground-truth sequence conditioned
on the previous target tokens. However, during inference, the model needs to
make a prediction conditioned on the tokens generated by itself. This
train-test discrepancy is referred to as exposure bias. Scheduled sampling is a
curriculum learning strategy that gradually exposes the model to its own
predictions during training to mitigate this bias. Most of the proposed
approaches design a scheduler based on training steps, which generally requires
careful tuning depending on the training setup. In this work, we introduce
Dynamic Scheduled Sampling with Imitation Loss (DySI), which maintains the
schedule based solely on the training time accuracy, while enhancing the
curriculum learning by introducing an imitation loss, which attempts to make
the behavior of the decoder indistinguishable from the behavior of a
teacher-forced decoder. DySI is universally applicable across training setups
with minimal tuning. Extensive experiments and analysis show that DySI not only
achieves notable improvements on standard machine translation benchmarks, but
also significantly improves the robustness of other text generation models.
</p></li>
</ul>

<h3>Title: Near Optimal Private and Robust Linear Regression. (arXiv:2301.13273v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13273">http://arxiv.org/abs/2301.13273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13273] Near Optimal Private and Robust Linear Regression](http://arxiv.org/abs/2301.13273) #robust</code></li>
<li>Summary: <p>We study the canonical statistical estimation problem of linear regression
from $n$ i.i.d.~examples under $(\varepsilon,\delta)$-differential privacy when
some response variables are adversarially corrupted. We propose a variant of
the popular differentially private stochastic gradient descent (DP-SGD)
algorithm with two innovations: a full-batch gradient descent to improve sample
complexity and a novel adaptive clipping to guarantee robustness. When there is
no adversarial corruption, this algorithm improves upon the existing
state-of-the-art approach and achieves a near optimal sample complexity. Under
label-corruption, this is the first efficient linear regression algorithm to
guarantee both $(\varepsilon,\delta)$-DP and robustness. Synthetic experiments
confirm the superiority of our approach.
</p></li>
</ul>

<h3>Title: Probabilistic Neural Data Fusion for Learning from an Arbitrary Number of Multi-fidelity Data Sets. (arXiv:2301.13271v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13271">http://arxiv.org/abs/2301.13271</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13271] Probabilistic Neural Data Fusion for Learning from an Arbitrary Number of Multi-fidelity Data Sets](http://arxiv.org/abs/2301.13271) #robust</code></li>
<li>Summary: <p>In many applications in engineering and sciences analysts have simultaneous
access to multiple data sources. In such cases, the overall cost of acquiring
information can be reduced via data fusion or multi-fidelity (MF) modeling
where one leverages inexpensive low-fidelity (LF) sources to reduce the
reliance on expensive high-fidelity (HF) data. In this paper, we employ neural
networks (NNs) for data fusion in scenarios where data is very scarce and
obtained from an arbitrary number of sources with varying levels of fidelity
and cost. We introduce a unique NN architecture that converts MF modeling into
a nonlinear manifold learning problem. Our NN architecture inversely learns
non-trivial (e.g., non-additive and non-hierarchical) biases of the LF sources
in an interpretable and visualizable manifold where each data source is encoded
via a low-dimensional distribution. This probabilistic manifold quantifies
model form uncertainties such that LF sources with small bias are encoded close
to the HF source. Additionally, we endow the output of our NN with a parametric
distribution not only to quantify aleatoric uncertainties, but also to
reformulate the network's loss function based on strictly proper scoring rules
which improve robustness and accuracy on unseen HF data. Through a set of
analytic and engineering examples, we demonstrate that our approach provides a
high predictive power while quantifying various sources uncertainties.
</p></li>
</ul>

<h3>Title: Incorporating Recurrent Reinforcement Learning into Model Predictive Control for Adaptive Control in Autonomous Driving. (arXiv:2301.13313v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13313">http://arxiv.org/abs/2301.13313</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13313] Incorporating Recurrent Reinforcement Learning into Model Predictive Control for Adaptive Control in Autonomous Driving](http://arxiv.org/abs/2301.13313) #robust</code></li>
<li>Summary: <p>Model Predictive Control (MPC) is attracting tremendous attention in the
autonomous driving task as a powerful control technique. The success of an MPC
controller strongly depends on an accurate internal dynamics model. However,
the static parameters, usually learned by system identification, often fail to
adapt to both internal and external perturbations in real-world scenarios. In
this paper, we firstly (1) reformulate the problem as a Partially Observed
Markov Decision Process (POMDP) that absorbs the uncertainties into
observations and maintains Markov property into hidden states; and (2) learn a
recurrent policy continually adapting the parameters of the dynamics model via
Recurrent Reinforcement Learning (RRL) for optimal and adaptive control; and
(3) finally evaluate the proposed algorithm (referred as $\textit{MPC-RRL}$) in
CARLA simulator and leading to robust behaviours under a wide range of
perturbations.
</p></li>
</ul>

<h3>Title: A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback. (arXiv:2301.13326v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13326">http://arxiv.org/abs/2301.13326</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13326] A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback](http://arxiv.org/abs/2301.13326) #robust</code></li>
<li>Summary: <p>We investigate the problem of stochastic, combinatorial multi-armed bandits
where the learner only has access to bandit feedback and the reward function
can be non-linear. We provide a general framework for adapting discrete offline
approximation algorithms into sublinear $\alpha$-regret methods that only
require bandit feedback, achieving
$\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ expected cumulative
$\alpha$-regret dependence on the horizon $T$. The framework only requires the
offline algorithms to be robust to small errors in function evaluation. The
adaptation procedure does not even require explicit knowledge of the offline
approximation algorithm -- the offline algorithm can be used as black box
subroutine.
</p></li>
</ul>

<p>To demonstrate the utility of the proposed framework, the proposed framework
is applied to multiple problems in submodular maximization, adapting
approximation algorithms for cardinality and for knapsack constraints. The new
CMAB algorithms for knapsack constraints outperform a full-bandit method
developed for the adversarial setting in experiments with real-world data.
</p>

<h3>Title: Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees. (arXiv:2301.13375v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13375">http://arxiv.org/abs/2301.13375</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13375] Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees](http://arxiv.org/abs/2301.13375) #robust</code></li>
<li>Summary: <p>Robustness and safety are critical for the trustworthy deployment of deep
reinforcement learning in real-world decision making applications. In
particular, we require algorithms that can guarantee robust, safe performance
in the presence of general environment disturbances, while making limited
assumptions on the data collection process during training. In this work, we
propose a safe reinforcement learning framework with robustness guarantees
through the use of an optimal transport cost uncertainty set. We provide an
efficient, theoretically supported implementation based on Optimal Transport
Perturbations, which can be applied in a completely offline fashion using only
data collected in a nominal training environment. We demonstrate the robust,
safe performance of our approach on a variety of continuous control tasks with
safety constraints in the Real-World Reinforcement Learning Suite.
</p></li>
</ul>

<h3>Title: Sequential Strategic Screening. (arXiv:2301.13397v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13397">http://arxiv.org/abs/2301.13397</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13397] Sequential Strategic Screening](http://arxiv.org/abs/2301.13397) #robust</code></li>
<li>Summary: <p>We initiate the study of strategic behavior in screening processes with
multiple classifiers. We focus on two contrasting settings: a conjunctive
setting in which an individual must satisfy all classifiers simultaneously, and
a sequential setting in which an individual to succeed must satisfy classifiers
one at a time. In other words, we introduce the combination of strategic
classification with screening processes.
</p></li>
</ul>

<p>We show that sequential screening pipelines exhibit new and surprising
behavior where individuals can exploit the sequential ordering of the tests to
zig-zag between classifiers without having to simultaneously satisfy all of
them. We demonstrate an individual can obtain a positive outcome using a
limited manipulation budget even when far from the intersection of the positive
regions of every classifier. Finally, we consider a learner whose goal is to
design a sequential screening process that is robust to such manipulations, and
provide a construction for the learner that optimizes a natural objective.
</p>

<h3>Title: Learning Against Distributional Uncertainty: On the Trade-off Between Robustness and Specificity. (arXiv:2301.13565v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13565">http://arxiv.org/abs/2301.13565</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13565] Learning Against Distributional Uncertainty: On the Trade-off Between Robustness and Specificity](http://arxiv.org/abs/2301.13565) #robust</code></li>
<li>Summary: <p>Trustworthy machine learning aims at combating distributional uncertainties
in training data distributions compared to population distributions. Typical
treatment frameworks include the Bayesian approach, (min-max) distributionally
robust optimization (DRO), and regularization. However, two issues have to be
raised: 1) All these methods are biased estimators of the true optimal cost; 2)
the prior distribution in the Bayesian method, the radius of the distributional
ball in the DRO method, and the regularizer in the regularization method are
difficult to specify. This paper studies a new framework that unifies the three
approaches and that addresses the two challenges mentioned above. The
asymptotic properties (e.g., consistency and asymptotic normalities),
non-asymptotic properties (e.g., unbiasedness and generalization error bound),
and a Monte--Carlo-based solution method of the proposed model are studied. The
new model reveals the trade-off between the robustness to the unseen data and
the specificity to the training data.
</p></li>
</ul>

<h3>Title: Policy Gradient for s-Rectangular Robust Markov Decision Processes. (arXiv:2301.13589v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13589">http://arxiv.org/abs/2301.13589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13589] Policy Gradient for s-Rectangular Robust Markov Decision Processes](http://arxiv.org/abs/2301.13589) #robust</code></li>
<li>Summary: <p>We present a novel robust policy gradient method (RPG) for s-rectangular
robust Markov Decision Processes (MDPs). We are the first to derive the
adversarial kernel in a closed form and demonstrate that it is a one-rank
perturbation of the nominal kernel. This allows us to derive an RPG that is
similar to the one used in non-robust MDPs, except with a robust Q-value
function and an additional correction term. Both robust Q-values and correction
terms are efficiently computable, thus the time complexity of our method
matches that of non-robust MDPs, which is significantly faster compared to
existing black box methods.
</p></li>
</ul>

<h3>Title: An Efficient Solution to s-Rectangular Robust Markov Decision Processes. (arXiv:2301.13642v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13642">http://arxiv.org/abs/2301.13642</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13642] An Efficient Solution to s-Rectangular Robust Markov Decision Processes](http://arxiv.org/abs/2301.13642) #robust</code></li>
<li>Summary: <p>We present an efficient robust value iteration for \texttt{s}-rectangular
robust Markov Decision Processes (MDPs) with a time complexity comparable to
standard (non-robust) MDPs which is significantly faster than any existing
method. We do so by deriving the optimal robust Bellman operator in concrete
forms using our $L_p$ water filling lemma. We unveil the exact form of the
optimal policies, which turn out to be novel threshold policies with the
probability of playing an action proportional to its advantage.
</p></li>
</ul>

<h3>Title: Enhancing Hyper-To-Real Space Projections Through Euclidean Norm Meta-Heuristic Optimization. (arXiv:2301.13671v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13671">http://arxiv.org/abs/2301.13671</a></li>
<li>Code URL: <a href="https://github.com/lzfelix/lio">https://github.com/lzfelix/lio</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13671] Enhancing Hyper-To-Real Space Projections Through Euclidean Norm Meta-Heuristic Optimization](http://arxiv.org/abs/2301.13671) #robust</code></li>
<li>Summary: <p>The continuous computational power growth in the last decades has made
solving several optimization problems significant to humankind a tractable
task; however, tackling some of them remains a challenge due to the
overwhelming amount of candidate solutions to be evaluated, even by using
sophisticated algorithms. In such a context, a set of nature-inspired
stochastic methods, called meta-heuristic optimization, can provide robust
approximate solutions to different kinds of problems with a small computational
burden, such as derivative-free real function optimization. Nevertheless, these
methods may converge to inadequate solutions if the function landscape is too
harsh, e.g., enclosing too many local optima. Previous works addressed this
issue by employing a hypercomplex representation of the search space, like
quaternions, where the landscape becomes smoother and supposedly easier to
optimize. Under this approach, meta-heuristic computations happen in the
hypercomplex space, whereas variables are mapped back to the real domain before
function evaluation. Despite this latter operation being performed by the
Euclidean norm, we have found that after the optimization procedure has
finished, it is usually possible to obtain even better solutions by employing
the Minkowski $p$-norm instead and fine-tuning $p$ through an auxiliary
sub-problem with neglecting additional cost and no hyperparameters. Such
behavior was observed in eight well-established benchmarking functions, thus
fostering a new research direction for hypercomplex meta-heuristic
optimization.
</p></li>
</ul>

<h3>Title: Toward Efficient Gradient-Based Value Estimation. (arXiv:2301.13757v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13757">http://arxiv.org/abs/2301.13757</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13757] Toward Efficient Gradient-Based Value Estimation](http://arxiv.org/abs/2301.13757) #robust</code></li>
<li>Summary: <p>Gradient-based methods for value estimation in reinforcement learning have
favorable stability properties, but they are typically much slower than
Temporal Difference (TD) learning methods. We study the root causes of this
slowness and show that Mean Square Bellman Error (MSBE) is an ill-conditioned
loss function in the sense that its Hessian has large condition-number. To
resolve the adverse effect of poor conditioning of MSBE on gradient based
methods, we propose a low complexity batch-free proximal method that
approximately follows the Gauss-Newton direction and is asymptotically robust
to parameterization. Our main algorithm, called RANS, is efficient in the sense
that it is significantly faster than the residual gradient methods while having
almost the same computational complexity, and is competitive with TD on the
classic problems that we tested.
</p></li>
</ul>

<h3>Title: Interpreting Robustness Proofs of Deep Neural Networks. (arXiv:2301.13845v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13845">http://arxiv.org/abs/2301.13845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13845] Interpreting Robustness Proofs of Deep Neural Networks](http://arxiv.org/abs/2301.13845) #robust</code></li>
<li>Summary: <p>In recent years numerous methods have been developed to formally verify the
robustness of deep neural networks (DNNs). Though the proposed techniques are
effective in providing mathematical guarantees about the DNNs behavior, it is
not clear whether the proofs generated by these methods are
human-interpretable. In this paper, we bridge this gap by developing new
concepts, algorithms, and representations to generate human understandable
interpretations of the proofs. Leveraging the proposed method, we show that the
robustness proofs of standard DNNs rely on spurious input features, while the
proofs of DNNs trained to be provably robust filter out even the semantically
meaningful features. The proofs for the DNNs combining adversarial and provably
robust training are the most effective at selectively filtering out spurious
features as well as relying on human-understandable input features.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: [Work in progress] Scalable, out-of-the box segmentation of individual particles from mineral samples acquired with micro CT. (arXiv:2301.13319v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13319">http://arxiv.org/abs/2301.13319</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13319] [Work in progress] Scalable, out-of-the box segmentation of individual particles from mineral samples acquired with micro CT](http://arxiv.org/abs/2301.13319) #extraction</code></li>
<li>Summary: <p>Minerals are indispensable for a functioning modern society. Yet, their
supply is limited causing a need for optimizing their exploration and
extraction both from ores and recyclable materials. Typically, these processes
must be meticulously adapted to the precise properties of the processed
particles, requiring an extensive characterization of their shapes, appearances
as well as the overall material composition. Current approaches perform this
analysis based on bulk segmentation and characterization of particles, and rely
on rudimentary postprocessing techniques to separate touching particles.
However, due to their inability to reliably perform this separation as well as
the need to retrain or reconfigure most methods for each new image, these
approaches leave untapped potential to be leveraged. Here, we propose an
instance segmentation method that is able to extract individual particles from
large micro CT images taken from mineral samples embedded in an epoxy matrix.
Our approach is based on the powerful nnU-Net framework, introduces a particle
size normalization, makes use of a border-core representation to enable
instance segmentation and is trained with a large dataset containing particles
of numerous different materials and minerals. We demonstrate that our approach
can be applied out-of-the box to a large variety of particle types, including
materials and appearances that have not been part of the training set. Thus, no
further manual annotations and retraining are required when applying the method
to new mineral samples, enabling substantially higher scalability of
experiments than existing methods. Our code and dataset are made publicly
available.
</p></li>
</ul>

<h3>Title: Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors. (arXiv:2301.13422v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13422">http://arxiv.org/abs/2301.13422</a></li>
<li>Code URL: <a href="https://github.com/jingtao-li-cver/asd">https://github.com/jingtao-li-cver/asd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13422] Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors](http://arxiv.org/abs/2301.13422) #extraction</code></li>
<li>Summary: <p>Anomaly segmentation in high spatial resolution (HSR) remote sensing imagery
is aimed at segmenting anomaly patterns of the earth deviating from normal
patterns, which plays an important role in various Earth vision applications.
However, it is a challenging task due to the complex distribution and the
irregular shapes of objects, and the lack of abnormal samples. To tackle these
problems, an anomaly segmentation model based on pixel descriptors (ASD) is
proposed for anomaly segmentation in HSR imagery. Specifically, deep one-class
classification is introduced for anomaly segmentation in the feature space with
discriminative pixel descriptors. The ASD model incorporates the data argument
for generating virtual ab-normal samples, which can force the pixel descriptors
to be compact for normal data and meanwhile to be diverse to avoid the model
collapse problems when only positive samples participated in the training. In
addition, the ASD introduced a multi-level and multi-scale feature extraction
strategy for learning the low-level and semantic information to make the pixel
descriptors feature-rich. The proposed ASD model was validated using four HSR
datasets and compared with the recent state-of-the-art models, showing its
potential value in Earth vision applications.
</p></li>
</ul>

<h3>Title: Lidar Upsampling with Sliced Wasserstein Distance. (arXiv:2301.13558v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13558">http://arxiv.org/abs/2301.13558</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13558] Lidar Upsampling with Sliced Wasserstein Distance](http://arxiv.org/abs/2301.13558) #extraction</code></li>
<li>Summary: <p>Lidar became an important component of the perception systems in autonomous
driving. But challenges of training data acquisition and annotation made
emphasized the role of the sensor to sensor domain adaptation. In this work, we
address the problem of lidar upsampling. Learning on lidar point clouds is
rather a challenging task due to their irregular and sparse structure. Here we
propose a method for lidar point cloud upsampling which can reconstruct
fine-grained lidar scan patterns. The key idea is to utilize edge-aware dense
convolutions for both feature extraction and feature expansion. Additionally
applying a more accurate Sliced Wasserstein Distance facilitates learning of
the fine lidar sweep structures. This in turn enables our method to employ a
one-stage upsampling paradigm without the need for coarse and fine
reconstruction. We conduct several experiments to evaluate our method and
demonstrate that it provides better upsampling.
</p></li>
</ul>

<h3>Title: Sifer: Overcoming simplicity bias in deep networks using a feature sieve. (arXiv:2301.13293v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13293">http://arxiv.org/abs/2301.13293</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13293] Sifer: Overcoming simplicity bias in deep networks using a feature sieve](http://arxiv.org/abs/2301.13293) #extraction</code></li>
<li>Summary: <p>Simplicity bias is the concerning tendency of deep networks to over-depend on
simple, weakly predictive features, to the exclusion of stronger, more complex
features. This causes biased, incorrect model predictions in many real-world
applications, exacerbated by incomplete training data containing spurious
feature-label correlations. We propose a direct, interventional method for
addressing simplicity bias in DNNs, which we call the feature sieve. We aim to
automatically identify and suppress easily-computable spurious features in
lower layers of the network, thereby allowing the higher network levels to
extract and utilize richer, more meaningful representations. We provide
concrete evidence of this differential suppression &amp; enhancement of relevant
features on both controlled datasets and real-world images, and report
substantial gains on many real-world debiasing benchmarks (11.4% relative gain
on Imagenet-A; 3.2% on BAR, etc). Crucially, we outperform many baselines that
incorporate knowledge about known spurious or biased attributes, despite our
method not using any such information. We believe that our feature sieve work
opens up exciting new research directions in automated adversarial feature
extraction &amp; representation learning for deep networks.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Fairness-aware Vision Transformer via Debiased Self-Attention. (arXiv:2301.13803v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13803">http://arxiv.org/abs/2301.13803</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13803] Fairness-aware Vision Transformer via Debiased Self-Attention](http://arxiv.org/abs/2301.13803) #fair</code></li>
<li>Summary: <p>Vision Transformer (ViT) has recently gained significant interest in solving
computer vision (CV) problems due to its capability of extracting informative
features and modeling long-range dependencies through the self-attention
mechanism. To fully realize the advantages of ViT in real-world applications,
recent works have explored the trustworthiness of ViT, including its robustness
and explainability. However, another desiderata, fairness has not yet been
adequately addressed in the literature. We establish that the existing
fairness-aware algorithms (primarily designed for CNNs) do not perform well on
ViT. This necessitates the need for developing our novel framework via Debiased
Self-Attention (DSA). DSA is a fairness-through-blindness approach that
enforces ViT to eliminate spurious features correlated with the sensitive
attributes for bias mitigation. Notably, adversarial examples are leveraged to
locate and mask the spurious features in the input image patches. In addition,
DSA utilizes an attention weights alignment regularizer in the training
objective to encourage learning informative features for target prediction.
Importantly, our DSA framework leads to improved fairness guarantees over prior
works on multiple prediction tasks without compromising target prediction
performance
</p></li>
</ul>

<h3>Title: Do Multi-Document Summarization Models Synthesize?. (arXiv:2301.13844v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13844">http://arxiv.org/abs/2301.13844</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13844] Do Multi-Document Summarization Models Synthesize?](http://arxiv.org/abs/2301.13844) #fair</code></li>
<li>Summary: <p>Multi-document summarization entails producing concise synopses of
collections of inputs. For some applications, the synopsis should accurately
\emph{synthesize} inputs with respect to a key property or aspect. For example,
a synopsis of film reviews all written about a particular movie should reflect
the average critic consensus. As a more consequential example, consider
narrative summaries that accompany biomedical \emph{systematic reviews} of
clinical trial results. These narratives should fairly summarize the
potentially conflicting results from individual trials.
</p></li>
</ul>

<p>In this paper we ask: To what extent do modern multi-document summarization
models implicitly perform this type of synthesis? To assess this we perform a
suite of experiments that probe the degree to which conditional generation
models trained for summarization using standard methods yield outputs that
appropriately synthesize inputs. We find that existing models do partially
perform synthesis, but do so imperfectly. In particular, they are
over-sensitive to changes in input ordering and under-sensitive to changes in
input compositions (e.g., the ratio of positive to negative movie reviews). We
propose a simple, general method for improving model synthesis capabilities by
generating an explicitly diverse set of candidate outputs, and then selecting
from these the string best aligned with the expected aggregate measure for the
inputs, or \emph{abstaining} when the model produces no good candidate. This
approach improves model synthesis performance. We hope highlighting the need
for synthesis (in some summarization settings), motivates further research into
multi-document summarization methods and learning objectives that explicitly
account for the need to synthesize.
</p>

<h3>Title: Fairness and Accuracy under Domain Generalization. (arXiv:2301.13323v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13323">http://arxiv.org/abs/2301.13323</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13323] Fairness and Accuracy under Domain Generalization](http://arxiv.org/abs/2301.13323) #fair</code></li>
<li>Summary: <p>As machine learning (ML) algorithms are increasingly used in high-stakes
applications, concerns have arisen that they may be biased against certain
social groups. Although many approaches have been proposed to make ML models
fair, they typically rely on the assumption that data distributions in training
and deployment are identical. Unfortunately, this is commonly violated in
practice and a model that is fair during training may lead to an unexpected
outcome during its deployment. Although the problem of designing robust ML
models under dataset shifts has been widely studied, most existing works focus
only on the transfer of accuracy. In this paper, we study the transfer of both
fairness and accuracy under domain generalization where the data at test time
may be sampled from never-before-seen domains. We first develop theoretical
bounds on the unfairness and expected loss at deployment, and then derive
sufficient conditions under which fairness and accuracy can be perfectly
transferred via invariant representation learning. Guided by this, we design a
learning algorithm such that fair ML models learned with training data still
have high fairness and accuracy when deployment environments change.
Experiments on real-world data validate the proposed algorithm. Model
implementation is available at https://github.com/pth1993/FATDM.
</p></li>
</ul>

<h3>Title: Superhuman Fairness. (arXiv:2301.13420v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13420">http://arxiv.org/abs/2301.13420</a></li>
<li>Code URL: <a href="https://github.com/omidMemari/superhumn-fairness">https://github.com/omidMemari/superhumn-fairness</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13420] Superhuman Fairness](http://arxiv.org/abs/2301.13420) #fair</code></li>
<li>Summary: <p>The fairness of machine learning-based decisions has become an increasingly
important focus in the design of supervised machine learning methods. Most
fairness approaches optimize a specified trade-off between performance
measure(s) (e.g., accuracy, log loss, or AUC) and fairness metric(s) (e.g.,
demographic parity, equalized odds). This begs the question: are the right
performance-fairness trade-offs being specified? We instead re-cast fair
machine learning as an imitation learning task by introducing superhuman
fairness, which seeks to simultaneously outperform human decisions on multiple
predictive performance and fairness measures. We demonstrate the benefits of
this approach given suboptimal decisions.
</p></li>
</ul>

<h3>Title: Retiring $\Delta$DP: New Distribution-Level Metrics for Demographic Parity. (arXiv:2301.13443v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13443">http://arxiv.org/abs/2301.13443</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13443] Retiring $\Delta$DP: New Distribution-Level Metrics for Demographic Parity](http://arxiv.org/abs/2301.13443) #fair</code></li>
<li>Summary: <p>Demographic parity is the most widely recognized measure of group fairness in
machine learning, which ensures equal treatment of different demographic
groups. Numerous works aim to achieve demographic parity by pursuing the
commonly used metric $\Delta DP$. Unfortunately, in this paper, we reveal that
the fairness metric $\Delta DP$ can not precisely measure the violation of
demographic parity, because it inherently has the following drawbacks:
\textit{i)} zero-value $\Delta DP$ does not guarantee zero violation of
demographic parity, \textit{ii)} $\Delta DP$ values can vary with different
classification thresholds. To this end, we propose two new fairness metrics,
\textsf{A}rea \textsf{B}etween \textsf{P}robability density function
\textsf{C}urves (\textsf{ABPC}) and \textsf{A}rea \textsf{B}etween
\textsf{C}umulative density function \textsf{C}urves (\textsf{ABCC}), to
precisely measure the violation of demographic parity in distribution level.
The new fairness metrics directly measure the difference between the
distributions of the prediction probability for different demographic groups.
Thus our proposed new metrics enjoy: \textit{i)} zero-value
\textsf{ABCC}/\textsf{ABPC} guarantees zero violation of demographic parity;
\textit{ii)} \textsf{ABCC}/\textsf{ABPC} guarantees demographic parity while
the classification threshold adjusted. We further re-evaluate the existing fair
models with our proposed fairness metrics and observe different fairness
behaviors of those models under the new metrics.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning. (arXiv:2301.13343v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13343">http://arxiv.org/abs/2301.13343</a></li>
<li>Code URL: <a href="https://github.com/madoibito80/im2sem">https://github.com/madoibito80/im2sem</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13343] Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning](http://arxiv.org/abs/2301.13343) #interpretability</code></li>
<li>Summary: <p>We investigate policy transfer using image-to-semantics translation to
mitigate learning difficulties in vision-based robotics control agents. This
problem assumes two environments: a simulator environment with semantics, that
is, low-dimensional and essential information, as the state space, and a
real-world environment with images as the state space. By learning mapping from
images to semantics, we can transfer a policy, pre-trained in the simulator, to
the real world, thereby eliminating real-world on-policy agent interactions to
learn, which are costly and risky. In addition, using image-to-semantics
mapping is advantageous in terms of the computational efficiency to train the
policy and the interpretability of the obtained policy over other types of
sim-to-real transfer strategies. To tackle the main difficulty in learning
image-to-semantics mapping, namely the human annotation cost for producing a
training dataset, we propose two techniques: pair augmentation with the
transition function in the simulator environment and active learning. We
observed a reduction in the annotation cost without a decline in the
performance of the transfer, and the proposed approach outperformed the
existing approach without annotation.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated Text. (arXiv:2301.13852v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13852">http://arxiv.org/abs/2301.13852</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13852] ChatGPT or Human? Detect and Explain](http://arxiv.org/abs/2301.13852) #explainability</code></li>
<li>Summary: <p>ChatGPT has the ability to generate grammatically flawless and
seemingly-human replies to different types of questions from various domains.
The number of its users and of its applications is growing at an unprecedented
rate. Unfortunately, use and abuse come hand in hand. In this paper, we study
whether a machine learning model can be effectively trained to accurately
distinguish between original human and seemingly human (that is,
ChatGPT-generated) text, especially when this text is short. Furthermore, we
employ an explainable artificial intelligence framework to gain insight into
the reasoning behind the model trained to differentiate between
ChatGPT-generated and human-generated text. The goal is to analyze model's
decisions and determine if any specific patterns or characteristics can be
identified. Our study focuses on short online reviews, conducting two
experiments comparing human-generated and ChatGPT-generated text. The first
experiment involves ChatGPT text generated from custom queries, while the
second experiment involves text generated by rephrasing original
human-generated reviews. We fine-tune a Transformer-based model and use it to
make predictions, which are then explained using SHAP. We compare our model
with a perplexity score-based approach and find that disambiguation between
human and ChatGPT-generated reviews is more challenging for the ML model when
using rephrased text. However, our proposed approach still achieves an accuracy
of 79%. Using explainability, we observe that ChatGPT's writing is polite,
without specific details, using fancy and atypical vocabulary, impersonal, and
typically it does not express feelings.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Zero3D: Semantic-Driven Multi-Category 3D Shape Generation. (arXiv:2301.13591v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13591">http://arxiv.org/abs/2301.13591</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13591] Zero3D: Semantic-Driven Multi-Category 3D Shape Generation](http://arxiv.org/abs/2301.13591) #diffusion</code></li>
<li>Summary: <p>Semantic-driven 3D shape generation aims to generate 3D objects conditioned
on text. Previous works face problems with single-category generation,
low-frequency 3D details, and requiring a large number of paired datasets for
training. To tackle these challenges, we propose a multi-category conditional
diffusion model. Specifically, 1) to alleviate the problem of lack of
large-scale paired data, we bridge the text, 2D image and 3D shape based on the
pre-trained CLIP model, and 2) to obtain the multi-category 3D shape feature,
we apply the conditional flow model to generate 3D shape vector conditioned on
CLIP embedding. 3) to generate multi-category 3D shape, we employ the
hidden-layer diffusion model conditioned on the multi-category shape vector,
which greatly reduces the training time and memory consumption.
</p></li>
</ul>

<h3>Title: Learning Data Representations with Joint Diffusion Models. (arXiv:2301.13622v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13622">http://arxiv.org/abs/2301.13622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13622] Learning Data Representations with Joint Diffusion Models](http://arxiv.org/abs/2301.13622) #diffusion</code></li>
<li>Summary: <p>We introduce a joint diffusion model that simultaneously learns meaningful
internal representations fit for both generative and predictive tasks. Joint
machine learning models that allow synthesizing and classifying data often
offer uneven performance between those tasks or are unstable to train. In this
work, we depart from a set of empirical observations that indicate the
usefulness of internal representations built by contemporary deep
diffusion-based generative models in both generative and predictive settings.
We then introduce an extension of the vanilla diffusion model with a classifier
that allows for stable joint training with shared parametrization between those
objectives. The resulting joint diffusion model offers superior performance
across various tasks, including generative modeling, semi-supervised
classification, and domain adaptation.
</p></li>
</ul>

<h3>Title: DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models. (arXiv:2301.13721v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13721">http://arxiv.org/abs/2301.13721</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13721] DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models](http://arxiv.org/abs/2301.13721) #diffusion</code></li>
<li>Summary: <p>In this paper, targeting to understand the underlying explainable factors
behind observations and modeling the conditional generation process on these
factors, we propose a new task, disentanglement of diffusion probabilistic
models (DPMs), to take advantage of the remarkable modeling ability of DPMs. To
tackle this task, we further devise an unsupervised approach named DisDiff. For
the first time, we achieve disentangled representation learning in the
framework of diffusion probabilistic models. Given a pre-trained DPM, DisDiff
can automatically discover the inherent factors behind the image data and
disentangle the gradient fields of DPM into sub-gradient fields, each
conditioned on the representation of each discovered factor. We propose a novel
Disentangling Loss for DisDiff to facilitate the disentanglement of the
representation and sub-gradients. The extensive experiments on synthetic and
real-world datasets demonstrate the effectiveness of DisDiff.
</p></li>
</ul>

<h3>Title: Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion. (arXiv:2301.13743v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13743">http://arxiv.org/abs/2301.13743</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13743] Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion](http://arxiv.org/abs/2301.13743) #diffusion</code></li>
<li>Summary: <p>Cross-modality data translation has attracted great interest in image
computing. Deep generative models (\textit{e.g.}, GANs) show performance
improvement in tackling those problems. Nevertheless, as a fundamental
challenge in image translation, the problem of Zero-shot-Learning
Cross-Modality Data Translation with fidelity remains unanswered. This paper
proposes a new unsupervised zero-shot-learning method named Mutual Information
guided Diffusion cross-modality data translation Model (MIDiffusion), which
learns to translate the unseen source data to the target domain. The
MIDiffusion leverages a score-matching-based generative model, which learns the
prior knowledge in the target domain. We propose a differentiable
local-wise-MI-Layer ($LMI$) for conditioning the iterative denoising sampling.
The $LMI$ captures the identical cross-modality features in the statistical
domain for the diffusion guidance; thus, our method does not require retraining
when the source domain is changed, as it does not rely on any direct mapping
between the source and target domains. This advantage is critical for applying
cross-modality data translation methods in practice, as a reasonable amount of
source domain dataset is not always available for supervised training. We
empirically show the advanced performance of MIDiffusion in comparison with an
influential group of generative models, including adversarial-based and other
score-matching-based models.
</p></li>
</ul>

<h3>Title: Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models. (arXiv:2301.13826v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13826">http://arxiv.org/abs/2301.13826</a></li>
<li>Code URL: <a href="https://github.com/AttendAndExcite/Attend-and-Excite">https://github.com/AttendAndExcite/Attend-and-Excite</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13826] Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models](http://arxiv.org/abs/2301.13826) #diffusion</code></li>
<li>Summary: <p>Recent text-to-image generative models have demonstrated an unparalleled
ability to generate diverse and creative imagery guided by a target text
prompt. While revolutionary, current state-of-the-art diffusion models may
still fail in generating images that fully convey the semantics in the given
text prompt. We analyze the publicly available Stable Diffusion model and
assess the existence of catastrophic neglect, where the model fails to generate
one or more of the subjects from the input prompt. Moreover, we find that in
some cases the model also fails to correctly bind attributes (e.g., colors) to
their corresponding subjects. To help mitigate these failure cases, we
introduce the concept of Generative Semantic Nursing (GSN), where we seek to
intervene in the generative process on the fly during inference time to improve
the faithfulness of the generated images. Using an attention-based formulation
of GSN, dubbed Attend-and-Excite, we guide the model to refine the
cross-attention units to attend to all subject tokens in the text prompt and
strengthen - or excite - their activations, encouraging the model to generate
all subjects described in the text prompt. We compare our approach to
alternative approaches and demonstrate that it conveys the desired concepts
more faithfully across a range of text prompts.
</p></li>
</ul>

<h3>Title: Optimizing DDPM Sampling with Shortcut Fine-Tuning. (arXiv:2301.13362v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13362">http://arxiv.org/abs/2301.13362</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13362] Optimizing DDPM Sampling with Shortcut Fine-Tuning](http://arxiv.org/abs/2301.13362) #diffusion</code></li>
<li>Summary: <p>In this study, we propose Shortcut Fine-tuning (SFT), a new approach for
addressing the challenge of fast sampling of pretrained Denoising Diffusion
Probabilistic Models (DDPMs). SFT advocates for the fine-tuning of DDPM
samplers through the direct minimization of Integral Probability Metrics (IPM),
instead of learning the backward diffusion process. This enables samplers to
discover an alternative and more efficient sampling shortcut, deviating from
the backward diffusion process. We also propose a new algorithm that is similar
to the policy gradient method for fine-tuning DDPMs by proving that under
certain assumptions, the gradient descent of diffusion models is equivalent to
the policy gradient approach. Through empirical evaluation, we demonstrate that
our fine-tuning method can further enhance existing fast DDPM samplers,
resulting in sample quality comparable to or even surpassing that of the
full-step model across various datasets.
</p></li>
</ul>

<h3>Title: DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising Diffusion Models. (arXiv:2301.13629v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13629">http://arxiv.org/abs/2301.13629</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13629] DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising Diffusion Models](http://arxiv.org/abs/2301.13629) #diffusion</code></li>
<li>Summary: <p>Spatio-temporal graph neural networks (STGNN) have emerged as the dominant
model for spatio-temporal graph (STG) forecasting. Despite their success, they
fail to model intrinsic uncertainties within STG data, which cripples their
practicality in downstream tasks for decision-making. To this end, this paper
focuses on probabilistic STG forecasting, which is challenging due to the
difficulty in modeling uncertainties and complex ST dependencies. In this
study, we present the first attempt to generalize the popular denoising
diffusion probabilistic models to STGs, leading to a novel non-autoregressive
framework called DiffSTG, along with the first denoising network UGnet for STG
in the framework. Our approach combines the spatio-temporal learning
capabilities of STGNNs with the uncertainty measurements of diffusion models.
Extensive experiments validate that DiffSTG reduces the Continuous Ranked
Probability Score (CRPS) by 4%-14%, and Root Mean Squared Error (RMSE) by 2%-7%
over existing methods on three real-world datasets.
</p></li>
</ul>

<h3>Title: Transport with Support: Data-Conditional Diffusion Bridges. (arXiv:2301.13636v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.13636">http://arxiv.org/abs/2301.13636</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.13636] Transport with Support: Data-Conditional Diffusion Bridges](http://arxiv.org/abs/2301.13636) #diffusion</code></li>
<li>Summary: <p>The dynamic Schr\"odinger bridge problem provides an appealing setting for
solving optimal transport problems by learning non-linear diffusion processes
using efficient iterative solvers. Recent works have demonstrated
state-of-the-art results (eg. in modelling single-cell embryo RNA sequences or
sampling from complex posteriors) but are limited to learning bridges with only
initial and terminal constraints. Our work extends this paradigm by proposing
the Iterative Smoothing Bridge (ISB). We integrate Bayesian filtering and
optimal control into learning the diffusion process, enabling constrained
stochastic processes governed by sparse observations at intermediate stages and
terminal constraints. We assess the effectiveness of our method on synthetic
and real-world data and show that the ISB generalises well to high-dimensional
data, is computationally efficient, and provides accurate estimates of the
marginals at intermediate and terminal times.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
