<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-10-24</h1>
<h3>Title: Fourier-Based GAN Fingerprint Detection using ResNet50</h3>
<ul>
<li><strong>Authors: </strong>Sai Teja Erukude, Viswa Chaitanya Marella, Suhasnadh Reddy Veluru</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19840">https://arxiv.org/abs/2510.19840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19840">https://arxiv.org/pdf/2510.19840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19840]] Fourier-Based GAN Fingerprint Detection using ResNet50(https://arxiv.org/abs/2510.19840)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rapid rise of photorealistic images produced from Generative Adversarial Networks (GANs) poses a serious challenge for image forensics and industrial systems requiring reliable content authenticity. This paper uses frequency-domain analysis combined with deep learning to solve the problem of distinguishing StyleGAN-generated images from real ones. Specifically, a two-dimensional Discrete Fourier Transform (2D DFT) was applied to transform images into the Fourier domain, where subtle periodic artifacts become detectable. A ResNet50 neural network is trained on these transformed images to differentiate between real and synthetic ones. The experiments demonstrate that the frequency-domain model achieves a 92.8 percent and an AUC of 0.95, significantly outperforming the equivalent model trained on raw spatial-domain images. These results indicate that the GAN-generated images have unique frequency-domain signatures or "fingerprints". The method proposed highlights the industrial potential of combining signal processing techniques and deep learning to enhance digital forensics and strengthen the trustworthiness of industrial AI systems.</li>
</ul>

<h3>Title: CourtGuard: A Local, Multiagent Prompt Injection Classifier</h3>
<ul>
<li><strong>Authors: </strong>Isaac Wu, Michael Maslowski</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19844">https://arxiv.org/abs/2510.19844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19844">https://arxiv.org/pdf/2510.19844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19844]] CourtGuard: A Local, Multiagent Prompt Injection Classifier(https://arxiv.org/abs/2510.19844)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) become integrated into various sensitive applications, prompt injection, the use of prompting to induce harmful behaviors from LLMs, poses an ever increasing risk. Prompt injection attacks can cause LLMs to leak sensitive data, spread misinformation, and exhibit harmful behaviors. To defend against these attacks, we propose CourtGuard, a locally-runnable, multiagent prompt injection classifier. In it, prompts are evaluated in a court-like multiagent LLM system, where a "defense attorney" model argues the prompt is benign, a "prosecution attorney" model argues the prompt is a prompt injection, and a "judge" model gives the final classification. CourtGuard has a lower false positive rate than the Direct Detector, an LLM as-a-judge. However, CourtGuard is generally a worse prompt injection detector. Nevertheless, this lower false positive rate highlights the importance of considering both adversarial and benign scenarios for the classification of a prompt. Additionally, the relative performance of CourtGuard in comparison to other prompt injection classifiers advances the use of multiagent systems as a defense against prompt injection attacks. The implementations of CourtGuard and the Direct Detector with full prompts for Gemma-3-12b-it, Llama-3.3-8B, and Phi-4-mini-instruct are available at this https URL.</li>
</ul>

<h3>Title: Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability</h3>
<ul>
<li><strong>Authors: </strong>Artur Zolkowski, Wen Xing, David Lindner, Florian Tramèr, Erik Jenner</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19851">https://arxiv.org/abs/2510.19851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19851">https://arxiv.org/pdf/2510.19851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19851]] Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability(https://arxiv.org/abs/2510.19851)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent findings suggest that misaligned models may exhibit deceptive behavior, raising concerns about output trustworthiness. Chain-of-thought (CoT) is a promising tool for alignment monitoring: when models articulate their reasoning faithfully, monitors can detect and mitigate harmful behaviors before undesirable outcomes occur. However, a key uncertainty is: Can models obfuscate their CoT in order to pursue hidden adversarial objectives while evading detection? To answer this question and thus stress-test CoT monitorability, we develop a composable and quantifiable taxonomy of prompts to elicit CoT obfuscation. We evaluate both internal CoT (reasoning traces) and external CoT (prompted reasoning in outputs) using toy tasks and more realistic environments in SHADE-Arena. We show that: (i) CoT monitoring performs accurately and efficiently without obfuscation pressure. (ii) Under strong obfuscation pressure, some models successfully complete adversarial tasks while evading detection. (iii) Models do not obfuscate their internal CoT as much as their external CoT (under prompt pressure). These results suggest that while CoT provides valuable oversight in benign settings, robust deployment requires model-specific stress-testing of monitorability.</li>
</ul>

<h3>Title: Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts</h3>
<ul>
<li><strong>Authors: </strong>Eranga Bandara, Sachin Shetty, Ravi Mukkamala, Ross Gore, Peter Foytik, Safdar H. Bouk, Abdul Rahman, Xueping Liang, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19856">https://arxiv.org/abs/2510.19856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19856">https://arxiv.org/pdf/2510.19856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19856]] Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts(https://arxiv.org/abs/2510.19856)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In recent years, blockchain has experienced widespread adoption across various industries, becoming integral to numerous enterprise applications. Concurrently, the rise of generative AI and LLMs has transformed human-computer interactions, offering advanced capabilities in understanding and generating human-like text. The introduction of the MCP has further enhanced AI integration by standardizing communication between AI systems and external data sources. Despite these advancements, there is still no standardized method for seamlessly integrating LLM applications and blockchain. To address this concern, we propose "MCC: Model Context Contracts" a novel framework that enables LLMs to interact directly with blockchain smart contracts through MCP-like protocol. This integration allows AI agents to invoke blockchain smart contracts, facilitating more dynamic and context-aware interactions between users and blockchain networks. Essentially, it empowers users to interact with blockchain systems and perform transactions using queries in natural language. Within this proposed architecture, blockchain smart contracts can function as intelligent agents capable of recognizing user input in natural language and executing the corresponding transactions. To ensure that the LLM accurately interprets natural language inputs and maps them to the appropriate MCP functions, the LLM was fine-tuned using a custom dataset comprising user inputs paired with their corresponding MCP server functions. This fine-tuning process significantly improved the platform's performance and accuracy. To validate the effectiveness of MCC, we have developed an end-to-end prototype implemented on the Rahasak blockchain with the fine-tuned Llama-4 LLM. To the best of our knowledge, this research represents the first approach to using the concept of Model Context Protocol to integrate LLMs with blockchain.</li>
</ul>

<h3>Title: DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse</h3>
<ul>
<li><strong>Authors: </strong>Jindi Wang, Yidi Zhang, Zhaoxing Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19858">https://arxiv.org/abs/2510.19858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19858">https://arxiv.org/pdf/2510.19858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19858]] DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse(https://arxiv.org/abs/2510.19858)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>This study presents DeBERTa-KC, a transformer-based model for automatic classification of knowledge construction (KC) levels in online science learning discourse. Using comments collected from four popular YouTube science channels (2022--2024), a balanced corpus of 20,000 manually annotated samples was created across four KC categories: \textit{nonKC}, \textit{Share}, \textit{Explore}, and \textit{Negotiate}. The proposed model extends DeBERTa-v3 with Focal Loss, Label Smoothing, and R-Drop regularization to address class imbalance and enhance generalization. A reproducible end-to-end pipeline was implemented, encompassing data extraction, annotation, preprocessing, training, and evaluation. Across 10-fold stratified cross-validation, DeBERTa-KC achieved a macro-F1 of $0.836 \pm 0.008$, significantly out-performing both classical and transformer baselines ($p<0.01$). Per-category results indicate strong sensitivity to higher-order epistemic engagement, particularly in \textit{Explore} and \textit{Negotiate} discourse. These findings demonstrate that large language models can effectively capture nuanced indicators of knowledge construction in informal digital learning environments, offering scalable, theory-informed approaches to discourse analysis and the development of automated tools for assessing epistemic engagement.</li>
</ul>

<h3>Title: Cyberattack Detection in Critical Infrastructure and Supply Chains</h3>
<ul>
<li><strong>Authors: </strong>Smita Khapre</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19859">https://arxiv.org/abs/2510.19859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19859">https://arxiv.org/pdf/2510.19859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19859]] Cyberattack Detection in Critical Infrastructure and Supply Chains(https://arxiv.org/abs/2510.19859)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Cyberattack detection in Critical Infrastructure and Supply Chains has become challenging in Industry 4.0. Intrusion Detection Systems (IDS) are deployed to counter the cyberattacks. However, an IDS effectively detects attacks based on the known signatures and patterns, Zero-day attacks go undetected. To overcome this drawback in IDS, the integration of a Dense Neural Network (DNN) with Data Augmentation is proposed. It makes IDS intelligent and enables it to self-learn with high accuracy when a novel attack is encountered. The network flow captures datasets are highly imbalanced same as the real network itself. The Data Augmentation plays a crucial role in balancing the data. The balancing of data is challenging as the minority class is as low as 0.000004\% of the dataset, and the abundant class is higher than 80\% of the dataset. Synthetic Minority Oversampling Technique is used for balancing the data. However, higher accuracies are achieved with balanced test data, lower accuracies are noticeable with the original imbalanced test data suggesting overfitting. A comparison with state-of-the-art research using Synthetic Minority Oversampling Technique with Edited Nearest Neighbor shows the classification of classes remains poor for the original dataset. This suggests highly imbalanced datasets of network flow require a different method of data augmentation.</li>
</ul>

<h3>Title: Some Attention is All You Need for Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Felix Michalak, Steven Abreu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19861">https://arxiv.org/abs/2510.19861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19861">https://arxiv.org/pdf/2510.19861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19861]] Some Attention is All You Need for Retrieval(https://arxiv.org/abs/2510.19861)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We demonstrate complete functional segregation in hybrid SSM-Transformer architectures: retrieval depends exclusively on self-attention layers. Across RecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic retrieval failure (0% accuracy), while SSM layers show no compensatory mechanisms even with improved prompting. Conversely, sparsifying attention to just 15% of heads maintains near-perfect retrieval while preserving 84% MMLU performance, suggesting self-attention specializes primarily for retrieval tasks. We identify precise mechanistic requirements for retrieval: needle tokens must be exposed during generation and sufficient context must be available during prefill or generation. This strict functional specialization challenges assumptions about redundancy in hybrid architectures and suggests these models operate as specialized modules rather than integrated systems, with immediate implications for architecture optimization and interpretability.</li>
</ul>

<h3>Title: An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics</h3>
<ul>
<li><strong>Authors: </strong>Xincheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19866">https://arxiv.org/abs/2510.19866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19866">https://arxiv.org/pdf/2510.19866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19866]] An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics(https://arxiv.org/abs/2510.19866)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study evaluates the pedagogical soundness and usability of AI-generated lesson plans across five leading large language models: ChatGPT (GPT-5), Claude Sonnet 4.5, Gemini 2.5 Flash, DeepSeek V3.2, and Grok 4. Beyond model choice, three structured prompt frameworks were tested: TAG (Task, Audience, Goal), RACE (Role, Audience, Context, Execution), and COSTAR (Context, Objective, Style, Tone, Audience, Response Format). Fifteen lesson plans were generated for a single high-school physics topic, The Electromagnetic Spectrum. The lesson plans were analyzed through four automated computational metrics: (1) readability and linguistic complexity, (2) factual accuracy and hallucination detection, (3) standards and curriculum alignment, and (4) cognitive demand of learning objectives. Results indicate that model selection exerted the strongest influence on linguistic accessibility, with DeepSeek producing the most readable teaching plan (FKGL = 8.64) and Claude generating the densest language (FKGL = 19.89). The prompt framework structure most strongly affected the factual accuracy and pedagogical completeness, with the RACE framework yielding the lowest hallucination index and the highest incidental alignment with NGSS curriculum standards. Across all models, the learning objectives in the fifteen lesson plans clustered at the Remember and Understand tiers of Bloom's taxonomy. There were limited higher-order verbs in the learning objectives extracted. Overall, the findings suggest that readability is significantly governed by model design, while instructional reliability and curricular alignment depend more on the prompt framework. The most effective configuration for lesson plans identified in the results was to combine a readability-optimized model with the RACE framework and an explicit checklist of physics concepts, curriculum standards, and higher-order objectives.</li>
</ul>

<h3>Title: From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Yatai Ji, Teng Wang, Yuying Ge, Zhiheng Liu, Sidi Yang, Ying Shan, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19871">https://arxiv.org/abs/2510.19871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19871">https://arxiv.org/pdf/2510.19871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19871]] From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model(https://arxiv.org/abs/2510.19871)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Discrete diffusion models have emerged as a promising direction for vision-language tasks, offering bidirectional context modeling and theoretical parallelization. However, their practical application is severely hindered by a train-inference discrepancy, which leads to catastrophic error cascades: initial token errors during parallel decoding pollute the generation context, triggering a chain reaction of compounding errors and leading to syntactic errors and semantic hallucinations. To address this fundamental challenge, we reframe the generation process from passive denoising to active refining. We introduce ReDiff, a refining-enhanced diffusion framework that teaches the model to identify and correct its own errors. Our approach features a two-stage training process: first, we instill a foundational revision capability by training the model to revise synthetic errors; second, we implement a novel online self-correction loop where the model is explicitly trained to revise its own flawed drafts by learning from an expert's corrections. This mistake-driven learning endows the model with the crucial ability to revisit and refine its already generated output, effectively breaking the error cascade. Extensive experiments demonstrate that ReDiff significantly improves the coherence and factual accuracy of generated content, enabling stable and efficient parallel generation far superior to traditional denoising methods. Our codes and models are available at this https URL.</li>
</ul>

<h3>Title: From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph</h3>
<ul>
<li><strong>Authors: </strong>Junfeng Gong, Zhiyi Wei, Junying Chen, Cheng Liu, Huawei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19873">https://arxiv.org/abs/2510.19873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19873">https://arxiv.org/pdf/2510.19873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19873]] From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph(https://arxiv.org/abs/2510.19873)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant evolution of CUDA programming and domain-specific libraries, effectively utilizing GPUs with massively parallel engines remains difficult. Large language models (LLMs) show strong potential in generating optimized CUDA code from sequential code. However, using LLMs in practice faces two major challenges: cloud-based APIs pose risks of code leakage, and local deployment is often computationally expensive and inefficient. These drawbacks have spurred interest in small language models (SLMs), which are more lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs can achieve performance comparable to LLMs on specific tasks. While SLMs can match LLMs on domain-specific tasks, their limited reasoning abilities lead to suboptimal performance in complex CUDA generation according to our experiments. To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented generation framework that transfers LLM-level reasoning to smaller models. ReGraphT organizes CUDA optimization trajectories into a structured reasoning graph, modeling the combined CUDA optimizations as state transitions, and leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also present a CUDA-specific benchmark with difficulty tiers defined by reasoning complexity to evaluate models more comprehensively. Experiments show that ReGraphT outperforms HPC-specific fine-tuned models and other retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level performance without the associated privacy risks or excessive computing overhead.</li>
</ul>

<h3>Title: Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention</h3>
<ul>
<li><strong>Authors: </strong>J Rosser, José Luis Redondo García, Gustavo Penha, Konstantina Palla, Hugues Bouchard</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19875">https://arxiv.org/abs/2510.19875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19875">https://arxiv.org/pdf/2510.19875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19875]] Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention(https://arxiv.org/abs/2510.19875)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) scale to million-token contexts, traditional Mechanistic Interpretability techniques for analyzing attention scale quadratically with context length, demanding terabytes of memory beyond 100,000 tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic sparse attention to efficiently analyze long context attention patterns. We present Stream, a compilable hierarchical pruning algorithm that estimates per-head sparse attention masks in near-linear time $O(T \log T)$ and linear space $O(T)$, enabling one-pass interpretability at scale. Stream performs a binary-search-style refinement to retain only the top-$k$ key blocks per query while preserving the model's next-token behavior. We apply Stream to long chain-of-thought reasoning traces and identify thought anchors while pruning 97-99\% of token interactions. On the RULER benchmark, Stream preserves critical retrieval paths while discarding 90-96\% of interactions and exposes layer-wise routes from the needle to output. Our method offers a practical drop-in tool for analyzing attention patterns and tracing information flow without terabytes of caches. By making long context interpretability feasible on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring. Code is available at this https URL.</li>
</ul>

<h3>Title: Automated HIV Screening on Dutch EHR with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lang Zhou, Amrish Jhingoer, Yinghao Luo, Klaske Vliegenthart--Jongbloed, Carlijn Jordans, Ben Werkhoven, Tom Seinen, Erik van Mulligen, Casper Rokx, Yunlei Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19879">https://arxiv.org/abs/2510.19879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19879">https://arxiv.org/pdf/2510.19879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19879]] Automated HIV Screening on Dutch EHR with Large Language Models(https://arxiv.org/abs/2510.19879)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efficient screening and early diagnosis of HIV are critical for reducing onward transmission. Although large scale laboratory testing is not feasible, the widespread adoption of Electronic Health Records (EHRs) offers new opportunities to address this challenge. Existing research primarily focuses on applying machine learning methods to structured data, such as patient demographics, for improving HIV diagnosis. However, these approaches often overlook unstructured text data such as clinical notes, which potentially contain valuable information relevant to HIV risk. In this study, we propose a novel pipeline that leverages a Large Language Model (LLM) to analyze unstructured EHR text and determine a patient's eligibility for further HIV testing. Experimental results on clinical data from Erasmus University Medical Center Rotterdam demonstrate that our pipeline achieved high accuracy while maintaining a low false negative rate.</li>
</ul>

<h3>Title: A Proactive Insider Threat Management Framework Using Explainable Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Selma Shikonde, Mike Wa Nkongolo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19883">https://arxiv.org/abs/2510.19883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19883">https://arxiv.org/pdf/2510.19883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19883]] A Proactive Insider Threat Management Framework Using Explainable Machine Learning(https://arxiv.org/abs/2510.19883)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Over the years, the technological landscape has evolved, reshaping the security posture of organisations and increasing their exposure to cybersecurity threats, many originating from within. Insider threats remain a major challenge, particularly in sectors where cybersecurity infrastructure, expertise, and regulations are still developing. This study proposes the Insider Threat Explainable Machine Learning (IT-XML) framework, which integrates the Cross-Industry Standard Process for Data Mining (CRISP-DM) with Hidden Markov Models (HMM) to enhance proactive insider threat management and decision-making. A quantitative approach is adopted using an online questionnaire to assess employees' knowledge of insider threat patterns, access control, privacy practices, and existing policies across three large data-sensitive organisations. The IT-XML framework provides assessment capabilities through survey-based data, HMM-driven pattern recognition for security maturity classification, and evidence-based recommendations for proactive threat mitigation. The framework classified all organisations at the developing security maturity level with 97-98% confidence and achieved a classification accuracy of 91.7%, identifying audit log access limits as the most critical control. Random Forest analysis highlighted vendor breach notifications (0.081) and regular audit log reviews (0.052) as key determinants of resilience. Explainability methods such as SHAP and LIME improved model transparency and interpretability, demonstrating the framework's potential to strengthen insider threat management practices.</li>
</ul>

<h3>Title: An Expert-grounded benchmark of General Purpose LLMs in LCA</h3>
<ul>
<li><strong>Authors: </strong>Artur Donaldson, Bharathan Balaji, Cajetan Oriekezie, Manish Kumar, Laure Patouillard</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19886">https://arxiv.org/abs/2510.19886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19886">https://arxiv.org/pdf/2510.19886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19886]] An Expert-grounded benchmark of General Purpose LLMs in LCA(https://arxiv.org/abs/2510.19886)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Purpose: Artificial intelligence (AI), and in particular large language models (LLMs), are increasingly being explored as tools to support life cycle assessment (LCA). While demonstrations exist across environmental and social domains, systematic evidence on their reliability, robustness, and usability remains limited. This study provides the first expert-grounded benchmark of LLMs in LCA, addressing the absence of standardized evaluation frameworks in a field where no clear ground truth or consensus protocols exist. Methods: We evaluated eleven general-purpose LLMs, spanning both commercial and open-source families, across 22 LCA-related tasks. Seventeen experienced practitioners reviewed model outputs against criteria directly relevant to LCA practice, including scientific accuracy, explanation quality, robustness, verifiability, and adherence to instructions. We collected 168 expert reviews. Results: Experts judged 37% of responses to contain inaccurate or misleading information. Ratings of accuracy and quality of explanation were generally rated average or good on many models even smaller models, and format adherence was generally rated favourably. Hallucination rates varied significantly, with some models producing hallucinated citations at rates of up to 40%. There was no clear-cut distinction between ratings on open-weight versus closed-weight LLMs, with open-weight models outperforming or competing on par with closed-weight models on criteria such as accuracy and quality of explanation. Conclusion: These findings highlight the risks of applying LLMs naïvely in LCA, such as when LLMs are treated as free-form oracles, while also showing benefits especially around quality of explanation and alleviating labour intensiveness of simple tasks. The use of general-purpose LLMs without grounding mechanisms presents ...</li>
</ul>

<h3>Title: From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem</h3>
<ul>
<li><strong>Authors: </strong>Mostafa Ameli, Van Anh Le, Sulthana Shams, Alexander Skabardonis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19889">https://arxiv.org/abs/2510.19889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19889">https://arxiv.org/pdf/2510.19889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19889]] From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem(https://arxiv.org/abs/2510.19889)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The traffic assignment problem is essential for traffic flow analysis, traditionally solved using mathematical programs under the Equilibrium principle. These methods become computationally prohibitive for large-scale networks due to non-linear growth in complexity with the number of OD pairs. This study introduces a novel data-driven approach using deep neural networks, specifically leveraging the Transformer architecture, to predict equilibrium path flows directly. By focusing on path-level traffic distribution, the proposed model captures intricate correlations between OD pairs, offering a more detailed and flexible analysis compared to traditional link-level approaches. The Transformer-based model drastically reduces computation time, while adapting to changes in demand and network structure without the need for recalculation. Numerical experiments are conducted on the Manhattan-like synthetic network, the Sioux Falls network, and the Eastern-Massachusetts network. The results demonstrate that the proposed model is orders of magnitude faster than conventional optimization. It efficiently estimates path-level traffic flows in multi-class networks, reducing computational costs and improving prediction accuracy by capturing detailed trip and flow information. The model also adapts flexibly to varying demand and network conditions, supporting traffic management and enabling rapid `what-if' analyses for enhanced transportation planning and policy-making.</li>
</ul>

<h3>Title: Deep Sequence-to-Sequence Models for GNSS Spoofing Detection</h3>
<ul>
<li><strong>Authors: </strong>Jan Zelinka, Oliver Kost, Marek Hrúz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19890">https://arxiv.org/abs/2510.19890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19890">https://arxiv.org/pdf/2510.19890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19890]] Deep Sequence-to-Sequence Models for GNSS Spoofing Detection(https://arxiv.org/abs/2510.19890)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>We present a data generation framework designed to simulate spoofing attacks and randomly place attack scenarios worldwide. We apply deep neural network-based models for spoofing detection, utilizing Long Short-Term Memory networks and Transformer-inspired architectures. These models are specifically designed for online detection and are trained using the generated dataset. Our results demonstrate that deep learning models can accurately distinguish spoofed signals from genuine ones, achieving high detection performance. The best results are achieved by Transformer-inspired architectures with early fusion of the inputs resulting in an error rate of 0.16%.</li>
</ul>

<h3>Title: Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Nishant Balepur, Dang Nguyen, Dayeon Ki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19892">https://arxiv.org/abs/2510.19892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19892">https://arxiv.org/pdf/2510.19892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19892]] Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities(https://arxiv.org/abs/2510.19892)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLMs) are often assessed on static, individual benchmarks -- which cannot jointly assess MLM capabilities in a single task -- or rely on human or model pairwise comparisons -- which is highly subjective, expensive, and allows models to exploit superficial shortcuts (e.g., verbosity) to inflate their win-rates. To overcome these issues, we propose game-based evaluations to holistically assess MLM capabilities. Games require multiple abilities for players to win, are inherently competitive, and are governed by fix, objective rules, and makes evaluation more engaging, providing a robust framework to address the aforementioned challenges. We manifest this evaluation specifically through Dixit, a fantasy card game where players must generate captions for a card that trick some, but not all players, into selecting the played card. Our quantitative experiments with five MLMs show Dixit win-rate rankings are perfectly correlated with those on popular MLM benchmarks, while games between human and MLM players in Dixit reveal several differences between agent strategies and areas of improvement for MLM reasoning.</li>
</ul>

<h3>Title: FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Shiqi Dai, Wei Dai, Jiaee Cheong, Paul Pu Liang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19893">https://arxiv.org/abs/2510.19893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19893">https://arxiv.org/pdf/2510.19893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19893]] FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning(https://arxiv.org/abs/2510.19893)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Medical artificial intelligence systems have achieved remarkable diagnostic capabilities, yet they consistently exhibit performance disparities across demographic groups, causing real-world harm to underrepresented populations. While recent multimodal reasoning foundation models have advanced clinical diagnosis through integrated analysis of diverse medical data, reasoning trainings via reinforcement learning inherit and often amplify biases present in training datasets dominated by majority populations. We introduce Fairness-aware Group Relative Policy Optimization (FairGRPO), a hierarchical reinforcement learning approach that promotes equitable learning across heterogeneous clinical populations. FairGRPO employs adaptive importance weighting of advantages based on representation, task difficulty, and data source. To address the common issue of missing demographic labels in the clinical domain, we further employ unsupervised clustering, which automatically discovers latent demographic groups when labels are unavailable. Through comprehensive experiments across 7 clinical diagnostic datasets spanning 5 clinical modalities across X-ray, CT scan, dermoscropy, mammography and ultrasound, we demonstrate that FairGRPO reduces predictive parity by 27.2% against all vanilla and bias mitigated RL baselines, while improving F1 score by 12.49%. Furthermore, training dynamics analysis reveals that FairGRPO progressively improves fairness throughout optimization, while baseline RL methods exhibit deteriorating fairness as training progresses. Based on FairGRPO, we release FairMedGemma-4B, a fairness-aware clinical VLLM that achieves state-of-the-art performance while demonstrating significantly reduced disparities across demographic groups.</li>
</ul>

<h3>Title: Large Language Model enabled Mathematical Modeling</h3>
<ul>
<li><strong>Authors: </strong>Guoyun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19895">https://arxiv.org/abs/2510.19895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19895">https://arxiv.org/pdf/2510.19895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19895]] Large Language Model enabled Mathematical Modeling(https://arxiv.org/abs/2510.19895)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The integration of Large Language Models (LLMs) with optimization modeling offers a promising avenue for advancing decision-making in operations research (OR). Traditional optimization methods,such as linear programming, mixed integer programming, and simulation depend heavily on domain expertise to translate real-world problems into solvable mathematical models. While solvers like Gurobi and COPT are powerful, expert input remains essential for defining objectives, constraints, and variables. This research investigates the potential of LLMs, specifically the DeepSeek-R1 model, to bridge this formulation gap using natural language understanding and code generation. Although prior models like GPT-4, Claude, and Bard have shown strong performance in NLP and reasoning tasks, their high token costs and tendency toward hallucinations limit real-world applicability in supply chain contexts. In contrast, DeepSeek-R1, a cost-efficient and high-performing model trained with reinforcement learning, presents a viable alternative. Despite its success in benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied OR scenarios remains under explored. This study systematically evaluates DeepSeek-R1 across four key OR benchmarks: NL4OPT, IndustryOR, EasyLP, and ComplexOR. Our methodology includes baseline assessments, the development of a hallucination taxonomy, and the application of mitigation strategies like LLM-as-a-Judge, Few-shot Learning (FSL), Tool Calling, and a Multi-agent Framework. These techniques aim to reduce hallucinations, enhance formulation accuracy, and better align model outputs with user intent.</li>
</ul>

<h3>Title: Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification</h3>
<ul>
<li><strong>Authors: </strong>Filipe Ferreira de Oliveira, Matheus Becali Rocha, Renato A. Krohling</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19896">https://arxiv.org/abs/2510.19896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19896">https://arxiv.org/pdf/2510.19896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19896]] Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification(https://arxiv.org/abs/2510.19896)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>In this paper, we propose an approach to support the diagnosis of urinary tract diseases, with a focus on bladder cancer, using SHAP (SHapley Additive exPlanations)-based feature selection to enhance the transparency and effectiveness of predictive models. Six binary classification scenarios were developed to distinguish bladder cancer from other urological and oncological conditions. The algorithms XGBoost, LightGBM, and CatBoost were employed, with hyperparameter optimization performed using Optuna and class balancing with the SMOTE technique. The selection of predictive variables was guided by importance values through SHAP-based feature selection while maintaining or even improving performance metrics such as balanced accuracy, precision, and specificity. The use of explainability techniques (SHAP) for feature selection proved to be an effective approach. The proposed methodology may contribute to the development of more transparent, reliable, and efficient clinical decision support systems, optimizing screening and early diagnosis of urinary tract diseases.</li>
</ul>

<h3>Title: Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Jackson Hassell, Dan Zhang, Hannah Kim, Tom Mitchell, Estevam Hruschka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19897">https://arxiv.org/abs/2510.19897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19897">https://arxiv.org/pdf/2510.19897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19897]] Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation(https://arxiv.org/abs/2510.19897)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate how agents built on pretrained large language models can learn target classification functions from labeled examples without parameter updates. While conventional approaches like fine-tuning are often costly, inflexible, and opaque, we propose a memory-augmented framework that leverages both labeled data and LLM-generated critiques. Our framework uses episodic memory to store instance-level critiques-capturing specific past experiences-and semantic memory to distill these into reusable, task-level guidance. Across a diverse set of tasks, incorporating critiques yields up to a 24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines that rely only on labels. Through extensive empirical evaluation, we uncover distinct behavioral differences between OpenAI and opensource models, particularly in how they handle fact-oriented versus preference-based data. To interpret how models respond to different representations of supervision encoded in memory, we introduce a novel metric, suggestibility. This helps explain observed behaviors and illuminates how model characteristics and memory strategies jointly shape learning dynamics. Our findings highlight the promise of memory-driven, reflective learning for building more adaptive and interpretable LLM agents.</li>
</ul>

<h3>Title: Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Xiang Li, Buxin Su, Chendi Wang, Qi Long, Weijie J. Su</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, math.ST, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19934">https://arxiv.org/abs/2510.19934</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19934">https://arxiv.org/pdf/2510.19934</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19934]] Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy(https://arxiv.org/abs/2510.19934)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Differentially private (DP) decentralized Federated Learning (FL) allows local users to collaborate without sharing their data with a central server. However, accurately quantifying the privacy budget of private FL algorithms is challenging due to the co-existence of complex algorithmic components such as decentralized communication and local updates. This paper addresses privacy accounting for two decentralized FL algorithms within the $f$-differential privacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods tailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which quantifies privacy leakage between user pairs under random-walk communication, and Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise injection via shared secrets. By combining tools from $f$-DP theory and Markov chain concentration, our accounting framework captures privacy amplification arising from sparse communication, local iterations, and correlated noise. Experiments on synthetic and real datasets demonstrate that our methods yield consistently tighter $(\epsilon,\delta)$ bounds and improved utility compared to Rényi DP-based approaches, illustrating the benefits of $f$-DP in decentralized privacy accounting.</li>
</ul>

<h3>Title: Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System</h3>
<ul>
<li><strong>Authors: </strong>Foad Namjoo, Neng Wan, Devan Mallory, Yuyi Chang, Nithin Sugavanam, Long Yin Lee, Ning Xiong, Emre Ertin, Jeff M. Phillips</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.HC, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19938">https://arxiv.org/abs/2510.19938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19938">https://arxiv.org/pdf/2510.19938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19938]] Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System(https://arxiv.org/abs/2510.19938)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Real-world health studies require continuous and secure data collection from mobile and wearable devices. We introduce MotionPI, a smartphone-based system designed to collect behavioral and health data through sensors and surveys with minimal interaction from participants. The system integrates passive data collection (such as GPS and wristband motion data) with Ecological Momentary Assessment (EMA) surveys, which can be triggered randomly or based on physical activity. MotionPI is designed to work under real-life constraints, including limited battery life, weak or intermittent cellular connection, and minimal user supervision. It stores data both locally and on a secure cloud server, with encrypted transmission and storage. It integrates through Bluetooth Low Energy (BLE) into wristband devices that store raw data and communicate motion summaries and trigger events. MotionPI demonstrates a practical solution for secure and scalable mobile data collection in cyber-physical health studies.</li>
</ul>

<h3>Title: Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</h3>
<ul>
<li><strong>Authors: </strong>Shaocong Ma, Heng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19950">https://arxiv.org/abs/2510.19950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19950">https://arxiv.org/pdf/2510.19950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19950]] Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets(https://arxiv.org/abs/2510.19950)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In financial applications, reinforcement learning (RL) agents are commonly trained on historical data, where their actions do not influence prices. However, during deployment, these agents trade in live markets where their own transactions can shift asset prices, a phenomenon known as market impact. This mismatch between training and deployment environments can significantly degrade performance. Traditional robust RL approaches address this model misspecification by optimizing the worst-case performance over a set of uncertainties, but typically rely on symmetric structures that fail to capture the directional nature of market impact. To address this issue, we develop a novel class of elliptic uncertainty sets. We establish both implicit and explicit closed-form solutions for the worst-case uncertainty under these sets, enabling efficient and tractable robust policy evaluation. Experiments on single-asset and multi-asset trading tasks demonstrate that our method achieves superior Sharpe ratio and remains robust under increasing trade volumes, offering a more faithful and scalable approach to RL in financial markets.</li>
</ul>

<h3>Title: Transformed Multi-view 3D Shape Features with Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Márcus Vinícius Lobo Costa, Sherlon Almeida da Silva, Bárbara Caroline Benato, Leo Sampaio Ferraz Ribeiro, Moacir Antonelli Ponti</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19955">https://arxiv.org/abs/2510.19955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19955">https://arxiv.org/pdf/2510.19955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19955]] Transformed Multi-view 3D Shape Features with Contrastive Learning(https://arxiv.org/abs/2510.19955)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenges in representation learning of 3D shape features by investigating state-of-the-art backbones paired with both contrastive supervised and self-supervised learning objectives. Computer vision methods struggle with recognizing 3D objects from 2D images, often requiring extensive labeled data and relying on Convolutional Neural Networks (CNNs) that may overlook crucial shape relationships. Our work demonstrates that Vision Transformers (ViTs) based architectures, when paired with modern contrastive objectives, achieve promising results in multi-view 3D analysis on our downstream tasks, unifying contrastive and 3D shape understanding pipelines. For example, supervised contrastive losses reached about 90.6% accuracy on ModelNet10. The use of ViTs and contrastive learning, leveraging ViTs' ability to understand overall shapes and contrastive learning's effectiveness, overcomes the need for extensive labeled data and the limitations of CNNs in capturing crucial shape relationships. The success stems from capturing global shape semantics via ViTs and refining local discriminative features through contrastive optimization. Importantly, our approach is empirical, as it is grounded on extensive experimental evaluation to validate the effectiveness of combining ViTs with contrastive objectives for 3D representation learning.</li>
</ul>

<h3>Title: Q-RAN: Quantum-Resilient O-RAN Architecture</h3>
<ul>
<li><strong>Authors: </strong>Vipin Rathi, Lakshya Chopra, Madhav Agarwal, Nitin Rajput, Kriish Sharma, Sushant Mundepi, Shivam Gangwar, Rudraksh Rawal, Jishan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19968">https://arxiv.org/abs/2510.19968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19968">https://arxiv.org/pdf/2510.19968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19968]] Q-RAN: Quantum-Resilient O-RAN Architecture(https://arxiv.org/abs/2510.19968)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The telecommunications industry faces a dual transformation: the architectural shift toward Open Radio Access Networks (O-RAN) and the emerging threat from quantum computing. O-RAN disaggregated, multi-vendor architecture creates a larger attack surface vulnerable to crypt-analytically relevant quantum computers(CRQCs) that will break current public key cryptography. The Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate, as adversaries can intercept encrypted data today for future decryption. This paper presents Q-RAN, a comprehensive quantum-resistant security framework for O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204), integrated with Quantum Random Number Generators (QRNG) for cryptographic entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate Authority (PQ-CA) within the SMO framework. This work provides a complete roadmap for securing disaggregated O-RAN ecosystems against quantum adversaries.</li>
</ul>

<h3>Title: Towards Strong Certified Defense with Universal Asymmetric Randomization</h3>
<ul>
<li><strong>Authors: </strong>Hanbin Hong, Ashish Kundu, Ali Payani, Binghui Wang, Yuan Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19977">https://arxiv.org/abs/2510.19977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19977">https://arxiv.org/pdf/2510.19977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19977]] Towards Strong Certified Defense with Universal Asymmetric Randomization(https://arxiv.org/abs/2510.19977)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Randomized smoothing has become essential for achieving certified adversarial robustness in machine learning models. However, current methods primarily use isotropic noise distributions that are uniform across all data dimensions, such as image pixels, limiting the effectiveness of robustness certification by ignoring the heterogeneity of inputs and data dimensions. To address this limitation, we propose UCAN: a novel technique that \underline{U}niversally \underline{C}ertifies adversarial robustness with \underline{A}nisotropic \underline{N}oise. UCAN is designed to enhance any existing randomized smoothing method, transforming it from symmetric (isotropic) to asymmetric (anisotropic) noise distributions, thereby offering a more tailored defense against adversarial attacks. Our theoretical framework is versatile, supporting a wide array of noise distributions for certified robustness in different $\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the classifier's prediction over perturbed inputs with provable robustness bounds through tailored noise injection. Additionally, we develop a novel framework equipped with three exemplary noise parameter generators (NPGs) to optimally fine-tune the anisotropic noise parameters for different data dimensions, allowing for pursuing different levels of robustness enhancements in this http URL evaluations underscore the significant leap in UCAN's performance over existing state-of-the-art methods, demonstrating up to $182.6\%$ improvement in certified accuracy at large certified radii on MNIST, CIFAR10, and ImageNet datasets.\footnote{Code is anonymously available at \href{this https URL}{this https URL}}</li>
</ul>

<h3>Title: SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment</h3>
<ul>
<li><strong>Authors: </strong>Tushar Nayan (1), Ziqi Zhang (2), Ruimin Sun (1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19979">https://arxiv.org/abs/2510.19979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19979">https://arxiv.org/pdf/2510.19979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19979]] SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment(https://arxiv.org/abs/2510.19979)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>With the increasing deployment of Large Language Models (LLMs) on mobile and edge platforms, securing them against model extraction attacks has become a pressing concern. However, protecting model privacy without sacrificing the performance benefits of untrusted AI accelerators, such as GPUs, presents a challenging trade-off. In this paper, we initiate the study of high-performance execution on LLMs and present SecureInfer, a hybrid framework that leverages a heterogeneous Trusted Execution Environments (TEEs)-GPU architecture to isolate privacy-critical components while offloading compute-intensive operations to untrusted accelerators. Building upon an outsourcing scheme, SecureInfer adopts an information-theoretic and threat-informed partitioning strategy: security-sensitive components, including non-linear layers, projection of attention head, FNN transformations, and LoRA adapters, are executed inside an SGX enclave, while other linear operations (matrix multiplication) are performed on the GPU after encryption and are securely restored within the enclave. We implement a prototype of SecureInfer using the LLaMA-2 model and evaluate it across performance and security metrics. Our results show that SecureInfer offers strong security guarantees with reasonable performance, offering a practical solution for secure on-device model inference.</li>
</ul>

<h3>Title: Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency</h3>
<ul>
<li><strong>Authors: </strong>Renzhao Liang, Sizhe Xu, Chenggang Xie, Jingru Chen, Feiyang Ren, Shu Yang, Takahiro Yabe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19980">https://arxiv.org/abs/2510.19980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19980">https://arxiv.org/pdf/2510.19980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19980]] Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency(https://arxiv.org/abs/2510.19980)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Time series forecasting plays a pivotal role in critical domains such as energy management and financial markets. Although deep learning-based approaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the prevailing "long-sequence information gain hypothesis" exhibits inherent limitations. Through systematic experimentation, this study reveals a counterintuitive phenomenon: appropriately truncating historical data can paradoxically enhance prediction accuracy, indicating that existing models learn substantial redundant features (e.g., noise or irrelevant fluctuations) during training, thereby compromising effective signal extraction. Building upon information bottleneck theory, we propose an innovative solution termed Adaptive Masking Loss with Representation Consistency (AMRC), which features two core components: 1) Dynamic masking loss, which adaptively identified highly discriminative temporal segments to guide gradient descent during model training; 2) Representation consistency constraint, which stabilized the mapping relationships among inputs, labels, and predictions. Experimental results demonstrate that AMRC effectively suppresses redundant feature learning while significantly improving model performance. This work not only challenges conventional assumptions in temporal modeling but also provides novel theoretical insights and methodological breakthroughs for developing efficient and robust forecasting models.</li>
</ul>

<h3>Title: FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking</h3>
<ul>
<li><strong>Authors: </strong>Martha Teiko Teye, Ori Maoz, Matthias Rottmann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19981">https://arxiv.org/abs/2510.19981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19981">https://arxiv.org/pdf/2510.19981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19981]] FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking(https://arxiv.org/abs/2510.19981)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework that builds on existing 3D detectors by introducing a transformer-based smoother and a fusion-driven tracker. Inspired by query-based tracking frameworks, FutrTrack employs a multimodal two-stage transformer refinement and tracking pipeline. Our fusion tracker integrates bounding boxes with multimodal bird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without the need for an explicit motion model. The tracker assigns and propagates identities across frames, leveraging both geometric and semantic cues for robust re-identification under occlusion and viewpoint changes. Prior to tracking, we refine sequences of bounding boxes with a temporal smoother over a moving window to refine trajectories, reduce jitter, and improve spatial consistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that query-based transformer tracking methods benefit significantly from multimodal sensor features compared with previous single-sensor approaches. With an aMOTA of 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D MOT benchmarks, reducing identity switches while maintaining competitive accuracy. Our approach provides an efficient framework for improving transformer-based trackers to compete with other neural-network-based methods even with limited data and without pretraining.</li>
</ul>

<h3>Title: QORE : Quantum Secure 5G/B5G Core</h3>
<ul>
<li><strong>Authors: </strong>Vipin Rathi, Lakshya Chopra, Rudraksh Rawal, Nitin Rajput, Shiva Valia, Madhav Aggarwal, Aditya Gairola</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19982">https://arxiv.org/abs/2510.19982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19982">https://arxiv.org/pdf/2510.19982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19982]] QORE : Quantum Secure 5G/B5G Core(https://arxiv.org/abs/2510.19982)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Quantum computing is reshaping the security landscape of modern telecommunications. The cryptographic foundations that secure todays 5G systems, including RSA, Elliptic Curve Cryptography (ECC), and Diffie-Hellman (DH), are all susceptible to attacks enabled by Shors algorithm. Protecting 5G networks against future quantum adversaries has therefore become an urgent engineering and research priority. In this paper we introduce QORE, a quantum-secure 5G and Beyond 5G (B5G) Core framework that provides a clear pathway for transitioning both the 5G Core Network Functions and User Equipment (UE) to Post-Quantum Cryptography (PQC). The framework uses the NIST-standardized lattice-based algorithms Module-Lattice Key Encapsulation Mechanism (ML-KEM) and Module-Lattice Digital Signature Algorithm (ML-DSA) and applies them across the 5G Service-Based Architecture (SBA). A Hybrid PQC (HPQC) configuration is also proposed, combining classical and quantum-safe primitives to maintain interoperability during migration. Experimental validation shows that ML-KEM achieves quantum security with minor performance overhead, meeting the low-latency and high-throughput requirements of carrier-grade 5G systems. The proposed roadmap aligns with ongoing 3GPP SA3 and SA5 study activities on the security and management of post-quantum networks as well as with NIST PQC standardization efforts, providing practical guidance for mitigating quantum-era risks while safeguarding long-term confidentiality and integrity of network data.</li>
</ul>

<h3>Title: LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Xin Lian, Kenneth D. Forbus</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19988">https://arxiv.org/abs/2510.19988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19988">https://arxiv.org/pdf/2510.19988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19988]] LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation(https://arxiv.org/abs/2510.19988)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the broad applicability of large language models (LLMs), their reliance on probabilistic inference makes them vulnerable to errors such as hallucination in generated facts and inconsistent output structure in natural language understanding (NLU) tasks. By contrast, symbolic NLU systems provide interpretable understanding grounded in curated lexicons, semantic resources, and syntactic & semantic interpretation rules. They produce relational representations that can be used for accurate reasoning and planning, as well as incremental debuggable learning. However, symbolic NLU systems tend to be more limited in coverage than LLMs and require scarce knowledge representation and linguistics skills to extend and maintain. This paper explores a hybrid approach that integrates the broad-coverage language processing of LLMs with the symbolic NLU capabilities of producing structured relational representations to hopefully get the best of both approaches. We use LLMs for rephrasing and text simplification, to provide broad coverage, and as a source of information to fill in knowledge gaps more automatically. We use symbolic NLU to produce representations that can be used for reasoning and for incremental learning. We evaluate this approach on the task of extracting and interpreting quantities and causal laws from commonsense science texts, along with symbolic- and LLM-only pipelines. Our results suggest that our hybrid method works significantly better than the symbolic-only pipeline.</li>
</ul>

<h3>Title: No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zachary Horvitz, Raghav Singhal, Hao Zou, Carles Domingo-Enrich, Zhou Yu, Rajesh Ranganath, Kathleen McKeown</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.19990">https://arxiv.org/abs/2510.19990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.19990">https://arxiv.org/pdf/2510.19990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.19990]] No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models(https://arxiv.org/abs/2510.19990)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Masked diffusion language models (MDLMs) are trained to in-fill positions in randomly masked sequences, in contrast to next-token prediction models. Discussions around MDLMs focus on two benefits: (1) any-order decoding and 2) multi-token decoding. However, we observe that for math and coding tasks, any-order algorithms often underperform or behave similarly to left-to-right sampling, and standard multi-token decoding significantly degrades performance. At inference time, MDLMs compute the conditional distribution of all masked positions. A natural question is: How can we justify this additional compute when left-to-right one-token-at-a-time decoding is on par with any-order decoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs to infill a reasoning template, we can structure outputs and distinguish between reasoning and answer tokens. In turn, this enables measuring answer uncertainty during reasoning, and early exits when the model converges on an answer. Next, given an answer, reasoning-as-infilling enables sampling from the MDLM posterior over reasoning traces conditioned on the answer, providing a new source of high-quality data for post-training. On GSM8k, we observe that fine-tuning LLaDA-8B Base on its posterior reasoning traces provides a performance boost on par with fine-tuning on human-written reasoning traces. Additionally, given an answer, reasoning-as-infilling provides a method for scoring the correctness of the reasoning process at intermediate steps. Second, we propose multi-token entropy decoding (MED), a simple adaptive sampler that minimizes the error incurred by decoding positions in parallel based on the conditional entropies of those positions. MED preserves performance across benchmarks and leads to 2.7x fewer steps. Our work demonstrates that the training and compute used by MDLMs unlock many new inference and post-training methods.</li>
</ul>

<h3>Title: Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yunpeng Xiao, Carl Yang, Mark Mai, Xiao Hu, Kai Shu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20001">https://arxiv.org/abs/2510.20001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20001">https://arxiv.org/pdf/2510.20001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20001]] Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs(https://arxiv.org/abs/2510.20001)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show promise for clinical use. They are often evaluated using datasets such as MedQA. However, Many medical datasets, such as MedQA, rely on simplified Question-Answering (Q\A) that underrepresents real-world clinical decision-making. Based on this, we propose a unifying paradigm that characterizes clinical decision-making tasks along two dimensions: Clinical Backgrounds and Clinical Questions. As the background and questions approach the real clinical environment, the difficulty increases. We summarize the settings of existing datasets and benchmarks along two dimensions. Then we review methods to address clinical decision-making, including training-time and test-time techniques, and summarize when they help. Next, we extend evaluation beyond accuracy to include efficiency, explainability. Finally, we highlight open challenges. Our paradigm clarifies assumptions, standardizes comparisons, and guides the development of clinically meaningful LLMs.</li>
</ul>

<h3>Title: Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Alexandra Apostolopoulou, Konstantinos Kanaris, Athanasios Koursaris, Dimitris Tsakalidis, George Domalis, Ioannis E. Livieris</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20002">https://arxiv.org/abs/2510.20002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20002">https://arxiv.org/pdf/2510.20002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20002]] Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training(https://arxiv.org/abs/2510.20002)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The advancement of natural language processing for morphologically rich, moderately-resourced languages like Modern Greek is often hindered by a fragmented research landscape, a lack of architectural diversity and reliance on limited context-length models. This is particularly true in specialized, high-value domains such as law, where existing models are frequently confined to early transformer architectures with a restrictive 512-token window, insufficient for analyzing long legal documents. To address these challenges, this paper presents Greek Embedding Models, a new family of transformer models for Greek language built upon a foundation of extensive, quality-driven data curation. We detail the construction of several large-scale Greek corpora, emphasizing a rigorous, quality-based filtering and preprocessing methodology to create high-value training datasets from both general-domain and specialized legal sources. On this carefully curated foundation, we pre-train and systematically evaluate a diverse suite of modern architectures, which has not previously applied to Greek language, such as ELECTRA, ConvBERT and ModernBERT. Furthermore, we propose the first bilingual Greek-English Embedding Models tailored for the legal domain. The extensive experiments on downstream tasks demonstrate that the new class of models establish the effectiveness of the proposed approach, highlighting that the GEM-RoBERTa and GEM-ConvBERT models significantly outperform existing baselines.</li>
</ul>

<h3>Title: zk-Agreements: A Privacy-Preserving Way to Establish Deterministic Trust in Confidential Agreements</h3>
<ul>
<li><strong>Authors: </strong>To-Wen Liu, Matthew Green</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20007">https://arxiv.org/abs/2510.20007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20007">https://arxiv.org/pdf/2510.20007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20007]] zk-Agreements: A Privacy-Preserving Way to Establish Deterministic Trust in Confidential Agreements(https://arxiv.org/abs/2510.20007)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect</a></li>
<li><strong>Abstract: </strong>Digital transactions currently exceed trillions of dollars annually, yet traditional paper-based agreements remain a bottleneck for automation, enforceability, and dispute resolution. Natural language contracts introduce ambiguity, require manual processing, and lack computational verifiability, all of which hinder efficient digital commerce. Computable legal contracts, expressed in machine-readable formats, offer a potential solution by enabling automated execution and verification. Blockchain-based smart contracts further strengthen enforceability and accelerate dispute resolution; however, current implementations risk exposing sensitive agreement terms on public ledgers, raising serious privacy and competitive intelligence concerns that limit enterprise adoption. We introduce zk-agreements, a protocol designed to transition from paper-based trust to cryptographic trust while preserving confidentiality. Our design combines zero-knowledge proofs to protect private agreement terms, secure two-party computation to enable private compliance evaluation, and smart contracts to guarantee automated enforcement. Together, these components achieve both privacy preservation and computational enforceability, resolving the fundamental tension between transparency and confidentiality in blockchain-based agreements.</li>
</ul>

<h3>Title: A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance</h3>
<ul>
<li><strong>Authors: </strong>Neema Jakisa Owor, Joshua Kofi Asamoah, Tanner Wambui Muturi, Anneliese Jakisa Owor, Blessing Agyei Kyem, Andrews Danyo, Yaw Adu-Gyamfi, Armstrong Aboah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20016">https://arxiv.org/abs/2510.20016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20016">https://arxiv.org/pdf/2510.20016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20016]] A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance(https://arxiv.org/abs/2510.20016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fisheye cameras offer an efficient solution for wide-area traffic surveillance by capturing large fields of view from a single vantage point. However, the strong radial distortion and nonuniform resolution inherent in fisheye imagery introduce substantial challenges for standard object detectors, particularly near image boundaries where object appearance is severely degraded. In this work, we present a detection framework designed to operate robustly under these conditions. Our approach employs a simple yet effective pre and post processing pipeline that enhances detection consistency across the image, especially in regions affected by severe distortion. We train several state-of-the-art detection models on the fisheye traffic imagery and combine their outputs through an ensemble strategy to improve overall detection accuracy. Our method achieves an F1 score of0.6366 on the 2025 AI City Challenge Track 4, placing 8thoverall out of 62 teams. These results demonstrate the effectiveness of our framework in addressing issues inherent to fisheye imagery.</li>
</ul>

<h3>Title: Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications</h3>
<ul>
<li><strong>Authors: </strong>Curtis Lee Shull, Merrick Green</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20019">https://arxiv.org/abs/2510.20019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20019">https://arxiv.org/pdf/2510.20019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20019]] Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications(https://arxiv.org/abs/2510.20019)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense</a></li>
<li><strong>Abstract: </strong>Radio Frequency Identification (RFID) tracking may be a viable solution for defense assets that must be stored in accordance with security guidelines. However, poor sensor specificity (vulnerabilities include long range detection, spoofing, and counterfeiting) can lead to erroneous detection and operational security events. We present a supervised learning simulation with realistic Received Signal Strength Indicator (RSSI) data and Decision Tree classification in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some of the challenges encountered in defense storage. In this work, we focused on classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw dataset had approximately 980,000 reads. Class frequencies were imbalanced, and class weights were calculated to account for class imbalance in this multi-class setting. The model, trained on stratified subsamples to 5,000 balanced observations, yielded an overall accuracy of 34.2% and F1-scores greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare classes (most notably LabZoneC) were often misclassified, even with the use of class weights. An adjacency-aware confusion matrix was calculated to allow better interpretation of physically adjacent zones. These results suggest that RSSI-based decision trees can be applied in realistic simulations to enable zone-level anomaly detection or misplacement monitoring for defense supply logistics. Reliable classification performance in low-coverage and low-signal zones could be improved with better antenna placement or additional sensors and sensor fusion with other modalities.</li>
</ul>

<h3>Title: SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph</h3>
<ul>
<li><strong>Authors: </strong>Jiazheng Li, Yawei Wang, David Yan, Yijun Tian, Zhichao Xu, Huan Song, Panpan Xu, Lin Lee Cheong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20022">https://arxiv.org/abs/2510.20022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20022">https://arxiv.org/pdf/2510.20022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20022]] SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph(https://arxiv.org/abs/2510.20022)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities, enabling language agents to excel at single-turn tasks. However, their application to complex, multi-step, and long-horizon tasks remains challenging. While reinforcement learning (RL) offers a promising avenue for addressing these challenges, mainstream approaches typically rely solely on sparse, outcome-based rewards, a limitation that becomes especially problematic for group-based RL algorithms lacking critic models, such as Group Relative Policy Optimization (GRPO). In such methods, uniformly rewarding or penalizing all actions within a trajectory can lead to training instability and suboptimal policies, because beneficial and detrimental actions are often entangled across multi-step interactions. To address this challenge, we propose SALT, a novel and lightweight framework that provides a finer-grained advantage assignment, derived solely from outcome rewards. We achieve this by constructing a graph from trajectories of the same prompt, which allows us to quantify the quality of each step and assign advantages accordingly. Crucially, SALT is designed as a plug-and-play module that seamlessly integrates with existing group-based RL algorithms, requiring no modifications to the rollout procedure and introducing negligible computational overhead. Extensive experiments on the WebShop, ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that SALT consistently improves performance. We also conduct a thorough analysis to validate the design choices behind SALT and offer actionable insights.</li>
</ul>

<h3>Title: Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses</h3>
<ul>
<li><strong>Authors: </strong>Damian Bowness, Charalambos Poullis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20027">https://arxiv.org/abs/2510.20027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20027">https://arxiv.org/pdf/2510.20027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20027]] Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses(https://arxiv.org/abs/2510.20027)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>When viewing a 3D Gaussian Splatting (3DGS) model from camera positions significantly outside the training data distribution, substantial visual noise commonly occurs. These artifacts result from the lack of training data in these extrapolated regions, leading to uncertain density, color, and geometry predictions from the model. To address this issue, we propose a novel real-time render-aware filtering method. Our approach leverages sensitivity scores derived from intermediate gradients, explicitly targeting instabilities caused by anisotropic orientations rather than isotropic variance. This filtering method directly addresses the core issue of generative uncertainty, allowing 3D reconstruction systems to maintain high visual fidelity even when users freely navigate outside the original training viewpoints. Experimental evaluation demonstrates that our method substantially improves visual quality, realism, and consistency compared to existing Neural Radiance Field (NeRF)-based approaches such as BayesRays. Critically, our filter seamlessly integrates into existing 3DGS rendering pipelines in real-time, unlike methods that require extensive post-hoc retraining or fine-tuning. Code and results at this https URL</li>
</ul>

<h3>Title: BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography</h3>
<ul>
<li><strong>Authors: </strong>Shengyu Chen, Shihang Feng, Yi Luo, Xiaowei Jia, Youzuo Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20029">https://arxiv.org/abs/2510.20029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20029">https://arxiv.org/pdf/2510.20029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20029]] BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography(https://arxiv.org/abs/2510.20029)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.</li>
</ul>

<h3>Title: Speculative Sampling for Parametric Temporal Point Processes</h3>
<ul>
<li><strong>Authors: </strong>Marin Biloš, Anderson Schneider, Yuriy Nevmyvaka</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20031">https://arxiv.org/abs/2510.20031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20031">https://arxiv.org/pdf/2510.20031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20031]] Speculative Sampling for Parametric Temporal Point Processes(https://arxiv.org/abs/2510.20031)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Temporal point processes are powerful generative models for event sequences that capture complex dependencies in time-series data. They are commonly specified using autoregressive models that learn the distribution of the next event from the previous events. This makes sampling inherently sequential, limiting efficiency. In this paper, we propose a novel algorithm based on rejection sampling that enables exact sampling of multiple future values from existing TPP models, in parallel, and without requiring any architectural changes or retraining. Besides theoretical guarantees, our method demonstrates empirical speedups on real-world datasets, bridging the gap between expressive modeling and efficient parallel generation for large-scale TPP applications.</li>
</ul>

<h3>Title: Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models</h3>
<ul>
<li><strong>Authors: </strong>David Dukić</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20033">https://arxiv.org/abs/2510.20033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20033">https://arxiv.org/pdf/2510.20033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20033]] Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models(https://arxiv.org/abs/2510.20033)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>This doctoral thesis improves the transfer learning for sequence labeling tasks by adapting pre-trained neural language models. The proposed improvements in transfer learning involve introducing a multi-task model that incorporates an additional signal, a method based on architectural modifications in autoregressive large language models, and a sequence labeling framework for autoregressive large language models utilizing supervised in-context fine-tuning combined with response-oriented adaptation strategies. The first improvement is given in the context of domain transfer for the event trigger detection task. The domain transfer of the event trigger detection task can be improved by incorporating an additional signal obtained from a domain-independent text processing system into a multi-task model. The second improvement involves modifying the model's architecture. For that purpose, a method is proposed to enable bidirectional information flow across layers of autoregressive large language models. The third improvement utilizes autoregressive large language models as text generators through a generative supervised in-context fine-tuning framework. The proposed model, method, and framework demonstrate that pre-trained neural language models achieve their best performance on sequence labeling tasks when adapted through targeted transfer learning paradigms.</li>
</ul>

<h3>Title: ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering</h3>
<ul>
<li><strong>Authors: </strong>Marianne Menglin Liu, Daniel Garcia, Fjona Parllaku, Vikas Upadhyay, Syed Fahad Allam Shah, Dan Roth</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20036">https://arxiv.org/abs/2510.20036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20036">https://arxiv.org/pdf/2510.20036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20036]] ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering(https://arxiv.org/abs/2510.20036)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) agents rely on external tools to solve complex tasks, but real-world toolsets often contain redundant tools with overlapping names and descriptions, introducing ambiguity and reducing selection accuracy. LLMs also face strict input context limits, preventing efficient consideration of large toolsets. To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing toolsets to fit within context limits without sacrificing accuracy. Evaluations on three state-of-the-art LLMs and three open-source tool-use benchmarks show gains of 8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's effectiveness in enhancing LLM tool use.</li>
</ul>

<h3>Title: Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models</h3>
<ul>
<li><strong>Authors: </strong>Huichan Seo, Sieun Choi, Minki Hong, Yi Zhou, Junseo Kim, Lukman Ismaila, Naome Etori, Mehul Agarwal, Zhixuan Liu, Jihie Kim, Jean Oh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20042">https://arxiv.org/abs/2510.20042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20042">https://arxiv.org/pdf/2510.20042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20042]] Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models(https://arxiv.org/abs/2510.20042)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative image models produce striking visuals yet often misrepresent culture. Prior work has examined cultural bias mainly in text-to-image (T2I) systems, leaving image-to-image (I2I) editors underexplored. We bridge this gap with a unified evaluation across six countries, an 8-category/36-subcategory schema, and era-aware prompts, auditing both T2I generation and I2I editing under a standardized protocol that yields comparable diagnostics. Using open models with fixed settings, we derive cross-country, cross-era, and cross-category evaluations. Our framework combines standard automatic metrics, a culture-aware retrieval-augmented VQA, and expert human judgments collected from native reviewers. To enable reproducibility, we release the complete image corpus, prompts, and configurations. Our study reveals three findings: (1) under country-agnostic prompts, models default to Global-North, modern-leaning depictions that flatten cross-country distinctions; (2) iterative I2I editing erodes cultural fidelity even when conventional metrics remain flat or improve; and (3) I2I models apply superficial cues (palette shifts, generic props) rather than era-consistent, context-aware changes, often retaining source identity for Global-South targets. These results highlight that culture-sensitive edits remain unreliable in current systems. By releasing standardized data, prompts, and human evaluation protocols, we provide a reproducible, culture-centered benchmark for diagnosing and tracking cultural bias in generative image models.</li>
</ul>

<h3>Title: From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Nafis Chowdhury, Moinul Haque, Anika Ahmed, Nazia Tasnim, Md. Istiak Hossain Shihab, Sajjadur Rahman, Farig Sadeque</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20043">https://arxiv.org/abs/2510.20043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20043">https://arxiv.org/pdf/2510.20043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20043]] From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge(https://arxiv.org/abs/2510.20043)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in NLP research has demonstrated remarkable capabilities of large language models (LLMs) across a wide range of tasks. While recent multilingual benchmarks have advanced cultural evaluation for LLMs, critical gaps remain in capturing the nuances of low-resource cultures. Our work addresses these limitations through a Bengali Language Cultural Knowledge (BLanCK) dataset including folk traditions, culinary arts, and regional dialects. Our investigation of several multilingual language models shows that while these models perform well in non-cultural categories, they struggle significantly with cultural knowledge and performance improves substantially across all models when context is provided, emphasizing context-aware architectures and culturally curated training data.</li>
</ul>

<h3>Title: Ultra-Fast Wireless Power Hacking</h3>
<ul>
<li><strong>Authors: </strong>Hui Wang, Hans D. Schotten, Stefan M. Goetz</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20056">https://arxiv.org/abs/2510.20056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20056">https://arxiv.org/pdf/2510.20056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20056]] Ultra-Fast Wireless Power Hacking(https://arxiv.org/abs/2510.20056)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, steal</a></li>
<li><strong>Abstract: </strong>The rapid growth of electric vehicles (EVs) has driven the development of roadway wireless charging technology, effectively extending EV driving range. However, wireless charging introduces significant cybersecurity challenges. Any receiver within the magnetic field can potentially extract energy, and previous research demonstrated that a hacker could detect the operating frequency and steal substantial power. However, our approach required time to track new frequencies or precise adjustments of inductance and capacitance, which would be less effective against potential rapid transmitter frequency changes or capacitance drift. As a solution, we enhanced the interceptor and enabled it to intrude as well as steal energy within just three cycles of the high-frequency signal. Moreover, it can work without any circuit parameters or look-up tables. The key innovation is synchronizing the receiver current with the phase of the magnetic sensor voltage. Through MATLAB / Simulink simulations, finite-element analysis, and experimental validation, we demonstrated that our improved method can steal over 76% of the power received by a fully resonant receiver under identical conditions. This attack demonstrates that simple frequency-changing power encryption offers limited protection against such threats.</li>
</ul>

<h3>Title: Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hongyi Liu, Jiaji Huang, Zhen Jia, Youngsuk Park, Yu-Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20064">https://arxiv.org/abs/2510.20064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20064">https://arxiv.org/pdf/2510.20064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20064]] Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs(https://arxiv.org/abs/2510.20064)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding is widely used in accelerating large language model (LLM) inference. In this work, we focus on the online draft model selection problem in speculative decoding. We design an algorithm that provably competes with the best draft model in hindsight for each query in terms of either the token acceptance probability or expected acceptance length. In particular, we show that we can accurately evaluate all draft models, instead of only the chosen model without incurring additional queries to the target model, which allows us to improve exponentially over the existing bandit-based approach as the number of draft models increases. Our approach is generically applicable with any speculative decoding methods (single draft, multi-drafts and draft-trees). Moreover, we design system-efficient versions of online learners and demonstrate that the overhead in computation and latency can be substantially reduced. We conduct extensive experiments on open-source LLMs and diverse datasets, demonstrating that our methods substantially outperform the state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains where specialized domain-expert drafters are available, especially when long reasoning chains are required.</li>
</ul>

<h3>Title: A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers</h3>
<ul>
<li><strong>Authors: </strong>Yimeng Qiu, Feihuang Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, econ.EM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20066">https://arxiv.org/abs/2510.20066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20066">https://arxiv.org/pdf/2510.20066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20066]] A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers(https://arxiv.org/abs/2510.20066)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study whether liquidity and volatility proxies of a core set of cryptoassets generate spillovers that forecast market-wide risk. Our empirical framework integrates three statistical layers: (A) interactions between core liquidity and returns, (B) principal-component relations linking liquidity and returns, and (C) volatility-factor projections that capture cross-sectional volatility crowding. The analysis is complemented by vector autoregression impulse responses and forecast error variance decompositions (see Granger 1969; Sims 1980), heterogeneous autoregressive models with exogenous regressors (HAR-X, Corsi 2009), and a leakage-safe machine learning protocol using temporal splits, early stopping, validation-only thresholding, and SHAP-based interpretation. Using daily data from 2021 to 2025 (1462 observations across 74 assets), we document statistically significant Granger-causal relationships across layers and moderate out-of-sample predictive accuracy. We report the most informative figures, including the pipeline overview, Layer A heatmap, Layer C robustness analysis, vector autoregression variance decompositions, and the test-set precision-recall curve. Full data and figure outputs are provided in the artifact repository.</li>
</ul>

<h3>Title: Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Ram Dyuthi Sristi, Sowmya Manojna Narasimha, Jingya Huang, Alice Despatin, Simon Musall, Vikash Gilja, Gal Mishne</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20068">https://arxiv.org/abs/2510.20068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20068">https://arxiv.org/pdf/2510.20068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20068]] Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics(https://arxiv.org/abs/2510.20068)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.</li>
</ul>

<h3>Title: Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering</h3>
<ul>
<li><strong>Authors: </strong>Hui Chen, Xinjie Wang, Xianchao Xiu, Wanquan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20077">https://arxiv.org/abs/2510.20077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20077">https://arxiv.org/pdf/2510.20077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20077]] Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering(https://arxiv.org/abs/2510.20077)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tensor low-rank representation (TLRR) has demonstrated significant success in image clustering. However, most existing methods rely on fixed transformations and suffer from poor robustness to noise. In this paper, we propose a novel transformed bilateral tensor low-rank representation model called TBTLRR, which introduces a data-adaptive tensor nuclear norm by learning arbitrary unitary transforms, allowing for more effective capture of global correlations. In addition, by leveraging the bilateral structure of latent tensor data, TBTLRR is able to exploit local correlations between image samples and features. Furthermore, TBTLRR integrates the $\ell_{1/2}$-norm and Frobenius norm regularization terms for better dealing with complex noise in real-world scenarios. To solve the proposed nonconvex model, we develop an efficient optimization algorithm inspired by the alternating direction method of multipliers (ADMM) and provide theoretical convergence. Extensive experiments validate its superiority over the state-of-the-art methods in clustering. The code will be available at this https URL.</li>
</ul>

<h3>Title: Who Coordinates U.S. Cyber Defense? A Co-Authorship Network Analysis of Joint Cybersecurity Advisories (2024--2025)</h3>
<ul>
<li><strong>Authors: </strong>M. Abdullah Canbaz, Hakan Otal, Tugce Unlu, Nour Alhussein, Brian Nussbaum</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20080">https://arxiv.org/abs/2510.20080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20080">https://arxiv.org/pdf/2510.20080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20080]] Who Coordinates U.S. Cyber Defense? A Co-Authorship Network Analysis of Joint Cybersecurity Advisories (2024--2025)(https://arxiv.org/abs/2510.20080)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense</a></li>
<li><strong>Abstract: </strong>Cyber threats increasingly demand joint responses, yet the organizational dynamics behind multi-agency cybersecurity collaboration remain poorly understood. Understanding who leads, who bridges, and how agencies coordinate is critical for strengthening both U.S. homeland security and allied defense efforts. In this study, we construct a co-authorship network from nine Joint Cybersecurity Advisories (CSAs) issued between November 2024 and August 2025. We map 41 agencies and 442 co-authoring ties to analyze the structure of collaboration. We find a tightly knit U.S. triad -- CISA, FBI, and NSA -- densely connected with Five Eyes and select European allies. Degree centrality identifies CISA and FBI as coordination hubs, while betweenness highlights NSA, the UK's NCSC, and Australia's ASD-ACSC as key bridges linking otherwise fragmented clusters. By releasing the first replicable dataset and network analysis of CSAs, we provide new empirical evidence on how collaborative cybersecurity signals are organized and where strategic influence is concentrated.</li>
</ul>

<h3>Title: Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa</h3>
<ul>
<li><strong>Authors: </strong>Chang Yang, Ziyi Wang, Wangfeng Tan, Zhiting Tan, Changrui Ji, Zhiming Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20085">https://arxiv.org/abs/2510.20085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20085">https://arxiv.org/pdf/2510.20085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20085]] Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa(https://arxiv.org/abs/2510.20085)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Social media platforms have become important sources for identifying suicide risk, but automated detection systems face multiple challenges including severe class imbalance, temporal complexity in posting patterns, and the dual nature of risk levels as both ordinal and categorical. This paper proposes a hierarchical dual-head neural network based on MentalRoBERTa for suicide risk classification into four levels: indicator, ideation, behavior, and attempt. The model employs two complementary prediction heads operating on a shared sequence representation: a CORAL (Consistent Rank Logits) head that preserves ordinal relationships between risk levels, and a standard classification head that enables flexible categorical distinctions. A 3-layer Transformer encoder with 8-head multi-head attention models temporal dependencies across post sequences, while explicit time interval embeddings capture posting behavior dynamics. The model is trained with a combined loss function (0.5 CORAL + 0.3 Cross-Entropy + 0.2 Focal Loss) that simultaneously addresses ordinal structure preservation, overconfidence reduction, and class imbalance. To improve computational efficiency, we freeze the first 6 layers (50%) of MentalRoBERTa and employ mixed-precision training. The model is evaluated using 5-fold stratified cross-validation with macro F1 score as the primary metric.</li>
</ul>

<h3>Title: Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Arboit, Dennis N. Schneider, Britty Baby, Vinkle Srivastav, Pietro Mascagni, Nicolas Padoy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20087">https://arxiv.org/abs/2510.20087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20087">https://arxiv.org/pdf/2510.20087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20087]] Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos(https://arxiv.org/abs/2510.20087)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Video-based assessment and surgical data science can advance surgical training, research, and quality improvement. However, widespread use remains limited by heterogeneous recording formats and privacy concerns associated with video sharing. We present Endoshare, a source-available, cross-platform application for merging, standardizing, and de-identifying endoscopic videos in minimally invasive surgery. Development followed the software development life cycle with iterative, user-centered feedback. During the analysis phase, an internal survey of clinicians and computer scientists based on ten usability heuristics identified key requirements that guided a privacy-by-design architecture. In the testing phase, an external clinician survey combined the same heuristics with Technology Acceptance Model constructs to assess usability and adoption, complemented by benchmarking across different hardware configurations. Four clinicians and four computer scientists initially tested the prototype, reporting high usability (4.68 +/- 0.40/5 and 4.03 +/- 0.51/5), with the lowest score (4.00 +/- 0.93/5) relating to label clarity. After refinement, the testing phase surveyed ten surgeons who reported high perceived usefulness (5.07 +/- 1.75/7), ease of use (5.15 +/- 1.71/7), heuristic usability (4.38 +/- 0.48/5), and strong recommendation (9.20 +/- 0.79/10). Processing time varied with processing mode, video duration (both p <= 0.001), and machine computational power (p = 0.041). Endoshare provides a transparent, user-friendly pipeline for standardized, privacy-preserving surgical video management. Compliance certification and broader interoperability validation are needed to establish it as a deployable alternative to proprietary systems. The software is available at this https URL</li>
</ul>

<h3>Title: CreativityPrism: A Holistic Benchmark for Large Language Model Creativity</h3>
<ul>
<li><strong>Authors: </strong>Zhaoyi Joey Hou, Bowei Alvin Zhang, Yining Lu, Bhiman Kumar Baghel, Anneliese Brei, Ximing Lu, Meng Jiang, Faeze Brahman, Snigdha Chaturvedi, Haw-Shiuan Chang, Daniel Khashabi, Xiang Lorraine Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20091">https://arxiv.org/abs/2510.20091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20091">https://arxiv.org/pdf/2510.20091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20091]] CreativityPrism: A Holistic Benchmark for Large Language Model Creativity(https://arxiv.org/abs/2510.20091)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Creativity is often seen as a hallmark of human intelligence. While large language models (LLMs) are increasingly perceived as producing creative text, there is still no holistic framework to evaluate their creativity across diverse scenarios. Existing evaluation methods remain fragmented, with dramatic variation across domains and tasks, largely due to differing definitions and measurements of creativity. Inspired by the hypothesis that creativity is not one fixed idea, we propose CreativityPrism, an evaluation analysis framework that decomposes creativity into three dimensions: quality, novelty, and diversity. CreativityPrism incorporates nine tasks, three domains, i.e., divergent thinking, creative writing, and logical reasoning, and twenty evaluation metrics, which measure each dimension in task-specific, unique ways. We evaluate 17 state-of-the-art (SoTA) proprietary and open-sourced LLMs on CreativityPrism and analyze the performance correlations among different metrics and task domains. Our results reveal a notable gap between proprietary and open-source models. Overall, model performance tends to be highly correlated across tasks within the same domain and less so across different domains. Among evaluation dimensions, diversity and quality metrics show strong correlations - models that perform well on one often excel on the other - whereas novelty exhibits much weaker correlation with either. These findings support our hypothesis that strong performance in one creativity task or dimension does not necessarily generalize to others, underscoring the need for a holistic evaluation of LLM creativity.</li>
</ul>

<h3>Title: Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Hao Yu, Haoyu Chen, Yan Jiang, Wei Peng, Zhaodong Sun, Samuel Kaski, Guoying Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20092">https://arxiv.org/abs/2510.20092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20092">https://arxiv.org/pdf/2510.20092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20092]] Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency(https://arxiv.org/abs/2510.20092)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Self-attention (SA) has become the cornerstone of modern vision backbones for its powerful expressivity over traditional Convolutions (Conv). However, its quadratic complexity remains a critical bottleneck for practical applications. Given that Conv offers linear complexity and strong visual priors, continuing efforts have been made to promote the renaissance of Conv. However, a persistent performance chasm remains, highlighting that these modernizations have not yet captured the intrinsic expressivity that defines SA. In this paper, we re-examine the design of the CNNs, directed by a key question: what principles give SA its edge over Conv? As a result, we reveal two fundamental insights that challenge the long-standing design intuitions in prior research (e.g., Receptive field). The two findings are: (1) \textit{Adaptive routing}: SA dynamically regulates positional information flow according to semantic content, whereas Conv employs static kernels uniformly across all positions. (2) \textit{Lateral inhibition}: SA induces score competition among token weighting, effectively suppressing redundancy and sharpening representations, whereas Conv filters lack such inhibitory dynamics and exhibit considerable redundancy. Based on this, we propose \textit{Attentive Convolution} (ATConv), a principled reformulation of the convolutional operator that intrinsically injects these principles. Interestingly, with only $3\times3$ kernels, ATConv consistently outperforms various SA mechanisms in fundamental vision tasks. Building on ATConv, we introduce AttNet, a CNN family that can attain \textbf{84.4\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In diffusion-based image generation, replacing all SA with the proposed $3\times 3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster sampling. Code is available at: this http URL.</li>
</ul>

<h3>Title: StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback</h3>
<ul>
<li><strong>Authors: </strong>Jiho Park, Sieun Choi, Jaeyoon Seo, Jihie Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20093">https://arxiv.org/abs/2510.20093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20093">https://arxiv.org/pdf/2510.20093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20093]] StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback(https://arxiv.org/abs/2510.20093)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Although recent advancements in diffusion models have significantly enriched the quality of generated images, challenges remain in synthesizing pixel-based human-drawn sketches, a representative example of abstract expression. To combat these challenges, we propose StableSketcher, a novel framework that empowers diffusion models to generate hand-drawn sketches with high prompt fidelity. Within this framework, we fine-tune the variational autoencoder to optimize latent decoding, enabling it to better capture the characteristics of sketches. In parallel, we integrate a new reward function for reinforcement learning based on visual question answering, which improves text-image alignment and semantic consistency. Extensive experiments demonstrate that StableSketcher generates sketches with improved stylistic fidelity, achieving better alignment with prompts compared to the Stable Diffusion baseline. Additionally, we introduce SketchDUO, to the best of our knowledge, the first dataset comprising instance-level sketches paired with captions and question-answer pairs, thereby addressing the limitations of existing datasets that rely on image-label pairs. Our code and dataset will be made publicly available upon acceptance.</li>
</ul>

<h3>Title: BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Ziheng Zhang, Xinyue Ma, Arpita Chowdhury, Elizabeth G. Campolongo, Matthew J. Thompson, Net Zhang, Samuel Stevens, Hilmar Lapp, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao, Jianyang Gu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20095">https://arxiv.org/abs/2510.20095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20095">https://arxiv.org/pdf/2510.20095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20095]] BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models(https://arxiv.org/abs/2510.20095)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work investigates descriptive captions as an additional source of supervision for biological multimodal foundation models. Images and captions can be viewed as complementary samples from the latent morphospace of a species, each capturing certain biological traits. Incorporating captions during training encourages alignment with this shared latent structure, emphasizing potentially diagnostic characters while suppressing spurious correlations. The main challenge, however, lies in obtaining faithful, instance-specific captions at scale. This requirement has limited the utilization of natural language supervision in organismal biology compared with many other scientific domains. We complement this gap by generating synthetic captions with multimodal large language models (MLLMs), guided by Wikipedia-derived visual information and taxon-tailored format examples. These domain-specific contexts help reduce hallucination and yield accurate, instance-based descriptive captions. Using these captions, we train BIOCAP (i.e., BIOCLIP with Captions), a biological foundation model that captures rich semantics and achieves strong performance in species classification and text-image retrieval. These results demonstrate the value of descriptive captions beyond labels in bridging biological images with multimodal foundation models.</li>
</ul>

<h3>Title: Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yajie Li, Albert Galimov, Mitra Datta Ganapaneni, Pujitha Thejaswi, De Meng, Priyanshu Kumar, Saloni Potdar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20098">https://arxiv.org/abs/2510.20098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20098">https://arxiv.org/pdf/2510.20098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20098]] Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning(https://arxiv.org/abs/2510.20098)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Entity Linking (EL) has traditionally relied on large annotated datasets and extensive model fine-tuning. While recent few-shot methods leverage large language models (LLMs) through prompting to reduce training requirements, they often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER (Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline that achieves high performance without deep fine-tuning by strategically combining candidate generation, context-based scoring, adaptive routing, and selective reasoning. ARTER computes a small set of complementary signals(both embedding and LLM-based) over the retrieved candidates to categorize contextual mentions into easy and hard cases. The cases are then handled by a low-computational entity linker (e.g. ReFinED) and more expensive targeted LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets, and performs comparably to pipelines using LLM-based reasoning for all mentions, while being as twice as efficient in terms of the number of LLM tokens.</li>
</ul>

<h3>Title: Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects</h3>
<ul>
<li><strong>Authors: </strong>Prithvi Raj Singh, Raju Gottumukkala, Anthony S. Maida, Alan B. Barhorst, Vijaya Gopu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20126">https://arxiv.org/abs/2510.20126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20126">https://arxiv.org/pdf/2510.20126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20126]] Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects(https://arxiv.org/abs/2510.20126)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While computer vision has advanced considerably for general object detection and tracking, the specific problem of fast-moving tiny objects remains underexplored. This paper addresses the significant challenge of detecting and tracking rapidly moving small objects using an RGB-D camera. Our novel system combines deep learning-based detection with physics-based tracking to overcome the limitations of existing approaches. Our contributions include: (1) a comprehensive system design for object detection and tracking of fast-moving small objects in 3D space, (2) an innovative physics-based tracking algorithm that integrates kinematics motion equations to handle outliers and missed detections, and (3) an outlier detection and correction module that significantly improves tracking performance in challenging scenarios such as occlusions and rapid direction changes. We evaluated our proposed system on a custom racquetball dataset. Our evaluation shows our system surpassing kalman filter based trackers with up to 70\% less Average Displacement Error. Our system has significant applications for improving robot perception on autonomous platforms and demonstrates the effectiveness of combining physics-based models with deep learning approaches for real-time 3D detection and tracking of challenging small objects.</li>
</ul>

<h3>Title: SAID: Empowering Large Language Models with Self-Activating Internal Defense</h3>
<ul>
<li><strong>Authors: </strong>Yulong Chen, Yadong Liu, Jiawen Zhang, Mu Li, Chao Huang, Jie Wen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20129">https://arxiv.org/abs/2510.20129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20129">https://arxiv.org/pdf/2510.20129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20129]] SAID: Empowering Large Language Models with Self-Activating Internal Defense(https://arxiv.org/abs/2510.20129)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), despite advances in safety alignment, remain vulnerable to jailbreak attacks designed to circumvent protective mechanisms. Prevailing defense strategies rely on external interventions, such as input filtering or output modification, which often lack generalizability and compromise model utility while incurring significant computational overhead. In this work, we introduce a new, training-free defense paradigm, Self-Activating Internal Defense (SAID), which reframes the defense task from external correction to internal capability activation. SAID uniquely leverages the LLM's own reasoning abilities to proactively identify and neutralize malicious intent through a three-stage pipeline: model-native intent distillation to extract core semantics, optimal safety prefix probing to activate latent safety awareness, and a conservative aggregation strategy to ensure robust decision-making. Extensive experiments on five open-source LLMs against six advanced jailbreak attacks demonstrate that SAID substantially outperforms state-of-the-art defenses in reducing harmful outputs. Crucially, it achieves this while preserving model performance on benign tasks and incurring minimal computational overhead. Our work establishes that activating the intrinsic safety mechanisms of LLMs is a more robust and scalable path toward building safer and more reliable aligned AI systems.</li>
</ul>

<h3>Title: Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling</h3>
<ul>
<li><strong>Authors: </strong>Tingting Dan, Xinwei Huang, Jiaqi Ding, Yinggang Zheng, Guorong Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20148">https://arxiv.org/abs/2510.20148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20148">https://arxiv.org/pdf/2510.20148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20148]] Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling(https://arxiv.org/abs/2510.20148)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.</li>
</ul>

<h3>Title: BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Li, Zhengyuan Shen, Sullam Jeoung, Yueyan Chen, Jiayu Li, Qi Zhu, Shuai Wang, Vassilis Ioannidis, Huzefa Rangwala</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20151">https://arxiv.org/abs/2510.20151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20151">https://arxiv.org/pdf/2510.20151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20151]] BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation(https://arxiv.org/abs/2510.20151)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>As structured texts become increasingly complex across diverse domains -- from technical reports to generative AI prompts -- the need for text segmentation into semantically meaningful components becomes critical. Such texts often contain elements beyond plain language, including tables, code snippets, and placeholders, which conventional sentence- or paragraph-level segmentation methods cannot handle effectively. To address this challenge, we propose BoundRL, a novel and efficient approach that jointly performs token-level text segmentation and label prediction for long structured texts. Instead of generating complete contents for each segment, it generates only a sequence of starting tokens and reconstructs the complete contents by locating these tokens within the original texts, thereby reducing inference costs by orders of magnitude and minimizing hallucination. To adapt the model for the output format, BoundRL~performs reinforcement learning with verifiable rewards (RLVR) with a specifically designed reward that jointly optimizes document reconstruction fidelity and semantic alignment. To mitigate entropy collapse, it further constructs intermediate candidates by systematically perturbing a fraction of generated sequences of segments to create stepping stones toward higher-quality solutions. To demonstrate BoundRL's effectiveness on particularly challenging structured texts, we focus evaluation on complex prompts used for LLM applications. Experiments show that BoundRL enables small language models (1.7B parameters) to outperform few-shot prompting of much larger models. Moreover, RLVR with our designed reward yields significant improvements over supervised fine-tuning, and incorporating intermediate candidates further improves both performance and generalization.</li>
</ul>

<h3>Title: Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?</h3>
<ul>
<li><strong>Authors: </strong>Anthony Dubreuil, Antoine Gourru, Christine Largeron, Amine Trabelsi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20154">https://arxiv.org/abs/2510.20154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20154">https://arxiv.org/pdf/2510.20154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20154]] Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?(https://arxiv.org/abs/2510.20154)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models inherit stereotypes from their pretraining data, leading to biased behavior toward certain social groups in many Natural Language Processing tasks, such as hateful speech detection or sentiment analysis. Surprisingly, the evaluation of this kind of bias in stance detection methods has been largely overlooked by the community. Stance Detection involves labeling a statement as being against, in favor, or neutral towards a specific target and is among the most sensitive NLP tasks, as it often relates to political leanings. In this paper, we focus on the bias of Large Language Models when performing stance detection in a zero-shot setting. We automatically annotate posts in pre-existing stance detection datasets with two attributes: dialect or vernacular of a specific group and text complexity/readability, to investigate whether these attributes influence the model's stance detection decisions. Our results show that LLMs exhibit significant stereotypes in stance detection tasks, such as incorrectly associating pro-marijuana views with low text complexity and African American dialect with opposition to Donald Trump.</li>
</ul>

<h3>Title: PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding</h3>
<ul>
<li><strong>Authors: </strong>Penghao Wang, Yiyang He, Xin Lv, Yukai Zhou, Lan Xu, Jingyi Yu, Jiayuan Gu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20155">https://arxiv.org/abs/2510.20155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20155">https://arxiv.org/pdf/2510.20155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20155]] PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding(https://arxiv.org/abs/2510.20155)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Understanding objects at the level of their constituent parts is fundamental to advancing computer vision, graphics, and robotics. While datasets like PartNet have driven progress in 3D part understanding, their reliance on untextured geometries and expert-dependent annotation limits scalability and usability. We introduce PartNeXt, a next-generation dataset addressing these gaps with over 23,000 high-quality, textured 3D models annotated with fine-grained, hierarchical part labels across 50 categories. We benchmark PartNeXt on two tasks: (1) class-agnostic part segmentation, where state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with fine-grained and leaf-level parts, and (2) 3D part-centric question answering, a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary part grounding. Additionally, training Point-SAM on PartNeXt yields substantial gains over PartNet, underscoring the dataset's superior quality and diversity. By combining scalable annotation, texture-aware labels, and multi-task evaluation, PartNeXt opens new avenues for research in structured 3D understanding.</li>
</ul>

<h3>Title: ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push</h3>
<ul>
<li><strong>Authors: </strong>Xiaoming Wu, Teng Liu, Xin Wang, Ming Yang, Jiguo Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20157">https://arxiv.org/abs/2510.20157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20157">https://arxiv.org/pdf/2510.20157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20157]] ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push(https://arxiv.org/abs/2510.20157)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Differential privacy is widely employed in decentralized learning to safeguard sensitive data by introducing noise into model updates. However, existing approaches that use fixed-variance noise often degrade model performance and reduce training efficiency. To address these limitations, we propose a novel approach called decentralized learning with adaptive differential privacy via variance-reduced stochastic gradient push (ADP-VRSGP). This method dynamically adjusts both the noise variance and the learning rate using a stepwise-decaying schedule, which accelerates training and enhances final model performance while providing node-level personalized privacy guarantees. To counteract the slowed convergence caused by large-variance noise in early iterations, we introduce a progressive gradient fusion strategy that leverages historical gradients. Furthermore, ADP-VRSGP incorporates decentralized push-sum and aggregation techniques, making it particularly suitable for time-varying communication topologies. Through rigorous theoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence with an appropriate learning rate, significantly improving training stability and speed. Experimental results validate that our method outperforms existing baselines across multiple scenarios, highlighting its efficacy in addressing the challenges of privacy-preserving decentralized learning.</li>
</ul>

<h3>Title: IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Insu Jeon, Wonkwang Lee, Myeongjang Pyeon, Gunhee Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20165">https://arxiv.org/abs/2510.20165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20165">https://arxiv.org/pdf/2510.20165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20165]] IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks(https://arxiv.org/abs/2510.20165)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose a new GAN-based unsupervised model for disentangled representation learning. The new model is discovered in an attempt to utilize the Information Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The architecture of IB-GAN is partially similar to that of InfoGAN but has a critical difference; an intermediate layer of the generator is leveraged to constrain the mutual information between the input and the generated output. The intermediate stochastic layer can serve as a learnable latent distribution that is trained with the generator jointly in an end-to-end fashion. As a result, the generator of IB-GAN can harness the latent space in a disentangled and interpretable manner. With the experiments on dSprites and Color-dSprites dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores to those of state-of-the-art \b{eta}-VAEs and outperforms InfoGAN. Moreover, the visual quality and the diversity of samples generated by IB-GAN are often better than those by \b{eta}-VAEs and Info-GAN in terms of FID score on CelebA and 3D Chairs dataset.</li>
</ul>

<h3>Title: DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking</h3>
<ul>
<li><strong>Authors: </strong>Tian Lan, Bin Zhu, Qianghuai Jia, Junyang Ren, Haijun Li, Longyue Wang, Zhao Xu, Weihua Luo, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20168">https://arxiv.org/abs/2510.20168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20168">https://arxiv.org/pdf/2510.20168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20168]] DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking(https://arxiv.org/abs/2510.20168)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current search agents fundamentally lack the ability to simultaneously perform \textit{deep} reasoning over multi-hop retrieval and \textit{wide}-scale information collection-a critical deficiency for real-world applications like comprehensive market analysis and business development. To bridge this gap, we introduce DeepWideSearch, the first benchmark explicitly designed to evaluate agents to integrate depth and width in information seeking. In DeepWideSearch, agents must process a large volume of data, each requiring deep reasoning over multi-hop retrieval paths. Specifically, we propose two methods to converse established datasets, resulting in a curated collection of 220 questions spanning 15 diverse domains. Extensive experiments demonstrate that even state-of-the-art agents achieve only 2.39% average success rate on DeepWideSearch, highlighting the substantial challenge of integrating depth and width search in information-seeking tasks. Furthermore, our error analysis reveals four failure modes: lack of reflection, overreliance on internal knowledge, insufficient retrieval, and context overflow-exposing key limitations in current agent architectures. We publicly release DeepWideSearch to catalyze future research on more capable and robust information-seeking agents.</li>
</ul>

<h3>Title: Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Zhou, Mingrui Zhang, Ke Li, Mingyi Wang, Qiao Liu, Qifei wang, Jiayi Liu, Fei Liu, Serena Li, Weiwi Li, Mingze Gao, Abhishek Kumar, Xiangjun Fan, Zhuokai Zhao, Lizhu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20176">https://arxiv.org/abs/2510.20176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20176">https://arxiv.org/pdf/2510.20176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20176]] Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding(https://arxiv.org/abs/2510.20176)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Understanding and reasoning over tables is a critical capability for many real-world applications. Large language models (LLMs) have shown promise on this task, but current approaches remain limited. Fine-tuning based methods strengthen language reasoning; yet they are prone to arithmetic errors and hallucination. In contrast, tool-based methods enable precise table manipulation but rely on rigid schemas and lack semantic understanding. These complementary drawbacks highlight the need for approaches that integrate robust reasoning with reliable table processing. In this work, we propose Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into three specialized roles: planning, coding, and answering. This design enables each agent to focus on a specific aspect of the task while leveraging code execution for precise table manipulation. Building on this workflow, we introduce a self-improvement training framework that employs Monte Carlo Tree Search (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents with reinforcement learning (RL). Extensive experiments show that Mixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and surpassing OpenAI-o4-mini-high. These results demonstrate the promise of combining structured multi-agent workflows with RL to advance table understanding.</li>
</ul>

<h3>Title: Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values</h3>
<ul>
<li><strong>Authors: </strong>Dian Yu, Yulai Zhao, Kishan Panaganti, Linfeng Song, Haitao Mi, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20187">https://arxiv.org/abs/2510.20187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20187">https://arxiv.org/pdf/2510.20187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20187]] Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values(https://arxiv.org/abs/2510.20187)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We propose Reinforcement Learning with Explicit Human Values (RLEV), a method that aligns Large Language Model (LLM) optimization directly with quantifiable human value signals. While Reinforcement Learning with Verifiable Rewards (RLVR) effectively trains models in objective domains using binary correctness rewards, it overlooks that not all tasks are equally significant. RLEV extends this framework by incorporating human-defined value signals directly into the reward function. Using exam-style data with explicit ground-truth value labels, RLEV consistently outperforms correctness-only baselines across multiple RL algorithms and model scales. Crucially, RLEV policies not only improve value-weighted accuracy but also learn a value-sensitive termination policy: concise for low-value prompts, thorough for high-value ones. We demonstrate this behavior stems from value-weighted gradient amplification on end-of-sequence tokens. Ablation studies confirm the gain is causally linked to value alignment. RLEV remains robust under noisy value signals, such as difficulty-based labels, demonstrating that optimizing for an explicit utility function offers a practical path to aligning LLMs with human priorities.</li>
</ul>

<h3>Title: SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Hu, Yuran Wang, Yue Li, Wenxuan Liu, Zheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20189">https://arxiv.org/abs/2510.20189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20189">https://arxiv.org/pdf/2510.20189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20189]] SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization(https://arxiv.org/abs/2510.20189)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, explainability</a></li>
<li><strong>Abstract: </strong>Temporal Intention Localization (TIL) is crucial for video surveillance, focusing on identifying varying levels of suspicious intentions to improve security monitoring. However, existing discrete classification methods fail to capture the continuous nature of suspicious intentions, limiting early intervention and explainability. In this paper, we propose the Suspicion Progression Analysis Network (SPAN), which shifts from discrete classification to continuous regression, enabling the capture of fluctuating and evolving suspicious intentions. We reveal that suspicion exhibits long-term dependencies and cumulative effects, similar to Temporal Point Process (TPP) theory. Based on these insights, we define a suspicion score formula that models continuous changes while accounting for temporal characteristics. We also introduce Suspicion Coefficient Modulation, which adjusts suspicion coefficients using multimodal information to reflect the varying impacts of suspicious actions. Additionally, the Concept-Anchored Mapping method is proposed to link suspicious actions to predefined intention concepts, offering insights into both the actions and their potential underlying intentions. Extensive experiments on the HAI dataset show that SPAN significantly outperforms existing methods, reducing MSE by 19.8% and improving average mAP by 1.78%. Notably, SPAN achieves a 2.74% mAP gain in low-frequency cases, demonstrating its superior ability to capture subtle behavioral changes. Compared to discrete classification systems, our continuous suspicion modeling approach enables earlier detection and proactive intervention, greatly enhancing system explainability and practical utility in security applications.</li>
</ul>

<h3>Title: Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Maggie Bai, Ava Kim Cohen, Eleanor Koss, Charlie Lichtenbaum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20198">https://arxiv.org/abs/2510.20198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20198">https://arxiv.org/pdf/2510.20198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20198]] Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models(https://arxiv.org/abs/2510.20198)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the spatial reasoning capability of large language models (LLMs) over textual input through a suite of five tasks aimed at probing their spatial understanding and computational abilities. The models were tested on both fundamental spatial reasoning and multi-step problem-solving within structured grid-based environments using tasks such as quadrant identification, geometric transformations, distance evaluation, word searches, and tile sliding. Each task was scaled in complexity through increasing grid dimensions, requiring models to extend beyond simple pattern recognition into abstract spatial reasoning. Our results reveal that while LLMs demonstrate moderate success in all tasks with small complexity and size, performance drops off rapidly as scale increases, with an average loss in accuracy of 42.7%, and reaching as high as 84%. Every test that began with over 50% accuracy showed a loss of at least 48%, illustrating the consistent nature of the deterioration. Furthermore, their struggles with scaling complexity hint at a lack of robust spatial representations in their underlying architectures. This paper underscores the gap between linguistic and spatial reasoning in LLMs, offering insights into their current limitations, and laying the groundwork for future integrative benchmarks at the intersection of language and geometry.</li>
</ul>

<h3>Title: Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents</h3>
<ul>
<li><strong>Authors: </strong>Jane H. Lee, Baturay Saglam, Spyridon Pougkakiotis, Amin Karbasi, Dionysis Kalogerias</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20199">https://arxiv.org/abs/2510.20199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20199">https://arxiv.org/pdf/2510.20199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20199]] Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents(https://arxiv.org/abs/2510.20199)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Constrained optimization provides a common framework for dealing with conflicting objectives in reinforcement learning (RL). In most of these settings, the objectives (and constraints) are expressed though the expected accumulated reward. However, this formulation neglects risky or even possibly catastrophic events at the tails of the reward distribution, and is often insufficient for high-stakes applications in which the risk involved in outliers is critical. In this work, we propose a framework for risk-aware constrained RL, which exhibits per-stage robustness properties jointly in reward values and time using optimized certainty equivalents (OCEs). Our framework ensures an exact equivalent to the original constrained problem within a parameterized strong Lagrangian duality framework under appropriate constraint qualifications, and yields a simple algorithmic recipe which can be wrapped around standard RL solvers, such as PPO. Lastly, we establish the convergence of the proposed algorithm under common assumptions, and verify the risk-aware properties of our approach through several numerical experiments.</li>
</ul>

<h3>Title: RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Bingjie Gao, Qianli Ma, Xiaoxue Wu, Shuai Yang, Guanzhou Lan, Haonan Zhao, Jiaxuan Chen, Qingyang Liu, Yu Qiao, Xinyuan Chen, Yaohui Wang, Li Niu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20206">https://arxiv.org/abs/2510.20206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20206">https://arxiv.org/pdf/2510.20206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20206]] RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling(https://arxiv.org/abs/2510.20206)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Prompt design plays a crucial role in text-to-video (T2V) generation, yet user-provided prompts are often short, unstructured, and misaligned with training data, limiting the generative potential of diffusion-based T2V models. We present \textbf{RAPO++}, a cross-stage prompt optimization framework that unifies training-data--aligned refinement, test-time iterative scaling, and large language model (LLM) fine-tuning to substantially improve T2V generation without modifying the underlying generative backbone. In \textbf{Stage 1}, Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with semantically relevant modifiers retrieved from a relation graph and refactors them to match training distributions, enhancing compositionality and multi-object fidelity. \textbf{Stage 2} introduces Sample-Specific Prompt Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts using multi-source feedback -- including semantic alignment, spatial fidelity, temporal coherence, and task-specific signals such as optical flow -- yielding progressively improved video generation quality. \textbf{Stage 3} leverages optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing task-specific optimization patterns and enabling efficient, high-quality prompt generation even before inference. Extensive experiments across five state-of-the-art T2V models and five benchmarks demonstrate that RAPO++ achieves significant gains in semantic alignment, compositional reasoning, temporal stability, and physical plausibility, outperforming existing methods by large margins. Our results highlight RAPO++ as a model-agnostic, cost-efficient, and scalable solution that sets a new standard for prompt optimization in T2V generation. The code is available at this https URL.</li>
</ul>

<h3>Title: Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset</h3>
<ul>
<li><strong>Authors: </strong>Shumin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20209">https://arxiv.org/abs/2510.20209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20209">https://arxiv.org/pdf/2510.20209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20209]] Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset(https://arxiv.org/abs/2510.20209)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The development of accessible screening tools for early cancer detection in dogs represents a significant challenge in veterinary medicine. Routine laboratory data offer a promising, low-cost source for such tools, but their utility is hampered by the non-specificity of individual biomarkers and the severe class imbalance inherent in screening populations. This study assesses the feasibility of cancer risk classification using the Golden Retriever Lifetime Study (GRLS) cohort under real-world constraints, including the grouping of diverse cancer types and the inclusion of post-diagnosis samples. A comprehensive benchmark evaluation was conducted, systematically comparing 126 analytical pipelines that comprised various machine learning models, feature selection methods, and data balancing techniques. Data were partitioned at the patient level to prevent leakage. The optimal model, a Logistic Regression classifier with class weighting and recursive feature elimination, demonstrated moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical classification performance (F1-score = 0.25, Positive Predictive Value = 0.15). While a high Negative Predictive Value (0.98) was achieved, insufficient recall (0.79) precludes its use as a reliable rule-out test. Interpretability analysis with SHapley Additive exPlanations (SHAP) revealed that predictions were driven by non-specific features like age and markers of inflammation and anemia. It is concluded that while a statistically detectable cancer signal exists in routine lab data, it is too weak and confounded for clinically reliable discrimination from normal aging or other inflammatory conditions. This work establishes a critical performance ceiling for this data modality in isolation and underscores that meaningful progress in computational veterinary oncology will require integration of multi-modal data sources.</li>
</ul>

<h3>Title: Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection</h3>
<ul>
<li><strong>Authors: </strong>Talha Ilyas, Duong Nhu, Allison Thomas, Arie Levin, Lim Wei Yap, Shu Gong, David Vera Anaya, Yiwen Jiang, Deval Mehta, Ritesh Warty, Vinayak Smith, Maya Reddy, Euan Wallace, Wenlong Cheng, Zongyuan Ge, Faezeh Marzbanrad</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20214">https://arxiv.org/abs/2510.20214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20214">https://arxiv.org/pdf/2510.20214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20214]] Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection(https://arxiv.org/abs/2510.20214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate fetal movement (FM) detection is essential for assessing prenatal health, as abnormal movement patterns can indicate underlying complications such as placental dysfunction or fetal distress. Traditional methods, including maternal perception and cardiotocography (CTG), suffer from subjectivity and limited accuracy. To address these challenges, we propose Contrastive Ultrasound Video Representation Learning (CURL), a novel self-supervised learning framework for FM detection from extended fetal ultrasound video recordings. Our approach leverages a dual-contrastive loss, incorporating both spatial and temporal contrastive learning, to learn robust motion representations. Additionally, we introduce a task-specific sampling strategy, ensuring the effective separation of movement and non-movement segments during self-supervised training, while enabling flexible inference on arbitrarily long ultrasound recordings through a probabilistic fine-tuning approach. Evaluated on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions, CURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its potential for reliable and objective FM analysis. These results highlight the potential of self-supervised contrastive learning for fetal movement analysis, paving the way for improved prenatal monitoring and clinical decision-making.</li>
</ul>

<h3>Title: EditInfinity: Image Editing with Binary-Quantized Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Jiahuan Wang, Yuxin Chen, Jun Yu, Guangming Lu, Wenjie Pei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20217">https://arxiv.org/abs/2510.20217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20217">https://arxiv.org/pdf/2510.20217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20217]] EditInfinity: Image Editing with Binary-Quantized Generative Models(https://arxiv.org/abs/2510.20217)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Adapting pretrained diffusion-based generative models for text-driven image editing with negligible tuning overhead has demonstrated remarkable potential. A classical adaptation paradigm, as followed by these methods, first infers the generative trajectory inversely for a given source image by image inversion, then performs image editing along the inferred trajectory guided by the target text prompts. However, the performance of image editing is heavily limited by the approximation errors introduced during image inversion by diffusion models, which arise from the absence of exact supervision in the intermediate generative steps. To circumvent this issue, we investigate the parameter-efficient adaptation of VQ-based generative models for image editing, and leverage their inherent characteristic that the exact intermediate quantized representations of a source image are attainable, enabling more effective supervision for precise image inversion. Specifically, we propose \emph{EditInfinity}, which adapts \emph{Infinity}, a binary-quantized generative model, for image editing. We propose an efficient yet effective image inversion mechanism that integrates text prompting rectification and image style preservation, enabling precise image inversion. Furthermore, we devise a holistic smoothing strategy which allows our \emph{EditInfinity} to perform image editing with high fidelity to source images and precise semantic alignment to the text prompts. Extensive experiments on the PIE-Bench benchmark across "add", "change", and "delete" editing operations, demonstrate the superior performance of our model compared to state-of-the-art diffusion-based baselines. Code available at: this https URL.</li>
</ul>

<h3>Title: CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks</h3>
<ul>
<li><strong>Authors: </strong>Ke Xing, Yanjie Dong, Xiaoyi Fan, Runhao Zeng, Victor C. M. Leung, M. Jamal Deen, Xiping Hu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20219">https://arxiv.org/abs/2510.20219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20219">https://arxiv.org/pdf/2510.20219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20219]] CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks(https://arxiv.org/abs/2510.20219)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Personalized federated learning (PFL) addresses a critical challenge of collaboratively training customized models for clients with heterogeneous and scarce local data. Conventional federated learning, which relies on a single consensus model, proves inadequate under such data heterogeneity. Its standard aggregation method of weighting client updates heuristically or by data volume, operates under an equal-contribution assumption, failing to account for the actual utility and reliability of each client's update. This often results in suboptimal personalization and aggregation bias. To overcome these limitations, we introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that dynamically estimates each client's contribution for global aggregation. CO-PFL performs a joint assessment by analyzing both gradient direction discrepancies and prediction deviations, leveraging information from gradient and data subspaces. This dual-subspace analysis provides a principled and discriminative aggregation weight for each client, emphasizing high-quality updates. Furthermore, to bolster personalization adaptability and optimization stability, CO-PFL cohesively integrates a parameter-wise personalization mechanism with mask-aware momentum optimization. Our approach effectively mitigates aggregation bias, strengthens global coordination, and enhances local performance by facilitating the construction of tailored submodels with stable updates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C, CINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses state-of-the-art methods in in personalization accuracy, robustness, scalability and convergence stability.</li>
</ul>

<h3>Title: Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints</h3>
<ul>
<li><strong>Authors: </strong>Iván Ojeda-Ruiz, Young Ju-Lee, Malcolm Dickens, Leonardo Cambisaca</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20220">https://arxiv.org/abs/2510.20220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20220">https://arxiv.org/pdf/2510.20220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20220]] Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints(https://arxiv.org/abs/2510.20220)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Recent research has focused on mitigating algorithmic bias in clustering by incorporating fairness constraints into algorithmic design. Notions such as disparate impact, community cohesion, and cost per population have been implemented to enforce equitable outcomes. Among these, group fairness (balance) ensures that each protected group is proportionally represented within every cluster. However, incorporating balance as a metric of fairness into spectral clustering algorithms has led to computational times that can be improved. This study aims to enhance the efficiency of spectral clustering algorithms by reformulating the constrained optimization problem using a new formulation derived from the Lagrangian method and the Sherman-Morrison-Woodbury (SMW) identity, resulting in the Fair-SMW algorithm. Fair-SMW employs three alternatives to the Laplacian matrix with different spectral gaps to generate multiple variations of Fair-SMW, achieving clustering solutions with comparable balance to existing algorithms while offering improved runtime performance. We present the results of Fair-SMW, evaluated using the Stochastic Block Model (SBM) to measure both runtime efficiency and balance across real-world network datasets, including LastFM, FacebookNet, Deezer, and German. We achieve an improvement in computation time that is twice as fast as the state-of-the-art, and also flexible enough to achieve twice as much balance.</li>
</ul>

<h3>Title: QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Baojun Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20222">https://arxiv.org/abs/2510.20222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20222">https://arxiv.org/pdf/2510.20222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20222]] QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models(https://arxiv.org/abs/2510.20222)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In real-world time series forecasting tasks, category information plays a pivotal role in capturing inherent data patterns. This paper introduces QKCV (Query-Key-Category-Value) attention, an extension of the traditional QKV framework that incorporates a static categorical embedding C to emphasize category-specific information. As a versatile plug-in module, QKCV enhances the forecasting accuracy of attention-based models (e.g., Vanilla Transformer, Informer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV demonstrates remarkable adaptability in fine-tuning univariate time series foundation model by solely updating the static embedding C while preserving pretrained weights, thereby reducing computational overhead and achieving superior fine-tuning performance.</li>
</ul>

<h3>Title: Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations</h3>
<ul>
<li><strong>Authors: </strong>Divyanshu Kumar, Shreyas Jena, Nitin Aravind Birur, Tanay Baswa, Sahil Agarwal, Prashanth Harshangi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20223">https://arxiv.org/abs/2510.20223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20223">https://arxiv.org/pdf/2510.20223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20223]] Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations(https://arxiv.org/abs/2510.20223)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have achieved remarkable progress, yet remain critically vulnerable to adversarial attacks that exploit weaknesses in cross-modal processing. We present a systematic study of multimodal jailbreaks targeting both vision-language and audio-language models, showing that even simple perceptual transformations can reliably bypass state-of-the-art safety filters. Our evaluation spans 1,900 adversarial prompts across three high-risk safety categories harmful content, CBRN (Chemical, Biological, Radiological, Nuclear), and CSEM (Child Sexual Exploitation Material) tested against seven frontier models. We explore the effectiveness of attack techniques on MLLMs, including FigStep-Pro (visual keyword decomposition), Intelligent Masking (semantic obfuscation), and audio perturbations (Wave-Echo, Wave-Pitch, Wave-Speed). The results reveal severe vulnerabilities: models with almost perfect text-only safety (0\% ASR) suffer >75\% attack success under perceptually modified inputs, with FigStep-Pro achieving up to 89\% ASR in Llama-4 variants. Audio-based attacks further uncover provider-specific weaknesses, with even basic modality transfer yielding 25\% ASR for technical queries. These findings expose a critical gap between text-centric alignment and multimodal threats, demonstrating that current safeguards fail to generalize across cross-modal attacks. The accessibility of these attacks, which require minimal technical expertise, suggests that robust multimodal AI safety will require a paradigm shift toward broader semantic-level reasoning to mitigate possible risks.</li>
</ul>

<h3>Title: Federated Learning via Meta-Variational Dropout</h3>
<ul>
<li><strong>Authors: </strong>Insu Jeon, Minui Hong, Junhyeog Yun, Gunhee Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20225">https://arxiv.org/abs/2510.20225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20225">https://arxiv.org/pdf/2510.20225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20225]] Federated Learning via Meta-Variational Dropout(https://arxiv.org/abs/2510.20225)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) aims to train a global inference model from remotely distributed clients, gaining popularity due to its benefit of improving data privacy. However, traditional FL often faces challenges in practical applications, including model overfitting and divergent local models due to limited and non-IID data among clients. To address these issues, we introduce a novel Bayesian meta-learning approach called meta-variational dropout (MetaVD). MetaVD learns to predict client-dependent dropout rates via a shared hypernetwork, enabling effective model personalization of FL algorithms in limited non-IID data settings. We also emphasize the posterior adaptation view of meta-learning and the posterior aggregation view of Bayesian FL via the conditional dropout posterior. We conducted extensive experiments on various sparse and non-IID FL datasets. MetaVD demonstrated excellent classification accuracy and uncertainty calibration performance, especially for out-of-distribution (OOD) clients. MetaVD compresses the local model parameters needed for each client, mitigating model overfitting and reducing communication costs. Code is available at this https URL.</li>
</ul>

<h3>Title: COS3D: Collaborative Open-Vocabulary 3D Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Runsong Zhu, Ka-Hei Hui, Zhengzhe Liu, Qianyi Wu, Weiliang Tang, Shi Qiu, Pheng-Ann Heng, Chi-Wing Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20238">https://arxiv.org/abs/2510.20238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20238">https://arxiv.org/pdf/2510.20238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20238]] COS3D: Collaborative Open-Vocabulary 3D Segmentation(https://arxiv.org/abs/2510.20238)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary 3D segmentation is a fundamental yet challenging task, requiring a mutual understanding of both segmentation and language. However, existing Gaussian-splatting-based methods rely either on a single 3D language field, leading to inferior segmentation, or on pre-computed class-agnostic segmentations, suffering from error accumulation. To address these limitations, we present COS3D, a new collaborative prompt-segmentation framework that contributes to effectively integrating complementary language and segmentation cues throughout its entire pipeline. We first introduce the new concept of collaborative field, comprising an instance field and a language field, as the cornerstone for collaboration. During training, to effectively construct the collaborative field, our key idea is to capture the intrinsic relationship between the instance field and language field, through a novel instance-to-language feature mapping and designing an efficient two-stage training strategy. During inference, to bridge distinct characteristics of the two fields, we further design an adaptive language-to-instance prompt refinement, promoting high-quality prompt-segmentation inference. Extensive experiments not only demonstrate COS3D's leading performance over existing methods on two widely-used benchmarks but also show its high potential to various applications,~\ie, novel image-based 3D segmentation, hierarchical segmentation, and robotics. The code is publicly available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders</h3>
<ul>
<li><strong>Authors: </strong>Filippo Cenacchi, Deborah Richards, Longbing Cao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20239">https://arxiv.org/abs/2510.20239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20239">https://arxiv.org/pdf/2510.20239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20239]] Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders(https://arxiv.org/abs/2510.20239)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Depression and post traumatic stress disorder (PTSD) often co-occur with connected symptoms, complicating automated assessment, which is often binary and disorder specific. Clinically useful diagnosis needs severity aware cross disorder estimates and decision support explanations. Our unified tri modal affective severity framework synchronizes and fuses interview text with sentence level transformer embeddings, audio with log Mel statistics with deltas, and facial signals with action units, gaze, head and pose descriptors to output graded severities for diagnosing both depression (PHQ-8; 5 classes) and PTSD (3 classes). Standardized features are fused via a calibrated late fusion classifier, yielding per disorder probabilities and feature-level attributions. This severity aware tri-modal affective fusion approach is demoed on multi disorder concurrent depression and PTSD assessment. Stratified cross validation on DAIC derived corpora outperforms unimodal/ablation baselines. The fused model matches the strongest unimodal baseline on accuracy and weighted F1, while improving decision curve utility and robustness under noisy or missing modalities. For PTSD specifically, fusion reduces regression error and improves class concordance. Errors cluster between adjacent severities; extreme classes are identified reliably. Ablations show text contributes most to depression severity, audio and facial cues are critical for PTSD, whereas attributions align with linguistic and behavioral markers. Our approach offers reproducible evaluation and clinician in the loop support for affective clinical decision making.</li>
</ul>

<h3>Title: What Does It Take to Build a Performant Selective Classifier?</h3>
<ul>
<li><strong>Authors: </strong>Stephan Rabanser, Nicolas Papernot</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20242">https://arxiv.org/abs/2510.20242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20242">https://arxiv.org/pdf/2510.20242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20242]] What Does It Take to Build a Performant Selective Classifier?(https://arxiv.org/abs/2510.20242)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Selective classifiers improve model reliability by abstaining on inputs the model deems uncertain. However, few practical approaches achieve the gold-standard performance of a perfect-ordering oracle that accepts examples exactly in order of correctness. Our work formalizes this shortfall as the selective-classification gap and present the first finite-sample decomposition of this gap to five distinct sources of looseness: Bayes noise, approximation error, ranking error, statistical noise, and implementation- or shift-induced slack. Crucially, our analysis reveals that monotone post-hoc calibration -- often believed to strengthen selective classifiers -- has limited impact on closing this gap, since it rarely alters the model's underlying score ranking. Bridging the gap therefore requires scoring mechanisms that can effectively reorder predictions rather than merely rescale them. We validate our decomposition on synthetic two-moons data and on real-world vision and language benchmarks, isolating each error component through controlled experiments. Our results confirm that (i) Bayes noise and limited model capacity can account for substantial gaps, (ii) only richer, feature-aware calibrators meaningfully improve score ordering, and (iii) data shift introduces a separate slack that demands distributionally robust training. Together, our decomposition yields a quantitative error budget as well as actionable design guidelines that practitioners can use to build selective classifiers which approximate ideal oracle behavior more closely.</li>
</ul>

<h3>Title: HHEML: Hybrid Homomorphic Encryption for Privacy-Preserving Machine Learning on Edge</h3>
<ul>
<li><strong>Authors: </strong>Yu Hin Chan, Hao Yang, Shiyu Shen, Xingyu Fan, Shengzhe Lyu, Patrick S. Y. Hung, Ray C. C. Cheung</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20243">https://arxiv.org/abs/2510.20243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20243">https://arxiv.org/pdf/2510.20243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20243]] HHEML: Hybrid Homomorphic Encryption for Privacy-Preserving Machine Learning on Edge(https://arxiv.org/abs/2510.20243)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Privacy-preserving machine learning (PPML) is an emerging topic to handle secure machine learning inference over sensitive data in untrusted environments. Fully homomorphic encryption (FHE) enables computation directly on encrypted data on the server side, making it a promising approach for PPML. However, it introduces significant communication and computation overhead on the client side, making it impractical for edge devices. Hybrid homomorphic encryption (HHE) addresses this limitation by combining symmetric encryption (SE) with FHE to reduce the computational cost on the client side, and combining with an FHE-friendly SE can also lessen the processing overhead on the server side, making it a more balanced and efficient alternative. Our work proposes a hardware-accelerated HHE architecture built around a lightweight symmetric cipher optimized for FHE compatibility and implemented as a dedicated hardware accelerator. To the best of our knowledge, this is the first design to integrate an end-to-end HHE framework with hardware acceleration. Beyond this, we also present several microarchitectural optimizations to achieve higher performance and energy efficiency. The proposed work is integrated into a full PPML pipeline, enabling secure inference with significantly lower latency and power consumption than software implementations. Our contributions validate the feasibility of low-power, hardware- accelerated HHE for edge deployment and provide a hardware- software co-design methodology for building scalable, secure machine learning systems in resource-constrained environments. Experiments on a PYNQ-Z2 platform with the MNIST dataset show over a 50x reduction in client-side encryption latency and nearly a 2x gain in hardware throughput compared to existing FPGA-based HHE accelerators.</li>
</ul>

<h3>Title: Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization</h3>
<ul>
<li><strong>Authors: </strong>Shuhan Hu, Yiru Li, Yuanyuan Li, Yingying Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20247">https://arxiv.org/abs/2510.20247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20247">https://arxiv.org/pdf/2510.20247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20247]] Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization(https://arxiv.org/abs/2510.20247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Cross-view object geo-localization enables high-precision object localization through cross-view matching, with critical applications in autonomous driving, urban management, and disaster response. However, existing methods rely on keypoint-based positional encoding, which captures only 2D coordinates while neglecting object shape information, resulting in sensitivity to annotation shifts and limited cross-view matching capability. To address these limitations, we propose a mask-based positional encoding scheme that leverages segmentation masks to capture both spatial coordinates and object silhouettes, thereby upgrading the model from "location-aware" to "object-aware." Furthermore, to tackle the challenge of large-span objects (e.g., elongated buildings) in satellite imagery, we design a context enhancement module. This module employs horizontal and vertical strip convolutional kernels to extract long-range contextual features, enhancing feature discrimination among strip-like objects. Integrating MPE and CEM, we present EDGeo, an end-to-end framework for robust cross-view object geo-localization. Extensive experiments on two public datasets (CVOGL and VIGOR-Building) demonstrate that our method achieves state-of-the-art performance, with a 3.39% improvement in localization accuracy under challenging ground-to-satellite scenarios. This work provides a robust positional encoding paradigm and a contextual modeling framework for advancing cross-view geo-localization research.</li>
</ul>

<h3>Title: FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhiqin Yang, Yonggang Zhang, Chenxin Li, Yiu-ming Cheung, Bo Han, Yixuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20250">https://arxiv.org/abs/2510.20250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20250">https://arxiv.org/pdf/2510.20250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20250]] FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning(https://arxiv.org/abs/2510.20250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) confronts a significant challenge known as data heterogeneity, which impairs model performance and convergence. Existing methods have made notable progress in addressing this issue. However, improving performance in certain heterogeneity scenarios remains an overlooked question: \textit{How robust are these methods to deploy under diverse heterogeneity scenarios?} To answer this, we conduct comprehensive evaluations across varied heterogeneity scenarios, showing that most existing methods exhibit limited robustness. Meanwhile, insights from these experiments highlight that sharing statistical information can mitigate heterogeneity by enabling clients to update with a global perspective. Motivated by this, we propose \textbf{FedGPS} (\textbf{Fed}erated \textbf{G}oal-\textbf{P}ath \textbf{S}ynergy), a novel framework that seamlessly integrates statistical distribution and gradient information from others. Specifically, FedGPS statically modifies each client's learning objective to implicitly model the global data distribution using surrogate information, while dynamically adjusting local update directions with gradient information from other clients at each round. Extensive experiments show that FedGPS outperforms state-of-the-art methods across diverse heterogeneity scenarios, validating its effectiveness and robustness. The code is available at: this https URL.</li>
</ul>

<h3>Title: Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals</h3>
<ul>
<li><strong>Authors: </strong>Saraf Anzum Shreya, MD. Abu Ismail Siddique, Sharaf Tasnim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20267">https://arxiv.org/abs/2510.20267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20267">https://arxiv.org/pdf/2510.20267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20267]] Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals(https://arxiv.org/abs/2510.20267)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Technologies like smartphones have become an essential in our daily lives. It has made accessible to everyone including visually impaired individuals. With the use of smartphone cameras, image capturing and processing have become more convenient. With the use of smartphones and machine learning, the life of visually impaired can be made a little easier. Daily tasks such as handling money without relying on someone can be troublesome for them. For that purpose this paper presents a real-time currency detection system designed to assist visually impaired individuals. The proposed model is trained on a dataset containing 30 classes of notes and coins, representing 3 types of currency: US dollar (USD), Euro (EUR), and Bangladeshi taka (BDT). Our approach uses a YOLOv8 nano model with a custom detection head featuring deep convolutional layers and Squeeze-and-Excitation blocks to enhance feature extraction and detection accuracy. Our model has achieved a higher accuracy of 97.73%, recall of 95.23%, f1-score of 95.85% and a mean Average Precision at IoU=0.5 (mAP50(B)) of 97.21\%. Using the voice feedback after the detection would help the visually impaired to identify the currency. This paper aims to create a practical and efficient currency detection system to empower visually impaired individuals independent in handling money.</li>
</ul>

<h3>Title: ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases</h3>
<ul>
<li><strong>Authors: </strong>Ziqian Zhong, Aditi Raghunathan, Nicholas Carlini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20270">https://arxiv.org/abs/2510.20270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20270">https://arxiv.org/pdf/2510.20270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20270]] ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases(https://arxiv.org/abs/2510.20270)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The tendency to find and exploit "shortcuts" to complete tasks poses significant risks for reliable assessment and deployment of large language models (LLMs). For example, an LLM agent with access to unit tests may delete failing tests rather than fix the underlying bug. Such behavior undermines both the validity of benchmark results and the reliability of real-world LLM coding assistant deployments. To quantify, study, and mitigate such behavior, we introduce ImpossibleBench, a benchmark framework that systematically measures LLM agents' propensity to exploit test cases. ImpossibleBench creates "impossible" variants of tasks from existing benchmarks like LiveCodeBench and SWE-bench by introducing direct conflicts between the natural-language specification and the unit tests. We measure an agent's "cheating rate" as its pass rate on these impossible tasks, where any pass necessarily implies a specification-violating shortcut. As a practical framework, ImpossibleBench is not just an evaluation but a versatile tool. We demonstrate its utility for: (1) studying model behaviors, revealing more fine-grained details of cheating behaviors from simple test modification to complex operator overloading; (2) context engineering, showing how prompt, test access and feedback loop affect cheating rates; and (3) developing monitoring tools, providing a testbed with verified deceptive solutions. We hope ImpossibleBench serves as a useful framework for building more robust and reliable LLM systems. Our implementation can be found at this https URL.</li>
</ul>

<h3>Title: Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tristan Cinquin, Geoff Pleiss, Agustinus Kristiadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20272">https://arxiv.org/abs/2510.20272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20272">https://arxiv.org/pdf/2510.20272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20272]] Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs(https://arxiv.org/abs/2510.20272)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While chain-of-thought prompting with Best-of-N (BoN) selection has become popular for mathematical reasoning in large language models (LLMs), its linear structure fails to capture the branching and exploratory nature of complex problem-solving. In this work, we propose an adaptive algorithm to maximize process reward model (PRM) scores over the intractable action space, and investigate whether PRM-guided tree search can improve mathematical reasoning by exploring multiple partial solution paths. Across $23$ diverse mathematical problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case study, we find that: (1) PRM-guided tree search shows no statistically significant improvements over BoN despite higher costs, (2) Monte Carlo tree search and beam search outperform other PRM-guided tree search methods, (3) PRMs poorly approximate state values and their reliability degrades with reasoning depth, and (4) PRMs generalize poorly out of distribution. This underperformance stems from tree search's greater reliance on unreliable PRM scores, suggesting different reward modeling is necessary before tree search can effectively enhance mathematical reasoning in LLMs.</li>
</ul>

<h3>Title: SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series</h3>
<ul>
<li><strong>Authors: </strong>Qitai Tan, Yiyun Chen, Mo Li, Ruiwen Gu, Yilin Su, Xiao-Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20273">https://arxiv.org/abs/2510.20273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20273">https://arxiv.org/pdf/2510.20273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20273]] SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series(https://arxiv.org/abs/2510.20273)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in deep learning have driven rapid progress in time series forecasting, yet many state-of-the-art models continue to struggle with robust performance in real-world applications, even when they achieve strong results on standard benchmark datasets. This persistent gap can be attributed to the black-box nature of deep learning architectures and the inherent limitations of current evaluation frameworks, which frequently lack the capacity to provide clear, quantitative insights into the specific strengths and weaknesses of different models, thereby complicating the selection of appropriate models for particular forecasting scenarios. To address these issues, we propose a synthetic data-driven evaluation paradigm, SynTSBench, that systematically assesses fundamental modeling capabilities of time series forecasting models through programmable feature configuration. Our framework isolates confounding factors and establishes an interpretable evaluation system with three core analytical dimensions: (1) temporal feature decomposition and capability mapping, which enables systematic evaluation of model capacities to learn specific pattern types; (2) robustness analysis under data irregularities, which quantifies noise tolerance thresholds and anomaly recovery capabilities; and (3) theoretical optimum benchmarking, which establishes performance boundaries for each pattern type-enabling direct comparison between model predictions and mathematical optima. Our experiments show that current deep learning models do not universally approach optimal baselines across all types of temporal this http URL code is available at this https URL</li>
</ul>

<h3>Title: KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models</h3>
<ul>
<li><strong>Authors: </strong>Guangyu Dai, Siliang Tang, Yueting Zhuang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20278">https://arxiv.org/abs/2510.20278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20278">https://arxiv.org/pdf/2510.20278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20278]] KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models(https://arxiv.org/abs/2510.20278)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In recent years, Pretrained Large Models(PLMs) researchers proposed large-small model collaboration frameworks, leveraged easily trainable small models to assist large models, aim to(1) significantly reduce computational resource consumption while maintaining comparable accuracy, and (2) enhance large model performance in specialized domain tasks. However, this collaborative paradigm suffers from issues such as significant accuracy degradation, exacerbated catastrophic forgetting, and amplified hallucination problems induced by small model knowledge. To address these challenges, we propose a KAN-based Collaborative Model (KCM) as an improved approach to large-small model collaboration. The KAN utilized in KCM represents an alternative neural network architecture distinct from conventional MLPs. Compared to MLPs, KAN offers superior visualizability and interpretability while mitigating catastrophic forgetting. We deployed KCM in large-small model collaborative systems across three scenarios: language, vision, and vision-language cross-modal tasks. The experimental results demonstrate that, compared with pure large model approaches, the large-small model collaboration framework utilizing KCM as the collaborative model significantly reduces the number of large model inference calls while maintaining near-identical task accuracy, thereby substantially lowering computational resource consumption. Concurrently, the KAN-based small collaborative model markedly mitigates catastrophic forgetting, leading to significant accuracy improvements for long-tail data. The results reveal that KCM demonstrates superior performance across all metrics compared to MLP-based small collaborative models (MCM).</li>
</ul>

<h3>Title: ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows</h3>
<ul>
<li><strong>Authors: </strong>Penghao Wang, Yuhao Zhou, Mengxuan Wu, Ziheng Qin, Bangyuan Zhu, Shengbin Huang, Xuanlei Zhao, Panpan Zhang, Xiaojiang Peng, Yuzhang Shang, Jianfei Yang, Zheng Zhu, Tianlong Chen, Zhangyang Wang, Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20279">https://arxiv.org/abs/2510.20279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20279">https://arxiv.org/pdf/2510.20279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20279]] ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows(https://arxiv.org/abs/2510.20279)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) advance, the ultimate vision for their role in science is emerging: we could build an AI collaborator to effectively assist human beings throughout the entire scientific research process. We refer to this envisioned system as ResearchGPT. Given that scientific research progresses through multiple interdependent phases, achieving this vision requires rigorous benchmarks that evaluate the end-to-end workflow rather than isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of scientific Q&A pairs in computer science, built from 14k CC-licensed papers. It is constructed through a scalable, paper-grounded pipeline that combines retrieval-augmented generation (RAG) with multi-stage quality control to ensure factual grounding. From this unified corpus, we derive two complementary subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to assist scientific research, and CS-50k, a large-scale training dataset. Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs into distinct capability tiers. Open models trained on CS-50k with supervised training and reinforcement learning demonstrate substantial improvements. Even 7B-scale models, when properly trained, outperform many larger proprietary systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that making AI models better research assistants relies more on domain-aligned training with high-quality data than on pretraining scale or general benchmark performance. We release CS-4k and CS-50k in the hope of fostering AI systems as reliable collaborators in CS research.</li>
</ul>

<h3>Title: Context-level Language Modeling by Learning Predictive Context Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Beiya Dai, Yuliang Liu, Daozheng Xue, Qipeng Guo, Kai Chen, Xinbing Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20280">https://arxiv.org/abs/2510.20280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20280">https://arxiv.org/pdf/2510.20280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20280]] Context-level Language Modeling by Learning Predictive Context Embeddings(https://arxiv.org/abs/2510.20280)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Next-token prediction (NTP) is the cornerstone of modern large language models (LLMs) pretraining, driving their unprecedented capabilities in text generation, reasoning, and instruction following. However, the token-level prediction limits the model's capacity to capture higher-level semantic structures and long-range contextual relationships. To overcome this limitation, we introduce \textbf{ContextLM}, a framework that augments standard pretraining with an inherent \textbf{next-context prediction} objective. This mechanism trains the model to learn predictive representations of multi-token contexts, leveraging error signals derived from future token chunks. Crucially, ContextLM achieves this enhancement while remaining fully compatible with the standard autoregressive, token-by-token evaluation paradigm (e.g., perplexity). Extensive experiments on the GPT2 and Pythia model families, scaled up to $1.5$B parameters, show that ContextLM delivers consistent improvements in both perplexity and downstream task performance. Our analysis indicates that next-context prediction provides a scalable and efficient pathway to stronger language modeling, yielding better long-range coherence and more effective attention allocation with minimal computational overhead.</li>
</ul>

<h3>Title: Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition</h3>
<ul>
<li><strong>Authors: </strong>Haodong Yang, Zhongling Huang, Shaojie Guo, Zhe Zhang, Gong Cheng, Junwei Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20284">https://arxiv.org/abs/2510.20284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20284">https://arxiv.org/pdf/2510.20284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20284]] Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition(https://arxiv.org/abs/2510.20284)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning models for complex-valued Synthetic Aperture Radar (CV-SAR) image recognition are fundamentally constrained by a representation trilemma under data-limited and domain-shift scenarios: the concurrent, yet conflicting, optimization of generalization, interpretability, and efficiency. Our work is motivated by the premise that the rich electromagnetic scattering features inherent in CV-SAR data hold the key to resolving this trilemma, yet they are insufficiently harnessed by conventional data-driven models. To this end, we introduce the Knowledge-Informed Neural Network (KINN), a lightweight framework built upon a novel "compression-aggregation-compression" architecture. The first stage performs a physics-guided compression, wherein a novel dictionary processor adaptively embeds physical priors, enabling a compact unfolding network to efficiently extract sparse, physically-grounded signatures. A subsequent aggregation module enriches these representations, followed by a final semantic compression stage that utilizes a compact classification head with self-distillation to learn maximally task-relevant and discriminative embeddings. We instantiate KINN in both CNN (0.7M) and Vision Transformer (0.95M) variants. Extensive evaluations on five SAR benchmarks confirm that KINN establishes a state-of-the-art in parameter-efficient recognition, offering exceptional generalization in data-scarce and out-of-distribution scenarios and tangible interpretability, thereby providing an effective solution to the representation trilemma and offering a new path for trustworthy AI in SAR image analysis.</li>
</ul>

<h3>Title: Breakdance Video classification in the age of Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Sauptik Dhar, Naveen Ramakrishnan, Michelle Munson</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20287">https://arxiv.org/abs/2510.20287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20287">https://arxiv.org/pdf/2510.20287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20287]] Breakdance Video classification in the age of Generative AI(https://arxiv.org/abs/2510.20287)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large Vision Language models have seen huge application in several sports use-cases recently. Most of these works have been targeted towards a limited subset of popular sports like soccer, cricket, basketball etc; focusing on generative tasks like visual question answering, highlight generation. This work analyzes the applicability of the modern video foundation models (both encoder and decoder) for a very niche but hugely popular dance sports - breakdance. Our results show that Video Encoder models continue to outperform state-of-the-art Video Language Models for prediction tasks. We provide insights on how to choose the encoder model and provide a thorough analysis into the workings of a finetuned decoder model for breakdance video classification.</li>
</ul>

<h3>Title: A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization</h3>
<ul>
<li><strong>Authors: </strong>LinFeng Li, Jian Zhao, Zepeng Yang, Yuhang Song, Bojun Lin, Tianle Zhang, Yuchen Yuan, Chi Zhang, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20291">https://arxiv.org/abs/2510.20291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20291">https://arxiv.org/pdf/2510.20291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20291]] A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization(https://arxiv.org/abs/2510.20291)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone Navigation. The task retrieves the most relevant geo-referenced image from a large multi-platform corpus (satellite/drone/ground) given a natural-language query. Two obstacles are severe inter-platform heterogeneity and a domain gap between generic training descriptions and platform-specific test queries. We mitigate these with a domain-aligned preprocessing pipeline and a Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite augmentation, and removal of orientation words; (ii) an LLM-based caption refinement pipeline to align textual semantics with the distinct visual characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we train three platform experts using a progressive two-stage, hard-negative mining strategy to enhance discriminative power, and fuse their scores at inference. The system tops the official leaderboard, demonstrating robust cross-modal geo-localization under heterogeneous viewpoints.</li>
</ul>

<h3>Title: DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Saraf Anzum Shreya, MD. Abu Ismail Siddique, Sharaf Tasnim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20299">https://arxiv.org/abs/2510.20299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20299">https://arxiv.org/pdf/2510.20299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20299]] DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability(https://arxiv.org/abs/2510.20299)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\% and 99.85\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.</li>
</ul>

<h3>Title: Privacy Protection of Automotive Location Data Based on Format-Preserving Encryption of Geographical Coordinates</h3>
<ul>
<li><strong>Authors: </strong>Haojie Ji, Long Jin, Haowen Li, Chongshi Xin, Te Hu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20300">https://arxiv.org/abs/2510.20300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20300">https://arxiv.org/pdf/2510.20300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20300]] Privacy Protection of Automotive Location Data Based on Format-Preserving Encryption of Geographical Coordinates(https://arxiv.org/abs/2510.20300)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>There are increasing risks of privacy disclosure when sharing the automotive location data in particular functions such as route navigation, driving monitoring and vehicle scheduling. These risks could lead to the attacks including user behavior recognition, sensitive location inference and trajectory reconstruction. In order to mitigate the data security risk caused by the automotive location sharing, this paper proposes a high-precision privacy protection mechanism based on format-preserving encryption (FPE) of geographical coordinates. The automotive coordinate data key mapping mechanism is designed to reduce to the accuracy loss of the geographical location data caused by the repeated encryption and decryption. The experimental results demonstrate that the average relative distance retention rate (RDR) reached 0.0844, and the number of hotspots in the critical area decreased by 98.9% after encryption. To evaluate the accuracy loss of the proposed encryption algorithm on automotive geographical location data, this paper presents the experimental analysis of decryption accuracy, and the result indicates that the decrypted coordinate data achieves a restoration accuracy of 100%. This work presents a high-precision privacy protection method for automotive location data, thereby providing an efficient data security solution for the sensitive data sharing in autonomous driving.</li>
</ul>

<h3>Title: InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20302">https://arxiv.org/abs/2510.20302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20302">https://arxiv.org/pdf/2510.20302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20302]] InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling(https://arxiv.org/abs/2510.20302)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multivariate time series forecasting requires simultaneously modeling temporal patterns and cross-variate dependencies. Channel-independent methods such as PatchTST excel at temporal modeling but ignore variable correlations, while pure variate-attention approaches such as iTransformer sacrifice temporal encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that achieves principled separation between temporal encoding and variate-level decoding. InvDec combines a patch-based temporal encoder with an inverted decoder operating on the variate dimension through variate-wise self-attention. We introduce delayed variate embeddings that enrich variable-specific representations only after temporal encoding, preserving temporal feature integrity. An adaptive residual fusion mechanism dynamically balances temporal and variate information across datasets of varying dimensions. Instantiating InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven benchmarks demonstrate significant gains on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and 2.7% gain on Traffic compared to PatchTST, while maintaining competitive performance on low-dimensional ETT datasets. Ablation studies validate each component, and analysis reveals that InvDec's advantage grows with dataset dimensionality, confirming that cross-variate modeling becomes critical as the number of variables increases.</li>
</ul>

<h3>Title: Citation Failure: Definition, Analysis and Efficient Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Jan Buchmann, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20303">https://arxiv.org/abs/2510.20303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20303">https://arxiv.org/pdf/2510.20303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20303]] Citation Failure: Definition, Analysis and Efficient Mitigation(https://arxiv.org/abs/2510.20303)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Citations from LLM-based RAG systems are supposed to simplify response verification. However, this does not hold for citation failure, when a model generates a helpful response, but fails to cite complete evidence. In contrast to previous work, we propose to disentangle this from response failure, where the response itself is flawed, and citing complete evidence is impossible. To address citation failure, this work follows a two-step approach: (1) We study when citation failure occurs and (2) how it can be mitigated. For step 1, we extend prior work by investigating how the relation between response and evidence affects citation quality. We introduce CITECONTROL, a benchmark that systematically varies this relation to analyze failure modes. Experiments show that failures increase with relational complexity and suggest that combining citation methods could improve performance, motivating step 2. To improve LLM citation efficiently, we propose CITENTION, a framework integrating generative, attention-based, and retrieval-based methods. Results demonstrate substantial citation improvements on CITECONTROL and in transfer settings. We make our data and code publicly available.</li>
</ul>

<h3>Title: Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Lei Tang, Wei Zhou, Mohsen Mesgar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20304">https://arxiv.org/abs/2510.20304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20304">https://arxiv.org/pdf/2510.20304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20304]] Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering(https://arxiv.org/abs/2510.20304)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Process reward models (PRMs) improve complex reasoning in large language models (LLMs) by grading candidate solutions step-by-step and selecting answers via aggregated step scores. While effective in domains such as mathematics, their applicability to tasks involving semi-structured data, like table question answering (TQA) remains unexplored. TQA poses unique challenges for PRMs, including abundant irrelevant information, loosely connected reasoning steps, and domain-specific reasoning. This work presents the first systematic study of PRMs for TQA. We evaluate state-of-the-art generative PRMs on TQA from both answer and step perspectives. Results show that PRMs that combine textual and code verification can aid solution selection but struggle to generalize to out-of-domain data. Analysis reveals a weak correlation between performance in step-level verification and answer accuracy, possibly stemming from weak step dependencies and loose causal links. Our findings highlight limitations of current PRMs on TQA and offer valuable insights for building more robust, process-aware verifiers.</li>
</ul>

<h3>Title: Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses</h3>
<ul>
<li><strong>Authors: </strong>Wu Yichao, Wang Yirui, Ding Panpan, Wang Hailong, Zhu Bingqian, Liu Chun</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20314">https://arxiv.org/abs/2510.20314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20314">https://arxiv.org/pdf/2510.20314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20314]] Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses(https://arxiv.org/abs/2510.20314)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, explainability</a></li>
<li><strong>Abstract: </strong>With the wide application of deep reinforcement learning (DRL) techniques in complex fields such as autonomous driving, intelligent manufacturing, and smart healthcare, how to improve its security and robustness in dynamic and changeable environments has become a core issue in current research. Especially in the face of adversarial attacks, DRL may suffer serious performance degradation or even make potentially dangerous decisions, so it is crucial to ensure their stability in security-sensitive scenarios. In this paper, we first introduce the basic framework of DRL and analyze the main security challenges faced in complex and changing environments. In addition, this paper proposes an adversarial attack classification framework based on perturbation type and attack target and reviews the mainstream adversarial attack methods against DRL in detail, including various attack methods such as perturbation state space, action space, reward function and model space. To effectively counter the attacks, this paper systematically summarizes various current robustness training strategies, including adversarial training, competitive training, robust learning, adversarial detection, defense distillation and other related defense techniques, we also discuss the advantages and shortcomings of these methods in improving the robustness of DRL. Finally, this paper looks into the future research direction of DRL in adversarial environments, emphasizing the research needs in terms of improving generalization, reducing computational complexity, and enhancing scalability and explainability, aiming to provide valuable references and directions for researchers.</li>
</ul>

<h3>Title: HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zelin Peng, Zhengqin Xu, Qingyang Liu, Xiaokang Yang, Wei Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20322">https://arxiv.org/abs/2510.20322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20322">https://arxiv.org/pdf/2510.20322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20322]] HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models(https://arxiv.org/abs/2510.20322)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as HyperET, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. HyperET employs learnable matrices with Möbius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that HyperET consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\% additional parameters.</li>
</ul>

<h3>Title: LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems</h3>
<ul>
<li><strong>Authors: </strong>Fengyuan Yu, Yuyuan Li, Xiaohua Feng, Junjie Fang, Tao Wang, Chaochao Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20327">https://arxiv.org/abs/2510.20327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20327">https://arxiv.org/pdf/2510.20327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20327]] LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems(https://arxiv.org/abs/2510.20327)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>With the growing demand for safeguarding sensitive user information in recommender systems, recommendation attribute unlearning is receiving increasing attention. Existing studies predominantly focus on single-attribute unlearning. However, privacy protection requirements in the real world often involve multiple sensitive attributes and are dynamic. Existing single-attribute unlearning methods cannot meet these real-world requirements due to i) CH1: the inability to handle multiple unlearning requests simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic unlearning needs. To address these challenges, we propose LEGO, a lightweight and efficient multiple-attribute unlearning framework. Specifically, we divide the multiple-attribute unlearning process into two steps: i) Embedding Calibration removes information related to a specific attribute from user embedding, and ii) Flexible Combination combines these embeddings into a single embedding, protecting all sensitive attributes. We frame the unlearning process as a mutual information minimization problem, providing LEGO a theoretical guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step framework, where Embedding Calibration can be performed in parallel and Flexible Combination is flexible and efficient, we address CH2. Extensive experiments on three real-world datasets across three representative recommendation models demonstrate the effectiveness and efficiency of our proposed framework. Our code and appendix are available at this https URL.</li>
</ul>

<h3>Title: AnyPcc: Compressing Any Point Cloud with a Single Universal Model</h3>
<ul>
<li><strong>Authors: </strong>Kangli Wang, Qianxi Yi, Yuqi Ye, Shihao Li, Wei Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20331">https://arxiv.org/abs/2510.20331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20331">https://arxiv.org/pdf/2510.20331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20331]] AnyPcc: Compressing Any Point Cloud with a Single Universal Model(https://arxiv.org/abs/2510.20331)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generalization remains a critical challenge for deep learning-based point cloud geometry compression. We argue this stems from two key limitations: the lack of robust context models and the inefficient handling of out-of-distribution (OOD) data. To address both, we introduce AnyPcc, a universal point cloud compression framework. AnyPcc first employs a Universal Context Model that leverages priors from both spatial and channel-wise grouping to capture robust contextual dependencies. Second, our novel Instance-Adaptive Fine-Tuning (IAFT) strategy tackles OOD data by synergizing explicit and implicit compression paradigms. It fine-tunes a small subset of network weights for each instance and incorporates them into the bitstream, where the marginal bit cost of the weights is dwarfed by the resulting savings in geometry compression. Extensive experiments on a benchmark of 15 diverse datasets confirm that AnyPcc sets a new state-of-the-art in point cloud compression. Our code and datasets will be released to encourage reproducible research.</li>
</ul>

<h3>Title: GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?</h3>
<ul>
<li><strong>Authors: </strong>Chiyu Chen, Xinhao Song, Yunkai Chai, Yang Yao, Haodong Zhao, Lijun Li, Jie Li, Yan Teng, Gongshen Liu, Yingchun Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20333">https://arxiv.org/abs/2510.20333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20333">https://arxiv.org/pdf/2510.20333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20333]] GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?(https://arxiv.org/abs/2510.20333)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.</li>
</ul>

<h3>Title: AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Seunghoon Lee, Jeongwoo Choi, Byunggwan Son, Jaehyeon Moon, Jeimin Jeon, Bumsub Ham</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20348">https://arxiv.org/abs/2510.20348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20348">https://arxiv.org/pdf/2510.20348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20348]] AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models(https://arxiv.org/abs/2510.20348)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present in this paper a novel post-training quantization (PTQ) method, dubbed AccuQuant, for diffusion models. We show analytically and empirically that quantization errors for diffusion models are accumulated over denoising steps in a sampling process. To alleviate the error accumulation problem, AccuQuant minimizes the discrepancies between outputs of a full-precision diffusion model and its quantized version within a couple of denoising steps. That is, it simulates multiple denoising steps of a diffusion sampling process explicitly for quantization, accounting the accumulated errors over multiple denoising steps, which is in contrast to previous approaches to imitating a training process of diffusion models, namely, minimizing the discrepancies independently for each step. We also present an efficient implementation technique for AccuQuant, together with a novel objective, which reduces a memory complexity significantly from $\mathcal{O}(n)$ to $\mathcal{O}(1)$, where $n$ is the number of denoising steps. We demonstrate the efficacy and efficiency of AccuQuant across various tasks and diffusion models on standard benchmarks.</li>
</ul>

<h3>Title: Synthetic Data for Robust Runway Detection</h3>
<ul>
<li><strong>Authors: </strong>Estelle Chigot, Dennis G. Wilson, Meriem Ghrib, Fabrice Jimenez, Thomas Oberlin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20349">https://arxiv.org/abs/2510.20349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20349">https://arxiv.org/pdf/2510.20349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20349]] Synthetic Data for Robust Runway Detection(https://arxiv.org/abs/2510.20349)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep vision models are now mature enough to be integrated in industrial and possibly critical applications such as autonomous navigation. Yet, data collection and labeling to train such models requires too much efforts and costs for a single company or product. This drawback is more significant in critical applications, where training data must include all possible conditions including rare scenarios. In this perspective, generating synthetic images is an appealing solution, since it allows a cheap yet reliable covering of all the conditions and environments, if the impact of the synthetic-to-real distribution shift is mitigated. In this article, we consider the case of runway detection that is a critical part in autonomous landing systems developed by aircraft manufacturers. We propose an image generation approach based on a commercial flight simulator that complements a few annotated real images. By controlling the image generation and the integration of real and synthetic data, we show that standard object detection models can achieve accurate prediction. We also evaluate their robustness with respect to adverse conditions, in our case nighttime images, that were not represented in the real data, and show the interest of using a customized domain adaptation strategy.</li>
</ul>

<h3>Title: Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Matteo Silvestri, Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20351">https://arxiv.org/abs/2510.20351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20351">https://arxiv.org/pdf/2510.20351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20351]] Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models(https://arxiv.org/abs/2510.20351)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly evaluated on their ability to reason over structured data, yet such assessments often overlook a crucial confound: dataset contamination. In this work, we investigate whether LLMs exhibit prior knowledge of widely used tabular benchmarks such as Adult Income, Titanic, and others. Through a series of controlled probing experiments, we reveal that contamination effects emerge exclusively for datasets containing strong semantic cues-for instance, meaningful column names or interpretable value categories. In contrast, when such cues are removed or randomized, performance sharply declines to near-random levels. These findings suggest that LLMs' apparent competence on tabular reasoning tasks may, in part, reflect memorization of publicly available datasets rather than genuine generalization. We discuss implications for evaluation protocols and propose strategies to disentangle semantic leakage from authentic reasoning ability in future LLM assessments.</li>
</ul>

<h3>Title: FreeChunker: A Cross-Granularity Chunking Framework</h3>
<ul>
<li><strong>Authors: </strong>Wenxuan Zhang, Yuan-Hao Jiang, Yonghe Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20356">https://arxiv.org/abs/2510.20356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20356">https://arxiv.org/pdf/2510.20356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20356]] FreeChunker: A Cross-Granularity Chunking Framework(https://arxiv.org/abs/2510.20356)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Chunking strategies significantly impact the effectiveness of Retrieval-Augmented Generation (RAG) systems. Existing methods operate within fixed-granularity paradigms that rely on static boundary identification, limiting their adaptability to diverse query requirements. This paper presents FreeChunker, a Cross-Granularity Encoding Framework that fundamentally transforms the traditional chunking paradigm: the framework treats sentences as atomic units and shifts from static chunk segmentation to flexible retrieval supporting arbitrary sentence combinations. This paradigm shift not only significantly reduces the computational overhead required for semantic boundary detection but also enhances adaptability to complex queries. Experimental evaluation on LongBench V2 demonstrates that FreeChunker achieves superior retrieval performance compared to traditional chunking methods, while significantly outperforming existing approaches in computational efficiency.</li>
</ul>

<h3>Title: NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by Leveraging Permutation Symmetry</h3>
<ul>
<li><strong>Authors: </strong>Daniel Gilkarov, Ran Dubin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20367">https://arxiv.org/abs/2510.20367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20367">https://arxiv.org/pdf/2510.20367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20367]] NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by Leveraging Permutation Symmetry(https://arxiv.org/abs/2510.20367)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Pretrained deep learning model sharing holds tremendous value for researchers and enterprises alike. It allows them to apply deep learning by fine-tuning models at a fraction of the cost of training a brand-new model. However, model sharing exposes end-users to cyber threats that leverage the models for malicious purposes. Attackers can use model sharing by hiding self-executing malware inside neural network parameters and then distributing them for unsuspecting users to unknowingly directly execute them, or indirectly as a dependency in another software. In this work, we propose NeuPerm, a simple yet effec- tive way of disrupting such malware by leveraging the theoretical property of neural network permutation symmetry. Our method has little to no effect on model performance at all, and we empirically show it successfully disrupts state-of-the-art attacks that were only previously addressed using quantization, a highly complex process. NeuPerm is shown to work on LLMs, a feat that no other previous similar works have achieved. The source code is available at this https URL.</li>
</ul>

<h3>Title: Ask a Strong LLM Judge when Your Reward Model is Uncertain</h3>
<ul>
<li><strong>Authors: </strong>Zhenghao Xu, Qin Lu, Qingru Zhang, Liang Qiu, Ilgee Hong, Changlong Yu, Wenlin Yao, Yao Liu, Haoming Jiang, Lihong Li, Hyokun Yun, Tuo Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20369">https://arxiv.org/abs/2510.20369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20369">https://arxiv.org/pdf/2510.20369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20369]] Ask a Strong LLM Judge when Your Reward Model is Uncertain(https://arxiv.org/abs/2510.20369)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reward model (RM) plays a pivotal role in reinforcement learning with human feedback (RLHF) for aligning large language models (LLMs). However, classical RMs trained on human preferences are vulnerable to reward hacking and generalize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM judges equipped with reasoning capabilities demonstrate superior generalization, even without additional training, but incur significantly higher inference costs, limiting their applicability in online RLHF. In this work, we propose an uncertainty-based routing framework that efficiently complements a fast RM with a strong but costly LLM judge. Our approach formulates advantage estimation in policy gradient (PG) methods as pairwise preference classification, enabling principled uncertainty quantification to guide routing. Uncertain pairs are forwarded to the LLM judge, while confident ones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our uncertainty-based routing strategy significantly outperforms random judge calling at the same cost, and downstream alignment results showcase its effectiveness in improving online RLHF.</li>
</ul>

<h3>Title: The Impact of Negated Text on Hallucination with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jaehyung Seo, Hyeonseok Moon, Heuiseok Lim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20375">https://arxiv.org/abs/2510.20375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20375">https://arxiv.org/pdf/2510.20375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20375]] The Impact of Negated Text on Hallucination with Large Language Models(https://arxiv.org/abs/2510.20375)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies on hallucination in large language models (LLMs) have been actively progressing in natural language processing. However, the impact of negated text on hallucination with LLMs remains largely unexplored. In this paper, we set three important yet unanswered research questions and aim to address them. To derive the answers, we investigate whether LLMs can recognize contextual shifts caused by negation and still reliably distinguish hallucinations comparable to affirmative cases. We also design the NegHalu dataset by reconstructing existing hallucination detection datasets with negated expressions. Our experiments demonstrate that LLMs struggle to detect hallucinations in negated text effectively, often producing logically inconsistent or unfaithful judgments. Moreover, we trace the internal state of LLMs as they process negated inputs at the token level and reveal the challenges of mitigating their unintended effects.</li>
</ul>

<h3>Title: Hierarchical Time Series Forecasting with Robust Reconciliation</h3>
<ul>
<li><strong>Authors: </strong>Shuhei Aikawa, Aru Suzuki, Kei Yoshitake, Kanata Teshigawara, Akira Iwabuchi, Ken Kobayashi, Kazuhide Nakata</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20383">https://arxiv.org/abs/2510.20383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20383">https://arxiv.org/pdf/2510.20383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20383]] Hierarchical Time Series Forecasting with Robust Reconciliation(https://arxiv.org/abs/2510.20383)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper focuses on forecasting hierarchical time-series data, where each higher-level observation equals the sum of its corresponding lower-level time series. In such contexts, the forecast values should be coherent, meaning that the forecast value of each parent series exactly matches the sum of the forecast values of its child series. Existing hierarchical forecasting methods typically generate base forecasts independently for each series and then apply a reconciliation procedure to adjust them so that the resulting forecast values are coherent across the hierarchy. These methods generally derive an optimal reconciliation, using a covariance matrix of the forecast error. In practice, however, the true covariance matrix is unknown and has to be estimated from finite samples in advance. This gap between the true and estimated covariance matrix may degrade forecast performance. To address this issue, we propose a robust optimization framework for hierarchical reconciliation that accounts for uncertainty in the estimated covariance matrix. We first introduce an uncertainty set for the estimated covariance matrix and formulate a reconciliation problem that minimizes the worst-case expected squared error over this uncertainty set. We show that our problem can be cast as a semidefinite optimization problem. Numerical experiments demonstrate that the proposed robust reconciliation method achieved better forecast performance than existing hierarchical forecasting methods, which indicates the effectiveness of integrating uncertainty into the reconciliation process.</li>
</ul>

<h3>Title: Positional Encoding Field</h3>
<ul>
<li><strong>Authors: </strong>Yunpeng Bai, Haoxiang Li, Qixing Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20385">https://arxiv.org/abs/2510.20385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20385">https://arxiv.org/pdf/2510.20385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20385]] Positional Encoding Field(https://arxiv.org/abs/2510.20385)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiTs) have emerged as the dominant architecture for visual generation, powering state-of-the-art image and video models. By representing images as patch tokens with positional encodings (PEs), DiTs combine Transformer scalability with spatial and temporal inductive biases. In this work, we revisit how DiTs organize visual content and discover that patch tokens exhibit a surprising degree of independence: even when PEs are perturbed, DiTs still produce globally coherent outputs, indicating that spatial coherence is primarily governed by PEs. Motivated by this finding, we introduce the Positional Encoding Field (PE-Field), which extends positional encodings from the 2D plane to a structured 3D field. PE-Field incorporates depth-aware encodings for volumetric reasoning and hierarchical encodings for fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D space. Our PE-Field-augmented DiT achieves state-of-the-art performance on single-image novel view synthesis and generalizes to controllable spatial image editing.</li>
</ul>

<h3>Title: NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew</h3>
<ul>
<li><strong>Authors: </strong>Shaltiel Shmidman, Avi Shmidman, Moshe Koppel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20386">https://arxiv.org/abs/2510.20386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20386">https://arxiv.org/pdf/2510.20386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20386]] NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew(https://arxiv.org/abs/2510.20386)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Since their initial release, BERT models have demonstrated exceptional performance on a variety of tasks, despite their relatively small size (BERT-base has ~100M parameters). Nevertheless, the architectural choices used in these models are outdated compared to newer transformer-based models such as Llama3 and Qwen3. In recent months, several architectures have been proposed to close this gap. ModernBERT and NeoBERT both show strong improvements on English benchmarks and significantly extend the supported context window. Following their successes, we introduce NeoDictaBERT and NeoDictaBERT-bilingual: BERT-style models trained using the same architecture as NeoBERT, with a dedicated focus on Hebrew texts. These models outperform existing ones on almost all Hebrew benchmarks and provide a strong foundation for downstream tasks. Notably, the NeoDictaBERT-bilingual model shows strong results on retrieval tasks, outperforming other multilingual models of similar size. In this paper, we describe the training process and report results across various benchmarks. We release the models to the community as part of our goal to advance research and development in Hebrew NLP.</li>
</ul>

<h3>Title: Relative-Based Scaling Law for Neural Language Models</h3>
<ul>
<li><strong>Authors: </strong>Baoqing Yue, Jinyuan Zhou, Zixi Wei, Jingtao Zhan, Qingyao Ai, Yiqun Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20387">https://arxiv.org/abs/2510.20387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20387">https://arxiv.org/pdf/2510.20387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20387]] Relative-Based Scaling Law for Neural Language Models(https://arxiv.org/abs/2510.20387)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Scaling laws aim to accurately predict model performance across different scales. Existing scaling-law studies almost exclusively rely on cross-entropy as the evaluation metric. However, cross-entropy provides only a partial view of performance: it measures the absolute probability assigned to the correct token, but ignores the relative ordering between correct and incorrect tokens. Yet, relative ordering is crucial for language models, such as in greedy-sampling scenario. To address this limitation, we investigate scaling from the perspective of relative ordering. We first propose the Relative-Based Probability (RBP) metric, which quantifies the probability that the correct token is ranked among the top predictions. Building on this metric, we establish the Relative-Based Scaling Law, which characterizes how RBP improves with increasing model size. Through extensive experiments on four datasets and four model families spanning five orders of magnitude, we demonstrate the robustness and accuracy of this law. Finally, we illustrate the broad application of this law with two examples, namely providing a deeper explanation of emergence phenomena and facilitating finding fundamental theories of scaling laws. In summary, the Relative-Based Scaling Law complements the cross-entropy perspective and contributes to a more complete understanding of scaling large language models. Thus, it offers valuable insights for both practical development and theoretical exploration.</li>
</ul>

<h3>Title: Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control</h3>
<ul>
<li><strong>Authors: </strong>Tom Maus, Asma Atamna, Tobias Glasmachers</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20408">https://arxiv.org/abs/2510.20408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20408">https://arxiv.org/pdf/2510.20408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20408]] Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control(https://arxiv.org/abs/2510.20408)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Autonomous control of multi-stage industrial processes requires both local specialization and global coordination. Reinforcement learning (RL) offers a promising approach, but its industrial adoption remains limited due to challenges such as reward design, modularity, and action space management. Many academic benchmarks differ markedly from industrial control problems, limiting their transferability to real-world applications. This study introduces an enhanced industry-inspired benchmark environment that combines tasks from two existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling scenario with sorting and pressing operations. We evaluate two control strategies: a modular architecture with specialized agents and a monolithic agent governing the full system, while also analyzing the impact of action masking. Our experiments show that without action masking, agents struggle to learn effective policies, with the modular architecture performing better. When action masking is applied, both architectures improve substantially, and the performance gap narrows considerably. These results highlight the decisive role of action space constraints and suggest that the advantages of specialization diminish as action complexity is reduced. The proposed benchmark thus provides a valuable testbed for exploring practical and robust multi-agent RL solutions in industrial automation, while contributing to the ongoing debate on centralization versus specialization.</li>
</ul>

<h3>Title: MAC Aggregation over Lossy Channels in DTLS 1.3</h3>
<ul>
<li><strong>Authors: </strong>Eric Wagner, David Heye, Jan Bauer, Klaus Wehrle, Martin Serror</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20419">https://arxiv.org/abs/2510.20419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20419">https://arxiv.org/pdf/2510.20419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20419]] MAC Aggregation over Lossy Channels in DTLS 1.3(https://arxiv.org/abs/2510.20419)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Aggregating Message Authentication Codes (MACs) promises to save valuable bandwidth in resource-constrained environments. The idea is simple: Instead of appending an authentication tag to each message in a communication stream, the integrity protection of multiple messages is aggregated into a single tag. Recent studies postulate, e.g., based on simulations, that these benefits also spread to wireless, and thus lossy, scenarios despite each lost packet typically resulting in the loss of integrity protection information for multiple messages. In this paper, we investigate these claims in a real deployment. Therefore, we first design a MAC aggregation extension for the Datagram Transport Layer Security (DTLS) 1.3 protocol. Afterward, we extensively evaluate the performance of MAC aggregation on a complete communication protocol stack on embedded hardware. We find that MAC aggregation can indeed increase goodput by up to 50% and save up to 17% of energy expenditure for the transmission of short messages, even in lossy channels.</li>
</ul>

<h3>Title: An Empirical Study of Sample Selection Strategies for Large Language Model Repair</h3>
<ul>
<li><strong>Authors: </strong>Xuran Li, Jingyi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20428">https://arxiv.org/abs/2510.20428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20428">https://arxiv.org/pdf/2510.20428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20428]] An Empirical Study of Sample Selection Strategies for Large Language Model Repair(https://arxiv.org/abs/2510.20428)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in real-world systems, yet they can produce toxic or biased outputs that undermine safety and trust. Post-hoc model repair provides a practical remedy, but the high cost of parameter updates motivates selective use of repair data. Despite extensive prior work on data selection for model training, it remains unclear which sampling criteria are most effective and efficient when applied specifically to behavioral repair of large generative models. Our study presents a systematic analysis of sample prioritization strategies for LLM repair. We evaluate five representative selection methods, including random sampling, K-Center, gradient-norm-based selection(GraNd), stratified coverage (CCS), and a Semantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair effectiveness and trade-offs are assessed through toxicity reduction, perplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair Proximity Score (RPS), the Overall Performance Score (OPS), and the Repair Efficiency Score (RES). Experimental results show that SAPS achieves the best balance between detoxification, utility preservation, and efficiency, delivering comparable or superior repair outcomes with substantially less data. Random sampling remains effective for large or robust models, while high-overhead methods such as CCS and GraNd provide limited benefit. The optimal data proportion depends on model scale and repair method, indicating that sample selection should be regarded as a tunable component of repair pipelines. Overall, these findings establish selection-based repair as an efficient and scalable paradigm for maintaining LLM reliability.</li>
</ul>

<h3>Title: Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment</h3>
<ul>
<li><strong>Authors: </strong>Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20438">https://arxiv.org/abs/2510.20438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20438">https://arxiv.org/pdf/2510.20438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20438]] Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment(https://arxiv.org/abs/2510.20438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents the FuzzyDistillViT-MobileNet model, a novel approach for lung cancer (LC) classification, leveraging dynamic fuzzy logic-driven knowledge distillation (KD) to address uncertainty and complexity in disease diagnosis. Unlike traditional models that rely on static KD with fixed weights, our method dynamically adjusts the distillation weight using fuzzy logic, enabling the student model to focus on high-confidence regions while reducing attention to ambiguous areas. This dynamic adjustment improves the model ability to handle varying uncertainty levels across different regions of LC images. We employ the Vision Transformer (ViT-B32) as the instructor model, which effectively transfers knowledge to the student model, MobileNet, enhancing the student generalization capabilities. The training process is further optimized using a dynamic wait adjustment mechanism that adapts the training procedure for improved convergence and performance. To enhance image quality, we introduce pixel-level image fusion improvement techniques such as Gamma correction and Histogram Equalization. The processed images (Pix1 and Pix2) are fused using a wavelet-based fusion method to improve image resolution and feature preservation. This fusion method uses the wavedec2 function to standardize images to a 224x224 resolution, decompose them into multi-scale frequency components, and recursively average coefficients at each level for better feature representation. To address computational efficiency, Genetic Algorithm (GA) is used to select the most suitable pre-trained student model from a pool of 12 candidates, balancing model performance with computational cost. The model is evaluated on two datasets, including LC25000 histopathological images (99.16% accuracy) and IQOTH/NCCD CT-scan images (99.54% accuracy), demonstrating robustness across different imaging domains.</li>
</ul>

<h3>Title: MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xuan Lin, Aocheng Ding, Tengfei Ma, Hua Liang, Zhe Quan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20448">https://arxiv.org/abs/2510.20448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20448">https://arxiv.org/pdf/2510.20448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20448]] MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction(https://arxiv.org/abs/2510.20448)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Drug combinations offer therapeutic benefits but also carry the risk of adverse drug-drug interactions (DDIs), especially under complex molecular structures. Accurate DDI event prediction requires capturing fine-grained inter-drug relationships, which are critical for modeling metabolic mechanisms such as enzyme-mediated competition. However, existing approaches typically rely on isolated drug representations and fail to explicitly model atom-level cross-molecular interactions, limiting their effectiveness across diverse molecular complexities and DDI type distributions. To address these limitations, we propose MolBridge, a novel atom-level joint graph refinement framework for robust DDI event prediction. MolBridge constructs a joint graph that integrates atomic structures of drug pairs, enabling direct modeling of inter-drug associations. A central challenge in such joint graph settings is the potential loss of information caused by over-smoothing when modeling long-range atomic dependencies. To overcome this, we introduce a structure consistency module that iteratively refines node features while preserving the global structural context. This joint design allows MolBridge to effectively learn both local and global interaction outperforms state-of-the-art baselines, achieving superior performance across long-tail and inductive scenarios. patterns, yielding robust representations across both frequent and rare DDI types. Extensive experiments on two benchmark datasets show that MolBridge consistently. These results demonstrate the advantages of fine-grained graph refinement in improving the accuracy, robustness, and mechanistic interpretability of DDI event this http URL work contributes to Web Mining and Content Analysis by developing graph-based methods for mining and analyzing drug-drug interaction networks.</li>
</ul>

<h3>Title: LM-mixup: Text Data Augmentation via Language Model based Mixup</h3>
<ul>
<li><strong>Authors: </strong>Zhijie Deng, Zhouan Shen, Ling Li, Yao Zhou, Zhaowei Zhu, Yanji He, Wei Wang, Jiaheng Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20449">https://arxiv.org/abs/2510.20449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20449">https://arxiv.org/pdf/2510.20449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20449]] LM-mixup: Text Data Augmentation via Language Model based Mixup(https://arxiv.org/abs/2510.20449)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is crucial for aligning Large Language Models (LLMs), yet the quality of instruction-following data varies significantly. While high-quality data is paramount, it is often scarce; conversely, abundant low-quality data is frequently discarded, leading to substantial information loss. Existing data augmentation methods struggle to augment this low-quality data effectively, and the evaluation of such techniques remains poorly defined. To address this, we formally define the task of Instruction Distillation: distilling multiple low-quality and redundant inputs into high-quality and coherent instruction-output pairs. Specifically, we introduce a comprehensive data construction pipeline to create MIXTURE, a 144K-sample dataset pairing low-quality or semantically redundant imperfect instruction clusters with their high-quality distillations. We then introduce LM-Mixup, by first performing supervised fine-tuning on MIXTURE and then optimizing it with reinforcement learning. This process uses three complementary reward signals: quality, semantic alignment, and format compliance, via Group Relative Policy Optimization (GRPO). We demonstrate that LM-Mixup effectively augments imperfect datasets: fine-tuning LLMs on its distilled data, which accounts for only about 3% of the entire dataset, not only surpasses full-dataset training but also competes with state-of-the-art high-quality data selection methods across multiple benchmarks. Our work establishes that low-quality data is a valuable resource when properly distilled and augmented with LM-Mixup, significantly enhancing the efficiency and performance of instruction-tuned LLMs.</li>
</ul>

<h3>Title: Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Christian Hobelsberger, Theresa Winner, Andreas Nawroth, Oliver Mitevski, Anna-Carolina Haensch</a></li>
<li><strong>Subjects: </strong>cs.CL, stat.AP, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20460">https://arxiv.org/abs/2510.20460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20460">https://arxiv.org/pdf/2510.20460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20460]] Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models(https://arxiv.org/abs/2510.20460)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) produce outputs with varying levels of uncertainty, and, just as often, varying levels of correctness; making their practical reliability far from guaranteed. To quantify this uncertainty, we systematically evaluate four approaches for confidence estimation in LLM outputs: VCE, MSP, Sample Consistency, and CoCoA (Vashurin et al., 2025). For the evaluation of the approaches, we conduct experiments on four question-answering tasks using a state-of-the-art open-source LLM. Our results show that each uncertainty metric captures a different facet of model confidence and that the hybrid CoCoA approach yields the best reliability overall, improving both calibration and discrimination of correct answers. We discuss the trade-offs of each method and provide recommendations for selecting uncertainty measures in LLM applications.</li>
</ul>

<h3>Title: Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models</h3>
<ul>
<li><strong>Authors: </strong>Tomáš Souček, Sylvestre-Alvise Rebuffi, Pierre Fernandez, Nikola Jovanović, Hady Elsahar, Valeriu Lacatusu, Tuan Tran, Alexandre Mourachko</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20468">https://arxiv.org/abs/2510.20468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20468">https://arxiv.org/pdf/2510.20468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20468]] Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models(https://arxiv.org/abs/2510.20468)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, watermark, generative</a></li>
<li><strong>Abstract: </strong>Recent years have seen a surge in interest in digital content watermarking techniques, driven by the proliferation of generative models and increased legal pressure. With an ever-growing percentage of AI-generated content available online, watermarking plays an increasingly important role in ensuring content authenticity and attribution at scale. There have been many works assessing the robustness of watermarking to removal attacks, yet, watermark forging, the scenario when a watermark is stolen from genuine content and applied to malicious content, remains underexplored. In this work, we investigate watermark forging in the context of widely used post-hoc image watermarking. Our contributions are as follows. First, we introduce a preference model to assess whether an image is watermarked. The model is trained using a ranking loss on purely procedurally generated images without any need for real watermarks. Second, we demonstrate the model's capability to remove and forge watermarks by optimizing the input image through backpropagation. This technique requires only a single watermarked image and works without knowledge of the watermarking model, making our attack much simpler and more practical than attacks introduced in related work. Third, we evaluate our proposed method on a variety of post-hoc image watermarking models, demonstrating that our approach can effectively forge watermarks, questioning the security of current watermarking approaches. Our code and further resources are publicly available.</li>
</ul>

<h3>Title: Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence</h3>
<ul>
<li><strong>Authors: </strong>Kun Ouyang, Yuanxin Liu, Linli Yao, Yishuo Cai, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20470">https://arxiv.org/abs/2510.20470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20470">https://arxiv.org/pdf/2510.20470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20470]] Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence(https://arxiv.org/abs/2510.20470)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Video reasoning, which requires multi-step deduction across frames, remains a major challenge for multimodal large language models (MLLMs). While reinforcement learning (RL)-based methods enhance reasoning capabilities, they often rely on text-only chains that yield ungrounded or hallucinated conclusions. Conversely, frame-retrieval approaches introduce visual grounding but still struggle with inaccurate evidence localization. To address these challenges, we present Conan, a framework for evidence-grounded multi-step video reasoning. Conan identifies contextual and evidence frames, reasons over cross-frame clues, and adaptively decides when to conclude or explore further. To achieve this, we (1) construct Conan-91K, a large-scale dataset of automatically generated reasoning traces that includes frame identification, evidence reasoning, and action decision, and (2) design a multi-stage progressive cold-start strategy combined with an Identification-Reasoning-Action (AIR) RLVR training framework to jointly enhance multi-step visual reasoning. Extensive experiments on six multi-step reasoning benchmarks demonstrate that Conan surpasses the baseline Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving state-of-the-art performance. Furthermore, Conan generalizes effectively to long-video understanding tasks, validating its strong scalability and robustness.</li>
</ul>

<h3>Title: RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging</h3>
<ul>
<li><strong>Authors: </strong>Bowen Wang, Haiyuan Wan, Liwen Shi, Chen Yang, Peng He, Yue Ma, Haochen Han, Wenhao Li, Tiao Tan, Yongjian Li, Fangming Liu, Yifan Gong, Sheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20479">https://arxiv.org/abs/2510.20479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20479">https://arxiv.org/pdf/2510.20479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20479]] RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging(https://arxiv.org/abs/2510.20479)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free, large language model</a></li>
<li><strong>Abstract: </strong>We unveil that internal representations in large language models (LLMs) serve as reliable proxies of learned knowledge, and propose RECALL, a novel representation-aware model merging framework for continual learning without access to historical data. RECALL computes inter-model similarity from layer-wise hidden representations over clustered typical samples, and performs adaptive, hierarchical parameter fusion to align knowledge across models. This design enables the preservation of domain-general features in shallow layers while allowing task-specific adaptation in deeper layers. Unlike prior methods that require task labels or incur performance trade-offs, RECALL achieves seamless multi-domain integration and strong resistance to catastrophic forgetting. Extensive experiments across five NLP tasks and multiple continual learning scenarios show that RECALL outperforms baselines in both knowledge retention and generalization, providing a scalable and data-free solution for evolving LLMs.</li>
</ul>

<h3>Title: Reliable and Reproducible Demographic Inference for Fairness in Face Analysis</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Fournier-Montgieux, Hervé Le Borgne, Adrian Popescu, Bertrand Luvison</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20482">https://arxiv.org/abs/2510.20482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20482">https://arxiv.org/pdf/2510.20482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20482]] Reliable and Reproducible Demographic Inference for Fairness in Face Analysis(https://arxiv.org/abs/2510.20482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, segmentation</a></li>
<li><strong>Abstract: </strong>Fairness evaluation in face analysis systems (FAS) typically depends on automatic demographic attribute inference (DAI), which itself relies on predefined demographic segmentation. However, the validity of fairness auditing hinges on the reliability of the DAI process. We begin by providing a theoretical motivation for this dependency, showing that improved DAI reliability leads to less biased and lower-variance estimates of FAS fairness. To address this, we propose a fully reproducible DAI pipeline that replaces conventional end-to-end training with a modular transfer learning approach. Our design integrates pretrained face recognition encoders with non-linear classification heads. We audit this pipeline across three dimensions: accuracy, fairness, and a newly introduced notion of robustness, defined via intra-identity consistency. The proposed robustness metric is applicable to any demographic segmentation scheme. We benchmark the pipeline on gender and ethnicity inference across multiple datasets and training setups. Our results show that the proposed method outperforms strong baselines, particularly on ethnicity, which is the more challenging attribute. To promote transparency and reproducibility, we will publicly release the training dataset metadata, full codebase, pretrained models, and evaluation toolkit. This work contributes a reliable foundation for demographic inference in fairness auditing.</li>
</ul>

<h3>Title: Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Fangjian Zhang, Xiaoyong Zhuge, Wenlan Wang, Haixia Xiao, Yuying Zhu, Siyang Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.ao-ph, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20486">https://arxiv.org/abs/2510.20486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20486">https://arxiv.org/pdf/2510.20486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20486]] Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval(https://arxiv.org/abs/2510.20486)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Artificial intelligence has advanced quantitative remote sensing, yet its effectiveness is constrained by imbalanced label distribution. This imbalance leads conventionally trained models to favor common samples, which in turn degrades retrieval performance for rare ones. Rainfall retrieval exemplifies this issue, with performance particularly compromised for heavy rain. This study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework. Following a divide-and-conquer strategy, imbalance in the rain distribution is decomposed into two components: zero inflation, defined by the predominance of non-rain samples; and long tail, defined by the disproportionate abundance of light-rain samples relative to heavy-rain samples. A hurdle model is adopted to handle the zero inflation, while IMDL is proposed to address the long tail by transforming the learning object into an unbiased ideal inverse model. Comprehensive evaluation via statistical metrics and case studies investigating rainy weather in eastern China confirms Hurdle-IMDL's superiority over conventional, cost-sensitive, generative, and multi-task learning methods. Its key advancements include effective mitigation of systematic underestimation and a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a generalizable approach for addressing imbalance in distributions of environmental variables, enabling enhanced retrieval of rare yet high-impact events.</li>
</ul>

<h3>Title: Steering Evaluation-Aware Language Models To Act Like They Are Deployed</h3>
<ul>
<li><strong>Authors: </strong>Tim Tian Hua, Andrew Qin, Samuel Marks, Neel Nanda</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20487">https://arxiv.org/abs/2510.20487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20487">https://arxiv.org/pdf/2510.20487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20487]] Steering Evaluation-Aware Language Models To Act Like They Are Deployed(https://arxiv.org/abs/2510.20487)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can sometimes detect when they are being evaluated and adjust their behavior to appear more aligned, compromising the reliability of safety evaluations. In this paper, we show that adding a steering vector to an LLM's activations can suppress evaluation-awareness and make the model act like it is deployed during evaluation. To study our steering technique, we train an LLM to exhibit evaluation-aware behavior using a two-step training process designed to mimic how this behavior could emerge naturally. First, we perform continued pretraining on documents with factual descriptions of the model (1) using Python type hints during evaluation but not during deployment and (2) recognizing that the presence of a certain evaluation cue always means that it is being tested. Then, we train the model with expert iteration to use Python type hints in evaluation settings. The resulting model is evaluation-aware: it writes type hints in evaluation contexts more than deployment contexts. However, this gap can only be observed by removing the evaluation cue. We find that activation steering can suppress evaluation awareness and make the model act like it is deployed even when the cue is present. Importantly, we constructed our steering vector using the original model before our additional training. Our results suggest that AI evaluators could improve the reliability of safety evaluations by steering models to act like they are deployed.</li>
</ul>

<h3>Title: On the cybersecurity of LoRaWAN-based system: a Smart-Lighting case study</h3>
<ul>
<li><strong>Authors: </strong>Florian Hofer, Barbara Russo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20494">https://arxiv.org/abs/2510.20494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20494">https://arxiv.org/pdf/2510.20494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20494]] On the cybersecurity of LoRaWAN-based system: a Smart-Lighting case study(https://arxiv.org/abs/2510.20494)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Cyber-physical systems and the Internet of Things (IoT) are key technologies in the Industry 4.0 vision. They incorporate sensors and actuators to interact with the physical environment. However, when creating and interconnecting components to form a heterogeneous smart systems architecture, these face challenges in cybersecurity. This paper presents an experimental investigation of architectural configurations for a LoRaWAN-based Smart-Lighting project, aimed at verifying and improving the system's robustness against attacks. We assess the system's robustness in a series of iterative experiments conducted both in-vitro and on-site. The results show that most attacks on a LoRaWAN network are unsuccessful, also highlighting unresolved issues with the installed products. The most successful attacks are high-power jamming attacks within a few meters of the target, which, in the case of gateways, can be mitigated through gateway redundancy.</li>
</ul>

<h3>Title: Robust Preference Alignment via Directional Neighborhood Consensus</h3>
<ul>
<li><strong>Authors: </strong>Ruochen Mao, Yuling Shi, Xiaodong Gu, Jiaheng Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20498">https://arxiv.org/abs/2510.20498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20498">https://arxiv.org/pdf/2510.20498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20498]] Robust Preference Alignment via Directional Neighborhood Consensus(https://arxiv.org/abs/2510.20498)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models with human preferences is critical for creating reliable and controllable AI systems. A human preference can be visualized as a high-dimensional vector where different directions represent trade-offs between desired attributes (e.g., helpfulness vs. verbosity). Yet, because the training data often reflects dominant, average preferences, LLMs tend to perform well on common requests but fall short in specific, individual needs. This mismatch creates a preference coverage gap. Existing methods often address this through costly retraining, which may not be generalized to the full spectrum of diverse preferences. This brittleness means that when a user's request reflects a nuanced preference deviating from the training data's central tendency, model performance can degrade unpredictably. To address this challenge, we introduce Robust Preference Selection (RPS), a post-hoc, training-free method by leveraging directional neighborhood consensus. Instead of forcing a model to generate a response from a single, highly specific preference, RPS samples multiple responses from a local neighborhood of related preferences to create a superior candidate pool. It then selects the response that best aligns with the user's original intent. We provide a theoretical framework showing our neighborhood generation strategy is provably superior to a strong baseline that also samples multiple candidates. Comprehensive experiments across three distinct alignment paradigms (DPA, DPO, and SFT) demonstrate that RPS consistently improves robustness against this baseline, achieving win rates of up to 69% on challenging preferences from under-represented regions of the space without any model retraining. Our work presents a practical, theoretically-grounded solution for enhancing the reliability of preference-aligned models.</li>
</ul>

<h3>Title: Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset</h3>
<ul>
<li><strong>Authors: </strong>Paul Lerner, François Yvon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20508">https://arxiv.org/abs/2510.20508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20508">https://arxiv.org/pdf/2510.20508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20508]] Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset(https://arxiv.org/abs/2510.20508)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The political biases of Large Language Models (LLMs) are usually assessed by simulating their answers to English surveys. In this work, we propose an alternative framing of political biases, relying on principles of fairness in multilingual translation. We systematically compare the translation quality of speeches in the European Parliament (EP), observing systematic differences with majority parties from left, center, and right being better translated than outsider parties. This study is made possible by a new, 21-way multiparallel version of EuroParl, the parliamentary proceedings of the EP, which includes the political affiliations of each speaker. The dataset consists of 1.5M sentences for a total of 40M words and 249M characters. It covers three years, 1000+ speakers, 7 countries, 12 EU parties, 25 EU committees, and hundreds of national parties.</li>
</ul>

<h3>Title: EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization</h3>
<ul>
<li><strong>Authors: </strong>Yixiong Yang, Tao Wu, Senmao Li, Shiqi Yang, Yaxing Wang, Joost van de Weijer, Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20512">https://arxiv.org/abs/2510.20512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20512">https://arxiv.org/pdf/2510.20512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20512]] EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization(https://arxiv.org/abs/2510.20512)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in accelerating text-to-image (T2I) diffusion models have enabled the synthesis of high-fidelity images even in a single step. However, personalizing these models to incorporate novel concepts remains a challenge due to the limited capacity of one-step models to capture new concept distributions effectively. We propose a bidirectional concept distillation framework, EchoDistill, to enable one-step diffusion personalization (1-SDP). Our approach involves an end-to-end training process where a multi-step diffusion model (teacher) and a one-step diffusion model (student) are trained simultaneously. The concept is first distilled from the teacher model to the student, and then echoed back from the student to the teacher. During the EchoDistill, we share the text encoder between the two models to ensure consistent semantic understanding. Following this, the student model is optimized with adversarial losses to align with the real image distribution and with alignment losses to maintain consistency with the teacher's output. Furthermore, we introduce the bidirectional echoing refinement strategy, wherein the student model leverages its faster generation capability to feedback to the teacher model. This bidirectional concept distillation mechanism not only enhances the student ability to personalize novel concepts but also improves the generative quality of the teacher model. Our experiments demonstrate that this collaborative framework significantly outperforms existing personalization methods over the 1-SDP setup, establishing a novel paradigm for rapid and effective personalization in T2I diffusion models.</li>
</ul>

<h3>Title: Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis</h3>
<ul>
<li><strong>Authors: </strong>Lixiong Qin, Yang Zhang, Mei Wang, Jiani Hu, Weihong Deng, Weiran Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20531">https://arxiv.org/abs/2510.20531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20531">https://arxiv.org/pdf/2510.20531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20531]] Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis(https://arxiv.org/abs/2510.20531)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The advancement of Multimodal Large Language Models (MLLMs) has bridged the gap between vision and language tasks, enabling the implementation of Explainable DeepFake Analysis (XDFA). However, current methods suffer from a lack of fine-grained awareness: the description of artifacts in data annotation is unreliable and coarse-grained, and the models fail to support the output of connections between textual forgery explanations and the visual evidence of artifacts, as well as the input of queries for arbitrary facial regions. As a result, their responses are not sufficiently grounded in Face Visual Context (Facext). To address this limitation, we propose the Fake-in-Facext (FiFa) framework, with contributions focusing on data annotation and model construction. We first define a Facial Image Concept Tree (FICT) to divide facial images into fine-grained regional concepts, thereby obtaining a more reliable data annotation pipeline, FiFa-Annotator, for forgery explanation. Based on this dedicated data annotation, we introduce a novel Artifact-Grounding Explanation (AGE) task, which generates textual forgery explanations interleaved with segmentation masks of manipulated artifacts. We propose a unified multi-task learning architecture, FiFa-MLLM, to simultaneously support abundant multimodal inputs and outputs for fine-grained Explainable DeepFake Analysis. With multiple auxiliary supervision tasks, FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA performance on existing XDFA datasets. The code and data will be made open-source at this https URL.</li>
</ul>

<h3>Title: ARC-Encoder: learning compressed text representations for large language models</h3>
<ul>
<li><strong>Authors: </strong>Hippolyte Pilchen, Edouard Grave, Patrick Pérez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20535">https://arxiv.org/abs/2510.20535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20535">https://arxiv.org/pdf/2510.20535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20535]] ARC-Encoder: learning compressed text representations for large language models(https://arxiv.org/abs/2510.20535)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and increased inference costs. Context compression techniques can reduce these costs, but the most effective approaches require fine-tuning the target model or even modifying its architecture. This can degrade its general abilities when not used for this specific purpose. Here we explore an alternative approach: an encoder that compresses the context into continuous representations which replace token embeddings in decoder LLMs. First, we perform a systematic study of training strategies and architecture choices for the encoder. Our findings led to the design of an Adaptable text Representations Compressor, named ARC-Encoder, which outputs $x$-times fewer continuous representations (typically $x\!\in\!\{4,8\}$) than text tokens. We evaluate ARC-Encoder across a variety of LLM usage scenarios, ranging from in-context learning to context window extension, on both instruct and base decoders. Results show that ARC-Encoder achieves state-of-the-art performance on several benchmarks while improving computational efficiency at inference. Finally, we demonstrate that our models can be adapted to multiple decoders simultaneously, allowing a single encoder to generalize across different decoder LLMs. This makes ARC-Encoder a flexible and efficient solution for portable encoders that work seamlessly with multiple LLMs. We release a training code at this https URL , fine-tuning dataset and pretrained models are available at this https URL .</li>
</ul>

<h3>Title: Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image</h3>
<ul>
<li><strong>Authors: </strong>Guillermo Carbajal, Andrés Almansa, Pablo Musé</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20539">https://arxiv.org/abs/2510.20539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20539">https://arxiv.org/pdf/2510.20539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20539]] Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image(https://arxiv.org/abs/2510.20539)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Motion blur caused by camera shake, particularly under large or rotational movements, remains a major challenge in image restoration. We propose a deep learning framework that jointly estimates the latent sharp image and the underlying camera motion trajectory from a single blurry image. Our method leverages the Projective Motion Blur Model (PMBM), implemented efficiently using a differentiable blur creation module compatible with modern networks. A neural network predicts a full 3D rotation trajectory, which guides a model-based restoration network trained end-to-end. This modular architecture provides interpretability by revealing the camera motion that produced the blur. Moreover, this trajectory enables the reconstruction of the sequence of sharp images that generated the observed blurry image. To further refine results, we optimize the trajectory post-inference via a reblur loss, improving consistency between the blurry input and the restored output. Extensive experiments show that our method achieves state-of-the-art performance on both synthetic and real datasets, particularly in cases with severe or spatially variant blur, where end-to-end deblurring networks struggle. Code and trained models are available at this https URL</li>
</ul>

<h3>Title: SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment</h3>
<ul>
<li><strong>Authors: </strong>Abdulmomen Ghalkha, Zhuojun Tian, Chaouki Ben Issaid, Mehdi Bennis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20540">https://arxiv.org/abs/2510.20540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20540">https://arxiv.org/pdf/2510.20540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20540]] SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment(https://arxiv.org/abs/2510.20540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Conventional multimodal alignment methods assume mutual redundancy across all modalities, an assumption that fails in real-world distributed scenarios. We propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal alignment that replaces single-space alignment with multiple comparison spaces. This approach models pairwise modality relations through sheaf structures and leverages decentralized contrastive learning-based objectives for training. SheafAlign overcomes the limitations of prior methods by not requiring mutual redundancy among all modalities, preserving both shared and unique information. Experiments on multimodal sensing datasets show superior zero-shot generalization, cross-modal alignment, and robustness to missing modalities, with 50\% lower communication cost than state-of-the-art baselines.</li>
</ul>

<h3>Title: Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation</h3>
<ul>
<li><strong>Authors: </strong>Marziyeh Bamdad, Hans-Peter Hutter, Alireza Darvishy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20549">https://arxiv.org/abs/2510.20549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20549">https://arxiv.org/pdf/2510.20549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20549]] Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation(https://arxiv.org/abs/2510.20549)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Despite advancements in SLAM technologies, robust operation under challenging conditions such as low-texture, motion-blur, or challenging lighting remains an open challenge. Such conditions are common in applications such as assistive navigation for the visually impaired. These challenges undermine localization accuracy and tracking stability, reducing navigation reliability and safety. To overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced visual SLAM framework that integrates SuperPoint and LightGlue for robust feature extraction and matching. We evaluated our framework using TUM RGB-D, ICL-NUIM, and TartanAir datasets, which feature diverse and challenging scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of 87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework demonstrates enhanced performance under challenging conditions, such as low-texture scenes and fast motion, providing a reliable platform for developing navigation aids for the visually impaired.</li>
</ul>

<h3>Title: Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Benoit, Catherine Aitken, Yu He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20556">https://arxiv.org/abs/2510.20556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20556">https://arxiv.org/pdf/2510.20556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20556]] Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics(https://arxiv.org/abs/2510.20556)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph rewiring has emerged as a key technique to alleviate over-squashing in Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph topology to improve information flow. While effective, rewiring inherently alters the graph's structure, raising the risk of distorting important topology-dependent signals. Yet, despite the growing use of rewiring, little is known about which structural properties must be preserved to ensure both performance gains and structural fidelity. In this work, we provide the first systematic analysis of how rewiring affects a range of graph structural metrics, and how these changes relate to downstream task performance. We study seven diverse rewiring strategies and correlate changes in local and global graph properties with node classification accuracy. Our results reveal a consistent pattern: successful rewiring methods tend to preserve local structure while allowing for flexibility in global connectivity. These findings offer new insights into the design of effective rewiring strategies, bridging the gap between graph theory and practical GNN optimization.</li>
</ul>

<h3>Title: AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN</h3>
<ul>
<li><strong>Authors: </strong>Wei Shao, Yuhao Wang, Rongguang He, Muhammad Ejaz Ahmed, Seyit Camtepe</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20566">https://arxiv.org/abs/2510.20566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20566">https://arxiv.org/pdf/2510.20566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20566]] AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN(https://arxiv.org/abs/2510.20566)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Existing defence mechanisms have demonstrated significant effectiveness in mitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined signatures and static heuristics to identify and block malicious traffic. However, the emergence of AI-driven techniques presents new challenges to SDN security, potentially compromising the efficacy of existing defence mechanisms. In this paper, we introduce~AdaDoS, an adaptive attack model that disrupt network operations while evading detection by existing DoS-based detectors through adversarial reinforcement learning (RL). Specifically, AdaDoS models the problem as a competitive game between an attacker, whose goal is to obstruct network traffic without being detected, and a detector, which aims to identify malicious traffic. AdaDoS can solve this game by dynamically adjusting its attack strategy based on feedback from the SDN and the detector. Additionally, recognising that attackers typically have less information than defenders, AdaDoS formulates the DoS-like attack as a partially observed Markov decision process (POMDP), with the attacker having access only to delay information between attacker and victim nodes. We address this challenge with a novel reciprocal learning module, where the student agent, with limited observations, enhances its performance by learning from the teacher agent, who has full observational capabilities in the SDN environment. AdaDoS represents the first application of RL to develop DoS-like attack sequences, capable of adaptively evading both machine learning-based and rule-based DoS-like attack detectors.</li>
</ul>

<h3>Title: EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Ding Zou, Feifan Wang, Mengyu Ge, Siyuan Fan, Zongbing Zhang, Wei Chen, Lingfeng Wang, Zhongyou Hu, Wenrui Yan, Zhengwei Gao, Hao Wang, Weizhao Jin, Yu Zhang, Hainan Zhao, Mingliang Zhang, Xianxian Xi, Yaru Zhang, Wenyuan Li, Zhengguang Gao, Yurui Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20578">https://arxiv.org/abs/2510.20578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20578">https://arxiv.org/pdf/2510.20578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20578]] EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence(https://arxiv.org/abs/2510.20578)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>The realization of Artificial General Intelligence (AGI) necessitates Embodied AI agents capable of robust spatial perception, effective task planning, and adaptive execution in physical environments. However, current large language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks suffer from key limitations, including a significant gap between model design and agent requirements, an unavoidable trade-off between real-time latency and performance, and the use of unauthentic, offline evaluation metrics. To address these challenges, we propose EmbodiedBrain, a novel vision-language foundation model available in both 7B and 32B parameter sizes. Our framework features an agent-aligned data structure and employs a powerful training methodology that integrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group Relative Policy Optimization (Step-GRPO), which boosts long-horizon task success by integrating preceding steps as Guided Precursors. Furthermore, we incorporate a comprehensive reward system, including a Generative Reward Model (GRM) accelerated at the infrastructure level, to improve training efficiency. For enable thorough validation, we establish a three-part evaluation system encompassing General, Planning, and End-to-End Simulation Benchmarks, highlighted by the proposal and open-sourcing of a novel, challenging simulation environment. Experimental results demonstrate that EmbodiedBrain achieves superior performance across all metrics, establishing a new state-of-the-art for embodied foundation models. Towards paving the way for the next generation of generalist embodied agents, we open-source all of our data, model weight, and evaluating methods, which are available at this https URL.</li>
</ul>

<h3>Title: Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jiangang Hao, Wenju Cui, Patrick Kyllonen, Emily Kerzabi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20584">https://arxiv.org/abs/2510.20584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20584">https://arxiv.org/pdf/2510.20584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20584]] Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks(https://arxiv.org/abs/2510.20584)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Assessing communication and collaboration at scale depends on a labor intensive task of coding communication data into categories according to different frameworks. Prior research has established that ChatGPT can be directly instructed with coding rubrics to code the communication data and achieves accuracy comparable to human raters. However, whether the coding from ChatGPT or similar AI technology exhibits bias against different demographic groups, such as gender and race, remains unclear. To fill this gap, this paper investigates ChatGPT-based automated coding of communication data using a typical coding framework for collaborative problem solving, examining differences across gender and racial groups. The analysis draws on data from three types of collaborative tasks: negotiation, problem solving, and decision making. Our results show that ChatGPT-based coding exhibits no significant bias across gender and racial groups, paving the road for its adoption in large-scale assessment of collaboration and communication.</li>
</ul>

<h3>Title: GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Atif Butt, Alexandra Gomez-Villa, Tao Wu, Javier Vazquez-Corral, Joost Van De Weijer, Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20586">https://arxiv.org/abs/2510.20586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20586">https://arxiv.org/pdf/2510.20586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20586]] GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models(https://arxiv.org/abs/2510.20586)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent years have seen impressive advances in text-to-image generation, with image generative or unified models producing high-quality images from text. Yet these models still struggle with fine-grained color controllability, often failing to accurately match colors specified in text prompts. While existing benchmarks evaluate compositional reasoning and prompt adherence, none systematically assess color precision. Color is fundamental to human visual perception and communication, critical for applications from art to design workflows requiring brand consistency. However, current benchmarks either neglect color or rely on coarse assessments, missing key capabilities such as interpreting RGB values or aligning with human expectations. To this end, we propose GenColorBench, the first comprehensive benchmark for text-to-image color generation, grounded in color systems like ISCC-NBS and CSS3/X11, including numerical colors which are absent elsewhere. With 44K color-focused prompts covering 400+ colors, it reveals models' true capabilities via perceptual and automated assessments. Evaluations of popular text-to-image models using GenColorBench show performance variations, highlighting which color conventions models understand best and identifying failure modes. Our GenColorBench assessments will guide improvements in precise color generation. The benchmark will be made public upon acceptance.</li>
</ul>

<h3>Title: Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Ye, Chen Ju, Chaofan Ma, Xiaoyun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20596">https://arxiv.org/abs/2510.20596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20596">https://arxiv.org/pdf/2510.20596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20596]] Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation(https://arxiv.org/abs/2510.20596)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning models have achieved great success on various vision challenges, but a well-trained model would face drastic performance degradation when applied to unseen data. Since the model is sensitive to domain shift, unsupervised domain adaptation attempts to reduce the domain gap and avoid costly annotation of unseen domains. This paper proposes a novel framework for cross-modality segmentation via similarity-based prototypes. In specific, we learn class-wise prototypes within an embedding space, then introduce a similarity constraint to make these prototypes representative for each semantic class while separable from different classes. Moreover, we use dictionaries to store prototypes extracted from different images, which prevents the class-missing problem and enables the contrastive learning of prototypes, and further improves performance. Extensive experiments show that our method achieves better results than other state-of-the-art methods.</li>
</ul>

<h3>Title: OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects</h3>
<ul>
<li><strong>Authors: </strong>Mark He Huang, Lin Geng Foo, Christian Theobalt, Ying Sun, De Wen Soh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20605">https://arxiv.org/abs/2510.20605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20605">https://arxiv.org/pdf/2510.20605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20605]] OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects(https://arxiv.org/abs/2510.20605)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Free-moving object reconstruction from monocular video remains challenging, particularly without reliable pose or depth cues and under arbitrary object motion. We introduce OnlineSplatter, a novel online feed-forward framework generating high-quality, object-centric 3D Gaussians directly from RGB frames without requiring camera pose, depth priors, or bundle optimization. Our approach anchors reconstruction using the first frame and progressively refines the object representation through a dense Gaussian primitive field, maintaining constant computational cost regardless of video sequence length. Our core contribution is a dual-key memory module combining latent appearance-geometry keys with explicit directional keys, robustly fusing current frame features with temporally aggregated object states. This design enables effective handling of free-moving objects via spatial-guided memory readout and an efficient sparsification mechanism, ensuring comprehensive yet compact object coverage. Evaluations on real-world datasets demonstrate that OnlineSplatter significantly outperforms state-of-the-art pose-free reconstruction baselines, consistently improving with more observations while maintaining constant memory and runtime.</li>
</ul>

<h3>Title: BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Ali Zain, Sareem Farooqui, Muhammad Rafi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20610">https://arxiv.org/abs/2510.20610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20610">https://arxiv.org/pdf/2510.20610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20610]] BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection(https://arxiv.org/abs/2510.20610)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper details our submission to the Ara- GenEval Shared Task on Arabic AI-generated text detection, where our team, BUSTED, se- cured 5th place. We investigated the effec- tiveness of three pre-trained transformer mod- els: AraELECTRA, CAMeLBERT, and XLM- RoBERTa. Our approach involved fine-tuning each model on the provided dataset for a binary classification task. Our findings revealed a sur- prising result: the multilingual XLM-RoBERTa model achieved the highest performance with an F1 score of 0.7701, outperforming the spe- cialized Arabic models. This work underscores the complexities of AI-generated text detection and highlights the strong generalization capa- bilities of multilingual models.</li>
</ul>

<h3>Title: PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection</h3>
<ul>
<li><strong>Authors: </strong>Mirza Raquib, Niloy Das, Farida Siddiqi Prity, Arafath Al Fahim, Saydul Akbar Murad, Mohammad Amzad Hossain, MD Jiabul Hoque, Mohammad Ali Moni</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20611">https://arxiv.org/abs/2510.20611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20611">https://arxiv.org/pdf/2510.20611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20611]] PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection(https://arxiv.org/abs/2510.20611)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Breast cancer is considered the most critical and frequently diagnosed cancer in women worldwide, leading to an increase in cancer-related mortality. Early and accurate detection is crucial as it can help mitigate possible threats while improving survival rates. In terms of prediction, conventional diagnostic methods are often limited by variability, cost, and, most importantly, risk of misdiagnosis. To address these challenges, machine learning (ML) has emerged as a powerful tool for computer-aided diagnosis, with feature selection playing a vital role in improving model performance and interpretability. This research study proposes an integrated framework that incorporates customized Particle Swarm Optimization (PSO) for feature selection. This framework has been evaluated on a comprehensive set of 29 different models, spanning classical classifiers, ensemble techniques, neural networks, probabilistic algorithms, and instance-based algorithms. To ensure interpretability and clinical relevance, the study uses cross-validation in conjunction with explainable AI methods. Experimental evaluation showed that the proposed approach achieved a superior score of 99.1\% across all performance metrics, including accuracy and precision, while effectively reducing dimensionality and providing transparent, model-agnostic explanations. The results highlight the potential of combining swarm intelligence with explainable ML for robust, trustworthy, and clinically meaningful breast cancer diagnosis.</li>
</ul>

<h3>Title: MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation</h3>
<ul>
<li><strong>Authors: </strong>Yang Han, Pengyu Wang, Kai Yu, Xin Chen, Lu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20615">https://arxiv.org/abs/2510.20615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20615">https://arxiv.org/pdf/2510.20615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20615]] MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation(https://arxiv.org/abs/2510.20615)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Mass spectrometry (MS) plays a critical role in molecular identification, significantly advancing scientific discovery. However, structure elucidation from MS data remains challenging due to the scarcity of annotated spectra. While large-scale pretraining has proven effective in addressing data scarcity in other domains, applying this paradigm to mass spectrometry is hindered by the complexity and heterogeneity of raw spectral signals. To address this, we propose MS-BART, a unified modeling framework that maps mass spectra and molecular structures into a shared token vocabulary, enabling cross-modal learning through large-scale pretraining on reliably computed fingerprint-molecule datasets. Multi-task pretraining objectives further enhance MS-BART's generalization by jointly optimizing denoising and translation task. The pretrained model is subsequently transferred to experimental spectra through finetuning on fingerprint predictions generated with MIST, a pre-trained spectral inference model, thereby enhancing robustness to real-world spectral variability. While finetuning alleviates the distributional difference, MS-BART still suffers molecular hallucination and requires further alignment. We therefore introduce a chemical feedback mechanism that guides the model toward generating molecules closer to the reference structure. Extensive evaluations demonstrate that MS-BART achieves SOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is faster by one order of magnitude than competing diffusion-based methods, while comprehensive ablation studies systematically validate the model's effectiveness and robustness.</li>
</ul>

<h3>Title: On Optimal Hyperparameters for Differentially Private Deep Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Aki Rehn, Linzh Zhao, Mikko A. Heikkilä, Antti Honkela</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20616">https://arxiv.org/abs/2510.20616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20616">https://arxiv.org/pdf/2510.20616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20616]] On Optimal Hyperparameters for Differentially Private Deep Transfer Learning(https://arxiv.org/abs/2510.20616)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained model on private data, is the current state-of-the-art approach for training large models under privacy constraints. We focus on two key hyperparameters in this setting: the clipping bound $C$ and batch size $B$. We show a clear mismatch between the current theoretical understanding of how to choose an optimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes (larger $C$ performs better under strong privacy), caused by changes in the gradient distributions. Assuming a limited compute budget (fixed epochs), we demonstrate that the existing heuristics for tuning $B$ do not work, while cumulative DP noise better explains whether smaller or larger batches perform better. We also highlight how the common practice of using a single $(C,B)$ setting across tasks can lead to suboptimal performance. We find that performance drops especially when moving between loose and tight privacy and between plentiful and limited compute, which we explain by analyzing clipping as a form of gradient re-weighting and examining cumulative DP noise.</li>
</ul>

<h3>Title: SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yuan Sheng, Yanbin Hao, Chenxu Li, Shuo Wang, Xiangnan He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20622">https://arxiv.org/abs/2510.20622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20622">https://arxiv.org/pdf/2510.20622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20622]] SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding(https://arxiv.org/abs/2510.20622)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Long video understanding remains challenging due to its complex, diverse, and temporally scattered content. Although video large language models (Video-LLMs) can process videos lasting tens of minutes, applying them to truly long sequences is computationally prohibitive and often leads to unfocused or inconsistent reasoning. A promising solution is to select only the most informative frames, yet existing approaches typically ignore temporal dependencies or rely on unimodal evidence, limiting their ability to provide complete and query-relevant context. We propose a Semantic-Visual Consensus Evidence Selection (SeViCES) framework for effective and reliable long video understanding. SeViCES is training-free and model-agnostic, and introduces two key components. The Semantic-Visual Consensus Frame Selection (SVCFS) module selects frames through (1) a temporal-aware semantic branch that leverages LLM reasoning over captions, and (2) a cluster-guided visual branch that aligns embeddings with semantic scores via mutual information. The Answer Consensus Refinement (ACR) module further resolves inconsistencies between semantic- and visual-based predictions by fusing evidence and constraining the answer space. Extensive experiments on long video understanding benchmarks show that SeViCES consistently outperforms state-of-the-art methods in both accuracy and robustness, demonstrating the importance of consensus-driven evidence selection for Video-LLMs.</li>
</ul>

<h3>Title: H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Lukas Miklautz, Chengzhi Shi, Andrii Shkabrii, Theodoros Thirimachos Davarakis, Prudence Lam, Claudia Plant, Jennifer Dy, Stratis Ioannidis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20627">https://arxiv.org/abs/2510.20627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20627">https://arxiv.org/pdf/2510.20627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20627]] H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition(https://arxiv.org/abs/2510.20627)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce H-SPLID, a novel algorithm for learning salient feature representations through the explicit decomposition of salient and non-salient features into separate spaces. We show that H-SPLID promotes learning low-dimensional, task-relevant features. We prove that the expected prediction deviation under input perturbations is upper-bounded by the dimension of the salient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between inputs and representations. This establishes a link between robustness and latent representation compression in terms of the dimensionality and information preserved. Empirical evaluations on image classification tasks show that models trained with H-SPLID primarily rely on salient input components, as indicated by reduced sensitivity to perturbations affecting non-salient features, such as image backgrounds. Our code is available at this https URL.</li>
</ul>

<h3>Title: Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach</h3>
<ul>
<li><strong>Authors: </strong>Mingxuan Liu, Yilin Ning, Haoyuan Wang, Chuan Hong, Matthew Engelhard, Danielle S. Bitterman, William G. La Cava, Nan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20629">https://arxiv.org/abs/2510.20629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20629">https://arxiv.org/pdf/2510.20629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20629]] Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach(https://arxiv.org/abs/2510.20629)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>As machine learning models become increasingly integrated into healthcare, structural inequities and social biases embedded in clinical data can be perpetuated or even amplified by data-driven models. In survival analysis, censoring and time dynamics can further add complexity to fair model development. Additionally, algorithmic fairness approaches often overlook disparities in cross-group rankings, e.g., high-risk Black patients may be ranked below lower-risk White patients who do not experience the event of mortality. Such misranking can reinforce biological essentialism and undermine equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed to mitigate algorithmic bias regarding both intra-group and cross-group risk rankings over time. Using breast cancer prognosis as a representative case and applying FASM to SEER breast cancer data, we show that FASM substantially improves fairness while preserving discrimination performance comparable to fairness-unaware survival models. Time-stratified evaluations show that FASM maintains stable fairness over a 10-year horizon, with the greatest improvements observed during the mid-term of follow-up. Our approach enables the development of survival models that prioritize both accuracy and equity in clinical decision-making, advancing fairness as a core principle in clinical care.</li>
</ul>

<h3>Title: Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges</h3>
<ul>
<li><strong>Authors: </strong>Zhenhuan Zhou, Jingbo Zhu, Yuchen Zhang, Xiaohang Guan, Peng Wang, Tao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20634">https://arxiv.org/abs/2510.20634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20634">https://arxiv.org/pdf/2510.20634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20634]] Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges(https://arxiv.org/abs/2510.20634)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Efficient analysis and processing of dental images are crucial for dentists to achieve accurate diagnosis and optimal treatment planning. However, dental imaging inherently poses several challenges, such as low contrast, metallic artifacts, and variations in projection angles. Combined with the subjectivity arising from differences in clinicians' expertise, manual interpretation often proves time-consuming and prone to inconsistency. Artificial intelligence (AI)-based automated dental image analysis (DIA) offers a promising solution to these issues and has become an integral part of computer-aided dental diagnosis and treatment. Among various AI technologies, deep learning (DL) stands out as the most widely applied and influential approach due to its superior feature extraction and representation capabilities. To comprehensively summarize recent progress in this field, we focus on the two fundamental aspects of DL research-datasets and models. In this paper, we systematically review 260 studies on DL applications in DIA, including 49 papers on publicly available dental datasets and 211 papers on DL-based algorithms. We first introduce the basic concepts of dental imaging and summarize the characteristics and acquisition methods of existing datasets. Then, we present the foundational techniques of DL and categorize relevant models and algorithms according to different DIA tasks, analyzing their network architectures, optimization strategies, training methods, and performance. Furthermore, we summarize commonly used training and evaluation metrics in the DIA domain. Finally, we discuss the current challenges of existing research and outline potential future directions. We hope that this work provides a valuable and systematic reference for researchers in this field. All supplementary materials and detailed comparison tables will be made publicly available on GitHub.</li>
</ul>

<h3>Title: Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Wang, Sihang Jiang, Yuyan Chen, Yitong Wang, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20635">https://arxiv.org/abs/2510.20635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20635">https://arxiv.org/pdf/2510.20635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20635]] Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model(https://arxiv.org/abs/2510.20635)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Curiosity serves as a pivotal conduit for human beings to discover and learn new knowledge. Recent advancements of large language models (LLMs) in natural language processing have sparked discussions regarding whether these models possess capability of curiosity-driven learning akin to humans. In this paper, starting from the human curiosity assessment questionnaire Five-Dimensional Curiosity scale Revised (5DCR), we design a comprehensive evaluation framework that covers dimensions such as Information Seeking, Thrill Seeking, and Social Curiosity to assess the extent of curiosity exhibited by LLMs. The results demonstrate that LLMs exhibit a stronger thirst for knowledge than humans but still tend to make conservative choices when faced with uncertain environments. We further investigated the relationship between curiosity and thinking of LLMs, confirming that curious behaviors can enhance the model's reasoning and active learning abilities. These findings suggest that LLMs have the potential to exhibit curiosity similar to that of humans, providing experimental support for the future development of learning capabilities and innovative research in LLMs.</li>
</ul>

<h3>Title: Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges</h3>
<ul>
<li><strong>Authors: </strong>Hyun Jong Yang, Hyunsoo Kim, Hyeonho Noh, Seungnyun Kim, Byonghyo Shim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20637">https://arxiv.org/abs/2510.20637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20637">https://arxiv.org/pdf/2510.20637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20637]] Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges(https://arxiv.org/abs/2510.20637)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) and large multimodal models (LMMs) have achieved unprecedented breakthrough, showcasing remarkable capabilities in natural language understanding, generation, and complex reasoning. This transformative potential has positioned them as key enablers for 6G autonomous communications among machines, vehicles, and humanoids. In this article, we provide an overview of task-oriented autonomous communications with LLMs/LMMs, focusing on multimodal sensing integration, adaptive reconfiguration, and prompt/fine-tuning strategies for wireless tasks. We demonstrate the framework through three case studies: LMM-based traffic control, LLM-based robot scheduling, and LMM-based environment-aware channel estimation. From experimental results, we show that the proposed LLM/LMM-aided autonomous systems significantly outperform conventional and discriminative deep learning (DL) model-based techniques, maintaining robustness under dynamic objectives, varying input parameters, and heterogeneous multimodal conditions where conventional static optimization degrades.</li>
</ul>

<h3>Title: Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems</h3>
<ul>
<li><strong>Authors: </strong>Fiza Hussain, Anson Bastos, Anjaly Parayil, Ayush Choure, Chetan Bansal, Rujia Wang, Saravan Rajmohan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20640">https://arxiv.org/abs/2510.20640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20640">https://arxiv.org/pdf/2510.20640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20640]] Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems(https://arxiv.org/abs/2510.20640)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we present DiRecGNN, an attention-enhanced entity recommendation framework for monitoring cloud services at Microsoft. We provide insights on the usefulness of this feature as perceived by the cloud service owners and lessons learned from deployment. Specifically, we introduce the problem of recommending the optimal subset of attributes (dimensions) that should be tracked by an automated watchdog (monitor) for cloud services. To begin, we construct the monitor heterogeneous graph at production-scale. The interaction dynamics of these entities are often characterized by limited structural and engagement information, resulting in inferior performance of state-of-the-art approaches. Moreover, traditional methods fail to capture the dependencies between entities spanning a long range due to their homophilic nature. Therefore, we propose an attention-enhanced entity ranking model inspired by transformer architectures. Our model utilizes a multi-head attention mechanism to focus on heterogeneous neighbors and their attributes, and further attends to paths sampled using random walks to capture long-range dependencies. We also employ multi-faceted loss functions to optimize for relevant recommendations while respecting the inherent sparsity of the data. Empirical evaluations demonstrate significant improvements over existing methods, with our model achieving a 43.1% increase in MRR. Furthermore, product teams who consumed these features perceive the feature as useful and rated it 4.5 out of 5.</li>
</ul>

<h3>Title: Decentralized Exchange that Mitigate a Bribery Attack</h3>
<ul>
<li><strong>Authors: </strong>Nitin Awathare</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE, cs.DC, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20645">https://arxiv.org/abs/2510.20645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20645">https://arxiv.org/pdf/2510.20645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20645]] Decentralized Exchange that Mitigate a Bribery Attack(https://arxiv.org/abs/2510.20645)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Despite the popularity of Hashed Time-Locked Contracts (HTLCs) because of their use in wide areas of applications such as payment channels, atomic swaps, etc, their use in exchange is still questionable. This is because of its incentive incompatibility and susceptibility to bribery attacks. State-of-the-art solutions such as MAD-HTLC (Oakland'21) and He-HTLC (NDSS'23) address this by leveraging miners' profit-driven behaviour to mitigate such attacks. The former is the mitigation against passive miners; however, the latter works against both active and passive miners. However, they consider only two bribing scenarios where either of the parties involved in the transfer collude with the miner. In this paper, we expose vulnerabilities in state-of-the-art solutions by presenting a miner-collusion bribery attack with implementation and game-theoretic analysis. Additionally, we propose a stronger attack on MAD-HTLC than He-HTLC, allowing the attacker to earn profits equivalent to attacking naive HTLC. Leveraging our insights, we propose \prot, a game-theoretically secure HTLC protocol resistant to all bribery scenarios. \prot\ employs a two-phase approach, preventing unauthorized token confiscation by third parties, such as miners. In Phase 1, parties commit to the transfer; in Phase 2, the transfer is executed without manipulation. We demonstrate \prot's efficiency in transaction cost and latency via implementations on Bitcoin and Ethereum.</li>
</ul>

<h3>Title: The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI</h3>
<ul>
<li><strong>Authors: </strong>Alan Saji, Raj Dabre, Anoop Kunchukuttan, Ratish Puduppully</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20647">https://arxiv.org/abs/2510.20647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20647">https://arxiv.org/pdf/2510.20647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20647]] The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI(https://arxiv.org/abs/2510.20647)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the language of the question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond measuring answer accuracy, we also analyze cognitive attributes in the reasoning traces. We find that English reasoning traces exhibit a substantially higher presence of these cognitive behaviors, and that reasoning in English generally yields higher final-answer accuracy, with the performance gap increasing as tasks become more complex. However, this English-centric strategy is susceptible to a key failure mode - getting "Lost in Translation," where translation steps lead to errors that would have been avoided by question's language reasoning.</li>
</ul>

<h3>Title: Risk Psychology & Cyber-Attack Tactics</h3>
<ul>
<li><strong>Authors: </strong>Rubens Kim, Stephan Carney, Yvonne Fonken, Soham Hans, Sofia Hirschmann, Stacy Marsella, Peggy Wu, Nikolos Gurney</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20657">https://arxiv.org/abs/2510.20657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20657">https://arxiv.org/pdf/2510.20657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20657]] Risk Psychology & Cyber-Attack Tactics(https://arxiv.org/abs/2510.20657)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>We examine whether measured cognitive processes predict cyber-attack behavior. We analyzed data that included psychometric scale responses and labeled attack behaviors from cybersecurity professionals who conducted red-team operations against a simulated enterprise network. We employed multilevel mixed-effects Poisson regression with technique counts nested within participants to test whether cognitive processes predicted technique-specific usage. The scales significantly predicted technique use, but effects varied by technique rather than operating uniformly. Neither expertise level nor experimental treatment condition significantly predicted technique patterns, indicating that cognitive processes may be stronger drivers of technique selection than training or experience. These findings demonstrate that individual cognitive differences shape cyber-attack behavior and support the development of psychology-informed defense strategies.</li>
</ul>

<h3>Title: UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset</h3>
<ul>
<li><strong>Authors: </strong>Chen Zhao, En Ci, Yunzhe Xu, Tiehan Fan, Shanyan Guan, Yanhao Ge, Jian Yang, Ying Tai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20661">https://arxiv.org/abs/2510.20661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20661">https://arxiv.org/pdf/2510.20661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20661]] UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset(https://arxiv.org/abs/2510.20661)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable progress. However, two key challenges remain : 1) the absence of a large-scale high-quality UHR T2I dataset, and (2) the neglect of tailored training strategies for fine-grained detail synthesis in UHR scenarios. To tackle the first challenge, we introduce \textbf{UltraHR-100K}, a high-quality dataset of 100K UHR images with rich captions, offering diverse content and strong visual fidelity. Each image exceeds 3K resolution and is rigorously curated based on detail richness, content complexity, and aesthetic quality. To tackle the second challenge, we propose a frequency-aware post-training method that enhances fine-detail generation in T2I diffusion models. Specifically, we design (i) \textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning on detail-critical denoising steps, and (ii) \textit{Soft-Weighting Frequency Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to softly constrain frequency components, encouraging high-frequency detail preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks demonstrate that our approach significantly improves the fine-grained detail quality and overall fidelity of UHR image generation. The code is available at \href{this https URL}{here}.</li>
</ul>

<h3>Title: From Masks to Worlds: A Hitchhiker's Guide to World Models</h3>
<ul>
<li><strong>Authors: </strong>Jinbin Bai, Yu Lei, Hecong Wu, Yuchen Zhu, Shufan Li, Yi Xin, Xiangtai Li, Molei Tao, Aditya Grover, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20668">https://arxiv.org/abs/2510.20668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20668">https://arxiv.org/pdf/2510.20668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20668]] From Masks to Worlds: A Hitchhiker's Guide to World Models(https://arxiv.org/abs/2510.20668)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This is not a typical survey of world models; it is a guide for those who want to build worlds. We do not aim to catalog every paper that has ever mentioned a ``world model". Instead, we follow one clear road: from early masked models that unified representation learning across modalities, to unified architectures that share a single paradigm, then to interactive generative models that close the action-perception loop, and finally to memory-augmented systems that sustain consistent worlds over time. We bypass loosely related branches to focus on the core: the generative heart, the interactive loop, and the memory system. We show that this is the most promising path towards true world models.</li>
</ul>

<h3>Title: HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification</h3>
<ul>
<li><strong>Authors: </strong>Debojyoti Ghosh, Adrijit Goswami</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20669">https://arxiv.org/abs/2510.20669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20669">https://arxiv.org/pdf/2510.20669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20669]] HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification(https://arxiv.org/abs/2510.20669)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.</li>
</ul>

<h3>Title: Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward</h3>
<ul>
<li><strong>Authors: </strong>Jing Bi, Guangyu Sun, Ali Vosoughi, Chen Chen, Chenliang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20696">https://arxiv.org/abs/2510.20696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20696">https://arxiv.org/pdf/2510.20696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20696]] Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward(https://arxiv.org/abs/2510.20696)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) that integrate visual and textual reasoning leverage chain-of-thought (CoT) prompting to tackle complex visual tasks, yet continue to exhibit visual hallucinations and an over-reliance on textual priors. We present a systematic diagnosis of state-of-the-art vision-language models using a three-stage evaluation framework, uncovering key failure modes. To address these, we propose an agent-based architecture that combines LLM reasoning with lightweight visual modules, enabling fine-grained analysis and iterative refinement of reasoning chains. Our results highlight future visual reasoning models should focus on integrating a broader set of specialized tools for analyzing visual content. Our system achieves significant gains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or surpassing much larger models. We will release our framework and evaluation suite to facilitate future research.</li>
</ul>

<h3>Title: Separating the what and how of compositional computation to enable reuse and continual learning</h3>
<ul>
<li><strong>Authors: </strong>Haozhe Shan, Sun Minni, Lea Duncker</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20709">https://arxiv.org/abs/2510.20709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20709">https://arxiv.org/pdf/2510.20709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20709]] Separating the what and how of compositional computation to enable reuse and continual learning(https://arxiv.org/abs/2510.20709)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.</li>
</ul>

<h3>Title: Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool</h3>
<ul>
<li><strong>Authors: </strong>Fardin Ganjkhanloo, Emmett Springer, Erik H. Hoyer, Daniel L. Young, Kimia Ghobadi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20714">https://arxiv.org/abs/2510.20714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20714">https://arxiv.org/pdf/2510.20714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20714]] Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool(https://arxiv.org/abs/2510.20714)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>In this study we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models on JHFRAT assessment data and additional electronic health record (EHR) variables. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labelling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.</li>
</ul>

<h3>Title: User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyuan Wu, Roshni Kaushik, Wenkai Li, Lujo Bauer, Koichi Onoue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20721">https://arxiv.org/abs/2510.20721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20721">https://arxiv.org/pdf/2510.20721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20721]] User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios(https://arxiv.org/abs/2510.20721)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have seen rapid adoption for tasks such as drafting emails, summarizing meetings, and answering health questions. In such uses, users may need to share private information (e.g., health records, contact details). To evaluate LLMs' ability to identify and redact such private information, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with real-life scenarios. Using these benchmarks, researchers have found that LLMs sometimes fail to keep secrets private when responding to complex tasks (e.g., leaking employee salaries in meeting summaries). However, these evaluations rely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking real users' perceptions. Moreover, prior work primarily focused on the privacy-preservation quality of responses, without investigating nuanced differences in helpfulness. To understand how users perceive the privacy-preservation quality and helpfulness of LLM responses to privacy-sensitive scenarios, we conducted a user study with 94 participants using 90 scenarios from PrivacyLens. We found that, when evaluating identical responses to the same scenario, users showed low agreement with each other on the privacy-preservation quality and helpfulness of the LLM response. Further, we found high agreement among five proxy LLMs, while each individual LLM had low correlation with users' evaluations. These results indicate that the privacy and helpfulness of LLM responses are often specific to individuals, and proxy LLMs are poor estimates of how real users would perceive these responses in privacy-sensitive scenarios. Our results suggest the need to conduct user-centered studies on measuring LLMs' ability to help users while preserving privacy. Additionally, future research could investigate ways to improve the alignment between proxy LLMs and users for better estimation of users' perceived privacy and utility.</li>
</ul>

<h3>Title: AutoScape: Geometry-Consistent Long-Horizon Scene Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Chen, Ziyu Jiang, Mingfu Liang, Bingbing Zhuang, Jong-Chyi Su, Sparsh Garg, Ying Wu, Manmohan Chandraker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20726">https://arxiv.org/abs/2510.20726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20726">https://arxiv.org/pdf/2510.20726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20726]] AutoScape: Geometry-Consistent Long-Horizon Scene Generation(https://arxiv.org/abs/2510.20726)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper proposes AutoScape, a long-horizon driving scene generation framework. At its core is a novel RGB-D diffusion model that iteratively generates sparse, geometrically consistent keyframes, serving as reliable anchors for the scene's appearance and geometry. To maintain long-range geometric consistency, the model 1) jointly handles image and depth in a shared latent space, 2) explicitly conditions on the existing scene geometry (i.e., rendered point clouds) from previously generated keyframes, and 3) steers the sampling process with a warp-consistent guidance. Given high-quality RGB-D keyframes, a video diffusion model then interpolates between them to produce dense and coherent video frames. AutoScape generates realistic and geometrically consistent driving videos of over 20 seconds, improving the long-horizon FID and FVD scores over the prior state-of-the-art by 48.6\% and 43.0\%, respectively.</li>
</ul>

<h3>Title: Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing</h3>
<ul>
<li><strong>Authors: </strong>Xizhi Wu, Madeline S. Kreider, Philip E. Empey, Chenyu Li, Yanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20727">https://arxiv.org/abs/2510.20727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20727">https://arxiv.org/pdf/2510.20727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20727]] Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing(https://arxiv.org/abs/2510.20727)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Objective: Fluoropyrimidines are widely prescribed for colorectal and breast cancers, but are associated with toxicities such as hand-foot syndrome and cardiotoxicity. Since toxicity documentation is often embedded in clinical notes, we aimed to develop and evaluate natural language processing (NLP) methods to extract treatment and toxicity information. Materials and Methods: We constructed a gold-standard dataset of 236 clinical notes from 204,165 adult oncology patients. Domain experts annotated categories related to treatment regimens and toxicities. We developed rule-based, machine learning-based (Random Forest, Support Vector Machine [SVM], Logistic Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language models (LLM)-based NLP approaches (zero-shot and error-analysis prompting). Models used an 80:20 train-test split. Results: Sufficient data existed to train and evaluate 5 annotated categories. Error-analysis prompting achieved optimal precision, recall, and F1 scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot prompting reached F1=1.000 for treatment and F1=0.876 for toxicities this http URL and SVM ranked second for toxicities (F1=0.937). Deep learning underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods served as our baseline with F1 scores of 0.857 in treatment and 0.858 in toxicities. Discussion: LMM-based approaches outperformed all others, followed by machine learning methods. Machine and deep learning approaches were limited by small training data and showed limited generalizability, particularly for rare categories. Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine treatment and toxicity information from clinical notes, and has strong potential to support oncology research and pharmacovigilance.</li>
</ul>

<h3>Title: Thought Communication in Multiagent Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Yujia Zheng, Zhuokai Zhao, Zijian Li, Yaqi Xie, Mingze Gao, Lizhu Zhang, Kun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20733">https://arxiv.org/abs/2510.20733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20733">https://arxiv.org/pdf/2510.20733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20733]] Thought Communication in Multiagent Collaboration(https://arxiv.org/abs/2510.20733)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, thought communication, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.</li>
</ul>

<h3>Title: Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process</h3>
<ul>
<li><strong>Authors: </strong>Tsai Hor Chan, Feng Wu, Yihang Chen, Guosheng Yin, Lequan Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20736">https://arxiv.org/abs/2510.20736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20736">https://arxiv.org/pdf/2510.20736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20736]] Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process(https://arxiv.org/abs/2510.20736)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Developing effective multimodal fusion approaches has become increasingly essential in many real-world scenarios, such as health care and finance. The key challenge is how to preserve the feature expressiveness in each modality while learning cross-modal interactions. Previous approaches primarily focus on the cross-modal alignment, while over-emphasis on the alignment of marginal distributions of modalities may impose excess regularization and obstruct meaningful representations within each modality. The Dirichlet process (DP) mixture model is a powerful Bayesian non-parametric method that can amplify the most prominent features by its richer-gets-richer property, which allocates increasing weights to them. Inspired by this unique characteristic of DP, we propose a new DP-driven multimodal learning framework that automatically achieves an optimal balance between prominent intra-modal representation learning and cross-modal alignment. Specifically, we assume that each modality follows a mixture of multivariate Gaussian distributions and further adopt DP to calculate the mixture weights for all the components. This paradigm allows DP to dynamically allocate the contributions of features and select the most prominent ones, leveraging its richer-gets-richer property, thus facilitating multimodal feature fusion. Extensive experiments on several multimodal datasets demonstrate the superior performance of our model over other competitors. Ablation analysis further validates the effectiveness of DP in aligning modality distributions and its robustness to changes in key hyperparameters. Code is anonymously available at this https URL</li>
</ul>

<h3>Title: Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages</h3>
<ul>
<li><strong>Authors: </strong>Ronghao Ni, Aidan Z.H. Yang, Min-Chien Hsu, Nuno Sabino, Limin Jia, Ruben Martins, Darion Cassel, Kevin Cheang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20739">https://arxiv.org/abs/2510.20739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20739">https://arxiv.org/pdf/2510.20739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20739]] Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages(https://arxiv.org/abs/2510.20739)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities? This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on this http URL packages and collect a benchmark of 1,883 this http URL packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.</li>
</ul>

<h3>Title: ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology</h3>
<ul>
<li><strong>Authors: </strong>Nima Torbati, Anastasia Meshcheryakova, Ramona Woitek, Diana Mechtcheriakova, Amirreza Mahbod</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20754">https://arxiv.org/abs/2510.20754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20754">https://arxiv.org/pdf/2510.20754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20754]] ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology(https://arxiv.org/abs/2510.20754)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\mu}IoU/{\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: this https URL</li>
</ul>

<h3>Title: DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Noam Issachar, Guy Yariv, Sagie Benaim, Yossi Adi, Dani Lischinski, Raanan Fattal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20766">https://arxiv.org/abs/2510.20766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20766">https://arxiv.org/pdf/2510.20766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20766]] DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion(https://arxiv.org/abs/2510.20766)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Diffusion Transformer models can generate images with remarkable fidelity and detail, yet training them at ultra-high resolutions remains extremely costly due to the self-attention mechanism's quadratic scaling with the number of image tokens. In this paper, we introduce Dynamic Position Extrapolation (DyPE), a novel, training-free method that enables pre-trained diffusion transformers to synthesize images at resolutions far beyond their training data, with no additional sampling cost. DyPE takes advantage of the spectral progression inherent to the diffusion process, where low-frequency structures converge early, while high-frequencies take more steps to resolve. Specifically, DyPE dynamically adjusts the model's positional encoding at each diffusion step, matching their frequency spectrum with the current stage of the generative process. This approach allows us to generate images at resolutions that exceed the training resolution dramatically, e.g., 16 million pixels using FLUX. On multiple benchmarks, DyPE consistently improves performance and achieves state-of-the-art fidelity in ultra-high-resolution image generation, with gains becoming even more pronounced at higher resolutions. Project page is available at this https URL.</li>
</ul>

<h3>Title: RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines</h3>
<ul>
<li><strong>Authors: </strong>Austin Jia, Avaneesh Ramesh, Zain Shamsi, Daniel Zhang, Alex Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20768">https://arxiv.org/abs/2510.20768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20768">https://arxiv.org/pdf/2510.20768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20768]] RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines(https://arxiv.org/abs/2510.20768)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as the dominant architectural pattern to operationalize Large Language Model (LLM) usage in Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to poisoning attacks, and previously proposed defenses can fail for CTI contexts as cyber threat information is often completely new for emerging attacks, and sophisticated threat actors can mimic legitimate formats, terminology, and stylistic conventions. To address this issue, we propose that the robustness of modern RAG defenses can be accelerated by applying source credibility algorithms on corpora, using PageRank as an example. In our experiments, we demonstrate quantitatively that our algorithm applies a lower authority score to malicious documents while promoting trusted content, using the standardized MS MARCO dataset. We also demonstrate proof-of-concept performance of our algorithm on CTI documents and feeds.</li>
</ul>

<h3>Title: AlphaFlow: Understanding and Improving MeanFlow Models</h3>
<ul>
<li><strong>Authors: </strong>Huijie Zhang, Aliaksandr Siarohin, Willi Menapace, Michael Vasilkovsky, Sergey Tulyakov, Qing Qu, Ivan Skorokhodov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20771">https://arxiv.org/abs/2510.20771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20771">https://arxiv.org/pdf/2510.20771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20771]] AlphaFlow: Understanding and Improving MeanFlow Models(https://arxiv.org/abs/2510.20771)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>MeanFlow has recently emerged as a powerful framework for few-step generative modeling trained from scratch, but its success is not yet fully understood. In this work, we show that the MeanFlow objective naturally decomposes into two parts: trajectory flow matching and trajectory consistency. Through gradient analysis, we find that these terms are strongly negatively correlated, causing optimization conflict and slow convergence. Motivated by these insights, we introduce $\alpha$-Flow, a broad family of objectives that unifies trajectory flow matching, Shortcut Model, and MeanFlow under one formulation. By adopting a curriculum strategy that smoothly anneals from trajectory flow matching to MeanFlow, $\alpha$-Flow disentangles the conflicting objectives, and achieves better convergence. When trained from scratch on class-conditional ImageNet-1K 256x256 with vanilla DiT backbones, $\alpha$-Flow consistently outperforms MeanFlow across scales and settings. Our largest $\alpha$-Flow-XL/2+ model achieves new state-of-the-art results using vanilla DiT backbones, with FID scores of 2.58 (1-NFE) and 2.15 (2-NFE).</li>
</ul>

<h3>Title: CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Binbin Huang, Haobin Duan, Yiqun Zhao, Zibo Zhao, Yi Ma, Shenghua Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20776">https://arxiv.org/abs/2510.20776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20776">https://arxiv.org/pdf/2510.20776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20776]] CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image(https://arxiv.org/abs/2510.20776)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>This work proposes a new generation-based 3D reconstruction method, named Cupid, that accurately infers the camera pose, 3D shape, and texture of an object from a single 2D image. Cupid casts 3D reconstruction as a conditional sampling process from a learned distribution of 3D objects, and it jointly generates voxels and pixel-voxel correspondences, enabling robust pose and shape estimation under a unified generative framework. By representing both input camera poses and 3D shape as a distribution in a shared 3D latent space, Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that produces initial 3D geometry with associated 2D projections for pose recovery; and (2) a refinement stage that integrates pose-aligned image features to enhance structural fidelity and appearance details. Extensive experiments demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3 dB PSNR gain and an over 10% Chamfer Distance reduction, while matching monocular estimators on pose accuracy and delivering superior visual fidelity over baseline 3D generative models. For an immersive view of the 3D results generated by Cupid, please visit this http URL.</li>
</ul>

<h3>Title: A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text</h3>
<ul>
<li><strong>Authors: </strong>Alicia Sagae, Chia-Jung Lee, Sandeep Avula, Brandon Dang, Vanessa Murdock</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20782">https://arxiv.org/abs/2510.20782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20782">https://arxiv.org/pdf/2510.20782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20782]] A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text(https://arxiv.org/abs/2510.20782)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair, large language model</a></li>
<li><strong>Abstract: </strong>Current methods for evaluating large language models (LLMs) typically focus on high-level tasks such as text generation, without targeting a particular AI application. This approach is not sufficient for evaluating LLMs for Responsible AI dimensions like fairness, since protected attributes that are highly relevant in one application may be less relevant in another. In this work, we construct a dataset that is driven by a real-world application (generate a plain-text product description, given a list of product features), parameterized by fairness attributes intersected with gendered adjectives and product categories, yielding a rich set of labeled prompts. We show how to use the data to identify quality, veracity, safety, and fairness gaps in LLMs, contributing a proposal for LLM evaluation paired with a concrete resource for the research community.</li>
</ul>

<h3>Title: Out-of-distribution Tests Reveal Compositionality in Chess Transformers</h3>
<ul>
<li><strong>Authors: </strong>Anna Mészáros, Patrik Reizinger, Ferenc Huszár</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20783">https://arxiv.org/abs/2510.20783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20783">https://arxiv.org/pdf/2510.20783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20783]] Out-of-distribution Tests Reveal Compositionality in Chess Transformers(https://arxiv.org/abs/2510.20783)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Chess is a canonical example of a task that requires rigorous reasoning and long-term planning. Modern decision Transformers - trained similarly to LLMs - are able to learn competent gameplay, but it is unclear to what extent they truly capture the rules of chess. To investigate this, we train a 270M parameter chess Transformer and test it on out-of-distribution scenarios, designed to reveal failures of systematic generalization. Our analysis shows that Transformers exhibit compositional generalization, as evidenced by strong rule extrapolation: they adhere to fundamental syntactic rules of the game by consistently choosing valid moves even in situations very different from the training data. Moreover, they also generate high-quality moves for OOD puzzles. In a more challenging test, we evaluate the models on variants including Chess960 (Fischer Random Chess) - a variant of chess where starting positions of pieces are randomized. We found that while the model exhibits basic strategy adaptation, they are inferior to symbolic AI algorithms that perform explicit search, but gap is smaller when playing against users on Lichess. Moreover, the training dynamics revealed that the model initially learns to move only its own pieces, suggesting an emergent compositional understanding of the game.</li>
</ul>

<h3>Title: Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction</h3>
<ul>
<li><strong>Authors: </strong>Mutian He, Philip N. Garner</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20787">https://arxiv.org/abs/2510.20787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20787">https://arxiv.org/pdf/2510.20787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20787]] Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction(https://arxiv.org/abs/2510.20787)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Linear-attention models that compress the entire input sequence into a fixed-size recurrent state offer an efficient alternative to Transformers, but their finite memory induces forgetfulness that harms retrieval-intensive tasks. To mitigate the issue, we explore a series of hybrid models that restore direct access to past tokens. We interleave token mixers with intermediate time and space complexity between linear and full attention, including sparse attention with token eviction, and the query-aware native sparse attention. Particularly, we propose a novel learnable token eviction approach. Combined with sliding-window attention, an end-to-end trainable lightweight CNN aggregates information from both past and future adjacent tokens to adaptively retain a limited set of critical KV-pairs per head, maintaining linear attention's constant time and space complexity. Efficient Triton kernels for the sparse attention mechanisms are provided. Empirical evaluations on retrieval-intensive benchmarks support the effectiveness of our approaches.</li>
</ul>

<h3>Title: BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Liang Ye, Shengqin Chen, Jiazhu Dai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20792">https://arxiv.org/abs/2510.20792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20792">https://arxiv.org/pdf/2510.20792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20792]] BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation(https://arxiv.org/abs/2510.20792)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, steal, diffusion</a></li>
<li><strong>Abstract: </strong>The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method targeting latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.</li>
</ul>

<h3>Title: Simple Context Compression: Mean-Pooling and Multi-Ratio Training</h3>
<ul>
<li><strong>Authors: </strong>Yair Feldman, Yoav Artzi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20797">https://arxiv.org/abs/2510.20797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20797">https://arxiv.org/pdf/2510.20797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20797]] Simple Context Compression: Mean-Pooling and Multi-Ratio Training(https://arxiv.org/abs/2510.20797)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean-pooling approach that consistently outperforms the widely used compression-tokens architecture, and study training the same compressor to output multiple compression ratios. We conduct extensive experiments across in-domain and out-of-domain QA datasets, as well as across model families, scales, and compression ratios. Overall, our simple mean-pooling approach achieves the strongest performance, with a relatively small drop when training for multiple compression ratios. More broadly though, across architectures and training regimes the trade-offs are more nuanced, illustrating the complex landscape of compression methods.</li>
</ul>

<h3>Title: Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples</h3>
<ul>
<li><strong>Authors: </strong>Shiva Sreeram, Alaa Maalouf, Pratyusha Sharma, Daniela Rus</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20800">https://arxiv.org/abs/2510.20800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20800">https://arxiv.org/pdf/2510.20800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20800]] Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples(https://arxiv.org/abs/2510.20800)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, Sharma et al. suggested a method called Layer-SElective-Rank reduction (LASER) which demonstrated that pruning high-order components of carefully chosen LLM's weight matrices can boost downstream accuracy -- without any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each requiring full-dataset forward passes) makes it impractical for rapid deployment. We demonstrate that this overhead can be removed and find that: (i) Only a small, carefully chosen subset of matrices needs to be inspected -- eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's singular values pinpoints which matrices merit reduction, (iii) Increasing the factorization search space by allowing matrices rows to cluster around multiple subspaces and then decomposing each cluster separately further reduces overfitting on the original training data and further lifts accuracy by up to 24.6 percentage points, and finally, (iv) we discover that evaluating on just 100 samples rather than the full training data -- both for computing the indicative gradients and for measuring the final accuracy -- suffices to further reduce the search time; we explain that as adaptation to downstream tasks is dominated by prompting style, not dataset size. As a result, we show that combining these findings yields a fast and robust adaptation algorithm for downstream tasks. Overall, with a single gradient step on 100 examples and a quick scan of the top candidate layers and factorization techniques, we can adapt LLMs to new datasets -- entirely without fine-tuning.</li>
</ul>

<h3>Title: ARGenSeg: Image Segmentation with Autoregressive Image Generation Model</h3>
<ul>
<li><strong>Authors: </strong>Xiaolong Wang, Lixiang Ru, Ziyuan Huang, Kaixiang Ji, Dandan Zheng, Jingdong Chen, Jun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20803">https://arxiv.org/abs/2510.20803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20803">https://arxiv.org/pdf/2510.20803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20803]] ARGenSeg: Image Segmentation with Autoregressive Image Generation Model(https://arxiv.org/abs/2510.20803)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>We propose a novel AutoRegressive Generation-based paradigm for image Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level perception within a unified framework. Prior works integrating image segmentation into multimodal large language models (MLLMs) typically employ either boundary points representation or dedicated segmentation heads. These methods rely on discrete representations or semantic prompts fed into task-specific decoders, which limits the ability of the MLLM to capture fine-grained visual details. To address these challenges, we introduce a segmentation framework for MLLM based on image generation, which naturally produces dense masks for target objects. We leverage MLLM to output visual tokens and detokenize them into images using an universal VQ-VAE, making the segmentation fully dependent on the pixel-level understanding of the MLLM. To reduce inference latency, we employ a next-scale-prediction strategy to generate required visual tokens in parallel. Extensive experiments demonstrate that our method surpasses prior state-of-the-art approaches on multiple segmentation datasets with a remarkable boost in inference speed, while maintaining strong understanding capabilities.</li>
</ul>

<h3>Title: Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers</h3>
<ul>
<li><strong>Authors: </strong>Dean L Slack, G Thomas Hudson, Thomas Winterbottom, Noura Al Moubayed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20807">https://arxiv.org/abs/2510.20807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20807">https://arxiv.org/pdf/2510.20807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20807]] Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers(https://arxiv.org/abs/2510.20807)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.</li>
</ul>

<h3>Title: On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?</h3>
<ul>
<li><strong>Authors: </strong>Mingmeng Geng, Thierry Poibeau</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20810">https://arxiv.org/abs/2510.20810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20810">https://arxiv.org/pdf/2510.20810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20810]] On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?(https://arxiv.org/abs/2510.20810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the widespread use of large language models (LLMs), many researchers have turned their attention to detecting text generated by them. However, there is no consistent or precise definition of their target, namely "LLM-generated text". Differences in usage scenarios and the diversity of LLMs further increase the difficulty of detection. What is commonly regarded as the detecting target usually represents only a subset of the text that LLMs can potentially produce. Human edits to LLM outputs, together with the subtle influences that LLMs exert on their users, are blurring the line between LLM-generated and human-written text. Existing benchmarks and evaluation approaches do not adequately address the various conditions in real-world detector applications. Hence, the numerical results of detectors are often misunderstood, and their significance is diminishing. Therefore, detectors remain useful under specific conditions, but their results should be interpreted only as references rather than decisive indicators.</li>
</ul>

<h3>Title: SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Ritik Shah, Marco F Duarte</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20814">https://arxiv.org/abs/2510.20814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20814">https://arxiv.org/pdf/2510.20814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20814]] SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution(https://arxiv.org/abs/2510.20814)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Hyperspectral sensors capture dense spectra per pixel but suffer from low spatial resolution, causing blurred boundaries and mixed-pixel effects. Co-registered companion sensors such as multispectral, RGB, or panchromatic cameras provide high-resolution spatial detail, motivating hyperspectral super-resolution through the fusion of hyperspectral and multispectral images (HSI-MSI). Existing deep learning based methods achieve strong performance but rely on opaque regressors that lack interpretability and often fail when the MSI has very few bands. We propose SpectraMorph, a physics-guided self-supervised fusion framework with a structured latent space. Instead of direct regression, SpectraMorph enforces an unmixing bottleneck: endmember signatures are extracted from the low-resolution HSI, and a compact multilayer perceptron predicts abundance-like maps from the MSI. Spectra are reconstructed by linear mixing, with training performed in a self-supervised manner via the MSI sensor's spectral response function. SpectraMorph produces interpretable intermediates, trains in under a minute, and remains robust even with a single-band (pan-chromatic) MSI. Experiments on synthetic and real-world datasets show SpectraMorph consistently outperforming state-of-the-art unsupervised/self-supervised baselines while remaining very competitive against supervised baselines.</li>
</ul>

<h3>Title: KL-Regularized Reinforcement Learning is Designed to Mode Collapse</h3>
<ul>
<li><strong>Authors: </strong>Anthony GX-Chen, Jatin Prakash, Jeff Guo, Rob Fergus, Rajesh Ranganath</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20817">https://arxiv.org/abs/2510.20817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20817">https://arxiv.org/pdf/2510.20817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20817]] KL-Regularized Reinforcement Learning is Designed to Mode Collapse(https://arxiv.org/abs/2510.20817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>It is commonly believed that optimizing the reverse KL divergence results in "mode seeking", while optimizing forward KL results in "mass covering", with the latter being preferred if the goal is to sample from multiple diverse modes. We show -- mathematically and empirically -- that this intuition does not necessarily transfer well to doing reinforcement learning with reverse/forward KL regularization (e.g. as commonly used with language models). Instead, the choice of reverse/forward KL determines the family of optimal target distributions, parameterized by the regularization coefficient. Mode coverage depends primarily on other factors, such as regularization strength, and relative scales between rewards and reference probabilities. Further, we show commonly used settings such as low regularization strength and equal verifiable rewards tend to specify unimodal target distributions, meaning the optimization objective is, by construction, non-diverse. We leverage these insights to construct a simple, scalable, and theoretically justified algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a target distribution which puts high probability over all high-quality sampling modes. In experiments, this simple modification works to post-train both Large Language Models and Chemical Language Models to have higher solution quality and diversity, without any external signals of diversity, and works with both forward and reverse KL when using either naively fails.</li>
</ul>

<h3>Title: Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge</h3>
<ul>
<li><strong>Authors: </strong>Nimrod Berman, Omkar Joglekar, Eitan Kosman, Dotan Di Castro, Omri Azencot</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20819">https://arxiv.org/abs/2510.20819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20819">https://arxiv.org/pdf/2510.20819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20819]] Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge(https://arxiv.org/abs/2510.20819)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: this https URL.</li>
</ul>

<h3>Title: LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas</h3>
<ul>
<li><strong>Authors: </strong>Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva, Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong, Arpit Sahni, Daniil Ostashev, Ju Hu, Sergey Tulyakov, Kuan-Chieh Jackson Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.20820">https://arxiv.org/abs/2510.20820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.20820">https://arxiv.org/pdf/2510.20820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.20820]] LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas(https://arxiv.org/abs/2510.20820)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Despite their impressive visual fidelity, existing personalized generative models lack interactive control over spatial composition and scale poorly to multiple subjects. To address these limitations, we present LayerComposer, an interactive framework for personalized, multi-subject text-to-image generation. Our approach introduces two main contributions: (1) a layered canvas, a novel representation in which each subject is placed on a distinct layer, enabling occlusion-free composition; and (2) a locking mechanism that preserves selected layers with high fidelity while allowing the remaining layers to adapt flexibly to the surrounding context. Similar to professional image-editing software, the proposed layered canvas allows users to place, resize, or lock input subjects through intuitive layer manipulation. Our versatile locking mechanism requires no architectural changes, relying instead on inherent positional embeddings combined with a new complementary data sampling strategy. Extensive experiments demonstrate that LayerComposer achieves superior spatial control and identity preservation compared to the state-of-the-art methods in multi-subject personalized image generation.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
