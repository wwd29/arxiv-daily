<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-06-10</h1>
<h3>Title: Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow</h3>
<ul>
<li><strong>Authors: </strong>Juexiao Zhou, Zhongyi Han, Mankun Xin, Xingwei He, Guotao Wang, Jiaoyan Song, Gongning Luo, Wenjia He, Xintong Li, Yuetan Chu, Juanwen Chen, Bo Wang, Xia Wu, Wenwen Duan, Zhixia Guo, Liyan Bai, Yilin Pan, Xuefei Bi, Lu Liu, Long Feng, Xiaonan He, Xin Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06283">https://arxiv.org/abs/2506.06283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06283">https://arxiv.org/pdf/2506.06283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06283]] Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow(https://arxiv.org/abs/2506.06283)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Global population aging presents increasing challenges to healthcare systems, with coronary artery disease (CAD) responsible for approximately 17.8 million deaths annually, making it a leading cause of global mortality. As CAD is largely preventable, early detection and proactive management are essential. In this work, we introduce DigitalShadow, an advanced early warning system for CAD, powered by a fine-tuned facial foundation model. The system is pre-trained on 21 million facial images and subsequently fine-tuned into LiveCAD, a specialized CAD risk assessment model trained on 7,004 facial images from 1,751 subjects across four hospitals in China. DigitalShadow functions passively and contactlessly, extracting facial features from live video streams without requiring active user engagement. Integrated with a personalized database, it generates natural language risk reports and individualized health recommendations. With privacy as a core design principle, DigitalShadow supports local deployment to ensure secure handling of user data.</li>
</ul>

<h3>Title: Mutual-Taught for Co-adapting Policy and Reward Models</h3>
<ul>
<li><strong>Authors: </strong>Tianyuan Shi, Canbin Huang, Fanqi Wan, Longguang Zhong, Ziyi Yang, Weizhou Shen, Xiaojun Quan, Ming Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06292">https://arxiv.org/abs/2506.06292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06292">https://arxiv.org/pdf/2506.06292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06292]] Mutual-Taught for Co-adapting Policy and Reward Models(https://arxiv.org/abs/2506.06292)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>During the preference optimization of large language models (LLMs), distribution shifts may arise between newly generated model samples and the data used to train the reward model (RM). This shift reduces the efficacy of the RM, which in turn negatively impacts the performance of the policy model (PM). To address this challenge, we propose Mutual-Taught, a self-training method that iteratively improves both the PM and RM without requiring additional human annotation. Our approach mirrors the expectation-maximization (EM) algorithm. In the E-step, the PM is updated using feedback from the current RM, guiding the PM toward a better approximation of the latent optimal preference distribution. In the M-step, we update the RM by constructing training data from the outputs of the PM before and after the E-step update. This process ensures that the RM adapts to the evolving policy distribution. Experimental results demonstrate that this iterative approach leads to consistent improvements in both models. Specifically, our 8B policy model, LLaMA-3-8B-Instruct-MT, achieves a length-controlled win rate of 54.1\% on AlpacaEval-2, while our 8B reward model, FsfairX-LLaMA3-RM-MT, performs on par with GPT-4o-2024-08-06 on RewardBench.</li>
</ul>

<h3>Title: Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Junyi Liu, Stanley Kok</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06293">https://arxiv.org/abs/2506.06293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06293">https://arxiv.org/pdf/2506.06293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06293]] Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks(https://arxiv.org/abs/2506.06293)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Agencies such as Standard & Poor's and Moody's provide bank credit ratings that influence economic stability and decision-making by stakeholders. Accurate and timely predictions support informed decision-making, regulatory actions, and investor protection. However, a complete interbank connection graph is often unavailable due to privacy concerns, complicating the direct application of Graph Neural Networks (GNNs) for rating prediction. our research utilizes persistent homology to construct a network that captures relationships among banks and combines this with a traditional lending network to create a heterogeneous network that integrates information from both sources, leading to improved predictions. Experiments on a global, real-world dataset validate the effectiveness of HTGNN. This research has implications for investors and regulatory bodies in enhancing proactive risk mitigation and the implementation of effective market this http URL code can be find at this https URL.</li>
</ul>

<h3>Title: dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Liu, Yicun Yang, Yaojie Zhang, Junjie Chen, Chang Zou, Qingyuan Wei, Shaobo Wang, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06295">https://arxiv.org/abs/2506.06295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06295">https://arxiv.org/pdf/2506.06295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06295]] dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching(https://arxiv.org/abs/2506.06295)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Autoregressive Models (ARMs) have long dominated the landscape of Large Language Models. Recently, a new paradigm has emerged in the form of diffusion-based Large Language Models (dLLMs), which generate text by iteratively denoising masked segments. This approach has shown significant advantages and potential. However, dLLMs suffer from high inference latency. Traditional ARM acceleration techniques, such as Key-Value caching, are incompatible with dLLMs due to their bidirectional attention mechanism. To address this specific challenge, our work begins with a key observation that dLLM inference involves a static prompt and a partially dynamic response, where most tokens remain stable across adjacent denoising steps. Based on this, we propose dLLM-Cache, a training-free adaptive caching framework that combines long-interval prompt caching with partial response updates guided by feature similarity. This design enables efficient reuse of intermediate computations without compromising model performance. Extensive experiments on representative dLLMs, including LLaDA 8B and Dream 7B, show that dLLM-Cache achieves up to 9.1 x speedup over standard inference without compromising output quality. Notably, our method brings dLLM inference latency close to that of ARMs under many settings. Codes are provided in the supplementary material and will be released publicly on GitHub.</li>
</ul>

<h3>Title: LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yuanye Zhou, Zhaokun Wang, Kai Zhou, Hui Tang, Xiaofan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06300">https://arxiv.org/abs/2506.06300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06300">https://arxiv.org/pdf/2506.06300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06300]] LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization(https://arxiv.org/abs/2506.06300)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-informed neural networks (PINNs) have emerged as a powerful meshless tool for topology optimization, capable of simultaneously determining optimal topologies and physical solutions. However, conventional PINNs rely on density-based topology descriptions, which necessitate manual interpolation and limit their applicability to complex geometries. To address this, we propose Lagrangian topology-conscious PINNs (LT-PINNs), a novel framework for boundary-focused engineering optimization. By parameterizing the control variables of topology boundary curves as learnable parameters, LT-PINNs eliminate the need for manual interpolation and enable precise boundary determination. We further introduce specialized boundary condition loss function and topology loss function to ensure sharp and accurate boundary representations, even for intricate topologies. The accuracy and robustness of LT-PINNs are validated via two types of partial differential equations (PDEs), including elastic equation with Dirichlet boundary conditions and Laplace's equation with Neumann boundary conditions. Furthermore, we demonstrate effectiveness of LT-PINNs on more complex time-dependent and time-independent flow problems without relying on measurement data, and showcase their engineering application potential in flow velocity rearrangement, transforming a uniform upstream velocity into a sine-shaped downstream profile. The results demonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors compared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2) LT-PINNs can handle arbitrary boundary conditions, making them suitable for a wide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries without manual interpolation, especially for complex topologies.</li>
</ul>

<h3>Title: Reward Is Enough: LLMs Are In-Context Reinforcement Learners</h3>
<ul>
<li><strong>Authors: </strong>Kefan Song, Amir Moeini, Peng Wang, Lei Gong, Rohan Chandra, Yanjun Qi, Shangtong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06303">https://arxiv.org/abs/2506.06303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06303">https://arxiv.org/pdf/2506.06303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06303]] Reward Is Enough: LLMs Are In-Context Reinforcement Learners(https://arxiv.org/abs/2506.06303)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) is a human-designed framework for solving sequential decision making problems. In this work, we demonstrate that, surprisingly, RL emerges in LLM's (Large Language Model) inference time -- a phenomenon known as in-context RL (ICRL). Specifically, we propose a novel multi-round prompting framework called ICRL prompting. The goal is to prompt the LLM to complete a task. After the LLM generates a response at the current round, we give numerical scalar feedbacks for the response, called the rewards. At the next round, we prompt the LLM again with the same task and a context consisting of all previous responses and rewards. We observe that the quality of the LLM's response increases as the context grows. In other words, the LLM is able to maximize the scalar reward signal in the inference time, just like an RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24, creative writing, and ScienceWorld) and demonstrate significant performance improvements over baseline methods such as Self-Refine and Reflexion. Surprisingly, in some experiments the reward signals are generated by the LLM itself, yet performance improvements are still observed from ICRL prompting, offering a promising paradigm for scaling test-time compute.</li>
</ul>

<h3>Title: ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications</h3>
<ul>
<li><strong>Authors: </strong>James Afful</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06330">https://arxiv.org/abs/2506.06330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06330">https://arxiv.org/pdf/2506.06330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06330]] ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications(https://arxiv.org/abs/2506.06330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>As machine learning systems are increasingly deployed in high-stakes domains such as criminal justice, finance, and healthcare, the demand for interpretable and trustworthy models has intensified. Despite the proliferation of local explanation techniques, including SHAP, LIME, and counterfactual methods, there exists no standardized, reproducible framework for their comparative evaluation, particularly in fairness-sensitive settings. We introduce ExplainBench, an open-source benchmarking suite for systematic evaluation of local model explanations across ethically consequential datasets. ExplainBench provides unified wrappers for popular explanation algorithms, integrates end-to-end pipelines for model training and explanation generation, and supports evaluation via fidelity, sparsity, and robustness metrics. The framework includes a Streamlit-based graphical interface for interactive exploration and is packaged as a Python module for seamless integration into research workflows. We demonstrate ExplainBench on datasets commonly used in fairness research, such as COMPAS, UCI Adult Income, and LendingClub, and showcase how different explanation methods behave under a shared experimental protocol. By enabling reproducible, comparative analysis of local explanations, ExplainBench advances the methodological foundations of interpretable machine learning and facilitates accountability in real-world AI systems.</li>
</ul>

<h3>Title: How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG</h3>
<ul>
<li><strong>Authors: </strong>Qiming Zeng, Xiao Yan, Hao Luo, Yuhao Lin, Yuxiang Wang, Fangcheng Fu, Bo Du, Quanqing Xu, Jiawei Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06331">https://arxiv.org/abs/2506.06331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06331">https://arxiv.org/pdf/2506.06331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06331]] How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG(https://arxiv.org/abs/2506.06331)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>By retrieving contexts from knowledge graphs, graph-based retrieval-augmented generation (GraphRAG) enhances large language models (LLMs) to generate quality answers for user questions. Many GraphRAG methods have been proposed and reported inspiring performance in answer quality. However, we observe that the current answer evaluation framework for GraphRAG has two critical flaws, i.e., unrelated questions and evaluation biases, which may lead to biased or even wrong conclusions on performance. To tackle the two flaws, we propose an unbiased evaluation framework that uses graph-text-grounded question generation to produce questions that are more related to the underlying dataset and an unbiased evaluation procedure to eliminate the biases in LLM-based answer assessment. We apply our unbiased framework to evaluate 3 representative GraphRAG methods and find that their performance gains are much more moderate than reported previously. Although our evaluation framework may still have flaws, it calls for scientific evaluations to lay solid foundations for GraphRAG research.</li>
</ul>

<h3>Title: Optimized Local Updates in Federated Learning via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ali Murad, Bo Hui, Wei-Shinn Ku</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06337">https://arxiv.org/abs/2506.06337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06337">https://arxiv.org/pdf/2506.06337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06337]] Optimized Local Updates in Federated Learning via Reinforcement Learning(https://arxiv.org/abs/2506.06337)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a distributed framework for collaborative model training over large-scale distributed data, enabling higher performance while maintaining client data privacy. However, the nature of model aggregation at the centralized server can result in a performance drop in the presence of non-IID data across different clients. We remark that training a client locally on more data than necessary does not benefit the overall performance of all clients. In this paper, we devise a novel framework that leverages a Deep Reinforcement Learning (DRL) agent to select an optimized amount of data necessary to train a client model without oversharing information with the server. Starting without awareness of the client's performance, the DRL agent utilizes the change in training loss as a reward signal and learns to optimize the amount of training data necessary for improving the client's performance. Specifically, after each aggregation round, the DRL algorithm considers the local performance as the current state and outputs the optimized weights for each class, in the training data, to be used during the next round of local training. In doing so, the agent learns a policy that creates an optimized partition of the local training dataset during the FL rounds. After FL, the client utilizes the entire local training dataset to further enhance its performance on its own data distribution, mitigating the non-IID effects of aggregation. Through extensive experiments, we demonstrate that training FL clients through our algorithm results in superior performance on multiple benchmark datasets and FL frameworks. Our code is available at this https URL.</li>
</ul>

<h3>Title: From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Antonesi, Tudor Cioara, Ionut Anghel, Vasilis Michalakopoulos, Elissaios Sarmas, Liana Toderean</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06359">https://arxiv.org/abs/2506.06359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06359">https://arxiv.org/pdf/2506.06359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06359]] From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins(https://arxiv.org/abs/2506.06359)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Artificial intelligence (AI) has long promised to improve energy management in smart grids by enhancing situational awareness and supporting more effective decision-making. While traditional machine learning has demonstrated notable results in forecasting and optimization, it often struggles with generalization, situational awareness, and heterogeneous data integration. Recent advances in foundation models such as Transformer architecture and Large Language Models (LLMs) have demonstrated improved capabilities in modelling complex temporal and contextual relationships, as well as in multi-modal data fusion which is essential for most AI applications in the energy sector. In this review we synthesize the rapid expanding field of AI applications in the energy domain focusing on Transformers and LLMs. We examine the architectural foundations, domain-specific adaptations and practical implementations of transformer models across various forecasting and grid management tasks. We then explore the emerging role of LLMs in the field: adaptation and fine tuning for the energy sector, the type of tasks they are suited for, and the new challenges they introduce. Along the way, we highlight practical implementations, innovations, and areas where the research frontier is rapidly expanding. These recent developments reviewed underscore a broader trend: Generative AI (GenAI) is beginning to augment decision-making not only in high-level planning but also in day-to-day operations, from forecasting and grid balancing to workforce training and asset onboarding. Building on these developments, we introduce the concept of the Agentic Digital Twin, a next-generation model that integrates LLMs to bring autonomy, proactivity, and social interaction into digital twin-based energy management systems.</li>
</ul>

<h3>Title: Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Panagiotis Koletsis, Christos Panagiotopoulos, Georgios Th. Papadopoulos, Vasilis Efthymiou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06371">https://arxiv.org/abs/2506.06371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06371">https://arxiv.org/pdf/2506.06371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06371]] Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models(https://arxiv.org/abs/2506.06371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Over the past few years, table interpretation tasks have made significant progress due to their importance and the introduction of new technologies and benchmarks in the field. This work experiments with a hybrid approach for detecting relationships among columns of unlabeled tabular data, using a Knowledge Graph (KG) as a reference point, a task known as CPA. This approach leverages large language models (LLMs) while employing statistical analysis to reduce the search space of potential KG relations. The main modules of this approach for reducing the search space are domain and range constraints detection, as well as relation co-appearance analysis. The experimental evaluation on two benchmark datasets provided by the SemTab challenge assesses the influence of each module and the effectiveness of different state-of-the-art LLMs at various levels of quantization. The experiments were performed, as well as at different prompting techniques. The proposed methodology, which is publicly available on github, proved to be competitive with state-of-the-art approaches on these datasets.</li>
</ul>

<h3>Title: Enhancing Decision-Making of Large Language Models via Actor-Critic</h3>
<ul>
<li><strong>Authors: </strong>Heng Dong, Kefei Duan, Chongjie Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06376">https://arxiv.org/abs/2506.06376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06376">https://arxiv.org/pdf/2506.06376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06376]] Enhancing Decision-Making of Large Language Models via Actor-Critic(https://arxiv.org/abs/2506.06376)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable advancements in natural language processing tasks, yet they encounter challenges in complex decision-making scenarios that require long-term reasoning and alignment with high-level objectives. Existing methods either rely on short-term auto-regressive action generation or face limitations in accurately simulating rollouts and assessing outcomes, leading to sub-optimal decisions. This paper introduces a novel LLM-based Actor-Critic framework, termed LAC, that effectively improves LLM policies with long-term action evaluations in a principled and scalable way. Our approach addresses two key challenges: (1) extracting robust action evaluations by computing Q-values via token logits associated with positive/negative outcomes, enhanced by future trajectory rollouts and reasoning; and (2) enabling efficient policy improvement through a gradient-free mechanism. Experiments across diverse environments -- including high-level decision-making (ALFWorld), low-level action spaces (BabyAI-Text), and large action spaces (WebShop) -- demonstrate the framework's generality and superiority over state-of-the-art methods. Notably, our approach achieves competitive performance using 7B/8B parameter LLMs, even outperforming baseline methods employing GPT-4 in complex tasks. These results underscore the potential of integrating structured policy optimization with LLMs' intrinsic knowledge to advance decision-making capabilities in multi-step environments.</li>
</ul>

<h3>Title: Beyond the Norm: A Survey of Synthetic Data Generation for Rare Events</h3>
<ul>
<li><strong>Authors: </strong>Jingyi Gu, Xuan Zhang, Guiling Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06380">https://arxiv.org/abs/2506.06380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06380">https://arxiv.org/pdf/2506.06380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06380]] Beyond the Norm: A Survey of Synthetic Data Generation for Rare Events(https://arxiv.org/abs/2506.06380)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative, large language model</a></li>
<li><strong>Abstract: </strong>Extreme events, such as market crashes, natural disasters, and pandemics, are rare but catastrophic, often triggering cascading failures across interconnected systems. Accurate prediction and early warning can help minimize losses and improve preparedness. While data-driven methods offer powerful capabilities for extreme event modeling, they require abundant training data, yet extreme event data is inherently scarce, creating a fundamental challenge. Synthetic data generation has emerged as a powerful solution. However, existing surveys focus on general data with privacy preservation emphasis, rather than extreme events' unique performance requirements. This survey provides the first overview of synthetic data generation for extreme events. We systematically review generative modeling techniques and large language models, particularly those enhanced by statistical theory as well as specialized training and sampling mechanisms to capture heavy-tailed distributions. We summarize benchmark datasets and introduce a tailored evaluation framework covering statistical, dependence, visual, and task-oriented metrics. A central contribution is our in-depth analysis of each metric's applicability in extremeness and domain-specific adaptations, providing actionable guidance for model evaluation in extreme settings. We categorize key application domains and identify underexplored areas like behavioral finance, wildfires, earthquakes, windstorms, and infectious outbreaks. Finally, we outline open challenges, providing a structured foundation for advancing synthetic rare-event research.</li>
</ul>

<h3>Title: Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering</h3>
<ul>
<li><strong>Authors: </strong>Yi Ji, Runzhi Li, Baolei Mao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06384">https://arxiv.org/abs/2506.06384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06384">https://arxiv.org/pdf/2506.06384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06384]] Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering(https://arxiv.org/abs/2506.06384)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the widespread adoption of Large Language Models (LLMs), prompt injection attacks have emerged as a significant security threat. Existing defense mechanisms often face critical trade-offs between effectiveness and generalizability. This highlights the urgent need for efficient prompt injection detection methods that are applicable across a wide range of LLMs. To address this challenge, we propose DMPI-PMHFE, a dual-channel feature fusion detection framework. It integrates a pretrained language model with heuristic feature engineering to detect prompt injection attacks. Specifically, the framework employs DeBERTa-v3-base as a feature extractor to transform input text into semantic vectors enriched with contextual information. In parallel, we design heuristic rules based on known attack patterns to extract explicit structural features commonly observed in attacks. Features from both channels are subsequently fused and passed through a fully connected neural network to produce the final prediction. This dual-channel approach mitigates the limitations of relying only on DeBERTa to extract features. Experimental results on diverse benchmark datasets demonstrate that DMPI-PMHFE outperforms existing methods in terms of accuracy, recall, and F1-score. Furthermore, when deployed actually, it significantly reduces attack success rates across mainstream LLMs, including GLM-4, LLaMA 3, Qwen 2.5, and GPT-4o.</li>
</ul>

<h3>Title: Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images</h3>
<ul>
<li><strong>Authors: </strong>Rifat Sadik, Tanvir Rahman, Arpan Bhattacharjee, Bikash Chandra Halder, Ismail Hossain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06389">https://arxiv.org/abs/2506.06389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06389">https://arxiv.org/pdf/2506.06389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06389]] Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images(https://arxiv.org/abs/2506.06389)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, watermark, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning models have shown remarkable success in dermatological image analysis, offering potential for automated skin disease diagnosis. Previously, convolutional neural network(CNN) based architectures have achieved immense popularity and success in computer vision (CV) based task like skin image recognition, generation and video analysis. But with the emergence of transformer based models, CV tasks are now are nowadays carrying out using these models. Vision Transformers (ViTs) is such a transformer-based models that have shown success in computer vision. It uses self-attention mechanisms to achieve state-of-the-art performance across various tasks. However, their reliance on global attention mechanisms makes them susceptible to adversarial perturbations. This paper aims to investigate the susceptibility of ViTs for medical images to adversarial watermarking-a method that adds so-called imperceptible perturbations in order to fool models. By generating adversarial watermarks through Projected Gradient Descent (PGD), we examine the transferability of such attacks to CNNs and analyze the performance defense mechanism -- adversarial training. Results indicate that while performance is not compromised for clean images, ViTs certainly become much more vulnerable to adversarial attacks: an accuracy drop of as low as 27.6%. Nevertheless, adversarial training raises it up to 90.0%.</li>
</ul>

<h3>Title: Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pengyi Li, Matvey Skripkin, Alexander Zubrey, Andrey Kuznetsov, Ivan Oseledets</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06395">https://arxiv.org/abs/2506.06395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06395">https://arxiv.org/pdf/2506.06395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06395]] Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models(https://arxiv.org/abs/2506.06395)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at reasoning, yet post-training remains critical for aligning their behavior with task goals. Existing reinforcement learning (RL) methods often depend on costly human annotations or external reward models. We propose Reinforcement Learning via Self-Confidence (RLSC), which uses the model's own confidence as reward signals-eliminating the need for labels, preference models, or reward engineering. Applied to Qwen2.5-Math-7B with only 8 samples per question and 4 training epochs, RLSC improves accuracy by +20.10% on AIME2024, +49.40% on MATH500, and +52.50% on AMC23. RLSC offers a simple, scalable post-training method for reasoning models with minimal supervision.</li>
</ul>

<h3>Title: Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things</h3>
<ul>
<li><strong>Authors: </strong>Christopher D. Molek, Roberto Fronteddu, K. Brent Venable, Niranjan Suri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06396">https://arxiv.org/abs/2506.06396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06396">https://arxiv.org/pdf/2506.06396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06396]] Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things(https://arxiv.org/abs/2506.06396)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The expansion of the Internet of Things (IoT) in the battlefield, Internet of Battlefield Things (IoBT), gives rise to new opportunities for enhancing situational awareness. To increase the potential of IoBT for situational awareness in critical decision making, the data from these devices must be processed into consumer-ready information objects, and made available to consumers on demand. To address this challenge we propose a workflow that makes use of natural language processing (NLP) to query a database technology and return a response in natural language. Our solution utilizes Large Language Models (LLMs) that are sized for edge devices to perform NLP as well as graphical databases which are well suited for dynamic connected networks which are pervasive in the IoBT. Our architecture employs LLMs for both mapping questions in natural language to Cypher database queries as well as to summarize the database output back to the user in natural language. We evaluate several medium sized LLMs for both of these tasks on a database representing publicly available data from the US Army's Multipurpose Sensing Area (MSA) at the Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion parameters) outperforms the other models across all the considered metrics. Most importantly, we note that, unlike current methods, our two step approach allows the relaxation of the Exact Match (EM) requirement of the produced Cypher queries with ground truth code and, in this way, it achieves a 19.4% increase in accuracy. Our workflow lays the ground work for deploying LLMs on edge devices to enable natural language interactions with databases containing information objects for critical decision making.</li>
</ul>

<h3>Title: Theoretical Analysis of Positional Encodings in Transformer Models: Impact on Expressiveness and Generalization</h3>
<ul>
<li><strong>Authors: </strong>Yin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06398">https://arxiv.org/abs/2506.06398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06398">https://arxiv.org/pdf/2506.06398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06398]] Theoretical Analysis of Positional Encodings in Transformer Models: Impact on Expressiveness and Generalization(https://arxiv.org/abs/2506.06398)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Positional encodings are a core part of transformer-based models, enabling processing of sequential data without recurrence. This paper presents a theoretical framework to analyze how various positional encoding methods, including sinusoidal, learned, relative, and bias-based methods like Attention with Linear Biases (ALiBi), impact a transformer's expressiveness, generalization ability, and extrapolation to longer sequences. Expressiveness is defined via function approximation, generalization bounds are established using Rademacher complexity, and new encoding methods based on orthogonal functions, such as wavelets and Legendre polynomials, are proposed. The extrapolation capacity of existing and proposed encodings is analyzed, extending ALiBi's biasing approach to a unified theoretical context. Experimental evaluation on synthetic sequence-to-sequence tasks shows that orthogonal transform-based encodings outperform traditional sinusoidal encodings in generalization and extrapolation. This work addresses a critical gap in transformer theory, providing insights for design choices in natural language processing, computer vision, and other transformer applications.</li>
</ul>

<h3>Title: Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hongming Yang, Shi Lin, Jun Shao, Changting Lin, Donghai Zhu, Meng Han, Qinglei Kong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06401">https://arxiv.org/abs/2506.06401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06401">https://arxiv.org/pdf/2506.06401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06401]] Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs(https://arxiv.org/abs/2506.06401)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized models designed to run efficiently on consumer-grade hardware, offering significant advantages in resource efficiency, cost-effectiveness, and data privacy. However, these models often struggle with limited inference and reasoning capabilities, which restrict their performance on complex tasks and limit their practical applicability. Moreover, existing prompt optimization methods typically rely on extensive manual effort or the meta-cognitive abilities of state-of-the-art LLMs, making them less effective for LwLLMs. To address these challenges, we introduce DeBoP, a new Direct Behavior Optimization Paradigm, original from the Chain-of-Thought (CoT) prompting technique. Unlike CoT Prompting, DeBoP is an automatic optimization method, which focuses on the optimization directly on the behavior of LwLLMs. In particular, DeBoP transforms the optimization of complex prompts into the optimization of discrete, quantifiable execution sequences using a gradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging tasks where state-of-the-art LLMs excel but LwLLMs generally underperform. Experimental results demonstrate that DeBoP significantly outperforms recent prompt optimization methods on most tasks. In particular, DeBoP-optimized LwLLMs surpass GPT-3.5 on most tasks while reducing computational time by approximately 60% compared to other automatic prompt optimization methods.</li>
</ul>

<h3>Title: Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights</h3>
<ul>
<li><strong>Authors: </strong>Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06404">https://arxiv.org/abs/2506.06404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06404">https://arxiv.org/pdf/2506.06404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06404]] Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights(https://arxiv.org/abs/2506.06404)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The application scope of Large Language Models (LLMs) continues to expand, leading to increasing interest in personalized LLMs that align with human values. However, aligning these models with individual values raises significant safety concerns, as certain values may correlate with harmful information. In this paper, we identify specific safety risks associated with value-aligned LLMs and investigate the psychological principles behind these challenges. Our findings reveal two key insights. (1) Value-aligned LLMs are more prone to harmful behavior compared to non-fine-tuned models and exhibit slightly higher risks in traditional safety evaluations than other fine-tuned models. (2) These safety issues arise because value-aligned LLMs genuinely generate text according to the aligned values, which can amplify harmful outcomes. Using a dataset with detailed safety categories, we find significant correlations between value alignment and safety risks, supported by psychological hypotheses. This study offers insights into the "black box" of value alignment and proposes in-context alignment methods to enhance the safety of value-aligned LLMs.</li>
</ul>

<h3>Title: SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Guoyang Xia, Yifeng Ding, Fengfa Li, Lei Ren, Chen Wei, Fangxiang Feng, Xiaojie Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06406">https://arxiv.org/abs/2506.06406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06406">https://arxiv.org/pdf/2506.06406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06406]] SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities(https://arxiv.org/abs/2506.06406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoE) architectures have become a key approach for scaling large language models, with growing interest in extending them to multimodal tasks. Existing methods to build multimodal MoE models either incur high training costs or suffer from degraded language capabilities when adapting pretrained models. To address this, we propose Soft ModalityAware Routing (SMAR), a novel regularization technique that uses Kullback Leibler divergence to control routing probability distributions across modalities, encouraging expert specialization without modifying model architecture or heavily relying on textual data. Experiments on visual instruction tuning show that SMAR preserves language ability at 86.6% retention with only 2.5% pure text, outperforming baselines while maintaining strong multimodal performance. Our approach offers a practical and efficient solution to balance modality differentiation and language capabilities in multimodal MoE models.</li>
</ul>

<h3>Title: TimeWak: Temporal Chained-Hashing Watermark for Time Series Data</h3>
<ul>
<li><strong>Authors: </strong>Zhi Wen Soi, Chaoyi Zhu, Fouad Abiad, Aditya Shankar, Jeroen M. Galjaard, Huijuan Wang, Lydia Y. Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06407">https://arxiv.org/abs/2506.06407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06407">https://arxiv.org/pdf/2506.06407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06407]] TimeWak: Temporal Chained-Hashing Watermark for Time Series Data(https://arxiv.org/abs/2506.06407)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, watermark, diffusion</a></li>
<li><strong>Abstract: </strong>Synthetic time series generated by diffusion models enable sharing privacy-sensitive datasets, such as patients' functional MRI records. Key criteria for synthetic data include high data utility and traceability to verify the data source. Recent watermarking methods embed in homogeneous latent spaces, but state-of-the-art time series generators operate in real space, making latent-based watermarking incompatible. This creates the challenge of watermarking directly in real space while handling feature heterogeneity and temporal dependencies. We propose TimeWak, the first watermarking algorithm for multivariate time series diffusion models. To handle temporal dependence and spatial heterogeneity, TimeWak embeds a temporal chained-hashing watermark directly within the real temporal-feature space. The other unique feature is the $\epsilon$-exact inversion, which addresses the non-uniform reconstruction error distribution across features from inverting the diffusion process to detect watermarks. We derive the error bound of inverting multivariate time series and further maintain high watermark detectability. We extensively evaluate TimeWak on its impact on synthetic data quality, watermark detectability, and robustness under various post-editing attacks, against 5 datasets and baselines of different temporal lengths. Our results show that TimeWak achieves improvements of 61.96% in context-FID score, and 8.44% in correlational scores against the state-of-the-art baseline, while remaining consistently detectable.</li>
</ul>

<h3>Title: HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions</h3>
<ul>
<li><strong>Authors: </strong>Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Chen-Fu Chen, Haim Permuter, Sajani Vithana, Flavio P. Calmon</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CY, cs.IT, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06409">https://arxiv.org/abs/2506.06409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06409">https://arxiv.org/pdf/2506.06409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06409]] HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions(https://arxiv.org/abs/2506.06409)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) watermarks enable authentication of text provenance, curb misuse of machine-generated text, and promote trust in AI systems. Current watermarks operate by changing the next-token predictions output by an LLM. The updated (i.e., watermarked) predictions depend on random side information produced, for example, by hashing previously generated tokens. LLM watermarking is particularly challenging in low-entropy generation tasks - such as coding - where next-token predictions are near-deterministic. In this paper, we propose an optimization framework for watermark design. Our goal is to understand how to most effectively use random side information in order to maximize the likelihood of watermark detection and minimize the distortion of generated text. Our analysis informs the design of two new watermarks: HeavyWater and SimplexWater. Both watermarks are tunable, gracefully trading-off between detection accuracy and text distortion. They can also be applied to any LLM and are agnostic to side information generation. We examine the performance of HeavyWater and SimplexWater through several benchmarks, demonstrating that they can achieve high watermark detection accuracy with minimal compromise of text generation quality, particularly in the low-entropy regime. Our theoretical analysis also reveals surprising new connections between LLM watermarking and coding theory. The code implementation can be found in this https URL</li>
</ul>

<h3>Title: NeurNCD: Novel Class Discovery via Implicit Neural Representation</h3>
<ul>
<li><strong>Authors: </strong>Junming Wang, Yi Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06412">https://arxiv.org/abs/2506.06412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06412">https://arxiv.org/pdf/2506.06412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06412]] NeurNCD: Novel Class Discovery via Implicit Neural Representation(https://arxiv.org/abs/2506.06412)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Discovering novel classes in open-world settings is crucial for real-world applications. Traditional explicit representations, such as object descriptors or 3D segmentation maps, are constrained by their discrete, hole-prone, and noisy nature, which hinders accurate novel class discovery. To address these challenges, we introduce NeurNCD, the first versatile and data-efficient framework for novel class discovery that employs the meticulously designed Embedding-NeRF model combined with KL divergence as a substitute for traditional explicit 3D segmentation maps to aggregate semantic embedding and entropy in visual embedding space. NeurNCD also integrates several key components, including feature query, feature modulation and clustering, facilitating efficient feature augmentation and information exchange between the pre-trained semantic segmentation network and implicit neural representations. As a result, our framework achieves superior segmentation performance in both open and closed-world settings without relying on densely labelled datasets for supervised training or human interaction to generate sparse label supervision. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art approaches on the NYUv2 and Replica datasets.</li>
</ul>

<h3>Title: Benchmarking Misuse Mitigation Against Covert Adversaries</h3>
<ul>
<li><strong>Authors: </strong>Davis Brown, Mahdi Sabbaghi, Luze Sun, Alexander Robey, George J. Pappas, Eric Wong, Hamed Hassani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06414">https://arxiv.org/abs/2506.06414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06414">https://arxiv.org/pdf/2506.06414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06414]] Benchmarking Misuse Mitigation Against Covert Adversaries(https://arxiv.org/abs/2506.06414)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Existing language model safety evaluations focus on overt attacks and low-stakes tasks. Realistic attackers can subvert current safeguards by requesting help on small, benign-seeming tasks across many independent queries. Because individual queries do not appear harmful, the attack is hard to {detect}. However, when combined, these fragments uplift misuse by helping the attacker complete hard and dangerous tasks. Toward identifying defenses against such strategies, we develop Benchmarks for Stateful Defenses (BSD), a data generation pipeline that automates evaluations of covert attacks and corresponding defenses. Using this pipeline, we curate two new datasets that are consistently refused by frontier models and are too difficult for weaker open-weight models. Our evaluations indicate that decomposition attacks are effective misuse enablers, and highlight stateful defenses as a countermeasure.</li>
</ul>

<h3>Title: Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance</h3>
<ul>
<li><strong>Authors: </strong>Ruizhong Qiu, Gaotang Li, Tianxin Wei, Jingrui He, Hanghang Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06444">https://arxiv.org/abs/2506.06444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06444">https://arxiv.org/pdf/2506.06444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06444]] Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance(https://arxiv.org/abs/2506.06444)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Existing safety assurance research has primarily focused on training-phase alignment to instill safe behaviors into LLMs. However, recent studies have exposed these methods' susceptibility to diverse jailbreak attacks. Concurrently, inference scaling has significantly advanced LLM reasoning capabilities but remains unexplored in the context of safety assurance. Addressing this gap, our work pioneers inference scaling for robust and effective LLM safety against emerging threats. We reveal that conventional inference scaling techniques, despite their success in reasoning tasks, perform poorly in safety contexts, even falling short of basic approaches like Best-of-N Sampling. We attribute this inefficiency to a newly identified challenge, the exploration--efficiency dilemma, arising from the high computational overhead associated with frequent process reward model (PRM) evaluations. To overcome this dilemma, we propose SAFFRON, a novel inference scaling paradigm tailored explicitly for safety assurance. Central to our approach is the introduction of a multifurcation reward model (MRM) that significantly reduces the required number of reward model evaluations. To operationalize this paradigm, we further propose: (i) a partial supervision training objective for MRM, (ii) a conservative exploration constraint to prevent out-of-distribution explorations, and (iii) a Trie-based key--value caching strategy that facilitates cache sharing across sequences during tree search. Extensive experiments validate the effectiveness of our method. Additionally, we publicly release our trained multifurcation reward model (Saffron-1) and the accompanying token-level safety reward dataset (Safety4M) to accelerate future research in LLM safety. Our code, model, and data are publicly available at this https URL , and our project homepage is at this https URL .</li>
</ul>

<h3>Title: Canonical Autoregressive Generation</h3>
<ul>
<li><strong>Authors: </strong>Ivi Chatzi, Nina Corvelo Benz, Stratis Tsirtsis, Manuel Gomez-Rodriguez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06446">https://arxiv.org/abs/2506.06446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06446">https://arxiv.org/pdf/2506.06446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06446]] Canonical Autoregressive Generation(https://arxiv.org/abs/2506.06446)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>State of the art large language models are trained using large amounts of tokens derived from raw text using what is called a tokenizer. Crucially, the tokenizer determines the (token) vocabulary a model will use during inference as well as, in principle, the (token) language. This is because, while the token vocabulary may allow for different tokenizations of a string, the tokenizer always maps the string to only one of these tokenizations--the canonical tokenization. However, multiple lines of empirical evidence suggest that large language models do not always generate canonical token sequences, and this comes with several negative consequences. In this work, we first show that, to generate a canonical token sequence, a model needs to generate (partial) canonical token sequences at each step of the autoregressive generation process underpinning its functioning. Building upon this theoretical result, we introduce canonical sampling, a simple and efficient sampling method that precludes a given model from generating non-canonical token sequences. Further, we also show that, in comparison with standard sampling, the distribution of token sequences generated using canonical sampling is provably closer to the true distribution of token sequences used during training.</li>
</ul>

<h3>Title: LETS Forecast: Learning Embedology for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Abrar Majeedi, Viswanatha Reddy Gajjala, Satya Sai Srinath Namburi GNVV, Nada Magdi Elkordi, Yin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06454">https://arxiv.org/abs/2506.06454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06454">https://arxiv.org/pdf/2506.06454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06454]] LETS Forecast: Learning Embedology for Time Series Forecasting(https://arxiv.org/abs/2506.06454)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Real-world time series are often governed by complex nonlinear dynamics. Understanding these underlying dynamics is crucial for precise future prediction. While deep learning has achieved major success in time series forecasting, many existing approaches do not explicitly model the dynamics. To bridge this gap, we introduce DeepEDM, a framework that integrates nonlinear dynamical systems modeling with deep neural networks. Inspired by empirical dynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel deep model that learns a latent space from time-delayed embeddings, and employs kernel regression to approximate the underlying dynamics, while leveraging efficient implementation of softmax attention and allowing for accurate prediction of future time steps. To evaluate our method, we conduct comprehensive experiments on synthetic data of nonlinear dynamical systems as well as real-world time series across domains. Our results show that DeepEDM is robust to input noise, and outperforms state-of-the-art methods in forecasting accuracy. Our code is available at: this https URL.</li>
</ul>

<h3>Title: WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets</h3>
<ul>
<li><strong>Authors: </strong>Antonio Jesús Banegas-Luna, Horacio Pérez-Sánchez, Carlos Martínez-Cortés</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06455">https://arxiv.org/abs/2506.06455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06455">https://arxiv.org/pdf/2506.06455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06455]] WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets(https://arxiv.org/abs/2506.06455)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>While predictive accuracy is often prioritized in machine learning (ML) models, interpretability remains essential in scientific and high-stakes domains. However, diverse interpretability algorithms frequently yield conflicting explanations, highlighting the need for consensus to harmonize results. In this study, six ML models were trained on six synthetic datasets with known ground truths, utilizing various model-agnostic interpretability techniques. Consensus explanations were generated using established methods and a novel approach: WISCA (Weighted Scaled Consensus Attributions), which integrates class probability and normalized attributions. WISCA consistently aligned with the most reliable individual method, underscoring the value of robust consensus strategies in improving explanation reliability.</li>
</ul>

<h3>Title: Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control</h3>
<ul>
<li><strong>Authors: </strong>Ruitao Chen, Mozhang Guo, Jinge Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06459">https://arxiv.org/abs/2506.06459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06459">https://arxiv.org/pdf/2506.06459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06459]] Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control(https://arxiv.org/abs/2506.06459)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Automated driving (AD) has substantially improved vehicle safety and driving comfort, but their impact on passenger well-being, particularly infant sleep, is not sufficiently studied. Sudden acceleration, abrupt braking, and sharp maneuvers can disrupt infant sleep, compromising both passenger comfort and parental convenience. To solve this problem, this paper explores the integration of reinforcement learning (RL) within AD to personalize driving behavior and optimally balance occupant comfort and travel efficiency. In particular, we propose an intelligent cruise control framework that adapts to varying driving conditions to enhance infant sleep quality by effectively synergizing wearable sensing and vehicle data. Long short-term memory (LSTM) and transformer-based neural networks are integrated with RL to model the relationship between driving behavior and infant sleep quality under diverse traffic and road conditions. Based on the sleep quality indicators from the wearable sensors, driving action data from vehicle controllers, and map data from map applications, the model dynamically computes the optimal driving aggressiveness level, which is subsequently translated into specific AD control strategies, e.g., the magnitude and frequency of acceleration, lane change, and overtaking. Simulation results demonstrate that the proposed solution significantly improves infant sleep quality compared to baseline methods, while preserving desirable travel efficiency.</li>
</ul>

<h3>Title: (LiFT) Lightweight Fitness Transformer: A language-vision model for Remote Monitoring of Physical Training</h3>
<ul>
<li><strong>Authors: </strong>A. Postlmayr, P. Cosman, S. Dey</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06480">https://arxiv.org/abs/2506.06480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06480">https://arxiv.org/pdf/2506.06480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06480]] (LiFT) Lightweight Fitness Transformer: A language-vision model for Remote Monitoring of Physical Training(https://arxiv.org/abs/2506.06480)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce a fitness tracking system that enables remote monitoring for exercises using only a RGB smartphone camera, making fitness tracking more private, scalable, and cost effective. Although prior work explored automated exercise supervision, existing models are either too limited in exercise variety or too complex for real-world deployment. Prior approaches typically focus on a small set of exercises and fail to generalize across diverse movements. In contrast, we develop a robust, multitask motion analysis model capable of performing exercise detection and repetition counting across hundreds of exercises, a scale far beyond previous methods. We overcome previous data limitations by assembling a large-scale fitness dataset, Olympia covering more than 1,900 exercises. To our knowledge, our vision-language model is the first that can perform multiple tasks on skeletal fitness data. On Olympia, our model can detect exercises with 76.5% accuracy and count repetitions with 85.3% off-by-one accuracy, using only RGB video. By presenting a single vision-language transformer model for both exercise identification and rep counting, we take a significant step toward democratizing AI-powered fitness tracking.</li>
</ul>

<h3>Title: What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kaiser Sun, Fan Bai, Mark Dredze</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06485">https://arxiv.org/abs/2506.06485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06485">https://arxiv.org/pdf/2506.06485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06485]] What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models(https://arxiv.org/abs/2506.06485)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models frequently rely on both contextual input and parametric knowledge to perform tasks. However, these sources can come into conflict, especially when retrieved documents contradict the model's parametric knowledge. We propose a diagnostic framework to systematically evaluate LLM behavior under context-memory conflict, where the contextual information diverges from their parametric beliefs. We construct diagnostic data that elicit these conflicts and analyze model performance across multiple task types. Our findings reveal that (1) knowledge conflict has minimal impact on tasks that do not require knowledge utilization, (2) model performance is consistently higher when contextual and parametric knowledge are aligned, (3) models are unable to fully suppress their internal knowledge even when instructed, and (4) providing rationales that explain the conflict increases reliance on contexts. These insights raise concerns about the validity of model-based evaluation and underscore the need to account for knowledge conflict in the deployment of LLMs.</li>
</ul>

<h3>Title: A Certified Unlearning Approach without Access to Source Data</h3>
<ul>
<li><strong>Authors: </strong>Umit Yigit Basaran, Sk Miraj Ahmed, Amit Roy-Chowdhury, Basak Guler</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06486">https://arxiv.org/abs/2506.06486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06486">https://arxiv.org/pdf/2506.06486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06486]] A Certified Unlearning Approach without Access to Source Data(https://arxiv.org/abs/2506.06486)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>With the growing adoption of data privacy regulations, the ability to erase private or copyrighted information from trained models has become a crucial requirement. Traditional unlearning methods often assume access to the complete training dataset, which is unrealistic in scenarios where the source data is no longer available. To address this challenge, we propose a certified unlearning framework that enables effective data removal \final{without access to the original training data samples}. Our approach utilizes a surrogate dataset that approximates the statistical properties of the source data, allowing for controlled noise scaling based on the statistical distance between the two. \updated{While our theoretical guarantees assume knowledge of the exact statistical distance, practical implementations typically approximate this distance, resulting in potentially weaker but still meaningful privacy guarantees.} This ensures strong guarantees on the model's behavior post-unlearning while maintaining its overall utility. We establish theoretical bounds, introduce practical noise calibration techniques, and validate our method through extensive experiments on both synthetic and real-world datasets. The results demonstrate the effectiveness and reliability of our approach in privacy-sensitive settings.</li>
</ul>

<h3>Title: Membership Inference Attacks for Unseen Classes</h3>
<ul>
<li><strong>Authors: </strong>Pratiksha Thaker, Neil Kale, Zhiwei Steven Wu, Virginia Smith</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06488">https://arxiv.org/abs/2506.06488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06488">https://arxiv.org/pdf/2506.06488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06488]] Membership Inference Attacks for Unseen Classes(https://arxiv.org/abs/2506.06488)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, membership infer</a></li>
<li><strong>Abstract: </strong>Shadow model attacks are the state-of-the-art approach for membership inference attacks on machine learning models. However, these attacks typically assume an adversary has access to a background (nonmember) data distribution that matches the distribution the target model was trained on. We initiate a study of membership inference attacks where the adversary or auditor cannot access an entire subclass from the distribution -- a more extreme but realistic version of distribution shift than has been studied previously. In this setting, we first show that the performance of shadow model attacks degrades catastrophically, and then demonstrate the promise of another approach, quantile regression, that does not have the same limitations. We show that quantile regression attacks consistently outperform shadow model attacks in the class dropout setting -- for example, quantile regression attacks achieve up to 11$\times$ the TPR of shadow models on the unseen class on CIFAR-100, and achieve nontrivial TPR on ImageNet even with 90% of training classes removed. We also provide a theoretical model that illustrates the potential and limitations of this approach.</li>
</ul>

<h3>Title: Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Daniel Kunin, Giovanni Luca Marchetti, Feng Chen, Dhruva Karkada, James B. Simon, Michael R. DeWeese, Surya Ganguli, Nina Miolane</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06489">https://arxiv.org/abs/2506.06489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06489">https://arxiv.org/pdf/2506.06489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06489]] Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks(https://arxiv.org/abs/2506.06489)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>What features neural networks learn, and how, remains an open question. In this paper, we introduce Alternating Gradient Flows (AGF), an algorithmic framework that describes the dynamics of feature learning in two-layer networks trained from small initialization. Prior works have shown that gradient flow in this regime exhibits a staircase-like loss curve, alternating between plateaus where neurons slowly align to useful directions and sharp drops where neurons rapidly grow in norm. AGF approximates this behavior as an alternating two-step process: maximizing a utility function over dormant neurons and minimizing a cost function over active ones. AGF begins with all neurons dormant. At each round, a dormant neuron activates, triggering the acquisition of a feature and a drop in the loss. AGF quantifies the order, timing, and magnitude of these drops, matching experiments across architectures. We show that AGF unifies and extends existing saddle-to-saddle analyses in fully connected linear networks and attention-only linear transformers, where the learned features are singular modes and principal components, respectively. In diagonal linear networks, we prove AGF converges to gradient flow in the limit of vanishing initialization. Applying AGF to quadratic networks trained to perform modular addition, we give the first complete characterization of the training dynamics, revealing that networks learn Fourier features in decreasing order of coefficient magnitude. Altogether, AGF offers a promising step towards understanding feature learning in neural networks.</li>
</ul>

<h3>Title: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Alex Havrilla, Edward Hughes, Mikayel Samvelyan, Jacob Abernethy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06499">https://arxiv.org/abs/2506.06499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06499">https://arxiv.org/pdf/2506.06499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06499]] Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms(https://arxiv.org/abs/2506.06499)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) driven synthetic data generation has emerged as a powerful method for improving model reasoning capabilities. However, most methods either distill large state-of-the-art models into small students or use natural ground-truth problem statements to guarantee problem statement quality. This limits the scalability of these approaches to more complex and diverse problem domains. To address this, we present SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms, a novel approach for generating high-quality and diverse synthetic math problem and solution pairs using only a single model by measuring a problem's solve-rate: a proxy for problem difficulty. Starting from a seed dataset of 7.5K samples, we generate over 20 million new problem-solution pairs. We show that filtering the generated data by difficulty and then fine-tuning the same model on the resulting data improves relative model performance by up to 24\%. Additionally, we conduct ablations studying the impact of synthetic data quantity, quality and diversity on model generalization. We find that higher quality, as measured by problem difficulty, facilitates better in-distribution performance. Further, while generating diverse synthetic data does not as strongly benefit in-distribution performance, filtering for more diverse data facilitates more robust OOD generalization. We also confirm the existence of model and data scaling laws for synthetically generated problems, which positively benefit downstream model generalization.</li>
</ul>

<h3>Title: Improving LLM-Powered EDA Assistants with RAFT</h3>
<ul>
<li><strong>Authors: </strong>Luyao Shi, Michael Kazda, Charles Schmitter, Hemlata Gupta</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06500">https://arxiv.org/abs/2506.06500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06500">https://arxiv.org/pdf/2506.06500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06500]] Improving LLM-Powered EDA Assistants with RAFT(https://arxiv.org/abs/2506.06500)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, large language model</a></li>
<li><strong>Abstract: </strong>Electronic design engineers often struggle to efficiently access relevant information for tasks like design verification and technology development. While large language models (LLMs) can enhance productivity as conversational agents, pre-trained open-source LLMs lack domain-specific knowledge for Electronic Design Automation (EDA). In a Retrieval-Augmented Generation (RAG) context, LLMs rely on external context but may still produce inaccurate responses. Retrieval-Augmented Fine-Tuning (RAFT) improves LLM performance, but acquiring labeled question/answer (Q/A) data in EDA is difficult. To address this, we propose using synthetic Q/A datasets to enhance LLMs with RAFT. Our results show that RAFT with synthetic data significantly boosts LLM performance for RAG-based EDA tasks. We also investigate the impact of using real user questions as Retrieval-Augmented Few-Shot (RAFS) examples for synthetic data generation. Additionally, we implement secure access control to ensure sensitive information is only accessible to authorized personnel. Finally, we assess the risk of data leakage and unintended memorization during fine-tuning with synthetic data, providing practical insights.</li>
</ul>

<h3>Title: Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes</h3>
<ul>
<li><strong>Authors: </strong>Kshitish Ghate, Tessa Charlesworth, Mona Diab, Aylin Caliskan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06506">https://arxiv.org/abs/2506.06506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06506">https://arxiv.org/pdf/2506.06506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06506]] Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes(https://arxiv.org/abs/2506.06506)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>To build fair AI systems we need to understand how social-group biases intrinsic to foundational encoder-based vision-language models (VLMs) manifest in biases in downstream tasks. In this study, we demonstrate that intrinsic biases in VLM representations systematically ``carry over'' or propagate into zero-shot retrieval tasks, revealing how deeply rooted biases shape a model's outputs. We introduce a controlled framework to measure this propagation by correlating (a) intrinsic measures of bias in the representational space with (b) extrinsic measures of bias in zero-shot text-to-image (TTI) and image-to-text (ITT) retrieval. Results show substantial correlations between intrinsic and extrinsic bias, with an average $\rho$ = 0.83 $\pm$ 0.10. This pattern is consistent across 114 analyses, both retrieval directions, six social groups, and three distinct VLMs. Notably, we find that larger/better-performing models exhibit greater bias propagation, a finding that raises concerns given the trend towards increasingly complex AI models. Our framework introduces baseline evaluation tasks to measure the propagation of group and valence signals. Investigations reveal that underrepresented groups experience less robust propagation, further skewing their model-related outcomes.</li>
</ul>

<h3>Title: GS4: Generalizable Sparse Splatting Semantic SLAM</h3>
<ul>
<li><strong>Authors: </strong>Mingqi Jiang, Chanho Kim, Chen Ziwen, Li Fuxin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06517">https://arxiv.org/abs/2506.06517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06517">https://arxiv.org/pdf/2506.06517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06517]] GS4: Generalizable Sparse Splatting Semantic SLAM(https://arxiv.org/abs/2506.06517)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Traditional SLAM algorithms are excellent at camera tracking but might generate lower resolution and incomplete 3D maps. Recently, Gaussian Splatting (GS) approaches have emerged as an option for SLAM with accurate, dense 3D map building. However, existing GS-based SLAM methods rely on per-scene optimization which is time-consuming and does not generalize to diverse scenes well. In this work, we introduce the first generalizable GS-based semantic SLAM algorithm that incrementally builds and updates a 3D scene representation from an RGB-D video stream using a learned generalizable network. Our approach starts from an RGB-D image recognition backbone to predict the Gaussian parameters from every downsampled and backprojected image location. Additionally, we seamlessly integrate 3D semantic segmentation into our GS framework, bridging 3D mapping and recognition through a shared backbone. To correct localization drifting and floaters, we propose to optimize the GS for only 1 iteration following global localization. We demonstrate state-of-the-art semantic SLAM performance on the real-world benchmark ScanNet with an order of magnitude fewer Gaussians compared to other recent GS-based methods, and showcase our model's generalization capability through zero-shot transfer to the NYUv2 and TUM RGB-D datasets.</li>
</ul>

<h3>Title: A Systematic Review of Poisoning Attacks Against Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Neil Fendley, Edward W. Staley, Joshua Carney, William Redman, Marie Chau, Nathan Drenkow</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06518">https://arxiv.org/abs/2506.06518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06518">https://arxiv.org/pdf/2506.06518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06518]] A Systematic Review of Poisoning Attacks Against Large Language Models(https://arxiv.org/abs/2506.06518)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, generative, large language model</a></li>
<li><strong>Abstract: </strong>With the widespread availability of pretrained Large Language Models (LLMs) and their training datasets, concerns about the security risks associated with their usage has increased significantly. One of these security risks is the threat of LLM poisoning attacks where an attacker modifies some part of the LLM training process to cause the LLM to behave in a malicious way. As an emerging area of research, the current frameworks and terminology for LLM poisoning attacks are derived from earlier classification poisoning literature and are not fully equipped for generative LLM settings. We conduct a systematic review of published LLM poisoning attacks to clarify the security implications and address inconsistencies in terminology across the literature. We propose a comprehensive poisoning threat model applicable to categorize a wide range of LLM poisoning attacks. The poisoning threat model includes four poisoning attack specifications that define the logistics and manipulation strategies of an attack as well as six poisoning metrics used to measure key characteristics of an attack. Under our proposed framework, we organize our discussion of published LLM poisoning literature along four critical dimensions of LLM poisoning attacks: concept poisons, stealthy poisons, persistent poisons, and poisons for unique tasks, to better understand the current landscape of security risks.</li>
</ul>

<h3>Title: Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance</h3>
<ul>
<li><strong>Authors: </strong>Aladin Djuhera, Swanand Ravindra Kadhe, Syed Zawad, Farhan Ahmed, Heiko Ludwig, Holger Boche</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06522">https://arxiv.org/abs/2506.06522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06522">https://arxiv.org/pdf/2506.06522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06522]] Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance(https://arxiv.org/abs/2506.06522)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent work on large language models (LLMs) has increasingly focused on post-training and alignment with datasets curated to enhance instruction following, world knowledge, and specialized skills. However, most post-training datasets used in leading open- and closed-source LLMs remain inaccessible to the public, with limited information about their construction process. This lack of transparency has motivated the recent development of open-source post-training corpora. While training on these open alternatives can yield performance comparable to that of leading models, systematic comparisons remain challenging due to the significant computational cost of conducting them rigorously at scale, and are therefore largely absent. As a result, it remains unclear how specific samples, task types, or curation strategies influence downstream performance when assessing data quality. In this work, we conduct the first comprehensive side-by-side analysis of two prominent open post-training datasets: Tulu-3-SFT-Mix and SmolTalk. Using the Magpie framework, we annotate each sample with detailed quality metrics, including turn structure (single-turn vs. multi-turn), task category, input quality, and response quality, and we derive statistics that reveal structural and qualitative similarities and differences between the two datasets. Based on these insights, we design a principled curation recipe that produces a new data mixture, TuluTalk, which contains 14% fewer samples than either source dataset while matching or exceeding their performance on key benchmarks. Our findings offer actionable insights for constructing more effective post-training datasets that improve model performance within practical resource limits. To support future research, we publicly release both the annotated source datasets and our curated TuluTalk mixture.</li>
</ul>

<h3>Title: Breaking the Gaussian Barrier: Residual-PAC Privacy for Automatic Privatization</h3>
<ul>
<li><strong>Authors: </strong>Tao Zhang, Yevgeniy Vorobeychik</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06530">https://arxiv.org/abs/2506.06530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06530">https://arxiv.org/pdf/2506.06530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06530]] Breaking the Gaussian Barrier: Residual-PAC Privacy for Automatic Privatization(https://arxiv.org/abs/2506.06530)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The Probably Approximately Correct (PAC) Privacy framework [1] provides a powerful instance-based methodology for certifying privacy in complex data-driven systems. However, existing PAC Privacy algorithms rely on a Gaussian mutual information upper bound. We show that this is in general too conservative: the upper bound obtained by these algorithms is tight if and only if the perturbed mechanism output is jointly Gaussian with independent Gaussian noise. To address the inefficiency inherent in the Gaussian-based approach, we introduce Residual PAC Privacy, an f-divergence-based measure that quantifies the privacy remaining after adversarial inference. When instantiated with Kullback-Leibler divergence, Residual-PAC Privacy is governed by conditional entropy. Moreover, we propose Stackelberg Residual-PAC (SR-PAC) privatization mechanisms for RPAC Privacy, a game-theoretic framework that selects optimal noise distributions through convex bilevel optimization. Our approach achieves tight privacy budget utilization for arbitrary data distributions. Moreover, it naturally composes under repeated mechanisms and provides provable privacy guarantees with higher statistical efficiency. Numerical experiments demonstrate that SR-PAC certifies the target privacy budget while consistently improving utility compared to existing methods.</li>
</ul>

<h3>Title: Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks</h3>
<ul>
<li><strong>Authors: </strong>Zijiang Yan, Hao Zhou, Jianhua Pei, Hina Tabassum</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NI, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06532">https://arxiv.org/abs/2506.06532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06532">https://arxiv.org/pdf/2506.06532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06532]] Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks(https://arxiv.org/abs/2506.06532)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Unmanned aerial vehicles (UAVs) have been widely adopted in various real-world applications. However, the control and optimization of multi-UAV systems remain a significant challenge, particularly in dynamic and constrained environments. This work explores the joint motion and communication control of multiple UAVs operating within integrated terrestrial and non-terrestrial networks that include high-altitude platform stations (HAPS). Specifically, we consider an aerial highway scenario in which UAVs must accelerate, decelerate, and change lanes to avoid collisions and maintain overall traffic flow. Different from existing studies, we propose a novel hierarchical and collaborative method based on large language models (LLMs). In our approach, an LLM deployed on the HAPS performs UAV access control, while another LLM onboard each UAV handles motion planning and control. This LLM-based framework leverages the rich knowledge embedded in pre-trained models to enable both high-level strategic planning and low-level tactical decisions. This knowledge-driven paradigm holds great potential for the development of next-generation 3D aerial highway systems. Experimental results demonstrate that our proposed collaborative LLM-based method achieves higher system rewards, lower operational costs, and significantly reduced UAV collision rates compared to baseline approaches.</li>
</ul>

<h3>Title: Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models</h3>
<ul>
<li><strong>Authors: </strong>Seung-jae Lee, Paul Hongsuck Seo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06537">https://arxiv.org/abs/2506.06537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06537">https://arxiv.org/pdf/2506.06537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06537]] Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models(https://arxiv.org/abs/2506.06537)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Audiovisual segmentation (AVS) aims to identify visual regions corresponding to sound sources, playing a vital role in video understanding, surveillance, and human-computer interaction. Traditional AVS methods depend on large-scale pixel-level annotations, which are costly and time-consuming to obtain. To address this, we propose a novel zero-shot AVS framework that eliminates task-specific training by leveraging multiple pretrained models. Our approach integrates audio, vision, and text representations to bridge modality gaps, enabling precise sound source segmentation without AVS-specific annotations. We systematically explore different strategies for connecting pretrained models and evaluate their efficacy across multiple datasets. Experimental results demonstrate that our framework achieves state-of-the-art zero-shot AVS performance, highlighting the effectiveness of multimodal model integration for finegrained audiovisual segmentation.</li>
</ul>

<h3>Title: Beyond Facts: Evaluating Intent Hallucination in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yijie Hao, Haofei Yu, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06539">https://arxiv.org/abs/2506.06539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06539">https://arxiv.org/pdf/2506.06539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06539]] Beyond Facts: Evaluating Intent Hallucination in Large Language Models(https://arxiv.org/abs/2506.06539)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>When exposed to complex queries containing multiple conditions, today's large language models (LLMs) tend to produce responses that only partially satisfy the query while neglecting certain conditions. We therefore introduce the concept of Intent Hallucination. In this phenomenon, LLMs either omit (neglecting to address certain parts) or misinterpret (responding to invented query parts) elements of the given query, leading to intent hallucinated generation. To systematically evaluate intent hallucination, we introduce FAITHQA, a novel benchmark for intent hallucination that contains 20,068 problems, covering both query-only and retrieval-augmented generation (RAG) setups with varying topics and difficulty. FAITHQA is the first hallucination benchmark that goes beyond factual verification, tailored to identify the fundamental cause of intent hallucination. By evaluating various LLMs on FAITHQA, we find that (1) intent hallucination is a common issue even for state-of-the-art models, and (2) the phenomenon stems from omission or misinterpretation of LLMs. To facilitate future research, we introduce an automatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting intent hallucination. Human evaluation results demonstrate that CONSTRAINT SCORE is closer to human performance for intent hallucination compared to baselines.</li>
</ul>

<h3>Title: GeoClip: Geometry-Aware Clipping for Differentially Private SGD</h3>
<ul>
<li><strong>Authors: </strong>Atefeh Gilani, Naima Tasnim, Lalitha Sankar, Oliver Kosut</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06549">https://arxiv.org/abs/2506.06549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06549">https://arxiv.org/pdf/2506.06549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06549]] GeoClip: Geometry-Aware Clipping for Differentially Private SGD(https://arxiv.org/abs/2506.06549)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Differentially private stochastic gradient descent (DP-SGD) is the most widely used method for training machine learning models with provable privacy guarantees. A key challenge in DP-SGD is setting the per-sample gradient clipping threshold, which significantly affects the trade-off between privacy and utility. While recent adaptive methods improve performance by adjusting this threshold during training, they operate in the standard coordinate system and fail to account for correlations across the coordinates of the gradient. We propose GeoClip, a geometry-aware framework that clips and perturbs gradients in a transformed basis aligned with the geometry of the gradient distribution. GeoClip adaptively estimates this transformation using only previously released noisy gradients, incurring no additional privacy cost. We provide convergence guarantees for GeoClip and derive a closed-form solution for the optimal transformation that minimizes the amount of noise added while keeping the probability of gradient clipping under control. Experiments on both tabular and image datasets demonstrate that GeoClip consistently outperforms existing adaptive clipping methods under the same privacy budget.</li>
</ul>

<h3>Title: SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks</h3>
<ul>
<li><strong>Authors: </strong>Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Yi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06556">https://arxiv.org/abs/2506.06556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06556">https://arxiv.org/pdf/2506.06556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06556]] SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks(https://arxiv.org/abs/2506.06556)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>As the development of autonomous and connected vehicles advances, the complexity of modern vehicles increases, with numerous Electronic Control Units (ECUs) integrated into the system. In an in-vehicle network, these ECUs communicate with one another using an standard protocol called Controller Area Network (CAN). Securing communication among ECUs plays a vital role in maintaining the safety and security of the vehicle. This paper proposes a robust SDN-based False Data Detection and Mitigation System (FDDMS) for in-vehicle networks. Leveraging the unique capabilities of Software-Defined Networking (SDN), FDDMS is designed to monitor and detect false data injection attacks in real-time. Specifically, we focus on brake-related ECUs within an SDN-enabled in-vehicle network. First, we decode raw CAN data to create an attack model that illustrates how false data can be injected into the system. Then, FDDMS, incorporating a Long Short Term Memory (LSTM)-based detection model, is used to identify false data injection attacks. We further propose an effective variant of DeepFool attack to evaluate the model's robustness. To countermeasure the impacts of four adversarial attacks including Fast gradient descent method, Basic iterative method, DeepFool, and the DeepFool variant, we further enhance a re-training technique method with a threshold based selection strategy. Finally, a mitigation scheme is implemented to redirect attack traffic by dynamically updating flow rules through SDN. Our experimental results show that the proposed FDDMS is robust against adversarial attacks and effectively detects and mitigates false data injection attacks in real-time.</li>
</ul>

<h3>Title: Rapid training of Hamiltonian graph networks without gradient descent</h3>
<ul>
<li><strong>Authors: </strong>Atamert Rahma, Chinmay Datar, Ana Cukarska, Felix Dietrich</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06558">https://arxiv.org/abs/2506.06558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06558">https://arxiv.org/pdf/2506.06558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06558]] Rapid training of Hamiltonian graph networks without gradient descent(https://arxiv.org/abs/2506.06558)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning dynamical systems that respect physical symmetries and constraints remains a fundamental challenge in data-driven modeling. Integrating physical laws with graph neural networks facilitates principled modeling of complex N-body dynamics and yields accurate and permutation-invariant models. However, training graph neural networks with iterative, gradient-based optimization algorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training, especially for large, complex systems. In comparison to 15 different optimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trained up to 600x faster--but with comparable accuracy--by replacing iterative optimization with random feature-based parameter construction. We show robust performance in diverse simulations, including N-body mass-spring systems in up to 3 dimensions with different geometries, while retaining essential physical invariances with respect to permutation, rotation, and translation. We reveal that even when trained on minimal 8-node systems, the model can generalize in a zero-shot manner to systems as large as 4096 nodes without retraining. Our work challenges the dominance of iterative gradient-descent-based optimization algorithms for training neural network models for physical systems.</li>
</ul>

<h3>Title: Securing Traffic Sign Recognition Systems in Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Thushari Hapuarachchi, Long Dang, Kaiqi Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06563">https://arxiv.org/abs/2506.06563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06563">https://arxiv.org/pdf/2506.06563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06563]] Securing Traffic Sign Recognition Systems in Autonomous Vehicles(https://arxiv.org/abs/2506.06563)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep Neural Networks (DNNs) are widely used for traffic sign recognition because they can automatically extract high-level features from images. These DNNs are trained on large-scale datasets obtained from unknown sources. Therefore, it is important to ensure that the models remain secure and are not compromised or poisoned during training. In this paper, we investigate the robustness of DNNs trained for traffic sign recognition. First, we perform the error-minimizing attacks on DNNs used for traffic sign recognition by adding imperceptible perturbations on training data. Then, we propose a data augmentation-based training method to mitigate the error-minimizing attacks. The proposed training method utilizes nonlinear transformations to disrupt the perturbations and improve the model robustness. We experiment with two well-known traffic sign datasets to demonstrate the severity of the attack and the effectiveness of our mitigation scheme. The error-minimizing attacks reduce the prediction accuracy of the DNNs from 99.90% to 10.6%. However, our mitigation scheme successfully restores the prediction accuracy to 96.05%. Moreover, our approach outperforms adversarial training in mitigating the error-minimizing attacks. Furthermore, we propose a detection model capable of identifying poisoned data even when the perturbations are imperceptible to human inspection. Our detection model achieves a success rate of over 99% in identifying the attack. This research highlights the need to employ advanced training methods for DNNs in traffic sign recognition systems to mitigate the effects of data poisoning attacks.</li>
</ul>

<h3>Title: Adapting Under Fire: Multi-Agent Reinforcement Learning for Adversarial Drift in Network Security</h3>
<ul>
<li><strong>Authors: </strong>Emilia Rivas, Sabrina Saika, Ahtesham Bakht, Aritran Piplai, Nathaniel D. Bastian, Ankit Shah</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06565">https://arxiv.org/abs/2506.06565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06565">https://arxiv.org/pdf/2506.06565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06565]] Adapting Under Fire: Multi-Agent Reinforcement Learning for Adversarial Drift in Network Security(https://arxiv.org/abs/2506.06565)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Evolving attacks are a critical challenge for the long-term success of Network Intrusion Detection Systems (NIDS). The rise of these changing patterns has exposed the limitations of traditional network security methods. While signature-based methods are used to detect different types of attacks, they often fail to detect unknown attacks. Moreover, the system requires frequent updates with new signatures as the attackers are constantly changing their tactics. In this paper, we design an environment where two agents improve their policies over time. The adversarial agent, referred to as the red agent, perturbs packets to evade the intrusion detection mechanism, whereas the blue agent learns new defensive policies using drift adaptation techniques to counter the attacks. Both agents adapt iteratively: the red agent responds to the evolving NIDS, while the blue agent adjusts to emerging attack patterns. By studying the model's learned policy, we offer concrete insights into drift adaptation techniques with high utility. Experiments show that the blue agent boosts model accuracy by 30% with just 2 to 3 adaptation steps using only 25 to 30 samples each.</li>
</ul>

<h3>Title: Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Yannis Spyridis, Vasileios Argyriou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06569">https://arxiv.org/abs/2506.06569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06569">https://arxiv.org/pdf/2506.06569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06569]] Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models(https://arxiv.org/abs/2506.06569)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated sorting is crucial for improving the efficiency and scalability of textile recycling, but accurately identifying material composition and detecting contaminants from sensor data remains challenging. This paper investigates the use of standard RGB imagery, a cost-effective sensing modality, for key pre-processing tasks in an automated system. We present computer vision components designed for a conveyor belt setup to perform (a) classification of four common textile types and (b) segmentation of non-textile features such as buttons and zippers. For classification, several pre-trained architectures were evaluated using transfer learning and cross-validation, with EfficientNetB0 achieving the best performance on a held-out test set with 81.25\% accuracy. For feature segmentation, a zero-shot approach combining the Grounding DINO open-vocabulary detector with the Segment Anything Model (SAM) was employed, demonstrating excellent performance with a mIoU of 0.90 for the generated masks against ground truth. This study demonstrates the feasibility of using RGB images coupled with modern deep learning techniques, including transfer learning for classification and foundation models for zero-shot segmentation, to enable essential analysis steps for automated textile recycling pipelines.</li>
</ul>

<h3>Title: Cyber Security of Sensor Systems for State Sequence Estimation: an AI Approach</h3>
<ul>
<li><strong>Authors: </strong>Xubin Fang, Rick S. Blum, Ramesh Bharadwaj, Brian M. Sadler</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06572">https://arxiv.org/abs/2506.06572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06572">https://arxiv.org/pdf/2506.06572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06572]] Cyber Security of Sensor Systems for State Sequence Estimation: an AI Approach(https://arxiv.org/abs/2506.06572)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Sensor systems are extremely popular today and vulnerable to sensor data attacks. Due to possible devastating consequences, counteracting sensor data attacks is an extremely important topic, which has not seen sufficient study. This paper develops the first methods that accurately identify/eliminate only the problematic attacked sensor data presented to a sequence estimation/regression algorithm under a powerful attack model constructed based on known/observed attacks. The approach does not assume a known form for the statistical model of the sensor data, allowing data-driven and machine learning sequence estimation/regression algorithms to be protected. A simple protection approach for attackers not endowed with knowledge of the details of our protection approach is first developed, followed by additional processing for attacks based on protection system knowledge. In the cases tested for which it was designed, experimental results show that the simple approach achieves performance indistinguishable, to two decimal places, from that for an approach which knows which sensors are attacked. For cases where the attacker has knowledge of the protection approach, experimental results indicate the additional processing can be configured so that the worst-case degradation under the additional processing and a large number of sensors attacked can be made significantly smaller than the worst-case degradation of the simple approach, and close to an approach which knows which sensors are attacked, for the same number of attacked sensors with just a slight degradation under no attacks. Mathematical descriptions of the worst-case attacks are used to demonstrate the additional processing will provide similar advantages for cases for which we do not have numerical results. All the data-driven processing used in our approaches employ only unattacked training data.</li>
</ul>

<h3>Title: A Deep Learning Approach for Facial Attribute Manipulation and Reconstruction in Surveillance and Reconnaissance</h3>
<ul>
<li><strong>Authors: </strong>Anees Nashath Shaik, Barbara Villarini, Vasileios Argyriou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06578">https://arxiv.org/abs/2506.06578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06578">https://arxiv.org/pdf/2506.06578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06578]] A Deep Learning Approach for Facial Attribute Manipulation and Reconstruction in Surveillance and Reconnaissance(https://arxiv.org/abs/2506.06578)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, fair, generative</a></li>
<li><strong>Abstract: </strong>Surveillance systems play a critical role in security and reconnaissance, but their performance is often compromised by low-quality images and videos, leading to reduced accuracy in face recognition. Additionally, existing AI-based facial analysis models suffer from biases related to skin tone variations and partially occluded faces, further limiting their effectiveness in diverse real-world scenarios. These challenges are the results of data limitations and imbalances, where available training datasets lack sufficient diversity, resulting in unfair and unreliable facial recognition performance. To address these issues, we propose a data-driven platform that enhances surveillance capabilities by generating synthetic training data tailored to compensate for dataset biases. Our approach leverages deep learning-based facial attribute manipulation and reconstruction using autoencoders and Generative Adversarial Networks (GANs) to create diverse and high-quality facial datasets. Additionally, our system integrates an image enhancement module, improving the clarity of low-resolution or occluded faces in surveillance footage. We evaluate our approach using the CelebA dataset, demonstrating that the proposed platform enhances both training data diversity and model fairness. This work contributes to reducing bias in AI-based facial analysis and improving surveillance accuracy in challenging environments, leading to fairer and more reliable security applications.</li>
</ul>

<h3>Title: EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras</h3>
<ul>
<li><strong>Authors: </strong>Youssef Farah, Federico Paredes-Vallés, Guido De Croon, Muhammad Ahmed Humais, Hussain Sajwani, Yahya Zweiri</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06596">https://arxiv.org/abs/2506.06596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06596">https://arxiv.org/pdf/2506.06596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06596]] EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras(https://arxiv.org/abs/2506.06596)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Event cameras are novel bio-inspired sensors that capture motion dynamics with much higher temporal resolution than traditional cameras, since pixels react asynchronously to brightness changes. They are therefore better suited for tasks involving motion such as motion segmentation. However, training event-based networks still represents a difficult challenge, as obtaining ground truth is very expensive, error-prone and limited in frequency. In this article, we introduce EV-LayerSegNet, a self-supervised CNN for event-based motion segmentation. Inspired by a layered representation of the scene dynamics, we show that it is possible to learn affine optical flow and segmentation masks separately, and use them to deblur the input events. The deblurring quality is then measured and used as self-supervised learning loss. We train and test the network on a simulated dataset with only affine motion, achieving IoU and detection rate up to 71% and 87% respectively.</li>
</ul>

<h3>Title: Stochastic Training for Side-Channel Resilient AI</h3>
<ul>
<li><strong>Authors: </strong>Anuj Dubey, Aydin Aysu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06597">https://arxiv.org/abs/2506.06597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06597">https://arxiv.org/pdf/2506.06597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06597]] Stochastic Training for Side-Channel Resilient AI(https://arxiv.org/abs/2506.06597)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The confidentiality of trained AI models on edge devices is at risk from side-channel attacks exploiting power and electromagnetic emissions. This paper proposes a novel training methodology to enhance resilience against such threats by introducing randomized and interchangeable model configurations during inference. Experimental results on Google Coral Edge TPU show a reduction in side-channel leakage and a slower increase in t-scores over 20,000 traces, demonstrating robustness against adversarial observations. The defense maintains high accuracy, with about 1% degradation in most configurations, and requires no additional hardware or software changes, making it the only applicable solution for existing Edge TPUs.</li>
</ul>

<h3>Title: Zero Shot Composed Image Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Santhosh Kakarla, Gautama Shastry Bulusu Venkata</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06602">https://arxiv.org/abs/2506.06602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06602">https://arxiv.org/pdf/2506.06602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06602]] Zero Shot Composed Image Retrieval(https://arxiv.org/abs/2506.06602)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Composed image retrieval (CIR) allows a user to locate a target image by applying a fine-grained textual edit (e.g., ``turn the dress blue'' or ``remove stripes'') to a reference image. Zero-shot CIR, which embeds the image and the text with separate pretrained vision-language encoders, reaches only 20-25\% Recall@10 on the FashionIQ benchmark. We improve this by fine-tuning BLIP-2 with a lightweight Q-Former that fuses visual and textual features into a single embedding, raising Recall@10 to 45.6\% (shirt), 40.1\% (dress), and 50.4\% (top-tee) and increasing the average Recall@50 to 67.6\%. We also examine Retrieval-DPO, which fine-tunes CLIP's text encoder with a Direct Preference Optimization loss applied to FAISS-mined hard negatives. Despite extensive tuning of the scaling factor, index, and sampling strategy, Retrieval-DPO attains only 0.02\% Recall@10 -- far below zero-shot and prompt-tuned baselines -- because it (i) lacks joint image-text fusion, (ii) uses a margin objective misaligned with top-$K$ metrics, (iii) relies on low-quality negatives, and (iv) keeps the vision and Transformer layers frozen. Our results show that effective preference-based CIR requires genuine multimodal fusion, ranking-aware objectives, and carefully curated negatives.</li>
</ul>

<h3>Title: Scoring the Unscorables: Cyber Risk Assessment Beyond Internet Scans</h3>
<ul>
<li><strong>Authors: </strong>Armin Sarabi, Manish Karir, Mingyan Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06604">https://arxiv.org/abs/2506.06604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06604">https://arxiv.org/pdf/2506.06604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06604]] Scoring the Unscorables: Cyber Risk Assessment Beyond Internet Scans(https://arxiv.org/abs/2506.06604)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>In this paper we present a study on using novel data types to perform cyber risk quantification by estimating the likelihood of a data breach. We demonstrate that it is feasible to build a highly accurate cyber risk assessment model using public and readily available technology signatures obtained from crawling an organization's website. This approach overcomes the limitations of previous similar approaches that relied on large-scale IP address based scanning data, which suffers from incomplete/missing IP address mappings as well as the lack of such data for large numbers of small and medium-sized organizations (SMEs). In comparison to scan data, technology digital signature data is more readily available for millions of SMEs. Our study shows that there is a strong relationship between these technology signatures and an organization's cybersecurity posture. In cross-validating our model using different cyber incident datasets, we also highlight the key differences between ransomware attack victims and the larger population of cyber incident and data breach victims.</li>
</ul>

<h3>Title: Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit</h3>
<ul>
<li><strong>Authors: </strong>Charles Goddard, Fernando Fernandes Neto</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06607">https://arxiv.org/abs/2506.06607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06607">https://arxiv.org/pdf/2506.06607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06607]] Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit(https://arxiv.org/abs/2506.06607)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a training-free method to transplant tokenizers in pretrained large language models (LLMs) by reconstructing unseen token embeddings via Orthogonal Matching Pursuit (OMP). Specifically, we approximate each out-of-vocabulary token as a sparse linear combination of shared tokens, in two phases: first, compute each new token's representation in the donor embedding space with a small dictionary of shared anchor tokens, then transfer these same sparse coefficients back into the base model's embedding space. On two challenging cross-tokenizer tasks--Llama$\to$Mistral NeMo (12B) and Qwen$\to$Llama (1B)--we show that OMP achieves best zero-shot preservation of the base model's performance across multiple benchmarks, while other zero-shot approaches degrade significantly. Compared to baselines (zero-init, mean-init, and existing approaches like WECHSEL, FOCUS, ZETT), OMP consistently achieves the best overall performance, effectively bridging large tokenizer discrepancies without gradient updates. Our analysis further identifies mismatched numerical tokenization schemes as a critical challenge for preserving mathematical reasoning capabilities. This technique enables direct reuse of pretrained model weights with new tokenizers, facilitating cross-tokenizer knowledge distillation, speculative decoding, ensembling, merging, and domain-specific vocabulary adaptations. We integrate our method into the open-source mergekit-tokensurgeon tool for post hoc vocabulary realignment.</li>
</ul>

<h3>Title: Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Samuel Kim, Oghenemaro Imieye, Yunting Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06616">https://arxiv.org/abs/2506.06616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06616">https://arxiv.org/pdf/2506.06616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06616]] Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings(https://arxiv.org/abs/2506.06616)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate and interpretable detection of depressive language in social media is useful for early interventions of mental health conditions, and has important implications for both clinical practice and broader public health efforts. In this paper, we investigate the performance of large language models (LLMs) and traditional machine learning classifiers across three classification tasks involving social media data: binary depression classification, depression severity classification, and differential diagnosis classification among depression, PTSD, and anxiety. Our study compares zero-shot LLMs with supervised classifiers trained on both conventional text embeddings and LLM-generated summary embeddings. Our experiments reveal that while zero-shot LLMs demonstrate strong generalization capabilities in binary classification, they struggle with fine-grained ordinal classifications. In contrast, classifiers trained on summary embeddings generated by LLMs demonstrate competitive, and in some cases superior, performance on the classification tasks, particularly when compared to models using traditional text embeddings. Our findings demonstrate the strengths of LLMs in mental health prediction, and suggest promising directions for better utilization of their zero-shot capabilities and context-aware summarization techniques.</li>
</ul>

<h3>Title: BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs</h3>
<ul>
<li><strong>Authors: </strong>Jesse Woo, Fateme Hashemi Chaleshtori, Ana Marasović, Kenneth Marino</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06619">https://arxiv.org/abs/2506.06619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06619">https://arxiv.org/pdf/2506.06619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06619]] BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs(https://arxiv.org/abs/2506.06619)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A core part of legal work that has been under-explored in Legal NLP is the writing and editing of legal briefs. This requires not only a thorough understanding of the law of a jurisdiction, from judgments to statutes, but also the ability to make new arguments to try to expand the law in a new direction and make novel and creative arguments that are persuasive to judges. To capture and evaluate these legal skills in language models, we introduce BRIEFME, a new dataset focused on legal briefs. It contains three tasks for language models to assist legal professionals in writing briefs: argument summarization, argument completion, and case retrieval. In this work, we describe the creation of these tasks, analyze them, and show how current models perform. We see that today's large language models (LLMs) are already quite good at the summarization and guided completion tasks, even beating human-generated headings. Yet, they perform poorly on other tasks in our benchmark: realistic argument completion and retrieving relevant legal cases. We hope this dataset encourages more development in Legal NLP in ways that will specifically aid people in performing legal work.</li>
</ul>

<h3>Title: Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations</h3>
<ul>
<li><strong>Authors: </strong>Junzhe Wang, Bichen Wang, Xing Fu, Yixin Sun, Yanyan Zhao, Bing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06626">https://arxiv.org/abs/2506.06626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06626">https://arxiv.org/pdf/2506.06626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06626]] Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations(https://arxiv.org/abs/2506.06626)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Large Language Models (LLMs) have made significant progress in automated psychological counseling. However, current research focuses on single-session counseling, which doesn't represent real-world scenarios. In practice, psychological counseling is a process, not a one-time event, requiring sustained, multi-session engagement to progressively address clients' issues. To overcome this limitation, we introduce a dataset for Multi-Session Psychological Counseling Conversation Dataset (MusPsy-Dataset). Our MusPsy-Dataset is constructed using real client profiles from publicly available psychological case reports. It captures the dynamic arc of counseling, encompassing multiple progressive counseling conversations from the same client across different sessions. Leveraging our dataset, we also developed our MusPsy-Model, which aims to track client progress and adapt its counseling direction over time. Experiments show that our model performs better than baseline models across multiple sessions.</li>
</ul>

<h3>Title: SafeLawBench: Towards Safe Alignment of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chuxue Cao, Han Zhu, Jiaming Ji, Qichao Sun, Zhenghao Zhu, Yinyu Wu, Juntao Dai, Yaodong Yang, Sirui Han, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06636">https://arxiv.org/abs/2506.06636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06636">https://arxiv.org/pdf/2506.06636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06636]] SafeLawBench: Towards Safe Alignment of Large Language Models(https://arxiv.org/abs/2506.06636)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the growing prevalence of large language models (LLMs), the safety of LLMs has raised significant concerns. However, there is still a lack of definitive standards for evaluating their safety due to the subjective nature of current safety benchmarks. To address this gap, we conducted the first exploration of LLMs' safety evaluation from a legal perspective by proposing the SafeLawBench benchmark. SafeLawBench categorizes safety risks into three levels based on legal standards, providing a systematic and comprehensive framework for evaluation. It comprises 24,860 multi-choice questions and 1,106 open-domain question-answering (QA) tasks. Our evaluation included 2 closed-source LLMs and 18 open-source LLMs using zero-shot and few-shot prompting, highlighting the safety features of each model. We also evaluated the LLMs' safety-related reasoning stability and refusal behavior. Additionally, we found that a majority voting mechanism can enhance model performance. Notably, even leading SOTA models like Claude-3.5-Sonnet and GPT-4o have not exceeded 80.5% accuracy in multi-choice tasks on SafeLawBench, while the average accuracy of 20 LLMs remains at 68.8\%. We urge the community to prioritize research on the safety of LLMs.</li>
</ul>

<h3>Title: Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Olimjon Toirov, Wei Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06637">https://arxiv.org/abs/2506.06637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06637">https://arxiv.org/pdf/2506.06637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06637]] Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning(https://arxiv.org/abs/2506.06637)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Non-Intrusive Load Monitoring (NILM) identifies the operating status and energy consumption of each electrical device in the circuit by analyzing the electrical signals at the bus, which is of great significance for smart power management. However, the complex and changeable load combinations and application environments lead to the challenges of poor feature robustness and insufficient model generalization of traditional NILM methods. To this end, this paper proposes a new non-intrusive load monitoring method that integrates "image load signature" and continual learning. This method converts multi-dimensional power signals such as current, voltage, and power factor into visual image load feature signatures, and combines deep convolutional neural networks to realize the identification and classification of multiple devices; at the same time, self-supervised pre-training is introduced to improve feature generalization, and continual online learning strategies are used to overcome model forgetting to adapt to the emergence of new loads. This paper conducts a large number of experiments on high-sampling rate load datasets, and compares a variety of existing methods and model variants. The results show that the proposed method has achieved significant improvements in recognition accuracy.</li>
</ul>

<h3>Title: Spark Transformer: Reactivating Sparsity in FFN and Attention</h3>
<ul>
<li><strong>Authors: </strong>Chong You, Kan Wu, Zhipeng Jia, Lin Chen, Srinadh Bhojanapalli, Jiaxian Guo, Utku Evci, Jan Wassenberg, Praneeth Netrapalli, Jeremiah J. Willcock, Suvinay Subramanian, Felix Chern, Alek Andreev, Shreya Pathak, Felix Yu, Prateek Jain, David E. Culler, Henry M. Levy, Sanjiv Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06644">https://arxiv.org/abs/2506.06644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06644">https://arxiv.org/pdf/2506.06644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06644]] Spark Transformer: Reactivating Sparsity in FFN and Attention(https://arxiv.org/abs/2506.06644)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The discovery of the lazy neuron phenomenon in trained Transformers, where the vast majority of neurons in their feed-forward networks (FFN) are inactive for each token, has spurred tremendous interests in activation sparsity for enhancing large model efficiency. While notable progress has been made in translating such sparsity to wall-time benefits, modern Transformers have moved away from the ReLU activation function crucial to this phenomenon. Existing efforts on re-introducing activation sparsity often degrade model quality, increase parameter count, complicate or slow down training. Sparse attention, the application of sparse activation to the attention mechanism, often faces similar challenges. This paper introduces the Spark Transformer, a novel architecture that achieves a high level of activation sparsity in both FFN and the attention mechanism while maintaining model quality, parameter count, and standard training procedures. Our method realizes sparsity via top-k masking for explicit control over sparsity level. Crucially, we introduce statistical top-k, a hardware-accelerator-friendly, linear-time approximate algorithm that avoids costly sorting and mitigates significant training slowdown from standard top-$k$ operators. Furthermore, Spark Transformer reallocates existing FFN parameters and attention key embeddings to form a low-cost predictor for identifying activated entries. This design not only mitigates quality loss from enforced sparsity, but also enhances wall-time benefit. Pretrained with the Gemma-2 recipe, Spark Transformer demonstrates competitive performance on standard benchmarks while exhibiting significant sparsity: only 8% of FFN neurons are activated, and each token attends to a maximum of 256 tokens. This sparsity translates to a 2.5x reduction in FLOPs, leading to decoding wall-time speedups of up to 1.79x on CPU and 1.40x on GPU.</li>
</ul>

<h3>Title: Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling</h3>
<ul>
<li><strong>Authors: </strong>Cheng Peng, Jingxiang Sun, Yushuo Chen, Zhaoqi Su, Zhuo Su, Yebin Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06645">https://arxiv.org/abs/2506.06645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06645">https://arxiv.org/pdf/2506.06645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06645]] Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling(https://arxiv.org/abs/2506.06645)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Photorealistic and animatable human avatars are a key enabler for virtual/augmented reality, telepresence, and digital entertainment. While recent advances in 3D Gaussian Splatting (3DGS) have greatly improved rendering quality and efficiency, existing methods still face fundamental challenges, including time-consuming per-subject optimization and poor generalization under sparse monocular inputs. In this work, we present the Parametric Gaussian Human Model (PGHM), a generalizable and efficient framework that integrates human priors into 3DGS for fast and high-fidelity avatar reconstruction from monocular videos. PGHM introduces two core components: (1) a UV-aligned latent identity map that compactly encodes subject-specific geometry and appearance into a learnable feature tensor; and (2) a disentangled Multi-Head U-Net that predicts Gaussian attributes by decomposing static, pose-dependent, and view-dependent components via conditioned decoders. This design enables robust rendering quality under challenging poses and viewpoints, while allowing efficient subject adaptation without requiring multi-view capture or long optimization time. Experiments show that PGHM is significantly more efficient than optimization-from-scratch methods, requiring only approximately 20 minutes per subject to produce avatars with comparable visual quality, thereby demonstrating its practical applicability for real-world monocular avatar creation.</li>
</ul>

<h3>Title: SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes</h3>
<ul>
<li><strong>Authors: </strong>Yishan Shen, Yuyang Ye, Hui Xiong, Yong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06649">https://arxiv.org/abs/2506.06649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06649">https://arxiv.org/pdf/2506.06649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06649]] SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes(https://arxiv.org/abs/2506.06649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dynamic treatment regimes (DTRs) are critical to precision medicine, optimizing long-term outcomes through personalized, real-time decision-making in evolving clinical contexts, but require careful supervision for unsafe treatment risks. Existing efforts rely primarily on clinician-prescribed gold standards despite the absence of a known optimal strategy, and predominantly using structured EHR data without extracting valuable insights from clinical notes, limiting their reliability for treatment recommendations. In this work, we introduce SAFER, a calibrated risk-aware tabular-language recommendation framework for DTR that integrates both structured EHR and clinical notes, enabling them to learn from each other, and addresses inherent label uncertainty by assuming ambiguous optimal treatment solution for deceased patients. Moreover, SAFER employs conformal prediction to provide statistical guarantees, ensuring safe treatment recommendations while filtering out uncertain predictions. Experiments on two publicly available sepsis datasets demonstrate that SAFER outperforms state-of-the-art baselines across multiple recommendation metrics and counterfactual mortality rate, while offering robust formal assurances. These findings underscore SAFER potential as a trustworthy and theoretically grounded solution for high-stakes DTR applications.</li>
</ul>

<h3>Title: Rescaled Influence Functions: Accurate Data Attribution in High Dimension</h3>
<ul>
<li><strong>Authors: </strong>Ittai Rubinstein, Samuel B. Hopkins</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06656">https://arxiv.org/abs/2506.06656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06656">https://arxiv.org/pdf/2506.06656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06656]] Rescaled Influence Functions: Accurate Data Attribution in High Dimension(https://arxiv.org/abs/2506.06656)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>How does the training data affect a model's behavior? This is the question we seek to answer with data attribution. The leading practical approaches to data attribution are based on influence functions (IF). IFs utilize a first-order Taylor approximation to efficiently predict the effect of removing a set of samples from the training set without retraining the model, and are used in a wide variety of machine learning applications. However, especially in the high-dimensional regime (# params $\geq \Omega($# samples$)$), they are often imprecise and tend to underestimate the effect of sample removals, even for simple models such as logistic regression. We present rescaled influence functions (RIF), a new tool for data attribution which can be used as a drop-in replacement for influence functions, with little computational overhead but significant improvement in accuracy. We compare IF and RIF on a range of real-world datasets, showing that RIFs offer significantly better predictions in practice, and present a theoretical analysis explaining this improvement. Finally, we present a simple class of data poisoning attacks that would fool IF-based detections but would be detected by RIF.</li>
</ul>

<h3>Title: Quantile Regression with Large Language Models for Price Prediction</h3>
<ul>
<li><strong>Authors: </strong>Nikhita Vedula, Dushyanta Dhyani, Laleh Jalali, Boris Oreshkin, Mohsen Bayati, Shervin Malmasi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06657">https://arxiv.org/abs/2506.06657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06657">https://arxiv.org/pdf/2506.06657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06657]] Quantile Regression with Large Language Models for Price Prediction(https://arxiv.org/abs/2506.06657)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown promise in structured prediction tasks, including regression, but existing approaches primarily focus on point estimates and lack systematic comparison across different methods. We investigate probabilistic regression using LLMs for unstructured inputs, addressing challenging text-to-distribution prediction tasks such as price estimation where both nuanced text understanding and uncertainty quantification are critical. We propose a novel quantile regression approach that enables LLMs to produce full predictive distributions, improving upon traditional point estimates. Through extensive experiments across three diverse price prediction datasets, we demonstrate that a Mistral-7B model fine-tuned with quantile heads significantly outperforms traditional approaches for both point and distributional estimations, as measured by three established metrics each for prediction accuracy and distributional calibration. Our systematic comparison of LLM approaches, model architectures, training approaches, and data scaling reveals that Mistral-7B consistently outperforms encoder architectures, embedding-based methods, and few-shot learning methods. Our experiments also reveal the effectiveness of LLM-assisted label correction in achieving human-level accuracy without systematic bias. Our curated datasets are made available at this https URL to support future research.</li>
</ul>

<h3>Title: Through the Gaps: Uncovering Tactical Line-Breaking Passes with Clustering</h3>
<ul>
<li><strong>Authors: </strong>Oktay Karakuş, Hasan Arkadaş</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06666">https://arxiv.org/abs/2506.06666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06666">https://arxiv.org/pdf/2506.06666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06666]] Through the Gaps: Uncovering Tactical Line-Breaking Passes with Clustering(https://arxiv.org/abs/2506.06666)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, segmentation</a></li>
<li><strong>Abstract: </strong>Line-breaking passes (LBPs) are crucial tactical actions in football, allowing teams to penetrate defensive lines and access high-value spaces. In this study, we present an unsupervised, clustering-based framework for detecting and analysing LBPs using synchronised event and tracking data from elite matches. Our approach models opponent team shape through vertical spatial segmentation and identifies passes that disrupt defensive lines within open play. Beyond detection, we introduce several tactical metrics, including the space build-up ratio (SBR) and two chain-based variants, LBPCh$^1$ and LBPCh$^2$, which quantify the effectiveness of LBPs in generating immediate or sustained attacking threats. We evaluate these metrics across teams and players in the 2022 FIFA World Cup, revealing stylistic differences in vertical progression and structural disruption. The proposed methodology is explainable, scalable, and directly applicable to modern performance analysis and scouting workflows.</li>
</ul>

<h3>Title: Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment</h3>
<ul>
<li><strong>Authors: </strong>Radha Kodali, Venkata Rao Dhulipalla, Venkata Siva Kishor Tatavarty, Madhavi Nadakuditi, Bharadwaj Thiruveedhula, Suryanarayana Gunnam, Durga Prasad Bavirisetti</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06680">https://arxiv.org/abs/2506.06680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06680">https://arxiv.org/pdf/2506.06680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06680]] Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment(https://arxiv.org/abs/2506.06680)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Infertility has a considerable impact on individuals' quality of life, affecting them socially and psychologically, with projections indicating a rise in the upcoming years. In vitro fertilization (IVF) emerges as one of the primary techniques within economically developed nations, employed to address the rising problem of low fertility. Expert embryologists conventionally grade embryos by reviewing blastocyst images to select the most optimal for transfer, yet this process is time-consuming and lacks efficiency. Blastocyst images provide a valuable resource for assessing embryo viability. In this study, we introduce an explainable artificial intelligence (XAI) framework for classifying embryos, employing a fusion of convolutional neural network (CNN) and long short-term memory (LSTM) architecture, referred to as CNN-LSTM. Utilizing deep learning, our model achieves high accuracy in embryo classification while maintaining interpretability through XAI.</li>
</ul>

<h3>Title: Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics</h3>
<ul>
<li><strong>Authors: </strong>Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06682">https://arxiv.org/abs/2506.06682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06682">https://arxiv.org/pdf/2506.06682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06682]] Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics(https://arxiv.org/abs/2506.06682)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>In graph self-supervised learning, masked autoencoders (MAE) and contrastive learning (CL) are two prominent paradigms. MAE focuses on reconstructing masked elements, while CL maximizes similarity between augmented graph views. Recent studies highlight their complementarity: MAE excels at local feature capture, and CL at global information extraction. Hybrid frameworks for homogeneous graphs have been proposed, but face challenges in designing shared encoders to meet the semantic requirements of both tasks. In semantically sparse scenarios, CL struggles with view construction, and gradient imbalance between positive and negative samples persists. This paper introduces HetCRF, a novel dual-channel self-supervised learning framework for heterogeneous graphs. HetCRF uses a two-stage aggregation strategy to adapt embedding semantics, making it compatible with both MAE and CL. To address semantic sparsity, it enhances encoder output for view construction instead of relying on raw features, improving efficiency. Two positive sample augmentation strategies are also proposed to balance gradient contributions. Node classification experiments on four real-world heterogeneous graph datasets demonstrate that HetCRF outperforms state-of-the-art baselines. On datasets with missing node features, such as Aminer and Freebase, at a 40% label rate in node classification, HetCRF improves the Macro-F1 score by 2.75% and 2.2% respectively compared to the second-best baseline, validating its effectiveness and superiority.</li>
</ul>

<h3>Title: Learning Distribution-Wise Control in Representation Space for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chunyuan Deng, Ruidi Chang, Hanjie Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06686">https://arxiv.org/abs/2506.06686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06686">https://arxiv.org/pdf/2506.06686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06686]] Learning Distribution-Wise Control in Representation Space for Language Models(https://arxiv.org/abs/2506.06686)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Interventions in language models (LMs) are applied strategically to steer model behavior during the forward pass. Learnable interventions, also known as representation fine-tuning, aim to apply pointwise control within the concept subspace and have proven effective in altering high-level behaviors. In this work, we extend this approach to the distribution level, enabling the model to learn not only pointwise transformations but also the surrounding regions of the concept subspace. We demonstrate that these methods perform effectively in early layers, with larger standard deviations correlating strongly with improved performance. Across eight commonsense reasoning and seven arithmetic reasoning benchmarks, our distribution-wise interventions consistently outperform pointwise interventions in controllability and robustness. These results illustrate that distribution-wise interventions provide a more comprehensive method for steering model behavior and enabling finer-grained control over language models. The code is at: \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Yuan Yuan, Yukun Liu, Chonghua Han, Jie Feng, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06694">https://arxiv.org/abs/2506.06694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06694">https://arxiv.org/pdf/2506.06694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06694]] Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning(https://arxiv.org/abs/2506.06694)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate, transformer, generative</a></li>
<li><strong>Abstract: </strong>Foundation models have revolutionized fields such as natural language processing and computer vision by enabling general-purpose learning across diverse tasks and datasets. However, building analogous models for human mobility remains challenging due to the privacy-sensitive nature of mobility data and the resulting data silos across institutions. To bridge this gap, we propose MoveGCL, a scalable and privacy-preserving framework for training mobility foundation models via generative continual learning. Without sharing raw data, MoveGCL enables decentralized and progressive model evolution by replaying synthetic trajectories generated from a frozen teacher model, and reinforces knowledge retention through a tailored distillation strategy that mitigates catastrophic forgetting. To address the heterogeneity of mobility patterns, MoveGCL incorporates a Mixture-of-Experts Transformer with a mobility-aware expert routing mechanism, and employs a layer-wise progressive adaptation strategy to stabilize continual updates. Experiments on six real-world urban datasets demonstrate that MoveGCL achieves performance comparable to joint training and significantly outperforms federated learning baselines, while offering strong privacy protection. MoveGCL marks a crucial step toward unlocking foundation models for mobility, offering a practical blueprint for open, scalable, and privacy-preserving model development in the era of foundation models.</li>
</ul>

<h3>Title: MarginSel : Max-Margin Demonstration Selection for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Rajeev Bhatt Ambati, James Lester, Shashank Srivastava, Snigdha Chaturvedi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06699">https://arxiv.org/abs/2506.06699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06699">https://arxiv.org/pdf/2506.06699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06699]] MarginSel : Max-Margin Demonstration Selection for LLMs(https://arxiv.org/abs/2506.06699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at few-shot learning via in-context learning (ICL). However, the effectiveness of ICL is often sensitive to the selection and ordering of demonstration examples. To address this, we present MarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that selects hard demonstration examples for the ICL prompt, adapting to each test instance. Our approach achieves 2-7% absolute improvement in F1-score across classification tasks, compared to a random selection of examples. We also provide theoretical insights and empirical evidence showing that MarginSel induces max-margin behavior in LLMs by effectively increasing the margin for hard examples, analogous to support vectors, thereby shifting the decision boundary in a beneficial direction.</li>
</ul>

<h3>Title: Do Protein Transformers Have Biological Intelligence?</h3>
<ul>
<li><strong>Authors: </strong>Fudong Lin, Wanrou Du, Jinchan Liu, Tarikul Milon, Shelby Meche, Wu Xu, Xiaoqi Qin, Xu Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06701">https://arxiv.org/abs/2506.06701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06701">https://arxiv.org/pdf/2506.06701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06701]] Do Protein Transformers Have Biological Intelligence?(https://arxiv.org/abs/2506.06701)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks, particularly Transformers, have been widely adopted for predicting the functional properties of proteins. In this work, we focus on exploring whether Protein Transformers can capture biological intelligence among protein sequences. To achieve our goal, we first introduce a protein function dataset, namely Protein-FN, providing over 9000 protein data with meaningful labels. Second, we devise a new Transformer architecture, namely Sequence Protein Transformers (SPT), for computationally efficient protein function predictions. Third, we develop a novel Explainable Artificial Intelligence (XAI) technique called Sequence Score, which can efficiently interpret the decision-making processes of protein models, thereby overcoming the difficulty of deciphering biological intelligence bided in Protein Transformers. Remarkably, even our smallest SPT-Tiny model, which contains only 5.4M parameters, demonstrates impressive predictive accuracy, achieving 94.3% on the Antibiotic Resistance (AR) dataset and 99.6% on the Protein-FN dataset, all accomplished by training from scratch. Besides, our Sequence Score technique helps reveal that our SPT models can discover several meaningful patterns underlying the sequence structures of protein data, with these patterns aligning closely with the domain knowledge in the biology community. We have officially released our Protein-FN dataset on Hugging Face Datasets this https URL. Our code is available at this https URL.</li>
</ul>

<h3>Title: Dynamic and Parametric Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Weihang Su, Qingyao Ai, Jingtao Zhan, Qian Dong, Yiqun Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06704">https://arxiv.org/abs/2506.06704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06704">https://arxiv.org/pdf/2506.06704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06704]] Dynamic and Parametric Retrieval-Augmented Generation(https://arxiv.org/abs/2506.06704)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has become a foundational paradigm for equipping large language models (LLMs) with external knowledge, playing a critical role in information retrieval and knowledge-intensive applications. However, conventional RAG systems typically adopt a static retrieve-then-generate pipeline and rely on in-context knowledge injection, which can be suboptimal for complex tasks that require multihop reasoning, adaptive information access, and deeper integration of external knowledge. Motivated by these limitations, the research community has moved beyond static retrieval and in-context knowledge injection. Among the emerging directions, this tutorial delves into two rapidly growing and complementary research areas on RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when and what to retrieve during the LLM's generation process, enabling real-time adaptation to the LLM's evolving information needs. Parametric RAG rethinks how retrieved knowledge should be injected into LLMs, transitioning from input-level to parameter-level knowledge injection for enhanced efficiency and effectiveness. This tutorial offers a comprehensive overview of recent advances in these emerging research areas. It also shares theoretical foundations and practical insights to support and inspire further research in RAG.</li>
</ul>

<h3>Title: DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains</h3>
<ul>
<li><strong>Authors: </strong>Zhihui Chen, Kai He, Yucheng Huang, Yunxiao Zhu, Mengling Feng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06705">https://arxiv.org/abs/2506.06705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06705">https://arxiv.org/pdf/2506.06705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06705]] DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains(https://arxiv.org/abs/2506.06705)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting LLM-generated text in specialized and high-stakes domains like medicine and law is crucial for combating misinformation and ensuring authenticity. However, current zero-shot detectors, while effective on general text, often fail when applied to specialized content due to domain shift. We provide a theoretical analysis showing this failure is fundamentally linked to the KL divergence between human, detector, and source text distributions. To address this, we propose DivScore, a zero-shot detection framework using normalized entropy-based scoring and domain knowledge distillation to robustly identify LLM-generated text in specialized domains. We also release a domain-specific benchmark for LLM-generated text detection in the medical and legal domains. Experiments on our benchmark show that DivScore consistently outperforms state-of-the-art detectors, with 14.4% higher AUROC and 64.0% higher recall (0.1% false positive rate threshold). In adversarial settings, DivScore demonstrates superior robustness than other baselines, achieving on average 22.8% advantage in AUROC and 29.5% in recall. Code and data are publicly available.</li>
</ul>

<h3>Title: A Survey of Retentive Network</h3>
<ul>
<li><strong>Authors: </strong>Haiqi Yang, Zhiyuan Li, Yi Chang, Yuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06708">https://arxiv.org/abs/2506.06708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06708">https://arxiv.org/pdf/2506.06708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06708]] A Survey of Retentive Network(https://arxiv.org/abs/2506.06708)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Retentive Network (RetNet) represents a significant advancement in neural network architecture, offering an efficient alternative to the Transformer. While Transformers rely on self-attention to model dependencies, they suffer from high memory costs and limited scalability when handling long sequences due to their quadratic complexity. To mitigate these limitations, RetNet introduces a retention mechanism that unifies the inductive bias of recurrence with the global dependency modeling of attention. This mechanism enables linear-time inference, facilitates efficient modeling of extended contexts, and remains compatible with fully parallelizable training pipelines. RetNet has garnered significant research interest due to its consistently demonstrated cross-domain effectiveness, achieving robust performance across machine learning paradigms including natural language processing, speech recognition, and time-series analysis. However, a comprehensive review of RetNet is still missing from the current literature. This paper aims to fill that gap by offering the first detailed survey of the RetNet architecture, its key innovations, and its diverse applications. We also explore the main challenges associated with RetNet and propose future research directions to support its continued advancement in both academic research and practical deployment.</li>
</ul>

<h3>Title: A Systematic Investigation on Deep Learning-Based Omnidirectional Image and Video Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Qianqian Zhao, Chunle Guo, Tianyi Zhang, Junpei Zhang, Peiyang Jia, Tan Su, Wenjie Jiang, Chongyi Li</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06710">https://arxiv.org/abs/2506.06710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06710">https://arxiv.org/pdf/2506.06710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06710]] A Systematic Investigation on Deep Learning-Based Omnidirectional Image and Video Super-Resolution(https://arxiv.org/abs/2506.06710)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Omnidirectional image and video super-resolution is a crucial research topic in low-level vision, playing an essential role in virtual reality and augmented reality applications. Its goal is to reconstruct high-resolution images or video frames from low-resolution inputs, thereby enhancing detail preservation and enabling more accurate scene analysis and interpretation. In recent years, numerous innovative and effective approaches have been proposed, predominantly based on deep learning techniques, involving diverse network architectures, loss functions, projection strategies, and training datasets. This paper presents a systematic review of recent progress in omnidirectional image and video super-resolution, focusing on deep learning-based methods. Given that existing datasets predominantly rely on synthetic degradation and fall short in capturing real-world distortions, we introduce a new dataset, 360Insta, that comprises authentically degraded omnidirectional images and videos collected under diverse conditions, including varying lighting, motion, and exposure settings. This dataset addresses a critical gap in current omnidirectional benchmarks and enables more robust evaluation of the generalization capabilities of omnidirectional super-resolution methods. We conduct comprehensive qualitative and quantitative evaluations of existing methods on both public datasets and our proposed dataset. Furthermore, we provide a systematic overview of the current status of research and discuss promising directions for future exploration. All datasets, methods, and evaluation metrics introduced in this work are publicly available and will be regularly updated. Project page: this https URL.</li>
</ul>

<h3>Title: Active Contour Models Driven by Hyperbolic Mean Curvature Flow for Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Saiyu Hu, Chunlei He, Jianfeng Zhang, Dexing Kong, Shoujun Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, math.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06712">https://arxiv.org/abs/2506.06712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06712">https://arxiv.org/pdf/2506.06712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06712]] Active Contour Models Driven by Hyperbolic Mean Curvature Flow for Image Segmentation(https://arxiv.org/abs/2506.06712)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Parabolic mean curvature flow-driven active contour models (PMCF-ACMs) are widely used in image segmentation, which however depend heavily on the selection of initial curve configurations. In this paper, we firstly propose several hyperbolic mean curvature flow-driven ACMs (HMCF-ACMs), which introduce tunable initial velocity fields, enabling adaptive optimization for diverse segmentation scenarios. We shall prove that HMCF-ACMs are indeed normal flows and establish the numerical equivalence between dissipative HMCF formulations and certain wave equations using the level set method with signed distance function. Building on this framework, we furthermore develop hyperbolic dual-mode regularized flow-driven ACMs (HDRF-ACMs), which utilize smooth Heaviside functions for edge-aware force modulation to suppress over-diffusion near weak boundaries. Then, we optimize a weighted fourth-order Runge-Kutta algorithm with nine-point stencil spatial discretization when solving the above-mentioned wave equations. Experiments show that both HMCF-ACMs and HDRF-ACMs could achieve more precise segmentations with superior noise resistance and numerical stability due to task-adaptive configurations of initial velocities and initial contours.</li>
</ul>

<h3>Title: Mitigating Object Hallucination via Robust Local Perception Search</h3>
<ul>
<li><strong>Authors: </strong>Zixian Gao, Chao Yang, Zhanhui Zhou, Xing Xu, Chaochao Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06729">https://arxiv.org/abs/2506.06729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06729">https://arxiv.org/pdf/2506.06729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06729]] Mitigating Object Hallucination via Robust Local Perception Search(https://arxiv.org/abs/2506.06729)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Multimodal Large Language Models (MLLMs) have enabled them to effectively integrate vision and language, addressing a variety of downstream tasks. However, despite their significant success, these models still exhibit hallucination phenomena, where the outputs appear plausible but do not align with the content of the images. To mitigate this issue, we introduce Local Perception Search (LPS), a decoding method during inference that is both simple and training-free, yet effectively suppresses hallucinations. This method leverages local visual prior information as a value function to correct the decoding process. Additionally, we observe that the impact of the local visual prior on model performance is more pronounced in scenarios with high levels of image noise. Notably, LPS is a plug-and-play approach that is compatible with various models. Extensive experiments on widely used hallucination benchmarks and noisy data demonstrate that LPS significantly reduces the incidence of hallucinations compared to the baseline, showing exceptional performance, particularly in noisy settings.</li>
</ul>

<h3>Title: Fuse and Federate: Enhancing EV Charging Station Security with Multimodal Fusion and Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Rabah Rahal, Abdelaziz Amara Korba, Yacine Ghamri-Doudane</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06730">https://arxiv.org/abs/2506.06730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06730">https://arxiv.org/pdf/2506.06730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06730]] Fuse and Federate: Enhancing EV Charging Station Security with Multimodal Fusion and Federated Learning(https://arxiv.org/abs/2506.06730)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>The rapid global adoption of electric vehicles (EVs) has established electric vehicle supply equipment (EVSE) as a critical component of smart grid infrastructure. While essential for ensuring reliable energy delivery and accessibility, EVSE systems face significant cybersecurity challenges, including network reconnaissance, backdoor intrusions, and distributed denial-of-service (DDoS) attacks. These emerging threats, driven by the interconnected and autonomous nature of EVSE, require innovative and adaptive security mechanisms that go beyond traditional intrusion detection systems (IDS). Existing approaches, whether network-based or host-based, often fail to detect sophisticated and targeted attacks specifically crafted to exploit new vulnerabilities in EVSE infrastructure. This paper proposes a novel intrusion detection framework that leverages multimodal data sources, including network traffic and kernel events, to identify complex attack patterns. The framework employs a distributed learning approach, enabling collaborative intelligence across EVSE stations while preserving data privacy through federated learning. Experimental results demonstrate that the proposed framework outperforms existing solutions, achieving a detection rate above 98% and a precision rate exceeding 97% in decentralized environments. This solution addresses the evolving challenges of EVSE security, offering a scalable and privacypreserving response to advanced cyber threats</li>
</ul>

<h3>Title: Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Mesut Ozdag</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06735">https://arxiv.org/abs/2506.06735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06735">https://arxiv.org/pdf/2506.06735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06735]] Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions(https://arxiv.org/abs/2506.06735)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Smart contracts, integral to blockchain ecosystems, enable decentralized applications to execute predefined operations without intermediaries. Their ability to enforce trustless interactions has made them a core component of platforms such as Ethereum. Vulnerabilities such as numerical overflows, reentrancy attacks, and improper access permissions have led to the loss of millions of dollars throughout the blockchain and smart contract sector. Traditional smart contract auditing techniques such as manual code reviews and formal verification face limitations in scalability, automation, and adaptability to evolving development patterns. As a result, AI-based solutions have emerged as a promising alternative, offering the ability to learn complex patterns, detect subtle flaws, and provide scalable security assurances. This paper examines novel AI-driven techniques for vulnerability detection in smart contracts, focusing on machine learning, deep learning, graph neural networks, and transformer-based models. This paper analyzes how each technique represents code, processes semantic information, and responds to real world vulnerability classes. We also compare their strengths and weaknesses in terms of accuracy, interpretability, computational overhead, and real time applicability. Lastly, it highlights open challenges and future opportunities for advancing this domain.</li>
</ul>

<h3>Title: C-PATH: Conversational Patient Assistance and Triage in Healthcare System</h3>
<ul>
<li><strong>Authors: </strong>Qi Shi, Qiwei Han, Cláudia Soares</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06737">https://arxiv.org/abs/2506.06737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06737">https://arxiv.org/pdf/2506.06737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06737]] C-PATH: Conversational Patient Assistance and Triage in Healthcare System(https://arxiv.org/abs/2506.06737)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Navigating healthcare systems can be complex and overwhelming, creating barriers for patients seeking timely and appropriate medical attention. In this paper, we introduce C-PATH (Conversational Patient Assistance and Triage in Healthcare), a novel conversational AI system powered by large language models (LLMs) designed to assist patients in recognizing symptoms and recommending appropriate medical departments through natural, multi-turn dialogues. C-PATH is fine-tuned on medical knowledge, dialogue data, and clinical summaries using a multi-stage pipeline built on the LLaMA3 architecture. A core contribution of this work is a GPT-based data augmentation framework that transforms structured clinical knowledge from DDXPlus into lay-person-friendly conversations, allowing alignment with patient communication norms. We also implement a scalable conversation history management strategy to ensure long-range coherence. Evaluation with GPTScore demonstrates strong performance across dimensions such as clarity, informativeness, and recommendation accuracy. Quantitative benchmarks show that C-PATH achieves superior performance in GPT-rewritten conversational datasets, significantly outperforming domain-specific baselines. C-PATH represents a step forward in the development of user-centric, accessible, and accurate AI tools for digital health assistance and triage.</li>
</ul>

<h3>Title: LADSG: Label-Anonymized Distillation and Similar Gradient Substitution for Label Privacy in Vertical Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Yan, Yifei Yao, Xuanbing Wen, Juli Zhang, Kai Fan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06742">https://arxiv.org/abs/2506.06742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06742">https://arxiv.org/pdf/2506.06742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06742]] LADSG: Label-Anonymized Distillation and Similar Gradient Substitution for Label Privacy in Vertical Federated Learning(https://arxiv.org/abs/2506.06742)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Vertical federated learning (VFL) has become a key paradigm for collaborative machine learning, enabling multiple parties to train models over distributed feature spaces while preserving data privacy. Despite security protocols that defend against external attacks - such as gradient masking and encryption, which prevent unauthorized access to sensitive data - recent label inference attacks from within the system have emerged. These attacks exploit gradients and semantic embeddings to reconstruct private labels, bypassing traditional defenses. For example, the passive label inference attack can reconstruct tens of thousands of participants' private data using just 40 auxiliary labels, posing a significant security threat. Existing defenses address single leakage pathways, such as gradient leakage or label exposure. As attack strategies evolve, their limitations become clear, especially against hybrid attacks that combine multiple vectors. To address this, we propose Label-Anonymized Defense with Substitution Gradient (LADSG), a unified defense framework that integrates gradient substitution, label anonymization, and anomaly detection. LADSG mitigates both gradient and label leakage while maintaining the scalability and efficiency of VFL. Experiments on six real-world datasets show that LADSG reduces label inference attack success rates by 30-60%, with minimal computational overhead, underscoring the importance of lightweight defenses in securing VFL.</li>
</ul>

<h3>Title: THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised Video Object Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mingqi Gao, Haoran Duan, Tianlu Zhang, Jungong Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06748">https://arxiv.org/abs/2506.06748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06748">https://arxiv.org/pdf/2506.06748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06748]] THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised Video Object Segmentation(https://arxiv.org/abs/2506.06748)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this report, we describe our approach to egocentric video object segmentation. Our method combines large-scale visual pretraining from SAM2 with depth-based geometric cues to handle complex scenes and long-term tracking. By integrating these signals in a unified framework, we achieve strong segmentation performance. On the VISOR test set, our method reaches a J&F score of 90.1%.</li>
</ul>

<h3>Title: SAR2Struct: Extracting 3D Semantic Structural Representation of Aircraft Targets from Single-View SAR Image</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Yue, Ruixi You, Feng Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06757">https://arxiv.org/abs/2506.06757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06757">https://arxiv.org/pdf/2506.06757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06757]] SAR2Struct: Extracting 3D Semantic Structural Representation of Aircraft Targets from Single-View SAR Image(https://arxiv.org/abs/2506.06757)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>To translate synthetic aperture radar (SAR) image into interpretable forms for human understanding is the ultimate goal of SAR advanced information retrieval. Existing methods mainly focus on 3D surface reconstruction or local geometric feature extraction of targets, neglecting the role of structural modeling in capturing semantic information. This paper proposes a novel task: SAR target structure recovery, which aims to infer the components of a target and the structural relationships between its components, specifically symmetry and adjacency, from a single-view SAR image. Through learning the structural consistency and geometric diversity across the same type of targets as observed in different SAR images, it aims to derive the semantic representation of target directly from its 2D SAR image. To solve this challenging task, a two-step algorithmic framework based on structural descriptors is developed. Specifically, in the training phase, it first detects 2D keypoints from real SAR images, and then learns the mapping from these keypoints to 3D hierarchical structures using simulated data. During the testing phase, these two steps are integrated to infer the 3D structure from real SAR images. Experimental results validated the effectiveness of each step and demonstrated, for the first time, that 3D semantic structural representation of aircraft targets can be directly derived from a single-view SAR image.</li>
</ul>

<h3>Title: LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security</h3>
<ul>
<li><strong>Authors: </strong>Nidheesh Gorthi, Kartik Thakral, Rishabh Ranjan, Richa Singh, Mayank Vatsa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06759">https://arxiv.org/abs/2506.06759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06759">https://arxiv.org/pdf/2506.06759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06759]] LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security(https://arxiv.org/abs/2506.06759)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, biometric</a></li>
<li><strong>Abstract: </strong>Biometric authentication systems are increasingly being deployed in critical applications, but they remain susceptible to spoofing. Since most of the research efforts focus on modality-specific anti-spoofing techniques, building a unified, resource-efficient solution across multiple biometric modalities remains a challenge. To address this, we propose LitMAS, a $\textbf{Li}$gh$\textbf{t}$ weight and generalizable $\textbf{M}$ulti-modal $\textbf{A}$nti-$\textbf{S}$poofing framework designed to detect spoofing attacks in speech, face, iris, and fingerprint-based biometric systems. At the core of LitMAS is a Modality-Aligned Concentration Loss, which enhances inter-class separability while preserving cross-modal consistency and enabling robust spoof detection across diverse biometric traits. With just 6M parameters, LitMAS surpasses state-of-the-art methods by $1.36\%$ in average EER across seven datasets, demonstrating high efficiency, strong generalizability, and suitability for edge deployment. Code and trained models are available at this https URL.</li>
</ul>

<h3>Title: The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing</h3>
<ul>
<li><strong>Authors: </strong>Adrià Molina Rodríguez, Oriol Ramos Terrades, Josep Lladós</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06761">https://arxiv.org/abs/2506.06761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06761">https://arxiv.org/pdf/2506.06761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06761]] The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing(https://arxiv.org/abs/2506.06761)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Achieving robustness in recognition systems across diverse domains is crucial for their practical utility. While ample data availability is usually assumed, low-resource languages, such as ancient manuscripts and non-western languages, tend to be kept out of the equations of massive pretraining and foundational techniques due to an under representation. In this work, we aim for building models which can generalize to new distributions of data, such as alphabets, faster than centralized fine-tune strategies. For doing so, we take advantage of the recent advancements in model editing to enhance the incorporation of unseen scripts (low-resource learning). In contrast to state-of-the-art meta-learning, we showcase the effectiveness of domain merging in sparse distributions of data, with agnosticity of its relation to the overall distribution or any other prototyping necessity. Even when using the same exact training data, our experiments showcase significant performance boosts in \textbf{transfer learning} to new alphabets and \textbf{out-of-domain evaluation} in challenging domain shifts, including historical ciphered texts and non-Latin scripts. This research contributes a novel approach into building models that can easily adopt under-represented alphabets and, therefore, enable document recognition to a wider set of contexts and cultures.</li>
</ul>

<h3>Title: They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse</h3>
<ul>
<li><strong>Authors: </strong>Walter Paci (1), Alessandro Panunzi (1), Sandro Pezzelle (2) ((1) University of Florence, (2) University of Amsterdam)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06775">https://arxiv.org/abs/2506.06775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06775">https://arxiv.org/pdf/2506.06775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06775]] They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse(https://arxiv.org/abs/2506.06775)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Implicit content plays a crucial role in political discourse, where speakers systematically employ pragmatic strategies such as implicatures and presuppositions to influence their audiences. Large Language Models (LLMs) have demonstrated strong performance in tasks requiring complex semantic and pragmatic understanding, highlighting their potential for detecting and explaining the meaning of implicit content. However, their ability to do this within political discourse remains largely underexplored. Leveraging, for the first time, the large IMPAQTS corpus, which comprises Italian political speeches with the annotation of manipulative implicit content, we propose methods to test the effectiveness of LLMs in this challenging problem. Through a multiple-choice task and an open-ended generation task, we demonstrate that all tested models struggle to interpret presuppositions and implicatures. We conclude that current LLMs lack the key pragmatic capabilities necessary for accurately interpreting highly implicit language, such as that found in political discourse. At the same time, we highlight promising trends and future directions for enhancing model performance. We release our data and code at this https URL</li>
</ul>

<h3>Title: Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World</h3>
<ul>
<li><strong>Authors: </strong>Qinting Jiang, Chuyang Ye, Dongyan Wei, Bingli Wang, Yuan Xue, Jingyan Jiang, Zhi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06782">https://arxiv.org/abs/2506.06782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06782">https://arxiv.org/pdf/2506.06782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06782]] Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World(https://arxiv.org/abs/2506.06782)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite progress, deep neural networks still suffer performance declines under distribution shifts between training and test domains, leading to a substantial decrease in Quality of Experience (QoE) for applications. Existing test-time adaptation (TTA) methods are challenged by dynamic, multiple test distributions within batches. We observe that feature distributions across different domains inherently cluster into distinct groups with varying means and variances. This divergence reveals a critical limitation of previous global normalization strategies in TTA, which inevitably distort the original data characteristics. Based on this insight, we propose Feature-based Instance Neighbor Discovery (FIND), which comprises three key components: Layer-wise Feature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and Selective FABN (S-FABN). LFD stably captures features with similar distributions at each layer by constructing graph structures. While FABN optimally combines source statistics with test-time distribution specific statistics for robust feature representation. Finally, S-FABN determines which layers require feature partitioning and which can remain unified, thereby enhancing inference efficiency. Extensive experiments demonstrate that FIND significantly outperforms existing methods, achieving a 30\% accuracy improvement in dynamic scenarios while maintaining computational efficiency.</li>
</ul>

<h3>Title: Caterpillar GNN: Replacing Message Passing with Efficient Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Marek Černý</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06784">https://arxiv.org/abs/2506.06784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06784">https://arxiv.org/pdf/2506.06784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06784]] Caterpillar GNN: Replacing Message Passing with Efficient Aggregation(https://arxiv.org/abs/2506.06784)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Message-passing graph neural networks (MPGNNs) dominate modern graph learning, typically prioritizing maximal expressive power. In contrast, we introduce an \emph{efficient aggregation} mechanism, deliberately trading off some expressivity for stronger and more structured aggregation capabilities. Our approach allows seamless scaling between classical message-passing and simpler methods based on colored or plain walks. We rigorously characterize the expressive power at each intermediate step using homomorphism counts from a hierarchy of generalized \emph{caterpillar graphs}. Based on this foundation, we propose the \emph{Caterpillar GNN}, whose robust graph-level aggregation enables it to successfully tackle synthetic graph-level task specifically designed to be challenging for classical MPGNNs. Moreover, we demonstrate that, on real-world datasets, the Caterpillar GNN achieves comparable predictive performance while significantly reducing the number of nodes in the hidden layers of the computational graph.</li>
</ul>

<h3>Title: FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Qiyun Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06787">https://arxiv.org/abs/2506.06787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06787">https://arxiv.org/pdf/2506.06787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06787]] FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks(https://arxiv.org/abs/2506.06787)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As integrated circuit scale grows and design complexity rises, effective circuit representation helps support logic synthesis, formal verification, and other automated processes in electronic design automation. And-Inverter Graphs (AIGs), as a compact and canonical structure, are widely adopted for representing Boolean logic in these workflows. However, the increasing complexity and integration density of modern circuits introduce structural heterogeneity and global logic information loss in AIGs, posing significant challenges to accurate circuit modeling. To address these issues, we propose FuncGNN, which integrates hybrid feature aggregation to extract multi-granularity topological patterns, thereby mitigating structural heterogeneity and enhancing logic circuit representations. FuncGNN further introduces gate-aware normalization that adapts to circuit-specific gate distributions, improving robustness to structural heterogeneity. Finally, FuncGNN employs multi-layer integration to merge intermediate features across layers, effectively synthesizing local and global semantic information for comprehensive logic representations. Experimental results on two logic-level analysis tasks (i.e., signal probability prediction and truth-table distance prediction) demonstrate that FuncGNN outperforms existing state-of-the-art methods, achieving improvements of 2.06% and 18.71%, respectively, while reducing training time by approximately 50.6% and GPU memory usage by about 32.8%.</li>
</ul>

<h3>Title: On the Adaptive Psychological Persuasion of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tianjie Ju, Yujia Chen, Hao Fei, Mong-Li Lee, Wynne Hsu, Pengzhou Cheng, Zongru Wu, Zhuosheng Zhang, Gongshen Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06800">https://arxiv.org/abs/2506.06800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06800">https://arxiv.org/pdf/2506.06800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06800]] On the Adaptive Psychological Persuasion of Large Language Models(https://arxiv.org/abs/2506.06800)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Previous work has showcased the intriguing capabilities of Large Language Models (LLMs) in instruction-following and rhetorical fluency. However, systematic exploration of their dual capabilities to autonomously persuade and resist persuasion, particularly in contexts involving psychological rhetoric, remains unexplored. In this paper, we first evaluate four commonly adopted LLMs by tasking them to alternately act as persuaders and listeners in adversarial dialogues. Empirical results show that persuader LLMs predominantly employ repetitive strategies, leading to low success rates. Then we introduce eleven comprehensive psychological persuasion strategies, finding that explicitly instructing LLMs to adopt specific strategies such as Fluency Effect and Repetition Effect significantly improves persuasion success rates. However, no ``one-size-fits-all'' strategy proves universally effective, with performance heavily dependent on contextual counterfactuals. Motivated by these observations, we propose an adaptive framework based on direct preference optimization that trains LLMs to autonomously select optimal strategies by leveraging persuasion results from strategy-specific responses as preference pairs. Experiments on three open-source LLMs confirm that the proposed adaptive psychological persuasion method effectively enables persuader LLMs to select optimal strategies, significantly enhancing their success rates while maintaining general capabilities. Our code is available at this https URL.</li>
</ul>

<h3>Title: Training-Free Identity Preservation in Stylized Image Generation Using Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Ali Rezaei, Helia Hajikazem, Saeed Khanehgir, Mahdi Javanmardi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06802">https://arxiv.org/abs/2506.06802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06802">https://arxiv.org/pdf/2506.06802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06802]] Training-Free Identity Preservation in Stylized Image Generation Using Diffusion Models(https://arxiv.org/abs/2506.06802)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>While diffusion models have demonstrated remarkable generative capabilities, existing style transfer techniques often struggle to maintain identity while achieving high-quality stylization. This limitation is particularly acute for images where faces are small or exhibit significant camera-to-face distances, frequently leading to inadequate identity preservation. To address this, we introduce a novel, training-free framework for identity-preserved stylized image synthesis using diffusion models. Key contributions include: (1) the "Mosaic Restored Content Image" technique, significantly enhancing identity retention, especially in complex scenes; and (2) a training-free content consistency loss that enhances the preservation of fine-grained content details by directing more attention to the original image during stylization. Our experiments reveal that the proposed approach substantially surpasses the baseline model in concurrently maintaining high stylistic fidelity and robust identity integrity, particularly under conditions of small facial regions or significant camera-to-face distances, all without necessitating model retraining or fine-tuning.</li>
</ul>

<h3>Title: Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification</h3>
<ul>
<li><strong>Authors: </strong>Subhendu Khatuya, Shashwat Naidu, Saptarshi Ghosh, Pawan Goyal, Niloy Ganguly</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06806">https://arxiv.org/abs/2506.06806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06806">https://arxiv.org/pdf/2506.06806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06806]] Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification(https://arxiv.org/abs/2506.06806)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>The explosion of textual data has made manual document classification increasingly challenging. To address this, we introduce a robust, efficient domain-agnostic generative model framework for multi-label text classification. Instead of treating labels as mere atomic symbols, our approach utilizes predefined label descriptions and is trained to generate these descriptions based on the input text. During inference, the generated descriptions are matched to the pre-defined labels using a finetuned sentence transformer. We integrate this with a dual-objective loss function, combining cross-entropy loss and cosine similarity of the generated sentences with the predefined target descriptions, ensuring both semantic alignment and accuracy. Our proposed model LAGAMC stands out for its parameter efficiency and versatility across diverse datasets, making it well-suited for practical applications. We demonstrate the effectiveness of our proposed model by achieving new state-of-the-art performances across all evaluated datasets, surpassing several strong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in Macro-F1 compared to the closest baseline across all datasets.</li>
</ul>

<h3>Title: Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events</h3>
<ul>
<li><strong>Authors: </strong>James A. Michaelov, Reeka Estacio, Zhien Zhang, Benjamin K. Bergen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06808">https://arxiv.org/abs/2506.06808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06808">https://arxiv.org/pdf/2506.06808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06808]] Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events(https://arxiv.org/abs/2506.06808)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Can language models reliably predict that possible events are more likely than merely improbable ones? By teasing apart possibility, typicality, and contextual relatedness, we show that despite the results of previous work, language models' ability to do this is far from robust. In fact, under certain conditions, all models tested - including Llama 3, Gemma 2, and Mistral NeMo - perform at worse-than-chance level, assigning higher probabilities to impossible sentences such as 'the car was given a parking ticket by the brake' than to merely unlikely sentences such as 'the car was given a parking ticket by the explorer'.</li>
</ul>

<h3>Title: IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder</h3>
<ul>
<li><strong>Authors: </strong>Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06809">https://arxiv.org/abs/2506.06809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06809">https://arxiv.org/pdf/2506.06809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06809]] IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder(https://arxiv.org/abs/2506.06809)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Self-supervised learning (SSL) methods have been increasingly applied to diverse downstream tasks due to their superior generalization capabilities and low annotation costs. However, most existing heterogeneous graph SSL models convert heterogeneous graphs into homogeneous ones via meta-paths for training, which only leverage information from nodes at both ends of meta-paths while underutilizing the heterogeneous node information along the meta-paths. To address this limitation, this paper proposes a novel framework named IMPA-HGAE to enhance target node embeddings by fully exploiting internal node information along meta-paths. Experimental results validate that IMPA-HGAE achieves superior performance on heterogeneous datasets. Furthermore, this paper introduce innovative masking strategies to strengthen the representational capacity of generative SSL models on heterogeneous graph data. Additionally, this paper discuss the interpretability of the proposed method and potential future directions for generative self-supervised learning in heterogeneous graphs. This work provides insights into leveraging meta-path-guided structural semantics for robust representation learning in complex graph scenarios.</li>
</ul>

<h3>Title: Path Integral Optimiser: Global Optimisation via Neural Schrödinger-Föllmer Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Max McGuinness, Eirik Fladmark, Francisco Vargas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06815">https://arxiv.org/abs/2506.06815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06815">https://arxiv.org/pdf/2506.06815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06815]] Path Integral Optimiser: Global Optimisation via Neural Schrödinger-Föllmer Diffusion(https://arxiv.org/abs/2506.06815)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present an early investigation into the use of neural diffusion processes for global optimisation, focusing on Zhang et al.'s Path Integral Sampler. One can use the Boltzmann distribution to formulate optimization as solving a Schrödinger bridge sampling problem, then apply Girsanov's theorem with a simple (single-point) prior to frame it in stochastic control terms, and compute the solution's integral terms via a neural approximation (a Fourier MLP). We provide theoretical bounds for this optimiser, results on toy optimisation tasks, and a summary of the stochastic theory motivating the model. Ultimately, we found the optimiser to display promising per-step performance at optimisation tasks between 2 and 1,247 dimensions, but struggle to explore higher-dimensional spaces when faced with a 15.9k parameter model, indicating a need for work on adaptation in such environments.</li>
</ul>

<h3>Title: Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Chao Yin, Hao Li, Kequan Yang, Jide Li, Pinpin Zhu, Xiaoqiang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06818">https://arxiv.org/abs/2506.06818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06818">https://arxiv.org/pdf/2506.06818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06818]] Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation(https://arxiv.org/abs/2506.06818)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>While promptable segmentation (\textit{e.g.}, SAM) has shown promise for various segmentation tasks, it still requires manual visual prompts for each object to be segmented. In contrast, task-generic promptable segmentation aims to reduce the need for such detailed prompts by employing only a task-generic prompt to guide segmentation across all test samples. However, when applied to Camouflaged Object Segmentation (COS), current methods still face two critical issues: 1) \textit{\textbf{semantic ambiguity in getting instance-specific text prompts}}, which arises from insufficient discriminative cues in holistic captions, leading to foreground-background confusion; 2) \textit{\textbf{semantic discrepancy combined with spatial separation in getting instance-specific visual prompts}}, which results from global background sampling far from object boundaries with low feature correlation, causing SAM to segment irrelevant regions. To address the issues above, we propose \textbf{RDVP-MSD}, a novel training-free test-time adaptation framework that synergizes \textbf{R}egion-constrained \textbf{D}ual-stream \textbf{V}isual \textbf{P}rompting (RDVP) via \textbf{M}ultimodal \textbf{S}tepwise \textbf{D}ecomposition Chain of Thought (MSD-CoT). MSD-CoT progressively disentangles image captions to eliminate semantic ambiguity, while RDVP injects spatial constraints into visual prompting and independently samples visual prompts for foreground and background points, effectively mitigating semantic discrepancy and spatial separation. Without requiring any training or supervision, RDVP-MSD achieves a state-of-the-art segmentation result on multiple COS benchmarks and delivers a faster inference speed than previous methods, demonstrating significantly improved accuracy and efficiency. The codes will be available at \href{this https URL}{this https URL}</li>
</ul>

<h3>Title: Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs</h3>
<ul>
<li><strong>Authors: </strong>Wenyu Zhang, Yingxu He, Geyu Lin, Zhuohan Liu, Shuo Sun, Bin Wang, Xunlong Zou, Jeremy H. M. Wong, Qiongqiong Wang, Hardik B. Sailor, Nancy F. Chen, Ai Ti Aw</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06820">https://arxiv.org/abs/2506.06820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06820">https://arxiv.org/pdf/2506.06820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06820]] Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs(https://arxiv.org/abs/2506.06820)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Audio Large Language Models (AudioLLMs) have achieved strong results in semantic tasks like speech recognition and translation, but remain limited in modeling paralinguistic cues such as emotion. Existing approaches often treat emotion understanding as a classification problem, offering little insight into the underlying rationale behind predictions. In this work, we explore emotion reasoning, a strategy that leverages the generative capabilities of AudioLLMs to enhance emotion recognition by producing semantically aligned, evidence-grounded explanations. To support this in multitask AudioLLMs, we introduce a unified framework combining reasoning-augmented data supervision, dual-encoder architecture, and task-alternating training. This approach enables AudioLLMs to effectively learn different tasks while incorporating emotional reasoning. Experiments on IEMOCAP and MELD show that our approach not only improves emotion prediction accuracy but also enhances the coherence and evidential grounding of the generated responses.</li>
</ul>

<h3>Title: Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems</h3>
<ul>
<li><strong>Authors: </strong>Yuhan Cao, Zian Chen, Kun Quan, Ziliang Zhang, Yu Wang, Xiaoning Dong, Yeqi Feng, Guanzhong He, Jingcheng Huang, Jianhao Li, Yixuan Tan, Jiafu Tang, Yilin Tang, Junlei Wu, Qianyu Xiao, Can Zheng, Shouchen Zhou, Yuxiang Zhu, Yiming Huang, Tian Xie, Tianxing He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06821">https://arxiv.org/abs/2506.06821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06821">https://arxiv.org/pdf/2506.06821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06821]] Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems(https://arxiv.org/abs/2506.06821)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, capable of tackling complex tasks during inference. However, the extent to which LLMs can be utilized for code checking or debugging through test case generation remains largely unexplored. We investigate this problem from the perspective of competition-level programming (CP) programs and propose TCGBench, a Benchmark for (LLM generation of) Test Case Generators. This benchmark comprises two tasks, aimed at studying the capabilities of LLMs in (1) generating valid test case generators for a given CP problem, and further (2) generating targeted test case generators that expose bugs in human-written code. Experimental results indicate that while state-of-the-art LLMs can generate valid test case generators in most cases, most LLMs struggle to generate targeted test cases that reveal flaws in human code effectively. Especially, even advanced reasoning models (e.g., o3-mini) fall significantly short of human performance in the task of generating targeted generators. Furthermore, we construct a high-quality, manually curated dataset of instructions for generating targeted generators. Analysis demonstrates that the performance of LLMs can be enhanced with the aid of this dataset, by both prompting and fine-tuning.</li>
</ul>

<h3>Title: Hi-LSplat: Hierarchical 3D Language Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Chenlu Zhan, Yufei Zhang, Gaoang Wang, Hongwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06822">https://arxiv.org/abs/2506.06822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06822">https://arxiv.org/pdf/2506.06822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06822]] Hi-LSplat: Hierarchical 3D Language Gaussian Splatting(https://arxiv.org/abs/2506.06822)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Modeling 3D language fields with Gaussian Splatting for open-ended language queries has recently garnered increasing attention. However, recent 3DGS-based models leverage view-dependent 2D foundation models to refine 3D semantics but lack a unified 3D representation, leading to view inconsistencies. Additionally, inherent open-vocabulary challenges cause inconsistencies in object and relational descriptions, impeding hierarchical semantic understanding. In this paper, we propose Hi-LSplat, a view-consistent Hierarchical Language Gaussian Splatting work for 3D open-vocabulary querying. To achieve view-consistent 3D hierarchical semantics, we first lift 2D features to 3D features by constructing a 3D hierarchical semantic tree with layered instance clustering, which addresses the view inconsistency issue caused by 2D semantic features. Besides, we introduce instance-wise and part-wise contrastive losses to capture all-sided hierarchical semantic representations. Notably, we construct two hierarchical semantic datasets to better assess the model's ability to distinguish different semantic levels. Extensive experiments highlight our method's superiority in 3D open-vocabulary segmentation and localization. Its strong performance on hierarchical semantic datasets underscores its ability to capture complex hierarchical semantics within 3D scenes.</li>
</ul>

<h3>Title: Exploring Visual Prompting: Robustness Inheritance and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Qi Li, Liangzhi Li, Zhouqiang Jiang, Bowen Wang, Keke Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06823">https://arxiv.org/abs/2506.06823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06823">https://arxiv.org/pdf/2506.06823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06823]] Exploring Visual Prompting: Robustness Inheritance and Beyond(https://arxiv.org/abs/2506.06823)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual Prompting (VP), an efficient method for transfer learning, has shown its potential in vision tasks. However, previous works focus exclusively on VP from standard source models, it is still unknown how it performs under the scenario of a robust source model: Can the robustness of the source model be successfully inherited? Does VP also encounter the same trade-off between robustness and generalization ability as the source model during this process? If such a trade-off exists, is there a strategy specifically tailored to VP to mitigate this limitation? In this paper, we thoroughly explore these three questions for the first time and provide affirmative answers to them. To mitigate the trade-off faced by VP, we propose a strategy called Prompt Boundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally compatible with VP, PBL effectively ensures the successful inheritance of robustness when the source model is a robust model, while significantly enhancing VP's generalization ability across various downstream datasets. Extensive experiments across various datasets show that our findings are universal and demonstrate the significant benefits of the proposed strategy.</li>
</ul>

<h3>Title: Controllable Coupled Image Generation via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Chenfei Yuan, Nanshan Jia, Hangqi Li, Peter W. Glynn, Zeyu Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06826">https://arxiv.org/abs/2506.06826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06826">https://arxiv.org/pdf/2506.06826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06826]] Controllable Coupled Image Generation via Diffusion Models(https://arxiv.org/abs/2506.06826)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We provide an attention-level control method for the task of coupled image generation, where "coupled" means that multiple simultaneously generated images are expected to have the same or very similar backgrounds. While backgrounds coupled, the centered objects in the generated images are still expected to enjoy the flexibility raised from different text prompts. The proposed method disentangles the background and entity components in the model's cross-attention modules, attached with a sequence of time-varying weight control parameters depending on the time step of sampling. We optimize this sequence of weight control parameters with a combined objective that assesses how coupled the backgrounds are as well as text-to-image alignment and overall visual quality. Empirical results demonstrate that our method outperforms existing approaches across these criteria.</li>
</ul>

<h3>Title: EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery</h3>
<ul>
<li><strong>Authors: </strong>Guankun Wang, Rui Tang, Mengya Xu, Long Bai, Huxin Gao, Hongliang Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06830">https://arxiv.org/abs/2506.06830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06830">https://arxiv.org/pdf/2506.06830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06830]] EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery(https://arxiv.org/abs/2506.06830)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Endoscopic surgery is the gold standard for robotic-assisted minimally invasive surgery, offering significant advantages in early disease detection and precise interventions. However, the complexity of surgical scenes, characterized by high variability in different surgical activity scenarios and confused image features between targets and the background, presents challenges for surgical environment understanding. Traditional deep learning models often struggle with cross-activity interference, leading to suboptimal performance in each downstream task. To address this limitation, we explore multi-task learning, which utilizes the interrelated features between tasks to enhance overall task performance. In this paper, we propose EndoARSS, a novel multi-task learning framework specifically designed for endoscopy surgery activity recognition and semantic segmentation. Built upon the DINOv2 foundation model, our approach integrates Low-Rank Adaptation to facilitate efficient fine-tuning while incorporating Task Efficient Shared Low-Rank Adapters to mitigate gradient conflicts across diverse tasks. Additionally, we introduce the Spatially-Aware Multi-Scale Attention that enhances feature representation discrimination by enabling cross-spatial learning of global information. In order to evaluate the effectiveness of our framework, we present three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailored for endoscopic surgery scenarios with detailed annotations for both activity recognition and semantic segmentation tasks. Extensive experiments demonstrate that EndoARSS achieves remarkable performance across multiple benchmarks, significantly improving both accuracy and robustness in comparison to existing models. These results underscore the potential of EndoARSS to advance AI-driven endoscopic surgical systems, offering valuable insights for enhancing surgical safety and efficiency.</li>
</ul>

<h3>Title: PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation</h3>
<ul>
<li><strong>Authors: </strong>Arkadiusz Modzelewski, Witold Sosnowski, Tiziano Labruna, Adam Wierzbicki, Giovanni Da San Martino</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06842">https://arxiv.org/abs/2506.06842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06842">https://arxiv.org/pdf/2506.06842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06842]] PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation(https://arxiv.org/abs/2506.06842)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Disinformation detection is a key aspect of media literacy. Psychological studies have shown that knowledge of persuasive fallacies helps individuals detect disinformation. Inspired by these findings, we experimented with large language models (LLMs) to test whether infusing persuasion knowledge enhances disinformation detection. As a result, we introduce the Persuasion-Augmented Chain of Thought (PCoT), a novel approach that leverages persuasion to improve disinformation detection in zero-shot classification. We extensively evaluate PCoT on online news and social media posts. Moreover, we publish two novel, up-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets enable the evaluation of PCoT on content entirely unseen by the LLMs used in our experiments, as the content was published after the models' knowledge cutoffs. We show that, on average, PCoT outperforms competitive methods by 15% across five LLMs and five datasets. These findings highlight the value of persuasion in strengthening zero-shot disinformation detection.</li>
</ul>

<h3>Title: Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models</h3>
<ul>
<li><strong>Authors: </strong>Naibin Gu, Peng Fu, Xiyu Liu, Ke Ma, Zheng Lin, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06844">https://arxiv.org/abs/2506.06844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06844">https://arxiv.org/pdf/2506.06844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06844]] Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models(https://arxiv.org/abs/2506.06844)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) has become a common method for fine-tuning large language models, where a base model can serve multiple users through PEFT module switching. To enhance user experience, base models require periodic updates. However, once updated, PEFT modules fine-tuned on previous versions often suffer substantial performance degradation on newer versions. Re-tuning these numerous modules to restore performance would incur significant computational costs. Through a comprehensive analysis of the changes that occur during base model updates, we uncover an interesting phenomenon: continual training primarily affects task-specific knowledge stored in Feed-Forward Networks (FFN), while having less impact on the task-specific pattern in the Attention mechanism. Based on these findings, we introduce Trans-PEFT, a novel approach that enhances the PEFT module by focusing on the task-specific pattern while reducing its dependence on certain knowledge in the base model. Further theoretical analysis supports our approach. Extensive experiments across 7 base models and 12 datasets demonstrate that Trans-PEFT trained modules can maintain performance on updated base models without re-tuning, significantly reducing maintenance overhead in real-world applications.</li>
</ul>

<h3>Title: Multi-StyleGS: Stylizing Gaussian Splatting with Multiple Styles</h3>
<ul>
<li><strong>Authors: </strong>Yangkai Lin, Jiabao Lei, Kui jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06846">https://arxiv.org/abs/2506.06846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06846">https://arxiv.org/pdf/2506.06846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06846]] Multi-StyleGS: Stylizing Gaussian Splatting with Multiple Styles(https://arxiv.org/abs/2506.06846)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, there has been a growing demand to stylize a given 3D scene to align with the artistic style of reference images for creative purposes. While 3D Gaussian Splatting(GS) has emerged as a promising and efficient method for realistic 3D scene modeling, there remains a challenge in adapting it to stylize 3D GS to match with multiple styles through automatic local style transfer or manual designation, while maintaining memory efficiency for stylization training. In this paper, we introduce a novel 3D GS stylization solution termed Multi-StyleGS to tackle these challenges. In particular, we employ a bipartite matching mechanism to au tomatically identify correspondences between the style images and the local regions of the rendered images. To facilitate local style transfer, we introduce a novel semantic style loss function that employs a segmentation network to apply distinct styles to various objects of the scene and propose a local-global feature matching to enhance the multi-view consistency. Furthermore, this technique can achieve memory efficient training, more texture details and better color match. To better assign a robust semantic label to each Gaussian, we propose several techniques to regularize the segmentation network. As demonstrated by our comprehensive experiments, our approach outperforms existing ones in producing plausible stylization results and offering flexible editing.</li>
</ul>

<h3>Title: Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>John Waithaka, Moise Busogi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06852">https://arxiv.org/abs/2506.06852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06852">https://arxiv.org/pdf/2506.06852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06852]] Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation(https://arxiv.org/abs/2506.06852)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of satellite imagery is crucial for Earth observation applications, but remains constrained by limited labelled training data. While self-supervised pretraining methods like Masked Autoencoders (MAE) have shown promise, they focus on reconstruction rather than localisation-a fundamental aspect of segmentation tasks. We propose adapting LOCA (Location-aware), a position prediction self-supervised learning method, for multimodal satellite imagery semantic segmentation. Our approach addresses the unique challenges of satellite data by extending SatMAE's channel grouping from multispectral to multimodal data, enabling effective handling of multiple modalities, and introducing same-group attention masking to encourage cross-modal interaction during pretraining. The method uses relative patch position prediction, encouraging spatial reasoning for localisation rather than reconstruction. We evaluate our approach on the Sen1Floods11 flood mapping dataset, where it significantly outperforms existing reconstruction-based self-supervised learning methods for satellite imagery. Our results demonstrate that position prediction tasks, when properly adapted for multimodal satellite imagery, learn representations more effective for satellite image semantic segmentation than reconstruction-based approaches.</li>
</ul>

<h3>Title: Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Chaoyang Wang, Zeyu Zhang, Haiyun Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06856">https://arxiv.org/abs/2506.06856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06856">https://arxiv.org/pdf/2506.06856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06856]] Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning(https://arxiv.org/abs/2506.06856)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual reasoning is crucial for understanding complex multimodal data and advancing Artificial General Intelligence. Existing methods enhance the reasoning capability of Multimodal Large Language Models (MLLMs) through Reinforcement Learning (RL) fine-tuning (e.g., GRPO). However, current RL approaches sample action groups solely from the policy model itself, which limits the upper boundary of the model's reasoning capability and leads to inefficient training. To address these limitations, this paper proposes a novel RL framework called \textbf{Vision-EKIPL}. The core of this framework lies in introducing high-quality actions generated by external auxiliary models during the RL training process to guide the optimization of the policy model. The policy learning with knowledge infusion from external models significantly expands the model's exploration space, effectively improves the reasoning boundary, and substantially accelerates training convergence speed and efficiency. Experimental results demonstrate that our proposed Vision-EKIPL achieved up to a 5\% performance improvement on the Reason-RFT-CoT Benchmark compared to the state-of-the-art (SOTA). It reveals that Vision-EKIPL can overcome the limitations of traditional RL methods, significantly enhance the visual reasoning performance of MLLMs, and provide a new effective paradigm for research in this field.</li>
</ul>

<h3>Title: Differentially Private Sparse Linear Regression with Heavy-tailed Responses</h3>
<ul>
<li><strong>Authors: </strong>Xizhi Tian, Meng Ding, Touming Tao, Zihang Xiang, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06861">https://arxiv.org/abs/2506.06861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06861">https://arxiv.org/pdf/2506.06861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06861]] Differentially Private Sparse Linear Regression with Heavy-tailed Responses(https://arxiv.org/abs/2506.06861)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>As a fundamental problem in machine learning and differential privacy (DP), DP linear regression has been extensively studied. However, most existing methods focus primarily on either regular data distributions or low-dimensional cases with irregular data. To address these limitations, this paper provides a comprehensive study of DP sparse linear regression with heavy-tailed responses in high-dimensional settings. In the first part, we introduce the DP-IHT-H method, which leverages the Huber loss and private iterative hard thresholding to achieve an estimation error bound of \( \tilde{O}\biggl( s^{* \frac{1 }{2}} \cdot \biggl(\frac{\log d}{n}\biggr)^{\frac{\zeta}{1 + \zeta}} + s^{* \frac{1 + 2\zeta}{2 + 2\zeta}} \cdot \biggl(\frac{\log^2 d}{n \varepsilon}\biggr)^{\frac{\zeta}{1 + \zeta}} \biggr) \) under the $(\varepsilon, \delta)$-DP model, where $n$ is the sample size, $d$ is the dimensionality, $s^*$ is the sparsity of the parameter, and $\zeta \in (0, 1]$ characterizes the tail heaviness of the data. In the second part, we propose DP-IHT-L, which further improves the error bound under additional assumptions on the response and achieves \( \tilde{O}\Bigl(\frac{(s^*)^{3/2} \log d}{n \varepsilon}\Bigr). \) Compared to the first result, this bound is independent of the tail parameter $\zeta$. Finally, through experiments on synthetic and real-world datasets, we demonstrate that our methods outperform standard DP algorithms designed for ``regular'' data.</li>
</ul>

<h3>Title: Face recognition on point cloud with cgan-top for denoising</h3>
<ul>
<li><strong>Authors: </strong>Junyu Liu, Jianfeng Ren, Sunhong Liang, Xudong Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06864">https://arxiv.org/abs/2506.06864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06864">https://arxiv.org/pdf/2506.06864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06864]] Face recognition on point cloud with cgan-top for denoising(https://arxiv.org/abs/2506.06864)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Face recognition using 3D point clouds is gaining growing interest, while raw point clouds often contain a significant amount of noise due to imperfect sensors. In this paper, an end-to-end 3D face recognition on a noisy point cloud is proposed, which synergistically integrates the denoising and recognition modules. Specifically, a Conditional Generative Adversarial Network on Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove the noise in the point cloud, and recover the underlying features for subsequent recognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) is then adapted to recognize faces from the processed point cloud, which hierarchically links both the local point features and neighboring features of multiple scales. The proposed method is validated on the Bosphorus dataset. It significantly improves the recognition accuracy under all noise settings, with a maximum gain of 14.81%.</li>
</ul>

<h3>Title: SAFE: Finding Sparse and Flat Minima to Improve Pruning</h3>
<ul>
<li><strong>Authors: </strong>Dongyeop Lee, Kwanhee Lee, Jinseok Chung, Namhoon Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06866">https://arxiv.org/abs/2506.06866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06866">https://arxiv.org/pdf/2506.06866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06866]] SAFE: Finding Sparse and Flat Minima to Improve Pruning(https://arxiv.org/abs/2506.06866)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sparsifying neural networks often suffers from seemingly inevitable performance degradation, and it remains challenging to restore the original performance despite much recent progress. Motivated by recent studies in robust optimization, we aim to tackle this problem by finding subnetworks that are both sparse and flat at the same time. Specifically, we formulate pruning as a sparsity-constrained optimization problem where flatness is encouraged as an objective. We solve it explicitly via an augmented Lagrange dual approach and extend it further by proposing a generalized projection operation, resulting in novel pruning methods called SAFE and its extension, SAFE$^+$. Extensive evaluations on standard image classification and language modeling tasks reveal that SAFE consistently yields sparse networks with improved generalization performance, which compares competitively to well-established baselines. In addition, SAFE demonstrates resilience to noisy data, making it well-suited for real-world conditions.</li>
</ul>

<h3>Title: Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning</h3>
<ul>
<li><strong>Authors: </strong>Armin Behnamnia, Gholamali Aminian, Alireza Aghaei, Chengchun Shi, Vincent Y. F. Tan, Hamid R. Rabiee</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06873">https://arxiv.org/abs/2506.06873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06873">https://arxiv.org/pdf/2506.06873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06873]] Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning(https://arxiv.org/abs/2506.06873)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Off-policy learning and evaluation leverage logged bandit feedback datasets, which contain context, action, propensity score, and feedback for each data point. These scenarios face significant challenges due to high variance and poor performance with low-quality propensity scores and heavy-tailed reward distributions. We address these issues by introducing a novel estimator based on the log-sum-exponential (LSE) operator, which outperforms traditional inverse propensity score estimators. Our LSE estimator demonstrates variance reduction and robustness under heavy-tailed conditions. For off-policy evaluation, we derive upper bounds on the estimator's bias and variance. In the off-policy learning scenario, we establish bounds on the regret -- the performance gap between our LSE estimator and the optimal policy -- assuming bounded $(1+\epsilon)$-th moment of weighted reward. Notably, we achieve a convergence rate of $O(n^{-\epsilon/(1+ \epsilon)})$ for the regret bounds, where $\epsilon \in [0,1]$ and $n$ is the size of logged bandit feedback dataset. Theoretical analysis is complemented by comprehensive empirical evaluations in both off-policy learning and evaluation scenarios, confirming the practical advantages of our approach. The code for our estimator is available at the following link: this https URL.</li>
</ul>

<h3>Title: Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jiaxing Guo, Wenjie Yang, Shengzhong Zhang, Tongshan Xu, Lun Du, Da Zheng, Zengfeng Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06877">https://arxiv.org/abs/2506.06877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06877">https://arxiv.org/pdf/2506.06877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06877]] Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning(https://arxiv.org/abs/2506.06877)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Outcome-rewarded Large Language Models (LLMs) have demonstrated remarkable success in mathematical problem-solving. However, this success often masks a critical issue: models frequently achieve correct answers through fundamentally unsound reasoning processes, a phenomenon indicative of reward hacking. We introduce MathOlympiadEval, a new dataset with fine-grained annotations, which reveals a significant gap between LLMs' answer correctness and their low process correctness. Existing automated methods like LLM-as-a-judge struggle to reliably detect these reasoning flaws. To address this, we propose ParaStepVerifier, a novel methodology for meticulous, step-by-step verification of mathematical solutions. ParaStepVerifier identifies incorrect reasoning steps. Empirical results demonstrate that ParaStepVerifier substantially improves the accuracy of identifying flawed solutions compared to baselines, especially for complex, multi-step problems. This offers a more robust path towards evaluating and training LLMs with genuine mathematical reasoning.</li>
</ul>

<h3>Title: FREE: Fast and Robust Vision Language Models with Early Exits</h3>
<ul>
<li><strong>Authors: </strong>Divya Jyoti Bajpai, Manjesh Kumar Hanawal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06884">https://arxiv.org/abs/2506.06884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06884">https://arxiv.org/pdf/2506.06884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06884]] FREE: Fast and Robust Vision Language Models with Early Exits(https://arxiv.org/abs/2506.06884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In recent years, Vision-Language Models (VLMs) have shown remarkable performance improvements in Vision-Language tasks. However, their large size poses challenges for real-world applications where inference latency is a concern. To tackle this issue, we propose employing Early Exit (EE) strategies in VLMs. However, training exit classifiers in VLMs is challenging, particularly with limited labeled training data. To address this, we introduce FREE, an adversarial training approach within a GAN-based framework. Here, each exit consists of a transformer layer and a classifier. The transformer layer is adversarially trained to produce feature representations similar to the final layer, while a feature classifier serves as the discriminator. Our method focuses on performing input-adaptive inference that increases inference speed with minimal drop in performance. Experimental results demonstrate the effectiveness of our approach in enhancing accuracy and model robustness by mitigating overthinking and the phenomenon of mid-crisis that we highlight. We experimentally validate that our method speeds up the inference process by more than 1.51x while retaining comparable performance. The source code is available at this https URL.</li>
</ul>

<h3>Title: Hybrid Vision Transformer-Mamba Framework for Autism Diagnosis via Eye-Tracking Analysis</h3>
<ul>
<li><strong>Authors: </strong>Wafaa Kasri, Yassine Himeur, Abigail Copiaco, Wathiq Mansoor, Ammar Albanna, Valsamma Eapen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06886">https://arxiv.org/abs/2506.06886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06886">https://arxiv.org/pdf/2506.06886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06886]] Hybrid Vision Transformer-Mamba Framework for Autism Diagnosis via Eye-Tracking Analysis(https://arxiv.org/abs/2506.06886)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate Autism Spectrum Disorder (ASD) diagnosis is vital for early intervention. This study presents a hybrid deep learning framework combining Vision Transformers (ViT) and Vision Mamba to detect ASD using eye-tracking data. The model uses attention-based fusion to integrate visual, speech, and facial cues, capturing both spatial and temporal dynamics. Unlike traditional handcrafted methods, it applies state-of-the-art deep learning and explainable AI techniques to enhance diagnostic accuracy and transparency. Tested on the Saliency4ASD dataset, the proposed ViT-Mamba model outperformed existing methods, achieving 0.96 accuracy, 0.95 F1-score, 0.97 sensitivity, and 0.94 specificity. These findings show the model's promise for scalable, interpretable ASD screening, especially in resource-constrained or remote clinical settings where access to expert diagnosis is limited.</li>
</ul>

<h3>Title: Mixture of Small and Large Models for Chinese Spelling Check</h3>
<ul>
<li><strong>Authors: </strong>Ziheng Qiao, Houquan Zhou, Zhenghua Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06887">https://arxiv.org/abs/2506.06887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06887">https://arxiv.org/pdf/2506.06887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06887]] Mixture of Small and Large Models for Chinese Spelling Check(https://arxiv.org/abs/2506.06887)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the era of large language models (LLMs), the Chinese Spelling Check (CSC) task has seen various LLM methods developed, yet their performance remains unsatisfactory. In contrast, fine-tuned BERT-based models, relying on high-quality in-domain data, show excellent performance but suffer from edit pattern overfitting. This paper proposes a novel dynamic mixture approach that effectively combines the probability distributions of small models and LLMs during the beam search decoding phase, achieving a balanced enhancement of precise corrections from small models and the fluency of LLMs. This approach also eliminates the need for fine-tuning LLMs, saving significant time and resources, and facilitating domain adaptation. Comprehensive experiments demonstrate that our mixture approach significantly boosts error correction capabilities, achieving state-of-the-art results across multiple datasets. Our code is available at this https URL.</li>
</ul>

<h3>Title: Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?</h3>
<ul>
<li><strong>Authors: </strong>Paulius Sasnauskas, Yiğit Yalın, Goran Radanović</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06891">https://arxiv.org/abs/2506.06891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06891">https://arxiv.org/pdf/2506.06891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06891]] Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?(https://arxiv.org/abs/2506.06891)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>We study the corruption-robustness of in-context reinforcement learning (ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al., 2023). To address the challenge of reward poisoning attacks targeting the DPT, we propose a novel adversarial training framework, called Adversarially Trained Decision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an attacker to minimize the true reward of the DPT by poisoning environment rewards, and a DPT model to infer optimal actions from the poisoned data. We evaluate the effectiveness of our approach against standard bandit algorithms, including robust baselines designed to handle reward contamination. Our results show that the proposed method significantly outperforms these baselines in bandit settings, under a learned attacker. We additionally evaluate AT-DPT on an adaptive attacker, and observe similar results. Furthermore, we extend our evaluation to the MDP setting, confirming that the robustness observed in bandit scenarios generalizes to more complex environments.</li>
</ul>

<h3>Title: KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search</h3>
<ul>
<li><strong>Authors: </strong>Nima Jamali, Matina Mahdizadeh Sani, Hanieh Naderi, Shohreh Kasaei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06906">https://arxiv.org/abs/2506.06906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06906">https://arxiv.org/pdf/2506.06906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06906]] KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search(https://arxiv.org/abs/2506.06906)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) have demonstrated remarkable performance in analyzing 3D point cloud data. However, their vulnerability to adversarial attacks-such as point dropping, shifting, and adding-poses a critical challenge to the reliability of 3D vision systems. These attacks can compromise the semantic and structural integrity of point clouds, rendering many existing defense mechanisms ineffective. To address this issue, a defense strategy named KNN-Defense is proposed, grounded in the manifold assumption and nearest-neighbor search in feature space. Instead of reconstructing surface geometry or enforcing uniform point distributions, the method restores perturbed inputs by leveraging the semantic similarity of neighboring samples from the training set. KNN-Defense is lightweight and computationally efficient, enabling fast inference and making it suitable for real-time and practical applications. Empirical results on the ModelNet40 dataset demonstrated that KNN-Defense significantly improves robustness across various attack types. In particular, under point-dropping attacks-where many existing methods underperform due to the targeted removal of critical points-the proposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% on PointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest that KNN-Defense offers a scalable and effective solution for enhancing the adversarial resilience of 3D point cloud classifiers. (An open-source implementation of the method, including code and data, is available at this https URL).</li>
</ul>

<h3>Title: Basis Transformers for Multi-Task Tabular Regression</h3>
<ul>
<li><strong>Authors: </strong>Wei Min Loh, Jiaqi Shang, Pascal Poupart</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06926">https://arxiv.org/abs/2506.06926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06926">https://arxiv.org/pdf/2506.06926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06926]] Basis Transformers for Multi-Task Tabular Regression(https://arxiv.org/abs/2506.06926)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Dealing with tabular data is challenging due to partial information, noise, and heterogeneous structure. Existing techniques often struggle to simultaneously address key aspects of tabular data such as textual information, a variable number of columns, and unseen data without metadata besides column names. We propose a novel architecture, \textit{basis transformers}, specifically designed to tackle these challenges while respecting inherent invariances in tabular data, including hierarchical structure and the representation of numeric values. We evaluate our design on a multi-task tabular regression benchmark, achieving an improvement of 0.338 in the median $R^2$ score and the lowest standard deviation across 34 tasks from the OpenML-CTR23 benchmark. Furthermore, our model has five times fewer parameters than the best-performing baseline and surpasses pretrained large language model baselines -- even when initialized from randomized weights.</li>
</ul>

<h3>Title: How Important are Videos for Training Video LLMs?</h3>
<ul>
<li><strong>Authors: </strong>George Lydakis, Alexander Hermans, Ali Athar, Daan de Geus, Bastian Leibe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06928">https://arxiv.org/abs/2506.06928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06928">https://arxiv.org/pdf/2506.06928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06928]] How Important are Videos for Training Video LLMs?(https://arxiv.org/abs/2506.06928)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Research into Video Large Language Models (LLMs) has progressed rapidly, with numerous models and benchmarks emerging in just a few years. Typically, these models are initialized with a pretrained text-only LLM and finetuned on both image- and video-caption datasets. In this paper, we present findings indicating that Video LLMs are more capable of temporal reasoning after image-only training than one would assume, and that improvements from video-specific training are surprisingly small. Specifically, we show that image-trained versions of two LLMs trained with the recent LongVU algorithm perform significantly above chance level on TVBench, a temporal reasoning benchmark. Additionally, we introduce a simple finetuning scheme involving sequences of annotated images and questions targeting temporal capabilities. This baseline results in temporal reasoning performance close to, and occasionally higher than, what is achieved by video-trained LLMs. This suggests suboptimal utilization of rich temporal features found in real video by current models. Our analysis motivates further research into the mechanisms that allow image-trained LLMs to perform temporal reasoning, as well as into the bottlenecks that render current video training schemes inefficient.</li>
</ul>

<h3>Title: Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mikhail Krasitskii, Grigori Sidorov, Olga Kolesnikova, Liliana Chanona Hernandez, Alexander Gelbukh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06929">https://arxiv.org/abs/2506.06929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06929">https://arxiv.org/pdf/2506.06929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06929]] Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis(https://arxiv.org/abs/2506.06929)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We propose a hybrid approach for multilingual sentiment analysis that combines extractive and abstractive summarization to address the limitations of standalone methods. The model integrates TF-IDF-based extraction with a fine-tuned XLM-R abstractive module, enhanced by dynamic thresholding and cultural adaptation. Experiments across 10 languages show significant improvements over baselines, achieving 0.90 accuracy for English and 0.84 for low-resource languages. The approach also demonstrates 22% greater computational efficiency than traditional methods. Practical applications include real-time brand monitoring and cross-cultural discourse analysis. Future work will focus on optimization for low-resource languages via 8-bit quantization.</li>
</ul>

<h3>Title: DiscoSum: Discourse-aware News Summarization</h3>
<ul>
<li><strong>Authors: </strong>Alexander Spangher, Tenghao Huang, Jialiang Gu, Jiatong Shi, Muhao Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06930">https://arxiv.org/abs/2506.06930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06930">https://arxiv.org/pdf/2506.06930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06930]] DiscoSum: Discourse-aware News Summarization(https://arxiv.org/abs/2506.06930)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in text summarization have predominantly leveraged large language models to generate concise summaries. However, language models often do not maintain long-term discourse structure, especially in news articles, where organizational flow significantly influences reader engagement. We introduce a novel approach to integrating discourse structure into summarization processes, focusing specifically on news articles across various media. We present a novel summarization dataset where news articles are summarized multiple times in different ways across different social media platforms (e.g. LinkedIn, Facebook, etc.). We develop a novel news discourse schema to describe summarization structures and a novel algorithm, DiscoSum, which employs beam search technique for structure-aware summarization, enabling the transformation of news stories to meet different stylistic and structural demands. Both human and automatic evaluation results demonstrate the efficacy of our approach in maintaining narrative fidelity and meeting structural requirements.</li>
</ul>

<h3>Title: Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Salmani, Alireza Abdollahpoorrostam, Seyed-Mohsen Moosavi-Dezfooli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06933">https://arxiv.org/abs/2506.06933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06933">https://arxiv.org/pdf/2506.06933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06933]] Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry(https://arxiv.org/abs/2506.06933)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Traditional decision-based black-box adversarial attacks on image classifiers aim to generate adversarial examples by slightly modifying input images while keeping the number of queries low, where each query involves sending an input to the model and observing its output. Most existing methods assume that all queries have equal cost. However, in practice, queries may incur asymmetric costs; for example, in content moderation systems, certain output classes may trigger additional review, enforcement, or penalties, making them more costly than others. While prior work has considered such asymmetric cost settings, effective algorithms for this scenario remain underdeveloped. In this paper, we propose a general framework for decision-based attacks under asymmetric query costs, which we refer to as asymmetric black-box attacks. We modify two core components of existing attacks: the search strategy and the gradient estimation process. Specifically, we propose Asymmetric Search (AS), a more conservative variant of binary search that reduces reliance on high-cost queries, and Asymmetric Gradient Estimation (AGREST), which shifts the sampling distribution to favor low-cost queries. We design efficient algorithms that minimize total attack cost by balancing different query types, in contrast to earlier methods such as stealthy attacks that focus only on limiting expensive (high-cost) queries. Our method can be integrated into a range of existing black-box attacks with minimal changes. We perform both theoretical analysis and empirical evaluation on standard image classification benchmarks. Across various cost regimes, our method consistently achieves lower total query cost and smaller perturbations than existing approaches, with improvements of up to 40% in some settings.</li>
</ul>

<h3>Title: Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences</h3>
<ul>
<li><strong>Authors: </strong>Mellon M. Zhang, Glen Chou, Saibal Mukhopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06944">https://arxiv.org/abs/2506.06944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06944">https://arxiv.org/pdf/2506.06944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06944]] Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences(https://arxiv.org/abs/2506.06944)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate and efficient object detection is essential for autonomous vehicles, where real-time perception requires low latency and high throughput. LiDAR sensors provide robust depth information, but conventional methods process full 360° scans in a single pass, introducing significant delay. Streaming approaches address this by sequentially processing partial scans in the native polar coordinate system, yet they rely on translation-invariant convolutions that are misaligned with polar geometry -- resulting in degraded performance or requiring complex distortion mitigation. Recent Mamba-based state space models (SSMs) have shown promise for LiDAR perception, but only in the full-scan setting, relying on geometric serialization and positional embeddings that are memory-intensive and ill-suited to streaming. We propose Polar Hierarchical Mamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming LiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial encoding and a global forward Mamba for inter-sector temporal modeling, replacing convolutions and positional encodings with distortion-aware, dimensionally-decomposed operations. PHiM sets a new state-of-the-art among streaming detectors on the Waymo Open Dataset, outperforming the previous best by 10\% and matching full-scan baselines at twice the throughput. Code will be available at this https URL .</li>
</ul>

<h3>Title: What Makes a Good Natural Language Prompt?</h3>
<ul>
<li><strong>Authors: </strong>Do Xuan Long, Duy Dinh, Ngoc-Hai Nguyen, Kenji Kawaguchi, Nancy F. Chen, Shafiq Joty, Min-Yen Kan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06950">https://arxiv.org/abs/2506.06950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06950">https://arxiv.org/pdf/2506.06950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06950]] What Makes a Good Natural Language Prompt?(https://arxiv.org/abs/2506.06950)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) have progressed towards more human-like and human--AI communications have become prevalent, prompting has emerged as a decisive component. However, there is limited conceptual consensus on what exactly quantifies natural language prompts. We attempt to address this question by conducting a meta-analysis surveying more than 150 prompting-related papers from leading NLP and AI conferences from 2022 to 2025 and blogs. We propose a property- and human-centric framework for evaluating prompt quality, encompassing 21 properties categorized into six dimensions. We then examine how existing studies assess their impact on LLMs, revealing their imbalanced support across models and tasks, and substantial research gaps. Further, we analyze correlations among properties in high-quality natural language prompts, deriving prompting recommendations. We then empirically explore multi-property prompt enhancements in reasoning tasks, observing that single-property enhancements often have the greatest impact. Finally, we discover that instruction-tuning on property-enhanced prompts can result in better reasoning models. Our findings establish a foundation for property-centric prompt evaluation and optimization, bridging the gaps between human--AI communication and opening new prompting research directions.</li>
</ul>

<h3>Title: LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer</h3>
<ul>
<li><strong>Authors: </strong>Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou, Lifu Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06952">https://arxiv.org/abs/2506.06952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06952">https://arxiv.org/pdf/2506.06952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06952]] LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer(https://arxiv.org/abs/2506.06952)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in multimodal foundation models unifying image understanding and generation have opened exciting avenues for tackling a wide range of vision-language tasks within a single framework. Despite progress, existing unified models typically require extensive pretraining and struggle to achieve the same level of performance compared to models dedicated to each task. Additionally, many of these models suffer from slow image generation speeds, limiting their practical deployment in real-time or resource-constrained settings. In this work, we propose Layerwise Timestep-Expert Flow-based Transformer (LaTtE-Flow), a novel and efficient architecture that unifies image understanding and generation within a single multimodal model. LaTtE-Flow builds upon powerful pretrained Vision-Language Models (VLMs) to inherit strong multimodal understanding capabilities, and extends them with a novel Layerwise Timestep Experts flow-based architecture for efficient image generation. LaTtE-Flow distributes the flow-matching process across specialized groups of Transformer layers, each responsible for a distinct subset of timesteps. This design significantly improves sampling efficiency by activating only a small subset of layers at each sampling timestep. To further enhance performance, we propose a Timestep-Conditioned Residual Attention mechanism for efficient information reuse across layers. Experiments demonstrate that LaTtE-Flow achieves strong performance on multimodal understanding tasks, while achieving competitive image generation quality with around 6x faster inference speed compared to recent unified multimodal models.</li>
</ul>

<h3>Title: BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ha-Thanh Nguyen, Chaoran Liu, Hirokazu Kiyomaru, Koichi Takeda, Yusuke Miyao, Maki Matsuda, Yusuke Oda, Pontus Stenetorp, Qianying Liu, Su Myat Noe, Hideyuki Tachibana, Kouta Nakayama, Sadao Kurohashi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06955">https://arxiv.org/abs/2506.06955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06955">https://arxiv.org/pdf/2506.06955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06955]] BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning(https://arxiv.org/abs/2506.06955)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present BIS Reasoning 1.0, the first large-scale Japanese dataset of syllogistic reasoning problems explicitly designed to evaluate belief-inconsistent reasoning in large language models (LLMs). Unlike prior datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent syllogisms to uncover reasoning biases in LLMs trained on human-aligned corpora. We benchmark state-of-the-art models - including GPT models, Claude models, and leading Japanese LLMs - revealing significant variance in performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies critical weaknesses in current LLMs when handling logically valid but belief-conflicting inputs. These findings have important implications for deploying LLMs in high-stakes domains such as law, healthcare, and scientific literature, where truth must override intuitive belief to ensure integrity and safety.</li>
</ul>

<h3>Title: Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Subhojyoti Mukherjee, Viet Dac Lai, Raghavendra Addanki, Ryan Rossi, Seunghyun Yoon, Trung Bui, Anup Rao, Jayakumar Subramanian, Branislav Kveton</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06964">https://arxiv.org/abs/2506.06964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06964">https://arxiv.org/pdf/2506.06964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06964]] Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning(https://arxiv.org/abs/2506.06964)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Question answering (QA) agents automatically answer questions posed in natural language. In this work, we learn to ask clarifying questions in QA agents. The key idea in our method is to simulate conversations that contain clarifying questions and learn from them using reinforcement learning (RL). To make RL practical, we propose and analyze offline RL objectives that can be viewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in large language models. Our work stands in a stark contrast to recently proposed methods, based on SFT and direct preference optimization, which have additional hyper-parameters and do not directly optimize rewards. We compare to these methods empirically and report gains in both optimized rewards and language quality.</li>
</ul>

<h3>Title: Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Jing, Guangxue Wang, Haoyang Zhai, Qin Tao, Jun Yang, Bing Wang, Peng Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06966">https://arxiv.org/abs/2506.06966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06966">https://arxiv.org/pdf/2506.06966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06966]] Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition(https://arxiv.org/abs/2506.06966)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Due to the emergence of many sign language datasets, isolated sign language recognition (ISLR) has made significant progress in recent years. In addition, the development of various advanced deep neural networks is another reason for this breakthrough. However, challenges remain in applying the technique in the real world. First, existing sign language datasets do not cover the whole sign vocabulary. Second, most of the sign language datasets provide only single view RGB videos, which makes it difficult to handle hand occlusions when performing ISLR. To fill this gap, this paper presents a dual-view sign language dataset for ISLR named NationalCSL-DP, which fully covers the Chinese national sign language vocabulary. The dataset consists of 134140 sign videos recorded by ten signers with respect to two vertical views, namely, the front side and the left side. Furthermore, a CNN transformer network is also proposed as a strong baseline and an extremely simple but effective fusion strategy for prediction. Extensive experiments were conducted to prove the effectiveness of the datasets as well as the baseline. The results show that the proposed fusion strategy can significantly increase the performance of the ISLR, but it is not easy for the sequence-to-sequence model, regardless of whether the early-fusion or late-fusion strategy is applied, to learn the complementary features from the sign videos of two vertical views.</li>
</ul>

<h3>Title: Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06970">https://arxiv.org/abs/2506.06970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06970">https://arxiv.org/pdf/2506.06970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06970]] Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment(https://arxiv.org/abs/2506.06970)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability to retrieve content across modalities, a substantial modality gap persists in its feature space. Intriguingly, we discover that off-the-shelf MLLMs (Multimodal Large Language Models) demonstrate powerful inherent modality alignment properties. While recent MLLM-based retrievers with unified architectures partially mitigate this gap, their reliance on coarse modality alignment mechanisms fundamentally limits their potential. In this work, We introduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel framework that leverages the fine grained alignment priors inherent in MLLM to guide cross modal representation learning. MAPLE formulates the learning process as reinforcement learning with two key components: (1) Automatic preference data construction using off-the-shelf MLLM, and (2) a new Relative Preference Alignment (RPA) loss, which adapts Direct Preference Optimization (DPO) to the embedding learning setting. Experimental results show that our preference-guided alignment achieves substantial gains in fine-grained cross-modal retrieval, underscoring its effectiveness in handling nuanced semantic distinctions.</li>
</ul>

<h3>Title: Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Jaechul Roh, Varun Gandhi, Shivani Anilkumar, Arin Garg</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06971">https://arxiv.org/abs/2506.06971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06971">https://arxiv.org/pdf/2506.06971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06971]] Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation(https://arxiv.org/abs/2506.06971)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success in tasks requiring complex reasoning, such as code generation, mathematical problem solving, and algorithmic synthesis -- especially when aided by reasoning tokens and Chain-of-Thought prompting. Yet, a core question remains: do these models truly reason, or do they merely exploit shallow statistical patterns? In this paper, we systematically investigate the robustness of reasoning LLMs by introducing a suite of semantically faithful yet adversarially structured prompt perturbations. Our evaluation -- spanning 700 perturbed code generations derived from LeetCode-style problems -- applies transformations such as storytelling reframing, irrelevant constraint injection, example reordering, and numeric perturbation. We observe that while certain modifications severely degrade performance (with accuracy drops up to -42.1%), others surprisingly improve model accuracy by up to 35.3%, suggesting sensitivity not only to semantics but also to surface-level prompt dynamics. These findings expose the fragility and unpredictability of current reasoning systems, underscoring the need for more principles approaches to reasoning alignments and prompting robustness. We release our perturbation datasets and evaluation framework to promote further research in trustworthy and resilient LLM reasoning.</li>
</ul>

<h3>Title: Atomic Reasoning for Scientific Table Claim Verification</h3>
<ul>
<li><strong>Authors: </strong>Yuji Zhang, Qingyun Wang, Cheng Qian, Jiateng Liu, Chenkai Sun, Denghui Zhang, Tarek Abdelzaher, Chengxiang Zhai, Preslav Nakov, Heng Ji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06972">https://arxiv.org/abs/2506.06972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06972">https://arxiv.org/pdf/2506.06972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06972]] Atomic Reasoning for Scientific Table Claim Verification(https://arxiv.org/abs/2506.06972)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scientific texts often convey authority due to their technical language and complex data. However, this complexity can sometimes lead to the spread of misinformation. Non-experts are particularly susceptible to misleading claims based on scientific tables due to their high information density and perceived credibility. Existing table claim verification models, including state-of-the-art large language models (LLMs), often struggle with precise fine-grained reasoning, resulting in errors and a lack of precision in verifying scientific claims. Inspired by Cognitive Load Theory, we propose that enhancing a model's ability to interpret table-based claims involves reducing cognitive load by developing modular, reusable reasoning components (i.e., atomic skills). We introduce a skill-chaining schema that dynamically composes these skills to facilitate more accurate and generalizable reasoning with a reduced cognitive load. To evaluate this, we create SciAtomicBench, a cross-domain benchmark with fine-grained reasoning annotations. With only 350 fine-tuning examples, our model trained by atomic reasoning outperforms GPT-4o's chain-of-thought method, achieving state-of-the-art results with far less training data.</li>
</ul>

<h3>Title: Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyuan Zhu, Yaowen Ye, Tianyi Qiu, Hanlin Zhu, Sijun Tan, Ajraf Mannan, Jonathan Michala, Raluca Ada Popa, Willie Neiswanger</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06975">https://arxiv.org/abs/2506.06975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06975">https://arxiv.org/pdf/2506.06975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06975]] Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test(https://arxiv.org/abs/2506.06975)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As API access becomes a primary interface to large language models (LLMs), users often interact with black-box systems that offer little transparency into the deployed model. To reduce costs or maliciously alter model behaviors, API providers may discreetly serve quantized or fine-tuned variants, which can degrade performance and compromise safety. Detecting such substitutions is difficult, as users lack access to model weights and, in most cases, even output logits. To tackle this problem, we propose a rank-based uniformity test that can verify the behavioral equality of a black-box LLM to a locally deployed authentic model. Our method is accurate, query-efficient, and avoids detectable query patterns, making it robust to adversarial providers that reroute or mix responses upon the detection of testing attempts. We evaluate the approach across diverse threat scenarios, including quantization, harmful fine-tuning, jailbreak prompts, and full model substitution, showing that it consistently achieves superior statistical power over prior methods under constrained query budgets.</li>
</ul>

<h3>Title: MoXGATE: Modality-aware cross-attention for multi-omic gastrointestinal cancer sub-type classification</h3>
<ul>
<li><strong>Authors: </strong>Sajib Acharjee Dip, Uddip Acharjee Shuvo, Dipanwita Mallick, Abrar Rahman Abir, Liqing Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06980">https://arxiv.org/abs/2506.06980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06980">https://arxiv.org/pdf/2506.06980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06980]] MoXGATE: Modality-aware cross-attention for multi-omic gastrointestinal cancer sub-type classification(https://arxiv.org/abs/2506.06980)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Cancer subtype classification is crucial for personalized treatment and prognostic assessment. However, effectively integrating multi-omic data remains challenging due to the heterogeneous nature of genomic, epigenomic, and transcriptomic features. In this work, we propose Modality-Aware Cross-Attention MoXGATE, a novel deep-learning framework that leverages cross-attention and learnable modality weights to enhance feature fusion across multiple omics sources. Our approach effectively captures inter-modality dependencies, ensuring robust and interpretable integration. Through experiments on Gastrointestinal Adenocarcinoma (GIAC) and Breast Cancer (BRCA) datasets from TCGA, we demonstrate that MoXGATE outperforms existing methods, achieving 95\% classification accuracy. Ablation studies validate the effectiveness of cross-attention over simple concatenation and highlight the importance of different omics modalities. Moreover, our model generalizes well to unseen cancer types e.g., breast cancer, underscoring its adaptability. Key contributions include (1) a cross-attention-based multi-omic integration framework, (2) modality-weighted fusion for enhanced interpretability, (3) application of focal loss to mitigate data imbalance, and (4) validation across multiple cancer subtypes. Our results indicate that MoXGATE is a promising approach for multi-omic cancer subtype classification, offering improved performance and biological generalizability.</li>
</ul>

<h3>Title: Chain of Methodologies: Scaling Test Time Computation without Training</h3>
<ul>
<li><strong>Authors: </strong>Cong Liu, Jie Wu, Weigang Wu, Xu Chen, Liang Lin, Wei-Shi Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06982">https://arxiv.org/abs/2506.06982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06982">https://arxiv.org/pdf/2506.06982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06982]] Chain of Methodologies: Scaling Test Time Computation without Training(https://arxiv.org/abs/2506.06982)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often struggle with complex reasoning tasks due to insufficient in-depth insights in their training data, which are typically absent in publicly available documents. This paper introduces the Chain of Methodologies (CoM), an innovative and intuitive prompting framework that enhances structured thinking by integrating human methodological insights, enabling LLMs to tackle complex tasks with extended reasoning. CoM leverages the metacognitive abilities of advanced LLMs, activating systematic reasoning throught user-defined methodologies without explicit fine-tuning. Experiments show that CoM surpasses competitive baselines, demonstrating the potential of training-free prompting methods as robust solutions for complex reasoning tasks and bridging the gap toward human-level reasoning through human-like methodological insights.</li>
</ul>

<h3>Title: Certified Unlearning for Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Anastasia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06985">https://arxiv.org/abs/2506.06985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06985">https://arxiv.org/pdf/2506.06985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06985]] Certified Unlearning for Neural Networks(https://arxiv.org/abs/2506.06985)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We address the problem of machine unlearning, where the goal is to remove the influence of specific training data from a model upon request, motivated by privacy concerns and regulatory requirements such as the "right to be forgotten." Unfortunately, existing methods rely on restrictive assumptions or lack formal guarantees. To this end, we propose a novel method for certified machine unlearning, leveraging the connection between unlearning and privacy amplification by stochastic post-processing. Our method uses noisy fine-tuning on the retain data, i.e., data that does not need to be removed, to ensure provable unlearning guarantees. This approach requires no assumptions about the underlying loss function, making it broadly applicable across diverse settings. We analyze the theoretical trade-offs in efficiency and accuracy and demonstrate empirically that our method not only achieves formal unlearning guarantees but also performs effectively in practice, outperforming existing baselines. Our code is available at this https URL</li>
</ul>

<h3>Title: Fully Explainable Classification Models Using Hyperblocks</h3>
<ul>
<li><strong>Authors: </strong>Austin Snyder, Ryan Gallagher, Boris Kovalerchuk</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06986">https://arxiv.org/abs/2506.06986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06986">https://arxiv.org/pdf/2506.06986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06986]] Fully Explainable Classification Models Using Hyperblocks(https://arxiv.org/abs/2506.06986)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Building on existing work with Hyperblocks, which classify data using minimum and maximum bounds for each attribute, we focus on enhancing interpretability, decreasing training time, and reducing model complexity without sacrificing accuracy. This system allows subject matter experts (SMEs) to directly inspect and understand the model's decision logic without requiring extensive machine learning expertise. To reduce Hyperblock complexity while retaining performance, we introduce a suite of algorithms for Hyperblock simplification. These include removing redundant attributes, removing redundant blocks through overlap analysis, and creating disjunctive units. These methods eliminate unnecessary parameters, dramatically reducing model size without harming classification power. We increase robustness by introducing an interpretable fallback mechanism using k-Nearest Neighbor (k-NN) classifiers for points not covered by any block, ensuring complete data coverage while preserving model transparency. Our results demonstrate that interpretable models can scale to high-dimensional, large-volume datasets while maintaining competitive accuracy. On benchmark datasets such as WBC (9-D), we achieve strong predictive performance with significantly reduced complexity. On MNIST (784-D), our method continues to improve through tuning and simplification, showing promise as a transparent alternative to black-box models in domains where trust, clarity, and control are crucial.</li>
</ul>

<h3>Title: Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors</h3>
<ul>
<li><strong>Authors: </strong>Senqi Yang, Dongyu Zhang, Jing Ren, Ziqi Xu, Xiuzhen Zhang, Yiliao Song, Hongfei Lin, Feng Xia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06987">https://arxiv.org/abs/2506.06987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06987">https://arxiv.org/pdf/2506.06987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06987]] Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors(https://arxiv.org/abs/2506.06987)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Metaphors are pervasive in communication, making them crucial for natural language processing (NLP). Previous research on automatic metaphor processing predominantly relies on training data consisting of English samples, which often reflect Western European or North American biases. This cultural skew can lead to an overestimation of model performance and contributions to NLP progress. However, the impact of cultural bias on metaphor processing, particularly in multimodal contexts, remains largely unexplored. To address this gap, we introduce MultiMM, a Multicultural Multimodal Metaphor dataset designed for cross-cultural studies of metaphor in Chinese and English. MultiMM consists of 8,461 text-image advertisement pairs, each accompanied by fine-grained annotations, providing a deeper understanding of multimodal metaphors beyond a single cultural domain. Additionally, we propose Sentiment-Enriched Metaphor Detection (SEMD), a baseline model that integrates sentiment embeddings to enhance metaphor comprehension across cultural backgrounds. Experimental results validate the effectiveness of SEMD on metaphor detection and sentiment analysis tasks. We hope this work increases awareness of cultural bias in NLP research and contributes to the development of fairer and more inclusive language models. Our dataset and code are available at this https URL.</li>
</ul>

<h3>Title: Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yanting Gao, Yepeng Liu, Junming Liu, Qi Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06992">https://arxiv.org/abs/2506.06992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06992">https://arxiv.org/pdf/2506.06992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06992]] Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization(https://arxiv.org/abs/2506.06992)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>Exploring effective and transferable adversarial examples is vital for understanding the characteristics and mechanisms of Vision Transformers (ViTs). However, adversarial examples generated from surrogate models often exhibit weak transferability in black-box settings due to overfitting. Existing methods improve transferability by diversifying perturbation inputs or applying uniform gradient regularization within surrogate models, yet they have not fully leveraged the shared and unique features of surrogate models trained on the same task, leading to suboptimal transfer performance. Therefore, enhancing perturbations of common information shared by surrogate models and suppressing those tied to individual characteristics offers an effective way to improve transferability. Accordingly, we propose a commonality-oriented gradient optimization strategy (COGO) consisting of two components: Commonality Enhancement (CE) and Individuality Suppression (IS). CE perturbs the mid-to-low frequency regions, leveraging the fact that ViTs trained on the same dataset tend to rely more on mid-to-low frequency information for classification. IS employs adaptive thresholds to evaluate the correlation between backpropagated gradients and model individuality, assigning weights to gradients accordingly. Extensive experiments demonstrate that COGO significantly improves the transfer success rates of adversarial attacks, outperforming current state-of-the-art methods.</li>
</ul>

<h3>Title: DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching</h3>
<ul>
<li><strong>Authors: </strong>Cong Guan, Jiacheng Ying, Yuya Ieiri, Osamu Yoshie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06993">https://arxiv.org/abs/2506.06993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06993">https://arxiv.org/pdf/2506.06993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06993]] DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching(https://arxiv.org/abs/2506.06993)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dual-camera super-resolution is highly practical for smartphone photography that primarily super-resolve the wide-angle images using the telephoto image as a reference. In this paper, we propose DM$^3$Net, a novel dual-camera super-resolution network based on Domain Modulation and Multi-scale Matching. To bridge the domain gap between the high-resolution domain and the degraded domain, we learn two compressed global representations from image pairs corresponding to the two domains. To enable reliable transfer of high-frequency structural details from the reference image, we design a multi-scale matching module that conducts patch-level feature matching and retrieval across multiple receptive fields to improve matching accuracy and robustness. Moreover, we also introduce Key Pruning to achieve a significant reduction in memory usage and inference time with little model performance sacrificed. Experimental results on three real-world datasets demonstrate that our DM$^3$Net outperforms the state-of-the-art approaches.</li>
</ul>

<h3>Title: Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems</h3>
<ul>
<li><strong>Authors: </strong>Xiaoya Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06995">https://arxiv.org/abs/2506.06995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06995">https://arxiv.org/pdf/2506.06995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06995]] Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems(https://arxiv.org/abs/2506.06995)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>This technical report presents the implementation details of the winning solution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. This challenge focuses on semantic segmentation of 3D point clouds from diverse unstructured outdoor environments collected from multiple robotic platforms. This problem was addressed by implementing Point Prompt Tuning (PPT) integrated with Point Transformer v3 (PTv3) backbone, enabling adaptive processing of heterogeneous LiDAR data through platform-specific conditioning and cross-dataset class alignment strategies. The model is trained without requiring additional external data. As a result, this approach achieved substantial performance improvements with mIoU increases of up to 22.59% on challenging platforms compared to the baseline PTv3 model, demonstrating the effectiveness of adaptive point cloud understanding for field robotics applications.</li>
</ul>

<h3>Title: Towards Physics-informed Diffusion for Anomaly Detection in Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Arun Sharma, Mingzhou Yang, Majid Farhadloo, Subhankar Ghosh, Bharat Jayaprakash, Shashi Shekhar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.06999">https://arxiv.org/abs/2506.06999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.06999">https://arxiv.org/pdf/2506.06999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.06999]] Towards Physics-informed Diffusion for Anomaly Detection in Trajectories(https://arxiv.org/abs/2506.06999)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Given trajectory data, a domain-specific study area, and a user-defined threshold, we aim to find anomalous trajectories indicative of possible GPS spoofing (e.g., fake trajectory). The problem is societally important to curb illegal activities in international waters, such as unauthorized fishing and illicit oil transfers. The problem is challenging due to advances in AI generated in deep fakes generation (e.g., additive noise, fake trajectories) and lack of adequate amount of labeled samples for ground-truth verification. Recent literature shows promising results for anomalous trajectory detection using generative models despite data sparsity. However, they do not consider fine-scale spatiotemporal dependencies and prior physical knowledge, resulting in higher false-positive rates. To address these limitations, we propose a physics-informed diffusion model that integrates kinematic constraints to identify trajectories that do not adhere to physical laws. Experimental results on real-world datasets in the maritime and urban domains show that the proposed framework results in higher prediction accuracy and lower estimation error rate for anomaly detection and trajectory generation methods, respectively. Our implementation is available at this https URL.</li>
</ul>

<h3>Title: Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text</h3>
<ul>
<li><strong>Authors: </strong>Yize Cheng, Vinu Sankar Sadasivan, Mehrdad Saberi, Shoumik Saha, Soheil Feizi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07001">https://arxiv.org/abs/2506.07001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07001">https://arxiv.org/pdf/2506.07001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07001]] Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text(https://arxiv.org/abs/2506.07001)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>The increasing capabilities of Large Language Models (LLMs) have raised concerns about their misuse in AI-generated plagiarism and social engineering. While various AI-generated text detectors have been proposed to mitigate these risks, many remain vulnerable to simple evasion techniques such as paraphrasing. However, recent detectors have shown greater robustness against such basic attacks. In this work, we introduce Adversarial Paraphrasing, a training-free attack framework that universally humanizes any AI-generated text to evade detection more effectively. Our approach leverages an off-the-shelf instruction-following LLM to paraphrase AI-generated content under the guidance of an AI text detector, producing adversarial examples that are specifically optimized to bypass detection. Extensive experiments show that our attack is both broadly effective and highly transferable across several detection systems. For instance, compared to simple paraphrasing attack--which, ironically, increases the true positive at 1% false positive (T@1%F) by 8.57% on RADAR and 15.03% on Fast-DetectGPT--adversarial paraphrasing, guided by OpenAI-RoBERTa-Large, reduces T@1%F by 64.49% on RADAR and a striking 98.96% on Fast-DetectGPT. Across a diverse set of detectors--including neural network-based, watermark-based, and zero-shot approaches--our attack achieves an average T@1%F reduction of 87.88% under the guidance of OpenAI-RoBERTa-Large. We also analyze the tradeoff between text quality and attack success to find that our method can significantly reduce detection rates, with mostly a slight degradation in text quality. Our adversarial setup highlights the need for more robust and resilient detection strategies in the light of increasingly sophisticated evasion techniques.</li>
</ul>

<h3>Title: End-to-End Probabilistic Framework for Learning with Hard Constraints</h3>
<ul>
<li><strong>Authors: </strong>Utkarsh Utkarsh, Danielle C. Maddix, Ruijun Ma, Michael W. Mahoney, Yuyang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07003">https://arxiv.org/abs/2506.07003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07003">https://arxiv.org/pdf/2506.07003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07003]] End-to-End Probabilistic Framework for Learning with Hard Constraints(https://arxiv.org/abs/2506.07003)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a general purpose probabilistic forecasting framework, ProbHardE2E, to learn systems that can incorporate operational/physical constraints as hard requirements. ProbHardE2E enforces hard constraints by exploiting variance information in a novel way; and thus it is also capable of performing uncertainty quantification (UQ) on the model. Our methodology uses a novel differentiable probabilistic projection layer (DPPL) that can be combined with a wide range of neural network architectures. This DPPL allows the model to learn the system in an end-to-end manner, compared to other approaches where the constraints are satisfied either through a post-processing step or at inference. In addition, ProbHardE2E can optimize a strictly proper scoring rule, without making any distributional assumptions on the target, which enables it to obtain robust distributional estimates (in contrast to existing approaches that generally optimize likelihood-based objectives, which are heavily biased by their distributional assumptions and model choices); and it can incorporate a range of non-linear constraints (increasing the power of modeling and flexibility). We apply ProbHardE2E to problems in learning partial differential equations with uncertainty estimates and to probabilistic time-series forecasting, showcasing it as a broadly applicable general setup that connects these seemingly disparate domains.</li>
</ul>

<h3>Title: ModelForge: Using GenAI to Improve the Development of Security Protocols</h3>
<ul>
<li><strong>Authors: </strong>Martin Duclos, Ivan A. Fernandez, Kaneesha Moore, Sudip Mittal, Edward Zieglar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07010">https://arxiv.org/abs/2506.07010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07010">https://arxiv.org/pdf/2506.07010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07010]] ModelForge: Using GenAI to Improve the Development of Security Protocols(https://arxiv.org/abs/2506.07010)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative, large language model</a></li>
<li><strong>Abstract: </strong>Formal methods can be used for verifying security protocols, but their adoption can be hindered by the complexity of translating natural language protocol specifications into formal representations. In this paper, we introduce ModelForge, a novel tool that automates the translation of protocol specifications for the Cryptographic Protocol Shapes Analyzer (CPSA). By leveraging advances in Natural Language Processing (NLP) and Generative AI (GenAI), ModelForge processes protocol specifications and generates a CPSA protocol definition. This approach reduces the manual effort required, making formal analysis more accessible. We evaluate ModelForge by fine-tuning a large language model (LLM) to generate protocol definitions for CPSA, comparing its performance with other popular LLMs. The results from our evaluation show that ModelForge consistently produces quality outputs, excelling in syntactic accuracy, though some refinement is needed to handle certain protocol details. The contributions of this work include the architecture and proof of concept for a translating tool designed to simplify the adoption of formal methods in the development of security protocols.</li>
</ul>

<h3>Title: UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment</h3>
<ul>
<li><strong>Authors: </strong>Wentao Zhao, Yihe Niu, Yanbo Wang, Tianchen Deng, Shenghai Yuan, Zhenli Wang, Rui Guo, Jingchuan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07013">https://arxiv.org/abs/2506.07013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07013">https://arxiv.org/pdf/2506.07013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07013]] UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment(https://arxiv.org/abs/2506.07013)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work presents UNO, a unified monocular visual odometry framework that enables robust and adaptable pose estimation across diverse environments, platforms, and motion patterns. Unlike traditional methods that rely on deployment-specific tuning or predefined motion priors, our approach generalizes effectively across a wide range of real-world scenarios, including autonomous vehicles, aerial drones, mobile robots, and handheld devices. To this end, we introduce a Mixture-of-Experts strategy for local state estimation, with several specialized decoders that each handle a distinct class of ego-motion patterns. Moreover, we introduce a fully differentiable Gumbel-Softmax module that constructs a robust inter-frame correlation graph, selects the optimal expert decoder, and prunes erroneous estimates. These cues are then fed into a unified back-end that combines pre-trained, scale-independent depth priors with a lightweight bundling adjustment to enforce geometric consistency. We extensively evaluate our method on three major benchmark datasets: KITTI (outdoor/autonomous driving), EuRoC-MAV (indoor/aerial drones), and TUM-RGBD (indoor/handheld), demonstrating state-of-the-art performance.</li>
</ul>

<h3>Title: Comparison of Lightweight Methods for Vehicle Dynamics-Based Driver Drowsiness Detection</h3>
<ul>
<li><strong>Authors: </strong>Yutaro Nakagama, Daisuke Ishii, Kazuki Yoshizoe</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07014">https://arxiv.org/abs/2506.07014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07014">https://arxiv.org/pdf/2506.07014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07014]] Comparison of Lightweight Methods for Vehicle Dynamics-Based Driver Drowsiness Detection(https://arxiv.org/abs/2506.07014)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Driver drowsiness detection (DDD) prevents road accidents caused by driver fatigue. Vehicle dynamics-based DDD has been proposed as a method that is both economical and high performance. However, there are concerns about the reliability of performance metrics and the reproducibility of many of the existing methods. For instance, some previous studies seem to have a data leakage issue among training and test datasets, and many do not openly provide the datasets they used. To this end, this paper aims to compare the performance of representative vehicle dynamics-based DDD methods under a transparent and fair framework that uses a public dataset. We first develop a framework for extracting features from an open dataset by Aygun et al. and performing DDD with lightweight ML models; the framework is carefully designed to support a variety of onfigurations. Second, we implement three existing representative methods and a concise random forest (RF)-based method in the framework. Finally, we report the results of experiments to verify the reproducibility and clarify the performance of DDD based on common metrics. Among the evaluated methods, the RF-based method achieved the highest accuracy of 88 %. Our findings imply the issues inherent in DDD methods developed in a non-standard manner, and demonstrate a high performance method implemented appropriately.</li>
</ul>

<h3>Title: TABLET: Table Structure Recognition using Encoder-only Transformers</h3>
<ul>
<li><strong>Authors: </strong>Qiyu Hou, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07015">https://arxiv.org/abs/2506.07015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07015">https://arxiv.org/pdf/2506.07015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07015]] TABLET: Table Structure Recognition using Encoder-only Transformers(https://arxiv.org/abs/2506.07015)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>To address the challenges of table structure recognition, we propose a novel Split-Merge-based top-down model optimized for large, densely populated tables. Our approach formulates row and column splitting as sequence labeling tasks, utilizing dual Transformer encoders to capture feature interactions. The merging process is framed as a grid cell classification task, leveraging an additional Transformer encoder to ensure accurate and coherent merging. By eliminating unstable bounding box predictions, our method reduces resolution loss and computational complexity, achieving high accuracy while maintaining fast processing speed. Extensive experiments on FinTabNet and PubTabNet demonstrate the superiority of our model over existing approaches, particularly in real-world applications. Our method offers a robust, scalable, and efficient solution for large-scale table recognition, making it well-suited for industrial deployment.</li>
</ul>

<h3>Title: MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks</h3>
<ul>
<li><strong>Authors: </strong>Sanjoy Chowdhury, Mohamed Elmoghany, Yohan Abeysinghe, Junjie Fei, Sayan Nag, Salman Khan, Mohamed Elhoseiny, Dinesh Manocha</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07016">https://arxiv.org/abs/2506.07016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07016">https://arxiv.org/pdf/2506.07016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07016]] MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks(https://arxiv.org/abs/2506.07016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large multimodal models (LMMs) have shown remarkable progress in audio-visual understanding, yet they struggle with real-world scenarios that require complex reasoning across extensive video collections. Existing benchmarks for video question answering remain limited in scope, typically involving one clip per query, which falls short of representing the challenges of large-scale, audio-visual retrieval and reasoning encountered in practical applications. To bridge this gap, we introduce a novel task named AV-HaystacksQA, where the goal is to identify salient segments across different videos in response to a query and link them together to generate the most informative answer. To this end, we present AVHaystacks, an audio-visual benchmark comprising 3100 annotated QA pairs designed to assess the capabilities of LMMs in multi-video retrieval and temporal grounding task. Additionally, we propose a model-agnostic, multi-agent framework MAGNET to address this challenge, achieving up to 89% and 65% relative improvements over baseline methods on BLEU@4 and GPT evaluation scores in QA task on our proposed AVHaystacks. To enable robust evaluation of multi-video retrieval and temporal grounding for optimal response generation, we introduce two new metrics, STEM, which captures alignment errors between a ground truth and a predicted step sequence and MTGS, to facilitate balanced and interpretable evaluation of segment-level grounding performance. Project: this https URL</li>
</ul>

<h3>Title: AlphaSteer: Learning Refusal Steering with Principled Null-Space Constraint</h3>
<ul>
<li><strong>Authors: </strong>Leheng Sheng, Changshuo Shen, Weixiang Zhao, Junfeng Fang, Xiaohao Liu, Zhenkai Liang, Xiang Wang, An Zhang, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07022">https://arxiv.org/abs/2506.07022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07022">https://arxiv.org/pdf/2506.07022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07022]] AlphaSteer: Learning Refusal Steering with Principled Null-Space Constraint(https://arxiv.org/abs/2506.07022)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>As LLMs are increasingly deployed in real-world applications, ensuring their ability to refuse malicious prompts, especially jailbreak attacks, is essential for safe and reliable use. Recently, activation steering has emerged as an effective approach for enhancing LLM safety by adding a refusal direction vector to internal activations of LLMs during inference, which will further induce the refusal behaviors of LLMs. However, indiscriminately applying activation steering fundamentally suffers from the trade-off between safety and utility, since the same steering vector can also lead to over-refusal and degraded performance on benign prompts. Although prior efforts, such as vector calibration and conditional steering, have attempted to mitigate this trade-off, their lack of theoretical grounding limits their robustness and effectiveness. To better address the trade-off between safety and utility, we present a theoretically grounded and empirically effective activation steering method called AlphaSteer. Specifically, it considers activation steering as a learnable process with two principled learning objectives: utility preservation and safety enhancement. For utility preservation, it learns to construct a nearly zero vector for steering benign data, with the null-space constraints. For safety enhancement, it learns to construct a refusal direction vector for steering malicious data, with the help of linear regression. Experiments across multiple jailbreak attacks and utility benchmarks demonstrate the effectiveness of AlphaSteer, which significantly improves the safety of LLMs without compromising general capabilities. Our codes are available at this https URL.</li>
</ul>

<h3>Title: HauntAttack: When Attack Follows Reasoning as a Shadow</h3>
<ul>
<li><strong>Authors: </strong>Jingyuan Ma, Rui Li, Zheng Li, Junfeng Liu, Lei Sha, Zhifang Sui</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07031">https://arxiv.org/abs/2506.07031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07031">https://arxiv.org/pdf/2506.07031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07031]] HauntAttack: When Attack Follows Reasoning as a Shadow(https://arxiv.org/abs/2506.07031)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Emerging Large Reasoning Models (LRMs) consistently excel in mathematical and reasoning tasks, showcasing exceptional capabilities. However, the enhancement of reasoning abilities and the exposure of their internal reasoning processes introduce new safety vulnerabilities. One intriguing concern is: when reasoning is strongly entangled with harmfulness, what safety-reasoning trade-off do LRMs exhibit? To address this issue, we introduce HauntAttack, a novel and general-purpose black-box attack framework that systematically embeds harmful instructions into reasoning questions. Specifically, we treat reasoning questions as carriers and substitute one of their original conditions with a harmful instruction. This process creates a reasoning pathway in which the model is guided step by step toward generating unsafe outputs. Based on HauntAttack, we conduct comprehensive experiments on multiple LRMs. Our results reveal that even the most advanced LRMs exhibit significant safety vulnerabilities. Additionally, we perform a detailed analysis of different models, various types of harmful instructions, and model output patterns, providing valuable insights into the security of LRMs.</li>
</ul>

<h3>Title: NanoZone: Scalable, Efficient, and Secure Memory Protection for Arm CCA</h3>
<ul>
<li><strong>Authors: </strong>Shiqi Liu, Yongpeng Gao, Mingyang Zhang, Jie Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07034">https://arxiv.org/abs/2506.07034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07034">https://arxiv.org/pdf/2506.07034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07034]] NanoZone: Scalable, Efficient, and Secure Memory Protection for Arm CCA(https://arxiv.org/abs/2506.07034)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack</a></li>
<li><strong>Abstract: </strong>Arm Confidential Computing Architecture (CCA) currently isolates at the granularity of an entire Confidential Virtual Machine (CVM), leaving intra-VM bugs such as Heartbleed unmitigated. The state-of-the-art narrows this to the process level, yet still cannot stop attacks that pivot within the same process, and prior intra-enclave schemes are either too slow or incompatible with CVM-style isolation. We extend CCA with a three-tier zone model that spawns an unlimited number of lightweight isolation domains inside a single process, while shielding them from kernel-space adversaries. To block domain-switch abuse, we also add a fast user-level Code-Pointer Integrity (CPI) mechanism. We developed two prototypes: a functional version on Arm's official simulator to validate resistance against intra-process and kernel-space adversaries, and a performance variant on Arm development boards evaluated for session-key isolation within server applications, in-memory key-value protection, and non-volatile-memory data isolation. NanoZone incurs roughly a 20% performance overhead while retaining 95% throughput compared to the system without fine-grained isolation.</li>
</ul>

<h3>Title: KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Zhongze Luo, Weixuan Wan, Qizhi Zheng, Yanhong Bai, Jingyun Sun, Jian Wang, Dan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07037">https://arxiv.org/abs/2506.07037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07037">https://arxiv.org/pdf/2506.07037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07037]] KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering(https://arxiv.org/abs/2506.07037)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>There are many types of standards in the field of communication. The traditional consulting model has a long cycle and relies on the knowledge and experience of experts, making it difficult to meet the rapidly developing technological demands. This paper combines the fine-tuning of large language models with the construction of knowledge graphs to implement an intelligent consultation and question-answering system for communication standards. The experimental results show that after LoRA tuning on the constructed dataset of 6,587 questions and answers in the field of communication standards, Qwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the field of communication standards on the test set. BLEU-4 rose from 18.8564 to 66.8993, and evaluation indicators such as ROUGE also increased significantly, outperforming the fine-tuning effect of the comparison model Llama-3-8B-Instruct. Based on the ontology framework containing 6 entity attributes and 10 relation attributes, a knowledge graph of the communication standard domain containing 13,906 entities and 13,524 relations was constructed, showing a relatively good query accuracy rate. The intelligent consultation and question-answering system enables the fine-tuned model on the server side to access the locally constructed knowledge graph and conduct graphical retrieval of key information first, which is conducive to improving the question-answering effect. The evaluation using DeepSeek as the Judge on the test set shows that our RAG framework enables the fine-tuned model to improve the scores at all five angles, with an average score increase of 2.26%. And combined with web services and API interfaces, it has achieved very good results in terms of interaction experience and back-end access, and has very good practical application value.</li>
</ul>

<h3>Title: Efficient $Q$-Learning and Actor-Critic Methods for Robust Average Reward Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yang Xu, Swetha Ganesh, Vaneet Aggarwal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07040">https://arxiv.org/abs/2506.07040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07040">https://arxiv.org/pdf/2506.07040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07040]] Efficient $Q$-Learning and Actor-Critic Methods for Robust Average Reward Reinforcement Learning(https://arxiv.org/abs/2506.07040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present the first $Q$-learning and actor-critic algorithms for robust average reward Markov Decision Processes (MDPs) with non-asymptotic convergence under contamination, TV distance and Wasserstein distance uncertainty sets. We show that the robust $Q$ Bellman operator is a strict contractive mapping with respect to a carefully constructed semi-norm with constant functions being quotiented out. This property supports a stochastic approximation update, that learns the optimal robust $Q$ function in $\tilde{\cO}(\epsilon^{-2})$ samples. We also show that the same idea can be used for robust $Q$ function estimation, which can be further used for critic estimation. Coupling it with theories in robust policy mirror descent update, we present a natural actor-critic algorithm that attains an $\epsilon$-optimal robust policy in $\tilde{\cO}(\epsilon^{-3})$ samples. These results advance the theory of distributionally robust reinforcement learning in the average reward setting.</li>
</ul>

<h3>Title: Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants</h3>
<ul>
<li><strong>Authors: </strong>Stergios Chatzikyriakidis</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07042">https://arxiv.org/abs/2506.07042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07042">https://arxiv.org/pdf/2506.07042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07042]] Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants(https://arxiv.org/abs/2506.07042)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Extracting structured computational representations of historical events from narrative text remains computationally expensive when constructed manually. While RDF/OWL reasoners enable graph-based reasoning, they are limited to fragments of first-order logic, preventing deeper temporal and semantic analysis. This paper addresses both challenges by developing automatic historical event extraction models using multiple LLMs (GPT-4, Claude, Llama 3.2) with three enhancement strategies: pure base generation, knowledge graph enhancement, and Retrieval-Augmented Generation (RAG). We conducted comprehensive evaluations using historical texts from Thucydides. Our findings reveal that enhancement strategies optimize different performance dimensions rather than providing universal improvements. For coverage and historical breadth, base generation achieves optimal performance with Claude and GPT-4 extracting comprehensive events. However, for precision, RAG enhancement improves coordinate accuracy and metadata completeness. Model architecture fundamentally determines enhancement sensitivity: larger models demonstrate robust baseline performance with incremental RAG improvements, while Llama 3.2 shows extreme variance from competitive performance to complete failure. We then developed an automated translation pipeline converting extracted RDF representations into Coq proof assistant specifications, enabling higher-order reasoning beyond RDF capabilities including multi-step causal verification, temporal arithmetic with BC dates, and formal proofs about historical causation. The Coq formalization validates that RAG-discovered event types represent legitimate domain-specific semantic structures rather than ontological violations.</li>
</ul>

<h3>Title: Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07044">https://arxiv.org/abs/2506.07044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07044">https://arxiv.org/pdf/2506.07044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07044]] Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning(https://arxiv.org/abs/2506.07044)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in understanding common visual elements, largely due to their large-scale datasets and advanced training strategies. However, their effectiveness in medical applications remains limited due to the inherent discrepancies between data and tasks in medical scenarios and those in the general domain. Concretely, existing medical MLLMs face the following critical limitations: (1) limited coverage of medical knowledge beyond imaging, (2) heightened susceptibility to hallucinations due to suboptimal data curation processes, (3) lack of reasoning capabilities tailored for complex medical scenarios. To address these challenges, we first propose a comprehensive data curation procedure that (1) efficiently acquires rich medical knowledge data not only from medical imaging but also from extensive medical texts and general-domain data; and (2) synthesizes accurate medical captions, visual question answering (VQA), and reasoning samples. As a result, we build a multimodal dataset enriched with extensive medical knowledge. Building on the curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu undergoes multi-stage training to embed medical expertise and enhance its task-solving capabilities progressively. Besides, we preliminarily explore the potential of applying reinforcement learning with verifiable rewards paradigm to enhance Lingshu's medical reasoning ability. Additionally, we develop MedEvalKit, a unified evaluation framework that consolidates leading multimodal and textual medical benchmarks for standardized, fair, and efficient model assessment. We evaluate the performance of Lingshu on three fundamental medical tasks, multimodal QA, text-based QA, and medical report generation. The results show that Lingshu consistently outperforms the existing open-source multimodal models on most tasks ...</li>
</ul>

<h3>Title: Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs</h3>
<ul>
<li><strong>Authors: </strong>Yikun Ji, Hong Yan, Jun Lan, Huijia Zhu, Weiqiang Wang, Qi Fan, Liqing Zhang, Jianfu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07045">https://arxiv.org/abs/2506.07045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07045">https://arxiv.org/pdf/2506.07045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07045]] Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs(https://arxiv.org/abs/2506.07045)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of image generation technologies intensifies the demand for interpretable and robust detection methods. Although existing approaches often attain high accuracy, they typically operate as black boxes without providing human-understandable justifications. Multi-modal Large Language Models (MLLMs), while not originally intended for forgery detection, exhibit strong analytical and reasoning capabilities. When properly fine-tuned, they can effectively identify AI-generated images and offer meaningful explanations. However, existing MLLMs still struggle with hallucination and often fail to align their visual interpretations with actual image content and human reasoning. To bridge this gap, we construct a dataset of AI-generated images annotated with bounding boxes and descriptive captions that highlight synthesis artifacts, establishing a foundation for human-aligned visual-textual grounded reasoning. We then finetune MLLMs through a multi-stage optimization strategy that progressively balances the objectives of accurate detection, visual localization, and coherent textual explanation. The resulting model achieves superior performance in both detecting AI-generated images and localizing visual flaws, significantly outperforming baseline methods.</li>
</ul>

<h3>Title: FairPFN: A Tabular Foundation Model for Causal Fairness</h3>
<ul>
<li><strong>Authors: </strong>Jake Robertson, Noah Hollmann, Samuel Müller, Noor Awad, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07049">https://arxiv.org/abs/2506.07049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07049">https://arxiv.org/pdf/2506.07049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07049]] FairPFN: A Tabular Foundation Model for Causal Fairness(https://arxiv.org/abs/2506.07049)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, fair</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) systems are utilized in critical sectors, such as healthcare, law enforcement, and finance. However, these systems are often trained on historical data that contains demographic biases, leading to ML decisions that perpetuate or exacerbate existing social inequalities. Causal fairness provides a transparent, human-in-the-loop framework to mitigate algorithmic discrimination, aligning closely with legal doctrines of direct and indirect discrimination. However, current causal fairness frameworks hold a key limitation in that they assume prior knowledge of the correct causal model, restricting their applicability in complex fairness scenarios where causal models are unknown or difficult to identify. To bridge this gap, we propose FairPFN, a tabular foundation model pre-trained on synthetic causal fairness data to identify and mitigate the causal effects of protected attributes in its predictions. FairPFN's key contribution is that it requires no knowledge of the causal model and still demonstrates strong performance in identifying and removing protected causal effects across a diverse set of hand-crafted and real-world scenarios relative to robust baseline methods. FairPFN paves the way for promising future research, making causal fairness more accessible to a wider variety of complex fairness problems.</li>
</ul>

<h3>Title: D2R: dual regularization loss with collaborative adversarial generation for model robustness</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Liu, Huizhi Liang, Rajiv Ranjan, Zhanxing Zhu, Vaclav Snasel, Varun Ojha</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07056">https://arxiv.org/abs/2506.07056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07056">https://arxiv.org/pdf/2506.07056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07056]] D2R: dual regularization loss with collaborative adversarial generation for model robustness(https://arxiv.org/abs/2506.07056)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The robustness of Deep Neural Network models is crucial for defending models against adversarial attacks. Recent defense methods have employed collaborative learning frameworks to enhance model robustness. Two key limitations of existing methods are (i) insufficient guidance of the target model via loss functions and (ii) non-collaborative adversarial generation. We, therefore, propose a dual regularization loss (D2R Loss) method and a collaborative adversarial generation (CAG) strategy for adversarial training. D2R loss includes two optimization steps. The adversarial distribution and clean distribution optimizations enhance the target model's robustness by leveraging the strengths of different loss functions obtained via a suitable function space exploration to focus more precisely on the target model's distribution. CAG generates adversarial samples using a gradient-based collaboration between guidance and target models. We conducted extensive experiments on three benchmark databases, including CIFAR-10, CIFAR-100, Tiny ImageNet, and two popular target models, WideResNet34-10 and PreActResNet18. Our results show that D2R loss with CAG produces highly robust models.</li>
</ul>

<h3>Title: Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kai Xiong, Xiao Ding, Yixin Cao, Yuxiong Yan, Li Du, Yufei Zhang, Jinglong Gao, Jiaqian Liu, Bing Qin, Ting Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07064">https://arxiv.org/abs/2506.07064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07064">https://arxiv.org/pdf/2506.07064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07064]] Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models(https://arxiv.org/abs/2506.07064)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have mastered abundant simple and explicit commonsense knowledge through pre-training, enabling them to achieve human-like performance in simple commonsense reasoning. Nevertheless, LLMs struggle to reason with complex and implicit commonsense knowledge that is derived from simple ones (such as understanding the long-term effects of certain events), an aspect humans tend to focus on more. Existing works focus on complex tasks like math and code, while complex commonsense reasoning remains underexplored due to its uncertainty and lack of structure. To fill this gap and align with real-world concerns, we propose a benchmark Com$^2$ focusing on complex commonsense reasoning. We first incorporate causal event graphs to serve as structured complex commonsense. Then we adopt causal theory~(e.g., intervention) to modify the causal event graphs and obtain different scenarios that meet human concerns. Finally, an LLM is employed to synthesize examples with slow thinking, which is guided by the logical relationships in the modified causal graphs. Furthermore, we use detective stories to construct a more challenging subset. Experiments show that LLMs struggle in reasoning depth and breadth, while post-training and slow thinking can alleviate this. The code and data are available at this https URL.</li>
</ul>

<h3>Title: Dual-Priv Pruning : Efficient Differential Private Fine-Tuning in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qianshan Wei, Jiaqi Li, Zihan You, Yi Zhan, Kecen Li, Jialin Wu, Xinfeng Li Hengjun Liu, Yi Yu, Bin Cao, Yiwen Xu, Yang Liu, Guilin Qi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07077">https://arxiv.org/abs/2506.07077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07077">https://arxiv.org/pdf/2506.07077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07077]] Dual-Priv Pruning : Efficient Differential Private Fine-Tuning in Multimodal Large Language Models(https://arxiv.org/abs/2506.07077)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Differential Privacy (DP) is a widely adopted technique, valued for its effectiveness in protecting the privacy of task-specific datasets, making it a critical tool for large language models. However, its effectiveness in Multimodal Large Language Models (MLLMs) remains uncertain. Applying Differential Privacy (DP) inherently introduces substantial computation overhead, a concern particularly relevant for MLLMs which process extensive textual and visual data. Furthermore, a critical challenge of DP is that the injected noise, necessary for privacy, scales with parameter dimensionality, leading to pronounced model degradation; This trade-off between privacy and utility complicates the application of Differential Privacy (DP) to complex architectures like MLLMs. To address these, we propose Dual-Priv Pruning, a framework that employs two complementary pruning mechanisms for DP fine-tuning in MLLMs: (i) visual token pruning to reduce input dimensionality by removing redundant visual information, and (ii) gradient-update pruning during the DP optimization process. This second mechanism selectively prunes parameter updates based on the magnitude of noisy gradients, aiming to mitigate noise impact and improve utility. Experiments demonstrate that our approach achieves competitive results with minimal performance degradation. In terms of computational efficiency, our approach consistently utilizes less memory than standard DP-SGD. While requiring only 1.74% more memory than zeroth-order methods which suffer from severe performance issues on A100 GPUs, our method demonstrates leading memory efficiency on H20 GPUs. To the best of our knowledge, we are the first to explore DP fine-tuning in MLLMs. Our code is coming soon.</li>
</ul>

<h3>Title: E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaheng Dong, Hong Jia, Soumyajit Chatterjee, Abhirup Ghosh, James Bailey, Ting Dang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07078">https://arxiv.org/abs/2506.07078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07078">https://arxiv.org/pdf/2506.07078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07078]] E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models(https://arxiv.org/abs/2506.07078)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Speech Foundation Models encounter significant performance degradation when deployed in real-world scenarios involving acoustic domain shifts, such as background noise and speaker accents. Test-time adaptation (TTA) has recently emerged as a viable strategy to address such domain shifts at inference time without requiring access to source data or labels. However, existing TTA approaches, particularly those relying on backpropagation, are memory-intensive, limiting their applicability in speech tasks and resource-constrained settings. Although backpropagation-free methods offer improved efficiency, existing ones exhibit poor accuracy. This is because they are predominantly developed for vision tasks, which fundamentally differ from speech task formulations, noise characteristics, and model architecture, posing unique transferability challenges. In this paper, we introduce E-BATS, the first Efficient BAckpropagation-free TTA framework designed explicitly for speech foundation models. E-BATS achieves a balance between adaptation effectiveness and memory efficiency through three key components: (i) lightweight prompt adaptation for a forward-pass-based feature alignment, (ii) a multi-scale loss to capture both global (utterance-level) and local distribution shifts (token-level) and (iii) a test-time exponential moving average mechanism for stable adaptation across utterances. Experiments conducted on four noisy speech datasets spanning sixteen acoustic conditions demonstrate consistent improvements, with 4.1%-13.5% accuracy gains over backpropagation-free baselines and 2.0-6.4 times GPU memory savings compared to backpropagation-based methods. By enabling scalable and robust adaptation under acoustic variability, this work paves the way for developing more efficient adaptation approaches for practical speech processing systems in real-world environments.</li>
</ul>

<h3>Title: FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping</h3>
<ul>
<li><strong>Authors: </strong>Anatol Garioud, Sébastien Giordano, Nicolas David, Nicolas Gonthier</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07080">https://arxiv.org/abs/2506.07080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07080">https://arxiv.org/pdf/2506.07080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07080]] FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping(https://arxiv.org/abs/2506.07080)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The growing availability of high-quality Earth Observation (EO) data enables accurate global land cover and crop type monitoring. However, the volume and heterogeneity of these datasets pose major processing and annotation challenges. To address this, the French National Institute of Geographical and Forest Information (IGN) is actively exploring innovative strategies to exploit diverse EO data, which require large annotated datasets. IGN introduces FLAIR-HUB, the largest multi-sensor land cover dataset with very-high-resolution (20 cm) annotations, covering 2528 km2 of France. It combines six aligned modalities: aerial imagery, Sentinel-1/2 time series, SPOT imagery, topographic data, and historical aerial images. Extensive benchmarks evaluate multimodal fusion and deep learning models (CNNs, transformers) for land cover or crop mapping and also explore multi-task learning. Results underscore the complexity of multimodal fusion and fine-grained classification, with best land cover performance (78.2% accuracy, 65.8% mIoU) achieved using nearly all modalities. FLAIR-HUB supports supervised and multimodal pretraining, with data and code available at this https URL.</li>
</ul>

<h3>Title: State Entropy Regularization for Robust Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Uri Koren, Yonatan Ashlag, Mirco Mutti, Esther Derman, Pierre-Luc Bacon, Shie Mannor</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07085">https://arxiv.org/abs/2506.07085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07085">https://arxiv.org/pdf/2506.07085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07085]] State Entropy Regularization for Robust Reinforcement Learning(https://arxiv.org/abs/2506.07085)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.</li>
</ul>

<h3>Title: UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning</h3>
<ul>
<li><strong>Authors: </strong>Weiqi Yan, Lvhai Chen, Huaijia Kou, Shengchuan Zhang, Yan Zhang, Liujuan Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07087">https://arxiv.org/abs/2506.07087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07087">https://arxiv.org/pdf/2506.07087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07087]] UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning(https://arxiv.org/abs/2506.07087)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised Camoflaged Object Detection (UCOD) has gained attention since it doesn't need to rely on extensive pixel-level labels. Existing UCOD methods typically generate pseudo-labels using fixed strategies and train 1 x1 convolutional layers as a simple decoder, leading to low performance compared to fully-supervised methods. We emphasize two drawbacks in these approaches: 1). The model is prone to fitting incorrect knowledge due to the pseudo-label containing substantial noise. 2). The simple decoder fails to capture and learn the semantic features of camouflaged objects, especially for small-sized objects, due to the low-resolution pseudo-labels and severe confusion between foreground and background pixels. To this end, we propose a UCOD method with a teacher-student framework via Dynamic Pseudo-label Learning called UCOD-DPL, which contains an Adaptive Pseudo-label Module (APM), a Dual-Branch Adversarial (DBA) decoder, and a Look-Twice mechanism. The APM module adaptively combines pseudo-labels generated by fixed strategies and the teacher model to prevent the model from overfitting incorrect knowledge while preserving the ability for self-correction; the DBA decoder takes adversarial learning of different segmentation objectives, guides the model to overcome the foreground-background confusion of camouflaged objects, and the Look-Twice mechanism mimics the human tendency to zoom in on camouflaged objects and performs secondary refinement on small-sized objects. Extensive experiments show that our method demonstrates outstanding performance, even surpassing some existing fully supervised methods. The code is available now.</li>
</ul>

<h3>Title: SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model</h3>
<ul>
<li><strong>Authors: </strong>Yangkai Lin, Jiabao Lei, Kui Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07091">https://arxiv.org/abs/2506.07091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07091">https://arxiv.org/pdf/2506.07091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07091]] SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model(https://arxiv.org/abs/2506.07091)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Our project page: this https URL. Automated generation of complex, interactive indoor scenes tailored to user prompt remains a formidable challenge. While existing methods achieve indoor scene synthesis, they struggle with rigid editing constraints, physical incoherence, excessive human effort, single-room limitations, and suboptimal material quality. To address these limitations, we propose SceneLCM, an end-to-end framework that synergizes Large Language Model (LLM) for layout design with Latent Consistency Model(LCM) for scene optimization. Our approach decomposes scene generation into four modular pipelines: (1) Layout Generation. We employ LLM-guided 3D spatial reasoning to convert textual descriptions into parametric blueprints(3D layout). And an iterative programmatic validation mechanism iteratively refines layout parameters through LLM-mediated dialogue loops; (2) Furniture Generation. SceneLCM employs Consistency Trajectory Sampling(CTS), a consistency distillation sampling loss guided by LCM, to form fast, semantically rich, and high-quality representations. We also offer two theoretical justification to demonstrate that our CTS loss is equivalent to consistency loss and its distillation error is bounded by the truncation error of the Euler solver; (3) Environment Optimization. We use a multiresolution texture field to encode the appearance of the scene, and optimize via CTS loss. To maintain cross-geometric texture coherence, we introduce a normal-aware cross-attention decoder to predict RGB by cross-attending to the anchors locations in geometrically heterogeneous instance. (4)Physically Editing. SceneLCM supports physically editing by integrating physical simulation, achieved persistent physical realism. Extensive experiments validate SceneLCM's superiority over state-of-the-art techniques, showing its wide-ranging potential for diverse applications.</li>
</ul>

<h3>Title: Patient Similarity Computation for Clinical Decision Support: An Efficient Use of Data Transformation, Combining Static and Time Series Data</h3>
<ul>
<li><strong>Authors: </strong>Joydeb Kumar Sana, Mohammad M. Masud, M Sohel Rahman, M Saifur Rahman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07092">https://arxiv.org/abs/2506.07092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07092">https://arxiv.org/pdf/2506.07092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07092]] Patient Similarity Computation for Clinical Decision Support: An Efficient Use of Data Transformation, Combining Static and Time Series Data(https://arxiv.org/abs/2506.07092)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Patient similarity computation (PSC) is a fundamental problem in healthcare informatics. The aim of the patient similarity computation is to measure the similarity among patients according to their historical clinical records, which helps to improve clinical decision support. This paper presents a novel distributed patient similarity computation (DPSC) technique based on data transformation (DT) methods, utilizing an effective combination of time series and static data. Time series data are sensor-collected patients' information, including metrics like heart rate, blood pressure, Oxygen saturation, respiration, etc. The static data are mainly patient background and demographic data, including age, weight, height, gender, etc. Static data has been used for clustering the patients. Before feeding the static data to the machine learning model adaptive Weight-of-Evidence (aWOE) and Z-score data transformation (DT) methods have been performed, which improve the prediction performances. In aWOE-based patient similarity models, sensitive patient information has been processed using aWOE which preserves the data privacy of the trained models. We used the Dynamic Time Warping (DTW) approach, which is robust and very popular, for time series similarity. However, DTW is not suitable for big data due to the significant computational run-time. To overcome this problem, distributed DTW computation is used in this study. For Coronary Artery Disease, our DT based approach boosts prediction performance by as much as 11.4%, 10.20%, and 12.6% in terms of AUC, accuracy, and F-measure, respectively. In the case of Congestive Heart Failure (CHF), our proposed method achieves performance enhancement up to 15.9%, 10.5%, and 21.9% for the same measures, respectively. The proposed method reduces the computation time by as high as 40%.</li>
</ul>

<h3>Title: Filling the Missings: Spatiotemporal Data Imputation by Conditional Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Wenying He, Jieling Huang, Junhua Gu, Ji Zhang, Yude Bai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07099">https://arxiv.org/abs/2506.07099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07099">https://arxiv.org/pdf/2506.07099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07099]] Filling the Missings: Spatiotemporal Data Imputation by Conditional Diffusion(https://arxiv.org/abs/2506.07099)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Missing data in spatiotemporal systems presents a significant challenge for modern applications, ranging from environmental monitoring to urban traffic management. The integrity of spatiotemporal data often deteriorates due to hardware malfunctions and software failures in real-world deployments. Current approaches based on machine learning and deep learning struggle to model the intricate interdependencies between spatial and temporal dimensions effectively and, more importantly, suffer from cumulative errors during the data imputation process, which propagate and amplify through iterations. To address these limitations, we propose CoFILL, a novel Conditional Diffusion Model for spatiotemporal data imputation. CoFILL builds on the inherent advantages of diffusion models to generate high-quality imputations without relying on potentially error-prone prior estimates. It incorporates an innovative dual-stream architecture that processes temporal and frequency domain features in parallel. By fusing these complementary features, CoFILL captures both rapid fluctuations and underlying patterns in the data, which enables more robust imputation. The extensive experiments reveal that CoFILL's noise prediction network successfully transforms random noise into meaningful values that align with the true data distribution. The results also show that CoFILL outperforms state-of-the-art methods in imputation accuracy. The source code is publicly available at this https URL.</li>
</ul>

<h3>Title: Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Samir Abdaljalil, Hasan Kurban, Khalid Qaraqe, Erchin Serpedin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07106">https://arxiv.org/abs/2506.07106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07106">https://arxiv.org/pdf/2506.07106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07106]] Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models(https://arxiv.org/abs/2506.07106)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown strong performance across natural language reasoning tasks, yet their reasoning processes remain brittle and difficult to interpret. Prompting techniques like Chain-of-Thought (CoT) enhance reliability by eliciting intermediate reasoning steps or aggregating multiple outputs. However, they lack mechanisms for enforcing logical structure and assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a novel framework that models reasoning as collaboration among three parallel agents, each simulating a distinct mode of inference: abductive, deductive, and inductive. Each agent produces a reasoning trace, which is structured into a formal reasoning graph. To evaluate consistency, we apply Bayesian belief propagation guided by natural language inference (NLI), assigning confidence scores to each step. The most coherent graph is selected to derive the final answer. Experiments on symbolic (WebOfLies) and numerical (MultiArith) reasoning benchmarks show that ToTh consistently outperforms CoT, Self-Consistency, and CoT-Decoding across multiple LLMs, while producing interpretable and logically grounded reasoning chains. Our findings suggest a promising direction for building more robust and cognitively inspired LLM reasoning. The implementation is available at this https URL.</li>
</ul>

<h3>Title: EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Changhong Fu, Hua Lin, Haobo Zuo, Liangliang Yao, Liguo Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07112">https://arxiv.org/abs/2506.07112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07112">https://arxiv.org/pdf/2506.07112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07112]] EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring(https://arxiv.org/abs/2506.07112)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Text spotting for industrial panels is a key task for intelligent monitoring. However, achieving efficient and accurate text spotting for complex industrial panels remains challenging due to issues such as cross-scale localization and ambiguous boundaries in dense text regions. Moreover, most existing methods primarily focus on representing a single text shape, neglecting a comprehensive exploration of multi-scale feature information across different texts. To address these issues, this work proposes a novel multi-scale dense text spotter for edge AI-based vision system (EdgeSpotter) to achieve accurate and robust industrial panel monitoring. Specifically, a novel Transformer with efficient mixer is developed to learn the interdependencies among multi-level features, integrating multi-layer spatial and semantic cues. In addition, a new feature sampling with catmull-rom splines is designed, which explicitly encodes the shape, position, and semantic information of text, thereby alleviating missed detections and reducing recognition errors caused by multi-scale or dense text regions. Furthermore, a new benchmark dataset for industrial panel monitoring (IPM) is constructed. Extensive qualitative and quantitative evaluations on this challenging benchmark dataset validate the superior performance of the proposed method in different challenging panel monitoring tasks. Finally, practical tests based on the self-designed edge AI-based vision system demonstrate the practicality of the method. The code and demo will be available at this https URL.</li>
</ul>

<h3>Title: Quality-Diversity Red-Teaming: Automated Generation of High-Quality and Diverse Attackers for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ren-Jian Wang, Ke Xue, Zeyu Qin, Ziniu Li, Sheng Tang, Hao-Tian Li, Shengcai Liu, Chao Qian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07121">https://arxiv.org/abs/2506.07121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07121">https://arxiv.org/pdf/2506.07121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07121]] Quality-Diversity Red-Teaming: Automated Generation of High-Quality and Diverse Attackers for Large Language Models(https://arxiv.org/abs/2506.07121)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Ensuring safety of large language models (LLMs) is important. Red teaming--a systematic approach to identifying adversarial prompts that elicit harmful responses from target LLMs--has emerged as a crucial safety evaluation method. Within this framework, the diversity of adversarial prompts is essential for comprehensive safety assessments. We find that previous approaches to red-teaming may suffer from two key limitations. First, they often pursue diversity through simplistic metrics like word frequency or sentence embedding similarity, which may not capture meaningful variation in attack strategies. Second, the common practice of training a single attacker model restricts coverage across potential attack styles and risk categories. This paper introduces Quality-Diversity Red-Teaming (QDRT), a new framework designed to address these limitations. QDRT achieves goal-driven diversity through behavior-conditioned training and implements a behavioral replay buffer in an open-ended manner. Additionally, it trains multiple specialized attackers capable of generating high-quality attacks across diverse styles and risk categories. Our empirical evaluation demonstrates that QDRT generates attacks that are both more diverse and more effective against a wide range of target LLMs, including GPT-2, Llama-3, Gemma-2, and Qwen2.5. This work advances the field of LLM safety by providing a systematic and effective approach to automated red-teaming, ultimately supporting the responsible deployment of LLMs.</li>
</ul>

<h3>Title: Image segmentation and classification of E-waste for waste segregation</h3>
<ul>
<li><strong>Authors: </strong>Prakriti Tripathi, Theertha Biju, Maniram Thota, Rakesh Lingam</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07122">https://arxiv.org/abs/2506.07122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07122">https://arxiv.org/pdf/2506.07122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07122]] Image segmentation and classification of E-waste for waste segregation(https://arxiv.org/abs/2506.07122)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Industry partners provided a problem statement that involves classifying electronic waste using machine learning models that will be used by pick-and-place robots for waste segregation. We started by taking common electronic waste items, such as a mouse and charger, unsoldering them, and taking pictures to create a custom dataset. Then state-of-the art YOLOv11 model was trained and run to achieve 70 mAP in real-time. Mask-RCNN model was also trained and achieved 41 mAP. The model will be further integrated with pick-and-place robots to perform segregation of e-waste.</li>
</ul>

<h3>Title: Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion</h3>
<ul>
<li><strong>Authors: </strong>Huaize Liu, Wenzhang Sun, Qiyuan Zhang, Donglin Di, Biao Gong, Hao Li, Chen Wei, Changqing Zou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07136">https://arxiv.org/abs/2506.07136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07136">https://arxiv.org/pdf/2506.07136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07136]] Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion(https://arxiv.org/abs/2506.07136)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent breakthroughs in video autoencoders (Video AEs) have advanced video generation, but existing methods fail to efficiently model spatio-temporal redundancies in dynamics, resulting in suboptimal compression factors. This shortfall leads to excessive training costs for downstream tasks. To address this, we introduce Hi-VAE, an efficient video autoencoding framework that hierarchically encode coarse-to-fine motion representations of video dynamics and formulate the decoding process as a conditional generation task. Specifically, Hi-VAE decomposes video dynamics into two latent spaces: Global Motion, capturing overarching motion patterns, and Detailed Motion, encoding high-frequency spatial details. Using separate self-supervised motion encoders, we compress video latents into compact motion representations to reduce redundancy significantly. A conditional diffusion decoder then reconstructs videos by combining hierarchical global and detailed motions, enabling high-fidelity video reconstructions. Extensive experiments demonstrate that Hi-VAE achieves a high compression factor of 1428$\times$, almost 30$\times$ higher than baseline methods (e.g., Cosmos-VAE at 48$\times$), validating the efficiency of our approach. Meanwhile, Hi-VAE maintains high reconstruction quality at such high compression rates and performs effectively in downstream generative tasks. Moreover, Hi-VAE exhibits interpretability and scalability, providing new perspectives for future exploration in video latent representation and generation.</li>
</ul>

<h3>Title: Learning Compact Vision Tokens for Efficient Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Tang, Chengchao Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07138">https://arxiv.org/abs/2506.07138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07138">https://arxiv.org/pdf/2506.07138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07138]] Learning Compact Vision Tokens for Efficient Large Multimodal Models(https://arxiv.org/abs/2506.07138)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large multimodal models (LMMs) suffer significant computational challenges due to the high cost of Large Language Models (LLMs) and the quadratic complexity of processing long vision token sequences. In this paper, we explore the spatial redundancy among vision tokens and shorten the length of vision token sequences for inference acceleration. Specifically, we propose a Spatial Token Fusion (STF) method to learn compact vision tokens for short vision token sequence, where spatial-adjacent tokens are fused into one. Meanwhile, weight-frozen vision encoder can not well adapt to the demand of extensive downstream vision-language tasks. To this end, we further introduce a Multi-Block Token Fusion (MBTF) module to supplement multi-granularity features for the reduced token sequence. Overall, we combine STF and MBTF module to balance token reduction and information preservation, thereby improving inference efficiency without sacrificing multimodal reasoning capabilities. Experimental results demonstrate that our method based on LLaVA-1.5 achieves comparable or even superior performance to the baseline on 8 popular vision-language benchmarks with only $25\%$ vision tokens of baseline. The source code and trained weights are available at this https URL.</li>
</ul>

<h3>Title: Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting</h3>
<ul>
<li><strong>Authors: </strong>Lennart Meincke, Ethan Mollick, Lilach Mollick, Dan Shapiro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07142">https://arxiv.org/abs/2506.07142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07142">https://arxiv.org/pdf/2506.07142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07142]] Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting(https://arxiv.org/abs/2506.07142)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This is the second in a series of short reports that seek to help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. In this report, we investigate Chain-of-Thought (CoT) prompting, a technique that encourages a large language model (LLM) to "think step by step" (Wei et al., 2022). CoT is a widely adopted method for improving reasoning tasks, however, our findings reveal a more nuanced picture of its effectiveness. We demonstrate two things: - The effectiveness of Chain-of-Thought prompting can vary greatly depending on the type of task and model. For non-reasoning models, CoT generally improves average performance by a small amount, particularly if the model does not inherently engage in step-by-step processing by default. However, CoT can introduce more variability in answers, sometimes triggering occasional errors in questions the model would otherwise get right. We also found that many recent models perform some form of CoT reasoning even if not asked; for these models, a request to perform CoT had little impact. Performing CoT generally requires far more tokens (increasing cost and time) than direct answers. - For models designed with explicit reasoning capabilities, CoT prompting often results in only marginal, if any, gains in answer accuracy. However, it significantly increases the time and tokens needed to generate a response.</li>
</ul>

<h3>Title: Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yaping Chai, Haoran Xie, Joe S. Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07148">https://arxiv.org/abs/2506.07148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07148">https://arxiv.org/pdf/2506.07148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07148]] Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis(https://arxiv.org/abs/2506.07148)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) is an effective approach to addressing data scarcity in low-resource scenarios. Recent existing research designs hand-crafted prompts to guide LLM for data augmentation. We introduce a data augmentation strategy for the aspect category sentiment analysis (ACSA) task that preserves the original sentence semantics and has linguistic diversity, specifically by providing a structured prompt template for an LLM to generate predefined content. In addition, we employ a post-processing technique to further ensure semantic consistency between the generated sentence and the original sentence. The augmented data increases the semantic coverage of the training distribution, enabling the model better to understand the relationship between aspect categories and sentiment polarities, enhancing its inference capabilities. Furthermore, we propose a confidence-weighted fine-tuning strategy to encourage the model to generate more confident and accurate sentiment polarity predictions. Compared with powerful and recent works, our method consistently achieves the best performance on four benchmark datasets over all baselines.</li>
</ul>

<h3>Title: Mind the Web: The Security of Web Use Agents</h3>
<ul>
<li><strong>Authors: </strong>Avishag Shapira, Parth Atulbhai Gandhi, Edan Habler, Oleg Brodt, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07153">https://arxiv.org/abs/2506.07153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07153">https://arxiv.org/pdf/2506.07153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07153]] Mind the Web: The Security of Web Use Agents(https://arxiv.org/abs/2506.07153)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Web-use agents are rapidly being deployed to automate complex web tasks, operating with extensive browser capabilities including multi-tab navigation, DOM manipulation, JavaScript execution and authenticated session access. However, these powerful capabilities create a critical and previously unexplored attack surface. This paper demonstrates how attackers can exploit web-use agents' high-privilege capabilities by embedding malicious content in web pages such as comments, reviews, or advertisements that agents encounter during legitimate browsing tasks. In addition, we introduce the task-aligned injection technique that frame malicious commands as helpful task guidance rather than obvious attacks. This technique exploiting fundamental limitations in LLMs' contextual reasoning: agents struggle in maintaining coherent contextual awareness and fail to detect when seemingly helpful web content contains steering attempts that deviate from their original task goal. Through systematic evaluation of four popular agents (OpenAI Operator, Browser Use, Do Browser, OpenOperator), we demonstrate nine payload types that compromise confidentiality, integrity, and availability, including unauthorized camera activation, user impersonation, local file exfiltration, password leakage, and denial of service, with validation across multiple LLMs achieving success rates of 80%-100%. These payloads succeed across agents with built-in safety mechanisms, requiring only the ability to post content on public websites, creating unprecedented risks given the ease of exploitation combined with agents' high-privilege access. To address this attack, we propose comprehensive mitigation strategies including oversight mechanisms, execution constraints, and task-aware reasoning techniques, providing practical directions for secure development and deployment.</li>
</ul>

<h3>Title: Syntactic Control of Language Models by Posterior Inference</h3>
<ul>
<li><strong>Authors: </strong>Vicky Xefteri, Tim Vieira, Ryan Cotterell, Afra Amini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07154">https://arxiv.org/abs/2506.07154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07154">https://arxiv.org/pdf/2506.07154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07154]] Syntactic Control of Language Models by Posterior Inference(https://arxiv.org/abs/2506.07154)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Controlling the syntactic structure of text generated by language models is valuable for applications requiring clarity, stylistic consistency, or interpretability, yet it remains a challenging task. In this paper, we argue that sampling algorithms based on the posterior inference can effectively enforce a target constituency structure during generation. Our approach combines sequential Monte Carlo, which estimates the posterior distribution by sampling from a proposal distribution, with a syntactic tagger that ensures that each generated token aligns with the desired syntactic structure. Our experiments with GPT2 and Llama3-8B models show that with an appropriate proposal distribution, we can improve syntactic accuracy, increasing the F1 score from $12.31$ (GPT2-large) and $35.33$ (Llama3-8B) to about $93$ in both cases without compromising the language model's fluency. These results underscore both the complexity of syntactic control and the effectiveness of sampling algorithms, offering a promising approach for applications where precise control over syntax is essential.</li>
</ul>

<h3>Title: GoTrack: Generic 6DoF Object Pose Refinement and Tracking</h3>
<ul>
<li><strong>Authors: </strong>Van Nguyen Nguyen, Christian Forster, Sindi Shkodrani, Vincent Lepetit, Bugra Tekin, Cem Keskin, Tomas Hodan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07155">https://arxiv.org/abs/2506.07155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07155">https://arxiv.org/pdf/2506.07155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07155]] GoTrack: Generic 6DoF Object Pose Refinement and Tracking(https://arxiv.org/abs/2506.07155)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce GoTrack, an efficient and accurate CAD-based method for 6DoF object pose refinement and tracking, which can handle diverse objects without any object-specific training. Unlike existing tracking methods that rely solely on an analysis-by-synthesis approach for model-to-frame registration, GoTrack additionally integrates frame-to-frame registration, which saves compute and stabilizes tracking. Both types of registration are realized by optical flow estimation. The model-to-frame registration is noticeably simpler than in existing methods, relying only on standard neural network blocks (a transformer is trained on top of DINOv2) and producing reliable pose confidence scores without a scoring network. For the frame-to-frame registration, which is an easier problem as consecutive video frames are typically nearly identical, we employ a light off-the-shelf optical flow model. We demonstrate that GoTrack can be seamlessly combined with existing coarse pose estimation methods to create a minimal pipeline that reaches state-of-the-art RGB-only results on standard benchmarks for 6DoF object pose estimation and tracking. Our source code and trained models are publicly available at this https URL</li>
</ul>

<h3>Title: GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yikun Wang, Yibin Wang, Dianyi Wang, Zimian Peng, Qipeng Guo, Dacheng Tao, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07160">https://arxiv.org/abs/2506.07160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07160">https://arxiv.org/pdf/2506.07160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07160]] GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization(https://arxiv.org/abs/2506.07160)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have demonstrated remarkable capabilities across diverse domains, particularly in mathematical reasoning, amid which geometry problem solving remains a challenging area where auxiliary construction plays a enssential role. Existing approaches either achieve suboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring massive computational costs. We posit that reinforcement learning with verifiable reward (e.g., GRPO) offers a promising direction for training smaller models that effectively combine auxiliary construction with robust geometric reasoning. However, directly applying GRPO to geometric reasoning presents fundamental limitations due to its dependence on unconditional rewards, which leads to indiscriminate and counterproductive auxiliary constructions. To address these challenges, we propose Group Contrastive Policy Optimization (GCPO), a novel reinforcement learning framework featuring two key innovations: (1) Group Contrastive Masking, which adaptively provides positive or negative reward signals for auxiliary construction based on contextual utility, and a (2) length reward that promotes longer reasoning chains. Building on GCPO, we develop GeometryZero, a family of affordable-size geometric reasoning models that judiciously determine when to employ auxiliary construction. Our extensive empirical evaluation across popular geometric benchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models consistently outperform baselines (e.g. GRPO), achieving an average improvement of 4.29% across all benchmarks.</li>
</ul>

<h3>Title: Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs</h3>
<ul>
<li><strong>Authors: </strong>Qiong Chang, Xinyuan Chen, Xiang Li, Weimin Wang, Jun Miyazaki</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07164">https://arxiv.org/abs/2506.07164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07164">https://arxiv.org/pdf/2506.07164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07164]] Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs(https://arxiv.org/abs/2506.07164)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The visual-based SLAM (Simultaneous Localization and Mapping) is a technology widely used in applications such as robotic navigation and virtual reality, which primarily focuses on detecting feature points from visual images to construct an unknown environmental map and simultaneously determines its own location. It usually imposes stringent requirements on hardware power consumption, processing speed and accuracy. Currently, the ORB (Oriented FAST and Rotated BRIEF)-based SLAM systems have exhibited superior performance in terms of processing speed and robustness. However, they still fall short of meeting the demands for real-time processing on mobile platforms. This limitation is primarily due to the time-consuming Oriented FAST calculations accounting for approximately half of the entire SLAM system. This paper presents two methods to accelerate the Oriented FAST feature detection on low-end embedded GPUs. These methods optimize the most time-consuming steps in Oriented FAST feature detection: FAST feature point detection and Harris corner detection, which is achieved by implementing a binary-level encoding strategy to determine candidate points quickly and a separable Harris detection strategy with efficient low-level GPU hardware-specific instructions. Extensive experiments on a Jetson TX2 embedded GPU demonstrate an average speedup of over 7.3 times compared to widely used OpenCV with GPU support. This significant improvement highlights its effectiveness and potential for real-time applications in mobile and resource-constrained environments.</li>
</ul>

<h3>Title: AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models</h3>
<ul>
<li><strong>Authors: </strong>Qi Liu, Jingqing Ruan, Hao Li, Haodong Zhao, Desheng Wang, Jiansong Chen, Wan Guanglu, Xunliang Cai, Zhi Zheng, Tong Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07165">https://arxiv.org/abs/2506.07165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07165">https://arxiv.org/pdf/2506.07165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07165]] AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models(https://arxiv.org/abs/2506.07165)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing multi-objective preference alignment methods for large language models (LLMs) face limitations: (1) the inability to effectively balance various preference dimensions, and (2) reliance on auxiliary reward/reference models introduces computational complexity. To address these challenges, we propose Adaptive Multi-objective Preference Optimization (AMoPO), a novel framework that achieves dynamic balance across preference dimensions. By introducing the multi-objective optimization paradigm to use the dimension-aware generation metrics as implicit rewards, AMoPO aligns LLMs with diverse preferences without additional reward models or reference models. We introduce an adaptive weight assignment mechanism that models the generation space as a Gaussian distribution, allowing dynamic prioritization of preference dimensions. Empirical results demonstrate that AMoPO outperforms state-of-the-art baselines by 28.5%, and the experiments on 7B, 14B, and 32B models reveal the scaling ability of AMoPO. Moreover, additional analysis of multiple dimensions verifies its adaptability and effectiveness. These findings validate AMoPO's capability to achieve dimension-aware preference alignment, highlighting its superiority. Our codes and datasets are available at this https URL.</li>
</ul>

<h3>Title: Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment</h3>
<ul>
<li><strong>Authors: </strong>Huanyi Xie, Lijie Hu, Lu Yu, Tianhao Huang, Longfei Li, Meng Li, Jun Zhou, Huan Wang, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07168">https://arxiv.org/abs/2506.07168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07168">https://arxiv.org/pdf/2506.07168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07168]] Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment(https://arxiv.org/abs/2506.07168)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the realm of Text-attributed Graphs (TAGs), traditional graph neural networks (GNNs) often fall short due to the complex textual information associated with each node. Recent methods have improved node representations by leveraging large language models (LLMs) to enhance node text features, but these approaches typically require extensive annotations or fine-tuning across all nodes, which is both time-consuming and costly. To overcome these challenges, we introduce GAGA, an efficient framework for TAG representation learning. GAGA reduces annotation time and cost by focusing on annotating only representative nodes and edges. It constructs an annotation graph that captures the topological relationships among these annotations. Furthermore, GAGA employs a two-level alignment module to effectively integrate the annotation graph with the TAG, aligning their underlying structures. Experiments show that GAGA achieves classification accuracies on par with or surpassing state-of-the-art methods while requiring only 1% of the data to be annotated, demonstrating its high efficiency.</li>
</ul>

<h3>Title: CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Dissertações e Trabalhos de Graduação em SI -- XXI Simpósio Brasileiro de Sistemas de Informação</h3>
<ul>
<li><strong>Authors: </strong>Washington Cunha, Leonardo Rocha, Marcos André Gonçalves</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07169">https://arxiv.org/abs/2506.07169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07169">https://arxiv.org/pdf/2506.07169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07169]] CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Dissertações e Trabalhos de Graduação em SI -- XXI Simpósio Brasileiro de Sistemas de Informação(https://arxiv.org/abs/2506.07169)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Progress in Natural Language Processing (NLP) has been dictated by the rule of more: more data, more computing power and more complexity, best exemplified by the Large Language Models. However, training (or fine-tuning) large dense models for specific applications usually requires significant amounts of computing resources. This \textbf{Ph.D. dissertation} focuses on an under-investi\-gated NLP data engineering technique, whose potential is enormous in the current scenario known as Instance Selection (IS). The IS goal is to reduce the training set size by removing noisy or redundant instances while maintaining the effectiveness of the trained models and reducing the training process cost. We provide a comprehensive and scientifically sound comparison of IS methods applied to an essential NLP task -- Automatic Text Classification (ATC), considering several classification solutions and many datasets. Our findings reveal a significant untapped potential for IS solutions. We also propose two novel IS solutions that are noise-oriented and redundancy-aware, specifically designed for large datasets and transformer architectures. Our final solution achieved an average reduction of 41\% in training sets, while maintaining the same levels of effectiveness in all datasets. Importantly, our solutions demonstrated speedup improvements of 1.67x (up to 2.46x), making them scalable for datasets with hundreds of thousands of documents.</li>
</ul>

<h3>Title: RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality</h3>
<ul>
<li><strong>Authors: </strong>Chenlong Zhang, Zhuoran Jin, Hongbang Yuan, Jiaheng Wei, Tong Zhou, Kang Liu, Jun Zhao, Yubo Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07171">https://arxiv.org/abs/2506.07171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07171">https://arxiv.org/pdf/2506.07171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07171]] RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality(https://arxiv.org/abs/2506.07171)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The widespread deployment of Large Language Models (LLMs) trained on massive, uncurated corpora has raised growing concerns about the inclusion of sensitive, copyrighted, or illegal content. This has led to increasing interest in LLM unlearning: the task of selectively removing specific information from a model without retraining from scratch or degrading overall utility. However, existing methods often rely on large-scale forget and retain datasets, and suffer from unnatural responses, poor generalization, or catastrophic utility loss. In this work, we propose Reinforcement UnLearning (RULE), an efficient framework that formulates unlearning as a refusal boundary optimization problem. RULE is trained with a small portion of the forget set and synthesized boundary queries, using a verifiable reward function that encourages safe refusal on forget--related queries while preserving helpful responses on permissible inputs. We provide both theoretical and empirical evidence demonstrating the effectiveness of RULE in achieving targeted unlearning without compromising model utility. Experimental results show that, with only $12%$ forget set and $8%$ synthesized boundary data, RULE outperforms existing baselines by up to $17.5%$ forget quality and $16.3%$ naturalness response while maintaining general utility, achieving forget--retain Pareto optimality. Remarkably, we further observe that RULE improves the naturalness of model outputs, enhances training efficiency, and exhibits strong generalization ability, generalizing refusal behavior to semantically related but unseen queries.</li>
</ul>

<h3>Title: Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Jaehong Yoon, Soo Ye Kim, Zhe Lin, Sung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07177">https://arxiv.org/abs/2506.07177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07177">https://arxiv.org/pdf/2506.07177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07177]] Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models(https://arxiv.org/abs/2506.07177)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Advancements in diffusion models have significantly improved video quality, directing attention to fine-grained controllability. However, many existing methods depend on fine-tuning large-scale video models for specific tasks, which becomes increasingly impractical as model sizes continue to grow. In this work, we present Frame Guidance, a training-free guidance for controllable video generation based on frame-level signals, such as keyframes, style reference images, sketches, or depth maps. For practical training-free guidance, we propose a simple latent processing method that dramatically reduces memory usage, and apply a novel latent optimization strategy designed for globally coherent video generation. Frame Guidance enables effective control across diverse tasks, including keyframe guidance, stylization, and looping, without any training, compatible with any video models. Experimental results show that Frame Guidance can produce high-quality controlled videos for a wide range of tasks and input signals.</li>
</ul>

<h3>Title: Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs</h3>
<ul>
<li><strong>Authors: </strong>Wenrui Zhou, Shu Yang, Qingsong Yang, Zikun Guo, Lijie Hu, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07180">https://arxiv.org/abs/2506.07180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07180">https://arxiv.org/pdf/2506.07180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07180]] Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs(https://arxiv.org/abs/2506.07180)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As video large language models (Video-LLMs) become increasingly integrated into real-world applications that demand grounded multimodal reasoning, ensuring their factual consistency and reliability is of critical importance. However, sycophancy, the tendency of these models to align with user input even when it contradicts the visual evidence, undermines their trustworthiness in such contexts. Current sycophancy research has largely overlooked its specific manifestations in the video-language domain, resulting in a notable absence of systematic benchmarks and targeted evaluations to understand how Video-LLMs respond under misleading user input. To fill this gap, we propose VISE (Video-LLM Sycophancy Benchmarking and Evaluation), the first dedicated benchmark designed to evaluate sycophantic behavior in state-of-the-art Video-LLMs across diverse question formats, prompt biases, and visual reasoning tasks. Specifically, VISE pioneeringly brings linguistic perspectives on sycophancy into the visual domain, enabling fine-grained analysis across multiple sycophancy types and interaction patterns. In addition, we explore key-frame selection as an interpretable, training-free mitigation strategy, which reveals potential paths for reducing sycophantic bias by strengthening visual grounding.</li>
</ul>

<h3>Title: Learning based on neurovectors for tabular data: a new neural network approach</h3>
<ul>
<li><strong>Authors: </strong>J.C. Husillos, A. Gallego, A. Roma, A. Troncoso</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07185">https://arxiv.org/abs/2506.07185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07185">https://arxiv.org/pdf/2506.07185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07185]] Learning based on neurovectors for tabular data: a new neural network approach(https://arxiv.org/abs/2506.07185)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel learning approach based on Neurovectors, an innovative paradigm that structures information through interconnected nodes and vector relationships for tabular data processing. Unlike traditional artificial neural networks that rely on weight adjustment through backpropagation, Neurovectors encode information by structuring data in vector spaces where energy propagation, rather than traditional weight updates, drives the learning process, enabling a more adaptable and explainable learning process. Our method generates dynamic representations of knowledge through neurovectors, thereby improving both the interpretability and efficiency of the predictive model. Experimental results using datasets from well-established repositories such as the UCI machine learning repository and Kaggle are reported both for classification and regression. To evaluate its performance, we compare our approach with standard machine learning and deep learning models, showing that Neurovectors achieve competitive accuracy.</li>
</ul>

<h3>Title: Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Ni Ding, Lei He, Shengbo Eben Li, Keqiang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07188">https://arxiv.org/abs/2506.07188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07188">https://arxiv.org/pdf/2506.07188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07188]] Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks(https://arxiv.org/abs/2506.07188)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>End-to-end autonomous driving has emerged as a dominant paradigm, yet its highly entangled black-box models pose significant challenges in terms of interpretability and safety assurance. To improve model transparency and training flexibility, this paper proposes a hierarchical and decoupled post-training framework tailored for pretrained neural networks. By reconstructing intermediate feature maps from ground-truth labels, surrogate supervisory signals are introduced at transitional layers to enable independent training of specific components, thereby avoiding the complexity and coupling of conventional end-to-end backpropagation and providing interpretable insights into networks' internal mechanisms. To the best of our knowledge, this is the first method to formalize feature-level reverse computation as well-posed optimization problems, which we rigorously reformulate as systems of linear equations or least squares problems. This establishes a novel and efficient training paradigm that extends gradient backpropagation to feature backpropagation. Extensive experiments on multiple standard image classification benchmarks demonstrate that the proposed method achieves superior generalization performance and computational efficiency compared to traditional training approaches, validating its effectiveness and potential.</li>
</ul>

<h3>Title: A Simulation-based Evaluation Framework for Inter-VM RowHammer Mitigation Techniques</h3>
<ul>
<li><strong>Authors: </strong>Hidemasa Kawasaki, Soramichi Akiyama</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07190">https://arxiv.org/abs/2506.07190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07190">https://arxiv.org/pdf/2506.07190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07190]] A Simulation-based Evaluation Framework for Inter-VM RowHammer Mitigation Techniques(https://arxiv.org/abs/2506.07190)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Inter-VM RowHammer is an attack that induces a bitflip beyond the boundaries of virtual machines (VMs) to compromise a VM from another, and some software-based techniques have been proposed to mitigate this attack. Evaluating these mitigation techniques requires to confirm that they actually mitigate inter-VM RowHammer in low overhead. A challenge in this evaluation process is that both the mitigation ability and the overhead depend on the underlying hardware whose DRAM address mappings are different from machine to machine. This makes comprehensive evaluation prohibitively costly or even implausible as no machine that has a specific DRAM address mapping might be available. To tackle this challenge, we propose a simulation-based framework to evaluate software-based inter-VM RowHammer mitigation techniques across configurable DRAM address mappings. We demonstrate how to reproduce existing mitigation techniques on our framework, and show that it can evaluate the mitigation abilities and performance overhead of them with configurable DRAM address mappings.</li>
</ul>

<h3>Title: Analyzing Breast Cancer Survival Disparities by Race and Demographic Location: A Survival Analysis Approach</h3>
<ul>
<li><strong>Authors: </strong>Ramisa Farha, Joshua O. Olukoya</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07191">https://arxiv.org/abs/2506.07191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07191">https://arxiv.org/pdf/2506.07191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07191]] Analyzing Breast Cancer Survival Disparities by Race and Demographic Location: A Survival Analysis Approach(https://arxiv.org/abs/2506.07191)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study employs a robust analytical framework to uncover patterns in survival outcomes among breast cancer patients from diverse racial and geographical backgrounds. This research uses the SEER 2021 dataset to analyze breast cancer survival outcomes to identify and comprehend dissimilarities. Our approach integrates exploratory data analysis (EDA), through this we identify key variables that influence survival rates and employ survival analysis techniques, including the Kaplan-Meier estimator and log-rank test and the advanced modeling Cox Proportional Hazards model to determine how survival rates vary across racial groups and countries. Model validation and interpretation are undertaken to ensure the reliability of our findings, which are documented comprehensively to inform policymakers and healthcare professionals. The outcome of this paper is a detailed version of statistical analysis that not just highlights disparities in breast cancer treatment and care but also serves as a foundational tool for developing targeted interventions to address the inequalities effectively. Through this research, our aim is to contribute to the global efforts to improve breast cancer outcomes and reduce treatment disparities.</li>
</ul>

<h3>Title: SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning</h3>
<ul>
<li><strong>Authors: </strong>Mengya Xu, Zhongzhen Huang, Dillan Imans, Yiru Ye, Xiaofan Zhang, Qi Dou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07196">https://arxiv.org/abs/2506.07196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07196">https://arxiv.org/pdf/2506.07196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07196]] SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning(https://arxiv.org/abs/2506.07196)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effective evaluation is critical for driving advancements in MLLM research. The surgical action planning (SAP) task, which aims to generate future action sequences from visual inputs, demands precise and sophisticated analytical capabilities. Unlike mathematical reasoning, surgical decision-making operates in life-critical domains and requires meticulous, verifiable processes to ensure reliability and patient safety. This task demands the ability to distinguish between atomic visual actions and coordinate complex, long-horizon procedures, capabilities that are inadequately evaluated by current benchmarks. To address this gap, we introduce SAP-Bench, a large-scale, high-quality dataset designed to enable multimodal large language models (MLLMs) to perform interpretable surgical action planning. Our SAP-Bench benchmark, derived from the cholecystectomy procedures context with the mean duration of 1137.5s, and introduces temporally-grounded surgical action annotations, comprising the 1,226 clinically validated action clips (mean duration: 68.7s) capturing five fundamental surgical actions across 74 procedures. The dataset provides 1,152 strategically sampled current frames, each paired with the corresponding next action as multimodal analysis anchors. We propose the MLLM-SAP framework that leverages MLLMs to generate next action recommendations from the current surgical scene and natural language instructions, enhanced with injected surgical domain knowledge. To assess our dataset's effectiveness and the broader capabilities of current models, we evaluate seven state-of-the-art MLLMs (e.g., OpenAI-o1, GPT-4o, QwenVL2.5-72B, Claude-3.5-Sonnet, GeminiPro2.5, Step-1o, and GLM-4v) and reveal critical gaps in next action prediction performance.</li>
</ul>

<h3>Title: GGBall: Graph Generative Model on Poincaré Ball</h3>
<ul>
<li><strong>Authors: </strong>Tianci Bu, Chuanrui Wang, Hao Ma, Haoren Zheng, Xin Lu, Tailin Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07198">https://arxiv.org/abs/2506.07198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07198">https://arxiv.org/pdf/2506.07198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07198]] GGBall: Graph Generative Model on Poincaré Ball(https://arxiv.org/abs/2506.07198)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Generating graphs with hierarchical structures remains a fundamental challenge due to the limitations of Euclidean geometry in capturing exponential complexity. Here we introduce \textbf{GGBall}, a novel hyperbolic framework for graph generation that integrates geometric inductive biases with modern generative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder (HVQVAE) with a Riemannian flow matching prior defined via closed-form geodesics. This design enables flow-based priors to model complex latent distributions, while vector quantization helps preserve the curvature-aware structure of the hyperbolic space. We further develop a suite of hyperbolic GNN and Transformer layers that operate entirely within the manifold, ensuring stability and scalability. Empirically, our model reduces degree MMD by over 75\% on Community-Small and over 40\% on Ego-Small compared to state-of-the-art baselines, demonstrating an improved ability to preserve topological hierarchies. These results highlight the potential of hyperbolic geometry as a powerful foundation for the generative modeling of complex, structured, and hierarchical data domains. Our code is available at \href{this https URL}{here}.</li>
</ul>

<h3>Title: Efficient RL-based Cache Vulnerability Exploration by Penalizing Useless Agent Actions</h3>
<ul>
<li><strong>Authors: </strong>Kanato Nakanishi, Soramichi Akiyama</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07200">https://arxiv.org/abs/2506.07200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07200">https://arxiv.org/pdf/2506.07200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07200]] Efficient RL-based Cache Vulnerability Exploration by Penalizing Useless Agent Actions(https://arxiv.org/abs/2506.07200)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Cache-timing attacks exploit microarchitectural characteristics to leak sensitive data, posing a severe threat to modern systems. Despite its severity, analyzing the vulnerability of a given cache structure against cache-timing attacks is challenging. To this end, a method based on Reinforcement Learning (RL) has been proposed to automatically explore vulnerabilities for a given cache structure. However, a naive RL-based approach suffers from inefficiencies due to the agent performing actions that do not contribute to the exploration. In this paper, we propose a method to identify these useless actions during training and penalize them so that the agent avoids them and the exploration efficiency is improved. Experiments on 17 cache structures show that our training mechanism reduces the number of useless actions by up to 43.08%. This resulted in the reduction of training time by 28\% in the base case and 4.84\% in the geomean compared to a naive RL-based approach.</li>
</ul>

<h3>Title: TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation</h3>
<ul>
<li><strong>Authors: </strong>Min-Jung Kim, Dongjin Kim, Seokju Yun, Jaegul Choo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07205">https://arxiv.org/abs/2506.07205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07205">https://arxiv.org/pdf/2506.07205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07205]] TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation(https://arxiv.org/abs/2506.07205)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Video editing has garnered increasing attention alongside the rapid progress of diffusion-based video generation models. As part of these advancements, there is a growing demand for more accessible and controllable forms of video editing, such as prompt-based editing. Previous studies have primarily focused on tasks such as style transfer, background replacement, object substitution, and attribute modification, while maintaining the content structure of the source video. However, more complex tasks, including the addition of novel objects and nonrigid transformations, remain relatively unexplored. In this paper, we present TV-LiVE, a Training-free and text-guided Video editing framework via Layerinformed Vitality Exploitation. We empirically identify vital layers within the video generation model that significantly influence the quality of generated outputs. Notably, these layers are closely associated with Rotary Position Embeddings (RoPE). Based on this observation, our method enables both object addition and non-rigid video editing by selectively injecting key and value features from the source model into the corresponding layers of the target model guided by the layer vitality. For object addition, we further identify prominent layers to extract the mask regions corresponding to the newly added target prompt. We found that the extracted masks from the prominent layers faithfully indicate the region to be edited. Experimental results demonstrate that TV-LiVE outperforms existing approaches for both object addition and non-rigid video editing. Project Page: this https URL</li>
</ul>

<h3>Title: Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Zhong, Zhen Sun, Yepang Liu, Xinlei He, Guanhong Tao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07214">https://arxiv.org/abs/2506.07214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07214">https://arxiv.org/pdf/2506.07214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07214]] Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation(https://arxiv.org/abs/2506.07214)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal</a></li>
<li><strong>Abstract: </strong>Vision Language Models (VLMs) have shown remarkable performance, but are also vulnerable to backdoor attacks whereby the adversary can manipulate the model's outputs through hidden triggers. Prior attacks primarily rely on single-modality triggers, leaving the crucial cross-modal fusion nature of VLMs largely unexplored. Unlike prior work, we identify a novel attack surface that leverages cross-modal semantic mismatches as implicit triggers. Based on this insight, we propose BadSem (Backdoor Attack with Semantic Manipulation), a data poisoning attack that injects stealthy backdoors by deliberately misaligning image-text pairs during training. To perform the attack, we construct SIMBad, a dataset tailored for semantic manipulation involving color and object attributes. Extensive experiments across four widely used VLMs show that BadSem achieves over 98% average ASR, generalizes well to out-of-distribution datasets, and can transfer across poisoning modalities. Our detailed analysis using attention visualization shows that backdoored models focus on semantically sensitive regions under mismatched conditions while maintaining normal behavior on clean inputs. To mitigate the attack, we try two defense strategies based on system prompt and supervised fine-tuning but find that both of them fail to mitigate the semantic backdoor. Our findings highlight the urgent need to address semantic vulnerabilities in VLMs for their safer deployment.</li>
</ul>

<h3>Title: AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?</h3>
<ul>
<li><strong>Authors: </strong>Nada Aboudeshish, Dmitry Ignatov, Radu Timofte</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07216">https://arxiv.org/abs/2506.07216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07216">https://arxiv.org/pdf/2506.07216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07216]] AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?(https://arxiv.org/abs/2506.07216)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data augmentation is a crucial technique in deep learning, particularly for tasks with limited dataset diversity, such as skeleton-based datasets. This paper proposes a comprehensive data augmentation framework that integrates geometric transformations, random cropping, rotation, zooming and intensity-based transformations, brightness and contrast adjustments to simulate real-world variations. Random cropping ensures the preservation of spatio-temporal integrity while addressing challenges such as viewpoint bias and occlusions. The augmentation pipeline generates three augmented versions for each sample in addition to the data set sample, thus quadrupling the data set size and enriching the diversity of gesture representations. The proposed augmentation strategy is evaluated on three models: multi-stream e2eET, FPPR point cloud-based hand gesture recognition (HGR), and DD-Network. Experiments are conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB. The e2eET model, recognized as the state-of-the-art for hand gesture recognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-best performing model on SHREC'17, excels in point cloud-based gesture recognition. DD-Net, a lightweight and efficient architecture for skeleton-based action recognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB). The results underline the effectiveness and versatility of the proposed augmentation strategy, significantly improving model generalization and robustness across diverse datasets and architectures. This framework not only establishes state-of-the-art results on all three evaluated models but also offers a scalable solution to advance HGR and action recognition applications in real-world scenarios. The framework is available at this https URL</li>
</ul>

<h3>Title: Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward</h3>
<ul>
<li><strong>Authors: </strong>Tong Xiao, Xin Xu, Zhenya Huang, Hongyu Gao, Quan Liu, Qi Liu, Enhong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07218">https://arxiv.org/abs/2506.07218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07218">https://arxiv.org/pdf/2506.07218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07218]] Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward(https://arxiv.org/abs/2506.07218)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enhancing the multimodal reasoning capabilities of Multimodal Large Language Models (MLLMs) is a challenging task that has attracted increasing attention in the community. Recently, several studies have applied Reinforcement Learning with Verifiable Rewards (RLVR) to the multimodal domain in order to enhance the reasoning abilities of MLLMs. However, these works largely overlook the enhancement of multimodal perception capabilities in MLLMs, which serve as a core prerequisite and foundational component of complex multimodal reasoning. Through McNemar's test, we find that existing RLVR method fails to effectively enhance the multimodal perception capabilities of MLLMs, thereby limiting their further improvement in multimodal reasoning. To address this limitation, we propose Perception-R1, which introduces a novel visual perception reward that explicitly encourages MLLMs to perceive the visual content accurately, thereby can effectively incentivizing both their multimodal perception and reasoning capabilities. Specifically, we first collect textual visual annotations from the CoT trajectories of multimodal problems, which will serve as visual references for reward assignment. During RLVR training, we employ a judging LLM to assess the consistency between the visual annotations and the responses generated by MLLM, and assign the visual perception reward based on these consistency judgments. Extensive experiments on several multimodal reasoning benchmarks demonstrate the effectiveness of our Perception-R1, which achieves state-of-the-art performance on most benchmarks using only 1,442 training data.</li>
</ul>

<h3>Title: Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Bai, Yuxuan Fan, Jiantao Qiu, Fupeng Sun, Jiayi Song, Junlin Han, Zichen Liu, Conghui He, Wentao Zhang, Binhang Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07227">https://arxiv.org/abs/2506.07227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07227">https://arxiv.org/pdf/2506.07227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07227]] Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning(https://arxiv.org/abs/2506.07227)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have achieved strong performance on vision-language tasks but still struggle with fine-grained visual differences, leading to hallucinations or missed semantic shifts. We attribute this to limitations in both training data and learning objectives. To address these issues, we propose a controlled data generation pipeline that produces minimally edited image pairs with semantically aligned captions. Using this pipeline, we construct the Micro Edit Dataset (MED), containing over 50K image-text pairs spanning 11 fine-grained edit categories, including attribute, count, position, and object presence changes. Building on MED, we introduce a supervised fine-tuning (SFT) framework with a feature-level consistency loss that promotes stable visual embeddings under small edits. We evaluate our approach on the Micro Edit Detection benchmark, which includes carefully balanced evaluation pairs designed to test sensitivity to subtle visual variations across the same edit categories. Our method improves difference detection accuracy and reduces hallucinations compared to strong baselines, including GPT-4o. Moreover, it yields consistent gains on standard vision-language tasks such as image captioning and visual question answering. These results demonstrate the effectiveness of combining targeted data and alignment objectives for enhancing fine-grained visual reasoning in MLLMs.</li>
</ul>

<h3>Title: Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Bai, Zengjie Hu, Fupeng Sun, Jiantao Qiu, Yizhen Jiang, Guangxin He, Bohan Zeng, Conghui He, Binhang Yuan, Wentao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07235">https://arxiv.org/abs/2506.07235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07235">https://arxiv.org/pdf/2506.07235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07235]] Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification(https://arxiv.org/abs/2506.07235)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) have achieved remarkable capabilities by integrating visual perception with language understanding, enabling applications such as image-grounded dialogue, visual question answering, and scientific analysis. However, most MLLMs adopt a static inference paradigm, encoding the entire image into fixed visual tokens upfront, which limits their ability to iteratively refine understanding or adapt to context during inference. This contrasts sharply with human perception, which is dynamic, selective, and feedback-driven. In this work, we introduce a novel framework for inference-time visual token scaling that enables MLLMs to perform iterative, verifier-guided reasoning over visual content. We formulate the problem as a Markov Decision Process, involving a reasoner that proposes visual actions and a verifier, which is trained via multi-step Direct Preference Optimization (DPO), that evaluates these actions and determines when reasoning should terminate. To support this, we present a new dataset, VTS, comprising supervised reasoning trajectories (VTS-SFT) and preference-labeled reasoning comparisons (VTS-DPO). Our method significantly outperforms existing approaches across diverse visual reasoning benchmarks, offering not only improved accuracy but also more interpretable and grounded reasoning processes. These results demonstrate the promise of dynamic inference mechanisms for enabling fine-grained, context-aware visual reasoning in next-generation MLLMs.</li>
</ul>

<h3>Title: SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes</h3>
<ul>
<li><strong>Authors: </strong>Wenxuan Xie, Yaxun Dai, Wenhao Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07245">https://arxiv.org/abs/2506.07245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07245">https://arxiv.org/pdf/2506.07245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07245]] SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes(https://arxiv.org/abs/2506.07245)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.</li>
</ul>

<h3>Title: Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Ngoc-Quan Pham, Tuan Truong, Quyen Tran, Tan Nguyen, Dinh Phung, Trung Le</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07247">https://arxiv.org/abs/2506.07247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07247">https://arxiv.org/pdf/2506.07247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07247]] Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models(https://arxiv.org/abs/2506.07247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce Interactive Bayesian Distributional Robustness (IBDR), a novel Bayesian inference framework that allows modeling the interactions between particles, thereby enhancing ensemble quality through increased particle diversity. IBDR is grounded in a generalized theoretical framework that connects the distributional population loss with the approximate posterior, motivating a practical dual optimization procedure that enforces distributional robustness while fostering particle diversity. We evaluate IBDR's performance against various baseline methods using the VTAB-1K benchmark and the common reasoning language task. The results consistently show that IBDR outperforms these baselines, underscoring its effectiveness in real-world applications.</li>
</ul>

<h3>Title: Improving the Efficiency of Long Document Classification using Sentence Ranking Approach</h3>
<ul>
<li><strong>Authors: </strong>Prathamesh Kokate, Mitali Sarnaik, Manavi Khopade, Raviraj Joshi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07248">https://arxiv.org/abs/2506.07248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07248">https://arxiv.org/pdf/2506.07248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07248]] Improving the Efficiency of Long Document Classification using Sentence Ranking Approach(https://arxiv.org/abs/2506.07248)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Long document classification poses challenges due to the computational limitations of transformer-based models, particularly BERT, which are constrained by fixed input lengths and quadratic attention complexity. Moreover, using the full document for classification is often redundant, as only a subset of sentences typically carries the necessary information. To address this, we propose a TF-IDF-based sentence ranking method that improves efficiency by selecting the most informative content. Our approach explores fixed-count and percentage-based sentence selection, along with an enhanced scoring strategy combining normalized TF-IDF scores and sentence length. Evaluated on the MahaNews LDC dataset of long Marathi news articles, the method consistently outperforms baselines such as first, last, and random sentence selection. With MahaBERT-v2, we achieve near-identical classification accuracy with just a 0.33 percent drop compared to the full-context baseline, while reducing input size by over 50 percent and inference latency by 43 percent. This demonstrates that significant context reduction is possible without sacrificing performance, making the method practical for real-world long document classification tasks.</li>
</ul>

<h3>Title: Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages</h3>
<ul>
<li><strong>Authors: </strong>Lance Calvin Lim Gamboa, Yue Feng, Mark Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07249">https://arxiv.org/abs/2506.07249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07249">https://arxiv.org/pdf/2506.07249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07249]] Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages(https://arxiv.org/abs/2506.07249)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Emerging research on bias attribution and interpretability have revealed how tokens contribute to biased behavior in language models processing English texts. We build on this line of inquiry by adapting the information-theoretic bias attribution score metric for implementation on models handling agglutinative languages, particularly Filipino. We then demonstrate the effectiveness of our adapted method by using it on a purely Filipino model and on three multilingual models: one trained on languages worldwide and two on Southeast Asian data. Our results show that Filipino models are driven towards bias by words pertaining to people, objects, and relationships, entity-based themes that stand in contrast to the action-heavy nature of bias-contributing themes in English (i.e., criminal, sexual, and prosocial behaviors). These findings point to differences in how English and non-English models process inputs linked to sociodemographic groups and bias.</li>
</ul>

<h3>Title: A Stable Whitening Optimizer for Efficient Neural Network Training</h3>
<ul>
<li><strong>Authors: </strong>Kevin Frans, Sergey Levine, Pieter Abbeel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07254">https://arxiv.org/abs/2506.07254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07254">https://arxiv.org/pdf/2506.07254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07254]] A Stable Whitening Optimizer for Efficient Neural Network Training(https://arxiv.org/abs/2506.07254)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>In this work, we take an experimentally grounded look at neural network optimization. Building on the Shampoo family of algorithms, we identify and alleviate three key issues, resulting in the proposed SPlus method. First, we find that naive Shampoo is prone to divergence when matrix-inverses are cached for long periods. We introduce an alternate bounded update combining a historical eigenbasis with instantaneous normalization, resulting in across-the-board stability and significantly lower computational requirements. Second, we adapt a shape-aware scaling to enable learning rate transfer across network width. Third, we find that high learning rates result in large parameter noise, and propose a simple iterate-averaging scheme which unblocks faster learning. To properly confirm these findings, we introduce a pointed Transformer training benchmark, considering three objectives (language modelling, image classification, and diffusion modelling) across different stages of training. On average, SPlus is able to reach the validation performance of Adam within 44% of the gradient steps and 62% of the wallclock time.</li>
</ul>

<h3>Title: Exploiting Inaccurate Branch History in Side-Channel Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yuhui Zhu, Alessandro Biondi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07263">https://arxiv.org/abs/2506.07263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07263">https://arxiv.org/pdf/2506.07263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07263]] Exploiting Inaccurate Branch History in Side-Channel Attacks(https://arxiv.org/abs/2506.07263)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Modern out-of-order CPUs heavily rely on speculative execution for performance optimization, with branch prediction serving as a cornerstone to minimize stalls and maximize efficiency. Whenever shared branch prediction resources lack proper isolation and sanitization methods, they may originate security vulnerabilities that expose sensitive data across different software contexts. This paper examines the fundamental components of modern Branch Prediction Units (BPUs) and investigates how resource sharing and contention affect two widely implemented but underdocumented features: Bias-Free Branch Prediction and Branch History Speculation. Our analysis demonstrates that these BPU features, while designed to enhance speculative execution efficiency through more accurate branch histories, can also introduce significant security risks. We show that these features can inadvertently modify the Branch History Buffer (BHB) update behavior and create new primitives that trigger malicious mis-speculations. This discovery exposes previously unknown cross-privilege attack surfaces for Branch History Injection (BHI). Based on these findings, we present three novel attack primitives: two Spectre attacks, namely Spectre-BSE and Spectre-BHS, and a cross-privilege control flow side-channel attack called BiasScope. Our research identifies corresponding patterns of vulnerable control flows and demonstrates exploitation on multiple processors. Finally, Chimera is presented: an attack demonstrator based on eBPF for a variant of Spectre-BHS that is capable of leaking kernel memory contents at 24,628 bit/s.</li>
</ul>

<h3>Title: Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Atahan Özer, Çağatay Yıldız</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07270">https://arxiv.org/abs/2506.07270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07270">https://arxiv.org/pdf/2506.07270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07270]] Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs(https://arxiv.org/abs/2506.07270)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit remarkable capabilities in question answering and reasoning thanks to their extensive parametric memory. However, their knowledge is inherently limited by the scope of their pre-training data, while real-world information evolves continuously. Updating this knowledge typically requires costly and brittle re-training, or in-context learning (ICL), which becomes impractical at scale given the volume and volatility of modern information. Motivated by these limitations, we investigate how LLMs perform when exposed to temporal text corpora, or documents that reflect evolving knowledge over time, such as sports biographies where facts like a player's "current team" change year by year. To this end, we introduce two new benchmarks: Temporal Wiki, which captures factual drift across historical Wikipedia snapshots, and Unified Clark, which aggregates timestamped news articles to simulate real-world information accumulation. Our analysis reveals that LLMs often struggle to reconcile conflicting or outdated facts and can be misled when multiple versions of a fact appear in context. To address these issues, we propose a lightweight, agentic framework that incrementally builds a structured, external memory from source documents without requiring re-training. This knowledge organization strategy enables models to retrieve and reason over temporally filtered, relevant information at inference time. Empirically, our method outperforms ICL and RAG baselines across both benchmarks, especially on questions requiring more complex reasoning or integration of conflicting facts.</li>
</ul>

<h3>Title: Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Olga Kellert, Nemika Tyagi, Muhammad Imran, Nelvin Licona-Guevara, Carlos Gómez-Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07274">https://arxiv.org/abs/2506.07274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07274">https://arxiv.org/pdf/2506.07274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07274]] Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages(https://arxiv.org/abs/2506.07274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Code-switching presents a complex challenge for syntactic analysis, especially in low-resource language settings where annotated data is scarce. While recent work has explored the use of large language models (LLMs) for sequence-level tagging, few approaches systematically investigate how well these models capture syntactic structure in code-switched contexts. Moreover, existing parsers trained on monolingual treebanks often fail to generalize to multilingual and mixed-language input. To address this gap, we introduce the BiLingua Parser, an LLM-based annotation pipeline designed to produce Universal Dependencies (UD) annotations for code-switched text. First, we develop a prompt-based framework for Spanish-English and Spanish-Guaraní data, combining few-shot LLM prompting with expert review. Second, we release two annotated datasets, including the first Spanish-Guaraní UD-parsed corpus. Third, we conduct a detailed syntactic analysis of switch points across language pairs and communicative contexts. Experimental results show that BiLingua Parser achieves up to 95.29% LAS after expert revision, significantly outperforming prior baselines and multilingual parsers. These results show that LLMs, when carefully guided, can serve as practical tools for bootstrapping syntactic resources in under-resourced, code-switched environments. Data and source code are available at this https URL</li>
</ul>

<h3>Title: Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haochen Song, Dominik Hofer, Rania Islambouli, Laura Hawkins, Ananya Bhattacharjee, Meredith Franklin, Joseph Jay Williams</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07275">https://arxiv.org/abs/2506.07275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07275">https://arxiv.org/pdf/2506.07275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07275]] Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models(https://arxiv.org/abs/2506.07275)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Machine learning approaches, such as contextual multi-armed bandit (cMAB) algorithms, offer a promising strategy to reduce sedentary behavior by delivering personalized interventions to encourage physical activity. However, cMAB algorithms typically require large participant samples to learn effectively and may overlook key psychological factors that are not explicitly encoded in the model. In this study, we propose a hybrid approach that combines cMAB for selecting intervention types with large language models (LLMs) to personalize message content. We evaluate four intervention types: behavioral self-monitoring, gain-framed, loss-framed, and social comparison, each delivered as a motivational message aimed at increasing motivation for physical activity and daily step count. Message content is further personalized using dynamic contextual factors including daily fluctuations in self-efficacy, social influence, and regulatory focus. Over a seven-day trial, participants receive daily messages assigned by one of four models: cMAB alone, LLM alone, combined cMAB with LLM personalization (cMABxLLM), or equal randomization (RCT). Outcomes include daily step count and message acceptance, assessed via ecological momentary assessments (EMAs). We apply a causal inference framework to evaluate the effects of each model. Our findings offer new insights into the complementary roles of LLM-based personalization and cMAB adaptation in promoting physical activity through personalized behavioral messaging.</li>
</ul>

<h3>Title: From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07280">https://arxiv.org/abs/2506.07280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07280">https://arxiv.org/pdf/2506.07280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07280]] From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models(https://arxiv.org/abs/2506.07280)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Video Diffusion Models (VDMs) have emerged as powerful generative tools, capable of synthesizing high-quality spatiotemporal content. Yet, their potential goes far beyond mere video generation. We argue that the training dynamics of VDMs, driven by the need to model coherent sequences, naturally pushes them to internalize structured representations and an implicit understanding of the visual world. To probe the extent of this internal knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs for new tasks using only a handful of examples. Our method transforms each task into a visual transition, enabling the training of LoRA weights on short input-output sequences without altering the generative interface of a frozen VDM. Despite minimal supervision, the model exhibits strong generalization across diverse tasks, from low-level vision (for example, segmentation and pose estimation) to high-level reasoning (for example, on ARC-AGI). These results reframe VDMs as more than generative engines. They are adaptable visual learners with the potential to serve as the backbone for future foundation models in vision.</li>
</ul>

<h3>Title: Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI</h3>
<ul>
<li><strong>Authors: </strong>Aditya Chakravarty</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07286">https://arxiv.org/abs/2506.07286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07286">https://arxiv.org/pdf/2506.07286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07286]] Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI(https://arxiv.org/abs/2506.07286)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown remarkable flexibility for solving inverse problems without task-specific retraining. However, existing approaches such as Manifold Preserving Guided Diffusion (MPGD) apply only a single gradient update per denoising step, limiting restoration fidelity and robustness, especially in embedded or out-of-distribution settings. In this work, we introduce a multistep optimization strategy within each denoising timestep, significantly enhancing image quality, perceptual accuracy, and generalization. Our experiments on super-resolution and Gaussian deblurring demonstrate that increasing the number of gradient updates per step improves LPIPS and PSNR with minimal latency overhead. Notably, we validate this approach on a Jetson Orin Nano using degraded ImageNet and a UAV dataset, showing that MPGD, originally trained on face datasets, generalizes effectively to natural and aerial scenes. Our findings highlight MPGD's potential as a lightweight, plug-and-play restoration module for real-time visual perception in embodied AI agents such as drones and mobile robots.</li>
</ul>

<h3>Title: Exploring the Impact of Temperature on Large Language Models:Hot or Cold?</h3>
<ul>
<li><strong>Authors: </strong>Lujun Li, Lama Sleem, Niccolo' Gentile, Geoffrey Nichil, Radu State</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07295">https://arxiv.org/abs/2506.07295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07295">https://arxiv.org/pdf/2506.07295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07295]] Exploring the Impact of Temperature on Large Language Models:Hot or Cold?(https://arxiv.org/abs/2506.07295)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The sampling temperature, a critical hyperparameter in large language models (LLMs), modifies the logits before the softmax layer, thereby reshaping the distribution of output tokens. Recent studies have challenged the Stochastic Parrots analogy by demonstrating that LLMs are capable of understanding semantics rather than merely memorizing data and that randomness, modulated by sampling temperature, plays a crucial role in model inference. In this study, we systematically evaluated the impact of temperature in the range of 0 to 2 on data sets designed to assess six different capabilities, conducting statistical analyses on open source models of three different sizes: small (1B--4B), medium (6B--13B), and large (40B--80B). Our findings reveal distinct skill-specific effects of temperature on model performance, highlighting the complexity of optimal temperature selection in practical applications. To address this challenge, we propose a BERT-based temperature selector that takes advantage of these observed effects to identify the optimal temperature for a given prompt. We demonstrate that this approach can significantly improve the performance of small and medium models in the SuperGLUE datasets. Furthermore, our study extends to FP16 precision inference, revealing that temperature effects are consistent with those observed in 4-bit quantized models. By evaluating temperature effects up to 4.0 in three quantized models, we find that the Mutation Temperature -- the point at which significant performance changes occur -- increases with model size.</li>
</ul>

<h3>Title: Pre-trained Large Language Models Learn Hidden Markov Models In-context</h3>
<ul>
<li><strong>Authors: </strong>Yijia Dai, Zhaolin Gao, Yahya Satter, Sarah Dean, Jennifer J. Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07298">https://arxiv.org/abs/2506.07298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07298">https://arxiv.org/pdf/2506.07298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07298]] Pre-trained Large Language Models Learn Hidden Markov Models In-context(https://arxiv.org/abs/2506.07298)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hidden Markov Models (HMMs) are foundational tools for modeling sequential data with latent Markovian structure, yet fitting them to real-world data remains computationally challenging. In this work, we show that pre-trained large language models (LLMs) can effectively model data generated by HMMs via in-context learning (ICL)$\unicode{x2013}$their ability to infer patterns from examples within a prompt. On a diverse set of synthetic HMMs, LLMs achieve predictive accuracy approaching the theoretical optimum. We uncover novel scaling trends influenced by HMM properties, and offer theoretical conjectures for these empirical observations. We also provide practical guidelines for scientists on using ICL as a diagnostic tool for complex data. On real-world animal decision-making tasks, ICL achieves competitive performance with models designed by human experts. To our knowledge, this is the first demonstration that ICL can learn and predict HMM-generated sequences$\unicode{x2013}$an advance that deepens our understanding of in-context learning in LLMs and establishes its potential as a powerful tool for uncovering hidden structure in complex scientific data.</li>
</ul>

<h3>Title: PASS: Private Attributes Protection with Stochastic Data Substitution</h3>
<ul>
<li><strong>Authors: </strong>Yizhuo Chen, Chun-Fu (Richard)Chen, Hsiang Hsu, Shaohan Hu, Tarek Abdelzaher</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07308">https://arxiv.org/abs/2506.07308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07308">https://arxiv.org/pdf/2506.07308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07308]] PASS: Private Attributes Protection with Stochastic Data Substitution(https://arxiv.org/abs/2506.07308)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>The growing Machine Learning (ML) services require extensive collections of user data, which may inadvertently include people's private information irrelevant to the services. Various studies have been proposed to protect private attributes by removing them from the data while maintaining the utilities of the data for downstream tasks. Nevertheless, as we theoretically and empirically show in the paper, these methods reveal severe vulnerability because of a common weakness rooted in their adversarial training based strategies. To overcome this limitation, we propose a novel approach, PASS, designed to stochastically substitute the original sample with another one according to certain probabilities, which is trained with a novel loss function soundly derived from information-theoretic objective defined for utility-preserving private attributes protection. The comprehensive evaluation of PASS on various datasets of different modalities, including facial images, human activity sensory signals, and voice recording datasets, substantiates PASS's effectiveness and generalizability.</li>
</ul>

<h3>Title: ConfQA: Answer Only If You Are Confident</h3>
<ul>
<li><strong>Authors: </strong>Yin Huang, Yifan Ethan Xu, Kai Sun, Vera Yan, Alicia Sun, Haidar Khan, Jimmy Nguyen, Mohammad Kachuee, Zhaojiang Lin, Yue Liu, Aaron Colak, Anuj Kumar, Wen-tau Yih, Xin Luna Dong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07309">https://arxiv.org/abs/2506.07309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07309">https://arxiv.org/pdf/2506.07309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07309]] ConfQA: Answer Only If You Are Confident(https://arxiv.org/abs/2506.07309)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Can we teach Large Language Models (LLMs) to refrain from hallucinating factual statements? In this paper we present a fine-tuning strategy that we call ConfQA, which can reduce hallucination rate from 20-40% to under 5% across multiple factuality benchmarks. The core idea is simple: when the LLM answers a question correctly, it is trained to continue with the answer; otherwise, it is trained to admit "I am unsure". But there are two key factors that make the training highly effective. First, we introduce a dampening prompt "answer only if you are confident" to explicitly guide the behavior, without which hallucination remains high as 15%-25%. Second, we leverage simple factual statements, specifically attribute values from knowledge graphs, to help LLMs calibrate the confidence, resulting in robust generalization across domains and question types. Building on this insight, we propose the Dual Neural Knowledge framework, which seamlessly select between internally parameterized neural knowledge and externally recorded symbolic knowledge based on ConfQA's confidence. The framework enables potential accuracy gains to beyond 95%, while reducing unnecessary external retrievals by over 30%.</li>
</ul>

<h3>Title: Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference</h3>
<ul>
<li><strong>Authors: </strong>Thomas Joshi, Herman Saini, Neil Dhillon, Antoni Viros i Martin, Kaoutar El Maghraoui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07311">https://arxiv.org/abs/2506.07311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07311">https://arxiv.org/pdf/2506.07311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07311]] Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference(https://arxiv.org/abs/2506.07311)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) encounter severe memory inefficiencies during long-context inference due to conventional handling of key-value (KV) caches. In this work, we introduce a novel integration of PagedAttention with PyTorch's FlexAttention, addressing internal fragmentation and inefficiencies associated with monolithic KV cache allocations. Implemented within IBM's Foundation Model Stack (FMS), our fused attention kernel efficiently gathers scattered KV data. Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reduced inference latency, growing only linearly (~2x) with sequence length from 128 to 2048 tokens when utilizing a global KV cache, compared to exponential latency increases without caching. While peak memory usage remains largely unchanged for single-step evaluations (dominated by model weights and activations), paged attention causes minimal incremental memory usage, observable only at sequence lengths exceeding 2048 tokens due to its power-of-two cache allocations. We open-source the full implementation and discuss its implications for future long-context model deployment.</li>
</ul>

<h3>Title: Generative Modeling of Networked Time-Series via Transformer Architectures</h3>
<ul>
<li><strong>Authors: </strong>Yusuf Elnady</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07312">https://arxiv.org/abs/2506.07312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07312">https://arxiv.org/pdf/2506.07312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07312]] Generative Modeling of Networked Time-Series via Transformer Architectures(https://arxiv.org/abs/2506.07312)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer, generative</a></li>
<li><strong>Abstract: </strong>Many security and network applications require having large datasets to train the machine learning models. Limited data access is a well-known problem in the security domain. Recent studies have shown the potential of Transformer models to enlarge the size of data by synthesizing new samples, but the synthesized samples don't improve the models over the real data. To address this issue, we design an efficient transformer-based model as a generative framework to generate time-series data, that can be used to boost the performance of existing and new ML workflows. Our new transformer model achieves the SOTA results. We style our model to be generalizable and work across different datasets, and produce high-quality samples.</li>
</ul>

<h3>Title: SCGAgent: Recreating the Benefits of Reasoning Models for Secure Code Generation with Agentic Workflows</h3>
<ul>
<li><strong>Authors: </strong>Rebecca Saul, Hao Wang, Koushik Sen, David Wagner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07313">https://arxiv.org/abs/2506.07313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07313">https://arxiv.org/pdf/2506.07313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07313]] SCGAgent: Recreating the Benefits of Reasoning Models for Secure Code Generation with Agentic Workflows(https://arxiv.org/abs/2506.07313)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have seen widespread success in code generation tasks for different scenarios, both everyday and professional. However current LLMs, despite producing functional code, do not prioritize security and may generate code with exploitable vulnerabilities. In this work, we propose techniques for generating code that is more likely to be secure and introduce SCGAgent, a proactive secure coding agent that implements our techniques. We use security coding guidelines that articulate safe programming practices, combined with LLM-generated unit tests to preserve functional correctness. In our evaluation, we find that SCGAgent is able to preserve nearly 98% of the functionality of the base Sonnet-3.7 LLM while achieving an approximately 25% improvement in security. Moreover, SCGAgent is able to match or best the performance of sophisticated reasoning LLMs using a non-reasoning model and an agentic workflow.</li>
</ul>

<h3>Title: DEF: Diffusion-augmented Ensemble Forecasting</h3>
<ul>
<li><strong>Authors: </strong>David Millard, Arielle Carr, Stéphane Gaudreault, Ali Baheri</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07324">https://arxiv.org/abs/2506.07324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07324">https://arxiv.org/pdf/2506.07324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07324]] DEF: Diffusion-augmented Ensemble Forecasting(https://arxiv.org/abs/2506.07324)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present DEF (\textbf{\ul{D}}iffusion-augmented \textbf{\ul{E}}nsemble \textbf{\ul{F}}orecasting), a novel approach for generating initial condition perturbations. Modern approaches to initial condition perturbations are primarily designed for numerical weather prediction (NWP) solvers, limiting their applicability in the rapidly growing field of machine learning for weather prediction. Consequently, stochastic models in this domain are often developed on a case-by-case basis. We demonstrate that a simple conditional diffusion model can (1) generate meaningful structured perturbations, (2) be applied iteratively, and (3) utilize a guidance term to intuitivey control the level of perturbation. This method enables the transformation of any deterministic neural forecasting system into a stochastic one. With our stochastic extended systems, we show that the model accumulates less error over long-term forecasts while producing meaningful forecast distributions. We validate our approach on the 5.625$^\circ$ ERA5 reanalysis dataset, which comprises atmospheric and surface variables over a discretized global grid, spanning from the 1960s to the present. On this dataset, our method demonstrates improved predictive performance along with reasonable spread estimates.</li>
</ul>

<h3>Title: Reward Model Interpretability via Optimal and Pessimal Tokens</h3>
<ul>
<li><strong>Authors: </strong>Brian Christian, Hannah Rose Kirk, Jessica A.F. Thompson, Christopher Summerfield, Tsvetomira Dumbalska</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07326">https://arxiv.org/abs/2506.07326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07326">https://arxiv.org/pdf/2506.07326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07326]] Reward Model Interpretability via Optimal and Pessimal Tokens(https://arxiv.org/abs/2506.07326)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Reward modeling has emerged as a crucial component in aligning large language models with human values. Significant attention has focused on using reward models as a means for fine-tuning generative models. However, the reward models themselves -- which directly encode human value judgments by turning prompt-response pairs into scalar rewards -- remain relatively understudied. We present a novel approach to reward model interpretability through exhaustive analysis of their responses across their entire vocabulary space. By examining how different reward models score every possible single-token response to value-laden prompts, we uncover several striking findings: (i) substantial heterogeneity between models trained on similar objectives, (ii) systematic asymmetries in how models encode high- vs low-scoring tokens, (iii) significant sensitivity to prompt framing that mirrors human cognitive biases, and (iv) overvaluation of more frequent tokens. We demonstrate these effects across ten recent open-source reward models of varying parameter counts and architectures. Our results challenge assumptions about the interchangeability of reward models, as well as their suitability as proxies of complex and context-dependent human values. We find that these models can encode concerning biases toward certain identity groups, which may emerge as unintended consequences of harmlessness training -- distortions that risk propagating through the downstream large language models now deployed to millions.</li>
</ul>

<h3>Title: Mobility-Aware Asynchronous Federated Learning with Dynamic Sparsification</h3>
<ul>
<li><strong>Authors: </strong>Jintao Yan, Tan Chen, Yuxuan Sun, Zhaojun Nan, Sheng Zhou, Zhisheng Niu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07328">https://arxiv.org/abs/2506.07328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07328">https://arxiv.org/pdf/2506.07328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07328]] Mobility-Aware Asynchronous Federated Learning with Dynamic Sparsification(https://arxiv.org/abs/2506.07328)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Asynchronous Federated Learning (AFL) enables distributed model training across multiple mobile devices, allowing each device to independently update its local model without waiting for others. However, device mobility introduces intermittent connectivity, which necessitates gradient sparsification and leads to model staleness, jointly affecting AFL convergence. This paper develops a theoretical model to characterize the interplay among sparsification, model staleness and mobility-induced contact patterns, and their joint impact on AFL convergence. Based on the analysis, we propose a mobility-aware dynamic sparsification (MADS) algorithm that optimizes the sparsification degree based on contact time and model staleness. Closed-form solutions are derived, showing that under low-speed conditions, MADS increases the sparsification degree to enhance convergence, while under high-speed conditions, it reduces the sparsification degree to guarantee reliable uploads within limited contact time. Experimental results validate the theoretical findings. Compared with the state-of-the-art benchmarks, the MADS algorithm increases the image classification accuracy on the CIFAR-10 dataset by 8.76% and reduces the average displacement error in the Argoverse trajectory prediction dataset by 9.46%.</li>
</ul>

<h3>Title: JavelinGuard: Low-Cost Transformer Architectures for LLM Security</h3>
<ul>
<li><strong>Authors: </strong>Yash Datta, Sharath Rajasekar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07330">https://arxiv.org/abs/2506.07330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07330">https://arxiv.org/pdf/2506.07330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07330]] JavelinGuard: Low-Cost Transformer Architectures for LLM Security(https://arxiv.org/abs/2506.07330)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>We present JavelinGuard, a suite of low-cost, high-performance model architectures designed for detecting malicious intent in Large Language Model (LLM) interactions, optimized specifically for production deployment. Recent advances in transformer architectures, including compact BERT(Devlin et al. 2019) variants (e.g., ModernBERT (Warner et al. 2024)), allow us to build highly accurate classifiers with as few as approximately 400M parameters that achieve rapid inference speeds even on standard CPU hardware. We systematically explore five progressively sophisticated transformer-based architectures: Sharanga (baseline transformer classifier), Mahendra (enhanced attention-weighted pooling with deeper heads), Vaishnava and Ashwina (hybrid neural ensemble architectures), and Raudra (an advanced multi-task framework with specialized loss functions). Our models are rigorously benchmarked across nine diverse adversarial datasets, including popular sets like the NotInject series, BIPIA, Garak, ImprovedLLM, ToxicChat, WildGuard, and our newly introduced JavelinBench, specifically crafted to test generalization on challenging borderline and hard-negative cases. Additionally, we compare our architectures against leading open-source guardrail models as well as large decoder-only LLMs such as gpt-4o, demonstrating superior cost-performance trade-offs in terms of accuracy, and latency. Our findings reveal that while Raudra's multi-task design offers the most robust performance overall, each architecture presents unique trade-offs in speed, interpretability, and resource requirements, guiding practitioners in selecting the optimal balance of complexity and efficiency for real-world LLM security applications.</li>
</ul>

<h3>Title: Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Wang, Peihao Wang, Mufei Li, Shikun Liu, Siqi Miao, Zhangyang Wang, Pan Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07334">https://arxiv.org/abs/2506.07334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07334">https://arxiv.org/pdf/2506.07334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07334]] Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models(https://arxiv.org/abs/2506.07334)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern large language models (LLMs) are inherently auto-regressive, requiring input to be serialized into flat sequences regardless of their structural dependencies. This serialization hinders the model's ability to leverage structural inductive biases, especially in tasks such as retrieval-augmented generation (RAG) and reasoning on data with native graph structures, where inter-segment dependencies are crucial. We introduce Graph-KV with the potential to overcome this limitation. Graph-KV leverages the KV-cache of text segments as condensed representations and governs their interaction through structural inductive biases. In this framework, 'target' segments selectively attend only to the KV-caches of their designated 'source' segments, rather than all preceding segments in a serialized sequence. This approach induces a graph-structured block mask, sparsifying attention and enabling a message-passing-like step within the LLM. Furthermore, strategically allocated positional encodings for source and target segments reduce positional bias and context window consumption. We evaluate Graph-KV across three scenarios: (1) seven RAG benchmarks spanning direct inference, multi-hop reasoning, and long-document understanding; (2) Arxiv-QA, a novel academic paper QA task with full-text scientific papers structured as citation ego-graphs; and (3) paper topic classification within a citation network. By effectively reducing positional bias and harnessing structural inductive biases, Graph-KV substantially outperforms baselines, including standard costly sequential encoding, across various settings. Code and the Graph-KV data are publicly available.</li>
</ul>

<h3>Title: Improving LLM Reasoning through Interpretable Role-Playing Steering</h3>
<ul>
<li><strong>Authors: </strong>Anyi Wang, Dong Shu, Yifan Wang, Yunpu Ma, Mengnan Du</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07335">https://arxiv.org/abs/2506.07335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07335">https://arxiv.org/pdf/2506.07335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07335]] Improving LLM Reasoning through Interpretable Role-Playing Steering(https://arxiv.org/abs/2506.07335)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Role-playing has emerged as an effective technique for enhancing the reasoning capabilities of large language models (LLMs). However, existing methods primarily rely on prompt engineering, which often lacks stability and interpretability. In this paper, we introduce Sparse Autoencoder Role-Playing Steering (SRPS), a novel framework that identifies and manipulates internal model features associated with role-playing behavior. Our approach extracts latent representations from role-play prompts, selects the most relevant features based on activation patterns, and constructs a steering vector that can be injected into the model's residual stream with controllable intensity. Our method enables fine-grained control over role-specific behavior and offers insights into how role information influences internal model activations. Extensive experiments across various reasoning benchmarks and model sizes demonstrate consistent performance gains. Notably, in the zero-shot chain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves from 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to 45.10%. These results highlight the potential of SRPS to enhance reasoning ability in LLMs, providing better interpretability and stability compared to traditional prompt-based role-playing.</li>
</ul>

<h3>Title: SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments</h3>
<ul>
<li><strong>Authors: </strong>Yuya Okada, Takayuki Nishio</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07355">https://arxiv.org/abs/2506.07355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07355">https://arxiv.org/pdf/2506.07355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07355]] SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments(https://arxiv.org/abs/2506.07355)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose SALT (Split-Adaptive Lightweight Tuning), a lightweight model adaptation framework for Split Computing under closed constraints, where the head and tail networks are proprietary and inaccessible to users. In such closed environments, conventional adaptation methods are infeasible since they require access to model parameters or architectures. SALT addresses this challenge by introducing a compact, trainable adapter on the client side to refine latent features from the head network, enabling user-specific adaptation without modifying the original models or increasing communication overhead. We evaluate SALT on user-specific classification tasks with CIFAR-10 and CIFAR-100, demonstrating improved accuracy with lower training latency compared to fine-tuning methods. Furthermore, SALT facilitates model adaptation for robust inference over lossy networks, a common challenge in edge-cloud environments. With minimal deployment overhead, SALT offers a practical solution for personalized inference in edge AI systems under strict system constraints.</li>
</ul>

<h3>Title: Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation</h3>
<ul>
<li><strong>Authors: </strong>Seokil Ham, Yubin Choi, Seungju Cho, Yujin Yang, Younghun Kim, Changick Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07356">https://arxiv.org/abs/2506.07356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07356">https://arxiv.org/pdf/2506.07356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07356]] Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation(https://arxiv.org/abs/2506.07356)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, large language model</a></li>
<li><strong>Abstract: </strong>Recently, major AI service providers such as Google and OpenAI have introduced Finetuning-as-a-Service, which enables users to customize Large Language Models (LLMs) for specific downstream tasks using their own data. However, this service is vulnerable to degradation of LLM safety-alignment when user data contains harmful prompts. While some prior works address this issue, fundamentally filtering harmful data from user data remains unexplored. Motivated by our observation that a directional representation reflecting refusal behavior (called the refusal feature) obtained from safety-aligned LLMs can inherently distinguish between harmful and harmless prompts, we propose the Refusal-Feature-guided Teacher (ReFT). Our ReFT model is trained to identify harmful prompts based on the similarity between input prompt features and its refusal feature. During finetuning, the ReFT model serves as a teacher that filters harmful prompts from user data and distills alignment knowledge into the base model. Extensive experiments demonstrate that our ReFT-based finetuning strategy effectively minimizes harmful outputs and enhances finetuning accuracy for user-specific tasks, offering a practical solution for secure and reliable deployment of LLMs in Finetuning-as-a-Service.</li>
</ul>

<h3>Title: CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms</h3>
<ul>
<li><strong>Authors: </strong>Satvik Praveen, Yoonsung Jung</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07357">https://arxiv.org/abs/2506.07357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07357">https://arxiv.org/pdf/2506.07357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07357]] CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms(https://arxiv.org/abs/2506.07357)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Object detection is vital in precision agriculture for plant monitoring, disease detection, and yield estimation. However, models like YOLO struggle with occlusions, irregular structures, and background noise, reducing detection accuracy. While Spatial Transformer Networks (STNs) improve spatial invariance through learned transformations, affine mappings are insufficient for non-rigid deformations such as bent leaves and overlaps. We propose CBAM-STN-TPS-YOLO, a model integrating Thin-Plate Splines (TPS) into STNs for flexible, non-rigid spatial transformations that better align features. Performance is further enhanced by the Convolutional Block Attention Module (CBAM), which suppresses background noise and emphasizes relevant spatial and channel-wise features. On the occlusion-heavy Plant Growth and Phenotyping (PGP) dataset, our model outperforms STN-YOLO in precision, recall, and mAP. It achieves a 12% reduction in false positives, highlighting the benefits of improved spatial flexibility and attention-guided refinement. We also examine the impact of the TPS regularization parameter in balancing transformation smoothness and detection performance. This lightweight model improves spatial awareness and supports real-time edge deployment, making it ideal for smart farming applications requiring accurate and efficient monitoring.</li>
</ul>

<h3>Title: Multiple Object Stitching for Unsupervised Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Chengchao Shen, Dawei Liu, Jianxin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07364">https://arxiv.org/abs/2506.07364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07364">https://arxiv.org/pdf/2506.07364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07364]] Multiple Object Stitching for Unsupervised Representation Learning(https://arxiv.org/abs/2506.07364)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Contrastive learning for single object centric images has achieved remarkable progress on unsupervised representation, but suffering inferior performance on the widespread images with multiple objects. In this paper, we propose a simple but effective method, Multiple Object Stitching (MOS), to refine the unsupervised representation for multi-object images. Specifically, we construct the multi-object images by stitching the single object centric ones, where the objects in the synthesized multi-object images are predetermined. Hence, compared to the existing contrastive methods, our method provides additional object correspondences between multi-object images without human annotations. In this manner, our method pays more attention to the representations of each object in multi-object image, thus providing more detailed representations for complicated downstream tasks, such as object detection and semantic segmentation. Experimental results on ImageNet, CIFAR and COCO datasets demonstrate that our proposed method achieves the leading unsupervised representation performance on both single object centric images and multi-object ones. The source code is available at this https URL.</li>
</ul>

<h3>Title: C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiaying He, Yitong Lin, Jiahe Chen, Honghui Xu, Jianwei Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07368">https://arxiv.org/abs/2506.07368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07368">https://arxiv.org/pdf/2506.07368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07368]] C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2506.07368)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>For the immanent challenge of insufficiently annotated samples in the medical field, semi-supervised medical image segmentation (SSMIS) offers a promising solution. Despite achieving impressive results in delineating primary target areas, most current methodologies struggle to precisely capture the subtle details of boundaries. This deficiency often leads to significant diagnostic inaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised segmentation model that synergistically integrates complementary competition and contrastive selection. This design significantly sharpens boundary delineation and enhances overall precision. Specifically, we develop an $\textit{Outcome-Driven Contrastive Learning}$ module dedicated to refining boundary localization. Additionally, we incorporate a $\textit{Dynamic Complementary Competition}$ module that leverages two high-performing sub-networks to generate pseudo-labels, thereby further improving segmentation quality. The proposed C3S3 undergoes rigorous validation on two publicly accessible datasets, encompassing the practices of both MRI and CT scans. The results demonstrate that our method achieves superior performance compared to previous cutting-edge competitors. Especially, on the 95HD and ASD metrics, our approach achieves a notable improvement of at least $6\%$, highlighting the significant advancements. The code is available at this https URL.</li>
</ul>

<h3>Title: Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding</h3>
<ul>
<li><strong>Authors: </strong>Bolin Chen, Shanzhi Yin, Goluck Konuko, Giuseppe Valenzise, Zihan Zhang, Shiqi Wang, Yan Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07369">https://arxiv.org/abs/2506.07369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07369">https://arxiv.org/pdf/2506.07369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07369]] Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding(https://arxiv.org/abs/2506.07369)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rise of deep generative models has greatly advanced video compression, reshaping the paradigm of face video coding through their powerful capability for semantic-aware representation and lifelike synthesis. Generative Face Video Coding (GFVC) stands at the forefront of this revolution, which could characterize complex facial dynamics into compact latent codes for bitstream compactness at the encoder side and leverages powerful deep generative models to reconstruct high-fidelity face signal from the compressed latent codes at the decoder side. As such, this well-designed GFVC paradigm could enable high-fidelity face video communication at ultra-low bitrate ranges, far surpassing the capabilities of the latest Versatile Video Coding (VVC) standard. To pioneer foundational research and accelerate the evolution of GFVC, this paper presents the first comprehensive survey of GFVC technologies, systematically bridging critical gaps between theoretical innovation and industrial standardization. In particular, we first review a broad range of existing GFVC methods with different feature representations and optimization strategies, and conduct a thorough benchmarking analysis. In addition, we construct a large-scale GFVC-compressed face video database with subjective Mean Opinion Scores (MOSs) based on human perception, aiming to identify the most appropriate quality metrics tailored to GFVC. Moreover, we summarize the GFVC standardization potentials with a unified high-level syntax and develop a low-complexity GFVC system which are both expected to push forward future practical deployments and applications. Finally, we envision the potential of GFVC in industrial applications and deliberate on the current challenges and future opportunities.</li>
</ul>

<h3>Title: ARGUS: Hallucination and Omission Evaluation in Video-LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruchit Rawal, Reza Shirkavand, Heng Huang, Gowthami Somepalli, Tom Goldstein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07371">https://arxiv.org/abs/2506.07371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07371">https://arxiv.org/pdf/2506.07371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07371]] ARGUS: Hallucination and Omission Evaluation in Video-LLMs(https://arxiv.org/abs/2506.07371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video large language models have not yet been widely deployed, largely due to their tendency to hallucinate. Typical benchmarks for Video-LLMs rely simply on multiple-choice questions. Unfortunately, VideoLLMs hallucinate far more aggressively on freeform text generation tasks like video captioning than they do on multiple choice verification tasks. To address this weakness, we propose ARGUS, a VideoLLM benchmark that measures freeform video captioning performance. By comparing VideoLLM outputs to human ground truth captions, ARGUS quantifies dual metrics. First, we measure the rate of hallucinations in the form of incorrect statements about video content or temporal relationships. Second, we measure the rate at which the model omits important descriptive details. Together, these dual metrics form a comprehensive view of video captioning performance.</li>
</ul>

<h3>Title: Enhanced Consistency Bi-directional GAN(CBiGAN) for Malware Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Thesath Wijayasiri, Kar Wai Fok, Vrizlynn L. L. Thing</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07372">https://arxiv.org/abs/2506.07372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07372">https://arxiv.org/pdf/2506.07372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07372]] Enhanced Consistency Bi-directional GAN(CBiGAN) for Malware Anomaly Detection(https://arxiv.org/abs/2506.07372)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Static analysis, a cornerstone technique in cybersecurity, offers a noninvasive method for detecting malware by analyzing dormant software without executing potentially harmful code. However, traditional static analysis often relies on biased or outdated datasets, leading to gaps in detection capabilities against emerging malware threats. To address this, our study focuses on the binary content of files as key features for malware detection. These binary contents are transformed and represented as images, which then serve as inputs to deep learning models. This method takes into account the visual patterns within the binary data, allowing the model to analyze potential malware effectively. This paper introduces the application of the CBiGAN in the domain of malware anomaly detection. Our approach leverages the CBiGAN for its superior latent space mapping capabilities, critical for modeling complex malware patterns by utilizing a reconstruction error-based anomaly detection method. We utilized several datasets including both portable executable (PE) files as well as Object Linking and Embedding (OLE) files. We then evaluated our model against a diverse set of both PE and OLE files, including self-collected malicious executables from 214 malware families. Our findings demonstrate the robustness of this innovative approach, with the CBiGAN achieving high Area Under the Curve (AUC) results with good generalizability, thereby confirming its capability to distinguish between benign and diverse malicious files with reasonably high accuracy.</li>
</ul>

<h3>Title: DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Xunjie He, Christina Dao Wen Lee, Meiling Wang, Chengran Yuan, Zefan Huang, Yufeng Yue, Marcelo H. Ang Jr</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07375">https://arxiv.org/abs/2506.07375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07375">https://arxiv.org/pdf/2506.07375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07375]] DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models(https://arxiv.org/abs/2506.07375)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Collaborative perception plays a crucial role in enhancing environmental understanding by expanding the perceptual range and improving robustness against sensor failures, which primarily involves collaborative 3D detection and tracking tasks. The former focuses on object recognition in individual frames, while the latter captures continuous instance tracklets over time. However, existing works in both areas predominantly focus on the vehicle superclass, lacking effective solutions for both multi-class collaborative detection and tracking. This limitation hinders their applicability in real-world scenarios, which involve diverse object classes with varying appearances and motion patterns. To overcome these limitations, we propose a multi-class collaborative detection and tracking framework tailored for diverse road users. We first present a detector with a global spatial attention fusion (GSAF) module, enhancing multi-scale feature learning for objects of varying sizes. Next, we introduce a tracklet RE-IDentification (REID) module that leverages visual semantics with a vision foundation model to effectively reduce ID SWitch (IDSW) errors, in cases of erroneous mismatches involving small objects like pedestrians. We further design a velocity-based adaptive tracklet management (VATM) module that adjusts the tracking interval dynamically based on object motion. Extensive experiments on the V2X-Real and OPV2V datasets show that our approach significantly outperforms existing state-of-the-art methods in both detection and tracking accuracy.</li>
</ul>

<h3>Title: Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jintao Tong, Ran Ma, Yixiong Zou, Guangyao Chen, Yuhua Li, Ruixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07376">https://arxiv.org/abs/2506.07376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07376">https://arxiv.org/pdf/2506.07376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07376]] Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation(https://arxiv.org/abs/2506.07376)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Cross-domain few-shot segmentation (CD-FSS) is proposed to pre-train the model on a source-domain dataset with sufficient samples, and then transfer the model to target-domain datasets where only a few samples are available for efficient fine-tuning. There are majorly two challenges in this task: (1) the domain gap and (2) fine-tuning with scarce data. To solve these challenges, we revisit the adapter-based methods, and discover an intriguing insight not explored in previous works: the adapter not only helps the fine-tuning of downstream tasks but also naturally serves as a domain information decoupler. Then, we delve into this finding for an interpretation, and find the model's inherent structure could lead to a natural decoupling of domain information. Building upon this insight, we propose the Domain Feature Navigator (DFN), which is a structure-based decoupler instead of loss-based ones like current works, to capture domain-specific information, thereby directing the model's attention towards domain-agnostic knowledge. Moreover, to prevent the potential excessive overfitting of DFN during the source-domain training, we further design the SAM-SVN method to constrain DFN from learning sample-specific knowledge. On target domains, we freeze the model and fine-tune the DFN to learn target-specific knowledge specific. Extensive experiments demonstrate that our method surpasses the state-of-the-art method in CD-FSS significantly by 2.69% and 4.68% MIoU in 1-shot and 5-shot scenarios, respectively.</li>
</ul>

<h3>Title: From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks</h3>
<ul>
<li><strong>Authors: </strong>Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Tian Qin, Yuyu Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07392">https://arxiv.org/abs/2506.07392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07392">https://arxiv.org/pdf/2506.07392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07392]] From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks(https://arxiv.org/abs/2506.07392)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>The proliferation of unmanned aerial vehicle (UAV) swarms has enabled a wide range of mission-critical applications, but also exposes UAV networks to severe Denial-of-Service (DoS) threats due to their open wireless environment, dynamic topology, and resource constraints. Traditional static or centralized defense mechanisms are often inadequate for such dynamic and distributed scenarios. To address these challenges, we propose a novel federated multi-agent deep reinforcement learning (FMADRL)-driven moving target defense (MTD) framework for proactive and adaptive DoS mitigation in UAV swarm networks. Specifically, we design three lightweight and coordinated MTD mechanisms, including leader switching, route mutation, and frequency hopping, that leverage the inherent flexibility of UAV swarms to disrupt attacker efforts and enhance network resilience. The defense problem is formulated as a multi-agent partially observable Markov decision process (POMDP), capturing the distributed, resource-constrained, and uncertain nature of UAV swarms under attack. Each UAV is equipped with a local policy agent that autonomously selects MTD actions based on partial observations and local experiences. By employing a policy gradient-based FMADRL algorithm, UAVs collaboratively optimize their defense policies via reward-weighted aggregation, enabling distributed learning without sharing raw data and thus reducing communication overhead. Extensive simulations demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving up to a 34.6% improvement in attack mitigation rate, a reduction in average recovery time of up to 94.6%, and decreases in energy consumption and defense cost by as much as 29.3% and 98.3%, respectively, while maintaining robust mission continuity under various DoS attack strategies.</li>
</ul>

<h3>Title: MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems</h3>
<ul>
<li><strong>Authors: </strong>Peiru Yang, Jinhua Yin, Haoran Zheng, Xueying Bai, Huili Wang, Yufei Sun, Xintian Li, Shangguang Wang, Yongfeng Huang, Tao Qi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07399">https://arxiv.org/abs/2506.07399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07399">https://arxiv.org/pdf/2506.07399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07399]] MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems(https://arxiv.org/abs/2506.07399)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, attack, robust, membership infer</a></li>
<li><strong>Abstract: </strong>Multimodal retrieval-augmented generation (RAG) systems enhance large vision-language models by integrating cross-modal knowledge, enabling their increasing adoption across real-world multimodal tasks. These knowledge databases may contain sensitive information that requires privacy protection. However, multimodal RAG systems inherently grant external users indirect access to such data, making them potentially vulnerable to privacy attacks, particularly membership inference attacks (MIAs). % Existing MIA methods targeting RAG systems predominantly focus on the textual modality, while the visual modality remains relatively underexplored. To bridge this gap, we propose MrM, the first black-box MIA framework targeted at multimodal RAG systems. It utilizes a multi-object data perturbation framework constrained by counterfactual attacks, which can concurrently induce the RAG systems to retrieve the target data and generate information that leaks the membership information. Our method first employs an object-aware data perturbation method to constrain the perturbation to key semantics and ensure successful retrieval. Building on this, we design a counterfact-informed mask selection strategy to prioritize the most informative masked regions, aiming to eliminate the interference of model self-knowledge and amplify attack efficacy. Finally, we perform statistical membership inference by modeling query trials to extract features that reflect the reconstruction of masked semantics from response patterns. Experiments on two visual datasets and eight mainstream commercial visual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves consistently strong performance across both sample-level and set-level evaluations, and remains robust under adaptive defenses.</li>
</ul>

<h3>Title: Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures</h3>
<ul>
<li><strong>Authors: </strong>Yukai Zhou, Sibei Yang, Wenjie Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07402">https://arxiv.org/abs/2506.07402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07402">https://arxiv.org/pdf/2506.07402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07402]] Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures(https://arxiv.org/abs/2506.07402)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in real-world applications, raising concerns about their security. While jailbreak attacks highlight failures under overtly harmful queries, they overlook a critical risk: incorrectly answering harmless-looking inputs can be dangerous and cause real-world harm (Implicit Harm). We systematically reformulate the LLM risk landscape through a structured quadrant perspective based on output factuality and input harmlessness, uncovering an overlooked high-risk region. To investigate this gap, we propose JailFlipBench, a benchmark aims to capture implicit harm, spanning single-modal, multimodal, and factual extension scenarios with diverse evaluation metrics. We further develop initial JailFlip attack methodologies and conduct comprehensive evaluations across multiple open-source and black-box LLMs, show that implicit harm present immediate and urgent real-world risks, calling for broader LLM safety assessments and alignment beyond conventional jailbreak paradigms.</li>
</ul>

<h3>Title: Enhancing Watermarking Quality for LLMs via Contextual Generation States Awareness</h3>
<ul>
<li><strong>Authors: </strong>Peiru Yang, Xintian Li, Wanchun Ni, Jinhua Yin, Huili Wang, Guoshun Nan, Shangguang Wang, Yongfeng Huang, Tao Qi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07403">https://arxiv.org/abs/2506.07403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07403">https://arxiv.org/pdf/2506.07403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07403]] Enhancing Watermarking Quality for LLMs via Contextual Generation States Awareness(https://arxiv.org/abs/2506.07403)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in watermarking techniques have enabled the embedding of secret messages into AI-generated text (AIGT), serving as an important mechanism for AIGT detection. Existing methods typically interfere with the generation processes of large language models (LLMs) to embed signals within the generated text. However, these methods often rely on heuristic rules, which can result in suboptimal token selection and a subsequent decline in the quality of the generated content. In this paper, we introduce a plug-and-play contextual generation states-aware watermarking framework (CAW) that dynamically adjusts the embedding process. It can be seamlessly integrated with various existing watermarking methods to enhance generation quality. First, CAW incorporates a watermarking capacity evaluator, which can assess the impact of embedding messages at different token positions by analyzing the contextual generation states. Furthermore, we introduce a multi-branch pre-generation mechanism to avoid the latency caused by the proposed watermarking strategy. Building on this, CAW can dynamically adjust the watermarking process based on the evaluated watermark capacity of each token, thereby minimizing potential degradation in content quality. Extensive experiments conducted on datasets across multiple domains have verified the effectiveness of our method, demonstrating superior performance compared to various baselines in terms of both detection rate and generation quality.</li>
</ul>

<h3>Title: Pixel-Sensitive and Robust Steganography Based on Polar Codes</h3>
<ul>
<li><strong>Authors: </strong>Yujun Ji, Jinsheng Li, Ling Liu, Qi Cao, Tao Dai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07404">https://arxiv.org/abs/2506.07404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07404">https://arxiv.org/pdf/2506.07404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07404]] Pixel-Sensitive and Robust Steganography Based on Polar Codes(https://arxiv.org/abs/2506.07404)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Steganography is an information hiding technique for covert communication. The core issue in steganography design is the rate-distortion coding problem. Polar codes, which have been proven to achieve the rate-distortion bound for any binary symmetric source, are utilized to design a steganographic scheme that can reach the embedding capacity for the Distortion-Limited Sender problem in certain cases. In adaptive steganography, for attack scenarios where each noise element can have different intensities, existing steganographic coding methods fail to resist such attacks. In this paper, we propose a pixel-sensitive and robust steganographic scheme based on polar codes. Our steganographic scheme not only matches the adaptive distortion well but is also robust against sophisticated noise attacks. Futher, it is proven that our scheme achieves the embedding capacity in certain cases. Experimentally, a steganographic scheme can be designed and implemented with a secret message error rate at the $10^{-5}$ level when the attack noise is known to both the sender and the receiver. This demonstrates its significant robustness.</li>
</ul>

<h3>Title: RiemannFormer: A Framework for Attention in Curved Spaces</h3>
<ul>
<li><strong>Authors: </strong>Zhongping Ji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07405">https://arxiv.org/abs/2506.07405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07405">https://arxiv.org/pdf/2506.07405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07405]] RiemannFormer: A Framework for Attention in Curved Spaces(https://arxiv.org/abs/2506.07405)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This research endeavors to offer insights into unlocking the further potential of transformer-based architectures. One of the primary motivations is to offer a geometric interpretation for the attention mechanism in transformers. In our framework, the attention mainly involves metric tensors, tangent spaces, inner product, and how they relate to each other. These quantities and structures at discrete positions are intricately interconnected via the parallel transport of tangent vectors. To make the learning process more efficient, we reduce the number of parameters through ingenious predefined configurations. Moreover, we introduce an explicit mechanism to highlight a neighborhood by attenuating the remote values, given that transformers inherently neglect local inductive bias. Experimental results demonstrate that our modules deliver significant performance improvements relative to the baseline. More evaluation experiments on visual and large language models will be launched successively.</li>
</ul>

<h3>Title: InverseScope: Scalable Activation Inversion for Interpreting Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yifan Luo, Zhennan Zhou, Bin Dong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07406">https://arxiv.org/abs/2506.07406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07406">https://arxiv.org/pdf/2506.07406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07406]] InverseScope: Scalable Activation Inversion for Interpreting Large Language Models(https://arxiv.org/abs/2506.07406)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Understanding the internal representations of large language models (LLMs) is a central challenge in interpretability research. Existing feature interpretability methods often rely on strong assumptions about the structure of representations that may not hold in practice. In this work, we introduce InverseScope, an assumption-light and scalable framework for interpreting neural activations via input inversion. Given a target activation, we define a distribution over inputs that generate similar activations and analyze this distribution to infer the encoded features. To address the inefficiency of sampling in high-dimensional spaces, we propose a novel conditional generation architecture that significantly improves sample efficiency compared to previous methods. We further introduce a quantitative evaluation protocol that tests interpretability hypotheses using feature consistency rate computed over the sampled inputs. InverseScope scales inversion-based interpretability methods to larger models and practical tasks, enabling systematic and quantitative analysis of internal representations in real-world LLMs.</li>
</ul>

<h3>Title: Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM</h3>
<ul>
<li><strong>Authors: </strong>Yihong Jin, Ze Yang, Juntian Liu, Xinhe Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07407">https://arxiv.org/abs/2506.07407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07407">https://arxiv.org/pdf/2506.07407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07407]] Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM(https://arxiv.org/abs/2506.07407)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>With the rapid development of multi-cloud environments, it is increasingly important to ensure the security and reliability of intelligent monitoring systems. In this paper, we propose an anomaly detection and early warning mechanism for intelligent monitoring system in multi-cloud environment based on Large-Scale Language Model (LLM). On the basis of the existing monitoring framework, the proposed model innovatively introduces a multi-level feature extraction method, which combines the natural language processing ability of LLM with traditional machine learning methods to enhance the accuracy of anomaly detection and improve the real-time response efficiency. By introducing the contextual understanding capabilities of LLMs, the model dynamically adapts to different cloud service providers and environments, so as to more effectively detect abnormal patterns and predict potential failures. Experimental results show that the proposed model is significantly better than the traditional anomaly detection system in terms of detection accuracy and latency, and significantly improves the resilience and active management ability of cloud infrastructure.</li>
</ul>

<h3>Title: Variational Supervised Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziwen Wang, Jiajun Fan, Thao Nguyen, Heng Ji, Ge Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07413">https://arxiv.org/abs/2506.07413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07413">https://arxiv.org/pdf/2506.07413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07413]] Variational Supervised Contrastive Learning(https://arxiv.org/abs/2506.07413)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Contrastive learning has proven to be highly efficient and adaptable in shaping representation spaces across diverse modalities by pulling similar samples together and pushing dissimilar ones apart. However, two key limitations persist: (1) Without explicit regulation of the embedding distribution, semantically related instances can inadvertently be pushed apart unless complementary signals guide pair selection, and (2) excessive reliance on large in-batch negatives and tailored augmentations hinders generalization. To address these limitations, we propose Variational Supervised Contrastive Learning (VarCon), which reformulates supervised contrastive learning as variational inference over latent class variables and maximizes a posterior-weighted evidence lower bound (ELBO) that replaces exhaustive pair-wise comparisons for efficient class-aware matching and grants fine-grained control over intra-class dispersion in the embedding space. Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art performance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy on ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while converging in just 200 epochs; (2) yields substantially clearer decision boundaries and semantic organization in the embedding space, as evidenced by KNN classification, hierarchical clustering results, and transfer-learning assessments; and (3) demonstrates superior performance in few-shot learning than supervised baseline and superior robustness across various augmentation strategies.</li>
</ul>

<h3>Title: DPFormer: Dynamic Prompt Transformer for Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Sheng-Kai Huang, Jiun-Feng Chang, Chun-Rong Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07414">https://arxiv.org/abs/2506.07414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07414">https://arxiv.org/pdf/2506.07414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07414]] DPFormer: Dynamic Prompt Transformer for Continual Learning(https://arxiv.org/abs/2506.07414)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In continual learning, solving the catastrophic forgetting problem may make the models fall into the stability-plasticity dilemma. Moreover, inter-task confusion will also occur due to the lack of knowledge exchanges between different tasks. In order to solve the aforementioned problems, we propose a novel dynamic prompt transformer (DPFormer) with prompt schemes. The prompt schemes help the DPFormer memorize learned knowledge of previous classes and tasks, and keep on learning new knowledge from new classes and tasks under a single network structure with a nearly fixed number of model parameters. Moreover, they also provide discrepant information to represent different tasks to solve the inter-task confusion problem. Based on prompt schemes, a unified classification module with the binary cross entropy loss, the knowledge distillation loss and the auxiliary loss is proposed to train the whole model in an end-to-end trainable manner. Compared with state-of-the-art methods, our method achieves the best performance in the CIFAR-100, ImageNet100 and ImageNet1K datasets under different class-incremental settings in continual learning. The source code will be available at our GitHub after acceptance.</li>
</ul>

<h3>Title: Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs</h3>
<ul>
<li><strong>Authors: </strong>Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07417">https://arxiv.org/abs/2506.07417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07417">https://arxiv.org/pdf/2506.07417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07417]] Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs(https://arxiv.org/abs/2506.07417)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-aware augmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.</li>
</ul>

<h3>Title: SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation</h3>
<ul>
<li><strong>Authors: </strong>Janghyeon Yun, Sang-goo Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07423">https://arxiv.org/abs/2506.07423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07423">https://arxiv.org/pdf/2506.07423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07423]] SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation(https://arxiv.org/abs/2506.07423)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Text-to-SQL enables non-experts to retrieve data from databases by converting natural language queries into SQL. However, state-of-the-art text-to-SQL studies rely on the BIRD dataset, which assumes that evidence is provided along with questions. Although BIRD facilitates research advancements, it assumes that users have expertise and domain knowledge, contradicting the fundamental goal of text-to-SQL. In addition, human-generated evidence in BIRD contains defects, including missing or erroneous evidence, which affects model performance. To address this issue, we propose SEED (System for Evidence Extraction and Domain knowledge generation), an approach that automatically generates evidence to improve performance and practical usability in real-world scenarios. SEED systematically analyzes database schema, description files, and values to extract relevant information. We evaluated SEED on BIRD and Spider, demonstrating that it significantly improves SQL generation accuracy in the no-evidence scenario, and in some cases, even outperforms the setting where BIRD evidence is provided. Our results highlight that SEED-generated evidence not only bridges the gap between research and real-world deployment but also improves the adaptability and robustness of text-to-SQL models. Our code is available at this https URL</li>
</ul>

<h3>Title: Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kyeonghyun Kim, Jinhee Jang, Juhwan Choi, Yoonji Lee, Kyohoon Jin, YoungBin Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07424">https://arxiv.org/abs/2506.07424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07424">https://arxiv.org/pdf/2506.07424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07424]] Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models(https://arxiv.org/abs/2506.07424)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are renowned for their extensive linguistic knowledge and strong generalization capabilities, but their high computational demands make them unsuitable for resource-constrained environments. In contrast, small language models (SLMs) are computationally efficient but often lack the broad generalization capacity of LLMs. To bridge this gap, we propose PiFi, a novel framework that combines the strengths of both LLMs and SLMs to achieve high performance while maintaining efficiency. PiFi integrates a single frozen layer from an LLM into a SLM and fine-tunes the combined model for specific tasks, boosting performance without a significant increase in computational cost. We show that PiFi delivers consistent performance improvements across a range of natural language processing tasks, including both natural language understanding and generation. Moreover, our findings demonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing generalization to unseen domains and facilitating the transfer of linguistic abilities.</li>
</ul>

<h3>Title: FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Jie He, Minglang Chen, Minying Lu, Bocheng Liang, Junming Wei, Guiyan Peng, Jiaxi Chen, Ying Tan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07431">https://arxiv.org/abs/2506.07431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07431">https://arxiv.org/pdf/2506.07431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07431]] FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement(https://arxiv.org/abs/2506.07431)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate ultrasound image segmentation is a prerequisite for precise biometrics and accurate assessment. Relying on manual delineation introduces significant errors and is time-consuming. However, existing segmentation models are designed based on objects in natural scenes, making them difficult to adapt to ultrasound objects with high noise and high similarity. This is particularly evident in small object segmentation, where a pronounced jagged effect occurs. Therefore, this paper proposes a fetal femur and cranial ultrasound image segmentation model based on feature perception and Mamba enhancement to address these challenges. Specifically, a longitudinal and transverse independent viewpoint scanning convolution block and a feature perception module were designed to enhance the ability to capture local detail information and improve the fusion of contextual information. Combined with the Mamba-optimized residual structure, this design suppresses the interference of raw noise and enhances local multi-dimensional scanning. The system builds global information and local feature dependencies, and is trained with a combination of different optimizers to achieve the optimal solution. After extensive experimental validation, the FAMSeg network achieved the fastest loss reduction and the best segmentation performance across images of varying sizes and orientations.</li>
</ul>

<h3>Title: Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding</h3>
<ul>
<li><strong>Authors: </strong>Feifan Song, Shaohang Wei, Wen Luo, Yuxuan Fan, Tianyu Liu, Guoyin Wang, Houfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07434">https://arxiv.org/abs/2506.07434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07434">https://arxiv.org/pdf/2506.07434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07434]] Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding(https://arxiv.org/abs/2506.07434)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) require alignment with human preferences to avoid generating offensive, false, or meaningless content. Recently, low-resource methods for LLM alignment have been popular, while still facing challenges in obtaining both high-quality and aligned content. Motivated by the observation that the difficulty of generating aligned responses is concentrated at the beginning of decoding, we propose a novel framework, Weak-to-Strong Decoding (WSD), to enhance the alignment ability of base models by the guidance of a small aligned model. The small model first drafts well-aligned beginnings, followed by the large base model to continue the rest, controlled by a well-designed auto-switch mechanism. We also collect a new dataset, GenerAlign, to fine-tune a small-sized Pilot-3B as the draft model, which effectively enhances different base models under the WSD framework to outperform all baseline methods, while avoiding degradation on downstream tasks, termed as the alignment tax. Extensive experiments are further conducted to examine the impact of different settings and time efficiency, as well as analyses on the intrinsic mechanisms of WSD in depth.</li>
</ul>

<h3>Title: Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition</h3>
<ul>
<li><strong>Authors: </strong>Nishi Chaudhary, S M Jamil Uddin, Sathvik Sharath Chandra, Anto Ovid, Alex Albert</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07436">https://arxiv.org/abs/2506.07436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07436">https://arxiv.org/pdf/2506.07436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07436]] Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition(https://arxiv.org/abs/2506.07436)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>The recent emergence of multimodal large language models (LLMs) has introduced new opportunities for improving visual hazard recognition on construction sites. Unlike traditional computer vision models that rely on domain-specific training and extensive datasets, modern LLMs can interpret and describe complex visual scenes using simple natural language prompts. However, despite growing interest in their applications, there has been limited investigation into how different LLMs perform in safety-critical visual tasks within the construction domain. To address this gap, this study conducts a comparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5, GPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify potential hazards from real-world construction images. Each model was tested under three prompting strategies: zero-shot, few-shot, and chain-of-thought (CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated basic safety context and a hazard source mnemonic, and CoT provided step-by-step reasoning examples to scaffold model thinking. Quantitative analysis was performed using precision, recall, and F1-score metrics across all conditions. Results reveal that prompting strategy significantly influenced performance, with CoT prompting consistently producing higher accuracy across models. Additionally, LLM performance varied under different conditions, with GPT-4.5 and GPT-o3 outperforming others in most settings. The findings also demonstrate the critical role of prompt design in enhancing the accuracy and consistency of multimodal LLMs for construction safety applications. This study offers actionable insights into the integration of prompt engineering and LLMs for practical hazard recognition, contributing to the development of more reliable AI-assisted safety systems.</li>
</ul>

<h3>Title: LG-ANNA-Embedding technical report</h3>
<ul>
<li><strong>Authors: </strong>Jooyoung Choi, Hyun Kim, Hansol Jang, Changwook Jun, Kyunghoon Bae, Hyewon Choi, Stanley Jungkyu Choi, Honglak Lee, Chulmin Yun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07438">https://arxiv.org/abs/2506.07438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07438">https://arxiv.org/pdf/2506.07438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07438]] LG-ANNA-Embedding technical report(https://arxiv.org/abs/2506.07438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This report presents a unified instruction-based framework for learning generalized text embeddings optimized for both information retrieval (IR) and non-IR tasks. Built upon a decoder-only large language model (Mistral-7B), our approach combines in-context learning, soft supervision, and adaptive hard-negative mining to generate context-aware embeddings without task-specific fine-tuning. Structured instructions and few-shot examples are used to guide the model across diverse tasks, enabling strong performance on classification, semantic similarity, clustering, and reranking benchmarks. To improve semantic discrimination, we employ a soft labeling framework where continuous relevance scores, distilled from a high-performance dense retriever and reranker, serve as fine-grained supervision signals. In addition, we introduce adaptive margin-based hard-negative mining, which filters out semantically ambiguous negatives based on their similarity to positive examples, thereby enhancing training stability and retrieval robustness. Our model is evaluated on the newly introduced MTEB (English, v2) benchmark, covering 41 tasks across seven categories. Results show that our method achieves strong generalization and ranks among the top-performing models by Borda score, outperforming several larger or fully fine-tuned baselines. These findings highlight the effectiveness of combining in-context prompting, soft supervision, and adaptive sampling for scalable, high-quality embedding generation.</li>
</ul>

<h3>Title: Federated In-Context Learning: Iterative Refinement for Improved Answer Quality</h3>
<ul>
<li><strong>Authors: </strong>Ruhan Wang, Zhiyong Wang, Chengkai Huang, Rui Wang, Tong Yu, Lina Yao, John C.S. Lui, Dongruo Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07440">https://arxiv.org/abs/2506.07440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07440">https://arxiv.org/pdf/2506.07440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07440]] Federated In-Context Learning: Iterative Refinement for Improved Answer Quality(https://arxiv.org/abs/2506.07440)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>For question-answering (QA) tasks, in-context learning (ICL) enables language models to generate responses without modifying their parameters by leveraging examples provided in the input. However, the effectiveness of ICL heavily depends on the availability of high-quality examples, which are often scarce due to data privacy constraints, annotation costs, and distribution disparities. A natural solution is to utilize examples stored on client devices, but existing approaches either require transmitting model parameters - incurring significant communication overhead - or fail to fully exploit local datasets, limiting their effectiveness. To address these challenges, we propose Federated In-Context Learning (Fed-ICL), a general framework that enhances ICL through an iterative, collaborative process. Fed-ICL progressively refines responses by leveraging multi-round interactions between clients and a central server, improving answer quality without the need to transmit model parameters. We establish theoretical guarantees for the convergence of Fed-ICL and conduct extensive experiments on standard QA benchmarks, demonstrating that our proposed approach achieves strong performance while maintaining low communication costs.</li>
</ul>

<h3>Title: Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs</h3>
<ul>
<li><strong>Authors: </strong>T. Duy Nguyen-Hien, Desi R. Ivanova, Yee Whye Teh, Wee Sun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07448">https://arxiv.org/abs/2506.07448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07448">https://arxiv.org/pdf/2506.07448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07448]] Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs(https://arxiv.org/abs/2506.07448)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) are highly interactive and extendable, current approaches to ensure reliability in deployments remain mostly limited to rejecting outputs with high uncertainty in order to avoid misinformation. This conservative strategy reflects the current lack of tools to systematically distinguish and respond to different sources of uncertainty. In this paper, we advocate for the adoption of Bayesian Modeling of Experiments -- a framework that provides a coherent foundation to reason about uncertainty and clarify the reducibility of uncertainty -- for managing and proactively addressing uncertainty that arises in LLM deployments. This framework enables LLMs and their users to take contextually appropriate steps, such as requesting clarification, retrieving external information, or refining inputs. By supporting active resolution rather than passive avoidance, it opens the door to more reliable, transparent, and broadly applicable LLM systems, particularly in high-stakes, real-world settings.</li>
</ul>

<h3>Title: When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Xiao, Sana Tonekaboni, Walter Gerych, Vinith Suriyakumar, Marzyeh Ghassemi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07452">https://arxiv.org/abs/2506.07452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07452">https://arxiv.org/pdf/2506.07452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07452]] When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment(https://arxiv.org/abs/2506.07452)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can be prompted with specific styles (e.g., formatting responses as lists), including in jailbreak queries. Although these style patterns are semantically unrelated to the malicious intents behind jailbreak queries, their safety impact remains unclear. In this work, we seek to understand whether style patterns compromise LLM safety, how superficial style alignment increases model vulnerability, and how best to mitigate these risks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks, and find that malicious queries with style patterns inflate the attack success rate (ASR) for nearly all models. Notably, ASR inflation correlates with both the length of style patterns and the relative attention an LLM exhibits on them. We then investigate superficial style alignment, and find that fine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of those same styles. Finally, we propose SafeStyle, a defense strategy that incorporates a small amount of safety training data augmented to match the distribution of style patterns in the fine-tuning data. Across three LLMs and five fine-tuning style settings, SafeStyle consistently outperforms baselines in maintaining LLM safety.</li>
</ul>

<h3>Title: Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling</h3>
<ul>
<li><strong>Authors: </strong>Pritom Saha Akash, Kevin Chen-Chuan Chang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07453">https://arxiv.org/abs/2506.07453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07453">https://arxiv.org/pdf/2506.07453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07453]] Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling(https://arxiv.org/abs/2506.07453)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Topic modeling plays a vital role in uncovering hidden semantic structures within text corpora, but existing models struggle in low-resource settings where limited target-domain data leads to unstable and incoherent topic inference. We address this challenge by formally introducing domain adaptation for low-resource topic modeling, where a high-resource source domain informs a low-resource target domain without overwhelming it with irrelevant content. We establish a finite-sample generalization bound showing that effective knowledge transfer depends on robust performance in both domains, minimizing latent-space discrepancy, and preventing overfitting to the data. Guided by these insights, we propose DALTA (Domain-Aligned Latent Topic Adaptation), a new framework that employs a shared encoder for domain-invariant features, specialized decoders for domain-specific nuances, and adversarial alignment to selectively transfer relevant information. Experiments on diverse low-resource datasets demonstrate that DALTA consistently outperforms state-of-the-art methods in terms of topic coherence, stability, and transferability.</li>
</ul>

<h3>Title: PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation</h3>
<ul>
<li><strong>Authors: </strong>Wei Yao, Yunlian Sun, Chang Liu, Hongwen Zhang, Jinhui Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07456">https://arxiv.org/abs/2506.07456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07456">https://arxiv.org/pdf/2506.07456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07456]] PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation(https://arxiv.org/abs/2506.07456)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Driven by advancements in motion capture and generative artificial intelligence, leveraging large-scale MoCap datasets to train generative models for synthesizing diverse, realistic human motions has become a promising research direction. However, existing motion-capture techniques and generative models often neglect physical constraints, leading to artifacts such as interpenetration, sliding, and floating. These issues are exacerbated in multi-person motion generation, where complex interactions are involved. To address these limitations, we introduce physical mapping, integrated throughout the human interaction generation pipeline. Specifically, motion imitation within a physics-based simulation environment is used to project target motions into a physically valid space. The resulting motions are adjusted to adhere to real-world physics constraints while retaining their original semantic meaning. This mapping not only improves MoCap data quality but also directly informs post-processing of generated motions. Given the unique interactivity of multi-person scenarios, we propose a tailored motion representation framework. Motion Consistency (MC) and Marker-based Interaction (MI) loss functions are introduced to improve model performance. Experiments show our method achieves impressive results in generated human motion quality, with a 3%-89% improvement in physical fidelity. Project page this http URL</li>
</ul>

<h3>Title: KScope: A Framework for Characterizing the Knowledge Status of Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Xiao, Shan Chen, Jack Gallifant, Danielle Bitterman, Thomas Hartvigsen, Marzyeh Ghassemi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07458">https://arxiv.org/abs/2506.07458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07458">https://arxiv.org/pdf/2506.07458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07458]] KScope: A Framework for Characterizing the Knowledge Status of Language Models(https://arxiv.org/abs/2506.07458)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Characterizing a large language model's (LLM's) knowledge of a given question is challenging. As a result, prior work has primarily examined LLM behavior under knowledge conflicts, where the model's internal parametric memory contradicts information in the external context. However, this does not fully reflect how well the model knows the answer to the question. In this paper, we first introduce a taxonomy of five knowledge statuses based on the consistency and correctness of LLM knowledge modes. We then propose KScope, a hierarchical framework of statistical tests that progressively refines hypotheses about knowledge modes and characterizes LLM knowledge into one of these five statuses. We apply KScope to nine LLMs across four datasets and systematically establish: (1) Supporting context narrows knowledge gaps across models. (2) Context features related to difficulty, relevance, and familiarity drive successful knowledge updates. (3) LLMs exhibit similar feature preferences when partially correct or conflicted, but diverge sharply when consistently wrong. (4) Context summarization constrained by our feature analysis, together with enhanced credibility, further improves update effectiveness and generalizes across LLMs.</li>
</ul>

<h3>Title: ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziwen Wang, Jiajun Fan, Ruihan Guo, Thao Nguyen, Heng Ji, Ge Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07459">https://arxiv.org/abs/2506.07459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07459">https://arxiv.org/pdf/2506.07459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07459]] ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning(https://arxiv.org/abs/2506.07459)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Protein generative models have shown remarkable promise in protein design but still face limitations in success rate, due to the scarcity of high-quality protein datasets for supervised pretraining. We present ProteinZero, a novel framework that enables scalable, automated, and continuous self-improvement of the inverse folding model through online reinforcement learning. To achieve computationally tractable online feedback, we introduce efficient proxy reward models based on ESM-fold and a novel rapid ddG predictor that significantly accelerates evaluation speed. ProteinZero employs a general RL framework balancing multi-reward maximization, KL-divergence from a reference model, and a novel protein-embedding level diversity regularization that prevents mode collapse while promoting higher sequence diversity. Through extensive experiments, we demonstrate that ProteinZero substantially outperforms existing methods across every key metric in protein design, achieving significant improvements in structural accuracy, designability, thermodynamic stability, and sequence diversity. Most impressively, ProteinZero reduces design failure rates by approximately 36% - 48% compared to widely-used methods like ProteinMPNN, ESM-IF and InstructPLM, consistently achieving success rates exceeding 90% across diverse and complex protein folds. Notably, the entire RL run on CATH-4.3 can be done with a single 8 X GPU node in under 3 days, including reward computation. Our work establishes a new paradigm for protein design where models evolve continuously from their own generated outputs, opening new possibilities for exploring the vast protein design space.</li>
</ul>

<h3>Title: From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered</h3>
<ul>
<li><strong>Authors: </strong>Siddartha Devic, Tejas Srinivasan, Jesse Thomason, Willie Neiswanger, Vatsal Sharan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07461">https://arxiv.org/abs/2506.07461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07461">https://arxiv.org/pdf/2506.07461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07461]] From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered(https://arxiv.org/abs/2506.07461)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly assisting users in the real world, yet their reliability remains a concern. Uncertainty quantification (UQ) has been heralded as a tool to enhance human-LLM collaboration by enabling users to know when to trust LLM predictions. We argue that current practices for uncertainty quantification in LLMs are not optimal for developing useful UQ for human users making decisions in real-world tasks. Through an analysis of 40 LLM UQ methods, we identify three prevalent practices hindering the community's progress toward its goal of benefiting downstream users: 1) evaluating on benchmarks with low ecological validity; 2) considering only epistemic uncertainty; and 3) optimizing metrics that are not necessarily indicative of downstream utility. For each issue, we propose concrete user-centric practices and research directions that LLM UQ researchers should consider. Instead of hill-climbing on unrepresentative tasks using imperfect metrics, we argue that the community should adopt a more human-centered approach to LLM uncertainty quantification.</li>
</ul>

<h3>Title: CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guang Liu, Liangdong Wang, Jijie Li, Yang Yu, Yao Xu, Jiabei Chen, Yu Bai, Feng Liao, Yonghua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07463">https://arxiv.org/abs/2506.07463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07463">https://arxiv.org/pdf/2506.07463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07463]] CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models(https://arxiv.org/abs/2506.07463)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered for superior data quality and diverse human-like reasoning trajectory. CCI4.0 occupies roughly $35$ TB of disk space and comprises two sub-datasets: CCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully curated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and diverse sources from math, wiki, arxiv, and code. Although these data are mostly sourced from well-processed datasets, the quality standards of various domains are dynamic and require extensive expert experience and labor to process. So, we propose a novel pipeline justifying data quality mainly based on models through two-stage deduplication, multiclassifier quality scoring, and domain-aware fluency filtering. We extract $4.5$ billion pieces of CoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the distillation of CoT from larger models, our proposed staged CoT extraction exemplifies diverse reasoning patterns and significantly decreases the possibility of hallucination. Empirical evaluations demonstrate that LLMs pre-trained in CCI4.0 benefit from cleaner, more reliable training signals, yielding consistent improvements in downstream tasks, especially in math and code reflection tasks. Our results underscore the critical role of rigorous data curation and human thinking templates in advancing LLM performance, shedding some light on automatically processing pretraining corpora.</li>
</ul>

<h3>Title: DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO</h3>
<ul>
<li><strong>Authors: </strong>Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07464">https://arxiv.org/abs/2506.07464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07464">https://arxiv.org/pdf/2506.07464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07464]] DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO(https://arxiv.org/abs/2506.07464)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks.</li>
</ul>

<h3>Title: Circumventing Backdoor Space via Weight Symmetry</h3>
<ul>
<li><strong>Authors: </strong>Jie Peng, Hongwei Yang, Jing Zhao, Hengji Dong, Hui He, Weizhe Zhang, Haoyu He</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07467">https://arxiv.org/abs/2506.07467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07467">https://arxiv.org/pdf/2506.07467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07467]] Circumventing Backdoor Space via Weight Symmetry(https://arxiv.org/abs/2506.07467)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks are vulnerable to backdoor attacks, where malicious behaviors are implanted during training. While existing defenses can effectively purify compromised models, they typically require labeled data or specific training procedures, making them difficult to apply beyond supervised learning settings. Notably, recent studies have shown successful backdoor attacks across various learning paradigms, highlighting a critical security concern. To address this gap, we propose Two-stage Symmetry Connectivity (TSC), a novel backdoor purification defense that operates independently of data format and requires only a small fraction of clean samples. Through theoretical analysis, we prove that by leveraging permutation invariance in neural networks and quadratic mode connectivity, TSC amplifies the loss on poisoned samples while maintaining bounded clean accuracy. Experiments demonstrate that TSC achieves robust performance comparable to state-of-the-art methods in supervised learning scenarios. Furthermore, TSC generalizes to self-supervised learning frameworks, such as SimCLR and CLIP, maintaining its strong defense capabilities. Our code is available at this https URL.</li>
</ul>

<h3>Title: Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mickel Liu, Liwei Jiang, Yancheng Liang, Simon Shaolei Du, Yejin Choi, Tim Althoff, Natasha Jaques</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07468">https://arxiv.org/abs/2506.07468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07468">https://arxiv.org/pdf/2506.07468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07468]] Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models(https://arxiv.org/abs/2506.07468)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Conventional language model (LM) safety alignment relies on a reactive, disjoint procedure: attackers exploit a static model, followed by defensive fine-tuning to patch exposed vulnerabilities. This sequential approach creates a mismatch -- attackers overfit to obsolete defenses, while defenders perpetually lag behind emerging threats. To address this, we propose Self-RedTeam, an online self-play reinforcement learning algorithm where an attacker and defender agent co-evolve through continuous interaction. We cast safety alignment as a two-player zero-sum game, where a single model alternates between attacker and defender roles -- generating adversarial prompts and safeguarding against them -- while a reward LM adjudicates outcomes. This enables dynamic co-adaptation. Grounded in the game-theoretic framework of zero-sum games, we establish a theoretical safety guarantee which motivates the design of our method: if self-play converges to a Nash Equilibrium, the defender will reliably produce safe responses to any adversarial input. Empirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared to attackers trained against static defenders and achieves higher robustness on safety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained against static attackers. We further propose hidden Chain-of-Thought, allowing agents to plan privately, which boosts adversarial diversity and reduces over-refusals. Our results motivate a shift from reactive patching to proactive co-evolution in LM safety training, enabling scalable, autonomous, and robust self-improvement of LMs via multi-agent reinforcement learning (MARL).</li>
</ul>

<h3>Title: Improving Fairness of Large Language Models in Multi-document Summarization</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Li Yusen Zhang, Snigdha Chaturvedi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07479">https://arxiv.org/abs/2506.07479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07479">https://arxiv.org/pdf/2506.07479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07479]] Improving Fairness of Large Language Models in Multi-document Summarization(https://arxiv.org/abs/2506.07479)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Fairness in multi-document summarization (MDS) is crucial for providing comprehensive views across documents with diverse social attribute values, which can significantly impact decision-making. For example, a summarization system that tends to overrepresent negative reviews of products can mislead customers into disregarding good products. Previous works measure fairness in MDS at two levels: summary-level and corpus-level. While summary-level fairness focuses on individual summaries, corpus-level fairness focuses on a corpus of summaries. Recent methods primarily focus on summary-level fairness. We propose FairPO, a preference tuning method that focuses on both summary-level and corpus-level fairness in MDS. To improve summary-level fairness, we propose to generate preference pairs by perturbing document sets. To improve corpus-level fairness, we propose fairness-aware preference tuning by dynamically adjusting the weights of preference pairs. Our experiments show that FairPO outperforms strong baselines while maintaining the critical qualities of summaries. The code is available at this https URL.</li>
</ul>

<h3>Title: Explainable AI for Enhancing IDS Against Advanced Persistent Kill Chain</h3>
<ul>
<li><strong>Authors: </strong>Bassam Noori Shaker, Bahaa Al-Musawi, Mohammed Falih Hassan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07480">https://arxiv.org/abs/2506.07480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07480">https://arxiv.org/pdf/2506.07480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07480]] Explainable AI for Enhancing IDS Against Advanced Persistent Kill Chain(https://arxiv.org/abs/2506.07480)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) represent a sophisticated and persistent cy-bersecurity challenge, characterized by stealthy, multi-phase, and targeted attacks aimed at compromising information systems over an extended period. Develop-ing an effective Intrusion Detection System (IDS) capable of detecting APTs at different phases relies on selecting network traffic features. However, not all of these features are directly related to the phases of APTs. Some network traffic features may be unrelated or have limited relevance to identifying malicious ac-tivity. Therefore, it is important to carefully select and analyze the most relevant features to improve the IDS performance. This work proposes a feature selection and classification model that integrates two prominent machine learning algo-rithms: SHapley Additive exPlanations (SHAP) and Extreme Gradient Boosting (XGBoost). The aim is to develop lightweight IDS based on a selected minimum number of influential features for detecting APTs at various phases. The pro-posed method also specifies the relevant features for each phase of APTs inde-pendently. Extensive experimental results on the SCVIC-APT-2021 dataset indi-cated that our proposed approach has improved performance compared to other standard techniques. Specifically, both the macro-average F1-score and recall reached 94% and 93 %, respectively, while reducing the complexity of the detec-tion model by selecting only 12 features out of 77.</li>
</ul>

<h3>Title: A Hybrid GA LLM Framework for Structured Task Optimization</h3>
<ul>
<li><strong>Authors: </strong>Berry Feng, Jonas Lin, Patrick Lau</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07483">https://arxiv.org/abs/2506.07483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07483">https://arxiv.org/pdf/2506.07483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07483]] A Hybrid GA LLM Framework for Structured Task Optimization(https://arxiv.org/abs/2506.07483)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>GA LLM is a hybrid framework that combines Genetic Algorithms with Large Language Models to handle structured generation tasks under strict constraints. Each output, such as a plan or report, is treated as a gene, and evolutionary operations like selection, crossover, and mutation are guided by the language model to iteratively improve solutions. The language model provides domain knowledge and creative variation, while the genetic algorithm ensures structural integrity and global optimization. GA LLM has proven effective in tasks such as itinerary planning, academic outlining, and business reporting, consistently producing well structured and requirement satisfying results. Its modular design also makes it easy to adapt to new tasks. Compared to using a language model alone, GA LLM achieves better constraint satisfaction and higher quality solutions by combining the strengths of both components.</li>
</ul>

<h3>Title: Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video</h3>
<ul>
<li><strong>Authors: </strong>Yahao Shi, Yang Liu, Yanmin Wu, Xing Liu, Chen Zhao, Jie Luo, Bin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07489">https://arxiv.org/abs/2506.07489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07489">https://arxiv.org/pdf/2506.07489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07489]] Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video(https://arxiv.org/abs/2506.07489)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose DriveAnyMesh, a method for driving mesh guided by monocular video. Current 4D generation techniques encounter challenges with modern rendering engines. Implicit methods have low rendering efficiency and are unfriendly to rasterization-based engines, while skeletal methods demand significant manual effort and lack cross-category generalization. Animating existing 3D assets, instead of creating 4D assets from scratch, demands a deep understanding of the input's 3D structure. To tackle these challenges, we present a 4D diffusion model that denoises sequences of latent sets, which are then decoded to produce mesh animations from point cloud trajectory sequences. These latent sets leverage a transformer-based variational autoencoder, simultaneously capturing 3D shape and motion information. By employing a spatiotemporal, transformer-based diffusion model, information is exchanged across multiple latent frames, enhancing the efficiency and generalization of the generated results. Our experimental results demonstrate that DriveAnyMesh can rapidly produce high-quality animations for complex motions and is compatible with modern rendering engines. This method holds potential for applications in both the gaming and filming industries.</li>
</ul>

<h3>Title: SpatialLM: Training Large Language Models for Structured Indoor Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07491">https://arxiv.org/abs/2506.07491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07491">https://arxiv.org/pdf/2506.07491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07491]] SpatialLM: Training Large Language Models for Structured Indoor Modeling(https://arxiv.org/abs/2506.07491)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>SpatialLM is a large language model designed to process 3D point cloud data and generate structured 3D scene understanding outputs. These outputs include architectural elements like walls, doors, windows, and oriented object boxes with their semantic categories. Unlike previous methods which exploit task-specific network designs, our model adheres to the standard multimodal LLM architecture and is fine-tuned directly from open-source LLMs. To train SpatialLM, we collect a large-scale, high-quality synthetic dataset consisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with ground-truth 3D annotations, and conduct a careful study on various modeling and training decisions. On public benchmarks, our model gives state-of-the-art performance in layout estimation and competitive results in 3D object detection. With that, we show a feasible path for enhancing the spatial understanding capabilities of modern LLMs for applications in augmented reality, embodied robotics, and more.</li>
</ul>

<h3>Title: Explicit Preference Optimization: No Need for an Implicit Reward Model</h3>
<ul>
<li><strong>Authors: </strong>Xiangkun Hu, Lemin Kong, Tong He, David Wipf</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07492">https://arxiv.org/abs/2506.07492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07492">https://arxiv.org/pdf/2506.07492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07492]] Explicit Preference Optimization: No Need for an Implicit Reward Model(https://arxiv.org/abs/2506.07492)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The generated responses of large language models (LLMs) are often fine-tuned to human preferences through a process called reinforcement learning from human feedback (RLHF). As RLHF relies on a challenging training sequence, whereby a separate reward model is independently learned and then later applied to LLM policy updates, ongoing research effort has targeted more straightforward alternatives. In this regard, direct preference optimization (DPO) and its many offshoots circumvent the need for a separate reward training step. Instead, through the judicious use of a reparameterization trick that induces an \textit{implicit} reward, DPO and related methods consolidate learning to the minimization of a single loss function. And yet despite demonstrable success in some real-world settings, we prove that DPO-based objectives are nonetheless subject to sub-optimal regularization and counter-intuitive interpolation behaviors, underappreciated artifacts of the reparameterizations upon which they are based. To this end, we introduce an \textit{explicit} preference optimization framework termed EXPO that requires no analogous reparameterization to achieve an implicit reward. Quite differently, we merely posit intuitively-appealing regularization factors from scratch that transparently avoid the potential pitfalls of key DPO variants, provably satisfying regularization desiderata that prior methods do not. Empirical results serve to corroborate our analyses and showcase the efficacy of EXPO.</li>
</ul>

<h3>Title: Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wenyu Liu, Xinggang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07497">https://arxiv.org/abs/2506.07497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07497">https://arxiv.org/pdf/2506.07497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07497]] Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency(https://arxiv.org/abs/2506.07497)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>We present Genesis, a unified framework for joint generation of multi-view driving videos and LiDAR sequences with spatio-temporal and cross-modal consistency. Genesis employs a two-stage architecture that integrates a DiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR generator with NeRF-based rendering and adaptive sampling. Both modalities are directly coupled through a shared latent space, enabling coherent evolution across visual and geometric domains. To guide the generation with structured semantics, we introduce DataCrafter, a captioning module built on vision-language models that provides scene-level and instance-level supervision. Extensive experiments on the nuScenes benchmark demonstrate that Genesis achieves state-of-the-art performance across video and LiDAR metrics (FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including segmentation and 3D detection, validating the semantic fidelity and practical utility of the generated data.</li>
</ul>

<h3>Title: Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Libo Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07501">https://arxiv.org/abs/2506.07501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07501">https://arxiv.org/pdf/2506.07501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07501]] Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning(https://arxiv.org/abs/2506.07501)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In view of the problem that each subchain in the chain-of-model (CoM) relies only on the information of the previous subchain and may lose long-range dependencies due to the causal mask blocking the global context flow between multi-level subchains, this work proposes a graph of causal evolution (GoCE). Its core principle is to map the implicit token representation into a differentiable and sparse causal adjacency matrix, then permeate causal constraints through each layer of calculation using causal-masked attention and causal-MoE. By combining intervention consistency loss test and self-evolution gate, the dynamic balance between causal structure learning and adaptive updating of transformer architecture is realized. The researcher built experimental environments in sandboxes built with Claude Sonnet 4, o4-mini-high, and DeepSeek R1 respectively with the transformer variant architecture introduced in GoCE. It is evaluated on publicly available datasets including CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the baseline LLMs. The finding proves that GoCE strengthens the transformer's ability to capture long-range causal dependencies, while the ability to self-evolve is improved. It not only surpasses the design of CoM in terms of design principles, but also provides experience for future research on causal learning and continuous adaptive improvement.</li>
</ul>

<h3>Title: What Do Indonesians Really Need from Language Technology? A Nationwide Survey</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Dehan Al Kautsar, Lucky Susanto, Derry Wijaya, Fajri Koto</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07506">https://arxiv.org/abs/2506.07506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07506">https://arxiv.org/pdf/2506.07506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07506]] What Do Indonesians Really Need from Language Technology? A Nationwide Survey(https://arxiv.org/abs/2506.07506)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>There is an emerging effort to develop NLP for Indonesias 700+ local languages, but progress remains costly due to the need for direct engagement with native speakers. However, it is unclear what these language communities truly need from language technology. To address this, we conduct a nationwide survey to assess the actual needs of native speakers in Indonesia. Our findings indicate that addressing language barriers, particularly through machine translation and information retrieval, is the most critical priority. Although there is strong enthusiasm for advancements in language technology, concerns around privacy, bias, and the use of public data for AI training highlight the need for greater transparency and clear communication to support broader AI adoption.</li>
</ul>

<h3>Title: DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction</h3>
<ul>
<li><strong>Authors: </strong>Solee Im, Wonjun Lee, Jinmyeong An, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07510">https://arxiv.org/abs/2506.07510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07510">https://arxiv.org/pdf/2506.07510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07510]] DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction(https://arxiv.org/abs/2506.07510)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present DeRAGEC, a method for improving Named Entity (NE) correction in Automatic Speech Recognition (ASR) systems. By extending the Retrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC employs synthetic denoising rationales to filter out noisy NE candidates before correction. By leveraging phonetic similarity and augmented definitions, it refines noisy retrieved NEs using in-context learning, requiring no additional training. Experimental results on CommonVoice and STOP datasets show significant improvements in Word Error Rate (WER) and NE hit ratio, outperforming baseline ASR and RAGEC methods. Specifically, we achieved a 28% relative reduction in WER compared to ASR without postprocessing. Our source code is publicly available at: this https URL</li>
</ul>

<h3>Title: Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems</h3>
<ul>
<li><strong>Authors: </strong>Shuqiang Zhang, Yuchao Zhang, Jinkun Chen, Haochen Sui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07517">https://arxiv.org/abs/2506.07517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07517">https://arxiv.org/pdf/2506.07517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07517]] Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems(https://arxiv.org/abs/2506.07517)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Recommendation systems (RS) aim to provide personalized content, but they face a challenge in unbiased learning due to selection bias, where users only interact with items they prefer. This bias leads to a distorted representation of user preferences, which hinders the accuracy and fairness of recommendations. To address the issue, various methods such as error imputation based, inverse propensity scoring, and doubly robust techniques have been developed. Despite the progress, from the structural causal model perspective, previous debiasing methods in RS assume the independence of the exogenous variables. In this paper, we release this assumption and propose a learning algorithm based on likelihood maximization to learn a prediction model. We first discuss the correlation and difference between unmeasured confounding and our scenario, then we propose a unified method that effectively handles latent exogenous variables. Specifically, our method models the data generation process with latent exogenous variables under mild normality assumptions. We then develop a Monte Carlo algorithm to numerically estimate the likelihood function. Extensive experiments on synthetic datasets and three real-world datasets demonstrate the effectiveness of our proposed method. The code is at this https URL.</li>
</ul>

<h3>Title: Towards Large Language Models with Self-Consistent Natural Language Explanations</h3>
<ul>
<li><strong>Authors: </strong>Sahar Admoni, Ofra Amir, Assaf Hallak, Yftah Ziser</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07523">https://arxiv.org/abs/2506.07523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07523">https://arxiv.org/pdf/2506.07523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07523]] Towards Large Language Models with Self-Consistent Natural Language Explanations(https://arxiv.org/abs/2506.07523)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) seem to offer an easy path to interpretability: just ask them to explain their decisions. Yet, studies show that these post-hoc explanations often misrepresent the true decision process, as revealed by mismatches in feature importance. Despite growing evidence of this inconsistency, no systematic solutions have emerged, partly due to the high cost of estimating feature importance, which limits evaluations to small datasets. To address this, we introduce the Post-hoc Self-Consistency Bank (PSCB) - a large-scale benchmark of decisions spanning diverse tasks and models, each paired with LLM-generated explanations and corresponding feature importance scores. Analysis of PSCB reveals that self-consistency scores barely differ between correct and incorrect predictions. We also show that the standard metric fails to meaningfully distinguish between explanations. To overcome this limitation, we propose an alternative metric that more effectively captures variation in explanation quality. We use it to fine-tune LLMs via Direct Preference Optimization (DPO), leading to significantly better alignment between explanations and decision-relevant features, even under domain shift. Our findings point to a scalable path toward more trustworthy, self-consistent LLMs.</li>
</ul>

<h3>Title: MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts</h3>
<ul>
<li><strong>Authors: </strong>Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Kai Lu, Jiguang Wan, Jianzong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07533">https://arxiv.org/abs/2506.07533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07533">https://arxiv.org/pdf/2506.07533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07533]] MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts(https://arxiv.org/abs/2506.07533)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>One of the primary challenges in optimizing large language models (LLMs) for long-context inference lies in the high memory consumption of the Key-Value (KV) cache. Existing approaches, such as quantization, have demonstrated promising results in reducing memory usage. However, current quantization methods cannot take both effectiveness and efficiency into account. In this paper, we propose MoQAE, a novel mixed-precision quantization method via mixture of quantization-aware experts. First, we view different quantization bit-width configurations as experts and use the traditional mixture of experts (MoE) method to select the optimal configuration. To avoid the inefficiency caused by inputting tokens one by one into the router in the traditional MoE method, we input the tokens into the router chunk by chunk. Second, we design a lightweight router-only fine-tuning process to train MoQAE with a comprehensive loss to learn the trade-off between model accuracy and memory usage. Finally, we introduce a routing freezing (RF) and a routing sharing (RS) mechanism to further reduce the inference overhead. Extensive experiments on multiple benchmark datasets demonstrate that our method outperforms state-of-the-art KV cache quantization approaches in both efficiency and effectiveness.</li>
</ul>

<h3>Title: Bit-level BPE: Below the byte boundary</h3>
<ul>
<li><strong>Authors: </strong>Sangwhan Moon, Tatsuya Hiraoka, Naoaki Okazaki</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07541">https://arxiv.org/abs/2506.07541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07541">https://arxiv.org/pdf/2506.07541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07541]] Bit-level BPE: Below the byte boundary(https://arxiv.org/abs/2506.07541)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Byte-level fallbacks for subword tokenization have become a common practice in large language models. In particular, it has been demonstrated to be incredibly effective as a pragmatic solution for preventing OOV, especially in the context of larger models. However, breaking a character down to individual bytes significantly increases the sequence length for long-tail tokens in languages such as Chinese, Japanese, and Korean (CJK) and other character-diverse contexts such as emoji. The increased sequence length results in longer computation during both training and inference. In this work, we propose a simple compression technique that reduces the sequence length losslessly.</li>
</ul>

<h3>Title: APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs</h3>
<ul>
<li><strong>Authors: </strong>Bowen Liu, Weiyi Zhang, Peranut Chotcomwongse, Xiaolan Chen, Ruoyu Chen, Pawin Pakaymaskul, Niracha Arjkongharn, Nattaporn Vongsa, Xuelian Cheng, Zongyuan Ge, Kun Huang, Xiaohui Li, Yiru Duan, Zhenbang Wang, BaoYe Xie, Qiang Chen, Huazhu Fu, Michael A. Mahr, Jiaqi Qu, Wangyiyang Chen, Shiye Wang, Yubo Tan, Yongjie Li, Mingguang He, Danli Shi, Paisan Ruamviboonsuk</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07542">https://arxiv.org/abs/2506.07542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07542">https://arxiv.org/pdf/2506.07542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07542]] APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs(https://arxiv.org/abs/2506.07542)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Optical Coherence Tomography (OCT) provides high-resolution, 3D, and non-invasive visualization of retinal layers in vivo, serving as a critical tool for lesion localization and disease diagnosis. However, its widespread adoption is limited by equipment costs and the need for specialized operators. In comparison, 2D color fundus photography offers faster acquisition and greater accessibility with less dependence on expensive devices. Although generative artificial intelligence has demonstrated promising results in medical image synthesis, translating 2D fundus images into 3D OCT images presents unique challenges due to inherent differences in data dimensionality and biological information between modalities. To advance generative models in the fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society (APTOS-2024) organized a challenge titled Artificial Intelligence-based OCT Generation from Fundus Images. This paper details the challenge framework (referred to as APTOS-2024 Challenge), including: the benchmark dataset, evaluation methodology featuring two fidelity metrics-image-based distance (pixel-level OCT B-scan similarity) and video-based distance (semantic-level volumetric consistency), and analysis of top-performing solutions. The challenge attracted 342 participating teams, with 42 preliminary submissions and 9 finalists. Leading methodologies incorporated innovations in hybrid data preprocessing or augmentation (cross-modality collaborative paradigms), pre-training on external ophthalmic imaging datasets, integration of vision foundation models, and model architecture improvement. The APTOS-2024 Challenge is the first benchmark demonstrating the feasibility of fundus-to-3D-OCT synthesis as a potential solution for improving ophthalmic care accessibility in under-resourced healthcare settings, while helping to expedite medical research and clinical applications.</li>
</ul>

<h3>Title: Improving Memory Efficiency for Training KANs via Meta Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhangchi Zhao, Jun Shu, Deyu Meng, Zongben Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07549">https://arxiv.org/abs/2506.07549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07549">https://arxiv.org/pdf/2506.07549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07549]] Improving Memory Efficiency for Training KANs via Meta Learning(https://arxiv.org/abs/2506.07549)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Inspired by the Kolmogorov-Arnold representation theorem, KANs offer a novel framework for function approximation by replacing traditional neural network weights with learnable univariate functions. This design demonstrates significant potential as an efficient and interpretable alternative to traditional MLPs. However, KANs are characterized by a substantially larger number of trainable parameters, leading to challenges in memory efficiency and higher training costs compared to MLPs. To address this limitation, we propose to generate weights for KANs via a smaller meta-learner, called MetaKANs. By training KANs and MetaKANs in an end-to-end differentiable manner, MetaKANs achieve comparable or even superior performance while significantly reducing the number of trainable parameters and maintaining promising interpretability. Extensive experiments on diverse benchmark tasks, including symbolic regression, partial differential equation solving, and image classification, demonstrate the effectiveness of MetaKANs in improving parameter efficiency and memory usage. The proposed method provides an alternative technique for training KANs, that allows for greater scalability and extensibility, and narrows the training cost gap with MLPs stated in the original paper of KANs. Our code is available at this https URL.</li>
</ul>

<h3>Title: ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning</h3>
<ul>
<li><strong>Authors: </strong>Mengsong Wu, YaFei Wang, Yidong Ming, Yuqi An, Yuwei Wan, Wenliang Chen, Binbin Lin, Yuqiang Li, Tong Xie, Dongzhan Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07551">https://arxiv.org/abs/2506.07551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07551">https://arxiv.org/pdf/2506.07551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07551]] ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning(https://arxiv.org/abs/2506.07551)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently demonstrated promising capabilities in chemistry tasks while still facing challenges due to outdated pretraining knowledge and the difficulty of incorporating specialized chemical expertise. To address these issues, we propose an LLM-based agent that synergistically integrates 137 external chemical tools created ranging from basic information retrieval to complex reaction predictions, and a dataset curation pipeline to generate the dataset ChemToolBench that facilitates both effective tool selection and precise parameter filling during fine-tuning and evaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search (HE-MCTS) framework, enabling independent optimization of tool planning and execution. By leveraging self-generated data, our approach supports step-level fine-tuning (FT) of the policy model and training task-adaptive PRM and ORM that surpass GPT-4o. Experimental evaluations demonstrate that our approach significantly improves performance in Chemistry QA and discovery tasks, offering a robust solution to integrate specialized tools with LLMs for advanced chemical applications. All datasets and code are available at this https URL .</li>
</ul>

<h3>Title: Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries</h3>
<ul>
<li><strong>Authors: </strong>Haoxiang Wang, Zinan Lin, Da Yu, Huishuai Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07555">https://arxiv.org/abs/2506.07555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07555">https://arxiv.org/pdf/2506.07555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07555]] Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries(https://arxiv.org/abs/2506.07555)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Generating high fidelity, differentially private (DP) synthetic images offers a promising route to share and analyze sensitive visual data without compromising individual privacy. However, existing DP image synthesis methods struggle to produce high resolution outputs that faithfully capture the structure of the original data. In this paper, we introduce a novel method, referred to as Synthesis via Private Textual Intermediaries (SPTI), that can generate high resolution DP images with easy adoption. The key idea is to shift the challenge of DP image synthesis from the image domain to the text domain by leveraging state of the art DP text generation methods. SPTI first summarizes each private image into a concise textual description using image to text models, then applies a modified Private Evolution algorithm to generate DP text, and finally reconstructs images using text to image models. Notably, SPTI requires no model training, only inference with off the shelf models. Given a private dataset, SPTI produces synthetic images of substantially higher quality than prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID less than or equal to 26.71 under epsilon equal to 1.0, improving over Private Evolution FID of 40.36. Similarly, on MM CelebA HQ, SPTI achieves an FID less than or equal to 33.27 at epsilon equal to 1.0, compared to 57.01 from DP fine tuning baselines. Overall, our results demonstrate that Synthesis via Private Textual Intermediaries provides a resource efficient and proprietary model compatible framework for generating high resolution DP synthetic images, greatly expanding access to private visual datasets.</li>
</ul>

<h3>Title: SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Mengsong Wu, Di Zhang, Yuqiang Li, Dongzhan Zhou, Wenliang Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07557">https://arxiv.org/abs/2506.07557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07557">https://arxiv.org/pdf/2506.07557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07557]] SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition(https://arxiv.org/abs/2506.07557)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have achieved remarkable success in a wide range of applications, their performance often degrades in complex reasoning tasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a novel framework that leverages a modified Monte Carlo Tree Search (MCTS) to enhance LLM reasoning without relying on external reward models. By redefining the Upper Confidence Bound scoring to align with intrinsic self-evaluation capabilities of LLMs and decomposing the inference process into atomic subtasks augmented with semantic clustering at each node, SELT effectively balances exploration and exploitation, reduces redundant reasoning paths, and mitigates hallucination. We validate our approach on challenging benchmarks, including the knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT achieves significant improvements in answer accuracy and reasoning robustness compared to baseline methods. Notably, our framework operates without task-specific fine-tuning, demonstrating strong generalizability across diverse reasoning tasks. Relevant results and code are available at this https URL .</li>
</ul>

<h3>Title: Cross-channel Perception Learning for H&E-to-IHC Virtual Staining</h3>
<ul>
<li><strong>Authors: </strong>Hao Yang, JianYu Wu, Run Fang, Xuelian Zhao, Yuan Ji, Zhiyu Chen, Guibin He, Junceng Guo, Yang Liu, Xinhua Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07559">https://arxiv.org/abs/2506.07559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07559">https://arxiv.org/pdf/2506.07559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07559]] Cross-channel Perception Learning for H&E-to-IHC Virtual Staining(https://arxiv.org/abs/2506.07559)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>With the rapid development of digital pathology, virtual staining has become a key technology in multimedia medical information systems, offering new possibilities for the analysis and diagnosis of pathological images. However, existing H&E-to-IHC studies often overlook the cross-channel correlations between cell nuclei and cell membranes. To address this issue, we propose a novel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPL first decomposes HER2 immunohistochemical staining into Hematoxylin and DAB staining channels, corresponding to cell nuclei and cell membranes, respectively. Using the pathology foundation model Gigapath's Tile Encoder, CCPL extracts dual-channel features from both the generated and real images and measures cross-channel correlations between nuclei and membranes. The features of the generated and real stained images, obtained through the Tile Encoder, are also used to calculate feature distillation loss, enhancing the model's feature extraction capabilities without increasing the inference burden. Additionally, CCPL performs statistical analysis on the focal optical density maps of both single channels to ensure consistency in staining distribution and intensity. Experimental results, based on quantitative metrics such as PSNR, SSIM, PCC, and FID, along with professional evaluations from pathologists, demonstrate that CCPL effectively preserves pathological features, generates high-quality virtual stained images, and provides robust support for automated pathological diagnosis using multimedia medical data.</li>
</ul>

<h3>Title: OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data</h3>
<ul>
<li><strong>Authors: </strong>Jinlu Zhang, Zixi Kang, Yizhou Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07565">https://arxiv.org/abs/2506.07565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07565">https://arxiv.org/pdf/2506.07565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07565]] OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data(https://arxiv.org/abs/2506.07565)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Music-driven dance generation offers significant creative potential yet faces considerable challenges. The absence of fine-grained multimodal data and the difficulty of flexible multi-conditional generation limit previous works on generation controllability and diversity in practice. In this paper, we build OpenDance5D, an extensive human dance dataset comprising over 101 hours across 14 distinct genres. Each sample has five modalities to facilitate robust cross-modal learning: RGB video, audio, 2D keypoints, 3D motion, and fine-grained textual descriptions from human arts. Furthermore, we propose OpenDanceNet, a unified masked modeling framework for controllable dance generation conditioned on music and arbitrary combinations of text prompts, keypoints, or character positioning. Comprehensive experiments demonstrate that OpenDanceNet achieves high-fidelity and flexible controllability.</li>
</ul>

<h3>Title: LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Yang, Zhen Luo, Tongsheng Ding, Junru Lu, Mingqi Gao, Jinyu Yang, Victor Sanchez, Feng Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07570">https://arxiv.org/abs/2506.07570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07570">https://arxiv.org/pdf/2506.07570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07570]] LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization(https://arxiv.org/abs/2506.07570)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Automatic indoor layout generation has attracted increasing attention due to its potential in interior design, virtual environment construction, and embodied AI. Existing methods fall into two categories: prompt-driven approaches that leverage proprietary LLM services (e.g., GPT APIs) and learning-based methods trained on layout data upon diffusion-based models. Prompt-driven methods often suffer from spatial inconsistency and high computational costs, while learning-based methods are typically constrained by coarse relational graphs and limited datasets, restricting their generalization to diverse room categories. In this paper, we revisit LLM-based indoor layout generation and present 3D-SynthPlace, a large-scale dataset that combines synthetic layouts generated via a 'GPT synthesize, Human inspect' pipeline, upgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000 scenes, covering four common room types -- bedroom, living room, kitchen, and bathroom -- enriched with diverse objects and high-level spatial annotations. We further introduce OptiScene, a strong open-source LLM optimized for indoor layout generation, fine-tuned based on our 3D-SynthPlace dataset through our two-stage training. For the warum-up stage I, we adopt supervised fine-tuning (SFT), which is taught to first generate high-level spatial descriptions then conditionally predict concrete object placements. For the reinforcing stage II, to better align the generated layouts with human design preferences, we apply multi-turn direct preference optimization (DPO), which significantly improving layout quality and generation success rates. Extensive experiments demonstrate that OptiScene outperforms traditional prompt-driven and learning-based baselines. Moreover, OptiScene shows promising potential in interactive tasks such as scene editing and robot navigation.</li>
</ul>

<h3>Title: Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Ruiyang Zhang, Hu Zhang, Hao Fei, Zhedong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07575">https://arxiv.org/abs/2506.07575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07575">https://arxiv.org/pdf/2506.07575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07575]] Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models(https://arxiv.org/abs/2506.07575)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Multimodal Models (LMMs), harnessing the complementarity among diverse modalities, are often considered more robust than pure Language Large Models (LLMs); yet do LMMs know what they do not know? There are three key open questions remaining: (1) how to evaluate the uncertainty of diverse LMMs in a unified manner, (2) how to prompt LMMs to show its uncertainty, and (3) how to quantify uncertainty for downstream tasks. In an attempt to address these challenges, we introduce Uncertainty-o: (1) a model-agnostic framework designed to reveal uncertainty in LMMs regardless of their modalities, architectures, or capabilities, (2) an empirical exploration of multimodal prompt perturbations to uncover LMM uncertainty, offering insights and findings, and (3) derive the formulation of multimodal semantic uncertainty, which enables quantifying uncertainty from multimodal responses. Experiments across 18 benchmarks spanning various modalities and 10 LMMs (both open- and closed-source) demonstrate the effectiveness of Uncertainty-o in reliably estimating LMM uncertainty, thereby enhancing downstream tasks such as hallucination detection, hallucination mitigation, and uncertainty-aware Chain-of-Thought reasoning.</li>
</ul>

<h3>Title: FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Tan Chen, Jintao Yan, Yuxuan Sun, Sheng Zhou, Zhisheng Niu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07581">https://arxiv.org/abs/2506.07581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07581">https://arxiv.org/pdf/2506.07581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07581]] FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning(https://arxiv.org/abs/2506.07581)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a promising paradigm for multiple devices to cooperatively train a model. When applied in wireless networks, two issues consistently affect the performance of FL, i.e., data heterogeneity of devices and limited bandwidth. Many papers have investigated device scheduling strategies considering the two issues. However, most of them recognize data heterogeneity as a property of individual devices. In this paper, we prove that the convergence speed of FL is affected by the sum of device-level and sample-level collective gradient divergence (CGD). The device-level CGD refers to the gradient divergence of the scheduled device group, instead of the sum of the individual device divergence. The sample-level CGD is statistically upper bounded by sampling variance, which is inversely proportional to the total number of samples scheduled for local update. To derive a tractable form of the device-level CGD, we further consider a classification problem and transform it into the weighted earth moving distance (WEMD) between the group distribution and the global distribution. Then we propose FedCGD algorithm to minimize the sum of multi-level CGDs by balancing WEMD and sampling variance, within polynomial time. Simulation shows that the proposed strategy increases classification accuracy on the CIFAR-10 dataset by up to 4.2\% while scheduling 41.8\% fewer devices, and flexibly switches between reducing WEMD and reducing sampling variance.</li>
</ul>

<h3>Title: Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ramakrishna Appicharla, Baban Gain, Santanu Pal, Asif Ekbal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07583">https://arxiv.org/abs/2506.07583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07583">https://arxiv.org/pdf/2506.07583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07583]] Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models(https://arxiv.org/abs/2506.07583)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the popularity of the large language models (LLMs), their application to machine translation is relatively underexplored, especially in context-aware settings. This work presents a literature review of context-aware translation with LLMs. The existing works utilise prompting and fine-tuning approaches, with few focusing on automatic post-editing and creating translation agents for context-aware machine translation. We observed that the commercial LLMs (such as ChatGPT and Tower LLM) achieved better results than the open-source LLMs (such as Llama and Bloom LLMs), and prompt-based approaches serve as good baselines to assess the quality of translations. Finally, we present some interesting future directions to explore.</li>
</ul>

<h3>Title: MIRA: Medical Time Series Foundation Model for Real-World Health Data</h3>
<ul>
<li><strong>Authors: </strong>Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07584">https://arxiv.org/abs/2506.07584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07584">https://arxiv.org/pdf/2506.07584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07584]] MIRA: Medical Time Series Foundation Model for Real-World Health Data(https://arxiv.org/abs/2506.07584)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>A unified foundation model for medical time series -- pretrained on open access and ethics board-approved medical corpora -- offers the potential to reduce annotation burdens, minimize model customization, and enable robust transfer across clinical institutions, modalities, and tasks, particularly in data-scarce or privacy-constrained environments. However, existing generalist time series foundation models struggle to handle medical time series data due to their inherent challenges, including irregular intervals, heterogeneous sampling rates, and frequent missing values. To address these challenges, we introduce MIRA, a unified foundation model specifically designed for medical time series forecasting. MIRA incorporates a Continuous-Time Rotary Positional Encoding that enables fine-grained modeling of variable time intervals, a frequency-specific mixture-of-experts layer that routes computation across latent frequency regimes to further promote temporal specialization, and a Continuous Dynamics Extrapolation Block based on Neural ODE that models the continuous trajectory of latent states, enabling accurate forecasting at arbitrary target timestamps. Pretrained on a large-scale and diverse medical corpus comprising over 454 billion time points collect from publicly available datasets, MIRA achieves reductions in forecasting errors by an average of 10% and 7% in out-of-distribution and in-distribution scenarios, respectively, when compared to other zero-shot and fine-tuned baselines. We also introduce a comprehensive benchmark spanning multiple downstream clinical tasks, establishing a foundation for future research in medical time series modeling.</li>
</ul>

<h3>Title: Aircraft Trajectory Dataset Augmentation in Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Seokbin Yoon, Keumjin Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07585">https://arxiv.org/abs/2506.07585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07585">https://arxiv.org/pdf/2506.07585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07585]] Aircraft Trajectory Dataset Augmentation in Latent Space(https://arxiv.org/abs/2506.07585)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Aircraft trajectory modeling plays a crucial role in Air Traffic Management (ATM) and is important for various downstream tasks, including conflict detection and landing time prediction. Dataset augmentation through the addition of synthetically generated trajectory data is necessary to develop a more robust aircraft trajectory model and ensure that the trajectory dataset is sufficient and balanced. In this work, we propose a novel framework called ATRADA for aircraft trajectory dataset augmentation. In the proposed framework, a Transformer encoder learns the underlying patterns in the original trajectory dataset and converts each data point into a context vector in the learned latent space. The converted dataset in the latent space is projected into reduced dimensions using principal component analysis (PCA), and a Gaussian mixture model (GMM) is applied to fit the probability distribution of the data points in the reduced-dimensional space. Finally, new samples are drawn from the fitted GMM, the dimension of the samples is reverted to the original dimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several experiments demonstrate that the framework effectively generates new, high-quality synthetic aircraft trajectory data, which were compared to the results of several baselines.</li>
</ul>

<h3>Title: MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity</h3>
<ul>
<li><strong>Authors: </strong>Bikash Saha, Sandeep Kumar Shukla</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07586">https://arxiv.org/abs/2506.07586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07586">https://arxiv.org/pdf/2506.07586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07586]] MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity(https://arxiv.org/abs/2506.07586)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal, generative, large language model</a></li>
<li><strong>Abstract: </strong>The dual use nature of Large Language Models (LLMs) presents a growing challenge in cybersecurity. While LLM enhances automation and reasoning for defenders, they also introduce new risks, particularly their potential to be misused for generating evasive, AI crafted malware. Despite this emerging threat, the research community currently lacks controlled and extensible tools that can simulate such behavior for testing and defense preparation. We present MalGEN, a multi agent framework that simulates coordinated adversarial behavior to generate diverse, activity driven malware samples. The agents work collaboratively to emulate attacker workflows, including payload planning, capability selection, and evasion strategies, within a controlled environment built for ethical and defensive research. Using MalGEN, we synthesized ten novel malware samples and evaluated them against leading antivirus and behavioral detection engines. Several samples exhibited stealthy and evasive characteristics that bypassed current defenses, validating MalGEN's ability to model sophisticated and new threats. By transforming the threat of LLM misuse into an opportunity for proactive defense, MalGEN offers a valuable framework for evaluating and strengthening cybersecurity systems. The framework addresses data scarcity, enables rigorous testing, and supports the development of resilient and future ready detection strategies.</li>
</ul>

<h3>Title: Explore the vulnerability of black-box models via diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Shi, Yanfu Zhang, Huajie Shao, Ashley Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07590">https://arxiv.org/abs/2506.07590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07590">https://arxiv.org/pdf/2506.07590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07590]] Explore the vulnerability of black-box models via diffusion models(https://arxiv.org/abs/2506.07590)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in diffusion models have enabled high-fidelity and photorealistic image generation across diverse applications. However, these models also present security and privacy risks, including copyright violations, sensitive information leakage, and the creation of harmful or offensive content that could be exploited maliciously. In this study, we uncover a novel security threat where an attacker leverages diffusion model APIs to generate synthetic images, which are then used to train a high-performing substitute model. This enables the attacker to execute model extraction and transfer-based adversarial attacks on black-box classification models with minimal queries, without needing access to the original training data. The generated images are sufficiently high-resolution and diverse to train a substitute model whose outputs closely match those of the target model. Across the seven benchmarks, including CIFAR and ImageNet subsets, our method shows an average improvement of 27.37% over state-of-the-art methods while using just 0.01 times of the query budget, achieving a 98.68% success rate in adversarial attacks on the target model.</li>
</ul>

<h3>Title: TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts</h3>
<ul>
<li><strong>Authors: </strong>Torsten Krauß, Hamid Dashtbani, Alexandra Dmitrienko</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07596">https://arxiv.org/abs/2506.07596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07596">https://arxiv.org/pdf/2506.07596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07596]] TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts(https://arxiv.org/abs/2506.07596)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Machine learning is advancing rapidly, with applications bringing notable benefits, such as improvements in translation and code generation. Models like ChatGPT, powered by Large Language Models (LLMs), are increasingly integrated into daily life. However, alongside these benefits, LLMs also introduce social risks. Malicious users can exploit LLMs by submitting harmful prompts, such as requesting instructions for illegal activities. To mitigate this, models often include a security mechanism that automatically rejects such harmful prompts. However, they can be bypassed through LLM jailbreaks. Current jailbreaks often require significant manual effort, high computational costs, or result in excessive model modifications that may degrade regular utility. We introduce TwinBreak, an innovative safety alignment removal method. Building on the idea that the safety mechanism operates like an embedded backdoor, TwinBreak identifies and prunes parameters responsible for this functionality. By focusing on the most relevant model layers, TwinBreak performs fine-grained analysis of parameters essential to model utility and safety. TwinBreak is the first method to analyze intermediate outputs from prompts with high structural and content similarity to isolate safety parameters. We present the TwinPrompt dataset containing 100 such twin prompts. Experiments confirm TwinBreak's effectiveness, achieving 89% to 98% success rates with minimal computational requirements across 16 LLMs from five vendors.</li>
</ul>

<h3>Title: Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque</h3>
<ul>
<li><strong>Authors: </strong>Oscar Sainz, Naiara Perez, Julen Etxaniz, Joseba Fernandez de Landa, Itziar Aldabe, Iker García-Ferrero, Aimar Zabala, Ekhi Azurmendi, German Rigau, Eneko Agirre, Mikel Artetxe, Aitor Soroa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07597">https://arxiv.org/abs/2506.07597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07597">https://arxiv.org/pdf/2506.07597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07597]] Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque(https://arxiv.org/abs/2506.07597)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Instructing language models with user intent requires large instruction datasets, which are only available for a limited set of languages. In this paper, we explore alternatives to conventional instruction adaptation pipelines in low-resource scenarios. We assume a realistic scenario for low-resource languages, where only the following are available: corpora in the target language, existing open-weight multilingual base and instructed backbone LLMs, and synthetically generated instructions sampled from the instructed backbone. We present a comprehensive set of experiments for Basque that systematically study different combinations of these components evaluated on benchmarks and human preferences from 1,680 participants. Our conclusions show that target language corpora are essential, with synthetic instructions yielding robust models, and, most importantly, that using as backbone an instruction-tuned model outperforms using a base non-instructed model, and improved results when scaling up. Using Llama 3.1 instruct 70B as backbone our model comes near frontier models of much larger sizes for Basque, without using any Basque data apart from the 1.2B word corpora. We release code, models, instruction datasets, and human preferences to support full reproducibility in future research on low-resource language adaptation.</li>
</ul>

<h3>Title: SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07600">https://arxiv.org/abs/2506.07600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07600">https://arxiv.org/pdf/2506.07600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07600]] SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding(https://arxiv.org/abs/2506.07600)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Despite recent advances in retrieval-augmented generation (RAG) for video understanding, effectively understanding long-form video content remains underexplored due to the vast scale and high complexity of video data. Current RAG approaches typically segment videos into fixed-length chunks, which often disrupts the continuity of contextual information and fails to capture authentic scene boundaries. Inspired by the human ability to naturally organize continuous experiences into coherent scenes, we present SceneRAG, a unified framework that leverages large language models to segment videos into narrative-consistent scenes by processing ASR transcripts alongside temporal metadata. SceneRAG further sharpens these initial boundaries through lightweight heuristics and iterative correction. For each scene, the framework fuses information from both visual and textual modalities to extract entity relations and dynamically builds a knowledge graph, enabling robust multi-hop retrieval and generation that account for long-range dependencies. Experiments on the LongerVideos benchmark, featuring over 134 hours of diverse content, confirm that SceneRAG substantially outperforms prior baselines, achieving a win rate of up to 72.5 percent on generation tasks.</li>
</ul>

<h3>Title: SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07603">https://arxiv.org/abs/2506.07603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07603">https://arxiv.org/pdf/2506.07603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07603]] SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis(https://arxiv.org/abs/2506.07603)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Surgical video understanding is pivotal for enabling automated intraoperative decision-making, skill assessment, and postoperative quality improvement. However, progress in developing surgical video foundation models (FMs) remains hindered by the scarcity of large-scale, diverse datasets for pretraining and systematic evaluation. In this paper, we introduce \textbf{SurgBench}, a unified surgical video benchmarking framework comprising a pretraining dataset, \textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}. SurgBench offers extensive coverage of diverse surgical scenarios, with SurgBench-P encompassing 53 million frames across 22 surgical procedures and 11 specialties, and SurgBench-E providing robust evaluation across six categories (phase classification, camera motion, tool recognition, disease diagnosis, action classification, and organ detection) spanning 72 fine-grained tasks. Extensive experiments reveal that existing video FMs struggle to generalize across varied surgical video analysis tasks, whereas pretraining on SurgBench-P yields substantial performance improvements and superior cross-domain generalization to unseen procedures and modalities. Our dataset and code are available upon request.</li>
</ul>

<h3>Title: TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems</h3>
<ul>
<li><strong>Authors: </strong>Marco Di Gennaro, Giovanni De Lucia, Stefano Longari, Stefano Zanero, Michele Carminati</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07605">https://arxiv.org/abs/2506.07605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07605">https://arxiv.org/pdf/2506.07605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07605]] TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems(https://arxiv.org/abs/2506.07605)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning has emerged as a privacy-oriented alternative to centralized Machine Learning, enabling collaborative model training without direct data sharing. While extensively studied for neural networks, the security and privacy implications of tree-based models remain underexplored. This work introduces TimberStrike, an optimization-based dataset reconstruction attack targeting horizontally federated tree-based models. Our attack, carried out by a single client, exploits the discrete nature of decision trees by using split values and decision paths to infer sensitive training data from other clients. We evaluate TimberStrike on State-of-the-Art federated gradient boosting implementations across multiple frameworks, including Flower, NVFlare, and FedTree, demonstrating their vulnerability to privacy breaches. On a publicly available stroke prediction dataset, TimberStrike consistently reconstructs between 73.05% and 95.63% of the target dataset across all implementations. We further analyze Differential Privacy, showing that while it partially mitigates the attack, it also significantly degrades model performance. Our findings highlight the need for privacy-preserving mechanisms specifically designed for tree-based Federated Learning systems, and we provide preliminary insights into their design.</li>
</ul>

<h3>Title: PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels</h3>
<ul>
<li><strong>Authors: </strong>Peyman Rostami, Vahid Rahimzadeh, Ali Adibi, Azadeh Shakery</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07606">https://arxiv.org/abs/2506.07606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07606">https://arxiv.org/pdf/2506.07606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07606]] PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels(https://arxiv.org/abs/2506.07606)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Stance detection identifies the viewpoint expressed in text toward a specific target, such as a political figure. While previous datasets have focused primarily on tweet-level stances from established platforms, user-level stance resources, especially on emerging platforms like Bluesky remain scarce. User-level stance detection provides a more holistic view by considering a user's complete posting history rather than isolated posts. We present the first stance detection dataset for the 2024 U.S. presidential election, collected from Bluesky and centered on Kamala Harris and Donald Trump. The dataset comprises 16,044 user-target stance pairs enriched with engagement metadata, interaction graphs, and user posting histories. PolitiSky24 was created using a carefully evaluated pipeline combining advanced information retrieval and large language models, which generates stance labels with supporting rationales and text spans for transparency. The labeling approach achieves 81\% accuracy with scalable LLMs. This resource addresses gaps in political stance analysis through its timeliness, open-data nature, and user-level perspective. The dataset is available at this https URL</li>
</ul>

<h3>Title: Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation</h3>
<ul>
<li><strong>Authors: </strong>Roman Kyslyi, Yuliia Maksymiuk, Ihor Pysmennyi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07617">https://arxiv.org/abs/2506.07617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07617">https://arxiv.org/pdf/2506.07617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07617]] Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation(https://arxiv.org/abs/2506.07617)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper we introduce the first effort to adapt large language models (LLMs) to the Ukrainian dialect (in our case Hutsul), a low-resource and morphologically complex dialect spoken in the Carpathian Highlands. We created a parallel corpus of 9852 dialect-to-standard Ukrainian sentence pairs and a dictionary of 7320 dialectal word mappings. We also addressed data shortage by proposing an advanced Retrieval-Augmented Generation (RAG) pipeline to generate synthetic parallel translation pairs, expanding the corpus with 52142 examples. We have fine-tuned multiple open-source LLMs using LoRA and evaluated them on a standard-to-dialect translation task, also comparing with few-shot GPT-4o translation. In the absence of human annotators, we adopt a multi-metric evaluation strategy combining BLEU, chrF++, TER, and LLM-based judgment (GPT-4o). The results show that even small(7B) finetuned models outperform zero-shot baselines such as GPT-4o across both automatic and LLM-evaluated metrics. All data, models, and code are publicly released at: this https URL</li>
</ul>

<h3>Title: LoRMA: Low-Rank Multiplicative Adaptation for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Harsh Bihany, Shubham Patel, Ashutosh Modi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07621">https://arxiv.org/abs/2506.07621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07621">https://arxiv.org/pdf/2506.07621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07621]] LoRMA: Low-Rank Multiplicative Adaptation for LLMs(https://arxiv.org/abs/2506.07621)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have shown remarkable capabilities in the NLP domain. Their effectiveness can mainly be attributed to their ability to adapt to an array of downstream tasks. However, generally, full fine-tuning is a computationally expensive job. To mitigate this, many techniques have been developed that prime efficiency, a prominent one being Low-Rank Adaptation (LoRA). However, LoRA and its variants employ re-parametrized additive updates. In this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which shifts the paradigm of additive updates to a richer space of matrix multiplicative transformations. We tackle challenges such as computational complexity and rank bottleneck of matrix multiplication by effectively re-ordering operations and introducing rank inflation strategies. We conduct extensive experiments to demonstrate the effectiveness of our approach in terms of various evaluation metrics.</li>
</ul>

<h3>Title: Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks</h3>
<ul>
<li><strong>Authors: </strong>Ali Hariri, Álvaro Arroyo, Alessio Gravina, Moshe Eliasof, Carola-Bibiane Schönlieb, Davide Bacciu, Kamyar Azizzadenesheli, Xiaowen Dong, Pierre Vandergheynst</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07624">https://arxiv.org/abs/2506.07624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07624">https://arxiv.org/pdf/2506.07624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07624]] Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks(https://arxiv.org/abs/2506.07624)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>ChebNet, one of the earliest spectral GNNs, has largely been overshadowed by Message Passing Neural Networks (MPNNs), which gained popularity for their simplicity and effectiveness in capturing local graph structure. Despite their success, MPNNs are limited in their ability to capture long-range dependencies between nodes. This has led researchers to adapt MPNNs through rewiring or make use of Graph Transformers, which compromises the computational efficiency that characterized early spatial message-passing architectures, and typically disregards the graph structure. Almost a decade after its original introduction, we revisit ChebNet to shed light on its ability to model distant node interactions. We find that out-of-box, ChebNet already shows competitive advantages relative to classical MPNNs and GTs on long-range benchmarks, while maintaining good scalability properties for high-order polynomials. However, we uncover that this polynomial expansion leads ChebNet to an unstable regime during training. To address this limitation, we cast ChebNet as a stable and non-dissipative dynamical system, which we coin Stable-ChebNet. Our Stable-ChebNet model allows for stable information propagation, and has controllable dynamics which do not require the use of eigendecompositions, positional encodings, or graph rewiring. Across several benchmarks, Stable-ChebNet achieves near state-of-the-art performance.</li>
</ul>

<h3>Title: Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation</h3>
<ul>
<li><strong>Authors: </strong>Kseniia Petukhova, Ekaterina Kochmar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07626">https://arxiv.org/abs/2506.07626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07626">https://arxiv.org/pdf/2506.07626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07626]] Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation(https://arxiv.org/abs/2506.07626)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) hold great promise for educational applications, particularly in intelligent tutoring systems. However, effective tutoring requires alignment with pedagogical strategies - something current LLMs lack without task-specific adaptation. In this work, we explore whether fine-grained annotation of teacher intents can improve the quality of LLM-generated tutoring responses. We focus on MathDial, a dialog dataset for math instruction, and apply an automated annotation framework to re-annotate a portion of the dataset using a detailed taxonomy of eleven pedagogical intents. We then fine-tune an LLM using these new annotations and compare its performance to models trained on the original four-category taxonomy. Both automatic and qualitative evaluations show that the fine-grained model produces more pedagogically aligned and effective responses. Our findings highlight the value of intent specificity for controlled text generation in educational settings, and we release our annotated data and code to facilitate further research.</li>
</ul>

<h3>Title: Event-Priori-Based Vision-Language Model for Efficient Visual Understanding</h3>
<ul>
<li><strong>Authors: </strong>Haotong Qin, Cheng Hu, Michele Magno</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07627">https://arxiv.org/abs/2506.07627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07627">https://arxiv.org/pdf/2506.07627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07627]] Event-Priori-Based Vision-Language Model for Efficient Visual Understanding(https://arxiv.org/abs/2506.07627)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM)-based Vision-Language Models (VLMs) have substantially extended the boundaries of visual understanding capabilities. However, their high computational demands hinder deployment on resource-constrained edge devices. A key source of inefficiency stems from the VLM's need to process dense and redundant visual information. Visual inputs contain significant regions irrelevant to text semantics, rendering the associated computations ineffective for inference. This paper introduces a novel Event-Priori-Based Vision-Language Model, termed EP-VLM. Its core contribution is a novel mechanism leveraging motion priors derived from dynamic event vision to enhance VLM efficiency. Inspired by human visual cognition, EP-VLM first employs event data to guide the patch-wise sparsification of RGB visual inputs, progressively concentrating VLM computation on salient regions of the visual input. Subsequently, we construct a position-preserving tokenization strategy for the visual encoder within the VLM architecture. This strategy processes the event-guided, unstructured, sparse visual input while accurately preserving positional understanding within the visual input. Experimental results demonstrate that EP-VLM achieves significant efficiency improvements while maintaining nearly lossless accuracy compared to baseline models from the Qwen2-VL series. For instance, against the original Qwen2-VL-2B, EP-VLM achieves 50% FLOPs savings while retaining 98% of the original accuracy on the RealWorldQA dataset. This work demonstrates the potential of event-based vision priors for improving VLM inference efficiency, paving the way for creating more efficient and deployable VLMs for sustainable visual understanding at the edge.</li>
</ul>

<h3>Title: Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline</h3>
<ul>
<li><strong>Authors: </strong>Brian Gordon, Yonatan Bitton, Andreea Marzoca, Yasumasa Onoe, Xiao Wang, Daniel Cohen-Or, Idan Szpektor</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07631">https://arxiv.org/abs/2506.07631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07631">https://arxiv.org/pdf/2506.07631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07631]] Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline(https://arxiv.org/abs/2506.07631)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (VLMs) now generate highly detailed, paragraphlength image captions, yet evaluating their factual accuracy remains challenging. Current methods often miss fine-grained errors, being designed for shorter texts or lacking datasets with verified inaccuracies. We introduce DOCCI-Critique, a benchmark with 1,400 VLM-generated paragraph captions (100 images, 14 VLMs) featuring over 10,216 sentence-level human annotations of factual correctness and explanatory rationales for errors, all within paragraph context. Building on this, we develop VNLI-Critique, a model for automated sentence-level factuality classification and critique generation. We highlight three key applications: (1) VNLI-Critique demonstrates robust generalization, validated by state-of-the-art performance on the M-HalDetect benchmark and strong results in CHOCOLATE claim verification. (2) The VNLI-Critique driven AutoRater for DOCCI-Critique provides reliable VLM rankings, showing excellent alignment with human factuality judgments (e.g., 0.98 Spearman). (3) An innovative Critic-and-Revise pipeline, where critiques from VNLI-Critique guide LLM-based corrections, achieves substantial improvements in caption factuality (e.g., a 46% gain on DetailCaps-4870). Our work offers a crucial benchmark alongside practical tools, designed to significantly elevate the standards for fine-grained evaluation and foster the improvement of VLM image understanding. Project page: this https URL</li>
</ul>

<h3>Title: HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuchong Long, Wen Sun, Ningxiao Sun, Wenxiao Wang, Chao Li, Shan Yin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07637">https://arxiv.org/abs/2506.07637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07637">https://arxiv.org/pdf/2506.07637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07637]] HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition(https://arxiv.org/abs/2506.07637)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automated pollen recognition is vital to paleoclimatology, biodiversity monitoring, and public health, yet conventional methods are hampered by inefficiency and subjectivity. Existing deep learning models often struggle to achieve the requisite localization accuracy for microscopic targets like pollen, which are characterized by their minute size, indistinct edges, and complex backgrounds. To overcome this limitation, we introduce HieraEdgeNet, a multi-scale edge-enhancement framework. The framework's core innovation is the introduction of three synergistic modules: the Hierarchical Edge Module (HEM), which explicitly extracts a multi-scale pyramid of edge features that corresponds to the semantic hierarchy at early network stages; the Synergistic Edge Fusion (SEF) module, for deeply fusing these edge priors with semantic information at each respective scale; and the Cross Stage Partial Omni-Kernel Module (CSPOKM), which maximally refines the most detail-rich feature layers using an Omni-Kernel operator - comprising anisotropic large-kernel convolutions and mixed-domain attention - all within a computationally efficient Cross-Stage Partial (CSP) framework. On a large-scale dataset comprising 120 pollen classes, HieraEdgeNet achieves a mean Average Precision (mAP@.5) of 0.9501, significantly outperforming state-of-the-art baseline models such as YOLOv12n and RT-DETR. Furthermore, qualitative analysis confirms that our approach generates feature representations that are more precisely focused on object boundaries. By systematically integrating edge information, HieraEdgeNet provides a robust and powerful solution for high-precision, high-efficiency automated detection of microscopic objects.</li>
</ul>

<h3>Title: TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review</h3>
<ul>
<li><strong>Authors: </strong>Yuan Chang, Ziyue Li, Hengyuan Zhang, Yuanbo Kong, Yanru Wu, Zhijiang Guo, Ngai Wong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07642">https://arxiv.org/abs/2506.07642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07642">https://arxiv.org/pdf/2506.07642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07642]] TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review(https://arxiv.org/abs/2506.07642)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have shown significant potential in assisting peer review, current methods often struggle to generate thorough and insightful reviews while maintaining efficiency. In this paper, we propose TreeReview, a novel framework that models paper review as a hierarchical and bidirectional question-answering process. TreeReview first constructs a tree of review questions by recursively decomposing high-level questions into fine-grained sub-questions and then resolves the question tree by iteratively aggregating answers from leaf to root to get the final review. Crucially, we incorporate a dynamic question expansion mechanism to enable deeper probing by generating follow-up questions when needed. We construct a benchmark derived from ICLR and NeurIPS venues to evaluate our method on full review generation and actionable feedback comments generation tasks. Experimental results of both LLM-based and human evaluation show that TreeReview outperforms strong baselines in providing comprehensive, in-depth, and expert-aligned review feedback, while reducing LLM token usage by up to 80% compared to computationally intensive approaches. Our code and benchmark dataset are available at this https URL.</li>
</ul>

<h3>Title: Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models</h3>
<ul>
<li><strong>Authors: </strong>Maciej Chrabąszcz, Katarzyna Lorenc, Karolina Seweryn</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07645">https://arxiv.org/abs/2506.07645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07645">https://arxiv.org/pdf/2506.07645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07645]] Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models(https://arxiv.org/abs/2506.07645)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated impressive capabilities across various natural language processing (NLP) tasks in recent years. However, their susceptibility to jailbreaks and perturbations necessitates additional evaluations. Many LLMs are multilingual, but safety-related training data contains mainly high-resource languages like English. This can leave them vulnerable to perturbations in low-resource languages such as Polish. We show how surprisingly strong attacks can be cheaply created by altering just a few characters and using a small proxy model for word importance calculation. We find that these character and word-level attacks drastically alter the predictions of different LLMs, suggesting a potential vulnerability that can be used to circumvent their internal safety mechanisms. We validate our attack construction methodology on Polish, a low-resource language, and find potential vulnerabilities of LLMs in this language. Additionally, we show how it can be extended to other languages. We release the created datasets and code for further research.</li>
</ul>

<h3>Title: FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images</h3>
<ul>
<li><strong>Authors: </strong>Hangbei Cheng, Xiaorong Dong, Xueyu Liu, Jianan Zhang, Xuetao Ma, Mingqiang Wei, Liansheng Wang, Junxin Chen, Yongfei Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07652">https://arxiv.org/abs/2506.07652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07652">https://arxiv.org/pdf/2506.07652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07652]] FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images(https://arxiv.org/abs/2506.07652)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate lesion segmentation in histopathology images is essential for diagnostic interpretation and quantitative analysis, yet it remains challenging due to the limited availability of costly pixel-level annotations. To address this, we propose FMaMIL, a novel two-stage framework for weakly supervised lesion segmentation based solely on image-level labels. In the first stage, a lightweight Mamba-based encoder is introduced to capture long-range dependencies across image patches under the MIL paradigm. To enhance spatial sensitivity and structural awareness, we design a learnable frequency-domain encoding module that supplements spatial-domain features with spectrum-based information. CAMs generated in this stage are used to guide segmentation training. In the second stage, we refine the initial pseudo labels via a CAM-guided soft-label supervision and a self-correction mechanism, enabling robust training even under label noise. Extensive experiments on both public and private histopathology datasets demonstrate that FMaMIL outperforms state-of-the-art weakly supervised methods without relying on pixel-level annotations, validating its effectiveness and potential for digital pathology applications.</li>
</ul>

<h3>Title: Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping</h3>
<ul>
<li><strong>Authors: </strong>Nitin Sharma, Thomas Wolfers, Çağatay Yıldız</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07658">https://arxiv.org/abs/2506.07658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07658">https://arxiv.org/pdf/2506.07658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07658]] Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping(https://arxiv.org/abs/2506.07658)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The paper addresses two critical challenges in language model (LM) evaluation: creating reliable domain-specific benchmarks and understanding knowledge representation during domain adaptation. We introduce a deterministic pipeline that converts raw domain corpora into completion-type benchmarks without relying on LMs or human curation, eliminating benchmark contamination issues while enabling evaluation on the latest domain data. Our approach generates domain-specific keywords and related word lists using TF and Term TF-IDF methods and constructs prompt-target pairs. We evaluate models by measuring their ability to complete these prompts with the correct domain-specific targets, providing a direct assessment of domain knowledge with low computational cost. Through comprehensive experiments across multiple models (GPT-2 medium/XL, Llama-2/3.1, OLMo-2, Qwen-2, Mistral) and domains, we demonstrate that our benchmark strongly correlates with expert-generated benchmarks while providing a more accurate measure of domain knowledge than traditional perplexity metrics. We reveal that domain adaptation happens rapidly in smaller models (within 500 steps) and illustrate a new approach to domain knowledge evaluation in base models during training for early stopping. By extending mechanistic analysis to domain adaptation, we discover that initial-to-mid layers are primarily responsible for attribute extraction, while later layers focus on next token prediction. Furthermore, we show that during adaptation, forgetting begins in the middle layers, where attribute extraction happens and is amplified in later layers. Our work provides both a practical evaluation methodology for domain-specific LMs and novel insights into knowledge representation during adaptation, with implications for more efficient fine-tuning strategies and targeted approaches to mitigate catastrophic forgetting.</li>
</ul>

<h3>Title: The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well</h3>
<ul>
<li><strong>Authors: </strong>Meir Feder, Ruediger Urbanke, Yaniv Fogel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07661">https://arxiv.org/abs/2506.07661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07661">https://arxiv.org/pdf/2506.07661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07661]] The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well(https://arxiv.org/abs/2506.07661)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A fundamental question in modern machine learning is why large, over-parameterized models, such as deep neural networks and transformers, tend to generalize well, even when their number of parameters far exceeds the number of training samples. We investigate this phenomenon through the lens of information theory, grounded in universal learning theory. Specifically, we study a Bayesian mixture learner with log-loss and (almost) uniform prior over an expansive hypothesis class. Our key result shows that the learner's regret is not determined by the overall size of the hypothesis class, but rather by the cumulative probability of all models that are close, in Kullback-Leibler divergence distance, to the true data-generating process. We refer to this cumulative probability as the weight of the hypothesis. This leads to a natural notion of model simplicity: simple models are those with large weight and thus require fewer samples to generalize, while complex models have small weight and need more data. This perspective provides a rigorous and intuitive explanation for why over-parameterized models often avoid overfitting: the presence of simple hypotheses allows the posterior to concentrate on them when supported by the data. We further bridge theory and practice by recalling that stochastic gradient descent with Langevin dynamics samples from the correct posterior distribution, enabling our theoretical learner to be approximated using standard machine learning methods combined with ensemble learning. Our analysis yields non-uniform regret bounds and aligns with key practical concepts such as flat minima and model distillation. The results apply broadly across online, batch, and supervised learning settings, offering a unified and principled understanding of the generalization behavior of modern AI systems.</li>
</ul>

<h3>Title: ProARD: progressive adversarial robustness distillation: provide wide range of robust students</h3>
<ul>
<li><strong>Authors: </strong>Seyedhamidreza Mousavi, Seyedali Mousavi, Masoud Daneshtalab</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07666">https://arxiv.org/abs/2506.07666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07666">https://arxiv.org/pdf/2506.07666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07666]] ProARD: progressive adversarial robustness distillation: provide wide range of robust students(https://arxiv.org/abs/2506.07666)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial Robustness Distillation (ARD) has emerged as an effective method to enhance the robustness of lightweight deep neural networks against adversarial attacks. Current ARD approaches have leveraged a large robust teacher network to train one robust lightweight student. However, due to the diverse range of edge devices and resource constraints, current approaches require training a new student network from scratch to meet specific constraints, leading to substantial computational costs and increased CO2 emissions. This paper proposes Progressive Adversarial Robustness Distillation (ProARD), enabling the efficient one-time training of a dynamic network that supports a diverse range of accurate and robust student networks without requiring retraining. We first make a dynamic deep neural network based on dynamic layers by encompassing variations in width, depth, and expansion in each design stage to support a wide range of architectures. Then, we consider the student network with the largest size as the dynamic teacher network. ProARD trains this dynamic network using a weight-sharing mechanism to jointly optimize the dynamic teacher network and its internal student networks. However, due to the high computational cost of calculating exact gradients for all the students within the dynamic network, a sampling mechanism is required to select a subset of students. We show that random student sampling in each iteration fails to produce accurate and robust students.</li>
</ul>

<h3>Title: ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views</h3>
<ul>
<li><strong>Authors: </strong>Xiaohan Lu, Jiaye Fu, Jiaqi Zhang, Zetian Song, Chuanmin Jia, Siwei Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07670">https://arxiv.org/abs/2506.07670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07670">https://arxiv.org/pdf/2506.07670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07670]] ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views(https://arxiv.org/abs/2506.07670)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Feed-forward 3D Gaussian Splatting (3DGS) has recently demonstrated promising results for novel view synthesis (NVS) from sparse input views, particularly under narrow-baseline conditions. However, its performance significantly degrades in wide-baseline scenarios due to limited texture details and geometric inconsistencies across views. To address these challenges, in this paper, we propose ProSplat, a two-stage feed-forward framework designed for high-fidelity rendering under wide-baseline conditions. The first stage involves generating 3D Gaussian primitives via a 3DGS generator. In the second stage, rendered views from these primitives are enhanced through an improvement model. Specifically, this improvement model is based on a one-step diffusion model, further optimized by our proposed Maximum Overlap Reference view Injection (MORI) and Distance-Weighted Epipolar Attention (DWEA). MORI supplements missing texture and color by strategically selecting a reference view with maximum viewpoint overlap, while DWEA enforces geometric consistency using epipolar constraints. Additionally, we introduce a divide-and-conquer training strategy that aligns data distributions between the two stages through joint optimization. We evaluate ProSplat on the RealEstate10K and DL3DV-10K datasets under wide-baseline settings. Experimental results demonstrate that ProSplat achieves an average improvement of 1 dB in PSNR compared to recent SOTA methods.</li>
</ul>

<h3>Title: How Benchmark Prediction from Fewer Data Misses the Mark</h3>
<ul>
<li><strong>Authors: </strong>Guanhua Zhang, Florian E. Dorner, Moritz Hardt</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07673">https://arxiv.org/abs/2506.07673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07673">https://arxiv.org/pdf/2506.07673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07673]] How Benchmark Prediction from Fewer Data Misses the Mark(https://arxiv.org/abs/2506.07673)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) evaluation is increasingly costly, prompting interest in methods that speed up evaluation by shrinking benchmark datasets. Benchmark prediction (also called efficient LLM evaluation) aims to select a small subset of evaluation points and predict overall benchmark performance from that subset. In this paper, we systematically assess the strengths and limitations of 11 benchmark prediction methods across 19 diverse benchmarks. First, we identify a highly competitive baseline: Take a random sample and fit a regression model on the sample to predict missing entries. Outperforming most existing methods, this baseline challenges the assumption that careful subset selection is necessary for benchmark prediction. Second, we discover that all existing methods crucially depend on model similarity. They work best when interpolating scores among similar models. The effectiveness of benchmark prediction sharply declines when new models have higher accuracy than previously seen models. In this setting of extrapolation, none of the previous methods consistently beat a simple average over random samples. To improve over the sample average, we introduce a new method inspired by augmented inverse propensity weighting. This method consistently outperforms the random sample average even for extrapolation. However, its performance still relies on model similarity and the gains are modest in general. This shows that benchmark prediction fails just when it is most needed: at the evaluation frontier, where the goal is to evaluate new models of unknown capabilities.</li>
</ul>

<h3>Title: Training Superior Sparse Autoencoders for Instruct Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Li, Haoran Ye, Yukun Chen, Xinyue Li, Lei Zhang, Hamid Alinejad-Rokny, Jimmy Chih-Hsien Peng, Min Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07691">https://arxiv.org/abs/2506.07691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07691">https://arxiv.org/pdf/2506.07691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07691]] Training Superior Sparse Autoencoders for Instruct Models(https://arxiv.org/abs/2506.07691)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) grow in scale and capability, understanding their internal mechanisms becomes increasingly critical. Sparse autoencoders (SAEs) have emerged as a key tool in mechanistic interpretability, enabling the extraction of human-interpretable features from LLMs. However, existing SAE training methods are primarily designed for base models, resulting in reduced reconstruction quality and interpretability when applied to instruct models. To bridge this gap, we propose $\underline{\textbf{F}}$inetuning-$\underline{\textbf{a}}$ligned $\underline{\textbf{S}}$equential $\underline{\textbf{T}}$raining ($\textit{FAST}$), a novel training method specifically tailored for instruct models. $\textit{FAST}$ aligns the training process with the data distribution and activation patterns characteristic of instruct models, resulting in substantial improvements in both reconstruction and feature interpretability. On Qwen2.5-7B-Instruct, $\textit{FAST}$ achieves a mean squared error of 0.6468 in token reconstruction, significantly outperforming baseline methods with errors of 5.1985 and 1.5096. In feature interpretability, $\textit{FAST}$ yields a higher proportion of high-quality features, for Llama3.2-3B-Instruct, $21.1\%$ scored in the top range, compared to $7.0\%$ and $10.2\%$ for $\textit{BT(P)}$ and $\textit{BT(F)}$. Surprisingly, we discover that intervening on the activations of special tokens via the SAEs leads to improvements in output quality, suggesting new opportunities for fine-grained control of model behavior. Code, data, and 240 trained SAEs are available at this https URL.</li>
</ul>

<h3>Title: OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Jens Piekenbrinck, Christian Schmidt, Alexander Hermans, Narunas Vaskevicius, Timm Linder, Bastian Leibe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07697">https://arxiv.org/abs/2506.07697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07697">https://arxiv.org/pdf/2506.07697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07697]] OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting(https://arxiv.org/abs/2506.07697)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has emerged as a powerful representation for neural scene reconstruction, offering high-quality novel view synthesis while maintaining computational efficiency. In this paper, we extend the capabilities of 3DGS beyond pure scene representation by introducing an approach for open-vocabulary 3D instance segmentation without requiring manual labeling, termed OpenSplat3D. Our method leverages feature-splatting techniques to associate semantic information with individual Gaussians, enabling fine-grained scene understanding. We incorporate Segment Anything Model instance masks with a contrastive loss formulation as guidance for the instance features to achieve accurate instance-level segmentation. Furthermore, we utilize language embeddings of a vision-language model, allowing for flexible, text-driven instance identification. This combination enables our system to identify and segment arbitrary objects in 3D scenes based on natural language descriptions. We show results on LERF-mask and LERF-OVS as well as the full ScanNet++ validation set, demonstrating the effectiveness of our approach.</li>
</ul>

<h3>Title: NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuxiao Yang, Peihao Li, Yuhong Zhang, Junzhe Lu, Xianglong He, Minghan Qin, Weitao Wang, Haoqian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07698">https://arxiv.org/abs/2506.07698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07698">https://arxiv.org/pdf/2506.07698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07698]] NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation(https://arxiv.org/abs/2506.07698)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D AI-generated content (AIGC) has made it increasingly accessible for anyone to become a 3D content creator. While recent methods leverage Score Distillation Sampling to distill 3D objects from pretrained image diffusion models, they often suffer from inadequate 3D priors, leading to insufficient multi-view consistency. In this work, we introduce NOVA3D, an innovative single-image-to-3D generation framework. Our key insight lies in leveraging strong 3D priors from a pretrained video diffusion model and integrating geometric information during multi-view video fine-tuning. To facilitate information exchange between color and geometric domains, we propose the Geometry-Temporal Alignment (GTA) attention mechanism, thereby improving generalization and multi-view consistency. Moreover, we introduce the de-conflict geometry fusion algorithm, which improves texture fidelity by addressing multi-view inaccuracies and resolving discrepancies in pose alignment. Extensive experiments validate the superiority of NOVA3D over existing baselines.</li>
</ul>

<h3>Title: Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Boris Martirosyan, Alexey Karmanov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07706">https://arxiv.org/abs/2506.07706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07706">https://arxiv.org/pdf/2506.07706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07706]] Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation(https://arxiv.org/abs/2506.07706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Latent diffusion models (LDMs) achieve state-of-the-art performance across various tasks, including image generation and video synthesis. However, they generally lack robustness, a limitation that remains not fully explored in current research. In this paper, we propose several methods to address this gap. First, we hypothesize that the robustness of LDMs primarily should be measured without their text encoder, because if we take and explore the whole architecture, the problems of image generator and text encoders wll be fused. Second, we introduce novel data augmentation techniques designed to reveal robustness shortcomings in LDMs when processing diverse textual prompts. We then fine-tune Stable Diffusion 3 and Stable Diffusion XL models using Dreambooth, incorporating these proposed augmentation methods across multiple tasks. Finally, we propose a novel evaluation pipeline specifically tailored to assess the robustness of LDMs fine-tuned via Dreambooth.</li>
</ul>

<h3>Title: Consistent Video Editing as Flow-Driven Image-to-Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Ge Wang, Songlin Fan, Hangxu Liu, Quanjian Song, Hewei Wang, Jinfeng Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07713">https://arxiv.org/abs/2506.07713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07713">https://arxiv.org/pdf/2506.07713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07713]] Consistent Video Editing as Flow-Driven Image-to-Video Generation(https://arxiv.org/abs/2506.07713)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the prosper of video diffusion models, down-stream applications like video editing have been significantly promoted without consuming much computational cost. One particular challenge in this task lies at the motion transfer process from the source video to the edited one, where it requires the consideration of the shape deformation in between, meanwhile maintaining the temporal consistency in the generated video sequence. However, existing methods fail to model complicated motion patterns for video editing, and are fundamentally limited to object replacement, where tasks with non-rigid object motions like multi-object and portrait editing are largely neglected. In this paper, we observe that optical flows offer a promising alternative in complex motion modeling, and present FlowV2V to re-investigate video editing as a task of flow-driven Image-to-Video (I2V) generation. Specifically, FlowV2V decomposes the entire pipeline into first-frame editing and conditional I2V generation, and simulates pseudo flow sequence that aligns with the deformed shape, thus ensuring the consistency during editing. Experimental results on DAVIS-EDIT with improvements of 13.67% and 50.66% on DOVER and warping error illustrate the superior temporal consistency and sample quality of FlowV2V compared to existing state-of-the-art ones. Furthermore, we conduct comprehensive ablation studies to analyze the internal functionalities of the first-frame paradigm and flow alignment in the proposed method.</li>
</ul>

<h3>Title: Profiling Electric Vehicles via Early Charging Voltage Patterns</h3>
<ul>
<li><strong>Authors: </strong>Francesco Marchiori, Denis Donadel, Alessandro Brighente, Mauro Conti</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07714">https://arxiv.org/abs/2506.07714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07714">https://arxiv.org/pdf/2506.07714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07714]] Profiling Electric Vehicles via Early Charging Voltage Patterns(https://arxiv.org/abs/2506.07714)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, steal</a></li>
<li><strong>Abstract: </strong>Electric Vehicles (EVs) are rapidly gaining adoption as a sustainable alternative to fuel-powered vehicles, making secure charging infrastructure essential. Despite traditional authentication protocols, recent results showed that attackers may steal energy through tailored relay attacks. One countermeasure is leveraging the EV's fingerprint on the current exchanged during charging. However, existing methods focus on the final charging stage, allowing malicious actors to consume substantial energy before being detected and repudiated. This underscores the need for earlier and more effective authentication methods to prevent unauthorized charging. Meanwhile, profiling raises privacy concerns, as uniquely identifying EVs through charging patterns could enable user tracking. In this paper, we propose a framework for uniquely identifying EVs using physical measurements from the early charging stages. We hypothesize that voltage behavior early in the process exhibits similar characteristics to current behavior in later stages. By extracting features from early voltage measurements, we demonstrate the feasibility of EV profiling. Our approach improves existing methods by enabling faster and more reliable vehicle identification. We test our solution on a dataset of 7408 usable charges from 49 EVs, achieving up to 0.86 accuracy. Feature importance analysis shows that near-optimal performance is possible with just 10 key features, improving efficiency alongside our lightweight models. This research lays the foundation for a novel authentication factor while exposing potential privacy risks from unauthorized access to charging data.</li>
</ul>

<h3>Title: Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU</h3>
<ul>
<li><strong>Authors: </strong>Vincenzo Timmel, Manfred Vogel, Daniel Perruchoud, Reza Kakooee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07726">https://arxiv.org/abs/2506.07726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07726">https://arxiv.org/pdf/2506.07726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07726]] Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU(https://arxiv.org/abs/2506.07726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a new long-form release of the Swiss Parliaments Corpus, converting entire multi-hour Swiss German debate sessions (each aligned with the official session protocols) into high-quality speech-text pairs. Our pipeline starts by transcribing all session audio into Standard German using Whisper Large-v3 under high-compute settings. We then apply a two-step GPT-4o correction process: first, GPT-4o ingests the raw Whisper output alongside the official protocols to refine misrecognitions, mainly named entities. Second, a separate GPT-4o pass evaluates each refined segment for semantic completeness. We filter out any segments whose Predicted BLEU score (derived from Whisper's average token log-probability) and GPT-4o evaluation score fall below a certain threshold. The final corpus contains 801 hours of audio, of which 751 hours pass our quality control. Compared to the original sentence-level SPC release, our long-form dataset achieves a 6-point BLEU improvement, demonstrating the power of combining robust ASR, LLM-based correction, and data-driven filtering for low-resource, domain-specific speech corpora.</li>
</ul>

<h3>Title: "I wasn't sure if this is indeed a security risk": Data-driven Understanding of Security Issue Reporting in GitHub Repositories of Open Source npm Packages</h3>
<ul>
<li><strong>Authors: </strong>Rajdeep Ghosh, Shiladitya De, Mainack Mondal</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07728">https://arxiv.org/abs/2506.07728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07728">https://arxiv.org/pdf/2506.07728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07728]] "I wasn't sure if this is indeed a security risk": Data-driven Understanding of Security Issue Reporting in GitHub Repositories of Open Source npm Packages(https://arxiv.org/abs/2506.07728)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The npm (Node Package Manager) ecosystem is the most important package manager for JavaScript development with millions of users. Consequently, a plethora of earlier work investigated how vulnerability reporting, patch propagation, and in general detection as well as resolution of security issues in such ecosystems can be facilitated. However, understanding the ground reality of security-related issue reporting by users (and bots) in npm-along with the associated challenges has been relatively less explored at scale. In this work, we bridge this gap by collecting 10,907,467 issues reported across GitHub repositories of 45,466 diverse npm packages. We found that the tags associated with these issues indicate the existence of only 0.13% security-related issues. However, our approach of manual analysis followed by developing high accuracy machine learning models identify 1,617,738 security-related issues which are not tagged as security-related (14.8% of all issues) as well as 4,461,934 comments made on these issues. We found that the bots which are in wide use today might not be sufficient for either detecting or offering assistance. Furthermore, our analysis of user-developer interaction data hints that many user-reported security issues might not be addressed by developers-they are not tagged as security-related issues and might be closed without valid justification. Consequently, a correlation analysis hints that the developers quickly handle security issues with known solutions (e.g., corresponding to CVE). However, security issues without such known solutions (even with reproducible code) might not be resolved. Our findings offer actionable insights for improving security management in open-source ecosystems, highlighting the need for smarter tools and better collaboration. The data and code for this work is available at this https URL</li>
</ul>

<h3>Title: Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07735">https://arxiv.org/abs/2506.07735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07735">https://arxiv.org/pdf/2506.07735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07735]] Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning(https://arxiv.org/abs/2506.07735)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Neural Architecture Representation Learning aims to transform network models into feature representations for predicting network attributes, playing a crucial role in deploying and designing networks for real-world applications. Recently, inspired by the success of transformers, transformer-based models integrated with Graph Neural Networks (GNNs) have achieved significant progress in representation learning. However, current methods still have some limitations. First, existing methods overlook hardware attribute information, which conflicts with the current trend of diversified deep learning hardware and limits the practical applicability of models. Second, current encoding approaches rely on static adjacency matrices to represent topological structures, failing to capture the structural differences between computational nodes, which ultimately compromises encoding effectiveness. In this paper, we introduce LeDG-Former, an innovative framework that addresses these limitations through the synergistic integration of language-based semantic embedding and dynamic graph representation learning. Specifically, inspired by large language models (LLMs), we propose a language embedding framework where both neural architectures and hardware platform specifications are projected into a unified semantic space through tokenization and LLM processing, enabling zero-shot prediction across different hardware platforms for the first time. Then, we propose a dynamic graph-based transformer for modeling neural architectures, resulting in improved neural architecture modeling performance. On the NNLQP benchmark, LeDG-Former surpasses previous methods, establishing a new SOTA while demonstrating the first successful cross-hardware latency prediction capability. Furthermore, our framework achieves superior performance on the cell-structured NAS-Bench-101 and NAS-Bench-201 datasets.</li>
</ul>

<h3>Title: AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization</h3>
<ul>
<li><strong>Authors: </strong>Lanjiong Li, Guanhua Zhao, Lingting Zhu, Zeyu Cai, Lequan Yu, Jian Zhang, Zeyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07738">https://arxiv.org/abs/2506.07738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07738">https://arxiv.org/pdf/2506.07738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07738]] AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization(https://arxiv.org/abs/2506.07738)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent research on generative models has primarily focused on creating product-ready visual outputs; however, designers often favor access to standardized asset libraries, a domain that has yet to be significantly enhanced by generative capabilities. Although open-world scenes provide ample raw materials for designers, efficiently extracting high-quality, standardized assets remains a challenge. To address this, we introduce AssetDropper, the first framework designed to extract assets from reference images, providing artists with an open-world asset palette. Our model adeptly extracts a front view of selected subjects from input images, effectively handling complex scenarios such as perspective distortion and subject occlusion. We establish a synthetic dataset of more than 200,000 image-subject pairs and a real-world benchmark with thousands more for evaluation, facilitating the exploration of future research in downstream tasks. Furthermore, to ensure precise asset extraction that aligns well with the image prompts, we employ a pre-trained reward model to fulfill a closed-loop with feedback. We design the reward model to perform an inverse task that pastes the extracted assets back into the reference sources, which assists training with additional consistency and mitigates hallucination. Extensive experiments show that, with the aid of reward-driven optimization, AssetDropper achieves the state-of-the-art results in asset extraction. Project page: this http URL.</li>
</ul>

<h3>Title: ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jing Zhong, Jun Yin, Peilin Li, Pengyu Zeng, Miao Zhang, Shuai Lu, Ran Luo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07739">https://arxiv.org/abs/2506.07739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07739">https://arxiv.org/pdf/2506.07739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07739]] ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models(https://arxiv.org/abs/2506.07739)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Architectural cultures across regions are characterized by stylistic diversity, shaped by historical, social, and technological contexts in addition to geograph-ical conditions. Understanding architectural styles requires the ability to describe and analyze the stylistic features of different architects from various regions through visual observations of architectural imagery. However, traditional studies of architectural culture have largely relied on subjective expert interpretations and historical literature reviews, often suffering from regional biases and limited ex-planatory scope. To address these challenges, this study proposes three core contributions: (1) We construct a professional architectural style dataset named ArchDiffBench, which comprises 1,765 high-quality architectural images and their corresponding style annotations, collected from different regions and historical periods. (2) We propose ArchiLense, an analytical framework grounded in Vision-Language Models and constructed using the ArchDiffBench dataset. By integrating ad-vanced computer vision techniques, deep learning, and machine learning algo-rithms, ArchiLense enables automatic recognition, comparison, and precise classi-fication of architectural imagery, producing descriptive language outputs that ar-ticulate stylistic differences. (3) Extensive evaluations show that ArchiLense achieves strong performance in architectural style recognition, with a 92.4% con-sistency rate with expert annotations and 84.5% classification accuracy, effec-tively capturing stylistic distinctions across images. The proposed approach transcends the subjectivity inherent in traditional analyses and offers a more objective and accurate perspective for comparative studies of architectural culture.</li>
</ul>

<h3>Title: Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images</h3>
<ul>
<li><strong>Authors: </strong>Yingping Liang, Ying Fu, Yutao Hu, Wenqi Shao, Jiaming Liu, Debing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07740">https://arxiv.org/abs/2506.07740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07740">https://arxiv.org/pdf/2506.07740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07740]] Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images(https://arxiv.org/abs/2506.07740)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Optical flow estimation is a crucial subfield of computer vision, serving as a foundation for video tasks. However, the real-world robustness is limited by animated synthetic datasets for training. This introduces domain gaps when applied to real-world applications and limits the benefits of scaling up datasets. To address these challenges, we propose \textbf{Flow-Anything}, a large-scale data generation framework designed to learn optical flow estimation from any single-view images in the real world. We employ two effective steps to make data scaling-up promising. First, we convert a single-view image into a 3D representation using advanced monocular depth estimation networks. This allows us to render optical flow and novel view images under a virtual camera. Second, we develop an Object-Independent Volume Rendering module and a Depth-Aware Inpainting module to model the dynamic objects in the 3D representation. These two steps allow us to generate realistic datasets for training from large-scale single-view images, namely \textbf{FA-Flow Dataset}. For the first time, we demonstrate the benefits of generating optical flow training data from large-scale real-world images, outperforming the most advanced unsupervised methods and supervised methods on synthetic datasets. Moreover, our models serve as a foundation model and enhance the performance of various downstream video tasks.</li>
</ul>

<h3>Title: E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time</h3>
<ul>
<li><strong>Authors: </strong>Adam Breuer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07747">https://arxiv.org/abs/2506.07747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07747">https://arxiv.org/pdf/2506.07747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07747]] E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time(https://arxiv.org/abs/2506.07747)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In this paper, we provide the first practical algorithms with provable guarantees for the problem of inferring the topics assigned to each document in an LDA topic model. This is the primary inference problem for many applications of topic models in social science, data exploration, and causal inference settings. We obtain this result by showing a novel non-gradient-based, combinatorial approach to estimating topic models. This yields algorithms that converge to near-optimal posterior probability in logarithmic parallel computation time (adaptivity) -- exponentially faster than any known LDA algorithm. We also show that our approach can provide interpretability guarantees such that each learned topic is formally associated with a known keyword. Finally, we show that unlike alternatives, our approach can maintain the independence assumptions necessary to use the learned topic model for downstream causal inference methods that allow researchers to study topics as treatments. In terms of practical performance, our approach consistently returns solutions of higher semantic quality than solutions from state-of-the-art LDA algorithms, neural topic models, and LLM-based topic models across a diverse range of text datasets and evaluation parameters.</li>
</ul>

<h3>Title: Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation</h3>
<ul>
<li><strong>Authors: </strong>Hyunsoo Kim, Donghyun Kim, Suhyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07750">https://arxiv.org/abs/2506.07750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07750">https://arxiv.org/pdf/2506.07750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07750]] Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation(https://arxiv.org/abs/2506.07750)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>How can we generate an image B' that satisfies A:A'::B:B', given the input images A,A' and B? Recent works have tackled this challenge through approaches like visual in-context learning or visual instruction. However, these methods are typically limited to specific models (e.g. InstructPix2Pix. Inpainting models) rather than general diffusion models (e.g. Stable Diffusion, SDXL). This dependency may lead to inherited biases or lower editing capabilities. In this paper, we propose Difference Inversion, a method that isolates only the difference from A and A' and applies it to B to generate a plausible B'. To address model dependency, it is crucial to structure prompts in the form of a "Full Prompt" suitable for input to stable diffusion models, rather than using an "Instruction Prompt". To this end, we accurately extract the Difference between A and A' and combine it with the prompt of B, enabling a plug-and-play application of the difference. To extract a precise difference, we first identify it through 1) Delta Interpolation. Additionally, to ensure accurate training, we propose the 2) Token Consistency Loss and 3) Zero Initialization of Token Embeddings. Our extensive experiments demonstrate that Difference Inversion outperforms existing baselines both quantitatively and qualitatively, indicating its ability to generate more feasible B' in a model-agnostic manner.</li>
</ul>

<h3>Title: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking</h3>
<ul>
<li><strong>Authors: </strong>Silin Gao, Antoine Bosselut, Samy Bengio, Emmanuel Abbe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07751">https://arxiv.org/abs/2506.07751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07751">https://arxiv.org/pdf/2506.07751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07751]] Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking(https://arxiv.org/abs/2506.07751)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that large language models (LLMs), especially smaller ones, often lack robustness in their reasoning. I.e., they tend to experience performance drops when faced with distribution shifts, such as changes to numerical or nominal variables, or insertions of distracting clauses. A possible strategy to address this involves generating synthetic data to further "instantiate" reasoning problems on potential variations. In contrast, our approach focuses on "abstracting" reasoning problems. This not only helps counteract distribution shifts but also facilitates the connection to symbolic tools for deriving solutions. We find that this abstraction process is better acquired through reinforcement learning (RL) than just supervised fine-tuning, which often fails to produce faithful abstractions. Our method, AbstraL -- which promotes abstract reasoning in LLMs using RL on granular abstraction data -- significantly mitigates performance degradation on recent GSM perturbation benchmarks.</li>
</ul>

<h3>Title: Comparing Credit Risk Estimates in the Gen-AI Era</h3>
<ul>
<li><strong>Authors: </strong>Nicola Lavecchia, Sid Fadanelli, Federico Ricciuti, Gennaro Aloe, Enrico Bagli, Pietro Giuffrida, Daniele Vergari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07754">https://arxiv.org/abs/2506.07754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07754">https://arxiv.org/pdf/2506.07754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07754]] Comparing Credit Risk Estimates in the Gen-AI Era(https://arxiv.org/abs/2506.07754)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative AI technologies have demonstrated significant potential across diverse applications. This study provides a comparative analysis of credit score modeling techniques, contrasting traditional approaches with those leveraging generative AI. Our findings reveal that current generative AI models fall short of matching the performance of traditional methods, regardless of the integration strategy employed. These results highlight the limitations in the current capabilities of generative AI for credit risk scoring, emphasizing the need for further research and development before the possibility of applying generative AI for this specific task, or equivalent ones.</li>
</ul>

<h3>Title: Clustered Federated Learning via Embedding Distributions</h3>
<ul>
<li><strong>Authors: </strong>Dekai Zhang, Matthew Williams, Francesca Toni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07769">https://arxiv.org/abs/2506.07769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07769">https://arxiv.org/pdf/2506.07769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07769]] Clustered Federated Learning via Embedding Distributions(https://arxiv.org/abs/2506.07769)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a widely used framework for machine learning in distributed data environments where clients hold data that cannot be easily centralised, such as for data protection reasons. FL, however, is known to be vulnerable to non-IID data. Clustered FL addresses this issue by finding more homogeneous clusters of clients. We propose a novel one-shot clustering method, EMD-CFL, using the Earth Mover's distance (EMD) between data distributions in embedding space. We theoretically motivate the use of EMDs using results from the domain adaptation literature and demonstrate empirically superior clustering performance in extensive comparisons against 16 baselines and on a range of challenging datasets.</li>
</ul>

<h3>Title: Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Djilani, Nassim Ali Ousalah, Nidhal Eddine Chenni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07773">https://arxiv.org/abs/2506.07773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07773">https://arxiv.org/pdf/2506.07773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07773]] Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity(https://arxiv.org/abs/2506.07773)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>We introduce a trend-aware and visually-grounded fashion recommendation system that integrates deep visual representations, garment-aware segmentation, semantic category similarity and user behavior simulation. Our pipeline extracts focused visual embeddings by masking non-garment regions via semantic segmentation followed by feature extraction using pretrained CNN backbones (ResNet-50, DenseNet-121, VGG16). To simulate realistic shopping behavior, we generate synthetic purchase histories influenced by user-specific trendiness and item popularity. Recommendations are computed using a weighted scoring function that fuses visual similarity, semantic coherence and popularity alignment. Experiments on the DeepFashion dataset demonstrate consistent gender alignment and improved category relevance, with ResNet-50 achieving 64.95% category similarity and lowest popularity MAE. An ablation study confirms the complementary roles of visual and popularity cues. Our method provides a scalable framework for personalized fashion recommendations that balances individual style with emerging trends. Our implementation is available at this https URL</li>
</ul>

<h3>Title: Language-Vision Planner and Executor for Text-to-Visual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Ling Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07778">https://arxiv.org/abs/2506.07778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07778">https://arxiv.org/pdf/2506.07778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07778]] Language-Vision Planner and Executor for Text-to-Visual Reasoning(https://arxiv.org/abs/2506.07778)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advancement in large language models (LLMs) and large vision models has fueled the rapid progress in multi-modal visual-text reasoning capabilities. However, existing vision-language models (VLMs) to date suffer from generalization performance. Inspired by recent development in LLMs for visual reasoning, this paper presents VLAgent, an AI system that can create a step-by-step visual reasoning plan with an easy-to-understand script and execute each step of the plan in real time by integrating planning script with execution verifications via an automated process supported by VLAgent. In the task planning phase, VLAgent fine-tunes an LLM through in-context learning to generate a step-by-step planner for each user-submitted text-visual reasoning task. During the plan execution phase, VLAgent progressively refines the composition of neuro-symbolic executable modules to generate high-confidence reasoning results. VLAgent has three unique design characteristics: First, we improve the quality of plan generation through in-context learning, improving logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM hallucinations. Second, we design a syntax-semantics parser to identify and correct additional logic errors of the LLM-generated planning script prior to launching the plan executor. Finally, we employ the ensemble method to improve the generalization performance of our step-executor. Extensive experiments with four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent achieves significant performance enhancement for multimodal text-visual reasoning applications, compared to the exiting representative VLMs and LLM based visual composition approaches like ViperGPT and VisProg, thanks to the novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer, Output Verifiers). Code and data will be made available upon paper acceptance.</li>
</ul>

<h3>Title: Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods</h3>
<ul>
<li><strong>Authors: </strong>Beining Xu, Junxian Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07779">https://arxiv.org/abs/2506.07779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07779">https://arxiv.org/pdf/2506.07779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07779]] Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods(https://arxiv.org/abs/2506.07779)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Visible images offer rich texture details, while infrared images emphasize salient targets. Fusing these complementary modalities enhances scene understanding, particularly for advanced vision tasks under challenging conditions. Recently, deep learning-based fusion methods have gained attention, but current evaluations primarily rely on general-purpose metrics without standardized benchmarks or downstream task performance. Additionally, the lack of well-developed dual-spectrum datasets and fair algorithm comparisons hinders progress. To address these gaps, we construct a high-quality dual-spectrum dataset captured in campus environments, comprising 1,369 well-aligned visible-infrared image pairs across four representative scenarios: daytime, nighttime, smoke occlusion, and underpasses. We also propose a comprehensive and fair evaluation framework that integrates fusion speed, general metrics, and object detection performance using the lang-segment-anything model to ensure fairness in downstream evaluation. Extensive experiments benchmark several state-of-the-art fusion algorithms under this framework. Results demonstrate that fusion models optimized for downstream tasks achieve superior performance in target detection, especially in low-light and occluded scenes. Notably, some algorithms that perform well on general metrics do not translate to strong downstream performance, highlighting limitations of current evaluation practices and validating the necessity of our proposed framework. The main contributions of this work are: (1)a campus-oriented dual-spectrum dataset with diverse and challenging scenes; (2) a task-aware, comprehensive evaluation framework; and (3) thorough comparative analysis of leading fusion methods across multiple datasets, offering insights for future development.</li>
</ul>

<h3>Title: LLM Unlearning Should Be Form-Independent</h3>
<ul>
<li><strong>Authors: </strong>Xiaotian Ye, Mengqi Zhang, Shu Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07795">https://arxiv.org/abs/2506.07795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07795">https://arxiv.org/pdf/2506.07795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07795]] LLM Unlearning Should Be Form-Independent(https://arxiv.org/abs/2506.07795)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify a pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, a novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques. We argue that LLM unlearning should be form-independent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), a novel training-free method, as a promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the model's perception of a specific unlearning target concept to another harmless concept. Extensive experiments demonstrate that ROCR significantly improves unlearning effectiveness compared to traditional methods while generating highly natural outputs.</li>
</ul>

<h3>Title: MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Iustin Sirbu (1), Robert-Adrian Popovici (1), Cornelia Caragea (2), Stefan Trausan-Matu (1), Traian Rebedea (1 and 3) ((1) National University of Science and Technology POLITEHNICA Bucharest, (2) University of Illinois Chicago, (3) NVIDIA)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07801">https://arxiv.org/abs/2506.07801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07801">https://arxiv.org/pdf/2506.07801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07801]] MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification(https://arxiv.org/abs/2506.07801)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm combining the paradigms of co-training and consistency regularization with pseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label weighting module designed for three key purposes: selecting and filtering pseudo-labels based on head agreement and model confidence, and weighting them according to the perceived classification difficulty. This novel module enhances and unifies three existing techniques -- heads agreement from Multihead Co-training, self-adaptive thresholds from FreeMatch, and Average Pseudo-Margins from MarginMatch -- resulting in a holistic approach that improves robustness and performance in SSL settings. Experimental results on benchmark datasets highlight the superior performance of MultiMatch, achieving state-of-the-art results on 9 out of 10 setups from 5 natural language processing datasets and ranking first according to the Friedman test among 19 methods. Furthermore, MultiMatch demonstrates exceptional robustness in highly imbalanced settings, outperforming the second-best approach by 3.26% -- and data imbalance is a key factor for many text classification tasks.</li>
</ul>

<h3>Title: Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability</h3>
<ul>
<li><strong>Authors: </strong>Jie Bao, Chuangyin Dang, Rui Luo, Hanwei Zhang, Zhixin Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07804">https://arxiv.org/abs/2506.07804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07804">https://arxiv.org/pdf/2506.07804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07804]] Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability(https://arxiv.org/abs/2506.07804)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>As deep learning models are increasingly deployed in high-risk applications, robust defenses against adversarial attacks and reliable performance guarantees become paramount. Moreover, accuracy alone does not provide sufficient assurance or reliable uncertainty estimates for these models. This study advances adversarial training by leveraging principles from Conformal Prediction. Specifically, we develop an adversarial attack method, termed OPSA (OPtimal Size Attack), designed to reduce the efficiency of conformal prediction at any significance level by maximizing model uncertainty without requiring coverage guarantees. Correspondingly, we introduce OPSA-AT (Adversarial Training), a defense strategy that integrates OPSA within a novel conformal training paradigm. Experimental evaluations demonstrate that our OPSA attack method induces greater uncertainty compared to baseline approaches for various defenses. Conversely, our OPSA-AT defensive model significantly enhances robustness not only against OPSA but also other adversarial attacks, and maintains reliable prediction. Our findings highlight the effectiveness of this integrated approach for developing trustworthy and resilient deep learning models for safety-critical domains. Our code is available at this https URL.</li>
</ul>

<h3>Title: Identifiable Object Representations under Spatial Ambiguities</h3>
<ul>
<li><strong>Authors: </strong>Avinash Kori, Francesca Toni, Ben Glocker</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07806">https://arxiv.org/abs/2506.07806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07806">https://arxiv.org/pdf/2506.07806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07806]] Identifiable Object Representations under Spatial Ambiguities(https://arxiv.org/abs/2506.07806)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modular object-centric representations are essential for *human-like reasoning* but are challenging to obtain under spatial ambiguities, *e.g. due to occlusions and view ambiguities*. However, addressing challenges presents both theoretical and practical difficulties. We introduce a novel multi-view probabilistic approach that aggregates view-specific slots to capture *invariant content* information while simultaneously learning disentangled global *viewpoint-level* information. Unlike prior single-view methods, our approach resolves spatial ambiguities, provides theoretical guarantees for identifiability, and requires *no viewpoint annotations*. Extensive experiments on standard benchmarks and novel complex datasets validate our method's robustness and scalability.</li>
</ul>

<h3>Title: Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Junseo Bang, Joonhee Lee, Kyeonghyun Lee, Haechang Lee, Dong Un Kang, Se Young Chun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07813">https://arxiv.org/abs/2506.07813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07813">https://arxiv.org/pdf/2506.07813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07813]] Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution(https://arxiv.org/abs/2506.07813)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Arbitrary-scale image super-resolution aims to upsample images to any desired resolution, offering greater flexibility than traditional fixed-scale super-resolution. Recent approaches in this domain utilize regression-based or generative models, but many of them are a single-stage upsampling process, which may be challenging to learn across a wide, continuous distribution of scaling factors. Progressive upsampling strategies have shown promise in mitigating this issue, yet their integration with diffusion models for flexible upscaling remains underexplored. Here, we present CasArbi, a novel self-cascaded diffusion framework for arbitrary-scale image super-resolution. CasArbi meets the varying scaling demands by breaking them down into smaller sequential factors and progressively enhancing the image resolution at each step with seamless transitions for arbitrary scales. Our novel coordinate-guided residual diffusion model allows for the learning of continuous image representations while enabling efficient diffusion sampling. Extensive experiments demonstrate that our CasArbi outperforms prior arts in both perceptual and distortion performance metrics across diverse arbitrary-scale super-resolution benchmarks.</li>
</ul>

<h3>Title: M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Yongzhen Wang, Yongjun Li, Zhuoran Zheng, Xiao-Ping Zhang, Mingqiang Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07814">https://arxiv.org/abs/2506.07814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07814">https://arxiv.org/pdf/2506.07814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07814]] M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration(https://arxiv.org/abs/2506.07814)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Natural images are often degraded by complex, composite degradations such as rain, snow, and haze, which adversely impact downstream vision applications. While existing image restoration efforts have achieved notable success, they are still hindered by two critical challenges: limited generalization across dynamically varying degradation scenarios and a suboptimal balance between preserving local details and modeling global dependencies. To overcome these challenges, we propose M2Restore, a novel Mixture-of-Experts (MoE)-based Mamba-CNN fusion framework for efficient and robust all-in-one image restoration. M2Restore introduces three key contributions: First, to boost the model's generalization across diverse degradation conditions, we exploit a CLIP-guided MoE gating mechanism that fuses task-conditioned prompts with CLIP-derived semantic priors. This mechanism is further refined via cross-modal feature calibration, which enables precise expert selection for various degradation types. Second, to jointly capture global contextual dependencies and fine-grained local details, we design a dual-stream architecture that integrates the localized representational strength of CNNs with the long-range modeling efficiency of Mamba. This integration enables collaborative optimization of global semantic relationships and local structural fidelity, preserving global coherence while enhancing detail restoration. Third, we introduce an edge-aware dynamic gating mechanism that adaptively balances global modeling and local enhancement by reallocating computational attention to degradation-sensitive regions. This targeted focus leads to more efficient and precise restoration. Extensive experiments across multiple image restoration benchmarks validate the superiority of M2Restore in both visual quality and quantitative performance.</li>
</ul>

<h3>Title: WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Lin, Zhengda Zhou, Zhiyuan Zhao, Tianrui Wan, Yilun Ma, Junyu Gao, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07818">https://arxiv.org/abs/2506.07818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07818">https://arxiv.org/pdf/2506.07818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07818]] WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code(https://arxiv.org/abs/2506.07818)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of Generative AI technology, Multimodal Large Language Models(MLLMs) have the potential to act as AI software engineers capable of executing complex web application development. Considering that the model requires a confluence of multidimensional sub-capabilities to address the challenges of various development phases, constructing a multi-view evaluation framework is crucial for accurately guiding the enhancement of development efficiency. However, existing benchmarks usually fail to provide an assessment of sub-capabilities and focus solely on webpage generation outcomes. In this work, we draw inspiration from the principles of software engineering and further propose WebUIBench, a benchmark systematically designed to evaluate MLLMs in four key areas: WebUI Perception, HTML Programming,WebUI-HTML Understanding, and WebUI-to-Code. WebUIBench comprises 21K high-quality question-answer pairs derived from over 0.7K real-world websites. The extensive evaluation of 29 mainstream MLLMs uncovers the skill characteristics and various weakness that models encountered during the development process.</li>
</ul>

<h3>Title: Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation</h3>
<ul>
<li><strong>Authors: </strong>Xintong Duan, Yutong He, Fahim Tajwar, Ruslan Salakhutdinov, J. Zico Kolter, Jeff Schneider</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07822">https://arxiv.org/abs/2506.07822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07822">https://arxiv.org/pdf/2506.07822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07822]] Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation(https://arxiv.org/abs/2506.07822)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Although diffusion models have achieved strong results in decision-making tasks, their slow inference speed remains a key limitation. While the consistency model offers a potential solution, its applications to decision-making often struggle with suboptimal demonstrations or rely on complex concurrent training of multiple networks. In this work, we propose a novel approach to consistency distillation for offline reinforcement learning that directly incorporates reward optimization into the distillation process. Our method enables single-step generation while maintaining higher performance and simpler training. Empirical evaluations on the Gym MuJoCo benchmarks and long horizon planning demonstrate that our approach can achieve an 8.7% improvement over previous state-of-the-art while offering up to 142x speedup over diffusion counterparts in inference time.</li>
</ul>

<h3>Title: R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation</h3>
<ul>
<li><strong>Authors: </strong>William Ljungbergh, Bernardo Taveira, Wenzhao Zheng, Adam Tonderski, Chensheng Peng, Fredrik Kahl, Christoffer Petersson, Michael Felsberg, Kurt Keutzer, Masayoshi Tomizuka, Wei Zhan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07826">https://arxiv.org/abs/2506.07826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07826">https://arxiv.org/pdf/2506.07826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07826]] R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation(https://arxiv.org/abs/2506.07826)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Validating autonomous driving (AD) systems requires diverse and safety-critical testing, making photorealistic virtual environments essential. Traditional simulation platforms, while controllable, are resource-intensive to scale and often suffer from a domain gap with real-world data. In contrast, neural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a scalable solution for creating photorealistic digital twins of real-world driving scenes. However, they struggle with dynamic object manipulation and reusability as their per-scene optimization-based methodology tends to result in incomplete object models with integrated illumination effects. This paper introduces R3D2, a lightweight, one-step diffusion model designed to overcome these limitations and enable realistic insertion of complete 3D assets into existing scenes by generating plausible rendering effects-such as shadows and consistent lighting-in real time. This is achieved by training R3D2 on a novel dataset: 3DGS object assets are generated from in-the-wild AD data using an image-conditioned 3D generative model, and then synthetically placed into neural rendering-based virtual environments, allowing R3D2 to learn realistic integration. Quantitative and qualitative evaluations demonstrate that R3D2 significantly enhances the realism of inserted assets, enabling use-cases like text-to-3D asset insertion and cross-scene/dataset object transfer, allowing for true scalability in AD validation. To promote further research in scalable and realistic AD simulation, we will release our dataset and code, see this https URL.</li>
</ul>

<h3>Title: Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information</h3>
<ul>
<li><strong>Authors: </strong>Jan Corazza, Hadi Partovi Aria, Hyohun Kim, Daniel Neider, Zhe Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07829">https://arxiv.org/abs/2506.07829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07829">https://arxiv.org/pdf/2506.07829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07829]] Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information(https://arxiv.org/abs/2506.07829)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) algorithms can find an optimal policy for a single agent to accomplish a particular task. However, many real-world problems require multiple agents to collaborate in order to achieve a common goal. For example, a robot executing a task in a warehouse may require the assistance of a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL (DMARL), agents learn independently and then combine their policies at execution time, but often must satisfy constraints on compatibility of local policies to ensure that they can achieve the global task when combined. In this paper, we study how providing high-level symbolic knowledge to agents can help address unique challenges of this setting, such as privacy constraints, communication limitations, and performance concerns. In particular, we extend the formal tools used to check the compatibility of local policies with the team task, making decentralized training with theoretical guarantees usable in more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge about the temporal evolution of events in the environment can significantly expedite the learning process in DMARL.</li>
</ul>

<h3>Title: Improving large language models with concept-aware fine-tuning</h3>
<ul>
<li><strong>Authors: </strong>Michael K. Chen, Xikun Zhang, Jiaxing Huang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07833">https://arxiv.org/abs/2506.07833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07833">https://arxiv.org/pdf/2506.07833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07833]] Improving large language models with concept-aware fine-tuning(https://arxiv.org/abs/2506.07833)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become the cornerstone of modern AI. However, the existing paradigm of next-token prediction fundamentally limits their ability to form coherent, high-level concepts, making it a critical barrier to human-like understanding and reasoning. Take the phrase "ribonucleic acid" as an example: an LLM will first decompose it into tokens, i.e., artificial text fragments ("rib", "on", ...), then learn each token sequentially, rather than grasping the phrase as a unified, coherent semantic entity. This fragmented representation hinders deeper conceptual understanding and, ultimately, the development of truly intelligent systems. In response, we introduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method that redefines how LLMs are fine-tuned. By enabling the learning of sequences that span multiple tokens, this method fosters stronger concept-aware learning. Our experiments demonstrate significant improvements compared to conventional next-token finetuning methods across diverse tasks, including traditional applications like text summarization and domain-specific ones like de novo protein design. Multi-token prediction was previously only possible in the prohibitively expensive pretraining phase; CAFT, to our knowledge, is the first to bring the multi-token setting to the post-training phase, thus effectively democratizing its benefits for the broader community of practitioners and researchers. Finally, the unexpected effectiveness of our proposed method suggests wider implications for the machine learning research community. All code and data are available at this https URL</li>
</ul>

<h3>Title: Are Trees Really Green? A Detection Approach of IoT Malware Attacks</h3>
<ul>
<li><strong>Authors: </strong>Silvia Lucia Sanna, Diego Soi, Davide Maiorca, Giorgio Giacinto</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07836">https://arxiv.org/abs/2506.07836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07836">https://arxiv.org/pdf/2506.07836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07836]] Are Trees Really Green? A Detection Approach of IoT Malware Attacks(https://arxiv.org/abs/2506.07836)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Nowadays, the Internet of Things (IoT) is widely employed, and its usage is growing exponentially because it facilitates remote monitoring, predictive maintenance, and data-driven decision making, especially in the healthcare and industrial sectors. However, IoT devices remain vulnerable due to their resource constraints and difficulty in applying security patches. Consequently, various cybersecurity attacks are reported daily, such as Denial of Service, particularly in IoT-driven solutions. Most attack detection methodologies are based on Machine Learning (ML) techniques, which can detect attack patterns. However, the focus is more on identification rather than considering the impact of ML algorithms on computational resources. This paper proposes a green methodology to identify IoT malware networking attacks based on flow privacy-preserving statistical features. In particular, the hyperparameters of three tree-based models -- Decision Trees, Random Forest and Extra-Trees -- are optimized based on energy consumption and test-time performance in terms of Matthew's Correlation Coefficient. Our results show that models maintain high performance and detection accuracy while consistently reducing power usage in terms of watt-hours (Wh). This suggests that on-premise ML-based Intrusion Detection Systems are suitable for IoT and other resource-constrained devices.</li>
</ul>

<h3>Title: Diffusion models under low-noise regime</h3>
<ul>
<li><strong>Authors: </strong>Elizabeth Pavlova, Xue-Xin Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07841">https://arxiv.org/abs/2506.07841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07841">https://arxiv.org/pdf/2506.07841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07841]] Diffusion models under low-noise regime(https://arxiv.org/abs/2506.07841)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent work on diffusion models proposed that they operate in two regimes: memorization, in which models reproduce their training data, and generalization, in which they generate novel samples. While this has been tested in high-noise settings, the behavior of diffusion models as effective denoisers when the corruption level is small remains unclear. To address this gap, we systematically investigated the behavior of diffusion models under low-noise diffusion dynamics, with implications for model robustness and interpretability. Using (i) CelebA subsets of varying sample sizes and (ii) analytic Gaussian mixture benchmarks, we reveal that models trained on disjoint data diverge near the data manifold even when their high-noise outputs converge. We quantify how training set size, data geometry, and model objective choice shape denoising trajectories and affect score accuracy, providing insights into how these models actually learn representations of data distributions. This work starts to address gaps in our understanding of generative model reliability in practical applications where small perturbations are common.</li>
</ul>

<h3>Title: Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels</h3>
<ul>
<li><strong>Authors: </strong>Davide Carbone</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07843">https://arxiv.org/abs/2506.07843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07843">https://arxiv.org/pdf/2506.07843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07843]] Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels(https://arxiv.org/abs/2506.07843)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Energy-Based Models (EBMs) provide a flexible framework for generative modeling, but their training remains theoretically challenging due to the need to approximate normalization constants and efficiently sample from complex, multi-modal distributions. Traditional methods, such as contrastive divergence and score matching, introduce biases that can hinder accurate learning. In this work, we present a theoretical analysis of Jarzynski reweighting, a technique from non-equilibrium statistical mechanics, and its implications for training EBMs. We focus on the role of the choice of the kernel and we illustrate these theoretical considerations in two key generative frameworks: (i) flow-based diffusion models, where we reinterpret Jarzynski reweighting in the context of stochastic interpolants to mitigate discretization errors and improve sample quality, and (ii) Restricted Boltzmann Machines, where we analyze its role in correcting the biases of contrastive divergence. Our results provide insights into the interplay between kernel choice and model performance, highlighting the potential of Jarzynski reweighting as a principled tool for generative learning.</li>
</ul>

<h3>Title: F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Hengzhi Chen, Liqian Feng, Wenhua Wu, Xiaogang Zhu, Shawn Leo, Kun Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07847">https://arxiv.org/abs/2506.07847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07847">https://arxiv.org/pdf/2506.07847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07847]] F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation(https://arxiv.org/abs/2506.07847)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of ultra-high-resolution (UHR) remote sensing imagery is critical for applications like environmental monitoring and urban planning but faces computational and optimization challenges. Conventional methods either lose fine details through downsampling or fragment global context via patch processing. While multi-branch networks address this trade-off, they suffer from computational inefficiency and conflicting gradient dynamics during training. We propose F2Net, a frequency-aware framework that decomposes UHR images into high- and low-frequency components for specialized processing. The high-frequency branch preserves full-resolution structural details, while the low-frequency branch processes downsampled inputs through dual sub-branches capturing short- and long-range dependencies. A Hybrid-Frequency Fusion module integrates these observations, guided by two novel objectives: Cross-Frequency Alignment Loss ensures semantic consistency between frequency components, and Cross-Frequency Balance Loss regulates gradient magnitudes across branches to stabilize training. Evaluated on DeepGlobe and Inria Aerial benchmarks, F2Net achieves state-of-the-art performance with mIoU of 80.22 and 83.39, respectively. Our code will be publicly available.</li>
</ul>

<h3>Title: PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Teng Hu, Zhentao Yu, Zhengguang Zhou, Jiangning Zhang, Yuan Zhou, Qinglin Lu, Ran Yi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07848">https://arxiv.org/abs/2506.07848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07848">https://arxiv.org/pdf/2506.07848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07848]] PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement(https://arxiv.org/abs/2506.07848)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Despite recent advances in video generation, existing models still lack fine-grained controllability, especially for multi-subject customization with consistent identity and interaction. In this paper, we propose PolyVivid, a multi-subject video customization framework that enables flexible and identity-consistent generation. To establish accurate correspondences between subject images and textual entities, we design a VLLM-based text-image fusion module that embeds visual identities into the textual space for precise grounding. To further enhance identity preservation and subject interaction, we propose a 3D-RoPE-based enhancement module that enables structured bidirectional fusion between text and image embeddings. Moreover, we develop an attention-inherited identity injection module to effectively inject fused identity features into the video generation process, mitigating identity drift. Finally, we construct an MLLM-based data pipeline that combines MLLM-based grounding, segmentation, and a clique-based subject consolidation strategy to produce high-quality multi-subject data, effectively enhancing subject distinction and reducing ambiguity in downstream video generation. Extensive experiments demonstrate that PolyVivid achieves superior performance in identity fidelity, video realism, and subject alignment, outperforming existing open-source and commercial baselines.</li>
</ul>

<h3>Title: SAM2Auto: Auto Annotation Using FLASH</h3>
<ul>
<li><strong>Authors: </strong>Arash Rocky, Q.M. Jonathan Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07850">https://arxiv.org/abs/2506.07850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07850">https://arxiv.org/pdf/2506.07850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07850]] SAM2Auto: Auto Annotation Using FLASH(https://arxiv.org/abs/2506.07850)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) lag behind Large Language Models due to the scarcity of annotated datasets, as creating paired visual-textual annotations is labor-intensive and expensive. To address this bottleneck, we introduce SAM2Auto, the first fully automated annotation pipeline for video datasets requiring no human intervention or dataset-specific training. Our approach consists of two key components: SMART-OD, a robust object detection system that combines automatic mask generation with open-world object detection capabilities, and FLASH (Frame-Level Annotation and Segmentation Handler), a multi-object real-time video instance segmentation (VIS) that maintains consistent object identification across video frames even with intermittent detection gaps. Unlike existing open-world detection methods that require frame-specific hyperparameter tuning and suffer from numerous false positives, our system employs statistical approaches to minimize detection errors while ensuring consistent object tracking throughout entire video sequences. Extensive experimental validation demonstrates that SAM2Auto achieves comparable accuracy to manual annotation while dramatically reducing annotation time and eliminating labor costs. The system successfully handles diverse datasets without requiring retraining or extensive parameter adjustments, making it a practical solution for large-scale dataset creation. Our work establishes a new baseline for automated video annotation and provides a pathway for accelerating VLM development by addressing the fundamental dataset bottleneck that has constrained progress in vision-language understanding.</li>
</ul>

<h3>Title: Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning</h3>
<ul>
<li><strong>Authors: </strong>Yiju Guo, Wenkai Yang, Zexu Sun, Ning Ding, Zhiyuan Liu, Yankai Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07851">https://arxiv.org/abs/2506.07851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07851">https://arxiv.org/pdf/2506.07851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07851]] Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning(https://arxiv.org/abs/2506.07851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated significant improvements in contextual understanding. However, their ability to attend to truly critical information during long-context reasoning and generation still falls behind the pace. Specifically, our preliminary experiments reveal that certain distracting patterns can misdirect the model's attention during inference, and removing these patterns substantially improves reasoning accuracy and generation quality. We attribute this phenomenon to spurious correlations in the training data, which obstruct the model's capacity to infer authentic causal instruction-response relationships. This phenomenon may induce redundant reasoning processes, potentially resulting in significant inference overhead and, more critically, the generation of erroneous or suboptimal responses. To mitigate this, we introduce a two-stage framework called Learning to Focus (LeaF) leveraging intervention-based inference to disentangle confounding factors. In the first stage, LeaF employs gradient-based comparisons with an advanced teacher to automatically identify confounding tokens based on causal relationships in the training corpus. Then, in the second stage, it prunes these tokens during distillation to enact intervention, aligning the student's attention with the teacher's focus distribution on truly critical context tokens. Experimental results demonstrate that LeaF not only achieves an absolute improvement in various mathematical reasoning and code generation benchmarks but also effectively suppresses attention to confounding tokens during inference, yielding a more interpretable and reliable reasoning model.</li>
</ul>

<h3>Title: LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Zihui Zhang, Weisheng Dai, Hongtao Wen, Bo Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07857">https://arxiv.org/abs/2506.07857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07857">https://arxiv.org/pdf/2506.07857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07857]] LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds(https://arxiv.org/abs/2506.07857)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We study the problem of unsupervised 3D semantic segmentation on raw point clouds without needing human labels in training. Existing methods usually formulate this problem into learning per-point local features followed by a simple grouping strategy, lacking the ability to discover additional and possibly richer semantic priors beyond local features. In this paper, we introduce LogoSP to learn 3D semantics from both local and global point features. The key to our approach is to discover 3D semantic information by grouping superpoints according to their global patterns in the frequency domain, thus generating highly accurate semantic pseudo-labels for training a segmentation network. Extensive experiments on two indoor and an outdoor datasets show that our LogoSP surpasses all existing unsupervised methods by large margins, achieving the state-of-the-art performance for unsupervised 3D semantic segmentation. Notably, our investigation into the learned global patterns reveals that they truly represent meaningful 3D semantics in the absence of human labels during training.</li>
</ul>

<h3>Title: Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ivan Alberico, Marco Cannici, Giovanni Cioffi, Davide Scaramuzza</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07860">https://arxiv.org/abs/2506.07860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07860">https://arxiv.org/pdf/2506.07860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07860]] Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction(https://arxiv.org/abs/2506.07860)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present a real-time egocentric trajectory prediction system for table tennis using event cameras. Unlike standard cameras, which suffer from high latency and motion blur at fast ball speeds, event cameras provide higher temporal resolution, allowing more frequent state updates, greater robustness to outliers, and accurate trajectory predictions using just a short time window after the opponent's impact. We collect a dataset of ping-pong game sequences, including 3D ground-truth trajectories of the ball, synchronized with sensor data from the Meta Project Aria glasses and event streams. Our system leverages foveated vision, using eye-gaze data from the glasses to process only events in the viewer's fovea. This biologically inspired approach improves ball detection performance and significantly reduces computational latency, as it efficiently allocates resources to the most perceptually relevant regions, achieving a reduction factor of 10.81 on the collected trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms, including computation and perception - significantly lower than a frame-based 30 FPS system, which, in the worst case, takes 66 ms solely for perception. Finally, we fit a trajectory prediction model to the estimated states of the ball, enabling 3D trajectory forecasting in the future. To the best of our knowledge, this is the first approach to predict table tennis trajectories from an egocentric perspective using event cameras.</li>
</ul>

<h3>Title: Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective</h3>
<ul>
<li><strong>Authors: </strong>Firas Laakom, Haobo Chen, Jürgen Schmidhuber, Yuheng Bu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07861">https://arxiv.org/abs/2506.07861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07861">https://arxiv.org/pdf/2506.07861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07861]] Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective(https://arxiv.org/abs/2506.07861)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Despite substantial progress in promoting fairness in high-stake applications using machine learning models, existing methods often modify the training process, such as through regularizers or other interventions, but lack formal guarantees that fairness achieved during training will generalize to unseen data. Although overfitting with respect to prediction performance has been extensively studied, overfitting in terms of fairness loss has received far less attention. This paper proposes a theoretical framework for analyzing fairness generalization error through an information-theoretic lens. Our novel bounding technique is based on Efron-Stein inequality, which allows us to derive tight information-theoretic fairness generalization bounds with both Mutual Information (MI) and Conditional Mutual Information (CMI). Our empirical results validate the tightness and practical relevance of these bounds across diverse fairness-aware learning algorithms. Our framework offers valuable insights to guide the design of algorithms improving fairness generalization.</li>
</ul>

<h3>Title: VIVAT: Virtuous Improving VAE Training through Artifact Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Lev Novitskiy, Viacheslav Vasilev, Maria Kovaleva, Vladimir Arkhipkin, Denis Dimitrov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07863">https://arxiv.org/abs/2506.07863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07863">https://arxiv.org/pdf/2506.07863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07863]] VIVAT: Virtuous Improving VAE Training through Artifact Mitigation(https://arxiv.org/abs/2506.07863)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Variational Autoencoders (VAEs) remain a cornerstone of generative computer vision, yet their training is often plagued by artifacts that degrade reconstruction and generation quality. This paper introduces VIVAT, a systematic approach to mitigating common artifacts in KL-VAE training without requiring radical architectural changes. We present a detailed taxonomy of five prevalent artifacts - color shift, grid patterns, blur, corner and droplet artifacts - and analyze their root causes. Through straightforward modifications, including adjustments to loss weights, padding strategies, and the integration of Spatially Conditional Normalization, we demonstrate significant improvements in VAE performance. Our method achieves state-of-the-art results in image reconstruction metrics (PSNR and SSIM) across multiple benchmarks and enhances text-to-image generation quality, as evidenced by superior CLIP scores. By preserving the simplicity of the KL-VAE framework while addressing its practical challenges, VIVAT offers actionable insights for researchers and practitioners aiming to optimize VAE training.</li>
</ul>

<h3>Title: Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes</h3>
<ul>
<li><strong>Authors: </strong>Mirko Paolo Barbato, Giorgia Rigamonti, Davide Marelli, Paolo Napoletano</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07864">https://arxiv.org/abs/2506.07864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07864">https://arxiv.org/pdf/2506.07864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07864]] Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes(https://arxiv.org/abs/2506.07864)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Type 1 Diabetes (T1D) affects millions worldwide, requiring continuous monitoring to prevent severe hypo- and hyperglycemic events. While continuous glucose monitoring has improved blood glucose management, deploying predictive models on wearable devices remains challenging due to computational and memory constraints. To address this, we propose a novel Lightweight Sequential Transformer model designed for blood glucose prediction in T1D. By integrating the strengths of Transformers' attention mechanisms and the sequential processing of recurrent neural networks, our architecture captures long-term dependencies while maintaining computational efficiency. The model is optimized for deployment on resource-constrained edge devices and incorporates a balanced loss function to handle the inherent data imbalance in hypo- and hyperglycemic events. Experiments on two benchmark datasets, OhioT1DM and DiaTrend, demonstrate that the proposed model outperforms state-of-the-art methods in predicting glucose levels and detecting adverse events. This work fills the gap between high-performance modeling and practical deployment, providing a reliable and efficient T1D management solution.</li>
</ul>

<h3>Title: FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity</h3>
<ul>
<li><strong>Authors: </strong>Jinxi Li, Ziyang Song, Siyuan Zhou, Bo Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CE, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07865">https://arxiv.org/abs/2506.07865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07865">https://arxiv.org/pdf/2506.07865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07865]] FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity(https://arxiv.org/abs/2506.07865)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we aim to model 3D scene geometry, appearance, and the underlying physics purely from multi-view videos. By applying various governing PDEs as PINN losses or incorporating physics simulation into neural networks, existing works often fail to learn complex physical motions at boundaries or require object priors such as masks or types. In this paper, we propose FreeGave to learn the physics of complex dynamic 3D scenes without needing any object priors. The key to our approach is to introduce a physics code followed by a carefully designed divergence-free module for estimating a per-Gaussian velocity field, without relying on the inefficient PINN losses. Extensive experiments on three public datasets and a newly collected challenging real-world dataset demonstrate the superior performance of our method for future frame extrapolation and motion segmentation. Most notably, our investigation into the learned physics codes reveals that they truly learn meaningful 3D physical motion patterns in the absence of any human labels in training.</li>
</ul>

<h3>Title: Securing Unbounded Differential Privacy Against Timing Attacks</h3>
<ul>
<li><strong>Authors: </strong>Zachary Ratliff, Salil Vadhan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07868">https://arxiv.org/abs/2506.07868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07868">https://arxiv.org/pdf/2506.07868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07868]] Securing Unbounded Differential Privacy Against Timing Attacks(https://arxiv.org/abs/2506.07868)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Recent works have started to theoretically investigate how we can protect differentially private programs against timing attacks, by making the joint distribution the output and the runtime differentially private (JOT-DP). However, the existing approaches to JOT-DP have some limitations, particularly in the setting of unbounded DP (which protects the size of the dataset and applies to arbitrarily large datasets). First, the known conversion of pure DP programs to pure JOT-DP programs in the unbounded setting (a) incurs a constant additive increase in error probability (and thus does not provide vanishing error as $n\to\infty$) (b) produces JOT-DP programs that fail to preserve the computational efficiency of the original pure DP program and (c) is analyzed in a toy computational model in which the runtime is defined to be the number of coin flips. In this work, we overcome these limitations. Specifically, we show that the error required for pure JOT-DP in the unbounded setting depends on the model of computation. In a randomized RAM model where the dataset size $n$ is given (or can be computed in constant time) and we can generate random numbers (not just random bits) in constant time, polynomially small error probability is necessary and sufficient. If $n$ is not given or we only have a random-bit generator, an (arbitrarily small) constant error probability is necessary and sufficient. The aforementioned positive results are proven by efficient procedures to convert any pure JOT-DP program $P$ in the upper-bounded setting to a pure JOT-DP program $P'$ in the unbounded setting, such that the output distribution of $P'$ is $\gamma$-close in total variation distance to that of $P$, where $\gamma$ is either an arbitrarily small constant or polynomially small, depending on the model of computation.</li>
</ul>

<h3>Title: Evaluating explainable AI for deep learning-based network intrusion detection system alert classification</h3>
<ul>
<li><strong>Authors: </strong>Rajesh Kalakoti, Risto Vaarandi, Hayretdin Bahsi, Sven Nõmm</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07882">https://arxiv.org/abs/2506.07882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07882">https://arxiv.org/pdf/2506.07882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07882]] Evaluating explainable AI for deep learning-based network intrusion detection system alert classification(https://arxiv.org/abs/2506.07882)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>A Network Intrusion Detection System (NIDS) monitors networks for cyber attacks and other unwanted activities. However, NIDS solutions often generate an overwhelming number of alerts daily, making it challenging for analysts to prioritize high-priority threats. While deep learning models promise to automate the prioritization of NIDS alerts, the lack of transparency in these models can undermine trust in their decision-making. This study highlights the critical need for explainable artificial intelligence (XAI) in NIDS alert classification to improve trust and interpretability. We employed a real-world NIDS alert dataset from Security Operations Center (SOC) of TalTech (Tallinn University Of Technology) in Estonia, developing a Long Short-Term Memory (LSTM) model to prioritize alerts. To explain the LSTM model's alert prioritization decisions, we implemented and compared four XAI methods: Local Interpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), Integrated Gradients, and DeepLIFT. The quality of these XAI methods was assessed using a comprehensive framework that evaluated faithfulness, complexity, robustness, and reliability. Our results demonstrate that DeepLIFT consistently outperformed the other XAI methods, providing explanations with high faithfulness, low complexity, robust performance, and strong reliability. In collaboration with SOC analysts, we identified key features essential for effective alert classification. The strong alignment between these analyst-identified features and those obtained by the XAI methods validates their effectiveness and enhances the practical applicability of our approach.</li>
</ul>

<h3>Title: Diffusion Counterfactual Generation with Semantic Abduction</h3>
<ul>
<li><strong>Authors: </strong>Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07883">https://arxiv.org/abs/2506.07883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07883">https://arxiv.org/pdf/2506.07883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07883]] Diffusion Counterfactual Generation with Semantic Abduction(https://arxiv.org/abs/2506.07883)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Counterfactual image generation presents significant challenges, including preserving identity, maintaining perceptual quality, and ensuring faithfulness to an underlying causal model. While existing auto-encoding frameworks admit semantic latent spaces which can be manipulated for causal control, they struggle with scalability and fidelity. Advancements in diffusion models present opportunities for improving counterfactual image editing, having demonstrated state-of-the-art visual quality, human-aligned perception and representation learning capabilities. Here, we present a suite of diffusion-based causal mechanisms, introducing the notions of spatial, semantic and dynamic abduction. We propose a general framework that integrates semantic representations into diffusion models through the lens of Pearlian causality to edit images via a counterfactual reasoning process. To our knowledge, this is the first work to consider high-level semantic identity preservation for diffusion counterfactuals and to demonstrate how semantic control enables principled trade-offs between faithful causal control and identity preservation.</li>
</ul>

<h3>Title: CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing</h3>
<ul>
<li><strong>Authors: </strong>Zubin Bhuyan, Yuanchang Xie, AngkeaReach Rith, Xintong Yan, Nasko Apostolov, Jimi Oke, Chengbo Ai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07885">https://arxiv.org/abs/2506.07885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07885">https://arxiv.org/pdf/2506.07885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07885]] CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing(https://arxiv.org/abs/2506.07885)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With the increasing availability of aerial and satellite imagery, deep learning presents significant potential for transportation asset management, safety analysis, and urban planning. This study introduces CrosswalkNet, a robust and efficient deep learning framework designed to detect various types of pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNet incorporates a novel detection approach that improves upon traditional object detection strategies by utilizing oriented bounding boxes (OBB), enhancing detection precision by accurately capturing crosswalks regardless of their orientation. Several optimization techniques, including Convolutional Block Attention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosine annealing, are implemented to maximize performance and efficiency. A comprehensive dataset comprising over 23,000 annotated crosswalk instances is utilized to train and validate the proposed framework. The best-performing model achieves an impressive precision of 96.5% and a recall of 93.3% on aerial imagery from Massachusetts, demonstrating its accuracy and effectiveness. CrosswalkNet has also been successfully applied to datasets from New Hampshire, Virginia, and Maine without transfer learning or fine-tuning, showcasing its robustness and strong generalization capability. Additionally, the crosswalk detection results, processed using High-Performance Computing (HPC) platforms and provided in polygon shapefile format, have been shown to accelerate data processing and detection, supporting real-time analysis for safety and mobility applications. This integration offers policymakers, transportation engineers, and urban planners an effective instrument to enhance pedestrian safety and improve urban mobility.</li>
</ul>

<h3>Title: EgoM2P: Egocentric Multimodal Multitask Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07886">https://arxiv.org/abs/2506.07886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07886">https://arxiv.org/pdf/2506.07886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07886]] EgoM2P: Egocentric Multimodal Multitask Pretraining(https://arxiv.org/abs/2506.07886)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Understanding multimodal signals in egocentric vision, such as RGB video, depth, camera poses, and gaze, is essential for applications in augmented reality, robotics, and human-computer interaction. These capabilities enable systems to better interpret the camera wearer's actions, intentions, and surrounding environment. However, building large-scale egocentric multimodal and multitask models presents unique challenges. Egocentric data are inherently heterogeneous, with large variations in modality coverage across devices and settings. Generating pseudo-labels for missing modalities, such as gaze or head-mounted camera trajectories, is often infeasible, making standard supervised learning approaches difficult to scale. Furthermore, dynamic camera motion and the complex temporal and spatial structure of first-person video pose additional challenges for the direct application of existing multimodal foundation models. To address these challenges, we introduce a set of efficient temporal tokenizers and propose EgoM2P, a masked modeling framework that learns from temporally aware multimodal tokens to train a large, general-purpose model for egocentric 4D understanding. This unified design supports multitasking across diverse egocentric perception and synthesis tasks, including gaze prediction, egocentric camera tracking, and monocular depth estimation from egocentric video. EgoM2P also serves as a generative model for conditional egocentric video synthesis. Across these tasks, EgoM2P matches or outperforms specialist models while being an order of magnitude faster. We will fully open-source EgoM2P to support the community and advance egocentric vision research. Project page: this https URL</li>
</ul>

<h3>Title: SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Rui Wen, Yiyong Liu, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07888">https://arxiv.org/abs/2506.07888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07888">https://arxiv.org/pdf/2506.07888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07888]] SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark(https://arxiv.org/abs/2506.07888)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Data reconstruction attacks, which aim to recover the training dataset of a target model with limited access, have gained increasing attention in recent years. However, there is currently no consensus on a formal definition of data reconstruction attacks or appropriate evaluation metrics for measuring their quality. This lack of rigorous definitions and universal metrics has hindered further advancement in this field. In this paper, we address this issue in the vision domain by proposing a unified attack taxonomy and formal definitions of data reconstruction attacks. We first propose a set of quantitative evaluation metrics that consider important criteria such as quantifiability, consistency, precision, and diversity. Additionally, we leverage large language models (LLMs) as a substitute for human judgment, enabling visual evaluation with an emphasis on high-quality reconstructions. Using our proposed taxonomy and metrics, we present a unified framework for systematically evaluating the strengths and limitations of existing attacks and establishing a benchmark for future research. Empirical results, primarily from a memorization perspective, not only validate the effectiveness of our metrics but also offer valuable insights for designing new attacks.</li>
</ul>

<h3>Title: Video Unlearning via Low-Rank Refusal Vector</h3>
<ul>
<li><strong>Authors: </strong>Simone Facchiano, Stefano Saravalle, Matteo Migliarini, Edoardo De Matteis, Alessio Sampieri, Andrea Pilzer, Emanuele Rodolà, Indro Spinelli, Luca Franco, Fabio Galasso</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07891">https://arxiv.org/abs/2506.07891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07891">https://arxiv.org/pdf/2506.07891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07891]] Video Unlearning via Low-Rank Refusal Vector(https://arxiv.org/abs/2506.07891)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Video generative models democratize the creation of visual content through intuitive instruction following, but they also inherit the biases and harmful concepts embedded within their web-scale training data. This inheritance creates a significant risk, as users can readily generate undesirable and even illegal content. This work introduces the first unlearning technique tailored explicitly for video diffusion models to address this critical issue. Our method requires 5 multi-modal prompt pairs only. Each pair contains a "safe" and an "unsafe" example that differ only by the target concept. Averaging their per-layer latent differences produces a "refusal vector", which, once subtracted from the model parameters, neutralizes the unsafe concept. We introduce a novel low-rank factorization approach on the covariance difference of embeddings that yields robust refusal vectors. This isolates the target concept while minimizing collateral unlearning of other semantics, thus preserving the visual quality of the generated video. Our method preserves the model's generation quality while operating without retraining or access to the original training data. By embedding the refusal direction directly into the model's weights, the suppression mechanism becomes inherently more robust against adversarial bypass attempts compared to surface-level input-output filters. In a thorough qualitative and quantitative evaluation, we show that we can neutralize a variety of harmful contents, including explicit nudity, graphic violence, copyrights, and trademarks. Project page: this https URL.</li>
</ul>

<h3>Title: Secure Distributed Learning for CAVs: Defending Against Gradient Leakage with Leveled Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ali Najjar, Ren-Yi Huang, Dumindu Samaraweera, Prashant Shekhar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07894">https://arxiv.org/abs/2506.07894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07894">https://arxiv.org/pdf/2506.07894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07894]] Secure Distributed Learning for CAVs: Defending Against Gradient Leakage with Leveled Homomorphic Encryption(https://arxiv.org/abs/2506.07894)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across distributed clients without sharing raw data, making it a promising approach for privacy-preserving machine learning in domains like Connected and Autonomous Vehicles (CAVs). However, recent studies have shown that exchanged model gradients remain susceptible to inference attacks such as Deep Leakage from Gradients (DLG), which can reconstruct private training data. While existing defenses like Differential Privacy (DP) and Secure Multi-Party Computation (SMPC) offer protection, they often compromise model accuracy. To that end, Homomorphic Encryption (HE) offers a promising alternative by enabling lossless computation directly on encrypted data, thereby preserving both privacy and model utility. However, HE introduces significant computational and communication overhead, which can hinder its practical adoption. To address this, we systematically evaluate various leveled HE schemes to identify the most suitable for FL in resource-constrained environments due to its ability to support fixed-depth computations without requiring costly bootstrapping. Our contributions in this paper include a comprehensive evaluation of HE schemes for real-world FL applications, a selective encryption strategy that targets only the most sensitive gradients to minimize computational overhead, and the development of a full HE-based FL pipeline that effectively mitigates DLG attacks while preserving model accuracy. We open-source our implementation to encourage reproducibility and facilitate adoption in safety-critical domains.</li>
</ul>

<h3>Title: MiniCPM4: Ultra-Efficient LLMs on End Devices</h3>
<ul>
<li><strong>Authors: </strong>MiniCPM Team: Chaojun Xiao, Yuxuan Li, Xu Han, Yuzhuo Bai, Jie Cai, Haotian Chen, Wentong Chen, Xin Cong, Ganqu Cui, Ning Ding, Shengdan Fan, Yewei Fang, Zixuan Fu, Wenyu Guan, Yitong Guan, Junshao Guo, Yufeng Han, Bingxiang He, Yuxiang Huang, Cunliang Kong, Qiuzuo Li, Siyuan Li, Wenhao Li, Yanghao Li, Yishan Li, Zhen Li, Dan Liu, Biyuan Lin, Yankai Lin, Xiang Long, Quanyu Lu, Yaxi Lu, Peiyan Luo, Hongya Lyu, Litu Ou, Yinxu Pan, Zekai Qu, Qundong Shi, Zijun Song, Jiayuan Su, Zhou Su, Ao Sun, Xianghui Sun, Peijun Tang, Fangzheng Wang, Feng Wang, Shuo Wang, Yudong Wang, Yesai Wu, Zhenyu Xiao, Jie Xie, Zihao Xie, Yukun Yan, Jiarui Yuan, Kaihuo Zhang, Lei Zhang, Linyue Zhang, Xueren Zhang, Yudi Zhang, Hengyu Zhao, Weilin Zhao, Weilun Zhao, Yuanqian Zhao, Zhi Zheng, Ge Zhou, Jie Zhou, Wei Zhou, Zihan Zhou, Zixuan Zhou, Zhiyuan Liu, Guoyang Zeng, Chao Jia, Dahai Li, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07900">https://arxiv.org/abs/2506.07900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07900">https://arxiv.org/pdf/2506.07900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07900]] MiniCPM4: Ultra-Efficient LLMs on End Devices(https://arxiv.org/abs/2506.07900)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces MiniCPM4, a highly efficient large language model (LLM) designed explicitly for end-side devices. We achieve this efficiency through systematic innovation in four key dimensions: model architecture, training data, training algorithms, and inference systems. Specifically, in terms of model architecture, we propose InfLLM v2, a trainable sparse attention mechanism that accelerates both prefilling and decoding phases for long-context processing. Regarding training data, we propose UltraClean, an efficient and accurate pre-training data filtering and generation strategy, and UltraChat v2, a comprehensive supervised fine-tuning dataset. These datasets enable satisfactory model performance to be achieved using just 8 trillion training tokens. Regarding training algorithms, we propose ModelTunnel v2 for efficient pre-training strategy search, and improve existing post-training methods by introducing chunk-wise rollout for load-balanced reinforcement learning and data-efficient tenary LLM, BitCPM. Regarding inference systems, we propose this http URL that integrates sparse attention, model quantization, and speculative sampling to achieve efficient prefilling and decoding. To meet diverse on-device requirements, MiniCPM4 is available in two versions, with 0.5B and 8B parameters, respectively. Sufficient evaluation results show that MiniCPM4 outperforms open-source models of similar size across multiple benchmarks, highlighting both its efficiency and effectiveness. Notably, MiniCPM4-8B demonstrates significant speed improvements over Qwen3-8B when processing long sequences. Through further adaptation, MiniCPM4 successfully powers diverse applications, including trustworthy survey generation and tool use with model context protocol, clearly showcasing its broad usability.</li>
</ul>

<h3>Title: FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling</h3>
<ul>
<li><strong>Authors: </strong>Sifan Wang, Zehao Dou, Tong-Rui Liu, Lu Lu</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07902">https://arxiv.org/abs/2506.07902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07902">https://arxiv.org/pdf/2506.07902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07902]] FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling(https://arxiv.org/abs/2506.07902)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative modeling -- particularly diffusion models and flow matching -- have achieved remarkable success in synthesizing discrete data such as images and videos. However, adapting these models to physical applications remains challenging, as the quantities of interest are continuous functions governed by complex physical laws. Here, we introduce $\textbf{FunDiff}$, a novel framework for generative modeling in function spaces. FunDiff combines a latent diffusion process with a function autoencoder architecture to handle input functions with varying discretizations, generate continuous functions evaluable at arbitrary locations, and seamlessly incorporate physical priors. These priors are enforced through architectural constraints or physics-informed loss functions, ensuring that generated samples satisfy fundamental physical laws. We theoretically establish minimax optimality guarantees for density estimation in function spaces, showing that diffusion-based estimators achieve optimal convergence rates under suitable regularity conditions. We demonstrate the practical effectiveness of FunDiff across diverse applications in fluid dynamics and solid mechanics. Empirical results show that our method generates physically consistent samples with high fidelity to the target distribution and exhibits robustness to noisy and low-resolution data. Code and datasets are publicly available at this https URL.</li>
</ul>

<h3>Title: Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces</h3>
<ul>
<li><strong>Authors: </strong>Kevin Rojas, Yuchen Zhu, Sichen Zhu, Felix X.-F. Ye, Molei Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07903">https://arxiv.org/abs/2506.07903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07903">https://arxiv.org/pdf/2506.07903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07903]] Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces(https://arxiv.org/abs/2506.07903)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated remarkable performance in generating unimodal data across various tasks, including image, video, and text generation. On the contrary, the joint generation of multimodal data through diffusion models is still in the early stages of exploration. Existing approaches heavily rely on external preprocessing protocols, such as tokenizers and variational autoencoders, to harmonize varied data representations into a unified, unimodal format. This process heavily demands the high accuracy of encoders and decoders, which can be problematic for applications with limited data. To lift this restriction, we propose a novel framework for building multimodal diffusion models on arbitrary state spaces, enabling native generation of coupled data across different modalities. By introducing an innovative decoupled noise schedule for each modality, we enable both unconditional and modality-conditioned generation within a single model simultaneously. We empirically validate our approach for text-image generation and mixed-type tabular data synthesis, demonstrating that it achieves competitive performance.</li>
</ul>

<h3>Title: WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Jie Yang, Feipeng Ma, Zitian Wang, Dacheng Yin, Kang Rong, Fengyun Rao, Ruimao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07905">https://arxiv.org/abs/2506.07905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07905">https://arxiv.org/pdf/2506.07905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07905]] WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning(https://arxiv.org/abs/2506.07905)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Building on the success of text-based reasoning models like DeepSeek-R1, extending these capabilities to multimodal reasoning holds great promise. While recent works have attempted to adapt DeepSeek-R1-style reinforcement learning (RL) training paradigms to multimodal large language models (MLLM), focusing on domain-specific tasks like math and visual perception, a critical question remains: How can we achieve the general-purpose visual-language reasoning through RL? To address this challenge, we make three key efforts: (1) A novel Scalable Multimodal QA Synthesis pipeline that autonomously generates context-aware, reasoning-centric question-answer (QA) pairs directly from the given images. (2) The open-source WeThink dataset containing over 120K multimodal QA pairs with annotated reasoning paths, curated from 18 diverse dataset sources and covering various question domains. (3) A comprehensive exploration of RL on our dataset, incorporating a hybrid reward mechanism that combines rule-based verification with model-based assessment to optimize RL training efficiency across various task domains. Across 14 diverse MLLM benchmarks, we demonstrate that our WeThink dataset significantly enhances performance, from mathematical reasoning to diverse general multimodal tasks. Moreover, we show that our automated data pipeline can continuously increase data diversity to further improve model performance.</li>
</ul>

<h3>Title: CausalPFN: Amortized Causal Effect Estimation via In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Vahid Balazadeh, Hamidreza Kamkari, Valentin Thomas, Benson Li, Junwei Ma, Jesse C. Cresswell, Rahul G. Krishnan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07918">https://arxiv.org/abs/2506.07918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07918">https://arxiv.org/pdf/2506.07918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07918]] CausalPFN: Amortized Causal Effect Estimation via In-Context Learning(https://arxiv.org/abs/2506.07918)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Causal effect estimation from observational data is fundamental across various applications. However, selecting an appropriate estimator from dozens of specialized methods demands substantial manual effort and domain expertise. We present CausalPFN, a single transformer that amortizes this workflow: trained once on a large library of simulated data-generating processes that satisfy ignorability, it infers causal effects for new observational datasets out-of-the-box. CausalPFN combines ideas from Bayesian causal inference with the large-scale training protocol of prior-fitted networks (PFNs), learning to map raw observations directly to causal effects without any task-specific adjustment. Our approach achieves superior average performance on heterogeneous and average treatment effect estimation benchmarks (IHDP, Lalonde, ACIC). Moreover, it shows competitive performance for real-world policy making on uplift modeling tasks. CausalPFN provides calibrated uncertainty estimates to support reliable decision-making based on Bayesian principles. This ready-to-use model does not require any further training or tuning and takes a step toward automated causal inference (this https URL).</li>
</ul>

<h3>Title: Uncovering the Functional Roles of Nonlinearity in Memory</h3>
<ul>
<li><strong>Authors: </strong>Manuel Brenner, Georgia Koppe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, nlin.CD, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07919">https://arxiv.org/abs/2506.07919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07919">https://arxiv.org/pdf/2506.07919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07919]] Uncovering the Functional Roles of Nonlinearity in Memory(https://arxiv.org/abs/2506.07919)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Memory and long-range temporal processing are core requirements for sequence modeling tasks across natural language processing, time-series forecasting, speech recognition, and control. While nonlinear recurrence has long been viewed as essential for enabling such mechanisms, recent work suggests that linear dynamics may often suffice. In this study, we go beyond performance comparisons to systematically dissect the functional role of nonlinearity in recurrent networks--identifying both when it is computationally necessary, and what mechanisms it enables. We use Almost Linear Recurrent Neural Networks (AL-RNNs), which allow fine-grained control over nonlinearity, as both a flexible modeling tool and a probe into the internal mechanisms of memory. Across a range of classic sequence modeling tasks and a real-world stimulus selection task, we find that minimal nonlinearity is not only sufficient but often optimal, yielding models that are simpler, more robust, and more interpretable than their fully nonlinear or linear counterparts. Our results provide a principled framework for selectively introducing nonlinearity, bridging dynamical systems theory with the functional demands of long-range memory and structured computation in recurrent neural networks, with implications for both artificial and biological neural systems.</li>
</ul>

<h3>Title: A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle</h3>
<ul>
<li><strong>Authors: </strong>Amirreza Yasami, Mohammadali Tofigh, Mahdi Shahbakhti, Charles Robert Koch</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07929">https://arxiv.org/abs/2506.07929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07929">https://arxiv.org/pdf/2506.07929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07929]] A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle(https://arxiv.org/abs/2506.07929)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurate driving cycle construction is crucial for vehicle design, fuel economy analysis, and environmental impact assessments. A generative Physics-Informed Expected SARSA-Monte Carlo (PIESMC) approach that constructs representative driving cycles by capturing transient dynamics, acceleration, deceleration, idling, and road grade transitions while ensuring model fidelity is introduced. Leveraging a physics-informed reinforcement learning framework with Monte Carlo sampling, PIESMC delivers efficient cycle construction with reduced computational cost. Experimental evaluations on two real-world datasets demonstrate that PIESMC replicates key kinematic and energy metrics, achieving up to a 57.3% reduction in cumulative kinematic fragment errors compared to the Micro-trip-based (MTB) method and a 10.5% reduction relative to the Markov-chain-based (MCB) method. Moreover, it is nearly an order of magnitude faster than conventional techniques. Analyses of vehicle-specific power distributions and wavelet-transformed frequency content further confirm its ability to reproduce experimental central tendencies and variability.</li>
</ul>

<h3>Title: Quantum Graph Transformer for NLP Sentiment Classification</h3>
<ul>
<li><strong>Authors: </strong>Shamminuj Aktar, Andreas Bärtschi, Abdel-Hameed A. Badawy, Stephan Eidenbenz</a></li>
<li><strong>Subjects: </strong>cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07937">https://arxiv.org/abs/2506.07937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07937">https://arxiv.org/pdf/2506.07937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07937]] Quantum Graph Transformer for NLP Sentiment Classification(https://arxiv.org/abs/2506.07937)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Quantum machine learning is a promising direction for building more efficient and expressive models, particularly in domains where understanding complex, structured data is critical. We present the Quantum Graph Transformer (QGT), a hybrid graph-based architecture that integrates a quantum self-attention mechanism into the message-passing framework for structured language modeling. The attention mechanism is implemented using parameterized quantum circuits (PQCs), which enable the model to capture rich contextual relationships while significantly reducing the number of trainable parameters compared to classical attention mechanisms. We evaluate QGT on five sentiment classification benchmarks. Experimental results show that QGT consistently achieves higher or comparable accuracy than existing quantum natural language processing (QNLP) models, including both attention-based and non-attention-based approaches. When compared with an equivalent classical graph transformer, QGT yields an average accuracy improvement of 5.42% on real-world datasets and 4.76% on synthetic datasets. Additionally, QGT demonstrates improved sample efficiency, requiring nearly 50% fewer labeled samples to reach comparable performance on the Yelp dataset. These results highlight the potential of graph-based QNLP techniques for advancing efficient and scalable language understanding.</li>
</ul>

<h3>Title: Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations</h3>
<ul>
<li><strong>Authors: </strong>Yizhen Li, Dell Zhang, Xuelong Li, Yiqing Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07943">https://arxiv.org/abs/2506.07943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07943">https://arxiv.org/pdf/2506.07943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07943]] Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations(https://arxiv.org/abs/2506.07943)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Reasoning Segmentation (RS) is a multimodal vision-text task that requires segmenting objects based on implicit text queries, demanding both precise visual perception and vision-text reasoning capabilities. Current RS approaches rely on fine-tuning vision-language models (VLMs) for both perception and reasoning, but their tokenization of images fundamentally disrupts continuous spatial relationships between objects. We introduce DTwinSeger, a novel RS approach that leverages Digital Twin (DT) representation as an intermediate layer to decouple perception from reasoning. Innovatively, DTwinSeger reformulates RS as a two-stage process, where the first transforms the image into a structured DT representation that preserves spatial relationships and semantic properties and then employs a Large Language Model (LLM) to perform explicit reasoning over this representation to identify target objects. We propose a supervised fine-tuning method specifically for LLM with DT representation, together with a corresponding fine-tuning dataset Seg-DT, to enhance the LLM's reasoning capabilities with DT representations. Experiments show that our method can achieve state-of-the-art performance on two image RS benchmarks and three image referring segmentation benchmarks. It yields that DT representation functions as an effective bridge between vision and text, enabling complex multimodal reasoning tasks to be accomplished solely with an LLM.</li>
</ul>

<h3>Title: Statistical Hypothesis Testing for Auditing Robustness in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Paulius Rauba, Qiyao Wei, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07947">https://arxiv.org/abs/2506.07947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07947">https://arxiv.org/pdf/2506.07947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07947]] Statistical Hypothesis Testing for Auditing Robustness in Language Models(https://arxiv.org/abs/2506.07947)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Consider the problem of testing whether the outputs of a large language model (LLM) system change under an arbitrary intervention, such as an input perturbation or changing the model variant. We cannot simply compare two LLM outputs since they might differ due to the stochastic nature of the system, nor can we compare the entire output distribution due to computational intractability. While existing methods for analyzing text-based outputs exist, they focus on fundamentally different problems, such as measuring bias or fairness. To this end, we introduce distribution-based perturbation analysis, a framework that reformulates LLM perturbation analysis as a frequentist hypothesis testing problem. We construct empirical null and alternative output distributions within a low-dimensional semantic similarity space via Monte Carlo sampling, enabling tractable inference without restrictive distributional assumptions. The framework is (i) model-agnostic, (ii) supports the evaluation of arbitrary input perturbations on any black-box LLM, (iii) yields interpretable p-values; (iv) supports multiple perturbations via controlled error rates; and (v) provides scalar effect sizes. We demonstrate the usefulness of the framework across multiple case studies, showing how we can quantify response changes, measure true/false positive rates, and evaluate alignment with reference models. Above all, we see this as a reliable frequentist hypothesis testing framework for LLM auditing.</li>
</ul>

<h3>Title: TokenBreak: Bypassing Text Classification Models Through Token Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Kasimir Schulz, Kenneth Yeung, Kieran Evans</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07948">https://arxiv.org/abs/2506.07948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07948">https://arxiv.org/pdf/2506.07948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07948]] TokenBreak: Bypassing Text Classification Models Through Token Manipulation(https://arxiv.org/abs/2506.07948)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>Natural Language Processing (NLP) models are used for text-related tasks such as classification and generation. To complete these tasks, input data is first tokenized from human-readable text into a format the model can understand, enabling it to make inferences and understand context. Text classification models can be implemented to guard against threats such as prompt injection attacks against Large Language Models (LLMs), toxic input and cybersecurity risks such as spam emails. In this paper, we introduce TokenBreak: a novel attack that can bypass these protection models by taking advantage of the tokenization strategy they use. This attack technique manipulates input text in such a way that certain models give an incorrect classification. Importantly, the end target (LLM or email recipient) can still understand and respond to the manipulated text and therefore be vulnerable to the very attack the protection model was put in place to prevent. The tokenizer is tied to model architecture, meaning it is possible to predict whether or not a model is vulnerable to attack based on family. We also present a defensive strategy as an added layer of protection that can be implemented without having to retrain the defensive model.</li>
</ul>

<h3>Title: Cost-Optimal Active AI Model Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Anastasios N. Angelopoulos, Jacob Eisenstein, Jonathan Berant, Alekh Agarwal, Adam Fisch</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07949">https://arxiv.org/abs/2506.07949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07949">https://arxiv.org/pdf/2506.07949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07949]] Cost-Optimal Active AI Model Evaluation(https://arxiv.org/abs/2506.07949)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The development lifecycle of generative AI systems requires continual evaluation, data acquisition, and annotation, which is costly in both resources and time. In practice, rapid iteration often makes it necessary to rely on synthetic annotation data because of the low cost, despite the potential for substantial bias. In this paper, we develop novel, cost-aware methods for actively balancing the use of a cheap, but often inaccurate, weak rater -- such as a model-based autorater that is designed to automatically assess the quality of generated content -- with a more expensive, but also more accurate, strong rater alternative such as a human. More specifically, the goal of our approach is to produce a low variance, unbiased estimate of the mean of the target "strong" rating, subject to some total annotation budget. Building on recent work in active and prediction-powered statistical inference, we derive a family of cost-optimal policies for allocating a given annotation budget between weak and strong raters so as to maximize statistical efficiency. Using synthetic and real-world data, we empirically characterize the conditions under which these policies yield improvements over prior methods. We find that, especially in tasks where there is high variability in the difficulty of examples, our policies can achieve the same estimation precision at a far lower total annotation budget than standard evaluation methods.</li>
</ul>

<h3>Title: Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs</h3>
<ul>
<li><strong>Authors: </strong>Salah A. Faroughi, Farinaz Mostajeran</a></li>
<li><strong>Subjects: </strong>cs.LG, math-ph, math.AP, math.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07958">https://arxiv.org/abs/2506.07958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07958">https://arxiv.org/pdf/2506.07958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07958]] Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs(https://arxiv.org/abs/2506.07958)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Physics-informed Kolmogorov-Arnold Networks (PIKANs), and in particular their Chebyshev-based variants (cPIKANs), have recently emerged as promising models for solving partial differential equations (PDEs). However, their training dynamics and convergence behavior remain largely unexplored both theoretically and numerically. In this work, we aim to advance the theoretical understanding of cPIKANs by analyzing them using Neural Tangent Kernel (NTK) theory. Our objective is to discern the evolution of kernel structure throughout gradient-based training and its subsequent impact on learning efficiency. We first derive the NTK of standard cKANs in a supervised setting, and then extend the analysis to the physics-informed context. We analyze the spectral properties of NTK matrices, specifically their eigenvalue distributions and spectral bias, for four representative PDEs: the steady-state Helmholtz equation, transient diffusion and Allen-Cahn equations, and forced vibrations governed by the Euler-Bernoulli beam equation. We also conduct an investigation into the impact of various optimization strategies, e.g., first-order, second-order, and hybrid approaches, on the evolution of the NTK and the resulting learning dynamics. Results indicate a tractable behavior for NTK in the context of cPIKANs, which exposes learning dynamics that standard physics-informed neural networks (PINNs) cannot capture. Spectral trends also reveal when domain decomposition improves training, directly linking kernel behavior to convergence rates under different setups. To the best of our knowledge, this is the first systematic NTK study of cPIKANs, providing theoretical insight that clarifies and predicts their empirical performance.</li>
</ul>

<h3>Title: Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920</h3>
<ul>
<li><strong>Authors: </strong>Ari Vesalainen, Jenna Kanerva, Aida Nitsch, Kiia Korsu, Ilari Larkiola, Laura Ruotsalainen, Filip Ginter</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07960">https://arxiv.org/abs/2506.07960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07960">https://arxiv.org/pdf/2506.07960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07960]] Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920(https://arxiv.org/abs/2506.07960)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This article presents a large-scale effort to create a structured dataset of internal migration in Finland between 1800 and 1920 using digitized church moving records. These records, maintained by Evangelical-Lutheran parishes, document the migration of individuals and families and offer a valuable source for studying historical demographic patterns. The dataset includes over six million entries extracted from approximately 200,000 images of handwritten migration records. The data extraction process was automated using a deep learning pipeline that included layout analysis, table detection, cell classification, and handwriting recognition. The complete pipeline was applied to all images, resulting in a structured dataset suitable for research. The dataset can be used to study internal migration, urbanization, and family migration, and the spread of disease in preindustrial Finland. A case study from the Elimäki parish shows how local migration histories can be reconstructed. The work demonstrates how large volumes of handwritten archival material can be transformed into structured data to support historical and demographic research.</li>
</ul>

<h3>Title: Correlated Errors in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Elliot Kim, Avi Garg, Kenny Peng, Nikhil Garg</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07962">https://arxiv.org/abs/2506.07962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07962">https://arxiv.org/pdf/2506.07962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07962]] Correlated Errors in Large Language Models(https://arxiv.org/abs/2506.07962)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Diversity in training data, architecture, and providers is assumed to mitigate homogeneity in LLMs. However, we lack empirical evidence on whether different LLMs differ meaningfully. We conduct a large-scale empirical evaluation on over 350 LLMs overall, using two popular leaderboards and a resume-screening task. We find substantial correlation in model errors -- on one leaderboard dataset, models agree 60% of the time when both models err. We identify factors driving model correlation, including shared architectures and providers. Crucially, however, larger and more accurate models have highly correlated errors, even with distinct architectures and providers. Finally, we show the effects of correlation in two downstream tasks: LLM-as-judge evaluation and hiring -- the latter reflecting theoretical predictions regarding algorithmic monoculture.</li>
</ul>

<h3>Title: SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design</h3>
<ul>
<li><strong>Authors: </strong>Wenxin Tang, Jingyu Xiao, Wenxuan Jiang, Xi Xiao, Yuhang Wang, Xuxin Tang, Qing Li, Yuehe Ma, Junliang Liu, Shisong Tang, Michael R. Lyu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07964">https://arxiv.org/abs/2506.07964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07964">https://arxiv.org/pdf/2506.07964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07964]] SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design(https://arxiv.org/abs/2506.07964)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Manual slide creation is labor-intensive and requires expert prior knowledge. Existing natural language-based LLM generation methods struggle to capture the visual and structural nuances of slide designs. To address this, we formalize the Reference Image to Slide Generation task and propose Slide2Code, the first benchmark with difficulty-tiered samples based on a novel Slide Complexity Metric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework for generating editable slides from reference images. SlideCoder integrates a Color Gradient-based Segmentation algorithm and a Hierarchical Retrieval-Augmented Generation method to decompose complex tasks and enhance code generation. We also release SlideMaster, a 7B open-source model fine-tuned with improved reverse-engineered data. Experiments show that SlideCoder outperforms state-of-the-art baselines by up to 40.5 points, demonstrating strong performance across layout fidelity, execution accuracy, and visual consistency. Our code is available at this https URL.</li>
</ul>

<h3>Title: SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07966">https://arxiv.org/abs/2506.07966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07966">https://arxiv.org/pdf/2506.07966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07966]] SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence(https://arxiv.org/abs/2506.07966)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have achieved remarkable progress in various multimodal tasks. To pursue higher intelligence in space, MLLMs require integrating multiple atomic spatial capabilities to handle complex and dynamic tasks. However, existing benchmarks struggle to comprehensively evaluate the spatial intelligence of common MLLMs from the atomic level to the compositional level. To fill this gap, we present SpaCE-10, a comprehensive benchmark for compositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial capabilities, which are combined to form 8 compositional capabilities. Based on these definitions, we propose a novel hierarchical annotation pipeline to generate high-quality and diverse question-answer (QA) pairs. With over 150+ hours of human expert effort, we obtain over 5k QA pairs for 811 real indoor scenes in SpaCE-10, which covers various evaluation settings like point cloud input and multi-choice QA. We conduct an extensive evaluation of common MLLMs on SpaCE-10 and find that even the most advanced MLLM still lags behind humans by large margins. Through our careful study, we also draw several significant findings that benefit the MLLM community. For example, we reveal that the shortcoming of counting capability greatly limits the compositional spatial capabilities of existing MLLMs. The evaluation code and benchmark datasets are available at this https URL.</li>
</ul>

<h3>Title: CyberV: Cybernetics for Test-time Scaling in Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Meng, Shuyang Sun, Yue Tan, Lu Qi, Yunhai Tong, Xiangtai Li, Longyin Wen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07971">https://arxiv.org/abs/2506.07971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07971">https://arxiv.org/pdf/2506.07971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07971]] CyberV: Cybernetics for Test-time Scaling in Video Understanding(https://arxiv.org/abs/2506.07971)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Current Multimodal Large Language Models (MLLMs) may struggle with understanding long or complex videos due to computational demands at test time, lack of robustness, and limited accuracy, primarily stemming from their feed-forward processing nature. These limitations could be more severe for models with fewer parameters. To address these limitations, we propose a novel framework inspired by cybernetic principles, redesigning video MLLMs as adaptive systems capable of self-monitoring, self-correction, and dynamic resource allocation during inference. Our approach, CyberV, introduces a cybernetic loop consisting of an MLLM Inference System, a Sensor, and a Controller. Specifically, the sensor monitors forward processes of the MLLM and collects intermediate interpretations, such as attention drift, then the controller determines when and how to trigger self-correction and generate feedback to guide the next round. This test-time adaptive scaling framework enhances frozen MLLMs without requiring retraining or additional components. Experiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7B by 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitive proprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0% improvement, achieving performance even comparable to human experts. Furthermore, our method demonstrates consistent gains on general-purpose benchmarks, such as VideoMME and WorldSense, highlighting its effectiveness and generalization capabilities in making MLLMs more robust and accurate for dynamic video understanding. The code is released at this https URL.</li>
</ul>

<h3>Title: HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization</h3>
<ul>
<li><strong>Authors: </strong>Hongzheng Chen, Yingheng Wang, Yaohui Cai, Hins Hu, Jiajie Li, Shirley Huang, Chenhui Deng, Rongjian Liang, Shufeng Kong, Haoxing Ren, Samitha Samaranayake, Carla P. Gomes, Zhiru Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07972">https://arxiv.org/abs/2506.07972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07972">https://arxiv.org/pdf/2506.07972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07972]] HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization(https://arxiv.org/abs/2506.07972)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.</li>
</ul>

<h3>Title: Exposing Hidden Backdoors in NFT Smart Contracts: A Static Security Analysis of Rug Pull Patterns</h3>
<ul>
<li><strong>Authors: </strong>Chetan Pathade, Shweta Hooli</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07974">https://arxiv.org/abs/2506.07974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07974">https://arxiv.org/pdf/2506.07974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07974]] Exposing Hidden Backdoors in NFT Smart Contracts: A Static Security Analysis of Rug Pull Patterns(https://arxiv.org/abs/2506.07974)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The explosive growth of Non-Fungible Tokens (NFTs) has revolutionized digital ownership by enabling the creation, exchange, and monetization of unique assets on blockchain networks. However, this surge in popularity has also given rise to a disturbing trend: the emergence of rug pulls - fraudulent schemes where developers exploit trust and smart contract privileges to drain user funds or invalidate asset ownership. Central to many of these scams are hidden backdoors embedded within NFT smart contracts. Unlike unintentional bugs, these backdoors are deliberately coded and often obfuscated to bypass traditional audits and exploit investor confidence. In this paper, we present a large-scale static analysis of 49,940 verified NFT smart contracts using Slither, a static analysis framework, to uncover latent vulnerabilities commonly linked to rug pulls. We introduce a custom risk scoring model that classifies contracts into high, medium, or low risk tiers based on the presence and severity of rug pull indicators. Our dataset was derived from verified contracts on the Ethereum mainnet, and we generate multiple visualizations to highlight red flag clusters, issue prevalence, and co-occurrence of critical vulnerabilities. While we do not perform live exploits, our results reveal how malicious patterns often missed by simple reviews can be surfaced through static analysis at scale. We conclude by offering mitigation strategies for developers, marketplaces, and auditors to enhance smart contract security. By exposing how hidden backdoors manifest in real-world smart contracts, this work contributes a practical foundation for detecting and mitigating NFT rug pulls through scalable automated analysis.</li>
</ul>

<h3>Title: Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator</h3>
<ul>
<li><strong>Authors: </strong>Alberto Bazán-Guillén, Carlos Beis-Penedo, Diego Cajaraville-Aboy, Pablo Barbecho-Bautista, Rebeca P. Díaz-Redondo, Luis J. de la Cruz Llopis, Ana Fernández-Vilas, Mónica Aguilar Igartua, Manuel Fernández-Veiga</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07980">https://arxiv.org/abs/2506.07980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07980">https://arxiv.org/pdf/2506.07980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07980]] Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator(https://arxiv.org/abs/2506.07980)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Realistic urban traffic simulation is essential for sustainable urban planning and the development of intelligent transportation systems. However, generating high-fidelity, time-varying traffic profiles that accurately reflect real-world conditions, especially in large-scale scenarios, remains a major challenge. Existing methods often suffer from limitations in accuracy, scalability, or raise privacy concerns due to centralized data processing. This work introduces DesRUTGe (Decentralized Realistic Urban Traffic Generator), a novel framework that integrates Deep Reinforcement Learning (DRL) agents with the SUMO simulator to generate realistic 24-hour traffic patterns. A key innovation of DesRUTGe is its use of Decentralized Federated Learning (DFL), wherein each traffic detector and its corresponding urban zone function as an independent learning node. These nodes train local DRL models using minimal historical data and collaboratively refine their performance by exchanging model parameters with selected peers (e.g., geographically adjacent zones), without requiring a central coordinator. Evaluated using real-world data from the city of Barcelona, DesRUTGe outperforms standard SUMO-based tools such as RouteSampler, as well as other centralized learning approaches, by delivering more accurate and privacy-preserving traffic pattern generation.</li>
</ul>

<h3>Title: CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray</h3>
<ul>
<li><strong>Authors: </strong>Mingquan Lin, Gregory Holste, Song Wang, Yiliang Zhou, Yishu Wei, Imon Banerjee, Pengyi Chen, Tianjie Dai, Yuexi Du, Nicha C. Dvornek, Yuyan Ge, Zuowei Guo, Shouhei Hanaoka, Dongkyun Kim, Pablo Messina, Yang Lu, Denis Parra, Donghyun Son, Álvaro Soto, Aisha Urooj, René Vidal, Yosuke Yamagishi, Zefan Yang, Ruichi Zhang, Yang Zhou, Leo Anthony Celi, Ronald M. Summers, Zhiyong Lu, Hao Chen, Adam Flanders, George Shih, Zhangyang Wang, Yifan Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07984">https://arxiv.org/abs/2506.07984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07984">https://arxiv.org/pdf/2506.07984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07984]] CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray(https://arxiv.org/abs/2506.07984)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The CXR-LT series is a community-driven initiative designed to enhance lung disease classification using chest X-rays (CXR). It tackles challenges in open long-tailed lung disease classification and enhances the measurability of state-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve these goals by providing high-quality benchmark CXR data for model development and conducting comprehensive evaluations to identify ongoing issues impacting lung disease classification performance. Building on the success of CXR-LT 2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45 disease labels, including 19 new rare disease findings. It also introduces a new focus on zero-shot learning to address limitations identified in the previous event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed classification on a large, noisy test set, (ii) long-tailed classification on a manually annotated "gold standard" subset, and (iii) zero-shot generalization to five previously unseen disease findings. This paper provides an overview of CXR-LT 2024, detailing the data curation process and consolidating state-of-the-art solutions, including the use of multimodal models for rare disease detection, advanced generative approaches to handle noisy labels, and zero-shot learning strategies for unseen diseases. Additionally, the expanded dataset enhances disease coverage to better represent real-world clinical settings, offering a valuable resource for future research. By synthesizing the insights and innovations of participating teams, we aim to advance the development of clinically realistic and generalizable diagnostic models for chest radiography.</li>
</ul>

<h3>Title: Rethinking Crowd-Sourced Evaluation of Neuron Explanations</h3>
<ul>
<li><strong>Authors: </strong>Tuomas Oikarinen, Ge Yan, Akshay Kulkarni, Tsui-Wei Weng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07985">https://arxiv.org/abs/2506.07985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07985">https://arxiv.org/pdf/2506.07985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07985]] Rethinking Crowd-Sourced Evaluation of Neuron Explanations(https://arxiv.org/abs/2506.07985)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Interpreting individual neurons or directions in activations space is an important component of mechanistic interpretability. As such, many algorithms have been proposed to automatically produce neuron explanations, but it is often not clear how reliable these explanations are, or which methods produce the best explanations. This can be measured via crowd-sourced evaluations, but they can often be noisy and expensive, leading to unreliable results. In this paper, we carefully analyze the evaluation pipeline and develop a cost-effective and highly accurate crowdsourced evaluation strategy. In contrast to previous human studies that only rate whether the explanation matches the most highly activating inputs, we estimate whether the explanation describes neuron activations across all inputs. To estimate this effectively, we introduce a novel application of importance sampling to determine which inputs are the most valuable to show to raters, leading to around 30x cost reduction compared to uniform sampling. We also analyze the label noise present in crowd-sourced evaluations and propose a Bayesian method to aggregate multiple ratings leading to a further ~5x reduction in number of ratings required for the same accuracy. Finally, we use these methods to conduct a large-scale study comparing the quality of neuron explanations produced by the most popular methods for two different vision models.</li>
</ul>

<h3>Title: Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Zhengyao Lv, Tianlin Pan, Chenyang Si, Zhaoxi Chen, Wangmeng Zuo, Ziwei Liu, Kwan-Yee K. Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07986">https://arxiv.org/abs/2506.07986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07986">https://arxiv.org/pdf/2506.07986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07986]] Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers(https://arxiv.org/abs/2506.07986)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress in text-driven visual generation. However, even state-of-the-art MM-DiT models like FLUX struggle with achieving precise alignment between text prompts and generated content. We identify two key issues in the attention mechanism of MM-DiT, namely 1) the suppression of cross-modal attention due to token imbalance between visual and textual modalities and 2) the lack of timestep-aware attention weighting, which hinder the alignment. To address these issues, we propose \textbf{Temperature-Adjusted Cross-modal Attention (TACA)}, a parameter-efficient method that dynamically rebalances multimodal interactions through temperature scaling and timestep-dependent adjustment. When combined with LoRA fine-tuning, TACA significantly enhances text-image alignment on the T2I-CompBench benchmark with minimal computational overhead. We tested TACA on state-of-the-art models like FLUX and SD3.5, demonstrating its ability to improve image-text alignment in terms of object appearance, attribute binding, and spatial relationships. Our findings highlight the importance of balancing cross-modal attention in improving semantic fidelity in text-to-image diffusion models. Our codes are publicly available at \href{this https URL}</li>
</ul>

<h3>Title: Unraveling Ethereum's Mempool: The Impact of Fee Fairness, Transaction Prioritization, and Consensus Efficiency</h3>
<ul>
<li><strong>Authors: </strong>S M Mostaq Hossain, Amani Altarawneh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07988">https://arxiv.org/abs/2506.07988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07988">https://arxiv.org/pdf/2506.07988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07988]] Unraveling Ethereum's Mempool: The Impact of Fee Fairness, Transaction Prioritization, and Consensus Efficiency(https://arxiv.org/abs/2506.07988)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Ethereum's transaction pool (mempool) dynamics and fee market efficiency critically affect transaction inclusion, validator workload, and overall network performance. This research empirically analyzes gas price variations, mempool clearance rates, and block finalization times in Ethereum's proof-of-stake ecosystem using real-time data from Geth and Prysm nodes. We observe that high-fee transactions are consistently prioritized, while low-fee transactions face delays or exclusion despite EIP-1559's intended improvements. Mempool congestion remains a key factor in validator efficiency and proposal latency. We provide empirical evidence of persistent fee-based disparities and show that extremely high fees do not always guarantee faster confirmation, revealing inefficiencies in the current fee market. To address these issues, we propose congestion-aware fee adjustments, reserved block slots for low-fee transactions, and improved handling of out-of-gas vulnerabilities. By mitigating prioritization bias and execution inefficiencies, our findings support more equitable transaction inclusion, enhance validator performance, and promote scalability. This work contributes to Ethereum's long-term decentralization by reducing dependence on high transaction fees for network participation.</li>
</ul>

<h3>Title: UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References</h3>
<ul>
<li><strong>Authors: </strong>Ming-Feng Li, Xin Yang, Fu-En Wang, Hritam Basak, Yuyin Sun, Shreekant Gayaka, Min Sun, Cheng-Hao Kuo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07996">https://arxiv.org/abs/2506.07996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07996">https://arxiv.org/pdf/2506.07996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07996]] UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References(https://arxiv.org/abs/2506.07996)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>6D object pose estimation has shown strong generalizability to novel objects. However, existing methods often require either a complete, well-reconstructed 3D model or numerous reference images that fully cover the object. Estimating 6D poses from partial references, which capture only fragments of an object's appearance and geometry, remains challenging. To address this, we propose UA-Pose, an uncertainty-aware approach for 6D object pose estimation and online object completion specifically designed for partial references. We assume access to either (1) a limited set of RGBD images with known poses or (2) a single 2D image. For the first case, we initialize a partial object 3D model based on the provided images and poses, while for the second, we use image-to-3D techniques to generate an initial object 3D model. Our method integrates uncertainty into the incomplete 3D model, distinguishing between seen and unseen regions. This uncertainty enables confidence assessment in pose estimation and guides an uncertainty-aware sampling strategy for online object completion, enhancing robustness in pose estimation accuracy and improving object completeness. We evaluate our method on the YCB-Video, YCBInEOAT, and HO3D datasets, including RGBD sequences of YCB objects manipulated by robots and human hands. Experimental results demonstrate significant performance improvements over existing methods, particularly when object observations are incomplete or partially captured. Project page: this https URL</li>
</ul>

<h3>Title: Generative Modeling of Weights: Generalization or Memorization?</h3>
<ul>
<li><strong>Authors: </strong>Boya Zeng, Yida Yin, Zhiqiu Xu, Zhuang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07998">https://arxiv.org/abs/2506.07998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07998">https://arxiv.org/pdf/2506.07998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07998]] Generative Modeling of Weights: Generalization or Memorization?(https://arxiv.org/abs/2506.07998)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models, with their success in image and video generation, have recently been explored for synthesizing effective neural network weights. These approaches take trained neural network checkpoints as training data, and aim to generate high-performing neural network weights during inference. In this work, we examine four representative methods on their ability to generate novel model weights, i.e., weights that are different from the checkpoints seen during training. Surprisingly, we find that these methods synthesize weights largely by memorization: they produce either replicas, or at best simple interpolations, of the training checkpoints. Current methods fail to outperform simple baselines, such as adding noise to the weights or taking a simple weight ensemble, in obtaining different and simultaneously high-performing models. We further show that this memorization cannot be effectively mitigated by modifying modeling factors commonly associated with memorization in image diffusion models, or applying data augmentations. Our findings provide a realistic assessment of what types of data current generative models can model, and highlight the need for more careful evaluation of generative models in new domains. Our code is available at this https URL.</li>
</ul>

<h3>Title: MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Junhao Chen, Yulia Tsvetkov, Xiaochuang Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.07999">https://arxiv.org/abs/2506.07999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.07999">https://arxiv.org/pdf/2506.07999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.07999]] MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation(https://arxiv.org/abs/2506.07999)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent progress in multimodal generation has increasingly combined autoregressive (AR) and diffusion-based approaches, leveraging their complementary strengths: AR models capture long-range dependencies and produce fluent, context-aware outputs, while diffusion models operate in continuous latent spaces to refine high-fidelity visual details. However, existing hybrids often lack systematic guidance on how and why to allocate model capacity between these paradigms. In this work, we introduce MADFormer, a Mixed Autoregressive and Diffusion Transformer that serves as a testbed for analyzing AR-diffusion trade-offs. MADFormer partitions image generation into spatial blocks, using AR layers for one-pass global conditioning across blocks and diffusion layers for iterative local refinement within each block. Through controlled experiments on FFHQ-1024 and ImageNet, we identify two key insights: (1) block-wise partitioning significantly improves performance on high-resolution images, and (2) vertically mixing AR and diffusion layers yields better quality-efficiency balances--improving FID by up to 75% under constrained inference compute. Our findings offer practical design principles for future hybrid generative models.</li>
</ul>

<h3>Title: Reparameterized LLM Training via Orthogonal Equivalence Transformation</h3>
<ul>
<li><strong>Authors: </strong>Zeju Qiu, Simon Buchholz, Tim Z. Xiao, Maximilian Dax, Bernhard Schölkopf, Weiyang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08001">https://arxiv.org/abs/2506.08001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08001">https://arxiv.org/pdf/2506.08001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08001]] Reparameterized LLM Training via Orthogonal Equivalence Transformation(https://arxiv.org/abs/2506.08001)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) are driving the rapid advancement of artificial intelligence, effectively and reliably training these large models remains one of the field's most significant challenges. To address this challenge, we propose POET, a novel reParameterized training algorithm that uses Orthogonal Equivalence Transformation to optimize neurons. Specifically, POET reparameterizes each neuron with two learnable orthogonal matrices and a fixed random weight matrix. Because of its provable preservation of spectral properties of weight matrices, POET can stably optimize the objective function with improved generalization. We further develop efficient approximations that make POET flexible and scalable for training large-scale neural networks. Extensive experiments validate the effectiveness and scalability of POET in training LLMs.</li>
</ul>

<h3>Title: Dynamic View Synthesis as an Inverse Problem</h3>
<ul>
<li><strong>Authors: </strong>Hidir Yesiltepe, Pinar Yanardag</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08004">https://arxiv.org/abs/2506.08004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08004">https://arxiv.org/pdf/2506.08004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08004]] Dynamic View Synthesis as an Inverse Problem(https://arxiv.org/abs/2506.08004)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we address dynamic view synthesis from monocular videos as an inverse problem in a training-free setting. By redesigning the noise initialization phase of a pre-trained video diffusion model, we enable high-fidelity dynamic view synthesis without any weight updates or auxiliary modules. We begin by identifying a fundamental obstacle to deterministic inversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and resolve it by introducing a novel noise representation, termed K-order Recursive Noise Representation. We derive a closed form expression for this representation, enabling precise and efficient alignment between the VAE-encoded and the DDIM inverted latents. To synthesize newly visible regions resulting from camera motion, we introduce Stochastic Latent Modulation, which performs visibility aware sampling over the latent space to complete occluded regions. Comprehensive experiments demonstrate that dynamic view synthesis can be effectively performed through structured latent manipulation in the noise initialization phase.</li>
</ul>

<h3>Title: ZeroVO: Visual Odometry with Minimal Assumptions</h3>
<ul>
<li><strong>Authors: </strong>Lei Lai, Zekai Yin, Eshed Ohn-Bar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08005">https://arxiv.org/abs/2506.08005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08005">https://arxiv.org/pdf/2506.08005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08005]] ZeroVO: Visual Odometry with Minimal Assumptions(https://arxiv.org/abs/2506.08005)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>We introduce ZeroVO, a novel visual odometry (VO) algorithm that achieves zero-shot generalization across diverse cameras and environments, overcoming limitations in existing methods that depend on predefined or static camera calibration setups. Our approach incorporates three main innovations. First, we design a calibration-free, geometry-aware network structure capable of handling noise in estimated depth and camera parameters. Second, we introduce a language-based prior that infuses semantic information to enhance robust feature extraction and generalization to previously unseen domains. Third, we develop a flexible, semi-supervised training paradigm that iteratively adapts to new scenes using unlabeled data, further boosting the models' ability to generalize across diverse real-world scenarios. We analyze complex autonomous driving contexts, demonstrating over 30% improvement against prior methods on three standard benchmarks, KITTI, nuScenes, and Argoverse 2, as well as a newly introduced, high-fidelity synthetic dataset derived from Grand Theft Auto (GTA). By not requiring fine-tuning or camera calibration, our work broadens the applicability of VO, providing a versatile solution for real-world deployment at scale.</li>
</ul>

<h3>Title: Dreamland: Controllable World Creation with Simulator and Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Sicheng Mo, Ziyang Leng, Leon Liu, Weizhen Wang, Honglin He, Bolei Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08006">https://arxiv.org/abs/2506.08006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08006">https://arxiv.org/pdf/2506.08006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08006]] Dreamland: Controllable World Creation with Simulator and Generative Models(https://arxiv.org/abs/2506.08006)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large-scale video generative models can synthesize diverse and realistic visual content for dynamic world creation, but they often lack element-wise controllability, hindering their use in editing scenes and training embodied AI agents. We propose Dreamland, a hybrid world generation framework combining the granular control of a physics-based simulator and the photorealistic content output of large-scale pretrained generative models. In particular, we design a layered world abstraction that encodes both pixel-level and object-level semantics and geometry as an intermediate representation to bridge the simulator and the generative model. This approach enhances controllability, minimizes adaptation cost through early alignment with real-world distributions, and supports off-the-shelf use of existing and future pretrained generative models. We further construct a D3Sim dataset to facilitate the training and evaluation of hybrid generation pipelines. Experiments demonstrate that Dreamland outperforms existing baselines with 50.8% improved image quality, 17.9% stronger controllability, and has great potential to enhance embodied agent training. Code and data will be made available.</li>
</ul>

<h3>Title: Reinforcement Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Qingxiu Dong, Li Dong, Yao Tang, Tianzhu Ye, Yutao Sun, Zhifang Sui, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08007">https://arxiv.org/abs/2506.08007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08007">https://arxiv.org/pdf/2506.08007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08007]] Reinforcement Pre-Training(https://arxiv.org/abs/2506.08007)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we introduce Reinforcement Pre-Training (RPT) as a new scaling paradigm for large language models and reinforcement learning (RL). Specifically, we reframe next-token prediction as a reasoning task trained using RL, where it receives verifiable rewards for correctly predicting the next token for a given context. RPT offers a scalable method to leverage vast amounts of text data for general-purpose RL, rather than relying on domain-specific annotated answers. By incentivizing the capability of next-token reasoning, RPT significantly improves the language modeling accuracy of predicting the next tokens. Moreover, RPT provides a strong pre-trained foundation for further reinforcement fine-tuning. The scaling curves show that increased training compute consistently improves the next-token prediction accuracy. The results position RPT as an effective and promising scaling paradigm to advance language model pre-training.</li>
</ul>

<h3>Title: Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xun Huang, Zhengqi Li, Guande He, Mingyuan Zhou, Eli Shechtman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08009">https://arxiv.org/abs/2506.08009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08009">https://arxiv.org/pdf/2506.08009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08009]] Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion(https://arxiv.org/abs/2506.08009)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce Self Forcing, a novel training paradigm for autoregressive video diffusion models. It addresses the longstanding issue of exposure bias, where models trained on ground-truth context must generate sequences conditioned on their own imperfect outputs during inference. Unlike prior methods that denoise future frames based on ground-truth context frames, Self Forcing conditions each frame's generation on previously self-generated outputs by performing autoregressive rollout with key-value (KV) caching during training. This strategy enables supervision through a holistic loss at the video level that directly evaluates the quality of the entire generated sequence, rather than relying solely on traditional frame-wise objectives. To ensure training efficiency, we employ a few-step diffusion model along with a stochastic gradient truncation strategy, effectively balancing computational cost and performance. We further introduce a rolling KV cache mechanism that enables efficient autoregressive video extrapolation. Extensive experiments demonstrate that our approach achieves real-time streaming video generation with sub-second latency on a single GPU, while matching or even surpassing the generation quality of significantly slower and non-causal diffusion models. Project website: this http URL</li>
</ul>

<h3>Title: Vision Transformers Don't Need Trained Registers</h3>
<ul>
<li><strong>Authors: </strong>Nick Jiang, Amil Dravid, Alexei Efros, Yossi Gandelsman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08010">https://arxiv.org/abs/2506.08010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08010">https://arxiv.org/pdf/2506.08010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08010]] Vision Transformers Don't Need Trained Registers(https://arxiv.org/abs/2506.08010)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We investigate the mechanism underlying a previously identified phenomenon in Vision Transformers -- the emergence of high-norm tokens that lead to noisy attention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a sparse set of neurons is responsible for concentrating high-norm activations on outlier tokens, leading to irregular attention patterns and degrading downstream visual processing. While the existing solution for removing these outliers involves retraining models from scratch with additional learned register tokens, we use our findings to create a training-free approach to mitigate these artifacts. By shifting the high-norm activations from our discovered register neurons into an additional untrained token, we can mimic the effect of register tokens on a model already trained without registers. We demonstrate that our method produces cleaner attention and feature maps, enhances performance over base models across multiple downstream visual tasks, and achieves results comparable to models explicitly trained with register tokens. We then extend test-time registers to off-the-shelf vision-language models to improve their interpretability. Our results suggest that test-time registers effectively take on the role of register tokens at test-time, offering a training-free solution for any pre-trained model released without them.</li>
</ul>

<h3>Title: Play to Generalize: Learning to Reason Through Game Play</h3>
<ul>
<li><strong>Authors: </strong>Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08011">https://arxiv.org/abs/2506.08011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08011">https://arxiv.org/pdf/2506.08011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08011]] Play to Generalize: Learning to Reason Through Game Play(https://arxiv.org/abs/2506.08011)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Developing generalizable reasoning capabilities in multimodal large language models (MLLMs) remains challenging. Motivated by cognitive science literature suggesting that gameplay promotes transferable cognitive skills, we propose a novel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs develop out-of-domain generalization of multimodal reasoning through playing arcade-like games. Specifically, we show that post-training a 7B-parameter MLLM via reinforcement learning (RL) on simple arcade-like games, e.g. Snake, significantly enhances its downstream performance on multimodal math benchmarks like MathVista, and on multi-discipline questions like MMMU, without seeing any worked solutions, equations, or diagrams during RL, suggesting the capture of transferable reasoning skills. Remarkably, our model outperforms specialist models tuned on multimodal reasoning data in multimodal reasoning benchmarks, while preserving the base model's performance on general visual benchmarks, a challenge where specialist models often fall short. Our findings suggest a new post-training paradigm: synthetic, rule-based games can serve as controllable and scalable pre-text tasks that unlock generalizable multimodal reasoning abilities in MLLMs.</li>
</ul>

<h3>Title: StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets</h3>
<ul>
<li><strong>Authors: </strong>Anh-Quan Cao, Ivan Lopes, Raoul de Charette</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08013">https://arxiv.org/abs/2506.08013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08013">https://arxiv.org/pdf/2506.08013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08013]] StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets(https://arxiv.org/abs/2506.08013)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Multi-task learning for dense prediction is limited by the need for extensive annotation for every task, though recent works have explored training with partial task labels. Leveraging the generalization power of diffusion models, we extend the partial learning setup to a zero-shot setting, training a multi-task model on multiple synthetic datasets, each labeled for only a subset of tasks. Our method, StableMTL, repurposes image generators for latent regression. Adapting a denoising framework with task encoding, per-task conditioning and a tailored training scheme. Instead of per-task losses requiring careful balancing, a unified latent loss is adopted, enabling seamless scaling to more tasks. To encourage inter-task synergy, we introduce a multi-stream model with a task-attention mechanism that converts N-to-N task interactions into efficient 1-to-N attention, promoting effective cross-task sharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.</li>
</ul>

<h3>Title: 4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos</h3>
<ul>
<li><strong>Authors: </strong>Zhen Xu, Zhengqin Li, Zhao Dong, Xiaowei Zhou, Richard Newcombe, Zhaoyang Lv</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08015">https://arxiv.org/abs/2506.08015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08015">https://arxiv.org/pdf/2506.08015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08015]] 4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos(https://arxiv.org/abs/2506.08015)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose 4DGT, a 4D Gaussian-based Transformer model for dynamic scene reconstruction, trained entirely on real-world monocular posed videos. Using 4D Gaussian as an inductive bias, 4DGT unifies static and dynamic components, enabling the modeling of complex, time-varying environments with varying object lifespans. We proposed a novel density control strategy in training, which enables our 4DGT to handle longer space-time input and remain efficient rendering at runtime. Our model processes 64 consecutive posed frames in a rolling-window fashion, predicting consistent 4D Gaussians in the scene. Unlike optimization-based methods, 4DGT performs purely feed-forward inference, reducing reconstruction time from hours to seconds and scaling effectively to long video sequences. Trained only on large-scale monocular posed video datasets, 4DGT can outperform prior Gaussian-based networks significantly in real-world videos and achieve on-par accuracy with optimization-based methods on cross-domain videos. Project page: this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
