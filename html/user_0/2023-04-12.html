<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Helix++: A platform for efficiently securing software. (arXiv:2304.04846v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04846">http://arxiv.org/abs/2304.04846</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04846] Helix++: A platform for efficiently securing software](http://arxiv.org/abs/2304.04846) #secure</code></li>
<li>Summary: <p>The open-source Helix++ project improves the security posture of computing
platforms by applying cutting-edge cybersecurity techniques to diversify and
harden software automatically. A distinguishing feature of Helix++ is that it
does not require source code or build artifacts; it operates directly on
software in binary form--even stripped executables and libraries. This feature
is key as rebuilding applications from source is a time-consuming and often
frustrating process. Diversification breaks the software monoculture and makes
attacks harder to execute as information needed for a successful attack will
have changed unpredictably. Diversification also forces attackers to customize
an attack for each target instead of attackers crafting an exploit that works
reliably on all similarly configured targets. Hardening directly targets key
attack classes. The combination of diversity and hardening provides
defense-in-depth, as well as a moving target defense, to secure the Nation's
cyber infrastructure.
</p></li>
</ul>

<h3>Title: TREBUCHET: Fully Homomorphic Encryption Accelerator for Deep Computation. (arXiv:2304.05237v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05237">http://arxiv.org/abs/2304.05237</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05237] TREBUCHET: Fully Homomorphic Encryption Accelerator for Deep Computation](http://arxiv.org/abs/2304.05237) #secure</code></li>
<li>Summary: <p>Secure computation is of critical importance to not only the DoD, but across
financial institutions, healthcare, and anywhere personally identifiable
information (PII) is accessed. Traditional security techniques require data to
be decrypted before performing any computation. When processed on untrusted
systems the decrypted data is vulnerable to attacks to extract the sensitive
information. To address these vulnerabilities Fully Homomorphic Encryption
(FHE) keeps the data encrypted during computation and secures the results, even
in these untrusted environments. However, FHE requires a significant amount of
computation to perform equivalent unencrypted operations. To be useful, FHE
must significantly close the computation gap (within 10x) to make encrypted
processing practical. To accomplish this ambitious goal the TREBUCHET project
is leading research and development in FHE processing hardware to accelerate
deep computations on encrypted data, as part of the DARPA MTO Data Privacy for
Virtual Environments (DPRIVE) program. We accelerate the major secure
standardized FHE schemes (BGV, BFV, CKKS, FHEW, etc.) at >=128-bit security
while integrating with the open-source PALISADE and OpenFHE libraries currently
used in the DoD and in industry. We utilize a novel tile-based chip design with
highly parallel ALUs optimized for vectorized 128b modulo arithmetic. The
TREBUCHET coprocessor design provides a highly modular, flexible, and
extensible FHE accelerator for easy reconfiguration, deployment, integration
and application on other hardware form factors, such as System-on-Chip or
alternate chip areas.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Advances in Cybercrime Prediction: A Survey of Machine, Deep, Transfer, and Adaptive Learning Techniques. (arXiv:2304.04819v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04819">http://arxiv.org/abs/2304.04819</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04819] Advances in Cybercrime Prediction: A Survey of Machine, Deep, Transfer, and Adaptive Learning Techniques](http://arxiv.org/abs/2304.04819) #security</code></li>
<li>Summary: <p>Cybercrime is a growing threat to organizations and individuals worldwide,
with criminals using increasingly sophisticated techniques to breach security
systems and steal sensitive data. In recent years, machine learning, deep
learning, and transfer learning techniques have emerged as promising tools for
predicting cybercrime and preventing it before it occurs. This paper aims to
provide a comprehensive survey of the latest advancements in cybercrime
prediction using above mentioned techniques, highlighting the latest research
related to each approach. For this purpose, we reviewed more than 150 research
articles and discussed around 50 most recent and relevant research articles. We
start the review by discussing some common methods used by cyber criminals and
then focus on the latest machine learning techniques and deep learning
techniques, such as recurrent and convolutional neural networks, which were
effective in detecting anomalous behavior and identifying potential threats. We
also discuss transfer learning, which allows models trained on one dataset to
be adapted for use on another dataset, and then focus on active and
reinforcement Learning as part of early-stage algorithmic research in
cybercrime prediction. Finally, we discuss critical innovations, research gaps,
and future research opportunities in Cybercrime prediction. Overall, this paper
presents a holistic view of cutting-edge developments in cybercrime prediction,
shedding light on the strengths and limitations of each method and equipping
researchers and practitioners with essential insights, publicly available
datasets, and resources necessary to develop efficient cybercrime prediction
systems.
</p></li>
</ul>

<h3>Title: Optimizing Linear Correctors: A Tight Output Min-Entropy Bound and Selection Technique. (arXiv:2304.05306v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05306">http://arxiv.org/abs/2304.05306</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05306] Optimizing Linear Correctors: A Tight Output Min-Entropy Bound and Selection Technique](http://arxiv.org/abs/2304.05306) #security</code></li>
<li>Summary: <p>Post-processing of the raw bits produced by a true random number generator
(TRNG) is always necessary when the entropy per bit is insufficient for
security applications. In this paper, we derive a tight bound on the output
min-entropy of the algorithmic post-processing module based on linear codes,
known as linear correctors. Our bound is based on the codes' weight
distributions, and we prove that it holds even for the real-world noise sources
that produce independent but not identically distributed bits. Additionally, we
present a method for identifying the optimal linear corrector for a given input
min-entropy rate that maximizes the throughput of the post-processed bits while
simultaneously achieving the needed security level. Our findings show that for
an output min-entropy rate of $0.999$, the extraction efficiency of the linear
correctors with the new bound can be up to $130.56\%$ higher when compared to
the old bound, with an average improvement of $41.2\%$ over the entire input
min-entropy range. On the other hand, the required min-entropy of the raw bits
for the individual correctors can be reduced by up to $61.62\%$.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Multi-step Jailbreaking Privacy Attacks on ChatGPT. (arXiv:2304.05197v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05197">http://arxiv.org/abs/2304.05197</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05197] Multi-step Jailbreaking Privacy Attacks on ChatGPT](http://arxiv.org/abs/2304.05197) #privacy</code></li>
<li>Summary: <p>With the rapid progress of large language models (LLMs), many downstream NLP
tasks can be well solved given good prompts. Though model developers and
researchers work hard on dialog safety to avoid generating harmful content from
LLMs, it is still challenging to steer AI-generated content (AIGC) for the
human good. As powerful LLMs are devouring existing text data from various
domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether
the private information is included in the training data and what privacy
threats can these LLMs and their downstream applications bring. In this paper,
we study the privacy threats from OpenAI's model APIs and New Bing enhanced by
ChatGPT and show that application-integrated LLMs may cause more severe privacy
threats ever than before. To this end, we conduct extensive experiments to
support our claims and discuss LLMs' privacy implications.
</p></li>
</ul>

<h3>Title: Privacy Amplification via Shuffling: Unified, Simplified, and Tightened. (arXiv:2304.05007v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05007">http://arxiv.org/abs/2304.05007</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05007] Privacy Amplification via Shuffling: Unified, Simplified, and Tightened](http://arxiv.org/abs/2304.05007) #privacy</code></li>
<li>Summary: <p>In decentralized settings, the shuffle model of differential privacy has
emerged as a promising alternative to the classical local model. Analyzing
privacy amplification via shuffling is a critical component in both
single-message and multi-message shuffle protocols. However, current methods
used in these two areas are distinct and specific, making them less convenient
for protocol designers and practitioners. In this work, we introduce
variation-ratio reduction as a unified framework for privacy amplification
analyses in the shuffle model. This framework utilizes total variation bounds
of local messages and probability ratio bounds of other users' blanket
messages, converting them to indistinguishable levels. Our results indicate
that the framework yields tighter bounds for both single-message and
multi-message encoders (e.g., with local DP, local metric DP, or general
multi-message randomizers). Specifically, for a broad range of local
randomizers having extremal probability design, our amplification bounds are
precisely tight. We also demonstrate that variation-ratio reduction is
well-suited for parallel composition in the shuffle model and results in
stricter privacy accounting for common sampling-based local randomizers. Our
experimental findings show that, compared to existing amplification bounds, our
numerical amplification bounds can save up to $30\%$ of the budget for
single-message protocols, $75\%$ of the budget for multi-message protocols, and
$75\%$-$95\%$ of the budget for parallel composition. Additionally, our
implementation for numerical amplification bounds has only $\tilde{O}(n)$
complexity and is highly efficient in practice, taking just $2$ minutes for
$n=10^8$ users. The code for our implementation can be found at
\url{https://github.com/wangsw/PrivacyAmplification}.
</p></li>
</ul>

<h3>Title: RecUP-FL: Reconciling Utility and Privacy in Federated Learning via User-configurable Privacy Defense. (arXiv:2304.05135v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05135">http://arxiv.org/abs/2304.05135</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05135] RecUP-FL: Reconciling Utility and Privacy in Federated Learning via User-configurable Privacy Defense](http://arxiv.org/abs/2304.05135) #privacy</code></li>
<li>Summary: <p>Federated learning (FL) provides a variety of privacy advantages by allowing
clients to collaboratively train a model without sharing their private data.
However, recent studies have shown that private information can still be leaked
through shared gradients. To further minimize the risk of privacy leakage,
existing defenses usually require clients to locally modify their gradients
(e.g., differential privacy) prior to sharing with the server. While these
approaches are effective in certain cases, they regard the entire data as a
single entity to protect, which usually comes at a large cost in model utility.
In this paper, we seek to reconcile utility and privacy in FL by proposing a
user-configurable privacy defense, RecUP-FL, that can better focus on the
user-specified sensitive attributes while obtaining significant improvements in
utility over traditional defenses. Moreover, we observe that existing inference
attacks often rely on a machine learning model to extract the private
information (e.g., attributes). We thus formulate such a privacy defense as an
adversarial learning problem, where RecUP-FL generates slight perturbations
that can be added to the gradients before sharing to fool adversary models. To
improve the transferability to un-queryable black-box adversary models,
inspired by the idea of meta-learning, RecUP-FL forms a model zoo containing a
set of substitute models and iteratively alternates between simulations of the
white-box and the black-box adversarial attack scenarios to generate
perturbations. Extensive experiments on four datasets under various adversarial
settings (both attribute inference attack and data reconstruction attack) show
that RecUP-FL can meet user-specified privacy constraints over the sensitive
attributes while significantly improving the model utility compared with
state-of-the-art privacy defenses.
</p></li>
</ul>

<h3>Title: iDML: Incentivized Decentralized Machine Learning. (arXiv:2304.05354v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05354">http://arxiv.org/abs/2304.05354</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05354] iDML: Incentivized Decentralized Machine Learning](http://arxiv.org/abs/2304.05354) #privacy</code></li>
<li>Summary: <p>With the rising emergence of decentralized and opportunistic approaches to
machine learning, end devices are increasingly tasked with training deep
learning models on-devices using crowd-sourced data that they collect
themselves. These approaches are desirable from a resource consumption
perspective and also from a privacy preservation perspective. When the devices
benefit directly from the trained models, the incentives are implicit -
contributing devices' resources are incentivized by the availability of the
higher-accuracy model that results from collaboration. However, explicit
incentive mechanisms must be provided when end-user devices are asked to
contribute their resources (e.g., computation, communication, and data) to a
task performed primarily for the benefit of others, e.g., training a model for
a task that a neighbor device needs but the device owner is uninterested in. In
this project, we propose a novel blockchain-based incentive mechanism for
completely decentralized and opportunistic learning architectures. We leverage
a smart contract not only for providing explicit incentives to end devices to
participate in decentralized learning but also to create a fully decentralized
mechanism to inspect and reflect on the behavior of the learning architecture.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: ImageCaptioner$^2$: Image Captioner for Image Captioning Bias Amplification Assessment. (arXiv:2304.04874v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04874">http://arxiv.org/abs/2304.04874</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04874] ImageCaptioner$^2$: Image Captioner for Image Captioning Bias Amplification Assessment](http://arxiv.org/abs/2304.04874) #protect</code></li>
<li>Summary: <p>Most pre-trained learning systems are known to suffer from bias, which
typically emerges from the data, the model, or both. Measuring and quantifying
bias and its sources is a challenging task and has been extensively studied in
image captioning. Despite the significant effort in this direction, we observed
that existing metrics lack consistency in the inclusion of the visual signal.
In this paper, we introduce a new bias assessment metric, dubbed
$ImageCaptioner^2$, for image captioning. Instead of measuring the absolute
bias in the model or the data, $ImageCaptioner^2$ pay more attention to the
bias introduced by the model w.r.t the data bias, termed bias amplification.
Unlike the existing methods, which only evaluate the image captioning
algorithms based on the generated captions only, $ImageCaptioner^2$
incorporates the image while measuring the bias. In addition, we design a
formulation for measuring the bias of generated captions as prompt-based image
captioning instead of using language classifiers. Finally, we apply our
$ImageCaptioner^2$ metric across 11 different image captioning architectures on
three different datasets, i.e., MS-COCO caption dataset, Artemis V1, and
Artemis V2, and on three different protected attributes, i.e., gender, race,
and emotions. Consequently, we verify the effectiveness of our
$ImageCaptioner^2$ metric by proposing AnonymousBench, which is a novel human
evaluation paradigm for bias metrics. Our metric shows significant superiority
over the recent bias metric; LIC, in terms of human alignment, where the
correlation scores are 80% and 54% for our metric and LIC, respectively. The
code is available at https://eslambakr.github.io/imagecaptioner2.github.io/.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning. (arXiv:2304.04824v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04824">http://arxiv.org/abs/2304.04824</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04824] Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning](http://arxiv.org/abs/2304.04824) #attack</code></li>
<li>Summary: <p>Predictions made by deep learning models are prone to data perturbations,
adversarial attacks, and out-of-distribution inputs. To build a trusted AI
system, it is therefore critical to accurately quantify the prediction
uncertainties. While current efforts focus on improving uncertainty
quantification accuracy and efficiency, there is a need to identify uncertainty
sources and take actions to mitigate their effects on predictions. Therefore,
we propose to develop explainable and actionable Bayesian deep learning methods
to not only perform accurate uncertainty quantification but also explain the
uncertainties, identify their sources, and propose strategies to mitigate the
uncertainty impacts. Specifically, we introduce a gradient-based uncertainty
attribution method to identify the most problematic regions of the input that
contribute to the prediction uncertainty. Compared to existing methods, the
proposed UA-Backprop has competitive accuracy, relaxed assumptions, and high
efficiency. Moreover, we propose an uncertainty mitigation strategy that
leverages the attribution results as attention to further improve the model
performance. Both qualitative and quantitative evaluations are conducted to
demonstrate the effectiveness of our proposed methods.
</p></li>
</ul>

<h3>Title: Simultaneous Adversarial Attacks On Multiple Face Recognition System Components. (arXiv:2304.05048v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05048">http://arxiv.org/abs/2304.05048</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05048] Simultaneous Adversarial Attacks On Multiple Face Recognition System Components](http://arxiv.org/abs/2304.05048) #attack</code></li>
<li>Summary: <p>In this work, we investigate the potential threat of adversarial examples to
the security of face recognition systems. Although previous research has
explored the adversarial risk to individual components of FRSs, our study
presents an initial exploration of an adversary simultaneously fooling multiple
components: the face detector and feature extractor in an FRS pipeline. We
propose three multi-objective attacks on FRSs and demonstrate their
effectiveness through a preliminary experimental analysis on a target system.
Our attacks achieved up to 100% Attack Success Rates against both the face
detector and feature extractor and were able to manipulate the face detection
probability by up to 50% depending on the adversarial objective. This research
identifies and examines novel attack vectors against FRSs and suggests possible
ways to augment the robustness by leveraging the attack vector's knowledge
during training of an FRS's components.
</p></li>
</ul>

<h3>Title: Overload: Latency Attacks on Object Detection for Edge Devices. (arXiv:2304.05370v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05370">http://arxiv.org/abs/2304.05370</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05370] Overload: Latency Attacks on Object Detection for Edge Devices](http://arxiv.org/abs/2304.05370) #attack</code></li>
<li>Summary: <p>Nowadays, the deployment of deep learning based applications on edge devices
is an essential task owing to the increasing demands on intelligent services.
However, the limited computing resources on edge nodes make the models
vulnerable to attacks, such that the predictions made by models are unreliable.
In this paper, we investigate latency attacks on deep learning applications.
Unlike common adversarial attacks for misclassification, the goal of latency
attacks is to increase the inference time, which may stop applications from
responding to the requests within a reasonable time. This kind of attack is
ubiquitous for various applications, and we use object detection to demonstrate
how such kind of attacks work. We also design a framework named Overload to
generate latency attacks at scale. Our method is based on a newly formulated
optimization problem and a novel technique, called spatial attention, to
increase the inference time of object detection. We have conducted experiments
using YOLOv5 models on Nvidia NX. The experimental results show that with
latency attacks, the inference time of a single image can be increased ten
times longer in reference to the normal setting. Moreover, comparing to
existing methods, our attacking method is simpler and more effective.
</p></li>
</ul>

<h3>Title: Detecting Anomalous Microflows in IoT Volumetric Attacks via Dynamic Monitoring of MUD Activity. (arXiv:2304.04987v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04987">http://arxiv.org/abs/2304.04987</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04987] Detecting Anomalous Microflows in IoT Volumetric Attacks via Dynamic Monitoring of MUD Activity](http://arxiv.org/abs/2304.04987) #attack</code></li>
<li>Summary: <p>IoT networks are increasingly becoming target of sophisticated new
cyber-attacks. Anomaly-based detection methods are promising in finding new
attacks, but there are certain practical challenges like false-positive alarms,
hard to explain, and difficult to scale cost-effectively. The IETF recent
standard called Manufacturer Usage Description (MUD) seems promising to limit
the attack surface on IoT devices by formally specifying their intended network
behavior. In this paper, we use SDN to enforce and monitor the expected
behaviors of each IoT device, and train one-class classifier models to detect
volumetric attacks.
</p></li>
</ul>

<p>Our specific contributions are fourfold. (1) We develop a multi-level
inferencing model to dynamically detect anomalous patterns in network activity
of MUD-compliant traffic flows via SDN telemetry, followed by packet inspection
of anomalous flows. This provides enhanced fine-grained visibility into
distributed and direct attacks, allowing us to precisely isolate volumetric
attacks with microflow (5-tuple) resolution. (2) We collect traffic traces
(benign and a variety of volumetric attacks) from network behavior of IoT
devices in our lab, generate labeled datasets, and make them available to the
public. (3) We prototype a full working system (modules are released as
open-source), demonstrates its efficacy in detecting volumetric attacks on
several consumer IoT devices with high accuracy while maintaining low false
positives, and provides insights into cost and performance of our system. (4)
We demonstrate how our models scale in environments with a large number of
connected IoTs (with datasets collected from a network of IP cameras in our
university campus) by considering various training strategies (per device unit
versus per device type), and balancing the accuracy of prediction against the
cost of models in terms of size and training time.
</p>

<h3>Title: Algorithms for Reconstructing DDoS Attack Graphs using Probabilistic Packet Marking. (arXiv:2304.05123v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05123">http://arxiv.org/abs/2304.05123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05123] Algorithms for Reconstructing DDoS Attack Graphs using Probabilistic Packet Marking](http://arxiv.org/abs/2304.05123) #attack</code></li>
<li>Summary: <p>DoS and DDoS attacks are widely used and pose a constant threat. Here we
explore Probability Packet Marking (PPM), one of the important methods for
reconstructing the attack-graph and detect the attackers. We present two
algorithms. Differently from others, their stopping time is not fixed a priori.
It rather depends on the actual distance of the attacker from the victim. Our
first algorithm returns the graph at the earliest feasible time, and turns out
to guarantee high success probability. The second algorithm enables attaining
any predetermined success probability at the expense of a longer runtime. We
study the performance of the two algorithms theoretically, and compare them to
other algorithms by simulation. Finally, we consider the order in which the
marks corresponding to the various edges of the attack graph are obtained by
the victim. We show that, although edges closer to the victim tend to be
discovered earlier in the process than farther edges, the differences are much
smaller than previously thought.
</p></li>
</ul>

<h3>Title: Journey to the Center of Software Supply Chain Attacks. (arXiv:2304.05200v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05200">http://arxiv.org/abs/2304.05200</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05200] Journey to the Center of Software Supply Chain Attacks](http://arxiv.org/abs/2304.05200) #attack</code></li>
<li>Summary: <p>This work discusses open-source software supply chain attacks and proposes a
general taxonomy describing how attackers conduct them. We then provide a list
of safeguards to mitigate such attacks. We present our tool "Risk Explorer for
Software Supply Chains" to explore such information and we discuss its
industrial use-cases.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Human Motion Detection Based on Dual-Graph and Weighted Nuclear Norm Regularizations. (arXiv:2304.04879v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04879">http://arxiv.org/abs/2304.04879</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04879] Human Motion Detection Based on Dual-Graph and Weighted Nuclear Norm Regularizations](http://arxiv.org/abs/2304.04879) #robust</code></li>
<li>Summary: <p>Motion detection has been widely used in many applications, such as
surveillance and robotics. Due to the presence of the static background, a
motion video can be decomposed into a low-rank background and a sparse
foreground. Many regularization techniques that preserve low-rankness of
matrices can therefore be imposed on the background. In the meanwhile,
geometry-based regularizations, such as graph regularizations, can be imposed
on the foreground. Recently, weighted regularization techniques including the
weighted nuclear norm regularization have been proposed in the image processing
community to promote adaptive sparsity while achieving efficient performance.
In this paper, we propose a robust dual graph regularized moving object
detection model based on a novel weighted nuclear norm regularization and
spatiotemporal graph Laplacians. Numerical experiments on realistic human
motion data sets have demonstrated the effectiveness and robustness of this
approach in separating moving objects from background, and the enormous
potential in robotic applications.
</p></li>
</ul>

<h3>Title: Multi-Sample Consensus Driven Unsupervised Normal Estimation for 3D Point Clouds. (arXiv:2304.04884v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04884">http://arxiv.org/abs/2304.04884</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04884] Multi-Sample Consensus Driven Unsupervised Normal Estimation for 3D Point Clouds](http://arxiv.org/abs/2304.04884) #robust</code></li>
<li>Summary: <p>Deep normal estimators have made great strides on synthetic benchmarks.
Unfortunately, their performance dramatically drops on the real scan data since
they are supervised only on synthetic datasets. The point-wise annotation of
ground truth normals is vulnerable to inefficiency and inaccuracies, which
totally makes it impossible to build perfect real datasets for supervised deep
learning. To overcome the challenge, we propose a multi-sample consensus
paradigm for unsupervised normal estimation. The paradigm consists of
multi-candidate sampling, candidate rejection, and mode determination. The
latter two are driven by neighbor point consensus and candidate consensus
respectively. Two primary implementations of the paradigm, MSUNE and MSUNE-Net,
are proposed. MSUNE minimizes a candidate consensus loss in mode determination.
As a robust optimization method, it outperforms the cutting-edge supervised
deep learning methods on real data at the cost of longer runtime for sampling
enough candidate normals for each query point. MSUNE-Net, the first
unsupervised deep normal estimator as far as we know, significantly promotes
the multi-sample consensus further. It transfers the three online stages of
MSUNE to offline training. Thereby its inference time is 100 times faster.
Besides that, more accurate inference is achieved, since the candidates of
query points from similar patches can form a sufficiently large candidate set
implicitly in MSUNE-Net. Comprehensive experiments demonstrate that the two
proposed unsupervised methods are noticeably superior to some supervised deep
normal estimators on the most common synthetic dataset. More importantly, they
show better generalization ability and outperform all the SOTA conventional and
deep methods on three real datasets: NYUV2, KITTI, and a dataset from PCV [1].
</p></li>
</ul>

<h3>Title: Neural Image-based Avatars: Generalizable Radiance Fields for Human Avatar Modeling. (arXiv:2304.04897v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04897">http://arxiv.org/abs/2304.04897</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04897] Neural Image-based Avatars: Generalizable Radiance Fields for Human Avatar Modeling](http://arxiv.org/abs/2304.04897) #robust</code></li>
<li>Summary: <p>We present a method that enables synthesizing novel views and novel poses of
arbitrary human performers from sparse multi-view images. A key ingredient of
our method is a hybrid appearance blending module that combines the advantages
of the implicit body NeRF representation and image-based rendering. Existing
generalizable human NeRF methods that are conditioned on the body model have
shown robustness against the geometric variation of arbitrary human performers.
Yet they often exhibit blurry results when generalized onto unseen identities.
Meanwhile, image-based rendering shows high-quality results when sufficient
observations are available, whereas it suffers artifacts in sparse-view
settings. We propose Neural Image-based Avatars (NIA) that exploits the best of
those two methods: to maintain robustness under new articulations and
self-occlusions while directly leveraging the available (sparse) source view
colors to preserve appearance details of new subject identities. Our hybrid
design outperforms recent methods on both in-domain identity generalization as
well as challenging cross-dataset generalization settings. Also, in terms of
the pose generalization, our method outperforms even the per-subject optimized
animatable NeRF methods. The video results are available at
https://youngjoongunc.github.io/nia
</p></li>
</ul>

<h3>Title: PlantDet: A benchmark for Plant Detection in the Three-Rivers-Source Region. (arXiv:2304.04963v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04963">http://arxiv.org/abs/2304.04963</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04963] PlantDet: A benchmark for Plant Detection in the Three-Rivers-Source Region](http://arxiv.org/abs/2304.04963) #robust</code></li>
<li>Summary: <p>The Three-River-Source region is a highly significant natural reserve in
China that harbors a plethora of untamed botanical resources. To meet the
practical requirements of botanical research and intelligent plant management,
we construct a large-scale dataset for Plant detection in the
Three-River-Source region (PTRS). This dataset comprises 6965 high-resolution
images of 2160*3840 pixels, captured by diverse sensors and platforms, and
featuring objects of varying shapes and sizes. Subsequently, a team of
botanical image interpretation experts annotated these images with 21 commonly
occurring object categories. The fully annotated PTRS images contain 122, 300
instances of plant leaves, each labeled by a horizontal rectangle. The PTRS
presents us with challenges such as dense occlusion, varying leaf resolutions,
and high feature similarity among plants, prompting us to develop a novel
object detection network named PlantDet. This network employs a window-based
efficient self-attention module (ST block) to generate robust feature
representation at multiple scales, improving the detection efficiency for small
and densely-occluded objects. Our experimental results validate the efficacy of
our proposed plant detection benchmark, with a precision of 88.1%, a mean
average precision (mAP) of 77.6%, and a higher recall compared to the baseline.
Additionally, our method effectively overcomes the issue of missing small
objects. We intend to share our data and code with interested parties to
advance further research in this field.
</p></li>
</ul>

<h3>Title: Generating Features with Increased Crop-related Diversity for Few-Shot Object Detection. (arXiv:2304.05096v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05096">http://arxiv.org/abs/2304.05096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05096] Generating Features with Increased Crop-related Diversity for Few-Shot Object Detection](http://arxiv.org/abs/2304.05096) #robust</code></li>
<li>Summary: <p>Two-stage object detectors generate object proposals and classify them to
detect objects in images. These proposals often do not contain the objects
perfectly but overlap with them in many possible ways, exhibiting great
variability in the difficulty levels of the proposals. Training a robust
classifier against this crop-related variability requires abundant training
data, which is not available in few-shot settings. To mitigate this issue, we
propose a novel variational autoencoder (VAE) based data generation model,
which is capable of generating data with increased crop-related diversity. The
main idea is to transform the latent space such latent codes with different
norms represent different crop-related variations. This allows us to generate
features with increased crop-related diversity in difficulty levels by simply
varying the latent norm. In particular, each latent code is rescaled such that
its norm linearly correlates with the IoU score of the input crop w.r.t. the
ground-truth box. Here the IoU score is a proxy that represents the difficulty
level of the crop. We train this VAE model on base classes conditioned on the
semantic code of each class and then use the trained model to generate features
for novel classes. In our experiments our generated features consistently
improve state-of-the-art few-shot object detection methods on the PASCAL VOC
and MS COCO datasets.
</p></li>
</ul>

<h3>Title: Benchmarking the Physical-world Adversarial Robustness of Vehicle Detection. (arXiv:2304.05098v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05098">http://arxiv.org/abs/2304.05098</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05098] Benchmarking the Physical-world Adversarial Robustness of Vehicle Detection](http://arxiv.org/abs/2304.05098) #robust</code></li>
<li>Summary: <p>Adversarial attacks in the physical world can harm the robustness of
detection models. Evaluating the robustness of detection models in the physical
world can be challenging due to the time-consuming and labor-intensive nature
of many experiments. Thus, virtual simulation experiments can provide a
solution to this challenge. However, there is no unified detection benchmark
based on virtual simulation environment. To address this challenge, we proposed
an instant-level data generation pipeline based on the CARLA simulator. Using
this pipeline, we generated the DCI dataset and conducted extensive experiments
on three detection models and three physical adversarial attacks. The dataset
covers 7 continuous and 1 discrete scenes, with over 40 angles, 20 distances,
and 20,000 positions. The results indicate that Yolo v6 had strongest
resistance, with only a 6.59% average AP drop, and ASA was the most effective
attack algorithm with a 14.51% average AP reduction, twice that of other
algorithms. Static scenes had higher recognition AP, and results under
different weather conditions were similar. Adversarial attack algorithm
improvement may be approaching its 'limitation'.
</p></li>
</ul>

<h3>Title: Loop Closure Detection Based on Object-level Spatial Layout and Semantic Consistency. (arXiv:2304.05146v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05146">http://arxiv.org/abs/2304.05146</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05146] Loop Closure Detection Based on Object-level Spatial Layout and Semantic Consistency](http://arxiv.org/abs/2304.05146) #robust</code></li>
<li>Summary: <p>Visual simultaneous localization and mapping (SLAM) systems face challenges
in detecting loop closure under the circumstance of large viewpoint changes. In
this paper, we present an object-based loop closure detection method based on
the spatial layout and semanic consistency of the 3D scene graph. Firstly, we
propose an object-level data association approach based on the semantic
information from semantic labels, intersection over union (IoU), object color,
and object embedding. Subsequently, multi-view bundle adjustment with the
associated objects is utilized to jointly optimize the poses of objects and
cameras. We represent the refined objects as a 3D spatial graph with semantics
and topology. Then, we propose a graph matching approach to select
correspondence objects based on the structure layout and semantic property
similarity of vertices' neighbors. Finally, we jointly optimize camera
trajectories and object poses in an object-level pose graph optimization, which
results in a globally consistent map. Experimental results demonstrate that our
proposed data association approach can construct more accurate 3D semantic
maps, and our loop closure method is more robust than point-based and
object-based methods in circumstances with large viewpoint changes.
</p></li>
</ul>

<h3>Title: Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05265">http://arxiv.org/abs/2304.05265</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05265] Controllable Textual Inversion for Personalized Text-to-Image Generation](http://arxiv.org/abs/2304.05265) #robust</code></li>
<li>Summary: <p>The recent large-scale generative modeling has attained unprecedented
performance especially in producing high-fidelity images driven by text
prompts. Text inversion (TI), alongside the text-to-image model backbones, is
proposed as an effective technique in personalizing the generation when the
prompts contain user-defined, unseen or long-tail concept tokens. Despite that,
we find and show that the deployment of TI remains full of "dark-magics" -- to
name a few, the harsh requirement of additional datasets, arduous human efforts
in the loop and lack of robustness. In this work, we propose a much-enhanced
version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all
the aforementioned problems and in turn delivering a robust, data-efficient and
easy-to-use framework. The core to COTI is a theoretically-guided loss
objective instantiated with a comprehensive and novel weighted scoring
mechanism, encapsulated by an active-learning paradigm. The extensive results
show that COTI significantly outperforms the prior TI-related approaches with a
26.05 decrease in the FID score and a 23.00% boost in the R-precision.
</p></li>
</ul>

<h3>Title: Unified Multi-Modal Image Synthesis for Missing Modality Imputation. (arXiv:2304.05340v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05340">http://arxiv.org/abs/2304.05340</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05340] Unified Multi-Modal Image Synthesis for Missing Modality Imputation](http://arxiv.org/abs/2304.05340) #robust</code></li>
<li>Summary: <p>Multi-modal medical images provide complementary soft-tissue characteristics
that aid in the screening and diagnosis of diseases. However, limited scanning
time, image corruption and various imaging protocols often result in incomplete
multi-modal images, thus limiting the usage of multi-modal data for clinical
purposes. To address this issue, in this paper, we propose a novel unified
multi-modal image synthesis method for missing modality imputation. Our method
overall takes a generative adversarial architecture, which aims to synthesize
missing modalities from any combination of available ones with a single model.
To this end, we specifically design a Commonality- and Discrepancy-Sensitive
Encoder for the generator to exploit both modality-invariant and specific
information contained in input modalities. The incorporation of both types of
information facilitates the generation of images with consistent anatomy and
realistic details of the desired distribution. Besides, we propose a Dynamic
Feature Unification Module to integrate information from a varying number of
available modalities, which enables the network to be robust to random missing
modalities. The module performs both hard integration and soft integration,
ensuring the effectiveness of feature combination while avoiding information
loss. Verified on two public multi-modal magnetic resonance datasets, the
proposed method is effective in handling various synthesis tasks and shows
superior performance compared to previous methods.
</p></li>
</ul>

<h3>Title: HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models. (arXiv:2304.05390v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05390">http://arxiv.org/abs/2304.05390</a></li>
<li>Code URL: <a href="https://github.com/eslambakr/HRS_benchmark">https://github.com/eslambakr/HRS_benchmark</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05390] HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models](http://arxiv.org/abs/2304.05390) #robust</code></li>
<li>Summary: <p>In recent years, Text-to-Image (T2I) models have been extensively studied,
especially with the emergence of diffusion models that achieve state-of-the-art
results on T2I synthesis tasks. However, existing benchmarks heavily rely on
subjective human evaluation, limiting their ability to holistically assess the
model's capabilities. Furthermore, there is a significant gap between efforts
in developing new T2I architectures and those in evaluation. To address this,
we introduce HRS-Bench, a concrete evaluation benchmark for T2I models that is
Holistic, Reliable, and Scalable. Unlike existing bench-marks that focus on
limited aspects, HRS-Bench measures 13 skills that can be categorized into five
major categories: accuracy, robustness, generalization, fairness, and bias. In
addition, HRS-Bench covers 50 scenarios, including fashion, animals,
transportation, food, and clothes. We evaluate nine recent large-scale T2I
models using metrics that cover a wide range of skills. A human evaluation
aligned with 95% of our evaluations on average was conducted to probe the
effectiveness of HRS-Bench. Our experiments demonstrate that existing models
often struggle to generate images with the desired count of objects, visual
text, or grounded emotions. We hope that our benchmark help ease future
text-to-image generation research. The code and data are available at
https://eslambakr.github.io/hrsbench.github.io
</p></li>
</ul>

<h3>Title: Expectations over Unspoken Alternatives Predict Pragmatic Inferences. (arXiv:2304.04758v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04758">http://arxiv.org/abs/2304.04758</a></li>
<li>Code URL: <a href="https://github.com/jennhu/expectations-over-alternatives">https://github.com/jennhu/expectations-over-alternatives</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04758] Expectations over Unspoken Alternatives Predict Pragmatic Inferences](http://arxiv.org/abs/2304.04758) #robust</code></li>
<li>Summary: <p>Scalar inferences (SI) are a signature example of how humans interpret
language based on unspoken alternatives. While empirical studies have
demonstrated that human SI rates are highly variable -- both within instances
of a single scale, and across different scales -- there have been few proposals
that quantitatively explain both cross- and within-scale variation.
Furthermore, while it is generally assumed that SIs arise through reasoning
about unspoken alternatives, it remains debated whether humans reason about
alternatives as linguistic forms, or at the level of concepts. Here, we test a
shared mechanism explaining SI rates within and across scales: context-driven
expectations about the unspoken alternatives. Using neural language models to
approximate human predictive distributions, we find that SI rates are captured
by the expectedness of the strong scalemate as an alternative. Crucially,
however, expectedness robustly predicts cross-scale variation only under a
meaning-based view of alternatives. Our results suggest that pragmatic
inferences arise from context-driven expectations over alternatives, and these
expectations operate at the level of concepts.
</p></li>
</ul>

<h3>Title: Approximating Human Evaluation of Social Chatbots with Prompting. (arXiv:2304.05253v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05253">http://arxiv.org/abs/2304.05253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05253] Approximating Human Evaluation of Social Chatbots with Prompting](http://arxiv.org/abs/2304.05253) #robust</code></li>
<li>Summary: <p>Once powerful conversational models have become available for a wide
audience, users started actively engaging in social interactions with this
technology. Such unprecedented interaction experiences may pose considerable
social and psychological risks to the users unless the technology is properly
controlled. This creates an urgent need for scalable and robust evaluation
metrics for conversational chatbots. Existing automatic evaluation metrics
usually focus on objective quality measures and disregard subjective
perceptions of social dimensions. Moreover, most of these approaches operate on
pre-produced dialogs from available benchmark corpora, which implies human
involvement for preparing the material for evaluation and, thus, impeded
scalability of the metrics. To address this limitation, we propose to make use
of the emerging large language models (LLMs) from the GPT-family and describe a
new framework allowing to conduct dialog system evaluation with prompting. With
this framework, we are able to achieve full automation of the evaluation
pipeline and reach impressive correlation with the human judgement (up to
Pearson r=0.95 on system level). The underlying concept is to collect synthetic
chat logs of evaluated bots with a LLM in the other-play setting, where LLM is
carefully conditioned to follow a specific scenario. We further explore
different prompting approaches to produce evaluation scores with the same LLM.
The best-performing prompts, containing few-show demonstrations and
instructions, show outstanding performance on the tested dataset and
demonstrate the ability to generalize to other dialog corpora.
</p></li>
</ul>

<h3>Title: RRHF: Rank Responses to Align Language Models with Human Feedback without tears. (arXiv:2304.05302v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05302">http://arxiv.org/abs/2304.05302</a></li>
<li>Code URL: <a href="https://github.com/ganjinzero/rrhf">https://github.com/ganjinzero/rrhf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05302] RRHF: Rank Responses to Align Language Models with Human Feedback without tears](http://arxiv.org/abs/2304.05302) #robust</code></li>
<li>Summary: <p>Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment
of large language models with human preferences, significantly enhancing the
quality of interactions between humans and these models. InstructGPT implements
RLHF through several stages, including Supervised Fine-Tuning (SFT), reward
model training, and Proximal Policy Optimization (PPO). PPO, however, is
sensitive to hyperparameters and requires a minimum of four models in its
standard implementation, which makes it hard to train. In contrast, we propose
a novel learning paradigm called RRHF, which scores responses generated by
different sampling policies and learns to align them with human preferences
through ranking loss. RRHF can efficiently align language model output
probabilities with human preferences as robust as fine-tuning and it only needs
1 to 2 models during tuning. In addition, RRHF can be considered an extension
of SFT and reward models while being simpler than PPO in terms of coding, model
counts, and hyperparameters. The entire alignment process can be accomplished
within a single RRHF training session. We evaluate RRHF using LLaMA and Alpaca
on Helpful and Harmless data, demonstrating performance comparable to PPO.
</p></li>
</ul>

<h3>Title: Toxicity in ChatGPT: Analyzing Persona-assigned Language Models. (arXiv:2304.05335v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05335">http://arxiv.org/abs/2304.05335</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05335] Toxicity in ChatGPT: Analyzing Persona-assigned Language Models](http://arxiv.org/abs/2304.05335) #robust</code></li>
<li>Summary: <p>Large language models (LLMs) have shown incredible capabilities and
transcended the natural language processing (NLP) community, with adoption
throughout many services like healthcare, therapy, education, and customer
service. Since users include people with critical information needs like
students or patients engaging with chatbots, the safety of these systems is of
prime importance. Therefore, a clear understanding of the capabilities and
limitations of LLMs is necessary. To this end, we systematically evaluate
toxicity in over half a million generations of ChatGPT, a popular
dialogue-based LLM. We find that setting the system parameter of ChatGPT by
assigning it a persona, say that of the boxer Muhammad Ali, significantly
increases the toxicity of generations. Depending on the persona assigned to
ChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect
stereotypes, harmful dialogue, and hurtful opinions. This may be potentially
defamatory to the persona and harmful to an unsuspecting user. Furthermore, we
find concerning patterns where specific entities (e.g., certain races) are
targeted more than others (3x more) irrespective of the assigned persona, that
reflect inherent discriminatory biases in the model. We hope that our findings
inspire the broader AI community to rethink the efficacy of current safety
guardrails and develop better techniques that lead to robust, safe, and
trustworthy AI systems.
</p></li>
</ul>

<h3>Title: Real-Time Model-Free Deep Reinforcement Learning for Force Control of a Series Elastic Actuator. (arXiv:2304.04911v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04911">http://arxiv.org/abs/2304.04911</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04911] Real-Time Model-Free Deep Reinforcement Learning for Force Control of a Series Elastic Actuator](http://arxiv.org/abs/2304.04911) #robust</code></li>
<li>Summary: <p>Many state-of-the art robotic applications utilize series elastic actuators
(SEAs) with closed-loop force control to achieve complex tasks such as walking,
lifting, and manipulation. Model-free PID control methods are more prone to
instability due to nonlinearities in the SEA where cascaded model-based robust
controllers can remove these effects to achieve stable force control. However,
these model-based methods require detailed investigations to characterize the
system accurately. Deep reinforcement learning (DRL) has proved to be an
effective model-free method for continuous control tasks, where few works deal
with hardware learning. This paper describes the training process of a DRL
policy on hardware of an SEA pendulum system for tracking force control
trajectories from 0.05 - 0.35 Hz at 50 N amplitude using the Proximal Policy
Optimization (PPO) algorithm. Safety mechanisms are developed and utilized for
training the policy for 12 hours (overnight) without an operator present within
the full 21 hours training period. The tracking performance is evaluated
showing improvements of $25$ N in mean absolute error when comparing the first
18 min. of training to the full 21 hours for a 50 N amplitude, 0.1 Hz sinusoid
desired force trajectory. Finally, the DRL policy exhibits better tracking and
stability margins when compared to a model-free PID controller for a 50 N chirp
force trajectory.
</p></li>
</ul>

<h3>Title: The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting. (arXiv:2304.05206v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05206">http://arxiv.org/abs/2304.05206</a></li>
<li>Code URL: <a href="https://github.com/hanlu-nju/channel_independent_mtsf">https://github.com/hanlu-nju/channel_independent_mtsf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05206] The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting](http://arxiv.org/abs/2304.05206) #robust</code></li>
<li>Summary: <p>Multivariate time series data comprises various channels of variables. The
multivariate forecasting models need to capture the relationship between the
channels to accurately predict future values. However, recently, there has been
an emergence of methods that employ the Channel Independent (CI) strategy.
These methods view multivariate time series data as separate univariate time
series and disregard the correlation between channels. Surprisingly, our
empirical results have shown that models trained with the CI strategy
outperform those trained with the Channel Dependent (CD) strategy, usually by a
significant margin. Nevertheless, the reasons behind this phenomenon have not
yet been thoroughly explored in the literature. This paper provides
comprehensive empirical and theoretical analyses of the characteristics of
multivariate time series datasets and the CI/CD strategy. Our results conclude
that the CD approach has higher capacity but often lacks robustness to
accurately predict distributionally drifted time series. In contrast, the CI
approach trades capacity for robust prediction. Practical measures inspired by
these analyses are proposed to address the capacity and robustness dilemma,
including a modified CD method called Predict Residuals with Regularization
(PRReg) that can surpass the CI strategy. We hope our findings can raise
awareness among researchers about the characteristics of multivariate time
series and inspire the construction of better forecasting models.
</p></li>
</ul>

<h3>Title: A surprisingly simple technique to control the pretraining bias for better transfer: Expand or Narrow your representation. (arXiv:2304.05369v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05369">http://arxiv.org/abs/2304.05369</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05369] A surprisingly simple technique to control the pretraining bias for better transfer: Expand or Narrow your representation](http://arxiv.org/abs/2304.05369) #robust</code></li>
<li>Summary: <p>Self-Supervised Learning (SSL) models rely on a pretext task to learn
representations. Because this pretext task differs from the downstream tasks
used to evaluate the performance of these models, there is an inherent
misalignment or pretraining bias. A commonly used trick in SSL, shown to make
deep networks more robust to such bias, is the addition of a small projector
(usually a 2 or 3 layer multi-layer perceptron) on top of a backbone network
during training. In contrast to previous work that studied the impact of the
projector architecture, we here focus on a simpler, yet overlooked lever to
control the information in the backbone representation. We show that merely
changing its dimensionality -- by changing only the size of the backbone's very
last block -- is a remarkably effective technique to mitigate the pretraining
bias. It significantly improves downstream transfer performance for both
Self-Supervised and Supervised pretrained models.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Advancing Medical Imaging with Language Models: A Journey from N-grams to ChatGPT. (arXiv:2304.04920v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04920">http://arxiv.org/abs/2304.04920</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04920] Advancing Medical Imaging with Language Models: A Journey from N-grams to ChatGPT](http://arxiv.org/abs/2304.04920) #extraction</code></li>
<li>Summary: <p>In this paper, we aimed to provide a review and tutorial for researchers in
the field of medical imaging using language models to improve their tasks at
hand. We began by providing an overview of the history and concepts of language
models, with a special focus on large language models. We then reviewed the
current literature on how language models are being used to improve medical
imaging, emphasizing different applications such as image captioning, report
generation, report classification, finding extraction, visual question
answering, interpretable diagnosis, and more for various modalities and organs.
The ChatGPT was specially highlighted for researchers to explore more potential
applications. We covered the potential benefits of accurate and efficient
language models for medical imaging analysis, including improving clinical
workflow efficiency, reducing diagnostic errors, and assisting healthcare
professionals in providing timely and accurate diagnoses. Overall, our goal was
to bridge the gap between language models and medical imaging and inspire new
ideas and innovations in this exciting area of research. We hope that this
review paper will serve as a useful resource for researchers in this field and
encourage further exploration of the possibilities of language models in
medical imaging.
</p></li>
</ul>

<h3>Title: Sentence-Level Relation Extraction via Contrastive Learning with Descriptive Relation Prompts. (arXiv:2304.04935v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04935">http://arxiv.org/abs/2304.04935</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04935] Sentence-Level Relation Extraction via Contrastive Learning with Descriptive Relation Prompts](http://arxiv.org/abs/2304.04935) #extraction</code></li>
<li>Summary: <p>Sentence-level relation extraction aims to identify the relation between two
entities for a given sentence. The existing works mostly focus on obtaining a
better entity representation and adopting a multi-label classifier for relation
extraction. A major limitation of these works is that they ignore background
relational knowledge and the interrelation between entity types and candidate
relations. In this work, we propose a new paradigm, Contrastive Learning with
Descriptive Relation Prompts(CTL-DRP), to jointly consider entity information,
relational knowledge and entity type restrictions. In particular, we introduce
an improved entity marker and descriptive relation prompts when generating
contextual embedding, and utilize contrastive learning to rank the restricted
candidate relations. The CTL-DRP obtains a competitive F1-score of 76.7% on
TACRED. Furthermore, the new presented paradigm achieves F1-scores of 85.8% and
91.6% on TACREV and Re-TACRED respectively, which are both the state-of-the-art
performance.
</p></li>
</ul>

<h3>Title: An Entity-based Claim Extraction Pipeline for Real-world Biomedical Fact-checking. (arXiv:2304.05268v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05268">http://arxiv.org/abs/2304.05268</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05268] An Entity-based Claim Extraction Pipeline for Real-world Biomedical Fact-checking](http://arxiv.org/abs/2304.05268) #extraction</code></li>
<li>Summary: <p>Existing fact-checking models for biomedical claims are typically trained on
synthetic or well-worded data and hardly transfer to social media content. This
mismatch can be mitigated by adapting the social media input to mimic the
focused nature of common training claims. To do so, Wuehrl &amp; Klinger (2022)
propose to extract concise claims based on medical entities in the text.
However, their study has two limitations: First, it relies on gold-annotated
entities. Therefore, its feasibility for a real-world application cannot be
assessed since this requires detecting relevant entities automatically. Second,
they represent claim entities with the original tokens. This constitutes a
terminology mismatch which potentially limits the fact-checking performance. To
understand both challenges, we propose a claim extraction pipeline for medical
tweets that incorporates named entity recognition and terminology normalization
via entity linking. We show that automatic NER does lead to a performance drop
in comparison to using gold annotations but the fact-checking performance still
improves considerably over inputting the unchanged tweets. Normalizing entities
to their canonical forms does, however, not improve the performance.
</p></li>
</ul>

<h3>Title: Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding. (arXiv:2304.05368v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05368">http://arxiv.org/abs/2304.05368</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05368] Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding](http://arxiv.org/abs/2304.05368) #extraction</code></li>
<li>Summary: <p>Large language models (LLMs) have made significant progress in various
domains, including healthcare. However, the specialized nature of clinical
language understanding tasks presents unique challenges and limitations that
warrant further investigation. In this study, we conduct a comprehensive
evaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within
the realm of clinical language understanding tasks. These tasks span a diverse
range, including named entity recognition, relation extraction, natural
language inference, semantic textual similarity, document classification, and
question-answering. We also introduce a novel prompting strategy,
self-questioning prompting (SQP), tailored to enhance LLMs' performance by
eliciting informative questions and answers pertinent to the clinical scenarios
at hand. Our evaluation underscores the significance of task-specific learning
strategies and prompting techniques for improving LLMs' effectiveness in
healthcare-related tasks. Additionally, our in-depth error analysis on the
challenging relation extraction task offers valuable insights into error
distribution and potential avenues for improvement using SQP. Our study sheds
light on the practical implications of employing LLMs in the specialized domain
of healthcare, serving as a foundation for future research and the development
of potential applications in healthcare settings.
</p></li>
</ul>

<h3>Title: TodyNet: Temporal Dynamic Graph Neural Network for Multivariate Time Series Classification. (arXiv:2304.05078v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05078">http://arxiv.org/abs/2304.05078</a></li>
<li>Code URL: <a href="https://github.com/liuxz1011/todynet">https://github.com/liuxz1011/todynet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05078] TodyNet: Temporal Dynamic Graph Neural Network for Multivariate Time Series Classification](http://arxiv.org/abs/2304.05078) #extraction</code></li>
<li>Summary: <p>Multivariate time series classification (MTSC) is an important data mining
task, which can be effectively solved by popular deep learning technology.
Unfortunately, the existing deep learning-based methods neglect the hidden
dependencies in different dimensions and also rarely consider the unique
dynamic features of time series, which lack sufficient feature extraction
capability to obtain satisfactory classification accuracy. To address this
problem, we propose a novel temporal dynamic graph neural network (TodyNet)
that can extract hidden spatio-temporal dependencies without undefined graph
structure. It enables information flow among isolated but implicit
interdependent variables and captures the associations between different time
slots by dynamic graph mechanism, which further improves the classification
performance of the model. Meanwhile, the hierarchical representations of graphs
cannot be learned due to the limitation of GNNs. Thus, we also design a
temporal graph pooling layer to obtain a global graph-level representation for
graph learning with learnable temporal parameters. The dynamic graph, graph
information propagation, and temporal convolution are jointly learned in an
end-to-end framework. The experiments on 26 UEA benchmark datasets illustrate
that the proposed TodyNet outperforms existing deep learning-based methods in
the MTSC tasks.
</p></li>
</ul>

<h3>Title: Asymmetric Polynomial Loss For Multi-Label Classification. (arXiv:2304.05361v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05361">http://arxiv.org/abs/2304.05361</a></li>
<li>Code URL: <a href="https://github.com/lumia-group/apl">https://github.com/lumia-group/apl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05361] Asymmetric Polynomial Loss For Multi-Label Classification](http://arxiv.org/abs/2304.05361) #extraction</code></li>
<li>Summary: <p>Various tasks are reformulated as multi-label classification problems, in
which the binary cross-entropy (BCE) loss is frequently utilized for optimizing
well-designed models. However, the vanilla BCE loss cannot be tailored for
diverse tasks, resulting in a suboptimal performance for different models.
Besides, the imbalance between redundant negative samples and rare positive
samples could degrade the model performance. In this paper, we propose an
effective Asymmetric Polynomial Loss (APL) to mitigate the above issues.
Specifically, we first perform Taylor expansion on BCE loss. Then we ameliorate
the coefficients of polynomial functions. We further employ the asymmetric
focusing mechanism to decouple the gradient contribution from the negative and
positive samples. Moreover, we validate that the polynomial coefficients can
recalibrate the asymmetric focusing hyperparameters. Experiments on relation
extraction, text classification, and image classification show that our APL
loss can consistently improve performance without extra training burden.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Improving Performance of Private Federated Models in Medical Image Analysis. (arXiv:2304.05127v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05127">http://arxiv.org/abs/2304.05127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05127] Improving Performance of Private Federated Models in Medical Image Analysis](http://arxiv.org/abs/2304.05127) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is a distributed machine learning (ML) approach that
allows data to be trained without being centralized. This approach is
particularly beneficial for medical applications because it addresses some key
challenges associated with medical data, such as privacy, security, and data
ownership. On top of that, FL can improve the quality of ML models used in
medical applications. Medical data is often diverse and can vary significantly
depending on the patient population, making it challenging to develop ML models
that are accurate and generalizable. FL allows medical data to be used from
multiple sources, which can help to improve the quality and generalizability of
ML models. Differential privacy (DP) is a go-to algorithmic tool to make this
process secure and private. In this work, we show that the model performance
can be further improved by employing local steps, a popular approach to
improving the communication efficiency of FL, and tuning the number of
communication rounds. Concretely, given the privacy budget, we show an optimal
number of local steps and communications rounds. We provide theoretical
motivations further corroborated with experimental evaluations on real-world
medical imaging tasks.
</p></li>
</ul>

<h3>Title: Federated Learning with Classifier Shift for Class Imbalance. (arXiv:2304.04972v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04972">http://arxiv.org/abs/2304.04972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04972] Federated Learning with Classifier Shift for Class Imbalance](http://arxiv.org/abs/2304.04972) #federate</code></li>
<li>Summary: <p>Federated learning aims to learn a global model collaboratively while the
training data belongs to different clients and is not allowed to be exchanged.
However, the statistical heterogeneity challenge on non-IID data, such as class
imbalance in classification, will cause client drift and significantly reduce
the performance of the global model. This paper proposes a simple and effective
approach named FedShift which adds the shift on the classifier output during
the local training phase to alleviate the negative impact of class imbalance.
We theoretically prove that the classifier shift in FedShift can make the local
optimum consistent with the global optimum and ensure the convergence of the
algorithm. Moreover, our experiments indicate that FedShift significantly
outperforms the other state-of-the-art federated learning approaches on various
datasets regarding accuracy and communication efficiency.
</p></li>
</ul>

<h3>Title: HPN: Personalized Federated Hyperparameter Optimization. (arXiv:2304.05195v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05195">http://arxiv.org/abs/2304.05195</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05195] HPN: Personalized Federated Hyperparameter Optimization](http://arxiv.org/abs/2304.05195) #federate</code></li>
<li>Summary: <p>Numerous research studies in the field of federated learning (FL) have
attempted to use personalization to address the heterogeneity among clients,
one of FL's most crucial and challenging problems. However, existing works
predominantly focus on tailoring models. Yet, due to the heterogeneity of
clients, they may each require different choices of hyperparameters, which have
not been studied so far. We pinpoint two challenges of personalized federated
hyperparameter optimization (pFedHPO): handling the exponentially increased
search space and characterizing each client without compromising its data
privacy. To overcome them, we propose learning a
\textsc{H}yper\textsc{P}arameter \textsc{N}etwork (HPN) fed with client
encoding to decide personalized hyperparameters. The client encoding is
calculated with a random projection-based procedure to protect each client's
privacy. Besides, we design a novel mechanism to debias the low-fidelity
function evaluation samples for learning HPN. We conduct extensive experiments
on FL tasks from various domains, demonstrating the superiority of HPN.
</p></li>
</ul>

<h3>Title: TinyReptile: TinyML with Federated Meta-Learning. (arXiv:2304.05201v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05201">http://arxiv.org/abs/2304.05201</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05201] TinyReptile: TinyML with Federated Meta-Learning](http://arxiv.org/abs/2304.05201) #federate</code></li>
<li>Summary: <p>Tiny machine learning (TinyML) is a rapidly growing field aiming to
democratize machine learning (ML) for resource-constrained microcontrollers
(MCUs). Given the pervasiveness of these tiny devices, it is inherent to ask
whether TinyML applications can benefit from aggregating their knowledge.
Federated learning (FL) enables decentralized agents to jointly learn a global
model without sharing sensitive local data. However, a common global model may
not work for all devices due to the complexity of the actual deployment
environment and the heterogeneity of the data available on each device. In
addition, the deployment of TinyML hardware has significant computational and
communication constraints, which traditional ML fails to address. Considering
these challenges, we propose TinyReptile, a simple but efficient algorithm
inspired by meta-learning and online learning, to collaboratively learn a solid
initialization for a neural network (NN) across tiny devices that can be
quickly adapted to a new device with respect to its data. We demonstrate
TinyReptile on Raspberry Pi 4 and Cortex-M4 MCU with only 256-KB RAM. The
evaluations on various TinyML use cases confirm a resource reduction and
training time saving by at least two factors compared with baseline algorithms
with comparable performance.
</p></li>
</ul>

<h3>Title: Re-Weighted Softmax Cross-Entropy to Control Forgetting in Federated Learning. (arXiv:2304.05260v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05260">http://arxiv.org/abs/2304.05260</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05260] Re-Weighted Softmax Cross-Entropy to Control Forgetting in Federated Learning](http://arxiv.org/abs/2304.05260) #federate</code></li>
<li>Summary: <p>In Federated Learning, a global model is learned by aggregating model updates
computed at a set of independent client nodes, to reduce communication costs
multiple gradient steps are performed at each node prior to aggregation. A key
challenge in this setting is data heterogeneity across clients resulting in
differing local objectives which can lead clients to overly minimize their own
local objective, diverging from the global solution. We demonstrate that
individual client models experience a catastrophic forgetting with respect to
data from other clients and propose an efficient approach that modifies the
cross-entropy objective on a per-client basis by re-weighting the softmax
logits prior to computing the loss. This approach shields classes outside a
client's label set from abrupt representation change and we empirically
demonstrate it can alleviate client forgetting and provide consistent
improvements to standard federated learning algorithms. Our method is
particularly beneficial under the most challenging federated learning settings
where data heterogeneity is high and client participation in each round is low.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Connecting Fairness in Machine Learning with Public Health Equity. (arXiv:2304.04761v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04761">http://arxiv.org/abs/2304.04761</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04761] Connecting Fairness in Machine Learning with Public Health Equity](http://arxiv.org/abs/2304.04761) #fair</code></li>
<li>Summary: <p>Machine learning (ML) has become a critical tool in public health, offering
the potential to improve population health, diagnosis, treatment selection, and
health system efficiency. However, biases in data and model design can result
in disparities for certain protected groups and amplify existing inequalities
in healthcare. To address this challenge, this study summarizes seminal
literature on ML fairness and presents a framework for identifying and
mitigating biases in the data and model. The framework provides guidance on
incorporating fairness into different stages of the typical ML pipeline, such
as data processing, model design, deployment, and evaluation. To illustrate the
impact of biases in data on ML models, we present examples that demonstrate how
systematic biases can be amplified through model predictions. These case
studies suggest how the framework can be used to prevent these biases and
highlight the need for fair and equitable ML models in public health. This work
aims to inform and guide the use of ML in public health towards a more ethical
and equitable outcome for all populations.
</p></li>
</ul>

<h3>Title: Learning Optimal Fair Scoring Systems for Multi-Class Classification. (arXiv:2304.05023v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05023">http://arxiv.org/abs/2304.05023</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05023] Learning Optimal Fair Scoring Systems for Multi-Class Classification](http://arxiv.org/abs/2304.05023) #fair</code></li>
<li>Summary: <p>Machine Learning models are increasingly used for decision making, in
particular in high-stakes applications such as credit scoring, medicine or
recidivism prediction. However, there are growing concerns about these models
with respect to their lack of interpretability and the undesirable biases they
can generate or reproduce. While the concepts of interpretability and fairness
have been extensively studied by the scientific community in recent years, few
works have tackled the general multi-class classification problem under
fairness constraints, and none of them proposes to generate fair and
interpretable models for multi-class classification. In this paper, we use
Mixed-Integer Linear Programming (MILP) techniques to produce inherently
interpretable scoring systems under sparsity and fairness constraints, for the
general multi-class classification setup. Our work generalizes the SLIM
(Supersparse Linear Integer Models) framework that was proposed by Rudin and
Ustun to learn optimal scoring systems for binary classification. The use of
MILP techniques allows for an easy integration of diverse operational
constraints (such as, but not restricted to, fairness or sparsity), but also
for the building of certifiably optimal models (or sub-optimal models with
bounded optimality gap).
</p></li>
</ul>

<h3>Title: BanditQ -- No-Regret Learning with Guaranteed Per-User Rewards in Adversarial Environments. (arXiv:2304.05219v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05219">http://arxiv.org/abs/2304.05219</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05219] BanditQ -- No-Regret Learning with Guaranteed Per-User Rewards in Adversarial Environments](http://arxiv.org/abs/2304.05219) #fair</code></li>
<li>Summary: <p>Classic online prediction algorithms, such as Hedge, are inherently unfair by
design, as they try to play the most rewarding arm as many times as possible
while ignoring the sub-optimal arms to achieve sublinear regret. In this paper,
we consider a fair online prediction problem in the adversarial setting with
hard lower bounds on the rate of accrual of rewards for all arms. By combining
elementary queueing theory with online learning, we propose a new online
prediction policy, called BanditQ, that achieves the target rate constraints
while achieving a regret of $O(T^{3/4})$ in the full-information setting. The
design and analysis of BanditQ involve a novel use of the potential function
method and are of independent interest.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Improving Vision-and-Language Navigation by Generating Future-View Image Semantics. (arXiv:2304.04907v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04907">http://arxiv.org/abs/2304.04907</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04907] Improving Vision-and-Language Navigation by Generating Future-View Image Semantics](http://arxiv.org/abs/2304.04907) #interpretability</code></li>
<li>Summary: <p>Vision-and-Language Navigation (VLN) is the task that requires an agent to
navigate through the environment based on natural language instructions. At
each step, the agent takes the next action by selecting from a set of navigable
locations. In this paper, we aim to take one step further and explore whether
the agent can benefit from generating the potential future view during
navigation. Intuitively, humans will have an expectation of how the future
environment will look like, based on the natural language instructions and
surrounding views, which will aid correct navigation. Hence, to equip the agent
with this ability to generate the semantics of future navigation views, we
first propose three proxy tasks during the agent's in-domain pre-training:
Masked Panorama Modeling (MPM), Masked Trajectory Modeling (MTM), and Action
Prediction with Image Generation (APIG). These three objectives teach the model
to predict missing views in a panorama (MPM), predict missing steps in the full
trajectory (MTM), and generate the next view based on the full instruction and
navigation history (APIG), respectively. We then fine-tune the agent on the VLN
task with an auxiliary loss that minimizes the difference between the view
semantics generated by the agent and the ground truth view semantics of the
next step. Empirically, our VLN-SIG achieves the new state-of-the-art on both
the Room-to-Room dataset and the CVDN dataset. We further show that our agent
learns to fill in missing patches in future views qualitatively, which brings
more interpretability over agents' predicted actions. Lastly, we demonstrate
that learning to predict future view semantics also enables the agent to have
better performance on longer paths.
</p></li>
</ul>

<h3>Title: Regression-based Deep-Learning predicts molecular biomarkers from pathology slides. (arXiv:2304.05153v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05153">http://arxiv.org/abs/2304.05153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05153] Regression-based Deep-Learning predicts molecular biomarkers from pathology slides](http://arxiv.org/abs/2304.05153) #interpretability</code></li>
<li>Summary: <p>Deep Learning (DL) can predict biomarkers from cancer histopathology. Several
clinically approved applications use this technology. Most approaches, however,
predict categorical labels, whereas biomarkers are often continuous
measurements. We hypothesized that regression-based DL outperforms
classification-based DL. Therefore, we developed and evaluated a new
self-supervised attention-based weakly supervised regression method that
predicts continuous biomarkers directly from images in 11,671 patients across
nine cancer types. We tested our method for multiple clinically and
biologically relevant biomarkers: homologous repair deficiency (HRD) score, a
clinically used pan-cancer biomarker, as well as markers of key biological
processes in the tumor microenvironment. Using regression significantly
enhances the accuracy of biomarker prediction, while also improving the
interpretability of the results over classification. In a large cohort of
colorectal cancer patients, regression-based prediction scores provide a higher
prognostic value than classification-based scores. Our open-source regression
approach offers a promising alternative for continuous biomarker analysis in
computational pathology.
</p></li>
</ul>

<h3>Title: Multi-scale Fusion Fault Diagnosis Method Based on Two-Dimensionaliztion Sequence in Complex Scenarios. (arXiv:2304.05198v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05198">http://arxiv.org/abs/2304.05198</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05198] Multi-scale Fusion Fault Diagnosis Method Based on Two-Dimensionaliztion Sequence in Complex Scenarios](http://arxiv.org/abs/2304.05198) #interpretability</code></li>
<li>Summary: <p>Rolling bearings are critical components in rotating machinery, and their
faults can cause severe damage. Early detection of abnormalities is crucial to
prevent catastrophic accidents. Traditional and intelligent methods have been
used to analyze time series data, but in real-life scenarios, sensor data is
often noisy and cannot be accurately characterized in the time domain, leading
to mode collapse in trained models. Two-dimensionalization methods such as the
Gram angle field method (GAF) or interval sampling have been proposed, but they
lack mathematical derivation and interpretability. This paper proposes an
improved GAF combined with grayscale images for convolution scenarios. The main
contributions include illustrating the feasibility of the approach in complex
scenarios, widening the data set, and introducing an improved convolutional
neural network method with a multi-scale feature fusion diffusion model and
deep learning compression techniques for deployment in industrial scenarios.
</p></li>
</ul>

<h3>Title: ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity. (arXiv:2304.05303v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05303">http://arxiv.org/abs/2304.05303</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05303] ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity](http://arxiv.org/abs/2304.05303) #interpretability</code></li>
<li>Summary: <p>Deep learning has shown great potential in assisting radiologists in reading
chest X-ray (CXR) images, but its need for expensive annotations for improving
performance prevents widespread clinical application. Visual language
pre-training (VLP) can alleviate the burden and cost of annotation by
leveraging routinely generated reports for radiographs, which exist in large
quantities as well as in paired form (imagetext pairs). Additionally,
extensions to localization-aware VLPs are being proposed to address the needs
of accurate localization of abnormalities for CAD in CXR. However, we find that
the formulation proposed by locality-aware VLP literatures actually leads to
loss in spatial relationships required for downstream localization tasks.
Therefore, we propose Empowering Locality of VLP with Intra-modal Similarity,
ELVIS, a VLP aware of intra-modal locality, to better preserve the locality
within radiographs or reports, which enhances the ability to comprehend
location references in text reports. Our locality-aware VLP method
significantly outperforms state-of-the art baselines in multiple segmentation
tasks and the MS-CXR phrase grounding task. Qualitatively, ELVIS is able to
focus well on regions of interest described in the report text compared to
prior approaches, allowing for enhanced interpretability.
</p></li>
</ul>

<h3>Title: OpenAL: Evaluation and Interpretation of Active Learning Strategies. (arXiv:2304.05246v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05246">http://arxiv.org/abs/2304.05246</a></li>
<li>Code URL: <a href="https://github.com/dataiku-research/openal">https://github.com/dataiku-research/openal</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05246] OpenAL: Evaluation and Interpretation of Active Learning Strategies](http://arxiv.org/abs/2304.05246) #interpretability</code></li>
<li>Summary: <p>Despite the vast body of literature on Active Learning (AL), there is no
comprehensive and open benchmark allowing for efficient and simple comparison
of proposed samplers. Additionally, the variability in experimental settings
across the literature makes it difficult to choose a sampling strategy, which
is critical due to the one-off nature of AL experiments. To address those
limitations, we introduce OpenAL, a flexible and open-source framework to
easily run and compare sampling AL strategies on a collection of realistic
tasks. The proposed benchmark is augmented with interpretability metrics and
statistical analysis methods to understand when and why some samplers
outperform others. Last but not least, practitioners can easily extend the
benchmark by submitting their own AL samplers.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges. (arXiv:2304.05351v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05351">http://arxiv.org/abs/2304.05351</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05351] The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges](http://arxiv.org/abs/2304.05351) #explainability</code></li>
<li>Summary: <p>Recently, large language models (LLMs) like ChatGPT have demonstrated
remarkable performance across a variety of natural language processing tasks.
However, their effectiveness in the financial domain, specifically in
predicting stock market movements, remains to be explored. In this paper, we
conduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal
stock movement prediction, on three tweets and historical stock price datasets.
Our findings indicate that ChatGPT is a "Wall Street Neophyte" with limited
success in predicting stock movements, as it underperforms not only
state-of-the-art methods but also traditional methods like linear regression
using price features. Despite the potential of Chain-of-Thought prompting
strategies and the inclusion of tweets, ChatGPT's performance remains subpar.
Furthermore, we observe limitations in its explainability and stability,
suggesting the need for more specialized training or fine-tuning. This research
provides insights into ChatGPT's capabilities and serves as a foundation for
future work aimed at improving financial market analysis and prediction by
leveraging social media sentiment and historical stock data.
</p></li>
</ul>

<h3>Title: A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?. (arXiv:2304.04780v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04780">http://arxiv.org/abs/2304.04780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04780] A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?](http://arxiv.org/abs/2304.04780) #explainability</code></li>
<li>Summary: <p>Artificial intelligence (AI) models are increasingly finding applications in
the field of medicine. Concerns have been raised about the explainability of
the decisions that are made by these AI models. In this article, we give a
systematic analysis of explainable artificial intelligence (XAI), with a
primary focus on models that are currently being used in the field of
healthcare. The literature search is conducted following the preferred
reporting items for systematic reviews and meta-analyses (PRISMA) standards for
relevant work published from 1 January 2012 to 02 February 2022. The review
analyzes the prevailing trends in XAI and lays out the major directions in
which research is headed. We investigate the why, how, and when of the uses of
these XAI models and their implications. We present a comprehensive examination
of XAI methodologies as well as an explanation of how a trustworthy AI can be
derived from describing AI models for healthcare fields. The discussion of this
work will contribute to the formalization of the XAI field.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: DDRF: Denoising Diffusion Model for Remote Sensing Image Fusion. (arXiv:2304.04774v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04774">http://arxiv.org/abs/2304.04774</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04774] DDRF: Denoising Diffusion Model for Remote Sensing Image Fusion](http://arxiv.org/abs/2304.04774) #diffusion</code></li>
<li>Summary: <p>Denosing diffusion model, as a generative model, has received a lot of
attention in the field of image generation recently, thanks to its powerful
generation capability. However, diffusion models have not yet received
sufficient research in the field of image fusion. In this article, we introduce
diffusion model to the image fusion field, treating the image fusion task as
image-to-image translation and designing two different conditional injection
modulation modules (i.e., style transfer modulation and wavelet modulation) to
inject coarse-grained style information and fine-grained high-frequency and
low-frequency information into the diffusion UNet, thereby generating fused
images. In addition, we also discussed the residual learning and the selection
of training objectives of the diffusion model in the image fusion task.
Extensive experimental results based on quantitative and qualitative
assessments compared with benchmarks demonstrates state-of-the-art results and
good generalization performance in image fusion tasks. Finally, it is hoped
that our method can inspire other works and gain insight into this field to
better apply the diffusion model to image fusion tasks. Code shall be released
for better reproducibility.
</p></li>
</ul>

<h3>Title: Binary Latent Diffusion. (arXiv:2304.04820v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04820">http://arxiv.org/abs/2304.04820</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04820] Binary Latent Diffusion](http://arxiv.org/abs/2304.04820) #diffusion</code></li>
<li>Summary: <p>In this paper, we show that a binary latent space can be explored for compact
yet expressive image representations. We model the bi-directional mappings
between an image and the corresponding latent binary representation by training
an auto-encoder with a Bernoulli encoding distribution. On the one hand, the
binary latent space provides a compact discrete image representation of which
the distribution can be modeled more efficiently than pixels or continuous
latent representations. On the other hand, we now represent each image patch as
a binary vector instead of an index of a learned cookbook as in discrete image
representations with vector quantization. In this way, we obtain binary latent
representations that allow for better image quality and high-resolution image
representations without any multi-stage hierarchy in the latent space. In this
binary latent space, images can now be generated effectively using a binary
latent diffusion model tailored specifically for modeling the prior over the
binary image representations. We present both conditional and unconditional
image generation experiments with multiple datasets, and show that the proposed
method performs comparably to state-of-the-art methods while dramatically
improving the sampling efficiency to as few as 16 steps without using any
test-time acceleration. The proposed framework can also be seamlessly scaled to
$1024 \times 1024$ high-resolution image generation without resorting to latent
hierarchy or multi-stage refinements.
</p></li>
</ul>

<h3>Title: Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond. (arXiv:2304.04968v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04968">http://arxiv.org/abs/2304.04968</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04968] Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond](http://arxiv.org/abs/2304.04968) #diffusion</code></li>
<li>Summary: <p>Although text-to-image diffusion models have made significant strides in
generating images from text, they are sometimes more inclined to generate
images like the data on which the model was trained rather than the provided
text. This limitation has hindered their usage in both 2D and 3D applications.
To address this problem, we explored the use of negative prompts but found that
the current implementation fails to produce desired results, particularly when
there is an overlap between the main and negative prompts. To overcome this
issue, we propose Perp-Neg, a new algorithm that leverages the geometrical
properties of the score space to address the shortcomings of the current
negative prompts algorithm. Perp-Neg does not require any training or
fine-tuning of the model. Moreover, we experimentally demonstrate that Perp-Neg
provides greater flexibility in generating images by enabling users to edit out
unwanted concepts from the initially generated images in 2D cases. Furthermore,
to extend the application of Perp-Neg to 3D, we conducted a thorough
exploration of how Perp-Neg can be used in 2D to condition the diffusion model
to generate desired views, rather than being biased toward the canonical views.
Finally, we applied our 2D intuition to integrate Perp-Neg with the
state-of-the-art text-to-3D (DreamFusion) method, effectively addressing its
Janus (multi-head) problem.
</p></li>
</ul>

<h3>Title: SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI. (arXiv:2304.05060v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05060">http://arxiv.org/abs/2304.05060</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05060] SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI](http://arxiv.org/abs/2304.05060) #diffusion</code></li>
<li>Summary: <p>Diffusion models are a leading method for image generation and have been
successfully applied in magnetic resonance imaging (MRI) reconstruction.
Current diffusion-based reconstruction methods rely on coil sensitivity maps
(CSM) to reconstruct multi-coil data. However, it is difficult to accurately
estimate CSMs in practice use, resulting in degradation of the reconstruction
quality. To address this issue, we propose a self-consistency-driven diffusion
model inspired by the iterative self-consistent parallel imaging (SPIRiT),
namely SPIRiT-Diffusion. Specifically, the iterative solver of the
self-consistent term in SPIRiT is utilized to design a novel stochastic
differential equation (SDE) for diffusion process. Then $\textit{k}$-space data
can be interpolated directly during the reverse diffusion process, instead of
using CSM to separate and combine individual coil images. This method indicates
that the optimization model can be used to design SDE in diffusion models,
driving the diffusion process strongly conforming with the physics involved in
the optimization model, dubbed model-driven diffusion. The proposed
SPIRiT-Diffusion method was evaluated on a 3D joint Intracranial and Carotid
Vessel Wall imaging dataset. The results demonstrate that it outperforms the
CSM-based reconstruction methods, and achieves high reconstruction quality at a
high acceleration rate of 10.
</p></li>
</ul>

<h3>Title: iPINNs: Incremental learning for Physics-informed neural networks. (arXiv:2304.04854v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04854">http://arxiv.org/abs/2304.04854</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04854] iPINNs: Incremental learning for Physics-informed neural networks](http://arxiv.org/abs/2304.04854) #diffusion</code></li>
<li>Summary: <p>Physics-informed neural networks (PINNs) have recently become a powerful tool
for solving partial differential equations (PDEs). However, finding a set of
neural network parameters that lead to fulfilling a PDE can be challenging and
non-unique due to the complexity of the loss landscape that needs to be
traversed. Although a variety of multi-task learning and transfer learning
approaches have been proposed to overcome these issues, there is no incremental
training procedure for PINNs that can effectively mitigate such training
challenges. We propose incremental PINNs (iPINNs) that can learn multiple tasks
(equations) sequentially without additional parameters for new tasks and
improve performance for every equation in the sequence. Our approach learns
multiple PDEs starting from the simplest one by creating its own subnetwork for
each PDE and allowing each subnetwork to overlap with previously learned
subnetworks. We demonstrate that previous subnetworks are a good initialization
for a new equation if PDEs share similarities. We also show that iPINNs achieve
lower prediction error than regular PINNs for two different scenarios: (1)
learning a family of equations (e.g., 1-D convection PDE); and (2) learning
PDEs resulting from a combination of processes (e.g., 1-D reaction-diffusion
PDE). The ability to learn all problems with a single network together with
learning more complex PDEs with better generalization than regular PINNs will
open new avenues in this field.
</p></li>
</ul>

<h3>Title: Neural Multi-network Diffusion towards Social Recommendation. (arXiv:2304.04994v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.04994">http://arxiv.org/abs/2304.04994</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.04994] Neural Multi-network Diffusion towards Social Recommendation](http://arxiv.org/abs/2304.04994) #diffusion</code></li>
<li>Summary: <p>Graph Neural Networks (GNNs) have been widely applied on a variety of
real-world applications, such as social recommendation. However, existing
GNN-based models on social recommendation suffer from serious problems of
generalization and oversmoothness, because of the underexplored negative
sampling method and the direct implanting of the off-the-shelf GNN models. In
this paper, we propose a succinct multi-network GNN-based neural model (NeMo)
for social recommendation. Compared with the existing methods, the proposed
model explores a generative negative sampling strategy, and leverages both the
positive and negative user-item interactions for users' interest propagation.
The experiments show that NeMo outperforms the state-of-the-art baselines on
various real-world benchmark datasets (e.g., by up to 38.8% in terms of
NDCG@15).
</p></li>
</ul>

<h3>Title: Modeling and design of heterogeneous hierarchical bioinspired spider web structures using generative deep learning and additive manufacturing. (arXiv:2304.05137v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05137">http://arxiv.org/abs/2304.05137</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05137] Modeling and design of heterogeneous hierarchical bioinspired spider web structures using generative deep learning and additive manufacturing](http://arxiv.org/abs/2304.05137) #diffusion</code></li>
<li>Summary: <p>Spider webs are incredible biological structures, comprising thin but strong
silk filament and arranged into complex hierarchical architectures with
striking mechanical properties (e.g., lightweight but high strength, achieving
diverse mechanical responses). While simple 2D orb webs can easily be mimicked,
the modeling and synthesis of 3D-based web structures remain challenging,
partly due to the rich set of design features. Here we provide a detailed
analysis of the heterogenous graph structures of spider webs, and use deep
learning as a way to model and then synthesize artificial, bio-inspired 3D web
structures. The generative AI models are conditioned based on key geometric
parameters (including average edge length, number of nodes, average node
degree, and others). To identify graph construction principles, we use
inductive representation sampling of large experimentally determined spider web
graphs, to yield a dataset that is used to train three conditional generative
models: 1) An analog diffusion model inspired by nonequilibrium thermodynamics,
with sparse neighbor representation, 2) a discrete diffusion model with full
neighbor representation, and 3) an autoregressive transformer architecture with
full neighbor representation. All three models are scalable, produce complex,
de novo bio-inspired spider web mimics, and successfully construct graphs that
meet the design objectives. We further propose algorithm that assembles web
samples produced by the generative models into larger-scale structures based on
a series of geometric design targets, including helical and parametric shapes,
mimicking, and extending natural design principles towards integration with
diverging engineering objectives. Several webs are manufactured using 3D
printing and tested to assess mechanical properties.
</p></li>
</ul>

<h3>Title: Diffusion Models for Constrained Domains. (arXiv:2304.05364v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.05364">http://arxiv.org/abs/2304.05364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.05364] Diffusion Models for Constrained Domains](http://arxiv.org/abs/2304.05364) #diffusion</code></li>
<li>Summary: <p>Denoising diffusion models are a recent class of generative models which
achieve state-of-the-art results in many domains such as unconditional image
generation and text-to-speech tasks. They consist of a noising process
destroying the data and a backward stage defined as the time-reversal of the
noising diffusion. Building on their success, diffusion models have recently
been extended to the Riemannian manifold setting. Yet, these Riemannian
diffusion models require geodesics to be defined for all times. While this
setting encompasses many important applications, it does not include manifolds
defined via a set of inequality constraints, which are ubiquitous in many
scientific domains such as robotics and protein design. In this work, we
introduce two methods to bridge this gap. First, we design a noising process
based on the logarithmic barrier metric induced by the inequality constraints.
Second, we introduce a noising process based on the reflected Brownian motion.
As existing diffusion model techniques cannot be applied in this setting, we
derive new tools to define such models in our framework. We empirically
demonstrate the applicability of our methods to a number of synthetic and
real-world tasks, including the constrained conformational modelling of protein
backbones and robotic arms.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
