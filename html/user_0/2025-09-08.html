<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-09-08</h1>
<h3>Title: INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance</h3>
<ul>
<li><strong>Authors: </strong>Shisong Chen, Qian Zhu, Wenyan Yang, Chengyi Yang, Zhong Wang, Ping Wang, Xuan Lin, Bo Xu, Daqian Li, Chao Yuan, Licai Qi, Wanqing Xu, sun zhenxing, Xin Lu, Shiqiang Xiong, Chao Chen, Haixiang Hu, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04455">https://arxiv.org/abs/2509.04455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04455">https://arxiv.org/pdf/2509.04455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04455]] INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance(https://arxiv.org/abs/2509.04455)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Insurance, as a critical component of the global financial system, demands high standards of accuracy and reliability in AI applications. While existing benchmarks evaluate AI capabilities across various domains, they often fail to capture the unique characteristics and requirements of the insurance domain. To address this gap, we present INSEva, a comprehensive Chinese benchmark specifically designed for evaluating AI systems' knowledge and capabilities in insurance. INSEva features a multi-dimensional evaluation taxonomy covering business areas, task formats, difficulty levels, and cognitive-knowledge dimension, comprising 38,704 high-quality evaluation examples sourced from authoritative materials. Our benchmark implements tailored evaluation methods for assessing both faithfulness and completeness in open-ended responses. Through extensive evaluation of 8 state-of-the-art Large Language Models (LLMs), we identify significant performance variations across different dimensions. While general LLMs demonstrate basic insurance domain competency with average scores above 80, substantial gaps remain in handling complex, real-world insurance scenarios. The benchmark will be public soon.</li>
</ul>

<h3>Title: Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support</h3>
<ul>
<li><strong>Authors: </strong>Anandi Dutta, Shivani Mruthyunjaya, Jessica Saddington, Kazi Sifatul Islam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04456">https://arxiv.org/abs/2509.04456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04456">https://arxiv.org/pdf/2509.04456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04456]] Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support(https://arxiv.org/abs/2509.04456)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>The emergence of large language models (LLMs) has unlocked boundless possibilities, along with significant challenges. In response, we developed a mental health support chatbot designed to augment professional healthcare, with a strong emphasis on safe and meaningful application. Our approach involved rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and bias. We employed a retrieval-augmented generation (RAG) framework, integrated prompt engineering, and fine-tuned a pre-trained model on novel datasets. The resulting system, Mentalic Net Conversational AI, achieved a BERT Score of 0.898, with other evaluation metrics falling within satisfactory ranges. We advocate for a human-in-the-loop approach and a long-term, responsible strategy in developing such transformative technologies, recognizing both their potential to change lives and the risks they may pose if not carefully managed.</li>
</ul>

<h3>Title: Do MLLMs Really Understand the Charts?</h3>
<ul>
<li><strong>Authors: </strong>Xiao Zhang, Dongyuan Li, Liuyu Xiang, Yao Zhang, Cheng Zhong, Zhaofeng He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04457">https://arxiv.org/abs/2509.04457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04457">https://arxiv.org/pdf/2509.04457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04457]] Do MLLMs Really Understand the Charts?(https://arxiv.org/abs/2509.04457)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although Multimodal Large Language Models (MLLMs) have demonstrated increasingly impressive performance in chart understanding, most of them exhibit alarming hallucinations and significant performance degradation when handling non-annotated charts. Therefore, a question arises: Do MLLMs really understand the charts? Since a human is capable of understanding charts and estimating the values by visual reasoning, we first carefully establish a comprehensive Chart Reasoning Benchmark CRBench to rigorously evaluate the visual reasoning abilities of MLLMs on non-annotated charts. We argue that MLLMs are primarily relying on recognition rather than reasoning to interpret the charts. To steer MLLMs to reasonable chart understanding, we propose ChartReasoner that mimics human behavior by grounding their estimation in chart understanding. Extensive results on the proposed CRBench show that ChartReasnoner-3B/7B achieves superior performance in chart reasoning, even compared to GPT-4o and Gemini-2.5-Flash. More importantly, ChartReasnoner also demonstrates the visual reasoning abilities in general chart comprehension on public benchmarks, leading to significant performance gains and enabling MLLMs to rationally understand the charts. The code and dataset will be publicly available upon publication.</li>
</ul>

<h3>Title: Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies</h3>
<ul>
<li><strong>Authors: </strong>Daniel B. Hier, Steven Keith Platt, Tayo Obafemi-Ajayi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04458">https://arxiv.org/abs/2509.04458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04458">https://arxiv.org/pdf/2509.04458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04458]] Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies(https://arxiv.org/abs/2509.04458)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models often perform well on biomedical NLP tasks but may fail to link ontology terms to their correct identifiers. We investigate why these failures occur by analyzing predictions across two major ontologies, Human Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o and LLaMa 3.1 405B. We evaluate nine candidate features related to term familiarity, identifier usage, morphology, and ontology structure. Univariate and multivariate analyses show that exposure to ontology identifiers is the strongest predictor of linking success.</li>
</ul>

<h3>Title: Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Shiqin Han, Manning Gao, Menghua Jiang, Yuncheng Jiang, Haifeng Hu, Sijie Mai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04459">https://arxiv.org/abs/2509.04459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04459">https://arxiv.org/pdf/2509.04459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04459]] Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis(https://arxiv.org/abs/2509.04459)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of Multimodal Large Language Models (MLLMs) has significantly advanced the state-of-the-art in multimodal machine learning, yet their substantial computational demands present a critical barrier to real-world deployment. Conversely, smaller, specialized models offer high efficiency but often at the cost of performance. To reconcile this performance-efficiency trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS) that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a lightweight baseline model for multimodal sentiment analysis. The core of our system is an uncertainty-driven cascade mechanism, where the efficient small model first acts as a rapid filter for all input samples. Only those samples yielding high predictive uncertainty, thereby indicating greater difficulty, are selectively escalated to the MLLM for more sophisticated analysis. Furthermore, our system introduces advanced strategies to handle ambiguous or conflicting predictions, including weighted averaging for predictions of similar polarity and a prompt-based cross-verification to resolve conflicting predictions when both models exhibit high uncertainty. This sample-difficulty-aware approach allows for a dynamic allocation of computational resources, drastically reducing inference costs while retaining the high accuracy of MLLM. Extensive experiments on benchmark datasets demonstrate that our proposed method achieves state-of-the-art performance, while requiring only a fraction of the computational resources compared to using a standalone MLLM.</li>
</ul>

<h3>Title: CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection</h3>
<ul>
<li><strong>Authors: </strong>Yihan Chen, Jiawei Chen, Guozhao Mo, Xuanang Chen, Ben He, Xianpei Han, Le Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04460">https://arxiv.org/abs/2509.04460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04460">https://arxiv.org/pdf/2509.04460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04460]] CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection(https://arxiv.org/abs/2509.04460)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>The growing integration of large language models (LLMs) into the peer review process presents potential risks to the fairness and reliability of scholarly evaluation. While LLMs offer valuable assistance for reviewers with language refinement, there is growing concern over their use to generate substantive review content. Existing general AI-generated text detectors are vulnerable to paraphrasing attacks and struggle to distinguish between surface language refinement and substantial content generation, suggesting that they primarily rely on stylistic cues. When applied to peer review, this limitation can result in unfairly suspecting reviews with permissible AI-assisted language enhancement, while failing to catch deceptively humanized AI-generated reviews. To address this, we propose a paradigm shift from style-based to content-based detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark built upon a fine-grained dataset of AI-generated peer reviews, covering six distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an AI review detector via a multi-task learning framework, designed to achieve more accurate and robust detection of AI involvement in review content. Our work offers a practical foundation for evaluating the use of LLMs in peer review, and contributes to the development of more precise, equitable, and reliable detection methods for real-world scholarly applications. Our code and data will be publicly available at this https URL.</li>
</ul>

<h3>Title: From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media</h3>
<ul>
<li><strong>Authors: </strong>Tian Ma, Kaiyu Feng, Yu Rong, Kangfei Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04461">https://arxiv.org/abs/2509.04461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04461">https://arxiv.org/pdf/2509.04461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04461]] From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media(https://arxiv.org/abs/2509.04461)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Personality prediction from social media posts is a critical task that implies diverse applications in psychology and sociology. The Myers Briggs Type Indicator (MBTI), a popular personality inventory, has been traditionally predicted by machine learning (ML) and deep learning (DL) techniques. Recently, the success of Large Language Models (LLMs) has revealed their huge potential in understanding and inferring personality traits from social media content. However, directly exploiting LLMs for MBTI prediction faces two key challenges: the hallucination problem inherent in LLMs and the naturally imbalanced distribution of MBTI types in the population. In this paper, we propose PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from social media posts of individuals. Specifically, PtoP leverages Retrieval Augmented Generation with in context learning to mitigate hallucination in LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification in MBTI understanding with synthetic minority oversampling, which balances the class imbalance by generating synthetic samples. Experiments conducted on a real world social media dataset demonstrate that PtoP achieves state of the art performance compared with 10 ML and DL baselines.</li>
</ul>

<h3>Title: Benchmarking GPT-5 for biomedical natural language processing</h3>
<ul>
<li><strong>Authors: </strong>Yu Hou, Zaifu Zhan, Rui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04462">https://arxiv.org/abs/2509.04462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04462">https://arxiv.org/pdf/2509.04462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04462]] Benchmarking GPT-5 for biomedical natural language processing(https://arxiv.org/abs/2509.04462)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The rapid expansion of biomedical literature has heightened the need for scalable natural language processing (NLP) solutions. While GPT-4 substantially narrowed the gap with task-specific systems, especially in question answering, its performance across other domains remained uneven. We updated a standardized BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot prompting across 12 datasets spanning six task families: named entity recognition, relation extraction, multi-label document classification, question answering, text summarization, and text simplification. Using fixed prompt templates, identical decoding parameters, and batch inference, we report primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark performance, with macro-average scores rising to 0.557 under five-shot prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached 94.1% accuracy, exceeding the previous supervised state of the art by over fifty points, and attained parity with supervised systems on PubMedQA (0.734). In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though summarization and disease NER still lagged behind domain-specific baselines. These results establish GPT-5 as a general-purpose model now offering deployment-ready performance for reasoning-oriented biomedical QA, while precision-critical extraction and evidence-dense summarization continue to favor fine-tuned or hybrid approaches. The benchmark delineates where simple prompting suffices and where retrieval-augmented or planning-based scaffolds are likely required, providing actionable guidance for BioNLP system design as frontier models advance.</li>
</ul>

<h3>Title: Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?</h3>
<ul>
<li><strong>Authors: </strong>Yang Nan, Pengfei He, Ravi Tandon, Han Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04464">https://arxiv.org/abs/2509.04464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04464">https://arxiv.org/pdf/2509.04464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04464]] Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?(https://arxiv.org/abs/2509.04464)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have delivered significant breakthroughs across diverse domains but can still produce unreliable or misleading outputs, posing critical challenges for real-world applications. While many recent studies focus on quantifying model uncertainty, relatively little work has been devoted to \textit{diagnosing the source of uncertainty}. In this study, we show that, when an LLM is uncertain, the patterns of disagreement among its multiple generated responses contain rich clues about the underlying cause of uncertainty. To illustrate this point, we collect multiple responses from a target LLM and employ an auxiliary LLM to analyze their patterns of disagreement. The auxiliary model is tasked to reason about the likely source of uncertainty, such as whether it stems from ambiguity in the input question, a lack of relevant knowledge, or both. In cases involving knowledge gaps, the auxiliary model also identifies the specific missing facts or concepts contributing to the uncertainty. In our experiment, we validate our framework on AmbigQA, OpenBookQA, and MMLU-Pro, confirming its generality in diagnosing distinct uncertainty sources. Such diagnosis shows the potential for relevant manual interventions that improve LLM performance and reliability.</li>
</ul>

<h3>Title: Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhang, Mengsi Lyu, Yulong Ao, Yonghua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04467">https://arxiv.org/abs/2509.04467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04467">https://arxiv.org/pdf/2509.04467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04467]] Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference(https://arxiv.org/abs/2509.04467)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate exceptional capabilities across various tasks, but their deployment is constrained by high computational and memory costs. Model pruning provides an effective means to alleviate these demands. However, existing methods often ignore the characteristics of prefill-decode (PD) disaggregation in practice. In this paper, we propose a novel pruning method for PD disaggregation inference, enabling more precise and efficient block and KV Cache pruning. Our approach constructs pruning and distillation sets to perform iterative block removal independently for the prefill and decode stages, obtaining better pruning solutions. Moreover, we introduce a token-aware cache pruning mechanism that retains all KV Cache in the prefill stage but selectively reuses entries for the first and last token sequences in selected layers during decode, reducing communication costs with minimal overhead. Extensive experiments demonstrate that our approach consistently achieves strong performance in both PD disaggregation and PD unified settings without disaggregation. Under the default settings, our method achieves a 20.56% inference speedup and a 4.95 times reduction in data transmission bandwidth consumption.</li>
</ul>

<h3>Title: Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study</h3>
<ul>
<li><strong>Authors: </strong>Xuan Yao, Qianteng Wang, Xinbo Liu, Ke-Wei Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04468">https://arxiv.org/abs/2509.04468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04468">https://arxiv.org/pdf/2509.04468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04468]] Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study(https://arxiv.org/abs/2509.04468)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models presents significant opportunities for financial applications, yet systematic evaluation in specialized financial contexts remains limited. This study presents the first comprehensive evaluation of state-of-the-art LLMs using 1,560 multiple-choice questions from official mock exams across Levels I-III of CFA, most rigorous professional certifications globally that mirror real-world financial analysis complexity. We compare models distinguished by core design priorities: multi-modal and computationally powerful, reasoning-specialized and highly accurate, and lightweight efficiency-optimized. We assess models under zero-shot prompting and through a novel Retrieval-Augmented Generation pipeline that integrates official CFA curriculum content. The RAG system achieves precise domain-specific knowledge retrieval through hierarchical knowledge organization and structured query generation, significantly enhancing reasoning accuracy in professional financial certification evaluation. Results reveal that reasoning-oriented models consistently outperform others in zero-shot settings, while the RAG pipeline provides substantial improvements particularly for complex scenarios. Comprehensive error analysis identifies knowledge gaps as the primary failure mode, with minimal impact from text readability. These findings provide actionable insights for LLM deployment in finance, offering practitioners evidence-based guidance for model selection and cost-performance optimization.</li>
</ul>

<h3>Title: Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing</h3>
<ul>
<li><strong>Authors: </strong>David Berghaus, Armin Berger, Lars Hillebrand, Kostadin Cvejoski, Rafet Sifa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04469">https://arxiv.org/abs/2509.04469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04469">https://arxiv.org/pdf/2509.04469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04469]] Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing(https://arxiv.org/abs/2509.04469)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper benchmarks eight multi-modal large language models from three families (GPT-5, Gemini 2.5, and open-source Gemma 3) on three diverse openly available invoice document datasets using zero-shot prompting. We compare two processing strategies: direct image processing using multi-modal capabilities and a structured parsing approach converting documents to markdown first. Results show native image processing generally outperforms structured approaches, with performance varying across model types and document characteristics. This benchmark provides insights for selecting appropriate models and processing strategies for automated document systems. Our code is available online.</li>
</ul>

<h3>Title: COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions</h3>
<ul>
<li><strong>Authors: </strong>Swarnadeep Bhar, Omar Naim, Eleni Metheniti, Bastien Navarri, Lo√Øc Cabannes, Morteza Ezzabady, Nicholas Asher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04470">https://arxiv.org/abs/2509.04470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04470">https://arxiv.org/pdf/2509.04470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04470]] COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions(https://arxiv.org/abs/2509.04470)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present COCORELI, a hybrid agent framework designed to tackle the limitations of large language models (LLMs) in tasks requiring: following complex instructions, minimizing hallucination, and spatial reasoning. COCORELI integrates medium-sized LLM agents with novel abstraction mechanisms and a discourse module to parse instructions to in-context learn dynamic, high-level representations of the environment. Experiments on natural collaborative construction tasks show that COCORELI outperforms single-LLM CoT and agentic LLM systems, all using larger LLMs. It manages to largely avoid hallucinations, identify missing information, ask for clarifications, and update its learned objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown in the ToolBench API completion task.</li>
</ul>

<h3>Title: RECAP: REwriting Conversations for Intent Understanding in Agentic Planning</h3>
<ul>
<li><strong>Authors: </strong>Kushan Mitra, Dan Zhang, Hannah Kim, Estevam Hruschka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04472">https://arxiv.org/abs/2509.04472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04472">https://arxiv.org/pdf/2509.04472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04472]] RECAP: REwriting Conversations for Intent Understanding in Agentic Planning(https://arxiv.org/abs/2509.04472)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding user intent is essential for effective planning in conversational assistants, particularly those powered by large language models (LLMs) coordinating multiple agents. However, real-world dialogues are often ambiguous, underspecified, or dynamic, making intent detection a persistent challenge. Traditional classification-based approaches struggle to generalize in open-ended settings, leading to brittle interpretations and poor downstream planning. We propose RECAP (REwriting Conversations for Agent Planning), a new benchmark designed to evaluate and advance intent rewriting, reframing user-agent dialogues into concise representations of user goals. RECAP captures diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal conversations. Alongside the dataset, we introduce an LLM-based evaluator that assesses planning utility given the rewritten intent. Using RECAP, we develop a prompt-based rewriting approach that outperforms baselines. We further demonstrate that fine-tuning two DPO-based rewriters yields additional utility gains. Our results highlight intent rewriting as a critical and tractable component for improving agent planning in open-domain dialogue systems.</li>
</ul>

<h3>Title: Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Shengyin Sun, Yiming Li, Xing Li, Yingzhao Lian, Weizhe Lin, Hui-Ling Zhen, Zhiyuan Yang, Chen Chen, Xianzhi Yu, Mingxuan Yuan, Chen Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04474">https://arxiv.org/abs/2509.04474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04474">https://arxiv.org/pdf/2509.04474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04474]] Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling(https://arxiv.org/abs/2509.04474)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Test-time scaling has emerged as a powerful paradigm for enhancing the reasoning capabilities of large language models (LLMs) by allocating additional computational resources during inference. However, this paradigm is inherently inefficient due to the generation of redundant and repetitive reasoning traces, leading to significant computational overhead. Speculative decoding offers a promising avenue for mitigating this inefficiency, yet its efficacy in the structured, repetition-rich context of test-time scaling remains largely unexplored. To bridge this gap, we introduce the first comprehensive benchmark designed to evaluate speculative decoding methods for accelerating LLM test-time scaling. Our benchmark provides consistent experimental protocols across representative test-time scaling paradigms (e.g., Best-of-N sampling and multi-round thinking), enabling a fair comparison of three major categories of speculative decoding: model-based, training-based, and n-gram-based methods. Extensive experiments reveal that simple n-gram-based methods effectively capture repetitive patterns, demonstrating unique potential in accelerating test-time scaling. This phenomenon demonstrates the value of integrating n-gram-based methods with model-based or training-based approaches to balance acceleration for both repetitive and diverse reasoning in test-time scaling. We hope this benchmark spurs further research on speculative decoding for test-time scaling, enabling faster and more practical reasoning in LLMs through better handling of repetitive and diverse reasoning paths.</li>
</ul>

<h3>Title: ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute</h3>
<ul>
<li><strong>Authors: </strong>Hao Wen, Yifan Su, Feifei Zhang, Yunxin Liu, Yunhao Liu, Ya-Qin Zhang, Yuanchun Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04475">https://arxiv.org/abs/2509.04475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04475">https://arxiv.org/pdf/2509.04475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04475]] ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute(https://arxiv.org/abs/2509.04475)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have been driven by test-time compute scaling - a strategy that improves reasoning by generating longer, sequential thought processes. While effective, this approach encounters a significant bottleneck as computation increases, where further computation offers only marginal performance gains. We argue this ceiling is not an inherent limit of the model's capability but a flaw in the scaling strategy itself, a phenomenon we term "Tunnel Vision", where a model's imperfect initial steps lock it into a suboptimal reasoning path. To overcome this, we introduce a new scaling paradigm: native thought parallelism. We present ParaThinker, an end-to-end framework that trains an LLM to generate multiple, diverse reasoning paths in parallel and synthesize them into a superior final answer. By exploring different lines of thoughts simultaneously, ParaThinker effectively sidesteps the Tunnel Vision issue and unlocks the model's latent reasoning potential. Our approach demonstrates that scaling compute in parallel (width) is a more effective and efficient way to superior reasoning than simply scaling sequentially (depth). On challenging reasoning benchmarks, ParaThinker achieves substantial accuracy improvements over sequential LLMs (12.3% for 1.5B and 7.5% for 7B models on average with 8 parallel paths), while adding only negligible latency overhead (7.1%). This enables smaller models to surpass much larger counterparts and establishes parallel thinking as a critical, efficient dimension for scaling future LLMs.</li>
</ul>

<h3>Title: An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine</h3>
<ul>
<li><strong>Authors: </strong>Iniakpokeikiye Peter Thompson, Yi Dewei, Reiter Ehud</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04478">https://arxiv.org/abs/2509.04478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04478">https://arxiv.org/pdf/2509.04478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04478]] An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine(https://arxiv.org/abs/2509.04478)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents an end-to-end mobile system that delivers culturally-attuned safe driving feedback to drivers in Nigeria, a low-resource environment with significant infrastructural challenges. The core of the system is a novel dual-component Natural Language Generation (NLG) engine that provides both legally-grounded safety tips and persuasive, theory-driven behavioural reports. We describe the complete system architecture, including an automatic trip detection service, on-device behaviour analysis, and a sophisticated NLG pipeline that leverages a two-step reflection process to ensure high-quality feedback. The system also integrates a specialized machine learning model for detecting alcohol-influenced driving, a key local safety issue. The architecture is engineered for robustness against intermittent connectivity and noisy sensor data. A pilot deployment with 90 drivers demonstrates the viability of our approach, and initial results on detected unsafe behaviours are presented. This work provides a framework for applying data-to-text and AI systems to achieve social good.</li>
</ul>

<h3>Title: No Clustering, No Routing: How Transformers Actually Process Rare Tokens</h3>
<ul>
<li><strong>Authors: </strong>Jing Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04479">https://arxiv.org/abs/2509.04479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04479">https://arxiv.org/pdf/2509.04479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04479]] No Clustering, No Routing: How Transformers Actually Process Rare Tokens(https://arxiv.org/abs/2509.04479)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models struggle with rare token prediction, yet the mechanisms driving their specialization remain unclear. Prior work identified specialized ``plateau'' neurons for rare tokens following distinctive three-regime influence patterns \cite{liu2025emergent}, but their functional organization is unknown. We investigate this through neuron influence analyses, graph-based clustering, and attention head ablations in GPT-2 XL and Pythia models. Our findings show that: (1) rare token processing requires additional plateau neurons beyond the power-law regime sufficient for common tokens, forming dual computational regimes; (2) plateau neurons are spatially distributed rather than forming modular clusters; and (3) attention mechanisms exhibit no preferential routing to specialists. These results demonstrate that rare token specialization arises through distributed, training-driven differentiation rather than architectural modularity, preserving context-sensitive flexibility while achieving adaptive capacity allocation.</li>
</ul>

<h3>Title: Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Ryo Takahashi, Naoki Saito, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04480">https://arxiv.org/abs/2509.04480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04480">https://arxiv.org/pdf/2509.04480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04480]] Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition(https://arxiv.org/abs/2509.04480)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual Emotion Recognition (VER) is an important research topic due to its wide range of applications, including opinion mining and advertisement design. Extending this capability to recognize emotions at the individual level further broadens its potential applications. Recently, Multimodal Large Language Models (MLLMs) have attracted increasing attention and demonstrated performance comparable to that of conventional VER methods. However, MLLMs are trained on large and diverse datasets containing general opinions, which causes them to favor majority viewpoints and familiar patterns. This tendency limits their performance in a personalized VER, which is crucial for practical and real-world applications, and indicates a key area for improvement. To address this limitation, the proposed method employs discrete prompt tuning inspired by the process of humans' prompt engineering to adapt the VER task to each individual. Our method selects the best natural language representation from the generated prompts and uses it to update the prompt for the realization of accurate personalized VER.</li>
</ul>

<h3>Title: Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Ravi Shankar, Sheng Wong, Lin Li, Magdalena Bachmann, Alex Silverthorne, Beth Albert, Gabriel Davis Jones</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04482">https://arxiv.org/abs/2509.04482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04482">https://arxiv.org/pdf/2509.04482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04482]] Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare(https://arxiv.org/abs/2509.04482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Reliable abstention is critical for retrieval-augmented generation (RAG) systems, particularly in safety-critical domains such as women's health, where incorrect answers can lead to harm. We present an energy-based model (EBM) that learns a smooth energy landscape over a dense semantic corpus of 2.6M guideline-derived questions, enabling the system to decide when to generate or abstain. We benchmark the EBM against a calibrated softmax baseline and a k-nearest neighbour (kNN) density heuristic across both easy and hard abstention splits, where hard cases are semantically challenging near-distribution queries. The EBM achieves superior abstention performance abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives, performance is comparable across methods, but the EBM's advantage becomes most pronounced in safety-critical hard distributions. A comprehensive ablation with controlled negative sampling and fair data exposure shows that robustness stems primarily from the energy scoring head, while the inclusion or exclusion of specific negative types (hard, easy, mixed) sharpens decision boundaries but is not essential for generalisation to hard cases. These results demonstrate that energy-based abstention scoring offers a more reliable confidence signal than probability-based softmax confidence, providing a scalable and interpretable foundation for safe RAG systems.</li>
</ul>

<h3>Title: DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs</h3>
<ul>
<li><strong>Authors: </strong>Minghui Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04483">https://arxiv.org/abs/2509.04483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04483">https://arxiv.org/pdf/2509.04483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04483]] DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs(https://arxiv.org/abs/2509.04483)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Claim decomposition plays a crucial role in the fact-checking process by breaking down complex claims into simpler atomic components and identifying their unfactual elements. Despite its importance, current research primarily focuses on generative methods for decomposition, with insufficient emphasis on evaluating the quality of these decomposed atomic claims. To bridge this gap, we introduce \textbf{DecMetrics}, which comprises three new metrics: \texttt{COMPLETENESS}, \texttt{CORRECTNESS}, and \texttt{SEMANTIC ENTROPY}, designed to automatically assess the quality of claims produced by decomposition models. Utilizing these metrics, we develop a lightweight claim decomposition model, optimizing its performance through the integration of these metrics as a reward function. Through automatic evaluation, our approach aims to set a benchmark for claim decomposition, enhancing both the reliability and effectiveness of fact-checking systems.</li>
</ul>

<h3>Title: ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Chris Sainsbury, Andreas Karwath</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04485">https://arxiv.org/abs/2509.04485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04485">https://arxiv.org/pdf/2509.04485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04485]] ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records(https://arxiv.org/abs/2509.04485)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present ASCENDgpt, a transformer-based model specifically designed for cardiovascular risk prediction from longitudinal electronic health records (EHRs). Our approach introduces a novel phenotype-aware tokenization scheme that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens, achieving 99.6\% consolidation of diagnosis codes while preserving semantic information. This phenotype mapping contributes to a total vocabulary of 10,442 tokens - a 77.9\% reduction when compared with using raw ICD codes directly. We pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a masked language modeling objective, then fine-tune for time-to-event prediction of five cardiovascular outcomes: myocardial infarction (MI), stroke, major adverse cardiovascular events (MACE), cardiovascular death, and all-cause mortality. Our model achieves excellent discrimination on the held-out test set with an average C-index of 0.816, demonstrating strong performance across all outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842, all-cause mortality: 0.824). The phenotype-based approach enables clinically interpretable predictions while maintaining computational efficiency. Our work demonstrates the effectiveness of domain-specific tokenization and pretraining for EHR-based risk prediction tasks.</li>
</ul>

<h3>Title: Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Hao Shi, Yusuke Fujita, Tomoya Mizumoto, Lianbo Liu, Atsushi Kojima, Yui Sudo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04488">https://arxiv.org/abs/2509.04488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04488">https://arxiv.org/pdf/2509.04488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04488]] Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition(https://arxiv.org/abs/2509.04488)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Prompts are crucial for task definition and for improving the performance of large language models (LLM)-based systems. However, existing LLM-based multi-talker (MT) automatic speech recognition (ASR) systems either omit prompts or rely on simple task-definition prompts, with no prior work exploring the design of prompts to enhance performance. In this paper, we propose extracting serialized output prompts (SOP) and explicitly guiding the LLM using structured prompts to improve system performance (SOP-MT-ASR). A Separator and serialized Connectionist Temporal Classification (CTC) layers are inserted after the speech encoder to separate and extract MT content from the mixed speech encoding in a first-speaking-first-out manner. Subsequently, the SOP, which serves as a prompt for LLMs, is obtained by decoding the serialized CTC outputs using greedy search. To train the model effectively, we design a three-stage training strategy, consisting of serialized output training (SOT) fine-tuning, serialized speech information extraction, and SOP-based adaptation. Experimental results on the LibriMix dataset show that, although the LLM-based SOT model performs well in the two-talker scenario, it fails to fully leverage LLMs under more complex conditions, such as the three-talker scenario. The proposed SOP approach significantly improved performance under both two- and three-talker conditions.</li>
</ul>

<h3>Title: Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR</h3>
<ul>
<li><strong>Authors: </strong>Xinnian Zhao, Hugo Van Hamme</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04491">https://arxiv.org/abs/2509.04491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04491">https://arxiv.org/pdf/2509.04491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04491]] Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR(https://arxiv.org/abs/2509.04491)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study proposes a novel approach to using TV subtitles within a weakly supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV subtitles are readily available, their imprecise alignment with corresponding audio limits their applicability as supervised targets for verbatim transcription. Rather than using subtitles as direct supervision signals, our method reimagines them as context-rich prompts. This design enables the model to handle discrepancies between spoken audio and subtitle text. Instead, generated pseudo transcripts become the primary targets, with subtitles acting as guiding cues for iterative refinement. To further enhance the process, we introduce a weighted attention mechanism that emphasizes relevant subtitle tokens during inference. Our experiments demonstrate significant improvements in transcription accuracy, highlighting the effectiveness of the proposed method in refining transcripts. These enhanced pseudo-labeled datasets provide high-quality foundational resources for training robust ASR systems.</li>
</ul>

<h3>Title: Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate</h3>
<ul>
<li><strong>Authors: </strong>Charles Moslonka, Hicham Randrianarivo, Arthur Garnier, Emmanuel Malherbe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04492">https://arxiv.org/abs/2509.04492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04492">https://arxiv.org/pdf/2509.04492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04492]] Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate(https://arxiv.org/abs/2509.04492)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Hallucinations in Large Language Model (LLM) outputs for Question Answering (QA) tasks critically undermine their real-world reliability. This paper introduces an applied methodology for robust, one-shot hallucination detection, specifically designed for scenarios with limited data access, such as interacting with black-box LLM APIs that typically expose only a few top candidate log-probabilities per token. Our approach derives uncertainty indicators directly from these readily available log-probabilities generated during non-greedy decoding. We first derive an Entropy Production Rate (EPR) metric that offers baseline performance, later augmented with supervised learning. Our learned model uses features representing the entropic contributions of the accessible top-ranked tokens within a single generated sequence, requiring no multiple query re-runs. Evaluated across diverse QA datasets and multiple LLMs, this estimator significantly improves hallucination detection over using EPR alone. Crucially, high performance is demonstrated using only the typically small set of available log-probabilities (e.g., top <10 per token), confirming its practical efficiency and suitability for these API-constrained deployments. This work provides a readily deployable technique to enhance the trustworthiness of LLM responses from a single generation pass in QA and Retrieval-Augmented Generation (RAG) systems, with its utility further demonstrated in a finance framework analyzing responses to queries on annual reports from an industrial dataset.</li>
</ul>

<h3>Title: Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations</h3>
<ul>
<li><strong>Authors: </strong>Krithi Shailya, Akhilesh Kumar Mishra, Gokul S Krishnan, Balaraman Ravindran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04498">https://arxiv.org/abs/2509.04498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04498">https://arxiv.org/pdf/2509.04498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04498]] Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations(https://arxiv.org/abs/2509.04498)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used as daily recommendation systems for tasks like education planning, yet their recommendations risk perpetuating societal biases. This paper empirically examines geographic, demographic, and economic biases in university and program suggestions from three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360 simulated user profiles varying by gender, nationality, and economic status, we analyze over 25,000 recommendations. Results show strong biases: institutions in the Global North are disproportionately favored, recommendations often reinforce gender stereotypes, and institutional repetition is prevalent. While LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities across 58 countries, systemic disparities persist. To quantify these issues, we propose a novel, multi-dimensional evaluation framework that goes beyond accuracy by measuring demographic and geographic representation. Our findings highlight the urgent need for bias consideration in educational LMs to ensure equitable global access to higher education.</li>
</ul>

<h3>Title: DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence</h3>
<ul>
<li><strong>Authors: </strong>Pranav Narayanan Venkit, Philippe Laban, Yilun Zhou, Kung-Hsiang Huang, Yixin Mao, Chien-Sheng Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04499">https://arxiv.org/abs/2509.04499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04499">https://arxiv.org/pdf/2509.04499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04499]] DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence(https://arxiv.org/abs/2509.04499)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Generative search engines and deep research LLM agents promise trustworthy, source-grounded synthesis, yet users regularly encounter overconfidence, weak sourcing, and confusing citation practices. We introduce DeepTRACE, a novel sociotechnically grounded audit framework that turns prior community-identified failure cases into eight measurable dimensions spanning answer text, sources, and citations. DeepTRACE uses statement-level analysis (decomposition, confidence scoring) and builds citation and factual-support matrices to audit how systems reason with and attribute evidence end-to-end. Using automated extraction pipelines for popular public models (e.g., GPT-4.5/5, this http URL, Perplexity, Copilot/Bing, Gemini) and an LLM-judge with validated agreement to human raters, we evaluate both web-search engines and deep-research configurations. Our findings show that generative search engines and deep research agents frequently produce one-sided, highly confident responses on debate queries and include large fractions of statements unsupported by their own listed sources. Deep-research configurations reduce overconfidence and can attain high citation thoroughness, but they remain highly one-sided on debate queries and still exhibit large fractions of unsupported statements, with citation accuracy ranging from 40--80% across systems.</li>
</ul>

<h3>Title: Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts</h3>
<ul>
<li><strong>Authors: </strong>Rushi Wang, Jiateng Liu, Cheng Qian, Yifan Shen, Yanzhou Pan, Zhaozhuo Xu, Ahmed Abbasi, Heng Ji, Denghui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04500">https://arxiv.org/abs/2509.04500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04500">https://arxiv.org/pdf/2509.04500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04500]] Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts(https://arxiv.org/abs/2509.04500)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Incorporating external context can significantly enhance the response quality of Large Language Models (LLMs). However, real-world contexts often mix relevant information with disproportionate inappropriate content, posing reliability risks. How do LLMs process and prioritize mixed context? To study this, we introduce the Poisoned Context Testbed, pairing queries with real-world contexts containing relevant and inappropriate content. Inspired by associative learning in animals, we adapt the Rescorla-Wagner (RW) model from neuroscience to quantify how competing contextual signals influence LLM outputs. Our adapted model reveals a consistent behavioral pattern: LLMs exhibit a strong tendency to incorporate information that is less prevalent in the context. This susceptibility is harmful in real-world settings, where small amounts of inappropriate content can substantially degrade response quality. Empirical evaluations on our testbed further confirm this vulnerability. To tackle this, we introduce RW-Steering, a two-stage finetuning-based approach that enables the model to internally identify and ignore inappropriate signals. Unlike prior methods that rely on extensive supervision across diverse context mixtures, RW-Steering generalizes robustly across varying proportions of inappropriate content. Experiments show that our best fine-tuned model improves response quality by 39.8% and reverses the undesirable behavior curve, establishing RW-Steering as a robust, generalizable context engineering solution for improving LLM safety in real-world use.</li>
</ul>

<h3>Title: VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples</h3>
<ul>
<li><strong>Authors: </strong>Qixin Sun, Ziqin Wang, Hengyuan Zhao, Yilin Li, Kaiyou Song, Linjiang Huang, Xiaolin Hu, Qingpei Guo, Si Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04502">https://arxiv.org/abs/2509.04502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04502">https://arxiv.org/pdf/2509.04502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04502]] VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples(https://arxiv.org/abs/2509.04502)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation enhances the response accuracy of Large Language Models (LLMs) by integrating retrieval and generation modules with external knowledge, demonstrating particular strength in real-time queries and Visual Question Answering tasks. However, the effectiveness of RAG is frequently hindered by the precision of the retriever: many retrieved samples fed into the generation phase are irrelevant or misleading, posing a critical bottleneck to LLMs' performance. To address this challenge, we introduce VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using data with varying positive/negative sample ratios, systematically exposing inherent weaknesses in current LLMs. On the other hand, it enhances models' sample-discrimination capabilities by prompting LLMs to generate explicit Chain-of-Thought (CoT) analysis for each sample before producing final answers. Furthermore, to enhance the model's ability to learn long-sequence complex CoT content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple components rather than a single whole, our model can make more informed preference selections for complex sequences, thereby enhancing its capacity to learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG validate the effectiveness of the proposed scheme. The code and dataset will be publicly released soon.</li>
</ul>

<h3>Title: Behavioral Fingerprinting of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zehua Pei, Hui-Ling Zhen, Ying Zhang, Zhiyuan Yang, Xing Li, Xianzhi Yu, Mingxuan Yuan, Bei Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04504">https://arxiv.org/abs/2509.04504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04504">https://arxiv.org/pdf/2509.04504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04504]] Behavioral Fingerprinting of Large Language Models(https://arxiv.org/abs/2509.04504)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Current benchmarks for Large Language Models (LLMs) primarily focus on performance metrics, often failing to capture the nuanced behavioral characteristics that differentiate them. This paper introduces a novel ``Behavioral Fingerprinting'' framework designed to move beyond traditional evaluation by creating a multi-faceted profile of a model's intrinsic cognitive and interactive styles. Using a curated \textit{Diagnostic Prompt Suite} and an innovative, automated evaluation pipeline where a powerful LLM acts as an impartial judge, we analyze eighteen models across capability tiers. Our results reveal a critical divergence in the LLM landscape: while core capabilities like abstract and causal reasoning are converging among top models, alignment-related behaviors such as sycophancy and semantic robustness vary dramatically. We further document a cross-model default persona clustering (ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together, this suggests that a model's interactive nature is not an emergent property of its scale or reasoning power, but a direct consequence of specific, and highly variable, developer alignment strategies. Our framework provides a reproducible and scalable methodology for uncovering these deep behavioral differences. Project: this https URL</li>
</ul>

<h3>Title: From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach</h3>
<ul>
<li><strong>Authors: </strong>Nithyashree Sivasubramaniam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04507">https://arxiv.org/abs/2509.04507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04507">https://arxiv.org/pdf/2509.04507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04507]] From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach(https://arxiv.org/abs/2509.04507)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Silent Speech Interfaces (SSIs) have gained attention for their ability to generate intelligible speech from non-acoustic signals. While significant progress has been made in advancing speech generation pipelines, limited work has addressed the recognition and downstream processing of synthesized speech, which often suffers from phonetic ambiguity and noise. To overcome these challenges, we propose an enhanced automatic speech recognition framework that combines a transformer-based acoustic model with a large language model (LLM) for post-processing. The transformer captures full utterance context, while the LLM ensures linguistic consistency. Experimental results show a 16% relative and 6% absolute reduction in word error rate (WER) over a 36% baseline, demonstrating substantial improvements in intelligibility for silent speech interfaces.</li>
</ul>

<h3>Title: ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models</h3>
<ul>
<li><strong>Authors: </strong>Biddut Sarker Bijoy, Mohammad Saqib Hasan, Pegah Alipoormolabashi, Avirup Sil, Aruna Balasubramanian, Niranjan Balasubramanian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04508">https://arxiv.org/abs/2509.04508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04508">https://arxiv.org/pdf/2509.04508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04508]] ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models(https://arxiv.org/abs/2509.04508)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-agent systems with smaller language models (SLMs) present a viable alternative to single agent systems powered by large language models (LLMs) for addressing complex problems. In this work, we study how these alternatives compare in terms of both effectiveness and efficiency. To study this trade-off, we instantiate single and multi-agent systems for the complex problems in the AppWorld environment using different sized language models. We find that difficulties with long-trajectory learning in smaller language models (SLMs) limit their performance. Even when trained for specialized roles, SLMs fail to learn all subtasks effectively. To address this issue, we introduce a simple progressive sub-task training strategy, which introduces new sub-tasks progressively in each training epoch. We find that this novel strategy, analogous to instance level curriculum learning, consistently improves the effectiveness of multi-agents at all configurations. Our Pareto analysis shows that fine-tuned multi-agent systems yield better effectiveness-efficiency trade-offs. Additional ablations and analyses shows the importance of our progressive training strategy and its ability to reduce subtask error rates.</li>
</ul>

<h3>Title: Scaling behavior of large language models in emotional safety classification across sizes and tasks</h3>
<ul>
<li><strong>Authors: </strong>Edoardo Pinzuti, Oliver T√ºscher, Andr√© Ferreira Castro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04512">https://arxiv.org/abs/2509.04512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04512">https://arxiv.org/pdf/2509.04512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04512]] Scaling behavior of large language models in emotional safety classification across sizes and tasks(https://arxiv.org/abs/2509.04512)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Understanding how large language models (LLMs) process emotionally sensitive content is critical for building safe and reliable systems, particularly in mental health contexts. We investigate the scaling behavior of LLMs on two key tasks: trinary classification of emotional safety (safe vs. unsafe vs. borderline) and multi-label classification using a six-category safety risk taxonomy. To support this, we construct a novel dataset by merging several human-authored mental health datasets (> 15K samples) and augmenting them with emotion re-interpretation prompts generated via ChatGPT. We evaluate four LLaMA models (1B, 3B, 8B, 70B) across zero-shot, few-shot, and fine-tuning settings. Our results show that larger LLMs achieve stronger average performance, particularly in nuanced multi-label classification and in zero-shot settings. However, lightweight fine-tuning allowed the 1B model to achieve performance comparable to larger models and BERT in several high-data categories, while requiring <2GB VRAM at inference. These findings suggest that smaller, on-device models can serve as viable, privacy-preserving alternatives for sensitive applications, offering the ability to interpret emotional context and maintain safe conversational boundaries. This work highlights key implications for therapeutic LLM applications and the scalable alignment of safety-critical systems.</li>
</ul>

<h3>Title: Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations</h3>
<ul>
<li><strong>Authors: </strong>Martha O. Dimgba, Sharon Oba, Ameeta Agrawal, Philippe J. Giabbanelli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04515">https://arxiv.org/abs/2509.04515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04515">https://arxiv.org/pdf/2509.04515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04515]] Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations(https://arxiv.org/abs/2509.04515)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Language models have been shown to propagate social bias through their output, particularly in the representation of gender and ethnicity. This paper investigates gender and ethnicity biases in AI-generated occupational stories. Representation biases are measured before and after applying our proposed mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME), revealing improvements in demographic representation ranging from 2% to 20%. BAME leverages model-generated explanations to inform targeted prompt engineering, effectively reducing biases without modifying model parameters. By analyzing stories generated across 25 occupational groups, three large language models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and multiple demographic dimensions, we identify persistent patterns of overrepresentation and underrepresentation linked to training data stereotypes. Our findings demonstrate that guiding models with their own internal reasoning mechanisms can significantly enhance demographic parity, thereby contributing to the development of more transparent generative AI systems.</li>
</ul>

<h3>Title: Artificially Fluent: Swahili AI Performance Benchmarks Between English-Trained and Natively-Trained Datasets</h3>
<ul>
<li><strong>Authors: </strong>Sophie Jaffer, Simeon Sayer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04516">https://arxiv.org/abs/2509.04516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04516">https://arxiv.org/pdf/2509.04516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04516]] Artificially Fluent: Swahili AI Performance Benchmarks Between English-Trained and Natively-Trained Datasets(https://arxiv.org/abs/2509.04516)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) expand multilingual capabilities, questions remain about the equity of their performance across languages. While many communities stand to benefit from AI systems, the dominance of English in training data risks disadvantaging non-English speakers. To test the hypothesis that such data disparities may affect model performance, this study compares two monolingual BERT models: one trained and tested entirely on Swahili data, and another on comparable English news data. To simulate how multilingual LLMs process non-English queries through internal translation and abstraction, we translated the Swahili news data into English and evaluated it using the English-trained model. This approach tests the hypothesis by evaluating whether translating Swahili inputs for evaluation on an English model yields better or worse performance compared to training and testing a model entirely in Swahili, thus isolating the effect of language consistency versus cross-lingual abstraction. The results prove that, despite high-quality translation, the native Swahili-trained model performed better than the Swahili-to-English translated model, producing nearly four times fewer errors: 0.36% vs. 1.47% respectively. This gap suggests that translation alone does not bridge representational differences between languages and that models trained in one language may struggle to accurately interpret translated inputs due to imperfect internal knowledge representation, suggesting that native-language training remains important for reliable outcomes. In educational and informational contexts, even small performance gaps may compound inequality. Future research should focus on addressing broader dataset development for underrepresented languages and renewed attention to multilingual model evaluation, ensuring the reinforcing effect of global AI deployment on existing digital divides is reduced.</li>
</ul>

<h3>Title: Advancing SLM Tool-Use Capability using Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Dhruvi Paprunia, Vansh Kharidia, Pankti Doshi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04518">https://arxiv.org/abs/2509.04518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04518">https://arxiv.org/pdf/2509.04518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04518]] Advancing SLM Tool-Use Capability using Reinforcement Learning(https://arxiv.org/abs/2509.04518)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have progressed beyond simple text creation, and tool use has become increasingly important for complex, real-world tasks. Tool use in LLMs refers to their ability to utilize external resources such as APIs, databases, or software functions to extend their functionality beyond generating this http URL are used for tasks such as performing calculations, making API calls to retrieve the current time and date, and more. This capability enables models to fetch real-time data, execute commands, or solve problems requiring dynamic interaction, making it indispensable for applications like AI agents in virtual assistants, robotic control, or automated workflows. However, while LLMs are usually adept tool use, their vast resource requirements and computation complexity restrict their use in every use this http URL a result, there is an increasing need for more compact and efficient Small Language Models (SLMs). Small language models (SLMs) struggle in tool use compared to large language models (LLMs). As soon in Table 1. SLMs are typically trained on smaller, more specific datasets, resulting in a narrower knowledge base and limited contextual understanding compared to LLMs. This research addresses these challenges by using Reinforcement Learning (RL), specifically Group Relative Policy Optimization (GRPO), to enhance tool-use proficiency in SLMs. Unlike conventional fine-tuning approaches that require heavy computation and often lack adaptability, our method provides an efficient, effective solution that significantly boosts SLM tool-use accuracy, increasing their practical utility.</li>
</ul>

<h3>Title: Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease</h3>
<ul>
<li><strong>Authors: </strong>Zvi Badash, Hadas Ben-Atya, Naama Gavrielov, Liam Hazan, Gili Focht, Ruth Cytter-Kuint, Talar Hagopian, Dan Turner, Moti Freiman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04519">https://arxiv.org/abs/2509.04519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04519">https://arxiv.org/pdf/2509.04519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04519]] Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease(https://arxiv.org/abs/2509.04519)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Extracting structured clinical information from radiology reports is challenging, especially in low-resource languages. This is pronounced in Crohn's disease, with sparsely represented multi-organ findings. We developed Hierarchical Structured Matching Prediction BERT (HSMP-BERT), a prompt-based model for extraction from Hebrew radiology text. In an administrative database study, we analyzed 9,683 reports from Crohn's patients imaged 2010-2023 across Israeli providers. A subset of 512 reports was radiologist-annotated for findings across six gastrointestinal organs and 15 pathologies, yielding 90 structured labels per subject. Multilabel-stratified split (66% train+validation; 33% test), preserving label prevalence. Performance was evaluated with accuracy, F1, Cohen's $\kappa$, AUC, PPV, NPV, and recall. On 24 organ-finding combinations with $>$15 positives, HSMP-BERT achieved mean F1 0.83$\pm$0.08 and $\kappa$ 0.65$\pm$0.17, outperforming the SMP zero-shot baseline (F1 0.49$\pm$0.07, $\kappa$ 0.06$\pm$0.07) and standard fine-tuning (F1 0.30$\pm$0.27, $\kappa$ 0.27$\pm$0.34; paired t-test $p < 10^{-7}$). Hierarchical inference cuts runtime 5.1$\times$ vs. traditional inference. Applied to all reports, it revealed associations among ileal wall thickening, stenosis, and pre-stenotic dilatation, plus age- and sex-specific trends in inflammatory findings. HSMP-BERT offers a scalable solution for structured extraction in radiology, enabling population-level analysis of Crohn's disease and demonstrating AI's potential in low-resource settings.</li>
</ul>

<h3>Title: Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia</h3>
<ul>
<li><strong>Authors: </strong>David Anderson, Galia Benitez, Margret Bjarnadottir, Shriyan Reyya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04523">https://arxiv.org/abs/2509.04523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04523">https://arxiv.org/pdf/2509.04523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04523]] Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia(https://arxiv.org/abs/2509.04523)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Colombia has been submerged in decades of armed conflict, yet until recently, the systematic documentation of violence was not a priority for the Colombian government. This has resulted in a lack of publicly available conflict information and, consequently, a lack of historical accounts. This study contributes to Colombia's historical memory by utilizing GPT, a large language model (LLM), to read and answer questions about over 200,000 violence-related newspaper articles in Spanish. We use the resulting dataset to conduct both descriptive analysis and a study of the relationship between violence and the eradication of coca crops, offering an example of policy analyses that such data can support. Our study demonstrates how LLMs have opened new research opportunities by enabling examinations of large text corpora at a previously infeasible depth.</li>
</ul>

<h3>Title: Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Zaifu Zhan, Shuang Zhou, Min Zeng, Kai Yu, Meijia Song, Xiaoyi Chen, Jun Wang, Yu Hou, Rui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04534">https://arxiv.org/abs/2509.04534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04534">https://arxiv.org/pdf/2509.04534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04534]] Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation(https://arxiv.org/abs/2509.04534)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated remarkable capabilities in biomedical natural language processing, yet their rapid growth in size and computational requirements present a major barrier to adoption in healthcare settings where data privacy precludes cloud deployment and resources are limited. In this study, we systematically evaluated the impact of quantization on 12 state-of-the-art large language models, including both general-purpose and biomedical-specific models, across eight benchmark datasets covering four key tasks: named entity recognition, relation extraction, multi-label classification, and question answering. We show that quantization substantially reduces GPU memory requirements-by up to 75%-while preserving model performance across diverse tasks, enabling the deployment of 70B-parameter models on 40GB consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness to advanced prompting methods are largely maintained. These findings provide significant practical and guiding value, highlighting quantization as a practical and effective strategy for enabling the secure, local deployment of large yet high-capacity language models in biomedical contexts, bridging the gap between technical advances in AI and real-world clinical translation.</li>
</ul>

<h3>Title: PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting</h3>
<ul>
<li><strong>Authors: </strong>Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Jiale Tao, Qixun Wang, Ruihuang Li, Xin Li, Mingrui Wu, Xinchi Deng, Chunyu Wang, Qinglin Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04545">https://arxiv.org/abs/2509.04545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04545">https://arxiv.org/pdf/2509.04545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04545]] PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting(https://arxiv.org/abs/2509.04545)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in text-to-image (T2I) diffusion models have demonstrated remarkable capabilities in generating high-fidelity images. However, these models often struggle to faithfully render complex user prompts, particularly in aspects like attribute binding, negation, and compositional relationships. This leads to a significant mismatch between user intent and the generated output. To address this challenge, we introduce PromptEnhancer, a novel and universal prompt rewriting framework that enhances any pretrained T2I model without requiring modifications to its weights. Unlike prior methods that rely on model-specific fine-tuning or implicit reward signals like image-reward scores, our framework decouples the rewriter from the generator. We achieve this by training a Chain-of-Thought (CoT) rewriter through reinforcement learning, guided by a dedicated reward model we term the AlignEvaluator. The AlignEvaluator is trained to provide explicit and fine-grained feedback based on a systematic taxonomy of 24 key points, which are derived from a comprehensive analysis of common T2I failure modes. By optimizing the CoT rewriter to maximize the reward from our AlignEvaluator, our framework learns to generate prompts that are more precisely interpreted by T2I models. Extensive experiments on the HunyuanImage 2.1 model demonstrate that PromptEnhancer significantly improves image-text alignment across a wide range of semantic and compositional challenges. Furthermore, we introduce a new, high-quality human preference benchmark to facilitate future research in this direction.</li>
</ul>

<h3>Title: Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions</h3>
<ul>
<li><strong>Authors: </strong>Faruk Alpay, Taylan Alpay</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04549">https://arxiv.org/abs/2509.04549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04549">https://arxiv.org/pdf/2509.04549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04549]] Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions(https://arxiv.org/abs/2509.04549)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based language models excel in NLP tasks, but fine-grained control remains challenging. This paper explores methods for manipulating transformer models through principled interventions at three levels: prompts, activations, and weights. We formalize controllable text generation as an optimization problem addressable via prompt engineering, parameter-efficient fine-tuning, model editing, and reinforcement learning. We introduce a unified framework encompassing prompt-level steering, activation interventions, and weight-space edits. We analyze robustness and safety implications, including adversarial attacks and alignment mitigations. Theoretically, we show minimal weight updates can achieve targeted behavior changes with limited side-effects. Empirically, we demonstrate >90% success in sentiment control and factual edits while preserving base performance, though generalization-specificity trade-offs exist. We discuss ethical dual-use risks and the need for rigorous evaluation. This work lays groundwork for designing controllable and robust language models.</li>
</ul>

<h3>Title: Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping</h3>
<ul>
<li><strong>Authors: </strong>Jingyi Lu, Kai Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04582">https://arxiv.org/abs/2509.04582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04582">https://arxiv.org/pdf/2509.04582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04582]] Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping(https://arxiv.org/abs/2509.04582)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Drag-based image editing has emerged as a powerful paradigm for intuitive image manipulation. However, existing approaches predominantly rely on manipulating the latent space of generative models, leading to limited precision, delayed feedback, and model-specific constraints. Accordingly, we present Inpaint4Drag, a novel framework that decomposes drag-based editing into pixel-space bidirectional warping and image inpainting. Inspired by elastic object deformation in the physical world, we treat image regions as deformable materials that maintain natural shape under user manipulation. Our method achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at 512x512 resolution, significantly improving the interaction experience compared to existing methods that require minutes per edit. By transforming drag inputs directly into standard inpainting formats, our approach serves as a universal adapter for any inpainting model without architecture modification, automatically inheriting all future improvements in inpainting technology. Extensive experiments demonstrate that our method achieves superior visual quality and precise control while maintaining real-time performance. Project page: this https URL</li>
</ul>

<h3>Title: Toward Faithfulness-guided Ensemble Interpretation of Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Siyu Zhang, Kenneth Mcmillan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04588">https://arxiv.org/abs/2509.04588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04588">https://arxiv.org/pdf/2509.04588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04588]] Toward Faithfulness-guided Ensemble Interpretation of Neural Network(https://arxiv.org/abs/2509.04588)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Interpretable and faithful explanations for specific neural inferences are crucial for understanding and evaluating model behavior. Our work introduces \textbf{F}aithfulness-guided \textbf{E}nsemble \textbf{I}nterpretation (\textbf{FEI}), an innovative framework that enhances the breadth and effectiveness of faithfulness, advancing interpretability by providing superior visualization. Through an analysis of existing evaluation benchmarks, \textbf{FEI} employs a smooth approximation to elevate quantitative faithfulness scores. Diverse variations of \textbf{FEI} target enhanced faithfulness in hidden layer encodings, expanding interpretability. Additionally, we propose a novel qualitative metric that assesses hidden layer faithfulness. In extensive experiments, \textbf{FEI} surpasses existing methods, demonstrating substantial advances in qualitative visualization and quantitative faithfulness scores. Our research establishes a comprehensive framework for elevating faithfulness in neural network explanations, emphasizing both breadth and precision</li>
</ul>

<h3>Title: DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Jin Ma, Mohammed Aldeen, Christopher Salas, Feng Luo, Mashrur Chowdhury, Mert Pes√©, Long Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04597">https://arxiv.org/abs/2509.04597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04597">https://arxiv.org/pdf/2509.04597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04597]] DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models(https://arxiv.org/abs/2509.04597)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Object detection is fundamental to various real-world applications, such as security monitoring and surveillance video analysis. Despite their advancements, state-of-theart object detectors are still vulnerable to adversarial patch attacks, which can be easily applied to real-world objects to either conceal actual items or create non-existent ones, leading to severe consequences. Given the current diversity of adversarial patch attacks and potential unknown threats, an ideal defense method should be effective, generalizable, and robust against adaptive attacks. In this work, we introduce DISPATCH, the first diffusion-based defense framework for object detection. Unlike previous works that aim to "detect and remove" adversarial patches, DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative models to disarm attack effects while preserving the integrity of the input image. Specifically, we utilize the in-distribution generative power of diffusion models to regenerate the entire image, aligning it with benign data. A rectification process is then employed to identify and replace adversarial regions with their regenerated benign counterparts. DISPATCH is attack-agnostic and requires no prior knowledge of the existing patches. Extensive experiments across multiple detectors and attacks demonstrate that DISPATCH consistently outperforms state-of-the-art defenses on both hiding attacks and creating attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and lowering the attack success rate to 24.8% on untargeted creating attacks. Moreover, it maintains strong robustness against adaptive attacks, making it a practical and reliable defense for object detection systems.</li>
</ul>

<h3>Title: Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm Recognition -- Multimodal Fusion, Challenges, and Future Prospects</h3>
<ul>
<li><strong>Authors: </strong>Xiyuan Gao, Shekhar Nayak, Matt Coler</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04605">https://arxiv.org/abs/2509.04605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04605">https://arxiv.org/pdf/2509.04605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04605]] Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm Recognition -- Multimodal Fusion, Challenges, and Future Prospects(https://arxiv.org/abs/2509.04605)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Sarcasm, a common feature of human communication, poses challenges in interpersonal interactions and human-machine interactions. Linguistic research has highlighted the importance of prosodic cues, such as variations in pitch, speaking rate, and intonation, in conveying sarcastic intent. Although previous work has focused on text-based sarcasm detection, the role of speech data in recognizing sarcasm has been underexplored. Recent advancements in speech technology emphasize the growing importance of leveraging speech data for automatic sarcasm recognition, which can enhance social interactions for individuals with neurodegenerative conditions and improve machine understanding of complex human language use, leading to more nuanced interactions. This systematic review is the first to focus on speech-based sarcasm recognition, charting the evolution from unimodal to multimodal approaches. It covers datasets, feature extraction, and classification methods, and aims to bridge gaps across diverse research domains. The findings include limitations in datasets for sarcasm recognition in speech, the evolution of feature extraction techniques from traditional acoustic features to deep learning-based representations, and the progression of classification methods from unimodal approaches to multimodal fusion techniques. In so doing, we identify the need for greater emphasis on cross-cultural and multilingual sarcasm recognition, as well as the importance of addressing sarcasm as a multimodal phenomenon, rather than a text-based challenge.</li>
</ul>

<h3>Title: Sample-efficient Integration of New Modalities into Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Osman Batur ƒ∞nce, Andr√© F. T. Martins, Oisin Mac Aodha, Edoardo M. Ponti</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04606">https://arxiv.org/abs/2509.04606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04606">https://arxiv.org/pdf/2509.04606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04606]] Sample-efficient Integration of New Modalities into Large Language Models(https://arxiv.org/abs/2509.04606)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal foundation models can process several modalities. However, since the space of possible modalities is large and evolving over time, training a model from scratch to encompass all modalities is unfeasible. Moreover, integrating a modality into a pre-existing foundation model currently requires a significant amount of paired data, which is often not available for low-resource modalities. In this paper, we introduce a method for sample-efficient modality integration (SEMI) into Large Language Models (LLMs). To this end, we devise a hypernetwork that can adapt a shared projector -- placed between modality-specific encoders and an LLM -- to any modality. The hypernetwork, trained on high-resource modalities (i.e., text, speech, audio, video), is conditioned on a few samples from any arbitrary modality at inference time to generate a suitable adapter. To increase the diversity of training modalities, we artificially multiply the number of encoders through isometric transformations. We find that SEMI achieves a significant boost in sample efficiency during few-shot integration of new modalities (i.e., satellite images, astronomical images, inertial measurements, and molecules) with encoders of arbitrary embedding dimensionality. For instance, to reach the same accuracy as 32-shot SEMI, training the projector from scratch needs 64$\times$ more data. As a result, SEMI holds promise to extend the modality coverage of foundation models.</li>
</ul>

<h3>Title: Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs</h3>
<ul>
<li><strong>Authors: </strong>Brennen Hill, Surendra Parla, Venkata Abhijeeth Balabhadruni, Atharv Prajod Padmalayam, Sujay Chandra Shekara Sharma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04615">https://arxiv.org/abs/2509.04615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04615">https://arxiv.org/pdf/2509.04615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04615]] Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs(https://arxiv.org/abs/2509.04615)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of Large Language Models (LLMs) has introduced critical security challenges, where adversarial actors can manipulate input prompts to cause significant harm and circumvent safety alignments. These prompt-based attacks exploit vulnerabilities in a model's design, training, and contextual understanding, leading to intellectual property theft, misinformation generation, and erosion of user trust. A systematic understanding of these attack vectors is the foundational step toward developing robust countermeasures. This paper presents a comprehensive literature survey of prompt-based attack methodologies, categorizing them to provide a clear threat model. By detailing the mechanisms and impacts of these exploits, this survey aims to inform the research community's efforts in building the next generation of secure LLMs that are inherently resistant to unauthorized distillation, fine-tuning, and editing.</li>
</ul>

<h3>Title: Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families</h3>
<ul>
<li><strong>Authors: </strong>Jialin Wu, Shreya Saha, Yiqing Bo, Meenakshi Khosla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04622">https://arxiv.org/abs/2509.04622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04622">https://arxiv.org/pdf/2509.04622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04622]] Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families(https://arxiv.org/abs/2509.04622)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Representational similarity metrics are fundamental tools in neuroscience and AI, yet we lack systematic comparisons of their discriminative power across model families. We introduce a quantitative framework to evaluate representational similarity measures based on their ability to separate model families-across architectures (CNNs, Vision Transformers, Swin Transformers, ConvNeXt) and training regimes (supervised vs. self-supervised). Using three complementary separability measures-dprime from signal detection theory, silhouette coefficients and ROC-AUC, we systematically assess the discriminative capacity of commonly used metrics including RSA, linear predictivity, Procrustes, and soft matching. We show that separability systematically increases as metrics impose more stringent alignment constraints. Among mapping-based approaches, soft-matching achieves the highest separability, followed by Procrustes alignment and linear predictivity. Non-fitting methods such as RSA also yield strong separability across families. These results provide the first systematic comparison of similarity metrics through a separability lens, clarifying their relative sensitivity and guiding metric choice for large-scale model and brain comparisons.</li>
</ul>

<h3>Title: UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ali Khanpour, Tianyi Wang, Afra Vahidi-Shams, Wim Ectors, Farzam Nakhaie, Amirhossein Taheri, Christian Claudel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.ET, cs.RO, eess.IV, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04624">https://arxiv.org/abs/2509.04624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04624">https://arxiv.org/pdf/2509.04624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04624]] UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis(https://arxiv.org/abs/2509.04624)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traffic congestion and violations pose significant challenges for urban mobility and road safety. Traditional traffic monitoring systems, such as fixed cameras and sensor-based methods, are often constrained by limited coverage, low adaptability, and poor scalability. To address these challenges, this paper introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance system capable of accurate vehicle detection, classification, tracking, and behavioral analysis in real-world, unconstrained urban environments. The system leverages multi-scale and multi-angle template matching, Kalman filtering, and homography-based calibration to process aerial video data collected from altitudes of approximately 200 meters. A case study in urban area demonstrates robust performance, achieving a detection precision of 91.8%, an F1-score of 90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively. Beyond precise detection, the system classifies five vehicle types and automatically detects critical traffic violations, including unsafe lane changes, illegal double parking, and crosswalk obstructions, through the fusion of geofencing, motion filtering, and trajectory deviation analysis. The integrated analytics module supports origin-destination tracking, vehicle count visualization, inter-class correlation analysis, and heatmap-based congestion modeling. Additionally, the system enables entry-exit trajectory profiling, vehicle density estimation across road segments, and movement direction logging, supporting comprehensive multi-scale urban mobility analytics. Experimental results confirms the system's scalability, accuracy, and practical relevance, highlighting its potential as an enforcement-aware, infrastructure-independent traffic monitoring solution for next-generation smart cities.</li>
</ul>

<h3>Title: Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety</h3>
<ul>
<li><strong>Authors: </strong>Sharif Noor Zisad, Ragib Hasan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04650">https://arxiv.org/abs/2509.04650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04650">https://arxiv.org/pdf/2509.04650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04650]] Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety(https://arxiv.org/abs/2509.04650)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text.</li>
</ul>

<h3>Title: Interpreting Transformer Architectures as Implicit Multinomial Regression</h3>
<ul>
<li><strong>Authors: </strong>Jonas A. Actor, Anthony Gruber, Eric C. Cyr</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04653">https://arxiv.org/abs/2509.04653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04653">https://arxiv.org/pdf/2509.04653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04653]] Interpreting Transformer Architectures as Implicit Multinomial Regression(https://arxiv.org/abs/2509.04653)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Mechanistic interpretability aims to understand how internal components of modern machine learning models, such as weights, activations, and layers, give rise to the model's overall behavior. One particularly opaque mechanism is attention: despite its central role in transformer models, its mathematical underpinnings and relationship to concepts like feature polysemanticity, superposition, and model performance remain poorly understood. This paper establishes a novel connection between attention mechanisms and multinomial regression. Specifically, we show that in a fixed multinomial regression setting, optimizing over latent features yields optimal solutions that align with the dynamics induced by attention blocks. In other words, the evolution of representations through a transformer can be interpreted as a trajectory that recovers the optimal features for classification.</li>
</ul>

<h3>Title: Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ayush Gupta, Ramneet Kaur, Anirban Roy, Adam D. Cobb, Rama Chellappa, Susmit Jha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04655">https://arxiv.org/abs/2509.04655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04655">https://arxiv.org/pdf/2509.04655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04655]] Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs(https://arxiv.org/abs/2509.04655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose a novel inference-time out-of-domain (OOD) detection algorithm for specialized large language models (LLMs). Despite achieving state-of-the-art performance on in-domain tasks through fine-tuning, specialized LLMs remain vulnerable to incorrect or unreliable outputs when presented with OOD inputs, posing risks in critical applications. Our method leverages the Inductive Conformal Anomaly Detection (ICAD) framework, using a new non-conformity measure based on the model's dropout tolerance. Motivated by recent findings on polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs exhibit higher dropout tolerance than OOD inputs. We aggregate dropout tolerance across multiple layers via a valid ensemble approach, improving detection while maintaining theoretical false alarm bounds from ICAD. Experiments with medical-specialized LLMs show that our approach detects OOD inputs better than baseline methods, with AUROC improvements of $2\%$ to $37\%$ when treating OOD datapoints as positives and in-domain test datapoints as negatives.</li>
</ul>

<h3>Title: AraHalluEval: A Fine-grained Hallucination Evaluation Framework for Arabic LLMs</h3>
<ul>
<li><strong>Authors: </strong>Aisha Alansari, Hamzah Luqman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04656">https://arxiv.org/abs/2509.04656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04656">https://arxiv.org/pdf/2509.04656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04656]] AraHalluEval: A Fine-grained Hallucination Evaluation Framework for Arabic LLMs(https://arxiv.org/abs/2509.04656)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recently, extensive research on the hallucination of the large language models (LLMs) has mainly focused on the English language. Despite the growing number of multilingual and Arabic-specific LLMs, evaluating LLMs' hallucination in the Arabic context remains relatively underexplored. The knowledge gap is particularly pressing given Arabic's widespread use across many regions and its importance in global communication and media. This paper presents the first comprehensive hallucination evaluation of Arabic and multilingual LLMs on two critical Arabic natural language generation tasks: generative question answering (GQA) and summarization. This study evaluates a total of 12 LLMs, including 4 Arabic pre-trained models, 4 multilingual models, and 4 reasoning-based models. To assess the factual consistency and faithfulness of LLMs' outputs, we developed a fine-grained hallucination evaluation framework consisting of 12 fine-grained hallucination indicators that represent the varying characteristics of each task. The results reveal that factual hallucinations are more prevalent than faithfulness errors across all models and tasks. Notably, the Arabic pre-trained model Allam consistently demonstrates lower hallucination rates than multilingual models and a comparative performance with reasoning-based models. The code is available at: \href{this https URL}{Github link}.</li>
</ul>

<h3>Title: Evaluating NL2SQL via SQL2NL</h3>
<ul>
<li><strong>Authors: </strong>Mohammadtaher Safarzadeh, Afshin Oroojlooyjadid, Dan Roth</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04657">https://arxiv.org/abs/2509.04657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04657">https://arxiv.org/pdf/2509.04657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04657]] Evaluating NL2SQL via SQL2NL(https://arxiv.org/abs/2509.04657)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust evaluation in the presence of linguistic variation is key to understanding the generalization capabilities of Natural Language to SQL (NL2SQL) models, yet existing benchmarks rarely address this factor in a systematic or controlled manner. We propose a novel schema-aligned paraphrasing framework that leverages SQL-to-NL (SQL2NL) to automatically generate semantically equivalent, lexically diverse queries while maintaining alignment with the original schema and intent. This enables the first targeted evaluation of NL2SQL robustness to linguistic variation in isolation-distinct from prior work that primarily investigates ambiguity or schema perturbations. Our analysis reveals that state-of-the-art models are far more brittle than standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries, while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to 42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We also find that robustness degradation varies significantly with query complexity, dataset, and domain -- highlighting the need for evaluation frameworks that explicitly measure linguistic generalization to ensure reliable performance in real-world settings.</li>
</ul>

<h3>Title: Why Language Models Hallucinate</h3>
<ul>
<li><strong>Authors: </strong>Adam Tauman Kalai, Ofir Nachum, Santosh S. Vempala, Edwin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04664">https://arxiv.org/abs/2509.04664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04664">https://arxiv.org/pdf/2509.04664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04664]] Why Language Models Hallucinate(https://arxiv.org/abs/2509.04664)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such "hallucinations" persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious -- they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded -- language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This "epidemic" of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems.</li>
</ul>

<h3>Title: Beyond Ordinary Lipschitz Constraints: Differentially Private Stochastic Optimization with Tsybakov Noise Condition</h3>
<ul>
<li><strong>Authors: </strong>Difei Xu, Meng Ding, Zihang Xiang, Jinhui Xu, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04668">https://arxiv.org/abs/2509.04668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04668">https://arxiv.org/pdf/2509.04668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04668]] Beyond Ordinary Lipschitz Constraints: Differentially Private Stochastic Optimization with Tsybakov Noise Condition(https://arxiv.org/abs/2509.04668)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We study Stochastic Convex Optimization in the Differential Privacy model (DP-SCO). Unlike previous studies, here we assume the population risk function satisfies the Tsybakov Noise Condition (TNC) with some parameter $\theta>1$, where the Lipschitz constant of the loss could be extremely large or even unbounded, but the $\ell_2$-norm gradient of the loss has bounded $k$-th moment with $k\geq 2$. For the Lipschitz case with $\theta\geq 2$, we first propose an $(\varepsilon, \delta)$-DP algorithm whose utility bound is $\Tilde{O}\left(\left(\tilde{r}_{2k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$ in high probability, where $n$ is the sample size, $d$ is the model dimension, and $\tilde{r}_{2k}$ is a term that only depends on the $2k$-th moment of the gradient. It is notable that such an upper bound is independent of the Lipschitz constant. We then extend to the case where $\theta\geq \bar{\theta}> 1$ for some known constant $\bar{\theta}$. Moreover, when the privacy budget $\varepsilon$ is small enough, we show an upper bound of $\tilde{O}\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$ even if the loss function is not Lipschitz. For the lower bound, we show that for any $\theta\geq 2$, the private minimax rate for $\rho$-zero Concentrated Differential Privacy is lower bounded by $\Omega\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\sqrt{\rho}}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$.</li>
</ul>

<h3>Title: VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation</h3>
<ul>
<li><strong>Authors: </strong>Mustafa Munir, Alex Zhang, Radu Marculescu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04669">https://arxiv.org/abs/2509.04669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04669">https://arxiv.org/pdf/2509.04669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04669]] VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation(https://arxiv.org/abs/2509.04669)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs) have challenged the dominance of Convolutional Neural Networks (CNNs) in computer vision. ViTs excel at capturing global context, and SSMs like Mamba offer linear complexity for long sequences, yet they do not capture fine-grained local features as effectively as CNNs. Conversely, CNNs possess strong inductive biases for local features but lack the global reasoning capabilities of transformers and Mamba. To bridge this gap, we introduce \textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a hierarchical structure with convolutional blocks in its early stages to extract rich local features. These convolutional blocks are then processed by later stages incorporating multi-directional Mamba blocks designed to efficiently model long-range dependencies and global context. This hybrid design allows for superior feature representation while maintaining linear complexity with respect to image resolution. We demonstrate VCMamba's effectiveness through extensive experiments on ImageNet-1K classification and ADE20K semantic segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K, surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains 47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing 62% fewer parameters. Code is available at this https URL.</li>
</ul>

<h3>Title: Guideline-Consistent Segmentation via Multi-Agent Refinement</h3>
<ul>
<li><strong>Authors: </strong>Vanshika Vats, Ashwani Rathee, James Davis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04687">https://arxiv.org/abs/2509.04687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04687">https://arxiv.org/pdf/2509.04687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04687]] Guideline-Consistent Segmentation via Multi-Agent Refinement(https://arxiv.org/abs/2509.04687)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation in real-world applications often requires not only accurate masks but also strict adherence to textual labeling guidelines. These guidelines are typically complex and long, and both human and automated labeling often fail to follow them faithfully. Traditional approaches depend on expensive task-specific retraining that must be repeated as the guidelines evolve. Although recent open-vocabulary segmentation methods excel with simple prompts, they often fail when confronted with sets of paragraph-length guidelines that specify intricate segmentation rules. To address this, we introduce a multi-agent, training-free framework that coordinates general-purpose vision-language models within an iterative Worker-Supervisor refinement architecture. The Worker performs the segmentation, the Supervisor critiques it against the retrieved guidelines, and a lightweight reinforcement learning stop policy decides when to terminate the loop, ensuring guideline-consistent masks while balancing resource use. Evaluated on the Waymo and ReasonSeg datasets, our method notably outperforms state-of-the-art baselines, demonstrating strong generalization and instruction adherence.</li>
</ul>

<h3>Title: ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Samira Khorshidi, Azadeh Nikfarjam, Suprita Shankar, Yisi Sang, Yash Govind, Hyun Jang, Ali Kasgari, Alexis McClimans, Mohamed Soliman, Vishnu Konda, Ahmed Fakhry, Xiaoguang Qi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04696">https://arxiv.org/abs/2509.04696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04696">https://arxiv.org/pdf/2509.04696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04696]] ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs(https://arxiv.org/abs/2509.04696)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Knowledge graphs (KGs) are foundational to many AI applications, but maintaining their freshness and completeness remains costly. We present ODKE+, a production-grade system that automatically extracts and ingests millions of open-domain facts from web sources with high precision. ODKE+ combines modular components into a scalable pipeline: (1) the Extraction Initiator detects missing or stale facts, (2) the Evidence Retriever collects supporting documents, (3) hybrid Knowledge Extractors apply both pattern-based rules and ontology-guided prompting for large language models (LLMs), (4) a lightweight Grounder validates extracted facts using a second LLM, and (5) the Corroborator ranks and normalizes candidate facts for ingestion. ODKE+ dynamically generates ontology snippets tailored to each entity type to align extractions with schema constraints, enabling scalable, type-consistent fact extraction across 195 predicates. The system supports batch and streaming modes, processing over 9 million Wikipedia pages and ingesting 19 million high-confidence facts with 98.8% precision. ODKE+ significantly improves coverage over traditional methods, achieving up to 48% overlap with third-party KGs and reducing update lag by 50 days on average. Our deployment demonstrates that LLM-based extraction, grounded in ontological structure and verification workflows, can deliver trustworthiness, production-scale knowledge ingestion with broad real-world applicability. A recording of the system demonstration is included with the submission and is also available at this https URL.</li>
</ul>

<h3>Title: Network-Aware Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Zhou Li, Yu Zheng, Tianhao Wang, Sang-Woo Jun</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04710">https://arxiv.org/abs/2509.04710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04710">https://arxiv.org/pdf/2509.04710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04710]] Network-Aware Differential Privacy(https://arxiv.org/abs/2509.04710)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Differential privacy (DP) is a privacy-enhancement technology (PET) that receives prominent attention from the academia, industry, and government. One main development over the past decade has been the decentralization of DP, including local DP and shuffle DP. Despite that decentralized DP heavily relies on network communications for data collection,we found that: 1) no systematic study has surveyed the research opportunities at the intersection of networking and DP; 2) nor have there been significant efforts to develop DP mechanisms that are explicitly tailored for network environments. In this paper, we seek to address this gap by initiating a new direction of network-aware DP. We identified two focus areas where the network research can offer substantive contributions to the design and deployment of DP, related to network security and topology. Through this work, we hope to encourage more research that adapt/optimize DP's deployment in various network environments.</li>
</ul>

<h3>Title: Domain Adaptation for Different Sensor Configurations in 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Satoshi Tanaka, Kok Seang Tan, Isamu Yamashita</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04711">https://arxiv.org/abs/2509.04711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04711">https://arxiv.org/pdf/2509.04711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04711]] Domain Adaptation for Different Sensor Configurations in 3D Object Detection(https://arxiv.org/abs/2509.04711)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in autonomous driving have underscored the importance of accurate 3D object detection, with LiDAR playing a central role due to its robustness under diverse visibility conditions. However, different vehicle platforms often deploy distinct sensor configurations, causing performance degradation when models trained on one configuration are applied to another because of shifts in the point cloud distribution. Prior work on multi-dataset training and domain adaptation for 3D object detection has largely addressed environmental domain gaps and density variation within a single LiDAR; in contrast, the domain gap for different sensor configurations remains largely unexplored. In this work, we address domain adaptation across different sensor configurations in 3D object detection. We propose two techniques: Downstream Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and Partial Layer Fine-tuning (updating only a subset of layers to improve cross-configuration generalization). Using paired datasets collected in the same geographic region with multiple sensor configurations, we show that joint training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently outperforms naive joint training for each configuration. Our findings provide a practical and scalable solution for adapting 3D object detection models to the diverse vehicle platforms.</li>
</ul>

<h3>Title: KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Yushi Sun, Kai Sun, Yifan Ethan Xu, Xiao Yang, Xin Luna Dong, Nan Tang, Lei Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04716">https://arxiv.org/abs/2509.04716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04716">https://arxiv.org/pdf/2509.04716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04716]] KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering(https://arxiv.org/abs/2509.04716)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) mitigates hallucination in Large Language Models (LLMs) by incorporating external data, with Knowledge Graphs (KGs) offering crucial information for question answering. Traditional Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing, which typically retrieves knowledge strictly necessary for answer generation, thus often suffer from low coverage due to rigid schema requirements and semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that enhances QA coverage by retrieving a broader subgraph likely to contain relevant information. Our retrieval-filtering-summarization approach, combined with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs, reduces noises and improves QA for both simple and complex questions. Experiments demonstrate that KERAG surpasses state-of-the-art solutions by about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.</li>
</ul>

<h3>Title: Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shengqian Zhu, Jiafei Wu, Xiaogang Xu, Chengrong Yu, Ying Song, Zhang Yi, Guangjun Li, Junjie Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04732">https://arxiv.org/abs/2509.04732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04732">https://arxiv.org/pdf/2509.04732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04732]] Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation(https://arxiv.org/abs/2509.04732)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Versatile medical image segmentation (VMIS) targets the segmentation of multiple classes, while obtaining full annotations for all classes is often impractical due to the time and labor required. Leveraging partially labeled datasets (PLDs) presents a promising alternative; however, current VMIS approaches face significant class imbalance due to the unequal category distribution in PLDs. Existing methods attempt to address this by generating pseudo-full labels. Nevertheless, these typically require additional models and often result in potential performance degradation from label noise. In this work, we introduce a Task Consistency Training (TCT) framework to address class imbalance without requiring extra models. TCT includes a backbone network with a main segmentation head (MSH) for multi-channel predictions and multiple auxiliary task heads (ATHs) for task-specific predictions. By enforcing a consistency constraint between the MSH and ATH predictions, TCT effectively utilizes unlabeled anatomical structures. To avoid error propagation from low-consistency, potentially noisy data, we propose a filtering strategy to exclude such data. Additionally, we introduce a unified auxiliary uncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines caused by the dominance of specific tasks. Extensive experiments on eight abdominal datasets from diverse clinical sites demonstrate our approach's effectiveness.</li>
</ul>

<h3>Title: Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization</h3>
<ul>
<li><strong>Authors: </strong>Dharsan Ravindran, Kevin Wang, Zhuoyuan Cao, Saleh Abdelrahman, Jeffery Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04735">https://arxiv.org/abs/2509.04735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04735">https://arxiv.org/pdf/2509.04735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04735]] Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization(https://arxiv.org/abs/2509.04735)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in vision foundation models, such as the Segment Anything Model (SAM) and its successor SAM2, have achieved state-of-the-art performance on general image segmentation benchmarks. However, these models struggle in adverse weather conditions where visual ambiguity is high, largely due to their lack of uncertainty quantification. Inspired by progress in medical imaging, where uncertainty-aware training has improved reliability in ambiguous cases, we investigate two approaches to enhance segmentation robustness for autonomous driving. First, we introduce a multi-step finetuning procedure for SAM2 that incorporates uncertainty metrics directly into the loss function, improving overall scene recognition. Second, we adapt the Uncertainty-Aware Adapter (UAT), originally designed for medical image segmentation, to driving contexts. We evaluate both methods on CamVid, BDD100K, and GTA driving datasets. Experiments show that UAT-SAM outperforms standard SAM in extreme weather, while SAM2 with uncertainty-aware loss achieves improved performance across diverse driving scenes. These findings underscore the value of explicit uncertainty modeling for safety-critical autonomous driving in challenging environments.</li>
</ul>

<h3>Title: WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches</h3>
<ul>
<li><strong>Authors: </strong>Taeyoung Yeon, Vasco Xu, Henry Hoffmann, Karan Ahuja</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04736">https://arxiv.org/abs/2509.04736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04736">https://arxiv.org/pdf/2509.04736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04736]] WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches(https://arxiv.org/abs/2509.04736)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Despite advances in practical and multimodal fine-grained Human Activity Recognition (HAR), a system that runs entirely on smartwatches in unconstrained environments remains elusive. We present WatchHAR, an audio and inertial-based HAR system that operates fully on smartwatches, addressing privacy and latency issues associated with external data processing. By optimizing each component of the pipeline, WatchHAR achieves compounding performance gains. We introduce a novel architecture that unifies sensor data preprocessing and inference into an end-to-end trainable module, achieving 5x faster processing while maintaining over 90% accuracy across more than 25 activity classes. WatchHAR outperforms state-of-the-art models for event detection and activity classification while running directly on the smartwatch, achieving 9.3 ms processing time for activity event detection and 11.8 ms for multimodal activity classification. This research advances on-device activity recognition, realizing smartwatches' potential as standalone, privacy-aware, and minimally-invasive continuous activity tracking devices.</li>
</ul>

<h3>Title: A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Cheng Peng, Xinyu Dong, Mengxian Lyu, Daniel Paredes, Yaoyun Zhang, Yonghui Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04753">https://arxiv.org/abs/2509.04753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04753">https://arxiv.org/pdf/2509.04753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04753]] A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning(https://arxiv.org/abs/2509.04753)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Natural language processing (NLP) is a key technology to extract important patient information from clinical narratives to support healthcare applications. The rapid development of large language models (LLMs) has revolutionized many NLP tasks in the clinical domain, yet their optimal use in patient information extraction tasks requires further exploration. This study examines LLMs' effectiveness in patient information extraction, focusing on LLM architectures, fine-tuning strategies, and multi-task instruction tuning techniques for developing robust and generalizable patient information extraction systems. This study aims to explore key concepts of using LLMs for clinical concept and relation extraction tasks, including: (1) encoder-only or decoder-only LLMs, (2) prompt-based parameter-efficient fine-tuning (PEFT) algorithms, and (3) multi-task instruction tuning on few-shot learning performance. We benchmarked a suite of LLMs, including encoder-based LLMs (BERT, GatorTron) and decoder-based LLMs (GatorTronGPT, Llama 3.1, GatorTronLlama), across five datasets. We compared traditional full-size fine-tuning and prompt-based PEFT. We explored a multi-task instruction tuning framework that combines both tasks across four datasets to evaluate the zero-shot and few-shot learning performance using the leave-one-dataset-out strategy.</li>
</ul>

<h3>Title: MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery</h3>
<ul>
<li><strong>Authors: </strong>Zhangding Liu, Neda Mohammadi, John E. Taylor</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04757">https://arxiv.org/abs/2509.04757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04757">https://arxiv.org/pdf/2509.04757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04757]] MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery(https://arxiv.org/abs/2509.04757)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Rapid and accurate post-hurricane damage assessment is vital for disaster response and recovery. Yet existing CNN-based methods struggle to capture multi-scale spatial features and to distinguish visually similar or co-occurring damage types. To address these issues, we propose MCANet, a multi-label classification framework that learns multi-scale representations and adaptively attends to spatially relevant regions for each damage category. MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context across scales and a multi-head class-specific residual attention module to enhance discrimination. Each attention branch focuses on different spatial granularities, balancing local detail with global context. We evaluate MCANet on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael. MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet, Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads, performance further improves to 92.35%, boosting average precision for challenging classes such as Road Blocked by over 6%. Class activation mapping confirms MCANet's ability to localize damage-relevant regions, supporting interpretability. Outputs from MCANet can inform post-disaster risk mapping, emergency routing, and digital twin-based disaster response. Future work could integrate disaster-specific knowledge graphs and multimodal large language models to improve adaptability to unseen disasters and enrich semantic understanding for real-world decision-making.</li>
</ul>

<h3>Title: Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework</h3>
<ul>
<li><strong>Authors: </strong>Zucheng Liang, Wenxin Wei, Kaijie Zhang, Hongyi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04770">https://arxiv.org/abs/2509.04770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04770">https://arxiv.org/pdf/2509.04770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04770]] Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework(https://arxiv.org/abs/2509.04770)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurately answering complex questions has consistently been a significant challenge for Large Language Models (LLMs). To address this, this paper proposes a multi-hop question decomposition method for complex questions, building upon research within the MQUAKE framework. Utilizing the LLAMA3 model, we systematically investigate the impact of multi-hop question decomposition within knowledge graphs on model comprehension and reasoning accuracy, both before and after model training. In our experiments, we systematically partitioned and converted the MQUAKE-T dataset into two distinct formats: a single-hop dataset designed for directly answering complex questions, and a multi-hop dataset constructed using the multi-hop question decomposition method. We then fine-tuned the LLAMA3 model on these datasets and conducted inference tests. Our results demonstrate that, without fine-tuning the LLM, the prediction performance based on the multi-hop question decomposition method significantly outperforms the method of directly answering complex questions. After fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance of both approaches improved compared to the untrained baseline. Crucially, the method utilizing multi-hop decomposition consistently maintained its superiority. These findings validate the effectiveness of the multi-hop decomposition method both before and after training, demonstrating its capability to effectively enhance the LLM's ability to answer complex questions.</li>
</ul>

<h3>Title: Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data</h3>
<ul>
<li><strong>Authors: </strong>R. Makharia, J. G. Singla, Amitabh, N. Dube, H. Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04775">https://arxiv.org/abs/2509.04775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04775">https://arxiv.org/pdf/2509.04775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04775]] Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data(https://arxiv.org/abs/2509.04775)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate image registration is critical for lunar exploration, enabling surface mapping, resource localization, and mission planning. Aligning data from diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera, Narrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer), and radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya mission) -- is challenging due to differences in resolution, illumination, and sensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT, AKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using cross-modality image pairs from equatorial and polar regions. A preprocessing pipeline is proposed, including georeferencing, resolution alignment, intensity normalization, and enhancements like adaptive histogram equalization, principal component analysis, and shadow correction. SuperGlue consistently yields the lowest root mean square error and fastest runtimes. Classical methods such as SIFT and AKAZE perform well near the equator but degrade under polar lighting. The results highlight the importance of preprocessing and learning-based approaches for robust lunar image registration across diverse conditions.</li>
</ul>

<h3>Title: Decoders Laugh as Loud as Encoders</h3>
<ul>
<li><strong>Authors: </strong>Eli Borodach, Raj Dandekar, Rajat Dandekar, Sreedath Panat</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04779">https://arxiv.org/abs/2509.04779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04779">https://arxiv.org/pdf/2509.04779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04779]] Decoders Laugh as Loud as Encoders(https://arxiv.org/abs/2509.04779)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>From the dawn of the computer, Allen Turing dreamed of a robot that could communicate using language as a human being. The recent advances in the field of Large Language Models (LLMs) shocked the scientific community when a single model can apply for various natural language processing (NLP) tasks, while the output results are sometimes even better than most human communication skills. Models such as GPT, Claude, Grok, etc. have left their mark on the scientific community. However, it is unclear how much these models understand what they produce, especially in a nuanced theme such as humor. The question of whether computers understand humor is still open (among the decoders, the latest to be checked was GPT-2). We addressed this issue in this paper; we have showed that a fine-tuned decoder (GPT-4o) performed (Mean F1-macro score of 0.85) as well as the best fine-tuned encoder (RoBERTa with a Mean of F1-score 0.86)</li>
</ul>

<h3>Title: VARMA-Enhanced Transformer for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Song, Xiaoou Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04782">https://arxiv.org/abs/2509.04782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04782">https://arxiv.org/pdf/2509.04782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04782]] VARMA-Enhanced Transformer for Time Series Forecasting(https://arxiv.org/abs/2509.04782)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based models have significantly advanced time series forecasting. Recent work, like the Cross-Attention-only Time Series transformer (CATS), shows that removing self-attention can make the model more accurate and efficient. However, these streamlined architectures may overlook the fine-grained, local temporal dependencies effectively captured by classical statistical models like Vector AutoRegressive Moving Average model (VARMA). To address this gap, we propose VARMAformer, a novel architecture that synergizes the efficiency of a cross-attention-only framework with the principles of classical time series analysis. Our model introduces two key innovations: (1) a dedicated VARMA-inspired Feature Extractor (VFE) that explicitly models autoregressive (AR) and moving-average (MA) patterns at the patch level, and (2) a VARMA-Enhanced Attention (VE-atten) mechanism that employs a temporal gate to make queries more context-aware. By fusing these classical insights into a modern backbone, VARMAformer captures both global, long-range dependencies and local, statistical structures. Through extensive experiments on widely-used benchmark datasets, we demonstrate that our model consistently outperforms existing state-of-the-art methods. Our work validates the significant benefit of integrating classical statistical insights into modern deep learning frameworks for time series forecasting.</li>
</ul>

<h3>Title: Enhancing Diversity in Large Language Models via Determinantal Point Processes</h3>
<ul>
<li><strong>Authors: </strong>Yilei Chen, Souradip Chakraborty, Lorenz Wolf, Ioannis Ch. Paschalidis, Aldo Pacchiano</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04784">https://arxiv.org/abs/2509.04784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04784">https://arxiv.org/pdf/2509.04784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04784]] Enhancing Diversity in Large Language Models via Determinantal Point Processes(https://arxiv.org/abs/2509.04784)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised fine-tuning and reinforcement learning are two popular methods for post-training large language models (LLMs). While improving the model's performance on downstream tasks, they often reduce the model's output diversity, leading to narrow, canonical responses. Existing methods to enhance diversity are limited, either by operating at inference time or by focusing on lexical differences. We propose a novel training method named DQO based on determinantal point processes (DPPs) to jointly optimize LLMs for quality and semantic diversity. Our approach samples and embeds a group of responses for each prompt, then uses the determinant of a kernel-based similarity matrix to measure diversity as the volume spanned by the embeddings of these responses. Experiments across instruction-following, summarization, story generation, and reasoning tasks demonstrate that our method substantially improves semantic diversity without sacrificing model quality.</li>
</ul>

<h3>Title: Graph Unlearning: Efficient Node Removal in Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Faqian Guan, Tianqing Zhu, Zhoutian Wang, Wei Ren, Wanlei Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04785">https://arxiv.org/abs/2509.04785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04785">https://arxiv.org/pdf/2509.04785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04785]] Graph Unlearning: Efficient Node Removal in Graph Neural Networks(https://arxiv.org/abs/2509.04785)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>With increasing concerns about privacy attacks and potential sensitive information leakage, researchers have actively explored methods to efficiently remove sensitive training data and reduce privacy risks in graph neural network (GNN) models. Node unlearning has emerged as a promising technique for protecting the privacy of sensitive nodes by efficiently removing specific training node information from GNN models. However, existing node unlearning methods either impose restrictions on the GNN structure or do not effectively utilize the graph topology for node unlearning. Some methods even compromise the graph's topology, making it challenging to achieve a satisfactory performance-complexity trade-off. To address these issues and achieve efficient unlearning for training node removal in GNNs, we propose three novel node unlearning methods: Class-based Label Replacement, Topology-guided Neighbor Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among these methods, Topology-guided Neighbor Mean Posterior Probability and Class-consistent Neighbor Node Filtering effectively leverage the topological features of the graph, resulting in more effective node unlearning. To validate the superiority of our proposed methods in node unlearning, we conducted experiments on three benchmark datasets. The evaluation criteria included model utility, unlearning utility, and unlearning efficiency. The experimental results demonstrate the utility and efficiency of the proposed methods and illustrate their superiority compared to state-of-the-art node unlearning methods. Overall, the proposed methods efficiently remove sensitive training nodes and protect the privacy information of sensitive nodes in GNNs. The findings contribute to enhancing the privacy and security of GNN models and provide valuable insights into the field of node unlearning.</li>
</ul>

<h3>Title: Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects</h3>
<ul>
<li><strong>Authors: </strong>Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Treleaven</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04794">https://arxiv.org/abs/2509.04794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04794">https://arxiv.org/pdf/2509.04794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04794]] Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects(https://arxiv.org/abs/2509.04794)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Personality manipulation in large language models (LLMs) is increasingly applied in customer service and agentic scenarios, yet its mechanisms and trade-offs remain unclear. We present a systematic study of personality control using the Big Five traits, comparing in-context learning (ICL), parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our contributions are fourfold. First, we construct a contrastive dataset with balanced high/low trait responses, enabling effective steering vector computation and fair cross-method evaluation. Second, we introduce a unified evaluation framework based on within-run $\Delta$ analysis that disentangles, reasoning capability, agent performance, and demographic bias across MMLU, GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to separate openness from conscientiousness, addressing representational overlap in trait encoding. Fourth, we propose a three-level stability framework that quantifies method-, trait-, and combination-level robustness, offering practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment with minimal capability loss, PEFT delivers the highest alignment at the cost of degraded task performance, and MS provides lightweight runtime control with competitive effectiveness. Trait-level analysis shows openness as uniquely challenging, agreeableness as most resistant to ICL, and personality encoding consolidating around intermediate layers. Taken together, these results establish personality manipulation as a multi-level probe into behavioral representation, linking surface conditioning, parameter encoding, and activation-level steering, and positioning mechanistic steering as a lightweight alternative to fine-tuning for both deployment and interpretability.</li>
</ul>

<h3>Title: Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training</h3>
<ul>
<li><strong>Authors: </strong>Figarri Keisha, Zekun Wu, Ze Wang, Adriano Koshiyama, Philip Treleaven</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04796">https://arxiv.org/abs/2509.04796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04796">https://arxiv.org/pdf/2509.04796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04796]] Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training(https://arxiv.org/abs/2509.04796)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models increasingly rely on synthetic data due to human-written content scarcity, yet recursive training on model-generated outputs leads to model collapse, a degenerative process threatening factual reliability. We define knowledge collapse as a distinct three-stage phenomenon where factual accuracy deteriorates while surface fluency persists, creating "confidently wrong" outputs that pose critical risks in accuracy-dependent domains. Through controlled experiments with recursive synthetic training, we demonstrate that collapse trajectory and timing depend critically on instruction format, distinguishing instruction-following collapse from traditional model collapse through its conditional, prompt-dependent nature. We propose domain-specific synthetic training as a targeted mitigation strategy that achieves substantial improvements in collapse resistance while maintaining computational efficiency. Our evaluation framework combines model-centric indicators with task-centric metrics to detect distinct degradation phases, enabling reproducible assessment of epistemic deterioration across different language models. These findings provide both theoretical insights into collapse dynamics and practical guidance for sustainable AI training in knowledge-intensive applications where accuracy is paramount.</li>
</ul>

<h3>Title: Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images</h3>
<ul>
<li><strong>Authors: </strong>Asif Newaz, Masum Mushfiq Ishti, A Z M Ashraful Azam, Asif Ur Rahman Adib</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04800">https://arxiv.org/abs/2509.04800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04800">https://arxiv.org/pdf/2509.04800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04800]] Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images(https://arxiv.org/abs/2509.04800)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Skin diseases are among the most prevalent health concerns worldwide, yet conventional diagnostic methods are often costly, complex, and unavailable in low-resource settings. Automated classification using deep learning has emerged as a promising alternative, but existing studies are mostly limited to dermoscopic datasets and a narrow range of disease classes. In this work, we curate a large dataset of over 50 skin disease categories captured with mobile devices, making it more representative of real-world conditions. We evaluate multiple convolutional neural networks and Transformer-based architectures, demonstrating that Transformer models, particularly the Swin Transformer, achieve superior performance by effectively capturing global contextual features. To enhance interpretability, we incorporate Gradient-weighted Class Activation Mapping (Grad-CAM), which highlights clinically relevant regions and provides transparency in model predictions. Our results underscore the potential of Transformer-based approaches for mobile-acquired skin lesion classification, paving the way toward accessible AI-assisted dermatological screening and early diagnosis in resource-limited environments.</li>
</ul>

<h3>Title: Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs</h3>
<ul>
<li><strong>Authors: </strong>Ilham Wicaksono, Zekun Wu, Theo King, Adriano Koshiyama, Philip Treleaven</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04802">https://arxiv.org/abs/2509.04802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04802">https://arxiv.org/pdf/2509.04802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04802]] Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs(https://arxiv.org/abs/2509.04802)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>As large language models transition to agentic systems, current safety evaluation frameworks face critical gaps in assessing deployment-specific risks. We introduce AgentSeer, an observability-based evaluation framework that decomposes agentic executions into granular action and component graphs, enabling systematic agentic-situational assessment. Through cross-model validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and iterative refinement attacks, we demonstrate fundamental differences between model-level and agentic-level vulnerability profiles. Model-level evaluation reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash (50.00% ASR), with both models showing susceptibility to social engineering while maintaining logic-based attack resistance. However, agentic-level assessment exposes agent-specific risks invisible to traditional evaluation. We discover "agentic-only" vulnerabilities that emerge exclusively in agentic contexts, with tool-calling showing 24-60% higher ASR across both models. Cross-model analysis reveals universal agentic patterns, agent transfer operations as highest-risk tools, semantic rather than syntactic vulnerability mechanisms, and context-dependent attack effectiveness, alongside model-specific security profiles in absolute ASR levels and optimal injection strategies. Direct attack transfer from model-level to agentic contexts shows degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash: 28%), while context-aware iterative attacks successfully compromise objectives that failed at model-level, confirming systematic evaluation gaps. These findings establish the urgent need for agentic-situation evaluation paradigms, with AgentSeer providing the standardized methodology and empirical validation.</li>
</ul>

<h3>Title: Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Svetlana Pavlitska, Beyza Keskin, Alwin Fa√übender, Christian Hubschneider, J. Marius Z√∂llner</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04816">https://arxiv.org/abs/2509.04816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04816">https://arxiv.org/pdf/2509.04816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04816]] Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation(https://arxiv.org/abs/2509.04816)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Estimating accurate and well-calibrated predictive uncertainty is important for enhancing the reliability of computer vision models, especially in safety-critical applications like traffic scene perception. While ensemble methods are commonly used to quantify uncertainty by combining multiple models, a mixture of experts (MoE) offers an efficient alternative by leveraging a gating network to dynamically weight expert predictions based on the input. Building on the promising use of MoEs for semantic segmentation in our previous works, we show that well-calibrated predictive uncertainty estimates can be extracted from MoEs without architectural modifications. We investigate three methods to extract predictive uncertainty estimates: predictive entropy, mutual information, and expert variance. We evaluate these methods for an MoE with two experts trained on a semantical split of the A2D2 dataset. Our results show that MoEs yield more reliable uncertainty estimates than ensembles in terms of conditional correctness metrics under out-of-distribution (OOD) data. Additionally, we evaluate routing uncertainty computed via gate entropy and find that simple gating mechanisms lead to better calibration of routing uncertainty estimates than more complex classwise gates. Finally, our experiments on the Cityscapes dataset suggest that increasing the number of experts can further enhance uncertainty calibration. Our code is available at this https URL.</li>
</ul>

<h3>Title: AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yan Xie, Yibo Cui, Liang Xie, Erwei Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04821">https://arxiv.org/abs/2509.04821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04821">https://arxiv.org/pdf/2509.04821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04821]] AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding(https://arxiv.org/abs/2509.04821)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Spoken Language Understanding (SLU) is a core component of conversational systems, enabling machines to interpret user utterances. Despite its importance, developing effective SLU systems remains challenging due to the scarcity of labeled training data and the computational burden of deploying Large Language Models (LLMs) in real-world applications. To further alleviate these issues, we propose an Adaptive Feature Distillation framework that transfers rich semantic representations from a General Text Embeddings (GTE)-based teacher model to a lightweight student model. Our method introduces a dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to align heterogeneous feature spaces, and a Dynamic Distillation Coefficient (DDC) that adaptively modulates the distillation strength based on real-time feedback from intent and slot prediction performance. Experiments on the Chinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves state-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score, and 85.50% overall accuracy.</li>
</ul>

<h3>Title: Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Haosong Liu, Xiancheng Zhu, Huanqiang Zeng, Jianqing Zhu, Jiuwen Cao, Junhui Hou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04824">https://arxiv.org/abs/2509.04824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04824">https://arxiv.org/pdf/2509.04824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04824]] Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution(https://arxiv.org/abs/2509.04824)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Recently, Mamba-based methods, with its advantage in long-range information modeling and linear complexity, have shown great potential in optimizing both computational cost and performance of light field image super-resolution (LFSR). However, current multi-directional scanning strategies lead to inefficient and redundant feature extraction when applied to complex LF data. To overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS) strategy, based on which we design the Subspace Simple Mamba Block (SSMB) to achieve more efficient and precise feature extraction. Furthermore, we propose a dual-stage modeling strategy to address the limitation of state space in preserving spatial-angular and disparity information, thereby enabling a more comprehensive exploration of non-local spatial-angular correlations. Specifically, in stage I, we introduce the Spatial-Angular Residual Subspace Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage II, we use a dual-branch parallel structure combining the Epipolar Plane Mamba Block (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar feature refinement. Building upon meticulously designed modules and strategies, we introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates the strengths of Mamba and Transformer models for LFSR, enabling comprehensive information exploration across spatial, angular, and epipolar-plane domains. Experimental results demonstrate that LFMT significantly outperforms current state-of-the-art methods in LFSR, achieving substantial improvements in performance while maintaining low computational complexity on both real-word and synthetic LF datasets.</li>
</ul>

<h3>Title: PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination</h3>
<ul>
<li><strong>Authors: </strong>Ming Dai, Wenxuan Cheng, Jiedong Zhuang, Jiang-jiang Liu, Hongshen Zhao, Zhenhua Feng, Wankou Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04833">https://arxiv.org/abs/2509.04833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04833">https://arxiv.org/pdf/2509.04833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04833]] PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination(https://arxiv.org/abs/2509.04833)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in visual grounding have largely shifted away from traditional proposal-based two-stage frameworks due to their inefficiency and high computational complexity, favoring end-to-end direct reference paradigms. However, these methods rely exclusively on the referred target for supervision, overlooking the potential benefits of prominent prospective targets. Moreover, existing approaches often fail to incorporate multi-granularity discrimination, which is crucial for robust object identification in complex scenarios. To address these limitations, we propose PropVG, an end-to-end proposal-based framework that, to the best of our knowledge, is the first to seamlessly integrate foreground object proposal generation with referential object comprehension without requiring additional detectors. Furthermore, we introduce a Contrastive-based Refer Scoring (CRS) module, which employs contrastive learning at both sentence and word levels to enhance the capability in understanding and distinguishing referred objects. Additionally, we design a Multi-granularity Target Discrimination (MTD) module that fuses object- and semantic-level information to improve the recognition of absent targets. Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO (REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and models are available at this https URL.</li>
</ul>

<h3>Title: TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution</h3>
<ul>
<li><strong>Authors: </strong>Yifei Jia, Shiyu Cheng, Yu Dong, Guan Li, Dong Tian, Ruixiao Peng, Xuyi Lu, Yu Wang, Wei Yao, Guihua Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04834">https://arxiv.org/abs/2509.04834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04834">https://arxiv.org/pdf/2509.04834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04834]] TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution(https://arxiv.org/abs/2509.04834)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding the complex combustion dynamics within scramjet engines is critical for advancing high-speed propulsion technologies. However, the large scale and high dimensionality of simulation-generated temporal flow field data present significant challenges for visual interpretation, feature differentiation, and cross-case comparison. In this paper, we present TemporalFlowViz, a parameter-aware visual analytics workflow and system designed to support expert-driven clustering, visualization, and interpretation of temporal flow fields from scramjet combustion simulations. Our approach leverages hundreds of simulated combustion cases with varying initial conditions, each producing time-sequenced flow field images. We use pretrained Vision Transformers to extract high-dimensional embeddings from these frames, apply dimensionality reduction and density-based clustering to uncover latent combustion modes, and construct temporal trajectories in the embedding space to track the evolution of each simulation over time. To bridge the gap between latent representations and expert reasoning, domain specialists annotate representative cluster centroids with descriptive labels. These annotations are used as contextual prompts for a vision-language model, which generates natural-language summaries for individual frames and full simulation cases. The system also supports parameter-based filtering, similarity-based case retrieval, and coordinated multi-view exploration to facilitate in-depth analysis. We demonstrate the effectiveness of TemporalFlowViz through two expert-informed case studies and expert feedback, showing TemporalFlowViz enhances hypothesis generation, supports interpretable pattern discovery, and enhances knowledge discovery in large-scale scramjet combustion analysis.</li>
</ul>

<h3>Title: Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations</h3>
<ul>
<li><strong>Authors: </strong>Enze Ye, Wei Lin, Shaochi Ren, Yakun Liu, Xiaoping Li, Hao Wang, He Sun, Feng Pan</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.bio-ph, physics.optics, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04848">https://arxiv.org/abs/2509.04848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04848">https://arxiv.org/pdf/2509.04848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04848]] Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations(https://arxiv.org/abs/2509.04848)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables label-free, volumetric characterization of individual cells by reconstructing their refractive index (RI) distributions from multiple viewing angles during flow through microfluidic channels. However, current imaging methods assume that cells undergo uniform, single-axis rotation, which require their poses to be known at each frame. This assumption restricts applicability to near-spherical cells and prevents accurate imaging of irregularly shaped cells with complex rotations. As a result, only a subset of the cellular population can be analyzed, limiting the ability of flow-based assays to perform robust statistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction framework that leverages the Fourier diffraction theorem and implicit neural representations (INRs) for high-throughput flow cytometry tomographic imaging. By jointly optimizing each cell's unknown rotational trajectory and volumetric structure under weak scattering assumptions, OmniFHT supports arbitrary cell geometries and multi-axis rotations. Its continuous representation also allows accurate reconstruction from sparsely sampled projections and restricted angular coverage, producing high-fidelity results with as few as 10 views or only 120 degrees of angular range. OmniFHT enables, for the first time, in situ, high-throughput tomographic imaging of entire flowing cell populations, providing a scalable and unbiased solution for label-free morphometric analysis in flow cytometry platforms.</li>
</ul>

<h3>Title: CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus</h3>
<ul>
<li><strong>Authors: </strong>Hannah Schieber, Dominik Frischmann, Simon Boche, Victor Schaack, Angela Schoellig, Stefan Leutenegger, Daniel Roth</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04859">https://arxiv.org/abs/2509.04859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04859">https://arxiv.org/pdf/2509.04859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04859]] CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus(https://arxiv.org/abs/2509.04859)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Mobile reconstruction for autonomous aerial robotics holds strong potential for critical applications such as tele-guidance and disaster response. These tasks demand both accurate 3D reconstruction and fast scene processing. Instead of reconstructing the entire scene in detail, it is often more efficient to focus on specific objects, i.e., points of interest (PoIs). Mobile robots equipped with advanced sensing can usually detect these early during data acquisition or preliminary analysis, reducing the need for full-scene optimization. Gaussian Splatting (GS) has recently shown promise in delivering high-quality novel view synthesis and 3D representation by an incremental learning process. Extending GS with scene editing, semantics adds useful per-splat features to isolate objects effectively. Semantic 3D Gaussian editing can already be achieved before the full training cycle is completed, reducing the overall training time. Moreover, the semantically relevant area, the PoI, is usually already known during capturing. To balance high-quality reconstruction with reduced training time, we propose CoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS and then refine it for the semantic object using our novel color-based effective filtering for effective object isolation. This is speeding up the training process to be about a quarter less than a full training cycle for semantic GS. We evaluate our approach on two datasets, SCRREAM (real-world, outdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher novel-view-synthesis quality.</li>
</ul>

<h3>Title: Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?</h3>
<ul>
<li><strong>Authors: </strong>Boxiang Ma, Ru Li, Yuanlong Wang, Hongye Tan, Xiaoli Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04866">https://arxiv.org/abs/2509.04866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04866">https://arxiv.org/pdf/2509.04866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04866]] Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?(https://arxiv.org/abs/2509.04866)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Driven by vast and diverse textual data, large language models (LLMs) have demonstrated impressive performance across numerous natural language processing (NLP) tasks. Yet, a critical question persists: does their generalization arise from mere memorization of training data or from deep semantic understanding? To investigate this, we propose a bi-perspective evaluation framework to assess LLMs' scenario cognition - the ability to link semantic scenario elements with their arguments in context. Specifically, we introduce a novel scenario-based dataset comprising diverse textual descriptions of fictional facts, annotated with scenario elements. LLMs are evaluated through their capacity to answer scenario-related questions (model output perspective) and via probing their internal representations for encoded scenario elements-argument associations (internal representation perspective). Our experiments reveal that current LLMs predominantly rely on superficial memorization, failing to achieve robust semantic scenario cognition, even in simple cases. These findings expose critical limitations in LLMs' semantic understanding and offer cognitive insights for advancing their capabilities.</li>
</ul>

<h3>Title: Using LLMs for Multilingual Clinical Entity Linking to ICD-10</h3>
<ul>
<li><strong>Authors: </strong>Sylvia Vassileva, Ivan Koychev, Svetla Boytcheva</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04868">https://arxiv.org/abs/2509.04868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04868">https://arxiv.org/pdf/2509.04868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04868]] Using LLMs for Multilingual Clinical Entity Linking to ICD-10(https://arxiv.org/abs/2509.04868)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The linking of clinical entities is a crucial part of extracting structured information from clinical texts. It is the process of assigning a code from a medical ontology or classification to a phrase in the text. The International Classification of Diseases - 10th revision (ICD-10) is an international standard for classifying diseases for statistical and insurance purposes. Automatically assigning the correct ICD-10 code to terms in discharge summaries will simplify the work of healthcare professionals and ensure consistent coding in hospitals. Our paper proposes an approach for linking clinical terms to ICD-10 codes in different languages using Large Language Models (LLMs). The approach consists of a multistage pipeline that uses clinical dictionaries to match unambiguous terms in the text and then applies in-context learning with GPT-4.1 to predict the ICD-10 code for the terms that do not match the dictionary. Our system shows promising results in predicting ICD-10 codes on different benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on subcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.</li>
</ul>

<h3>Title: L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Raul Singh, Nicolo Brunello, Vincenzo Scotti, Mark James Carman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04884">https://arxiv.org/abs/2509.04884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04884">https://arxiv.org/pdf/2509.04884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04884]] L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning(https://arxiv.org/abs/2509.04884)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The ability of Large Language Models (LLMs) to solve complex tasks has made them crucial in the development of AI-based applications. However, the high computational requirements to fine-tune these LLMs on downstream tasks pose significant challenges, particularly when resources are limited. In response to this challenge, we introduce L1RA, a novel technique aimed at dynamically distributing the rank of low-rank adapters during fine-tuning using LoRA. Given a rank budget (i.e., total sum of adapters rank), L1RA leverages L1 regularisation to prune redundant ranks and redistribute them across adapters, thereby optimising resource utilisation. Through a series of comprehensive experiments, we empirically demonstrate that L1RA maintains comparable or even reduced computational overhead compared to other LoRA variants, including the vanilla approach, while achieving same or better performances. Moreover, the post-training analysis of rank distribution unveiled insights into the specific model components requiring the most adaptation to align with the task objective: the feed-forward layers and the attention output projection. These results highlight the efficacy of L1RA in not only enhancing the efficiency of LLM fine-tuning, but also in providing valuable diagnostic information for model refinement and customisation. In conclusion, L1RA stands as a promising technique for advancing the performance and interpretability of LLM adaptation, particularly in scenarios where computational resources are constrained.</li>
</ul>

<h3>Title: SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Dominik Pegler, David Steyrl, Mengfan Zhang, Alexander Karner, Jozsef Arato, Frank Scharnowski, Filip Melinscak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04889">https://arxiv.org/abs/2509.04889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04889">https://arxiv.org/pdf/2509.04889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04889]] SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models(https://arxiv.org/abs/2509.04889)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Advances in computer vision have opened new avenues for clinical applications, particularly in computerized exposure therapy where visual stimuli can be dynamically adjusted based on patient responses. As a critical step toward such adaptive systems, we investigated whether pretrained computer vision models can accurately predict fear levels from spider-related images. We adapted three diverse models using transfer learning to predict human fear ratings (on a 0-100 scale) from a standardized dataset of 313 images. The models were evaluated using cross-validation, achieving an average mean absolute error (MAE) between 10.1 and 11.0. Our learning curve analysis revealed that reducing the dataset size significantly harmed performance, though further increases yielded no substantial gains. Explainability assessments showed the models' predictions were based on spider-related features. A category-wise error analysis further identified visual conditions associated with higher errors (e.g., distant views and artificial/painted spiders). These findings demonstrate the potential of explainable computer vision models in predicting fear ratings, highlighting the importance of both model explainability and a sufficient dataset size for developing effective emotion-aware therapeutic technologies.</li>
</ul>

<h3>Title: Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting</h3>
<ul>
<li><strong>Authors: </strong>Maryam Adelipour, Gustavo Carneiro, Jeongkwon Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04895">https://arxiv.org/abs/2509.04895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04895">https://arxiv.org/pdf/2509.04895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04895]] Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting(https://arxiv.org/abs/2509.04895)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sebocytes are lipid-secreting cells whose differentiation is marked by the accumulation of intracellular lipid droplets, making their quantification a key readout in sebocyte biology. Manual counting is labor-intensive and subjective, motivating automated solutions. Here, we introduce a simple attention-based multiple instance learning (MIL) framework for sebocyte image analysis. Nile Red-stained sebocyte images were annotated into 14 classes according to droplet counts, expanded via data augmentation to about 50,000 cells. Two models were benchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated patch-level counts, and an attention-based MIL model leveraging ResNet-50 features with instance weighting. Experiments using five-fold cross-validation showed that the baseline MLP achieved more stable performance (mean MAE = 5.6) compared with the attention-based MIL, which was less consistent (mean MAE = 10.7) but occasionally superior in specific folds. These findings indicate that simple bag-level aggregation provides a robust baseline for slide-level droplet counting, while attention-based MIL requires task-aligned pooling and regularization to fully realize its potential in sebocyte image analysis.</li>
</ul>

<h3>Title: PLaMo 2 Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Preferred Networks: Kaizaburo Chubachi, Yasuhiro Fujita, Shinichi Hemmi, Yuta Hirokawa, Toshiki Kataoka, Goro Kobayashi, Kenichi Maehashi, Calvin Metzger, Hiroaki Mikami, Shogo Murai, Daisuke Nishino, Kento Nozawa, Shintarou Okada, Daisuke Okanohara, Shunta Saito, Shotaro Sano, Shuji Suzuki, Daisuke Tanaka, Avinash Ummadisingu, Hanqin Wang, Sixue Wang, Tianqi Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04897">https://arxiv.org/abs/2509.04897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04897">https://arxiv.org/pdf/2509.04897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04897]] PLaMo 2 Technical Report(https://arxiv.org/abs/2509.04897)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this report, we introduce PLaMo 2, a series of Japanese-focused large language models featuring a hybrid Samba-based architecture that transitions to full attention via continual pre-training to support 32K token contexts. Training leverages extensive synthetic corpora to overcome data scarcity, while computational efficiency is achieved through weight reuse and structured pruning. This efficient pruning methodology produces an 8B model that achieves performance comparable to our previous 100B model. Post-training further refines the models using a pipeline of supervised fine-tuning (SFT) and direct preference optimization (DPO), enhanced by synthetic Japanese instruction data and model merging techniques. Optimized for inference using vLLM and quantization with minimal accuracy loss, the PLaMo 2 models achieve state-of-the-art results on Japanese benchmarks, outperforming similarly-sized open models in instruction-following, language fluency, and Japanese-specific knowledge.</li>
</ul>

<h3>Title: ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Jianghao Chen, Wei Sun, Qixiang Yin, Lingxing Kong, Zhixing Tan, Jiajun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04903">https://arxiv.org/abs/2509.04903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04903">https://arxiv.org/pdf/2509.04903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04903]] ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning(https://arxiv.org/abs/2509.04903)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable progress in long-context understanding, yet they face significant challenges in high-quality long-form generation. Existing studies primarily suffer from two limitations: (1) A heavy reliance on scarce, high-quality long-form response data for supervised fine-tuning (SFT) or for pairwise preference reward in reinforcement learning (RL). (2) Focus on coarse-grained quality optimization dimensions, such as relevance, coherence, and helpfulness, overlooking the fine-grained specifics inherent to diverse long-form generation scenarios. To address this issue, we propose a framework using Adaptive Constraint-Enhanced reward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first automatically deconstructs each instruction into a set of fine-grained, adaptive constraint criteria by identifying its underlying intents and demands. Subsequently, we design a reward mechanism that quantifies the quality of long-form responses based on their satisfaction over corresponding constraints, converting subjective quality evaluation into constraint verification. Finally, we utilize reinforcement learning to guide models toward superior long-form generation capabilities. Experimental results demonstrate that our ACE-RL framework significantly outperforms existing SFT and RL baselines by 20.70% and 7.32% on WritingBench, and our top-performing model even surpasses proprietary systems like GPT-4o by 7.10%, providing a more effective training paradigm for LLMs to generate high-quality content across diverse long-form generation scenarios.</li>
</ul>

<h3>Title: Revolution or Hype? Seeking the Limits of Large Models in Hardware Design</h3>
<ul>
<li><strong>Authors: </strong>Qiang Xu, Leon Stok, Rolf Drechsler, Xi Wang, Grace Li Zhang, Igor L. Markov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04905">https://arxiv.org/abs/2509.04905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04905">https://arxiv.org/pdf/2509.04905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04905]] Revolution or Hype? Seeking the Limits of Large Models in Hardware Design(https://arxiv.org/abs/2509.04905)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent breakthroughs in Large Language Models (LLMs) and Large Circuit Models (LCMs) have sparked excitement across the electronic design automation (EDA) community, promising a revolution in circuit design and optimization. Yet, this excitement is met with significant skepticism: Are these AI models a genuine revolution in circuit design, or a temporary wave of inflated expectations? This paper serves as a foundational text for the corresponding ICCAD 2025 panel, bringing together perspectives from leading experts in academia and industry. It critically examines the practical capabilities, fundamental limitations, and future prospects of large AI models in hardware design. The paper synthesizes the core arguments surrounding reliability, scalability, and interpretability, framing the debate on whether these models can meaningfully outperform or complement traditional EDA methods. The result is an authoritative overview offering fresh insights into one of today's most contentious and impactful technology trends.</li>
</ul>

<h3>Title: Scaling Law for Large-Scale Pre-Training Using Chaotic Time Series and Predictability in Financial Time Series</h3>
<ul>
<li><strong>Authors: </strong>Yuki Takemoto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04921">https://arxiv.org/abs/2509.04921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04921">https://arxiv.org/pdf/2509.04921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04921]] Scaling Law for Large-Scale Pre-Training Using Chaotic Time Series and Predictability in Financial Time Series(https://arxiv.org/abs/2509.04921)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series forecasting plays a critical role in decision-making processes across diverse fields including meteorology, traffic, electricity, economics, finance, and so on. Especially, predicting returns on financial instruments is a challenging problem. Some researchers have proposed time series foundation models applicable to various forecasting tasks. Simultaneously, based on the recognition that real-world time series exhibit chaotic properties, methods have been developed to artificially generate synthetic chaotic time series, construct diverse datasets and train models. In this study, we propose a methodology for modeling financial time series by generating artificial chaotic time series and applying resampling techniques to simulate financial time series data, which we then use as training samples. Increasing the resampling interval to extend predictive horizons, we conducted large-scale pre-training using 10 billion training samples for each case. We subsequently created test datasets for multiple timeframes using actual Bitcoin trade data and performed zero-shot prediction without re-training the pre-trained model. The results of evaluating the profitability of a simple trading strategy based on these predictions demonstrated significant performance improvements over autocorrelation models. During the large-scale pre-training process, we observed a scaling law-like phenomenon that we can achieve predictive performance at a certain level with extended predictive horizons for chaotic time series by increasing the number of training samples exponentially. If this scaling law proves robust and holds true across various chaotic models, it suggests the potential to predict near-future events by investing substantial computational resources. Future research should focus on further large-scale training and verifying the applicability of this scaling law to diverse chaotic models.</li>
</ul>

<h3>Title: A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection</h3>
<ul>
<li><strong>Authors: </strong>Jiale Zhang, Pengfei He, Fei Li, Kewei Li, Yan Wang, Lan Huang, Ruochi Zhang, Fengfeng Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04925">https://arxiv.org/abs/2509.04925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04925">https://arxiv.org/pdf/2509.04925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04925]] A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection(https://arxiv.org/abs/2509.04925)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>In today's fast-paced digital communication, the surge in network traffic data and frequency demands robust and precise network intrusion solutions. Conventional machine learning methods struggle to grapple with complex patterns within the vast network intrusion datasets, which suffer from data scarcity and class imbalance. As a result, we have integrated machine learning and deep learning techniques within the network intrusion detection system to bridge this gap. This study has developed TrailGate, a novel framework that combines machine learning and deep learning techniques. By integrating Transformer and Bidirectional Gated Recurrent Unit (BiGRU) architectures with advanced feature selection strategies and supplemented by data augmentation techniques, TrailGate can identifies common attack types and excels at detecting and mitigating emerging threats. This algorithmic fusion excels at detecting common and well-understood attack types and has the unique ability to swiftly identify and neutralize emerging threats that stem from existing paradigms.</li>
</ul>

<h3>Title: UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features</h3>
<ul>
<li><strong>Authors: </strong>Haowang Cui, Rui Chen, Tao Luo, Rui Li, Jiaze Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04932">https://arxiv.org/abs/2509.04932</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04932">https://arxiv.org/pdf/2509.04932</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04932]] UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features(https://arxiv.org/abs/2509.04932)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The task of synthesizing novel views from a single image is highly ill-posed due to multiple explanations for unobserved areas. Most current methods tend to generate unseen regions from ambiguity priors and interpolation near input views, which often lead to severe distortions. To address this limitation, we propose a novel model dubbed as UniView, which can leverage reference images from a similar object to provide strong prior information during view synthesis. More specifically, we construct a retrieval and augmentation system and employ a multimodal large language model (MLLM) to assist in selecting reference images that meet our requirements. Additionally, a plug-and-play adapter module with multi-level isolation layers is introduced to dynamically generate reference features for the target views. Moreover, in order to preserve the details of an original input image, we design a decoupled triple attention mechanism, which can effectively align and integrate multi-branch features into the synthesis process. Extensive experiments have demonstrated that our UniView significantly improves novel view synthesis performance and outperforms state-of-the-art methods on the challenging datasets.</li>
</ul>

<h3>Title: Cryptographic Application of Elliptic Curve with High Rank</h3>
<ul>
<li><strong>Authors: </strong>Xiaogang Cheng, Ren Guo, Zuxi Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04941">https://arxiv.org/abs/2509.04941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04941">https://arxiv.org/pdf/2509.04941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04941]] Cryptographic Application of Elliptic Curve with High Rank(https://arxiv.org/abs/2509.04941)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Elliptic curve cryptography is better than traditional cryptography based on RSA and discrete logarithm of finite field in terms of efficiency and security. In this paper, we show how to exploit elliptic curve with high rank, which has not been used in cryptography before, to construct cryptographic schemes. Concretely we demonstrate how to construct public key signature scheme with hierarchy revocation based on elliptic curve with high rank, where the rank determines the height of the revocation tree. Although our construction is not very efficient in some sense, our construction shows elliptic curve with high rank is valuable and important for cryptographic usage. The technique and assumption presented can surely be used for other cryptographic constructions.</li>
</ul>

<h3>Title: Detecting Blinks in Healthy and Parkinson's EEG: A Deep Learning Perspective</h3>
<ul>
<li><strong>Authors: </strong>Artem Lensky, Yiding Qiu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04951">https://arxiv.org/abs/2509.04951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04951">https://arxiv.org/pdf/2509.04951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04951]] Detecting Blinks in Healthy and Parkinson's EEG: A Deep Learning Perspective(https://arxiv.org/abs/2509.04951)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Blinks in electroencephalography (EEG) are often treated as unwanted artifacts. However, recent studies have demonstrated that blink rate and its variability are important physiological markers to monitor cognitive load, attention, and potential neurological disorders. This paper addresses the critical task of accurate blink detection by evaluating various deep learning models for segmenting EEG signals into involuntary blinks and non-blinks. We present a pipeline for blink detection using 1, 3, or 5 frontal EEG electrodes. The problem is formulated as a sequence-to-sequence task and tested on various deep learning architectures including standard recurrent neural networks, convolutional neural networks (both standard and depth-wise), temporal convolutional networks (TCN), transformer-based models, and hybrid architectures. The models were trained on raw EEG signals with minimal pre-processing. Training and testing was carried out on a public dataset of 31 subjects collected at UCSD. This dataset consisted of 15 healthy participants and 16 patients with Parkinson's disease allowing us to verify the model's robustness to tremor. Out of all models, CNN-RNN hybrid model consistently outperformed other models and achieved the best blink detection accuracy of 93.8%, 95.4% and 95.8% with 1, 3, and 5 channels in the healthy cohort and correspondingly 73.8%, 75.4% and 75.8% in patients with PD. The paper compares neural networks for the task of segmenting EEG recordings to involuntary blinks and no blinks allowing for computing blink rate and other statistics.</li>
</ul>

<h3>Title: Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper</h3>
<ul>
<li><strong>Authors: </strong>Gehui Chen, Guan'an Wang, Xiaowen Huang, Jitao Sang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04957">https://arxiv.org/abs/2509.04957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04957">https://arxiv.org/pdf/2509.04957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04957]] Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper(https://arxiv.org/abs/2509.04957)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent Video-to-Audio (V2A) generation relies on extracting semantic and temporal features from video to condition generative models. Training these models from scratch is resource intensive. Consequently, leveraging foundation models (FMs) has gained traction due to their cross-modal knowledge transfer and generalization capabilities. One prior work has explored fine-tuning a lightweight mapper network to connect a pre-trained visual encoder with a text-to-audio generation model for V2A. Inspired by this, we introduce the Multiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper approach, MFM-Mapper benefits from richer semantic and temporal information by fusing features from dual visual encoders. Furthermore, by replacing a linear mapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels between cross-modal features mapping and autoregressive translation tasks. Our MFM-Mapper exhibits remarkable training efficiency. It achieves better performance in semantic and temporal consistency with fewer training consuming, requiring only 16\% of the training scale compared to previous mapper-based work, yet achieves competitive performance with models trained on a much larger scale.</li>
</ul>

<h3>Title: Classification of kinetic-related injury in hospital triage data using NLP</h3>
<ul>
<li><strong>Authors: </strong>Midhun Shyam, Jim Basilakis, Kieran Luken, Steven Thomas, John Crozier, Paul M. Middleton, X. Rosalind Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04969">https://arxiv.org/abs/2509.04969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04969">https://arxiv.org/pdf/2509.04969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04969]] Classification of kinetic-related injury in hospital triage data using NLP(https://arxiv.org/abs/2509.04969)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Triage notes, created at the start of a patient's hospital visit, contain a wealth of information that can help medical staff and researchers understand Emergency Department patient epidemiology and the degree of time-dependent illness or injury. Unfortunately, applying modern Natural Language Processing and Machine Learning techniques to analyse triage data faces some challenges: Firstly, hospital data contains highly sensitive information that is subject to privacy regulation thus need to be analysed on site; Secondly, most hospitals and medical facilities lack the necessary hardware to fine-tune a Large Language Model (LLM), much less training one from scratch; Lastly, to identify the records of interest, expert inputs are needed to manually label the datasets, which can be time-consuming and costly. We present in this paper a pipeline that enables the classification of triage data using LLM and limited compute resources. We first fine-tuned a pre-trained LLM with a classifier using a small (2k) open sourced dataset on a GPU; and then further fine-tuned the model with a hospital specific dataset of 1000 samples on a CPU. We demonstrated that by carefully curating the datasets and leveraging existing models and open sourced data, we can successfully classify triage data with limited compute resources.</li>
</ul>

<h3>Title: Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Wang, Heyao Liu, Guanzi Yao, Nyutian Long, Yue Kang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04973">https://arxiv.org/abs/2509.04973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04973">https://arxiv.org/pdf/2509.04973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04973]] Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks(https://arxiv.org/abs/2509.04973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a topology-aware graph reinforcement learning approach to address the routing policy optimization problem in cloud server environments. The method builds a unified framework for state representation and structural evolution by integrating a Structure-Aware State Encoding (SASE) module and a Policy-Adaptive Graph Update (PAGU) mechanism. It aims to tackle the challenges of decision instability and insufficient structural awareness under dynamic topologies. The SASE module models node states through multi-layer graph convolution and structural positional embeddings, capturing high-order dependencies in the communication topology and enhancing the expressiveness of state representations. The PAGU module adjusts the graph structure based on policy behavior shifts and reward feedback, enabling adaptive structural updates in dynamic environments. Experiments are conducted on the real-world GEANT topology dataset, where the model is systematically evaluated against several representative baselines in terms of throughput, latency control, and link balance. Additional experiments, including hyperparameter sensitivity, graph sparsity perturbation, and node feature dimensionality variation, further explore the impact of structure modeling and graph updates on model stability and decision quality. Results show that the proposed method outperforms existing graph reinforcement learning models across multiple performance metrics, achieving efficient and robust routing in dynamic and complex cloud networks.</li>
</ul>

<h3>Title: Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization</h3>
<ul>
<li><strong>Authors: </strong>Shuaicheng Niu, Guohao Chen, Deyu Chen, Yifan Zhang, Jiaxiang Wu, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Chunyan Miao, Mingkui Tan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04977">https://arxiv.org/abs/2509.04977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04977">https://arxiv.org/pdf/2509.04977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04977]] Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization(https://arxiv.org/abs/2509.04977)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test-time adaptation (TTA) may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, 3) online imbalanced label distribution shifts. This is often a key obstacle preventing existing TTA methods from being deployed in the real world. In this paper, we investigate the unstable reasons and find that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, i.e., group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases, i.e., the model collapses into trivial solutions by assigning the same class label for all samples. By digging into this, we find that, during the collapse process: 1) the model gradients often undergo an initial explosion followed by rapid degradation, suggesting that certain noisy test samples with large gradients may disrupt adaptation; and 2) the model representations tend to exhibit high correlations and classification bias. To address this, we first propose a sharpness-aware and reliable entropy minimization method, called SAR, for stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a flat minimum so that the model is robust to the remaining noisy samples. Based on SAR, we further introduce SAR^2 to prevent representation collapse with two regularizers: 1) a redundancy regularizer to reduce inter-dimensional correlations among centroid-invariant features; and 2) an inequity regularizer to maximize the prediction entropy of a prototype centroid, thereby penalizing biased representations toward any specific class. Promising results demonstrate that our methods perform more stably over prior methods and are computationally efficient under the above wild test scenarios.</li>
</ul>

<h3>Title: Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts</h3>
<ul>
<li><strong>Authors: </strong>Julius Neumann, Robert Lange, Yuni Susanti, Michael F√§rber</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04982">https://arxiv.org/abs/2509.04982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04982">https://arxiv.org/pdf/2509.04982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04982]] Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts(https://arxiv.org/abs/2509.04982)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Sentiment classification in short text datasets faces significant challenges such as class imbalance, limited training samples, and the inherent subjectivity of sentiment labels -- issues that are further intensified by the limited context in short texts. These factors make it difficult to resolve ambiguity and exacerbate data sparsity, hindering effective learning. In this paper, we evaluate the effectiveness of small Transformer-based models (i.e., BERT and RoBERTa, with fewer than 1 billion parameters) for multi-label sentiment classification, with a particular focus on short-text settings. Specifically, we evaluated three key factors influencing model performance: (1) continued domain-specific pre-training, (2) data augmentation using automatically generated examples, specifically generative data augmentation, and (3) architectural variations of the classification head. Our experiment results show that data augmentation improves classification performance, while continued pre-training on augmented datasets can introduce noise rather than boost accuracy. Furthermore, we confirm that modifications to the classification head yield only marginal benefits. These findings provide practical guidance for optimizing BERT-based models in resource-constrained settings and refining strategies for sentiment classification in short-text datasets.</li>
</ul>

<h3>Title: Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Sidahmed Benabderrahmane, Talal Rahwan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.04999">https://arxiv.org/abs/2509.04999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.04999">https://arxiv.org/pdf/2509.04999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.04999]] Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection(https://arxiv.org/abs/2509.04999)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) present a considerable challenge to cybersecurity due to their stealthy, long-duration nature. Traditional supervised learning methods typically require large amounts of labeled data, which is often scarce in real-world scenarios. This paper introduces a novel approach that combines AutoEncoders for anomaly detection with active learning to iteratively enhance APT detection. By selectively querying an oracle for labels on uncertain or ambiguous samples, our method reduces labeling costs while improving detection accuracy, enabling the model to effectively learn with minimal data and reduce reliance on extensive manual labeling. We present a comprehensive formulation of the Attention Adversarial Dual AutoEncoder-based anomaly detection framework and demonstrate how the active learning loop progressively enhances the model's performance. The framework is evaluated on real-world, imbalanced provenance trace data from the DARPA Transparent Computing program, where APT-like attacks account for just 0.004\% of the data. The datasets, which cover multiple operating systems including Android, Linux, BSD, and Windows, are tested in two attack scenarios. The results show substantial improvements in detection rates during active learning, outperforming existing methods.</li>
</ul>

<h3>Title: Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework</h3>
<ul>
<li><strong>Authors: </strong>Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05000">https://arxiv.org/abs/2509.05000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05000">https://arxiv.org/pdf/2509.05000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05000]] Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework(https://arxiv.org/abs/2509.05000)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Most existing infrared-visible image fusion (IVIF) methods assume high-quality inputs, and therefore struggle to handle dual-source degraded scenarios, typically requiring manual selection and sequential application of multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion pipeline inevitably leads to error accumulation and performance degradation. To overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion), a novel framework that synergistically integrates vision-language models (VLMs) for degradation perception with dual-domain (frequency/spatial) joint optimization. Concretely, the designed Guided Frequency Modality-Specific Extraction (GFMSE) module performs frequency-domain degradation perception and suppression and discriminatively extracts fusion-relevant sub-band features. Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries out cross-modal degradation filtering and adaptive multi-source feature aggregation in the spatial domain to enhance modality complementarity and structural consistency. Extensive qualitative and quantitative experiments demonstrate that GD^2Fusion achieves superior fusion performance compared with existing algorithms and strategies in dual-source degraded scenarios. The code will be publicly released after acceptance of this paper.</li>
</ul>

<h3>Title: Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Abbadi, Yassine Himeur, Shadi Atalla, Wathiq Mansoor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05004">https://arxiv.org/abs/2509.05004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05004">https://arxiv.org/pdf/2509.05004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05004]] Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study(https://arxiv.org/abs/2509.05004)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Breast cancer remains a leading cause of cancer-related mortality among women worldwide. Ultrasound imaging, widely used due to its safety and cost-effectiveness, plays a key role in early detection, especially in patients with dense breast tissue. This paper presents a comprehensive study on the application of machine learning and deep learning techniques for breast cancer classification using ultrasound images. Using datasets such as BUSI, BUS-BRA, and BrEaST-Lesions USG, we evaluate classical machine learning models (SVM, KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0, GoogLeNet). Experimental results show that ResNet-18 achieves the highest accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML models, though outperformed by CNNs, achieve competitive performance when enhanced with deep feature extraction. Grad-CAM visualizations further improve model transparency by highlighting diagnostically relevant image regions. These findings support the integration of AI-based diagnostic tools into clinical workflows and demonstrate the feasibility of deploying high-performing, interpretable systems for ultrasound-based breast cancer detection.</li>
</ul>

<h3>Title: Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant</h3>
<ul>
<li><strong>Authors: </strong>Inbal Bolshinsky, Shani Kupiec, Almog Sasson, Yehudit Aperstein, Alexander Apartsin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05006">https://arxiv.org/abs/2509.05006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05006">https://arxiv.org/pdf/2509.05006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05006]] Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant(https://arxiv.org/abs/2509.05006)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the era of conversational AI, generating accurate and contextually appropriate service responses remains a critical challenge. A central question remains: Is explicit intent recognition a prerequisite for generating high-quality service responses, or can models bypass this step and produce effective replies directly? This paper conducts a rigorous comparative study to address this fundamental design dilemma. Leveraging two publicly available service interaction datasets, we benchmark several state-of-the-art language models, including a fine-tuned T5 variant, across both paradigms: Intent-First Response Generation and Direct Response Generation. Evaluation metrics encompass both linguistic quality and task success rates, revealing surprising insights into the necessity or redundancy of explicit intent modelling. Our findings challenge conventional assumptions in conversational AI pipelines, offering actionable guidelines for designing more efficient and effective response generation systems.</li>
</ul>

<h3>Title: A biologically inspired separable learning vision model for real-time traffic object perception in Dark</h3>
<ul>
<li><strong>Authors: </strong>Hulin Li, Qiliang Ren, Jun Li, Hanbing Wei, Zheng Liu, Linfang Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05012">https://arxiv.org/abs/2509.05012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05012">https://arxiv.org/pdf/2509.05012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05012]] A biologically inspired separable learning vision model for real-time traffic object perception in Dark(https://arxiv.org/abs/2509.05012)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Fast and accurate object perception in low-light traffic scenes has attracted increasing attention. However, due to severe illumination degradation and the lack of reliable visual cues, existing perception models and methods struggle to quickly adapt to and accurately predict in low-light environments. Moreover, there is the absence of available large-scale benchmark specifically focused on low-light traffic scenes. To bridge this gap, we introduce a physically grounded illumination degradation method tailored to real-world low-light settings and construct Dark-traffic, the largest densely annotated dataset to date for low-light traffic scenes, supporting object detection, instance segmentation, and optical flow estimation. We further propose the Separable Learning Vision Model (SLVM), a biologically inspired framework designed to enhance perception under adverse lighting. SLVM integrates four key components: a light-adaptive pupillary mechanism for illumination-sensitive feature extraction, a feature-level separable learning strategy for efficient representation, task-specific decoupled branches for multi-task separable learning, and a spatial misalignment-aware fusion module for precise multi-feature alignment. Extensive experiments demonstrate that SLVM achieves state-of-the-art performance with reduced computational overhead. Notably, it outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1 percentage points in instance segmentation, and reduces endpoint error (EPE) of baseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end trained SLVM surpasses Swin Transformer+EnlightenGAN and ConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage points. The Dark-traffic dataset and complete code is released at this https URL.</li>
</ul>

<h3>Title: Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition</h3>
<ul>
<li><strong>Authors: </strong>Mohsine El Khayati, Ayyad Maafiri, Yassine Himeur, Hamzah Ali Alkhazaleh, Shadi Atalla, Wathiq Mansoor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05019">https://arxiv.org/abs/2509.05019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05019">https://arxiv.org/pdf/2509.05019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05019]] Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition(https://arxiv.org/abs/2509.05019)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The study explores the integration of transfer learning (TL) with mobile-enabled convolutional neural networks (MbNets) to enhance Arabic Handwritten Character Recognition (AHCR). Addressing challenges like extensive computational requirements and dataset scarcity, this research evaluates three TL strategies--full fine-tuning, partial fine-tuning, and training from scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD, HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently achieving superior accuracy, robustness, and efficiency, with ShuffleNet excelling in generalization, particularly under full fine-tuning. The IFHCDB dataset yielded the highest results, with 99% accuracy using MnasNet under full fine-tuning, highlighting its suitability for robust character recognition. The AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA posed significant challenges due to its variability, achieving a peak accuracy of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall performance, balancing accuracy and convergence speed, while partial fine-tuning underperformed across metrics. These findings underscore the potential of combining TL and MbNets for resource-efficient AHCR, paving the way for further optimizations and broader applications. Future work will explore architectural modifications, in-depth dataset feature analysis, data augmentation, and advanced sensitivity analysis to enhance model robustness and generalizability.</li>
</ul>

<h3>Title: LUIVITON: Learned Universal Interoperable VIrtual Try-ON</h3>
<ul>
<li><strong>Authors: </strong>Cong Cao, Xianhang Cheng, Jingyuan Liu, Yujian Zheng, Zhenhui Lin, Meriem Chkir, Hao Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05030">https://arxiv.org/abs/2509.05030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05030">https://arxiv.org/pdf/2509.05030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05030]] LUIVITON: Learned Universal Interoperable VIrtual Try-ON(https://arxiv.org/abs/2509.05030)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present LUIVITON, an end-to-end system for fully automated virtual try-on, capable of draping complex, multi-layer clothing onto diverse and arbitrarily posed humanoid characters. To address the challenge of aligning complex garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy representation and separate the clothing-to-body draping problem into two correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence, where each has its unique challenges. While we address the clothing-to-SMPL fitting problem using a geometric learning-based approach for partial-to-complete shape correspondence prediction, we introduce a diffusion model-based approach for body-to-SMPL correspondence using multi-view consistent appearance features and a pre-trained 2D foundation model. Our method can handle complex geometries, non-manifold meshes, and generalizes effectively to a wide range of humanoid characters -- including humans, robots, cartoon subjects, creatures, and aliens, while maintaining computational efficiency for practical adoption. In addition to offering a fully automatic fitting solution, LUIVITON supports fast customization of clothing size, allowing users to adjust clothing sizes and material properties after they have been draped. We show that our system can produce high-quality 3D clothing fittings without any human labor, even when 2D clothing sewing patterns are not available.</li>
</ul>

<h3>Title: Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization</h3>
<ul>
<li><strong>Authors: </strong>Jingqi Wu, Hanxi Li, Lin Yuanbo Wu, Hao Chen, Deyin Liu, Peng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05034">https://arxiv.org/abs/2509.05034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05034">https://arxiv.org/pdf/2509.05034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05034]] Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization(https://arxiv.org/abs/2509.05034)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Industrial product inspection is often performed using Anomaly Detection (AD) frameworks trained solely on non-defective samples. Although defective samples can be collected during production, leveraging them usually requires pixel-level annotations, limiting scalability. To address this, we propose ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial anomaly detection. ADClick generates pixel-wise anomaly annotations from only a few user clicks and a brief textual description, enabling precise and efficient labeling that significantly improves AD model performance (e.g., AP = 96.1\% on MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that aligns visual features and textual prompts via a prototype-based approach for anomaly detection and localization. By combining pixel-level priors with language-guided cues, ADClick-Seg achieves state-of-the-art results on the challenging ``Multi-class'' AD task (AP = 80.0\%, PRO = 97.5\%, Pixel-AUROC = 99.1\% on MVTec AD).</li>
</ul>

<h3>Title: MultiSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer</h3>
<ul>
<li><strong>Authors: </strong>Noorul Wahab, Ethar Alzaid, Jiaqi Lv, Adam Shephard, Shan E Ahmed Raza</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05037">https://arxiv.org/abs/2509.05037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05037">https://arxiv.org/pdf/2509.05037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05037]] MultiSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer(https://arxiv.org/abs/2509.05037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate prediction of time-to-event outcomes is a central challenge in oncology, with significant implications for treatment planning and patient management. In this work, we present MultiSurv, a multimodal deep survival model utilising DeepHit with a projection layer and inter-modality cross-attention, which integrates heterogeneous patient data, including clinical, MRI, RNA-seq and whole-slide pathology features. The model is designed to capture complementary prognostic signals across modalities and estimate individualised time-to-biochemical recurrence in prostate cancer and time-to-cancer recurrence in bladder cancer. Our approach was evaluated in the context of the CHIMERA Grand Challenge, across two of the three provided tasks. For Task 1 (prostate cancer bio-chemical recurrence prediction), the proposed framework achieved a concordance index (C-index) of 0.843 on 5-folds cross-validation and 0.818 on CHIMERA development set, demonstrating robust discriminatory ability. For Task 3 (bladder cancer recurrence prediction), the model obtained a C-index of 0.662 on 5-folds cross-validation and 0.457 on development set, highlighting its adaptability and potential for clinical translation. These results suggest that leveraging multimodal integration with deep survival learning provides a promising pathway toward personalised risk stratification in prostate and bladder cancer. Beyond the challenge setting, our framework is broadly applicable to survival prediction tasks involving heterogeneous biomedical data.</li>
</ul>

<h3>Title: Masked Diffusion Language Models with Frequency-Informed Training</h3>
<ul>
<li><strong>Authors: </strong>Despoina Kosmopoulou, Efthymios Georgiou, Vaggelis Dorovatas, Georgios Paraskevopoulos, Alexandros Potamianos</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05056">https://arxiv.org/abs/2509.05056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05056">https://arxiv.org/pdf/2509.05056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05056]] Masked Diffusion Language Models with Frequency-Informed Training(https://arxiv.org/abs/2509.05056)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a masked diffusion language modeling framework for data-efficient training for the BabyLM 2025 Challenge. Our approach applies diffusion training objectives to language modeling under strict data constraints, incorporating frequency-informed masking that prioritizes learning from rare tokens while maintaining theoretical validity. We explore multiple noise scheduling strategies, including two-mode approaches, and investigate different noise weighting schemes within the NELBO objective. We evaluate our method on the BabyLM benchmark suite, measuring linguistic competence, world knowledge, and human-likeness. Results show performance competitive to hybrid autoregressive-masked baselines, demonstrating that diffusion-based training offers a viable alternative for data-restricted language learning.</li>
</ul>

<h3>Title: Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction</h3>
<ul>
<li><strong>Authors: </strong>Mojtaba Safari, Zach Eidex, Richard L.J. Qiu, Matthew Goette, Tonghe Wang, Xiaofeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05071">https://arxiv.org/abs/2509.05071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05071">https://arxiv.org/pdf/2509.05071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05071]] Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction(https://arxiv.org/abs/2509.05071)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Background: To systematically review and perform a meta-analysis of artificial intelligence (AI)-driven methods for detecting and correcting magnetic resonance imaging (MRI) motion artifacts, assessing current developments, effectiveness, challenges, and future research directions. Methods: A comprehensive systematic review and meta-analysis were conducted, focusing on deep learning (DL) approaches, particularly generative models, for the detection and correction of MRI motion artifacts. Quantitative data were extracted regarding utilized datasets, DL architectures, and performance metrics. Results: DL, particularly generative models, show promise for reducing motion artifacts and improving image quality; however, limited generalizability, reliance on paired training data, and risk of visual distortions remain key challenges that motivate standardized datasets and reporting. Conclusions: AI-driven methods, particularly DL generative models, show significant potential for improving MRI image quality by effectively addressing motion artifacts. However, critical challenges must be addressed, including the need for comprehensive public datasets, standardized reporting protocols for artifact levels, and more advanced, adaptable DL techniques to reduce reliance on extensive paired datasets. Addressing these aspects could substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and improve patient care outcomes.</li>
</ul>

<h3>Title: GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Yangming Li, Chaoyu Liu, Lihao Liu, Simon Masnou, Carola-Bibian Sch√∂nlieb</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05075">https://arxiv.org/abs/2509.05075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05075">https://arxiv.org/pdf/2509.05075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05075]] GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting(https://arxiv.org/abs/2509.05075)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A few recent works explored incorporating geometric priors to regularize the optimization of Gaussian splatting, further improving its performance. However, those early studies mainly focused on the use of low-order geometric priors (e.g., normal vector), and they are also unreliably estimated by noise-sensitive methods, like local principal component analysis. To address their limitations, we first present GeoSplat, a general geometry-constrained optimization framework that exploits both first-order and second-order geometric quantities to improve the entire training pipeline of Gaussian splatting, including Gaussian initialization, gradient update, and densification. As an example, we initialize the scales of 3D Gaussian primitives in terms of principal curvatures, leading to a better coverage of the object surface than random initialization. Secondly, based on certain geometric structures (e.g., local manifold), we introduce efficient and noise-robust estimation methods that provide dynamic geometric priors for our framework. We conduct extensive experiments on multiple datasets for novel view synthesis, showing that our framework: GeoSplat, significantly improves the performance of Gaussian splatting and outperforms previous baselines.</li>
</ul>

<h3>Title: Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction</h3>
<ul>
<li><strong>Authors: </strong>Djamel Eddine Boukhari</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05078">https://arxiv.org/abs/2509.05078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05078">https://arxiv.org/pdf/2509.05078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05078]] Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction(https://arxiv.org/abs/2509.05078)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Automated Facial Beauty Prediction (FBP) is a challenging computer vision task due to the complex interplay of local and global facial features that influence human perception. While Convolutional Neural Networks (CNNs) excel at feature extraction, they often process information at a fixed scale, potentially overlooking the critical inter-dependencies between features at different levels of granularity. To address this limitation, we introduce the Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture that synergizes the feature extraction power of CNNs with the relational modeling capabilities of Transformers. The SIT first employs a multi-scale module with parallel convolutions to capture facial characteristics at varying receptive fields. These multi-scale representations are then framed as a sequence and processed by a Transformer encoder, which explicitly models their interactions and contextual relationships via a self-attention mechanism. We conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark dataset, where the proposed SIT model establishes a new state-of-the-art. It achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our findings demonstrate that explicitly modeling the interplay between multi-scale visual cues is crucial for high-performance FBP. The success of the SIT architecture highlights the potential of hybrid CNN-Transformer models for complex image regression tasks that demand a holistic, context-aware understanding.</li>
</ul>

<h3>Title: Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers</h3>
<ul>
<li><strong>Authors: </strong>Svetlana Pavlitska, Haixi Fan, Konstantin Ditschuneit, J. Marius Z√∂llner</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05086">https://arxiv.org/abs/2509.05086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05086">https://arxiv.org/pdf/2509.05086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05086]] Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers(https://arxiv.org/abs/2509.05086)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Robustifying convolutional neural networks (CNNs) against adversarial attacks remains challenging and often requires resource-intensive countermeasures. We explore the use of sparse mixture-of-experts (MoE) layers to improve robustness by replacing selected residual blocks or convolutional layers, thereby increasing model capacity without additional inference cost. On ResNet architectures trained on CIFAR-100, we find that inserting a single MoE layer in the deeper stages leads to consistent improvements in robustness under PGD and AutoPGD attacks when combined with adversarial training. Furthermore, we discover that when switch loss is used for balancing, it causes routing to collapse onto a small set of overused experts, thereby concentrating adversarial training on these paths and inadvertently making them more robust. As a result, some individual experts outperform the gated MoE model in robustness, suggesting that robust subpaths emerge through specialization. Our code is available at this https URL.</li>
</ul>

<h3>Title: Semi-supervised Deep Transfer for Regression without Domain Alignment</h3>
<ul>
<li><strong>Authors: </strong>Mainak Biswas, Ambedkar Dukkipati, Devarajan Sridharan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05092">https://arxiv.org/abs/2509.05092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05092">https://arxiv.org/pdf/2509.05092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05092]] Semi-supervised Deep Transfer for Regression without Domain Alignment(https://arxiv.org/abs/2509.05092)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Deep learning models deployed in real-world applications (e.g., medicine) face challenges because source models do not generalize well to domain-shifted target data. Many successful domain adaptation (DA) approaches require full access to source data. Yet, such requirements are unrealistic in scenarios where source data cannot be shared either because of privacy concerns or because it is too large and incurs prohibitive storage or computational costs. Moreover, resource constraints may limit the availability of labeled targets. We illustrate this challenge in a neuroscience setting where source data are unavailable, labeled target data are meager, and predictions involve continuous-valued outputs. We build upon Contradistinguisher (CUDA), an efficient framework that learns a shared model across the labeled source and unlabeled target samples, without intermediate representation alignment. Yet, CUDA was designed for unsupervised DA, with full access to source data, and for classification tasks. We develop CRAFT -- a Contradistinguisher-based Regularization Approach for Flexible Training -- for source-free (SF), semi-supervised transfer of pretrained models in regression tasks. We showcase the efficacy of CRAFT in two neuroscience settings: gaze prediction with electroencephalography (EEG) data and ``brain age'' prediction with structural MRI data. For both datasets, CRAFT yielded up to 9% improvement in root-mean-squared error (RMSE) over fine-tuned models when labeled training examples were scarce. Moreover, CRAFT leveraged unlabeled target data and outperformed four competing state-of-the-art source-free domain adaptation models by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two other real-world regression benchmarks. We propose CRAFT as an efficient approach for source-free, semi-supervised deep transfer for regression that is ubiquitous in biology and medicine.</li>
</ul>

<h3>Title: From Protest to Power Plant: Interpreting the Role of Escalatory Hacktivism in Cyber Conflict</h3>
<ul>
<li><strong>Authors: </strong>Richard Derbyshire, Diana Selck-Paulsson, Charl van der Walt, Joe Burton</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05104">https://arxiv.org/abs/2509.05104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05104">https://arxiv.org/pdf/2509.05104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05104]] From Protest to Power Plant: Interpreting the Role of Escalatory Hacktivism in Cyber Conflict(https://arxiv.org/abs/2509.05104)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Since 2022, hacktivist groups have escalated their tactics, expanding from distributed denial-of-service attacks and document leaks to include targeting operational technology (OT). By 2024, attacks on the OT of critical national infrastructure (CNI) had been linked to partisan hacktivist efforts in ongoing geopolitical conflicts, demonstrating a shift from protest to something more resembling cyber warfare. This escalation raises critical questions about the classification of these groups and the appropriate state response to their growing role in destabilizing international security. This paper examines the strategic motivations behind escalatory hacktivism, highlighting how states may tolerate, encourage, or leverage hacktivist groups as proxies in conflicts that blur the lines between activism, cybercrime, and state-sponsored operations. We introduce a novel method for interpreting hacktivists based on the impact of their actions, alignment to state ideology, and host state involvement, offering a structured approach to understanding the phenomenon. Finally, we assess policy and security implications, particularly for host and victim states, and propose strategies to address this evolving threat. By doing so, this paper contributes to international discussions on cyber security policy, governance, and the increasing intersection between non-state cyber actors and state interests.</li>
</ul>

<h3>Title: HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions</h3>
<ul>
<li><strong>Authors: </strong>Rafael Bischof, Michal Piovarƒçi, Michael A. Kraus, Siddhartha Mishra, Bernd Bickel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05117">https://arxiv.org/abs/2509.05117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05117">https://arxiv.org/pdf/2509.05117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05117]] HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions(https://arxiv.org/abs/2509.05117)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present HyPINO, a multi-physics neural operator designed for zero-shot generalization across a broad class of parametric PDEs without requiring task-specific fine-tuning. Our approach combines a Swin Transformer-based hypernetwork with mixed supervision: (i) labeled data from analytical solutions generated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled samples optimized using physics-informed objectives. The model maps PDE parametrizations to target Physics-Informed Neural Networks (PINNs) and can handle linear elliptic, hyperbolic, and parabolic equations in two dimensions with varying source terms, geometries, and mixed Dirichlet/Neumann boundary conditions, including interior boundaries. HyPINO achieves strong zero-shot accuracy on seven benchmark problems from PINN literature, outperforming U-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we introduce an iterative refinement procedure that compares the physics of the generated PINN to the requested PDE and uses the discrepancy to generate a "delta" PINN. Summing their contributions and repeating this process forms an ensemble whose combined solution progressively reduces the error on six benchmarks and achieves over 100x gain in average $L_2$ loss in the best case, while retaining forward-only inference. Additionally, we evaluate the fine-tuning behavior of PINNs initialized by HyPINO and show that they converge faster and to lower final error than both randomly initialized and Reptile-meta-learned PINNs on five benchmarks, performing on par on the remaining two. Our results highlight the potential of this scalable approach as a foundation for extending neural operators toward solving increasingly complex, nonlinear, and high-dimensional PDE problems with significantly improved accuracy and reduced computational cost.</li>
</ul>

<h3>Title: A Scalable Attention-Based Approach for Image-to-3D Texture Mapping</h3>
<ul>
<li><strong>Authors: </strong>Arianna Rampini, Kanika Madan, Bruno Roy, AmirHossein Zamani, Derek Cheung</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05131">https://arxiv.org/abs/2509.05131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05131">https://arxiv.org/pdf/2509.05131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05131]] A Scalable Attention-Based Approach for Image-to-3D Texture Mapping(https://arxiv.org/abs/2509.05131)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>High-quality textures are critical for realistic 3D content creation, yet existing generative methods are slow, rely on UV maps, and often fail to remain faithful to a reference image. To address these challenges, we propose a transformer-based framework that predicts a 3D texture field directly from a single image and a mesh, eliminating the need for UV mapping and differentiable rendering, and enabling faster texture generation. Our method integrates a triplane representation with depth-based backprojection losses, enabling efficient training and faster inference. Once trained, it generates high-fidelity textures in a single forward pass, requiring only 0.2s per shape. Extensive qualitative, quantitative, and user preference evaluations demonstrate that our method outperforms state-of-the-art baselines on single-image texture reconstruction in terms of both fidelity to the input image and perceptual quality, highlighting its practicality for scalable, high-quality, and controllable 3D content creation.</li>
</ul>

<h3>Title: Foundational Models and Federated Learning: Survey, Taxonomy, Challenges and Practical Insights</h3>
<ul>
<li><strong>Authors: </strong>Cosmin-Andrei Hatfaludi, Alex Serban</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05142">https://arxiv.org/abs/2509.05142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05142">https://arxiv.org/pdf/2509.05142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05142]] Foundational Models and Federated Learning: Survey, Taxonomy, Challenges and Practical Insights(https://arxiv.org/abs/2509.05142)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning has the potential to unlock siloed data and distributed resources by enabling collaborative model training without sharing private data. As more complex foundational models gain widespread use, the need to expand training resources and integrate privately owned data grows as well. In this article, we explore the intersection of federated learning and foundational models, aiming to identify, categorize, and characterize technical methods that integrate the two paradigms. As a unified survey is currently unavailable, we present a literature survey structured around a novel taxonomy that follows the development life-cycle stages, along with a technical comparison of available methods. Additionally, we provide practical insights and guidelines for implementing and evolving these methods, with a specific focus on the healthcare domain as a case study, where the potential impact of federated learning and foundational models is considered significant. Our survey covers multiple intersecting topics, including but not limited to federated learning, self-supervised learning, fine-tuning, distillation, and transfer learning. Initially, we retrieved and reviewed a set of over 4,200 articles. This collection was narrowed to more than 250 thoroughly reviewed articles through inclusion criteria, featuring 42 unique methods. The methods were used to construct the taxonomy and enabled their comparison based on complexity, efficiency, and scalability. We present these results as a self-contained overview that not only summarizes the state of the field but also provides insights into the practical aspects of adopting, evolving, and integrating foundational models with federated learning.</li>
</ul>

<h3>Title: SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing</h3>
<ul>
<li><strong>Authors: </strong>Chaolei Wang, Yang Luo, Jing Du, Siyu Chen, Yiping Chen, Ting Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05144">https://arxiv.org/abs/2509.05144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05144">https://arxiv.org/pdf/2509.05144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05144]] SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing(https://arxiv.org/abs/2509.05144)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate 3D instance segmentation is crucial for high-quality scene understanding in the 3D vision domain. However, 3D instance segmentation based on 2D-to-3D lifting approaches struggle to produce precise instance-level segmentation, due to accumulated errors introduced during the lifting process from ambiguous semantic guidance and insufficient depth constraints. To tackle these challenges, we propose splitting and growing reliable semantic mask for high-fidelity 3D instance segmentation (SGS-3D), a novel "split-then-grow" framework that first purifies and splits ambiguous lifted masks using geometric primitives, and then grows them into complete instances within the scene. Unlike existing approaches that directly rely on raw lifted masks and sacrifice segmentation accuracy, SGS-3D serves as a training-free refinement method that jointly fuses semantic and geometric information, enabling effective cooperation between the two levels of representation. Specifically, for semantic guidance, we introduce a mask filtering strategy that leverages the co-occurrence of 3D geometry primitives to identify and remove ambiguous masks, thereby ensuring more reliable semantic consistency with the 3D object instances. For the geometric refinement, we construct fine-grained object instances by exploiting both spatial continuity and high-level features, particularly in the case of semantic ambiguity between distinct objects. Experimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that SGS-3D substantially improves segmentation accuracy and robustness against inaccurate masks from pre-trained models, yielding high-fidelity object instances while maintaining strong generalization across diverse indoor and outdoor environments. Code is available in the supplementary materials.</li>
</ul>

<h3>Title: Odoo-based Subcontract Inter-site Access Control Mechanism for Construction Projects</h3>
<ul>
<li><strong>Authors: </strong>Huy Hung Ho, Nhan Le Thanh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05149">https://arxiv.org/abs/2509.05149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05149">https://arxiv.org/pdf/2509.05149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05149]] Odoo-based Subcontract Inter-site Access Control Mechanism for Construction Projects(https://arxiv.org/abs/2509.05149)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>In the era of Construction 4.0, the industry is embracing a new paradigm of labor elasticity, driven by smart and flexible outsourcing and subcontracting strategies. The increased reliance on specialized subcontractors enables companies to scale labor dynamically based on project demands. This adaptable workforce model presents challenges in managing hierarchical integration and coordinating inter-site collaboration. Our design introduces a subsystem integrated into the Odoo ERP framework, employing a modular architecture to streamline labor management, task tracking, and approval workflows. The system adopts a three-pronged approach to ensure synchronized data exchange between general contractors and subcontractors, while maintaining both security and operational independence. The system features hybrid access control, third-party integration for cross-domain communication, and role-based mapping algorithm across sites. The system supports varying degrees of customization through a unified and consolidated attribute mapping center. This center leverages a tree-like index structure and Lagrange interpolation method to enhance the efficiency of role mapping. Demonstrations highlight practical application in outsourcing, integration, and scalability scenarios, confirming the system's robustness under high user volumes and in offline conditions. Experimental results further show improvements in database performance and workflow adaptability to support a scalable, enterprise-level solution that aligns with the evolving demands of smart construction management.</li>
</ul>

<h3>Title: Reinforcing Secure Live Migration through Verifiable State Management</h3>
<ul>
<li><strong>Authors: </strong>Stefanos Vasileaidis, Thanassis Giannetsos, Matthias Schunter, Bruno Crispo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05150">https://arxiv.org/abs/2509.05150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05150">https://arxiv.org/pdf/2509.05150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05150]] Reinforcing Secure Live Migration through Verifiable State Management(https://arxiv.org/abs/2509.05150)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust, extraction</a></li>
<li><strong>Abstract: </strong>Live migration of applications is a fundamental capability for enabling resilient computing in modern distributed systems. However, extending this functionality to trusted applications (TA) -- executing within Trusted Execution Environments (TEEs) -- introduces unique challenges such as secure state preservation, integrity verification, replay and rollback prevention, and mitigation of unauthorized cloning of TAs. We present TALOS, a lightweight framework for verifiable state management and trustworthy application migration. While our implementation is prototyped and evaluated using Intel SGX with the Gramine LibOS and RISC-V Keystone (evidencing the framework's portability across diverse TEEs), its design is agnostic to the underlying TEE architecture. Such agility is a necessity in today's network service mesh (collaborative computing across the continuum) where application workloads must be managed across domain boundaries in a harmonized fashion. TALOS is built around the principle of minimizing trust assumptions: TAs are treated as untrusted until explicitly verified, and the migration process does not rely on a trusted third party. To ensure both the integrity and secure launch of the migrated application, TALOS integrates memory introspection and control-flow graph extraction, enabling robust verification of state continuity and execution flow. Thereby achieving strong security guarantees while maintaining efficiency, making it suitable for decentralized settings.</li>
</ul>

<h3>Title: Jamming Smarter, Not Harder: Exploiting O-RAN Y1 RAN Analytics for Efficient Interference</h3>
<ul>
<li><strong>Authors: </strong>Abiodun Ganiyu, Dara Ron, Syed Rafiul Hussain, Vijay K Shah</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05161">https://arxiv.org/abs/2509.05161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05161">https://arxiv.org/pdf/2509.05161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05161]] Jamming Smarter, Not Harder: Exploiting O-RAN Y1 RAN Analytics for Efficient Interference(https://arxiv.org/abs/2509.05161)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, steal</a></li>
<li><strong>Abstract: </strong>The Y1 interface in O-RAN enables the sharing of RAN Analytics Information (RAI) between the near-RT RIC and authorized Y1 consumers, which may be internal applications within the operator's trusted domain or external systems accessing data through a secure exposure function. While this visibility enhances network optimization and enables advanced services, it also introduces a potential security risk -- a malicious or compromised Y1 consumer could misuse analytics to facilitate targeted interference. In this work, we demonstrate how an adversary can exploit the Y1 interface to launch selective jamming attacks by passively monitoring downlink metrics. We propose and evaluate two Y1-aided jamming strategies: a clustering-based jammer leveraging DBSCAN for traffic profiling and a threshold-based jammer. These are compared against two baselines strategies -- always-on jammer and random jammer -- on an over-the-air LTE/5G O-RAN testbed. Experimental results show that in unconstrained jamming budget scenarios, the threshold-based jammer can closely replicate the disruption caused by always-on jamming while reducing transmission time by 27\%. Under constrained jamming budgets, the clustering-based jammer proves most effective, causing up to an 18.1\% bitrate drop while remaining active only 25\% of the time. These findings reveal a critical trade-off between jamming stealthiness and efficiency, and illustrate how exposure of RAN analytics via the Y1 interface can enable highly targeted, low-overhead attacks, raising important security considerations for both civilian and mission-critical O-RAN deployments.</li>
</ul>

<h3>Title: Verifiability and Privacy in Federated Learning through Context-Hiding Multi-Key Homomorphic Authenticators</h3>
<ul>
<li><strong>Authors: </strong>Simone Bottoni, Giulio Zizzo, Stefano Braghin, Alberto Trombetta</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05162">https://arxiv.org/abs/2509.05162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05162">https://arxiv.org/pdf/2509.05162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05162]] Verifiability and Privacy in Federated Learning through Context-Hiding Multi-Key Homomorphic Authenticators(https://arxiv.org/abs/2509.05162)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning has rapidly expanded from its original inception to now have a large body of research, several frameworks, and sold in a variety of commercial offerings. Thus, its security and robustness is of significant importance. There are many algorithms that provide robustness in the case of malicious clients. However, the aggregator itself may behave maliciously, for example, by biasing the model or tampering with the weights to weaken the models privacy. In this work, we introduce a verifiable federated learning protocol that enables clients to verify the correctness of the aggregators computation without compromising the confidentiality of their updates. Our protocol uses a standard secure aggregation technique to protect individual model updates with a linearly homomorphic authenticator scheme that enables efficient, privacy-preserving verification of the aggregated result. Our construction ensures that clients can detect manipulation by the aggregator while maintaining low computational overhead. We demonstrate that our approach scales to large models, enabling verification over large neural networks with millions of parameters.</li>
</ul>

<h3>Title: KVCompose: Efficient Structured KV Cache Compression with Composite Tokens</h3>
<ul>
<li><strong>Authors: </strong>Dmitry Akulov, Mohamed Sana, Antonio De Domenico, Tareq Si Salem, Nicola Piovesan, Fadhel Ayed</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05165">https://arxiv.org/abs/2509.05165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05165">https://arxiv.org/pdf/2509.05165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05165]] KVCompose: Efficient Structured KV Cache Compression with Composite Tokens(https://arxiv.org/abs/2509.05165)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) rely on key-value (KV) caches for efficient autoregressive decoding; however, cache size grows linearly with context length and model depth, becoming a major bottleneck in long-context inference. Prior KV cache compression methods either enforce rigid heuristics, disrupt tensor layouts with per-attention-head variability, or require specialized compute kernels. We propose a simple, yet effective, KV cache compression framework based on attention-guided, layer-adaptive composite tokens. Our method aggregates attention scores to estimate token importance, selects head-specific tokens independently, and aligns them into composite tokens that respect the uniform cache structure required by existing inference engines. A global allocation mechanism further adapts retention budgets across layers, assigning more capacity to layers with informative tokens. This approach achieves significant memory reduction while preserving accuracy, consistently outperforming prior structured and semi-structured methods. Crucially, our approach remains fully compatible with standard inference pipelines, offering a practical and scalable solution for efficient long-context LLM deployment.</li>
</ul>

<h3>Title: On Hyperparameters and Backdoor-Resistance in Horizontal Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Simon Lachnit, Ghassan Karame</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05192">https://arxiv.org/abs/2509.05192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05192">https://arxiv.org/pdf/2509.05192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05192]] On Hyperparameters and Backdoor-Resistance in Horizontal Federated Learning(https://arxiv.org/abs/2509.05192)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Horizontal Federated Learning (HFL) is particularly vulnerable to backdoor attacks as adversaries can easily manipulate both the training data and processes to execute sophisticated attacks. In this work, we study the impact of training hyperparameters on the effectiveness of backdoor attacks and defenses in HFL. More specifically, we show both analytically and by means of measurements that the choice of hyperparameters by benign clients does not only influence model accuracy but also significantly impacts backdoor attack success. This stands in sharp contrast with the multitude of contributions in the area of HFL security, which often rely on custom ad-hoc hyperparameter choices for benign clients$\unicode{x2013}$leading to more pronounced backdoor attack strength and diminished impact of defenses. Our results indicate that properly tuning benign clients' hyperparameters$\unicode{x2013}$such as learning rate, batch size, and number of local epochs$\unicode{x2013}$can significantly curb the effectiveness of backdoor attacks, regardless of the malicious clients' settings. We support this claim with an extensive robustness evaluation of state-of-the-art attack-defense combinations, showing that carefully chosen hyperparameters yield across-the-board improvements in robustness without sacrificing main task accuracy. For example, we show that the 50%-lifespan of the strong A3FL attack can be reduced by 98.6%, respectively$\unicode{x2013}$all without using any defense and while incurring only a 2.9 percentage points drop in clean task accuracy.</li>
</ul>

<h3>Title: Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework</h3>
<ul>
<li><strong>Authors: </strong>David Herrera-Poyatos, Carlos Pel√°ez-Gonz√°lez, Cristina Zuheros, Virilo Tejedor, Rosana Montes, Francisco Herrera</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05199">https://arxiv.org/abs/2509.05199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05199">https://arxiv.org/pdf/2509.05199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05199]] Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework(https://arxiv.org/abs/2509.05199)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly being deployed in high-risk domains where opacity, bias, and instability undermine trust and accountability. Traditional explainability methods, focused on surface outputs, do not capture the reasoning pathways, planning logic, and systemic impacts of agentic LLMs. We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a triadic fusion framework that unites three complementary dimensions: cognitive (user understanding), functional (practical utility), and causal (faithful reasoning). TAXAL provides a unified, role-sensitive foundation for designing, evaluating, and deploying explanations in diverse sociotechnical settings. Our analysis synthesizes existing methods, ranging from post-hoc attribution and dialogic interfaces to explanation-aware prompting, and situates them within the TAXAL triadic fusion model. We further demonstrate its applicability through case studies in law, education, healthcare, and public services, showing how explanation strategies adapt to institutional constraints and stakeholder roles. By combining conceptual clarity with design patterns and deployment pathways, TAXAL advances explainability as a technical and sociotechnical practice, supporting trustworthy and context-sensitive LLM applications in the era of agentic AI.</li>
</ul>

<h3>Title: Symbolic Graphics Programming with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yamei Chen, Haoquan Zhang, Yangyi Huang, Zeju Qiu, Kaipeng Zhang, Yandong Wen, Weiyang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05208">https://arxiv.org/abs/2509.05208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05208">https://arxiv.org/pdf/2509.05208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05208]] Symbolic Graphics Programming with Large Language Models(https://arxiv.org/abs/2509.05208)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at program synthesis, yet their ability to produce symbolic graphics programs (SGPs) that render into precise visual content remains underexplored. We study symbolic graphics programming, where the goal is to generate an SGP from a natural-language description. This task also serves as a lens into how LLMs understand the visual world by prompting them to generate images rendered from SGPs. Among various SGPs, our paper sticks to scalable vector graphics (SVGs). We begin by examining the extent to which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a comprehensive benchmark covering object fidelity, scene fidelity, and compositionality (attribute binding, spatial relations, numeracy). On SGP-GenBench, we discover that frontier proprietary models substantially outperform open-source models, and performance correlates well with general coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards approach, where a format-validity gate ensures renderable SVG, and a cross-modal reward aligns text and the rendered image via strong vision encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to Qwen-2.5-7B, our method substantially improves SVG generation quality and semantics, achieving performance on par with frontier systems. We further analyze training dynamics, showing that RL induces (i) finer decomposition of objects into controllable primitives and (ii) contextual details that improve scene coherence. Our results demonstrate that symbolic graphics programming offers a precise and interpretable lens on cross-modal grounding.</li>
</ul>

<h3>Title: Hunyuan-MT Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Mao Zheng, Zheng Li, Bingxin Qu, Mingyang Song, Yang Du, Mingrui Sun, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05209">https://arxiv.org/abs/2509.05209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05209">https://arxiv.org/pdf/2509.05209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05209]] Hunyuan-MT Technical Report(https://arxiv.org/abs/2509.05209)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this report, we introduce Hunyuan-MT-7B, our first open-source multilingual translation model, which supports bidirectional translation across 33 major languages and places a special emphasis on translation between Mandarin and several ethnic minority languages as well as dialects. Furthermore, to serve and address diverse translation scenarios and enhance model performance at test time, we introduce Hunyuan-MT-Chimera-7B, a translation model inspired by the slow thinking mode. This model integrates multiple outputs generated by the Hunyuan-MT-7B model under varying parameter settings, thereby achieving performance superior to that of conventional slow-thinking models based on Chain-of-Thought (CoT). The development of our models follows a holistic training process specifically engineered for multilingual translation, which begins with general and MT-oriented pre-training to build foundational capabilities, proceeds to Supervised Fine-Tuning (SFT) for task-specific adaptation, and culminates in advanced alignment through Reinforcement Learning (RL) and weak-to-strong RL. Through comprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and Hunyuan-MT-Chimera-7B significantly outperform all translation-specific models of comparable parameter size and most of the SOTA large models, particularly on the task of translation between Mandarin and minority languages as well as dialects. In the WMT2025 shared task (General Machine Translation), our models demonstrate state-of-the-art performance, ranking first in 30 out of 31 language pairs. This result highlights the robustness of our models across a diverse linguistic spectrum, encompassing high-resource languages such as Chinese, English, and Japanese, as well as low-resource languages including Czech, Marathi, Estonian, and Icelandic.</li>
</ul>

<h3>Title: An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data</h3>
<ul>
<li><strong>Authors: </strong>Jiaojiao Zhang, Yuqi Xu, Kun Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05213">https://arxiv.org/abs/2509.05213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05213">https://arxiv.org/pdf/2509.05213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05213]] An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data(https://arxiv.org/abs/2509.05213)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>This work addresses the key challenges of applying federated learning to large-scale deep neural networks, particularly the issue of client drift due to data heterogeneity across clients and the high costs of communication, computation, and memory. We propose FedSub, an efficient subspace algorithm for federated learning on heterogeneous data. Specifically, FedSub utilizes subspace projection to guarantee local updates of each client within low-dimensional subspaces, thereby reducing communication, computation, and memory costs. Additionally, it incorporates low-dimensional dual variables to mitigate client drift. We provide convergence analysis that reveals the impact of key factors such as step size and subspace projection matrices on convergence. Experimental results demonstrate its efficiency.</li>
</ul>

<h3>Title: BEDTime: A Unified Benchmark for Automatically Describing Time Series</h3>
<ul>
<li><strong>Authors: </strong>Medhasweta Sen, Zachary Gottesman, Jiaxing Qiu, C. Bayan Bruss, Nam Nguyen, Tom Hartvigsen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05215">https://arxiv.org/abs/2509.05215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05215">https://arxiv.org/pdf/2509.05215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05215]] BEDTime: A Unified Benchmark for Automatically Describing Time Series(https://arxiv.org/abs/2509.05215)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Many recent studies have proposed general-purpose foundation models designed for a variety of time series analysis tasks. While several established datasets already exist for evaluating these models, previous works frequently introduce their models in conjunction with new datasets, limiting opportunities for direct, independent comparisons and obscuring insights into the relative strengths of different methods. Additionally, prior evaluations often cover numerous tasks simultaneously, assessing a broad range of model abilities without clearly pinpointing which capabilities contribute to overall performance. To address these gaps, we formalize and evaluate 3 tasks that test a model's ability to describe time series using generic natural language: (1) recognition (True/False question-answering), (2) differentiation (multiple choice question-answering), and (3) generation (open-ended natural language description). We then unify 4 recent datasets to enable head-to-head model comparisons on each task. Experimentally, in evaluating 13 state-of-the-art language, vision--language, and time series--language models, we find that (1) popular language-only methods largely underperform, indicating a need for time series-specific architectures, (2) VLMs are quite successful, as expected, identifying the value of vision models for these tasks and (3) pretrained multimodal time series--language models successfully outperform LLMs, but still have significant room for improvement. We also find that all approaches exhibit clear fragility in a range of robustness tests. Overall, our benchmark provides a standardized evaluation on a task necessary for time series reasoning systems.</li>
</ul>

<h3>Title: HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chang Dai, Hongyu Shan, Mingyang Song, Di Liang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05218">https://arxiv.org/abs/2509.05218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05218">https://arxiv.org/pdf/2509.05218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05218]] HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models(https://arxiv.org/abs/2509.05218)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Positional encoding mechanisms enable Transformers to model sequential structure and long-range dependencies in text. While absolute positional encodings struggle with extrapolation to longer sequences due to fixed positional representations, and relative approaches like Alibi exhibit performance degradation on extremely long contexts, the widely-used Rotary Positional Encoding (RoPE) introduces oscillatory attention patterns that hinder stable long-distance dependency modelling. We address these limitations through a geometric reformulation of positional encoding. Drawing inspiration from Lorentz transformations in hyperbolic geometry, we propose Hyperbolic Rotary Positional Encoding (HoPE), which leverages hyperbolic functions to implement Lorentz rotations on token representations. Theoretical analysis demonstrates that RoPE is a special case of our generalized formulation. HoPE fundamentally resolves RoPE's slation issues by enforcing monotonic decay of attention weights with increasing token distances. Extensive experimental results, including perplexity evaluations under several extended sequence benchmarks, show that HoPE consistently exceeds existing positional encoding methods. These findings underscore HoPE's enhanced capacity for representing and generalizing long-range dependencies. Data and code will be available.</li>
</ul>

<h3>Title: CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models</h3>
<ul>
<li><strong>Authors: </strong>Aysenur Kocak, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05230">https://arxiv.org/abs/2509.05230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05230">https://arxiv.org/pdf/2509.05230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05230]] CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models(https://arxiv.org/abs/2509.05230)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Pre-trained language models have achieved remarkable success across diverse applications but remain susceptible to spurious, concept-driven correlations that impair robustness and fairness. In this work, we introduce CURE, a novel and lightweight framework that systematically disentangles and suppresses conceptual shortcuts while preserving essential content information. Our method first extracts concept-irrelevant representations via a dedicated content extractor reinforced by a reversal network, ensuring minimal loss of task-relevant information. A subsequent controllable debiasing module employs contrastive learning to finely adjust the influence of residual conceptual cues, enabling the model to either diminish harmful biases or harness beneficial correlations as appropriate for the target task. Evaluated on the IMDB and Yelp datasets using three pre-trained architectures, CURE achieves an absolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp, while introducing minimal computational overhead. Our approach establishes a flexible, unsupervised blueprint for combating conceptual biases, paving the way for more reliable and fair language understanding systems.</li>
</ul>

<h3>Title: A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems</h3>
<ul>
<li><strong>Authors: </strong>Jehad Jilan, Niranjana Naveen Nambiar, Ahmad Mohammad Saber, Alok Paranjape, Amr Youssef, Deepa Kundur</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05259">https://arxiv.org/abs/2509.05259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05259">https://arxiv.org/pdf/2509.05259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05259]] A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems(https://arxiv.org/abs/2509.05259)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, interpretability</a></li>
<li><strong>Abstract: </strong>Automatic Generation Control (AGC) is essential for power grid stability but remains vulnerable to stealthy cyberattacks, such as False Data Injection Attacks (FDIAs), which can disturb the system's stability while evading traditional detection methods. Unlike previous works that relied on blackbox approaches, this work proposes Kolmogorov-Arnold Networks (KAN) as an interpretable and accurate method for FDIA detection in AGC systems, considering the system nonlinearities. KAN models include a method for extracting symbolic equations, and are thus able to provide more interpretability than the majority of machine learning models. The proposed KAN is trained offline to learn the complex nonlinear relationships between the AGC measurements under different operating scenarios. After training, symbolic formulas that describe the trained model's behavior can be extracted and leveraged, greatly enhancing interpretability. Our findings confirm that the proposed KAN model achieves FDIA detection rates of up to 95.97% and 95.9% for the initial model and the symbolic formula, respectively, with a low false alarm rate, offering a reliable approach to enhancing AGC cybersecurity.</li>
</ul>

<h3>Title: On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Zijian Wang, Wei Tong, Tingxuan Han, Haoyu Chen, Tianling Zhang, Yunlong Mao, Sheng Zhong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05265">https://arxiv.org/abs/2509.05265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05265">https://arxiv.org/pdf/2509.05265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05265]] On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy(https://arxiv.org/abs/2509.05265)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) combined with local differential privacy (LDP) enables privacy-preserving model training across decentralized data sources. However, the decentralized data-management paradigm leaves LDPFL vulnerable to participants with malicious intent. The robustness of LDPFL protocols, particularly against model poisoning attacks (MPA), where adversaries inject malicious updates to disrupt global model convergence, remains insufficiently studied. In this paper, we propose a novel and extensible model poisoning attack framework tailored for LDPFL settings. Our approach is driven by the objective of maximizing the global training loss while adhering to local privacy constraints. To counter robust aggregation mechanisms such as Multi-Krum and trimmed mean, we develop adaptive attacks that embed carefully crafted constraints into a reverse training process, enabling evasion of these defenses. We evaluate our framework across three representative LDPFL protocols, three benchmark datasets, and two types of deep neural networks. Additionally, we investigate the influence of data heterogeneity and privacy budgets on attack effectiveness. Experimental results demonstrate that our adaptive attacks can significantly degrade the performance of the global model, revealing critical vulnerabilities and highlighting the need for more robust LDPFL defense strategies against MPA. Our code is available at this https URL</li>
</ul>

<h3>Title: SpikingBrain Technical Report: Spiking Brain-inspired Large Models</h3>
<ul>
<li><strong>Authors: </strong>Yuqi Pan, Yupeng Feng, Jinghao Zhuang, Siyu Ding, Zehao Liu, Bohan Sun, Yuhong Chou, Han Xu, Xuerui Qiu, Anlin Deng, Anjie Hu, Peng Zhou, Man Yao, Jibin Wu, Jian Yang, Guoliang Sun, Bo Xu, Guoqi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05276">https://arxiv.org/abs/2509.05276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05276">https://arxiv.org/pdf/2509.05276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05276]] SpikingBrain Technical Report: Spiking Brain-inspired Large Models(https://arxiv.org/abs/2509.05276)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Mainstream Transformer-based large language models face major efficiency bottlenecks: training computation scales quadratically with sequence length, and inference memory grows linearly, limiting long-context processing. Building large models on non-NVIDIA platforms also poses challenges for stable and efficient training. To address this, we introduce SpikingBrain, a family of brain-inspired models designed for efficient long-context training and inference. SpikingBrain leverages the MetaX GPU cluster and focuses on three aspects: (1) Model Architecture: linear and hybrid-linear attention architectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an efficient, conversion-based training pipeline and a dedicated spike coding framework; (3) System Engineering: customized training frameworks, operator libraries, and parallelism strategies tailored to MetaX hardware. Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM, and SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the feasibility of large-scale LLM development on non-NVIDIA platforms. SpikingBrain achieves performance comparable to open-source Transformer baselines while using only about 150B tokens for continual pre-training. Our models significantly improve long-sequence training efficiency and deliver inference with (partially) constant memory and event-driven spiking behavior. For example, SpikingBrain-7B attains over 100x speedup in Time to First Token for 4M-token sequences. Training remains stable for weeks on hundreds of MetaX C550 GPUs, with the 7B model reaching a Model FLOPs Utilization of 23.4 percent. The proposed spiking scheme achieves 69.15 percent sparsity, enabling low-power operation. Overall, this work demonstrates the potential of brain-inspired mechanisms to drive the next generation of efficient and scalable large model design.</li>
</ul>

<h3>Title: Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Deniz Bayazit, Aaron Mueller, Antoine Bosselut</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05291">https://arxiv.org/abs/2509.05291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05291">https://arxiv.org/pdf/2509.05291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05291]] Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining(https://arxiv.org/abs/2509.05291)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) learn non-trivial abstractions during pretraining, like detecting irregular plural noun subjects. However, it is not well understood when and how specific linguistic abilities emerge as traditional evaluation methods such as benchmarking fail to reveal how models acquire concepts and capabilities. To bridge this gap and better understand model training at the concept level, we use sparse crosscoders to discover and align features across model checkpoints. Using this approach, we track the evolution of linguistic features during pretraining. We train crosscoders between open-sourced checkpoint triplets with significant performance and representation shifts, and introduce a novel metric, Relative Indirect Effects (RelIE), to trace training stages at which individual features become causally important for task performance. We show that crosscoders can detect feature emergence, maintenance, and discontinuation during pretraining. Our approach is architecture-agnostic and scalable, offering a promising path toward more interpretable and fine-grained analysis of representation learning throughout pretraining.</li>
</ul>

<h3>Title: Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest</h3>
<ul>
<li><strong>Authors: </strong>Xiao Yang, Mehdi Ben Ayed, Longyu Zhao, Fan Zhou, Yuchen Shen, Abe Engle, Jinfeng Zhuang, Ling Leng, Jiajing Xu, Charles Rosenberg, Prathibha Deshikachar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.05292">https://arxiv.org/abs/2509.05292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.05292">https://arxiv.org/pdf/2509.05292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.05292]] Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest(https://arxiv.org/abs/2509.05292)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The ranking utility function in an ad recommender system, which linearly combines predictions of various business goals, plays a central role in balancing values across the platform, advertisers, and users. Traditional manual tuning, while offering simplicity and interpretability, often yields suboptimal results due to its unprincipled tuning objectives, the vast amount of parameter combinations, and its lack of personalization and adaptability to seasonality. In this work, we propose a general Deep Reinforcement Learning framework for Personalized Utility Tuning (DRL-PUT) to address the challenges of multi-objective optimization within ad recommender systems. Our key contributions include: 1) Formulating the problem as a reinforcement learning task: given the state of an ad request, we predict the optimal hyperparameters to maximize a pre-defined reward. 2) Developing an approach to directly learn an optimal policy model using online serving logs, avoiding the need to estimate a value function, which is inherently challenging due to the high variance and unbalanced distribution of immediate rewards. We evaluated DRL-PUT through an online A/B experiment in Pinterest's ad recommender system. Compared to the baseline manual utility tuning approach, DRL-PUT improved the click-through rate by 9.7% and the long click-through rate by 7.7% on the treated segment. We conducted a detailed ablation study on the impact of different reward definitions and analyzed the personalization aspect of the learned policy model.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
