<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Efficiency-Improved Inter-Rollup Transfer System Leveraging Batch Settlement Methods. (arXiv:2305.19514v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19514">http://arxiv.org/abs/2305.19514</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19514] Efficiency-Improved Inter-Rollup Transfer System Leveraging Batch Settlement Methods](http://arxiv.org/abs/2305.19514) #secure</code></li>
<li>Summary: <p>As the significance of blockchain innovation grows and the focus on
scalability intensifies, rollup technology has emerged as a promising approach
to tackle these scalability concerns. Nonetheless, rollups encounter
restrictions when interacting with other rollups, leading to diminished
throughput, increased latency, higher fees, and a complex user experience in
transactions between rollups. In this paper, we put forth a novel system that
employs batch settlement techniques to augment the efficiency of transfers
between rollups. Our proposed system comprises a settlement rollup responsible
for batch settling transfers among rollups and a smart contract structure that
carries out the settlements. Notably, we utilize a zero-knowledge proof
algorithm to guarantee the computational integrity of the settlement rollup
while ensuring security through Ethereum smart contracts for proof verification
and settlement execution. By implementing this approach, the proposed system
can effectively and securely execute asset transfers between rollups,
ultimately improving their scalability and usability. Consequently, our
research provides a fresh perspective on resolving the challenges of
throughput, latency, and fees associated with transfer systems.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: An Insider Threat Mitigation Framework Using Attribute Based Access Control. (arXiv:2305.19477v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19477">http://arxiv.org/abs/2305.19477</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19477] An Insider Threat Mitigation Framework Using Attribute Based Access Control](http://arxiv.org/abs/2305.19477) #security</code></li>
<li>Summary: <p>Insider Threat is a significant and potentially dangerous security issue in
corporate settings. It is difficult to mitigate because, unlike external
threats, insiders have knowledge of an organization's access policies, access
hierarchy, access protocols, and access scheduling. Several approaches to
reducing insider threat have been proposed in the literature. However, the
integration of access control and moving target defense (MTD) for deceiving
insiders has not been adequately discussed. In this paper, we combine MTD,
deception, and attribute-based access control to make it more difficult and
expensive for an insider to gain unauthorized access. We introduce the concept
of correlated attributes into ABAC and extend the ABAC model with MTD by
generating mutated policy using the correlated attributes for insider threat
mitigation. The evaluation results show that the proposed framework can
effectively identify correlated attributes and produce adequate mutated policy
without affecting the usability of the access control systems.
</p></li>
</ul>

<h3>Title: Adoption of Blockchain Platform for Security Enhancement in Energy Transaction. (arXiv:2305.19490v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19490">http://arxiv.org/abs/2305.19490</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19490] Adoption of Blockchain Platform for Security Enhancement in Energy Transaction](http://arxiv.org/abs/2305.19490) #security</code></li>
<li>Summary: <p>Renewable energy has become a reality in the present and is being preferred
by countries to become a considerable part of the central grid. With the
increasing adoption of renewables it will soon become crucial to have a
platform which would facilitate secure transaction of energy for consumers as
well as producers. This paper discusses and implements a Blockchain based
platform which enhances and establishes a secure method to exchange energy. It
would also lower the operation costs and accommodate other technologies like
the IoT. A basic market mechanism has been developed for peer-to-peer (P2P)
transaction of energy where different types of entities can be directly
involved. Another concept which is discussed in the paper is the consensus
mechanism and whether the model market could hold the security and privacy of
the individual users.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Quantifying Overfitting: Evaluating Neural Network Performance through Analysis of Null Space. (arXiv:2305.19424v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19424">http://arxiv.org/abs/2305.19424</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19424] Quantifying Overfitting: Evaluating Neural Network Performance through Analysis of Null Space](http://arxiv.org/abs/2305.19424) #privacy</code></li>
<li>Summary: <p>Machine learning models that are overfitted/overtrained are more vulnerable
to knowledge leakage, which poses a risk to privacy. Suppose we download or
receive a model from a third-party collaborator without knowing its training
accuracy. How can we determine if it has been overfitted or overtrained on its
training data? It's possible that the model was intentionally over-trained to
make it vulnerable during testing. While an overfitted or overtrained model may
perform well on testing data and even some generalization tests, we can't be
sure it's not over-fitted. Conducting a comprehensive generalization test is
also expensive. The goal of this paper is to address these issues and ensure
the privacy and generalization of our method using only testing data. To
achieve this, we analyze the null space in the last layer of neural networks,
which enables us to quantify overfitting without access to training data or
knowledge of the accuracy of those data. We evaluated our approach on various
architectures and datasets and observed a distinct pattern in the angle of null
space when models are overfitted. Furthermore, we show that models with poor
generalization exhibit specific characteristics in this space. Our work
represents the first attempt to quantify overfitting without access to training
data or knowing any knowledge about the training samples.
</p></li>
</ul>

<h3>Title: Concentrated Geo-Privacy. (arXiv:2305.19756v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19756">http://arxiv.org/abs/2305.19756</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19756] Concentrated Geo-Privacy](http://arxiv.org/abs/2305.19756) #privacy</code></li>
<li>Summary: <p>This paper proposes concentrated geo-privacy (CGP), a privacy notion that can
be considered as the counterpart of concentrated differential privacy (CDP) for
geometric data. Compared with the previous notion of geo-privacy [ABCP13,
CABP13], which is the counterpart of standard differential privacy, CGP offers
many benefits including simplicity of the mechanism, lower noise scale in high
dimensions, and better composability known as advanced composition. The last
one is the most important, as it allows us to design complex mechanisms using
smaller building blocks while achieving better utilities. To complement this
result, we show that the previous notion of geo-privacy inherently does not
admit advanced composition even using its approximate version. Next, we study
three problems on private geometric data: the identity query, k nearest
neighbors, and convex hulls. While the first problem has been previously
studied, we give the first mechanisms for the latter two under geo-privacy. For
all three problems, composability is essential in obtaining good utility
guarantees on the privatized query answer.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Examining risks of racial biases in NLP tools for child protective services. (arXiv:2305.19409v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19409">http://arxiv.org/abs/2305.19409</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19409] Examining risks of racial biases in NLP tools for child protective services](http://arxiv.org/abs/2305.19409) #protect</code></li>
<li>Summary: <p>Although much literature has established the presence of demographic bias in
natural language processing (NLP) models, most work relies on curated bias
metrics that may not be reflective of real-world applications. At the same
time, practitioners are increasingly using algorithmic tools in high-stakes
settings, with particular recent interest in NLP. In this work, we focus on one
such setting: child protective services (CPS). CPS workers often write copious
free-form text notes about families they are working with, and CPS agencies are
actively seeking to deploy NLP models to leverage these data. Given
well-established racial bias in this setting, we investigate possible ways
deployed NLP is liable to increase racial disparities. We specifically examine
word statistics within notes and algorithmic fairness in risk prediction,
coreference resolution, and named entity recognition (NER). We document
consistent algorithmic unfairness in NER models, possible algorithmic
unfairness in coreference resolution models, and little evidence of exacerbated
racial bias in risk prediction. While there is existing pronounced criticism of
risk prediction, our results expose previously undocumented risks of racial
bias in realistic information extraction systems, highlighting potential
concerns in deploying them, even though they may appear more benign. Our work
serves as a rare realistic examination of NLP algorithmic fairness in a
potential deployed setting and a timely investigation of a specific risk
associated with deploying NLP in CPS settings.
</p></li>
</ul>

<h3>Title: Red Teaming Language Model Detectors with Language Models. (arXiv:2305.19713v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19713">http://arxiv.org/abs/2305.19713</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19713] Red Teaming Language Model Detectors with Language Models](http://arxiv.org/abs/2305.19713) #protect</code></li>
<li>Summary: <p>The prevalence and high capacity of large language models (LLMs) present
significant safety and ethical risks when malicious users exploit them for
automated content generation. To prevent the potentially deceptive usage of
LLMs, recent works have proposed several algorithms to detect machine-generated
text. In this paper, we systematically test the reliability of the existing
detectors, by designing two types of attack strategies to fool the detectors:
1) replacing words with their synonyms based on the context; 2) altering the
writing style of generated text. These strategies are implemented by
instructing LLMs to generate synonymous word substitutions or writing
directives that modify the style without human involvement, and the LLMs
leveraged in the attack can also be protected by detectors. Our research
reveals that our attacks effectively compromise the performance of all tested
detectors, thereby underscoring the urgent need for the development of more
robust machine-generated text detection systems.
</p></li>
</ul>

<h3>Title: You Can Run But You Can't Hide: Runtime Protection Against Malicious Package Updates For Node.js. (arXiv:2305.19760v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19760">http://arxiv.org/abs/2305.19760</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19760] You Can Run But You Can't Hide: Runtime Protection Against Malicious Package Updates For Node](http://arxiv.org/abs/2305.19760) #protect</code></li>
<li>Summary: <p>Maliciously prepared software packages are an extensively leveraged weapon
for software supply chain attacks. The detection of malicious packages is
undoubtedly of high priority and many academic and commercial approaches have
been developed. In the inevitable case of an attack, one needs resilience
against malicious code. To this end, we present a runtime protection for
Node.js that automatically limits a package's capabilities to an established
minimum. The detection of required capabilities as well as their enforcement at
runtime has been implemented and evaluated against known malicious attacks. Our
approach was able to prevent 9/10 historic attacks with a median install-time
overhead of less than 0.6 seconds and a median runtime overhead of less than
0.2 seconds.
</p></li>
</ul>

<h3>Title: A Hybrid Blockchain-Edge Architecture for Electronic Health Records Management with Attribute-based Cryptographic Mechanisms. (arXiv:2305.19797v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19797">http://arxiv.org/abs/2305.19797</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19797] A Hybrid Blockchain-Edge Architecture for Electronic Health Records Management with Attribute-based Cryptographic Mechanisms](http://arxiv.org/abs/2305.19797) #protect</code></li>
<li>Summary: <p>This paper presents a hybrid blockchain-edge architecture for managing
Electronic Health Records (EHRs) with attribute-based cryptographic mechanisms.
The architecture introduces a novel attribute-based signature aggregation
(ABSA) scheme and multi-authority attribute-based encryption (MA-ABE)
integrated with Paillier homomorphic encryption (HE) to protect patients'
anonymity and safeguard their EHRs. All the EHR activities and access control
events are recorded permanently as blockchain transactions. We develop the ABSA
module on Hyperledger Ursa cryptography library, MA-ABE module on OpenABE
toolset, and blockchain network on Hyperledger Fabric. We measure the execution
time of ABSA's signing and verification functions, MA-ABE with different access
policies and homomorphic encryption schemes, and compare the results with other
existing blockchain-based EHR systems. We validate the access activities and
authentication events recorded in blockchain transactions and evaluate the
transaction throughput and latency using Hyperledger Caliper. The results show
that the performance meets real-world scenarios' requirements while
safeguarding EHR and is robust against unauthorized retrievals.
</p></li>
</ul>

<h3>Title: Perimeter Control Using Deep Reinforcement Learning: A Model-free Approach towards Homogeneous Flow Rate Optimization. (arXiv:2305.19291v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19291">http://arxiv.org/abs/2305.19291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19291] Perimeter Control Using Deep Reinforcement Learning: A Model-free Approach towards Homogeneous Flow Rate Optimization](http://arxiv.org/abs/2305.19291) #protect</code></li>
<li>Summary: <p>Perimeter control maintains high traffic efficiency within protected regions
by controlling transfer flows among regions to ensure that their traffic
densities are below critical values. Existing approaches can be categorized as
either model-based or model-free, depending on whether they rely on network
transmission models (NTMs) and macroscopic fundamental diagrams (MFDs).
Although model-based approaches are more data efficient and have performance
guarantees, they are inherently prone to model bias and inaccuracy. For
example, NTMs often become imprecise for a large number of protected regions,
and MFDs can exhibit scatter and hysteresis that are not captured in existing
model-based works. Moreover, no existing studies have employed reinforcement
learning for homogeneous flow rate optimization in microscopic simulation,
where spatial characteristics, vehicle-level information, and metering
realizations -- often overlooked in macroscopic simulations -- are taken into
account. To circumvent issues of model-based approaches and macroscopic
simulation, we propose a model-free deep reinforcement learning approach that
optimizes the flow rate homogeneously at the perimeter at the microscopic
level. Results demonstrate that our model-free reinforcement learning approach
without any knowledge of NTMs or MFDs can compete and match the performance of
a model-based approach, and exhibits enhanced generalizability and scalability.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems. (arXiv:2305.19607v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19607">http://arxiv.org/abs/2305.19607</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19607] Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems](http://arxiv.org/abs/2305.19607) #defense</code></li>
<li>Summary: <p>Clean-label (CL) attack is a form of data poisoning attack where an adversary
modifies only the textual input of the training data, without requiring access
to the labeling function. CL attacks are relatively unexplored in NLP, as
compared to label flipping (LF) attacks, where the latter additionally requires
access to the labeling function as well. While CL attacks are more resilient to
data sanitization and manual relabeling methods than LF attacks, they often
demand as high as ten times the poisoning budget than LF attacks. In this work,
we first introduce an Adversarial Clean Label attack which can adversarially
perturb in-class training examples for poisoning the training set. We then show
that an adversary can significantly bring down the data requirements for a CL
attack, using the aforementioned approach, to as low as 20% of the data
otherwise required. We then systematically benchmark and analyze a number of
defense methods, for both LF and CL attacks, some previously employed solely
for LF attacks in the textual domain and others adapted from computer vision.
We find that text-specific defenses greatly vary in their effectiveness
depending on their properties.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: UKP-SQuARE: An Interactive Tool for Teaching Question Answering. (arXiv:2305.19748v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19748">http://arxiv.org/abs/2305.19748</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19748] UKP-SQuARE: An Interactive Tool for Teaching Question Answering](http://arxiv.org/abs/2305.19748) #attack</code></li>
<li>Summary: <p>The exponential growth of question answering (QA) has made it an
indispensable topic in any Natural Language Processing (NLP) course.
Additionally, the breadth of QA derived from this exponential growth makes it
an ideal scenario for teaching related NLP topics such as information
retrieval, explainability, and adversarial attacks among others. In this paper,
we introduce UKP-SQuARE as a platform for QA education. This platform provides
an interactive environment where students can run, compare, and analyze various
QA models from different perspectives, such as general behavior,
explainability, and robustness. Therefore, students can get a first-hand
experience in different QA techniques during the class. Thanks to this, we
propose a learner-centered approach for QA education in which students
proactively learn theoretical concepts and acquire problem-solving skills
through interactive exploration, experimentation, and practical assignments,
rather than solely relying on traditional lectures. To evaluate the
effectiveness of UKP-SQuARE in teaching scenarios, we adopted it in a
postgraduate NLP course and surveyed the students after the course. Their
positive feedback shows the platform's effectiveness in their course and
invites a wider adoption.
</p></li>
</ul>

<h3>Title: SPGNN-API: A Transferable Graph Neural Network for Attack Paths Identification and Autonomous Mitigation. (arXiv:2305.19487v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19487">http://arxiv.org/abs/2305.19487</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19487] SPGNN-API: A Transferable Graph Neural Network for Attack Paths Identification and Autonomous Mitigation](http://arxiv.org/abs/2305.19487) #attack</code></li>
<li>Summary: <p>Attack paths are the potential chain of malicious activities an attacker
performs to compromise network assets and acquire privileges through exploiting
network vulnerabilities. Attack path analysis helps organizations to identify
new/unknown chains of attack vectors that reach critical assets within the
network, as opposed to individual attack vectors in signature-based attack
analysis. Timely identification of attack paths enables proactive mitigation of
threats. Nevertheless, manual analysis of complex network configurations,
vulnerabilities, and security events to identify attack paths is rarely
feasible. This work proposes a novel transferable graph neural network-based
model for shortest path identification. The proposed shortest path detection
approach, integrated with a novel holistic and comprehensive model for
identifying potential network vulnerabilities interactions, is then utilized to
detect network attack paths. Our framework automates the risk assessment of
attack paths indicating the propensity of the paths to enable the compromise of
highly-critical assets (e.g., databases) given the network configuration,
assets' criticality, and the severity of the vulnerabilities in-path to the
asset. The proposed framework, named SPGNN-API, incorporates automated threat
mitigation through a proactive timely tuning of the network firewall rules and
zero-trust policies to break critical attack paths and bolster cyber defenses.
Our evaluation process is twofold; evaluating the performance of the shortest
path identification and assessing the attack path detection accuracy. Our
results show that SPGNN-API largely outperforms the baseline model for shortest
path identification with an average accuracy >= 95% and successfully detects
100% of the potentially compromised assets, outperforming the attack graph
baseline by 47%.
</p></li>
</ul>

<h3>Title: Incremental Randomized Smoothing Certification. (arXiv:2305.19521v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19521">http://arxiv.org/abs/2305.19521</a></li>
<li>Code URL: <a href="https://github.com/uiuc-arc/incremental-dnn-verification">https://github.com/uiuc-arc/incremental-dnn-verification</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19521] Incremental Randomized Smoothing Certification](http://arxiv.org/abs/2305.19521) #attack</code></li>
<li>Summary: <p>Randomized smoothing-based certification is an effective approach for
obtaining robustness certificates of deep neural networks (DNNs) against
adversarial attacks. This method constructs a smoothed DNN model and certifies
its robustness through statistical sampling, but it is computationally
expensive, especially when certifying with a large number of samples.
Furthermore, when the smoothed model is modified (e.g., quantized or pruned),
certification guarantees may not hold for the modified DNN, and recertifying
from scratch can be prohibitively expensive.
</p></li>
</ul>

<p>We present the first approach for incremental robustness certification for
randomized smoothing, IRS. We show how to reuse the certification guarantees
for the original smoothed model to certify an approximated model with very few
samples. IRS significantly reduces the computational cost of certifying
modified DNNs while maintaining strong robustness guarantees. We experimentally
demonstrate the effectiveness of our approach, showing up to 3x certification
speedup over the certification that applies randomized smoothing of the
approximate model from scratch.
</p>

<h3>Title: Exploring the Vulnerabilities of Machine Learning and Quantum Machine Learning to Adversarial Attacks using a Malware Dataset: A Comparative Analysis. (arXiv:2305.19593v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19593">http://arxiv.org/abs/2305.19593</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19593] Exploring the Vulnerabilities of Machine Learning and Quantum Machine Learning to Adversarial Attacks using a Malware Dataset: A Comparative Analysis](http://arxiv.org/abs/2305.19593) #attack</code></li>
<li>Summary: <p>The burgeoning fields of machine learning (ML) and quantum machine learning
(QML) have shown remarkable potential in tackling complex problems across
various domains. However, their susceptibility to adversarial attacks raises
concerns when deploying these systems in security sensitive applications. In
this study, we present a comparative analysis of the vulnerability of ML and
QML models, specifically conventional neural networks (NN) and quantum neural
networks (QNN), to adversarial attacks using a malware dataset. We utilize a
software supply chain attack dataset known as ClaMP and develop two distinct
models for QNN and NN, employing Pennylane for quantum implementations and
TensorFlow and Keras for traditional implementations. Our methodology involves
crafting adversarial samples by introducing random noise to a small portion of
the dataset and evaluating the impact on the models performance using accuracy,
precision, recall, and F1 score metrics. Based on our observations, both ML and
QML models exhibit vulnerability to adversarial attacks. While the QNNs
accuracy decreases more significantly compared to the NN after the attack, it
demonstrates better performance in terms of precision and recall, indicating
higher resilience in detecting true positives under adversarial conditions. We
also find that adversarial samples crafted for one model type can impair the
performance of the other, highlighting the need for robust defense mechanisms.
Our study serves as a foundation for future research focused on enhancing the
security and resilience of ML and QML models, particularly QNN, given its
recent advancements. A more extensive range of experiments will be conducted to
better understand the performance and robustness of both models in the face of
adversarial attacks.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Cones 2: Customizable Image Synthesis with Multiple Subjects. (arXiv:2305.19327v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19327">http://arxiv.org/abs/2305.19327</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19327] Cones 2: Customizable Image Synthesis with Multiple Subjects](http://arxiv.org/abs/2305.19327) #robust</code></li>
<li>Summary: <p>Synthesizing images with user-specified subjects has received growing
attention due to its practical applications. Despite the recent success in
single subject customization, existing algorithms suffer from high training
cost and low success rate along with increased number of subjects. Towards
controllable image synthesis with multiple subjects as the constraints, this
work studies how to efficiently represent a particular subject as well as how
to appropriately compose different subjects. We find that the text embedding
regarding the subject token already serves as a simple yet effective
representation that supports arbitrary combinations without any model tuning.
Through learning a residual on top of the base embedding, we manage to robustly
shift the raw subject to the customized subject given various text conditions.
We then propose to employ layout, a very abstract and easy-to-obtain prior, as
the spatial guidance for subject arrangement. By rectifying the activations in
the cross-attention map, the layout appoints and separates the location of
different subjects in the image, significantly alleviating the interference
across them. Both qualitative and quantitative experimental results demonstrate
our superiority over state-of-the-art alternatives under a variety of settings
for multi-subject customization.
</p></li>
</ul>

<h3>Title: Contextual Vision Transformers for Robust Representation Learning. (arXiv:2305.19402v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19402">http://arxiv.org/abs/2305.19402</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19402] Contextual Vision Transformers for Robust Representation Learning](http://arxiv.org/abs/2305.19402) #robust</code></li>
<li>Summary: <p>We present Contextual Vision Transformers (ContextViT), a method for
producing robust feature representations for images exhibiting grouped
structure such as covariates. ContextViT introduces an extra context token to
encode group-specific information, allowing the model to explain away
group-specific covariate structures while keeping core visual features shared
across groups. Specifically, given an input image, Context-ViT maps images that
share the same covariate into this context token appended to the input image
tokens to capture the effects of conditioning the model on group membership. We
furthermore introduce a context inference network to predict such tokens on the
fly given a few samples from a group distribution, enabling ContextViT to
generalize to new testing distributions at inference time. We illustrate the
performance of ContextViT through a diverse range of applications. In
supervised fine-tuning, we demonstrate that augmenting pre-trained ViTs with
additional context conditioning leads to significant improvements in
out-of-distribution generalization on iWildCam and FMoW. We also explored
self-supervised representation learning with ContextViT. Our experiments on the
Camelyon17 pathology imaging benchmark and the cpg-0000 microscopy imaging
benchmark demonstrate that ContextViT excels in learning stable image
featurizations amidst covariate shift, consistently outperforming its ViT
counterpart.
</p></li>
</ul>

<h3>Title: A Computational Account Of Self-Supervised Visual Learning From Egocentric Object Play. (arXiv:2305.19445v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19445">http://arxiv.org/abs/2305.19445</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19445] A Computational Account Of Self-Supervised Visual Learning From Egocentric Object Play](http://arxiv.org/abs/2305.19445) #robust</code></li>
<li>Summary: <p>Research in child development has shown that embodied experience handling
physical objects contributes to many cognitive abilities, including visual
learning. One characteristic of such experience is that the learner sees the
same object from several different viewpoints. In this paper, we study how
learning signals that equate different viewpoints -- e.g., assigning similar
representations to different views of a single object -- can support robust
visual learning. We use the Toybox dataset, which contains egocentric videos of
humans manipulating different objects, and conduct experiments using a computer
vision framework for self-supervised contrastive learning. We find that
representations learned by equating different physical viewpoints of an object
benefit downstream image classification accuracy. Further experiments show that
this performance improvement is robust to variations in the gaps between
viewpoints, and that the benefits transfer to several different image
classification tasks.
</p></li>
</ul>

<h3>Title: Learning by Aligning 2D Skeleton Sequences in Time. (arXiv:2305.19480v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19480">http://arxiv.org/abs/2305.19480</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19480] Learning by Aligning 2D Skeleton Sequences in Time](http://arxiv.org/abs/2305.19480) #robust</code></li>
<li>Summary: <p>This paper presents a novel self-supervised temporal video alignment
framework which is useful for several fine-grained human activity understanding
applications. In contrast with the state-of-the-art method of CASA, where
sequences of 3D skeleton coordinates are taken directly as input, our key idea
is to use sequences of 2D skeleton heatmaps as input. Given 2D skeleton
heatmaps, we utilize a video transformer which performs self-attention in the
spatial and temporal domains for extracting effective spatiotemporal and
contextual features. In addition, we introduce simple heatmap augmentation
techniques based on 2D skeletons for self-supervised learning. Despite the lack
of 3D information, our approach achieves not only higher accuracy but also
better robustness against missing and noisy keypoints than CASA. Extensive
evaluations on three public datasets, i.e., Penn Action, IKEA ASM, and H2O,
demonstrate that our approach outperforms previous methods in different
fine-grained human activity understanding tasks, i.e., phase classification,
phase progression, video alignment, and fine-grained frame retrieval.
</p></li>
</ul>

<h3>Title: Spotlight Attention: Robust Object-Centric Learning With a Spatial Locality Prior. (arXiv:2305.19550v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19550">http://arxiv.org/abs/2305.19550</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19550] Spotlight Attention: Robust Object-Centric Learning With a Spatial Locality Prior](http://arxiv.org/abs/2305.19550) #robust</code></li>
<li>Summary: <p>The aim of object-centric vision is to construct an explicit representation
of the objects in a scene. This representation is obtained via a set of
interchangeable modules called \emph{slots} or \emph{object files} that compete
for local patches of an image. The competition has a weak inductive bias to
preserve spatial continuity; consequently, one slot may claim patches scattered
diffusely throughout the image. In contrast, the inductive bias of human vision
is strong, to the degree that attention has classically been described with a
spotlight metaphor. We incorporate a spatial-locality prior into
state-of-the-art object-centric vision models and obtain significant
improvements in segmenting objects in both synthetic and real-world datasets.
Similar to human visual attention, the combination of image content and spatial
constraints yield robust unsupervised object-centric learning, including less
sensitivity to model hyperparameters.
</p></li>
</ul>

<h3>Title: Neural Kernel Surface Reconstruction. (arXiv:2305.19590v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19590">http://arxiv.org/abs/2305.19590</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19590] Neural Kernel Surface Reconstruction](http://arxiv.org/abs/2305.19590) #robust</code></li>
<li>Summary: <p>We present a novel method for reconstructing a 3D implicit surface from a
large-scale, sparse, and noisy point cloud. Our approach builds upon the
recently introduced Neural Kernel Fields (NKF) representation. It enjoys
similar generalization capabilities to NKF, while simultaneously addressing its
main limitations: (a) We can scale to large scenes through compactly supported
kernel functions, which enable the use of memory-efficient sparse linear
solvers. (b) We are robust to noise, through a gradient fitting solve. (c) We
minimize training requirements, enabling us to learn from any dataset of dense
oriented points, and even mix training data consisting of objects and scenes at
different scales. Our method is capable of reconstructing millions of points in
a few seconds, and handling very large scenes in an out-of-core fashion. We
achieve state-of-the-art results on reconstruction benchmarks consisting of
single objects, indoor scenes, and outdoor scenes.
</p></li>
</ul>

<h3>Title: Mask, Stitch, and Re-Sample: Enhancing Robustness and Generalizability in Anomaly Detection through Automatic Diffusion Models. (arXiv:2305.19643v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19643">http://arxiv.org/abs/2305.19643</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19643] Mask, Stitch, and Re-Sample: Enhancing Robustness and Generalizability in Anomaly Detection through Automatic Diffusion Models](http://arxiv.org/abs/2305.19643) #robust</code></li>
<li>Summary: <p>The introduction of diffusion models in anomaly detection has paved the way
for more effective and accurate image reconstruction in pathologies. However,
the current limitations in controlling noise granularity hinder diffusion
models' ability to generalize across diverse anomaly types and compromise the
restoration of healthy tissues. To overcome these challenges, we propose
AutoDDPM, a novel approach that enhances the robustness of diffusion models.
AutoDDPM utilizes diffusion models to generate initial likelihood maps of
potential anomalies and seamlessly integrates them with the original image.
Through joint noised distribution re-sampling, AutoDDPM achieves harmonization
and in-painting effects. Our study demonstrates the efficacy of AutoDDPM in
replacing anomalous regions while preserving healthy tissues, considerably
surpassing diffusion models' limitations. It also contributes valuable insights
and analysis on the limitations of current diffusion models, promoting robust
and interpretable anomaly detection in medical imaging - an essential aspect of
building autonomous clinical decision systems with higher interpretability.
</p></li>
</ul>

<h3>Title: Ambiguity in solving imaging inverse problems with deep learning based operators. (arXiv:2305.19774v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19774">http://arxiv.org/abs/2305.19774</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19774] Ambiguity in solving imaging inverse problems with deep learning based operators](http://arxiv.org/abs/2305.19774) #robust</code></li>
<li>Summary: <p>In recent years, large convolutional neural networks have been widely used as
tools for image deblurring, because of their ability in restoring images very
precisely. It is well known that image deblurring is mathematically modeled as
an ill-posed inverse problem and its solution is difficult to approximate when
noise affects the data. Really, one limitation of neural networks for
deblurring is their sensitivity to noise and other perturbations, which can
lead to instability and produce poor reconstructions. In addition, networks do
not necessarily take into account the numerical formulation of the underlying
imaging problem, when trained end-to-end. In this paper, we propose some
strategies to improve stability without losing to much accuracy to deblur
images with deep-learning based methods. First, we suggest a very small neural
architecture, which reduces the execution time for training, satisfying a green
AI need, and does not extremely amplify noise in the computed image. Second, we
introduce a unified framework where a pre-processing step balances the lack of
stability of the following, neural network-based, step. Two different
pre-processors are presented: the former implements a strong parameter-free
denoiser, and the latter is a variational model-based regularized formulation
of the latent imaging problem. This framework is also formally characterized by
mathematical analysis. Numerical experiments are performed to verify the
accuracy and stability of the proposed approaches for image deblurring when
unknown or not-quantified noise is present; the results confirm that they
improve the network stability with respect to noise. In particular, the
model-based framework represents the most reliable trade-off between visual
precision and robustness.
</p></li>
</ul>

<h3>Title: Breeding Machine Translations: Evolutionary approach to survive and thrive in the world of automated evaluation. (arXiv:2305.19330v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19330">http://arxiv.org/abs/2305.19330</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19330] Breeding Machine Translations: Evolutionary approach to survive and thrive in the world of automated evaluation](http://arxiv.org/abs/2305.19330) #robust</code></li>
<li>Summary: <p>We propose a genetic algorithm (GA) based method for modifying n-best lists
produced by a machine translation (MT) system. Our method offers an innovative
approach to improving MT quality and identifying weaknesses in evaluation
metrics. Using common GA operations (mutation and crossover) on a list of
hypotheses in combination with a fitness function (an arbitrary MT metric), we
obtain novel and diverse outputs with high metric scores. With a combination of
multiple MT metrics as the fitness function, the proposed method leads to an
increase in translation quality as measured by other held-out automatic
metrics. With a single metric (including popular ones such as COMET) as the
fitness function, we find blind spots and flaws in the metric. This allows for
an automated search for adversarial examples in an arbitrary metric, without
prior assumptions on the form of such example. As a demonstration of the
method, we create datasets of adversarial examples and use them to show that
reference-free COMET is substantially less robust than the reference-based
version.
</p></li>
</ul>

<h3>Title: The Tag-Team Approach: Leveraging CLS and Language Tagging for Enhancing Multilingual ASR. (arXiv:2305.19584v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19584">http://arxiv.org/abs/2305.19584</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19584] The Tag-Team Approach: Leveraging CLS and Language Tagging for Enhancing Multilingual ASR](http://arxiv.org/abs/2305.19584) #robust</code></li>
<li>Summary: <p>Building a multilingual Automated Speech Recognition (ASR) system in a
linguistically diverse country like India can be a challenging task due to the
differences in scripts and the limited availability of speech data. This
problem can be solved by exploiting the fact that many of these languages are
phonetically similar. These languages can be converted into a Common Label Set
(CLS) by mapping similar sounds to common labels. In this paper, new approaches
are explored and compared to improve the performance of CLS based multilingual
ASR model. Specific language information is infused in the ASR model by giving
Language ID or using CLS to Native script converter on top of the CLS
Multilingual model. These methods give a significant improvement in Word Error
Rate (WER) compared to the CLS baseline. These methods are further tried on
out-of-distribution data to check their robustness.
</p></li>
</ul>

<h3>Title: Assessing Word Importance Using Models Trained for Semantic Tasks. (arXiv:2305.19689v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19689">http://arxiv.org/abs/2305.19689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19689] Assessing Word Importance Using Models Trained for Semantic Tasks](http://arxiv.org/abs/2305.19689) #robust</code></li>
<li>Summary: <p>Many NLP tasks require to automatically identify the most significant words
in a text. In this work, we derive word significance from models trained to
solve semantic task: Natural Language Inference and Paraphrase Identification.
Using an attribution method aimed to explain the predictions of these models,
we derive importance scores for each input token. We evaluate their relevance
using a so-called cross-task evaluation: Analyzing the performance of one model
on an input masked according to the other model's weight, we show that our
method is robust with respect to the choice of the initial task. Additionally,
we investigate the scores from the syntax point of view and observe interesting
patterns, e.g. words closer to the root of a syntactic tree receive higher
importance scores. Altogether, these observations suggest that our method can
be used to identify important words in sentences without any explicit word
importance labeling in training.
</p></li>
</ul>

<h3>Title: Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios. (arXiv:2305.19757v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19757">http://arxiv.org/abs/2305.19757</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19757] Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios](http://arxiv.org/abs/2305.19757) #robust</code></li>
<li>Summary: <p>We tackle the task of automatically discriminating between human and machine
translations. As opposed to most previous work, we perform experiments in a
multilingual setting, considering multiple languages and multilingual
pretrained language models. We show that a classifier trained on parallel data
with a single source language (in our case German-English) can still perform
well on English translations that come from different source languages, even
when the machine translations were produced by other systems than the one it
was trained on. Additionally, we demonstrate that incorporating the source text
in the input of a multilingual classifier improves (i) its accuracy and (ii)
its robustness on cross-system evaluation, compared to a monolingual
classifier. Furthermore, we find that using training data from multiple source
languages (German, Russian, and Chinese) tends to improve the accuracy of both
monolingual and multilingual classifiers. Finally, we show that bilingual
classifiers and classifiers trained on multiple source languages benefit from
being trained on longer text sequences, rather than on sentences.
</p></li>
</ul>

<h3>Title: Deep into The Domain Shift: Transfer Learning through Dependence Regularization. (arXiv:2305.19499v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19499">http://arxiv.org/abs/2305.19499</a></li>
<li>Code URL: <a href="https://github.com/yzr1991/deep_into_the_domain_shift">https://github.com/yzr1991/deep_into_the_domain_shift</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19499] Deep into The Domain Shift: Transfer Learning through Dependence Regularization](http://arxiv.org/abs/2305.19499) #robust</code></li>
<li>Summary: <p>Classical Domain Adaptation methods acquire transferability by regularizing
the overall distributional discrepancies between features in the source domain
(labeled) and features in the target domain (unlabeled). They often do not
differentiate whether the domain differences come from the marginals or the
dependence structures. In many business and financial applications, the
labeling function usually has different sensitivities to the changes in the
marginals versus changes in the dependence structures. Measuring the overall
distributional differences will not be discriminative enough in acquiring
transferability. Without the needed structural resolution, the learned transfer
is less optimal. This paper proposes a new domain adaptation approach in which
one can measure the differences in the internal dependence structure separately
from those in the marginals. By optimizing the relative weights among them, the
new regularization strategy greatly relaxes the rigidness of the existing
approaches. It allows a learning machine to pay special attention to places
where the differences matter the most. Experiments on three real-world datasets
show that the improvements are quite notable and robust compared to various
benchmark domain adaptation models.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Global Layers: Non-IID Tabular Federated Learning. (arXiv:2305.19290v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19290">http://arxiv.org/abs/2305.19290</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19290] Global Layers: Non-IID Tabular Federated Learning](http://arxiv.org/abs/2305.19290) #federate</code></li>
<li>Summary: <p>Data heterogeneity between clients remains a key challenge in Federated
Learning (FL), particularly in the case of tabular data. This work presents
Global Layers (GL), a novel partial model personalization method robust in the
presence of joint distribution $P(X,Y)$ shift and mixed input/output spaces $X
\times Y$ across clients. To the best of our knowledge, GL is the first method
capable of supporting both client-exclusive features and classes. We introduce
two new benchmark experiments for tabular FL naturally partitioned from
existing real world datasets: i) UCI Covertype split into 4 clients by
"wilderness area" feature, and ii) UCI Heart Disease, SAHeart, UCI Heart
Failure, each as clients. Empirical results in these experiments in the
full-participant setting show that GL achieves better outcomes than Federated
Averaging (FedAvg) and local-only training, with some clients even performing
better than their centralized baseline.
</p></li>
</ul>

<h3>Title: SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning. (arXiv:2305.19442v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19442">http://arxiv.org/abs/2305.19442</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19442] SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning](http://arxiv.org/abs/2305.19442) #federate</code></li>
<li>Summary: <p>Federated bilevel optimization (FBO) has shown great potential recently in
machine learning and edge computing due to the emerging nested optimization
structure in meta-learning, fine-tuning, hyperparameter tuning, etc. However,
existing FBO algorithms often involve complicated computations and require
multiple sub-loops per iteration, each of which contains a number of
communication rounds. In this paper, we propose a simple and flexible FBO
framework named SimFBO, which is easy to implement without sub-loops, and
includes a generalized server-side aggregation and update for improving
communication efficiency. We further propose System-level heterogeneity robust
FBO (ShroFBO) as a variant of SimFBO with stronger resilience to heterogeneous
local computation. We show that SimFBO and ShroFBO provably achieve a linear
convergence speedup with partial client participation and client sampling
without replacement, as well as improved sample and communication complexities.
Experiments demonstrate the effectiveness of the proposed methods over existing
FBO algorithms.
</p></li>
</ul>

<h3>Title: Federated Learning on Heterogeneous Data via Adaptive Self-Distillation. (arXiv:2305.19600v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19600">http://arxiv.org/abs/2305.19600</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19600] Federated Learning on Heterogeneous Data via Adaptive Self-Distillation](http://arxiv.org/abs/2305.19600) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) is a machine learning paradigm that enables clients
to jointly train a global model by aggregating the locally trained models
without sharing any local training data. In practice, there can often be
substantial heterogeneity (e.g., class imbalance) across the local data
distributions observed by each of these clients. Under such non-iid data
distributions across clients, FL suffers from the 'client-drift' problem where
every client converges to its own local optimum. This results in slower
convergence and poor performance of the aggregated model. To address this
limitation, we propose a novel regularization technique based on adaptive
self-distillation (ASD) for training models on the client side. Our
regularization scheme adaptively adjusts to the client's training data based
on: (1) the closeness of the local model's predictions with that of the global
model and (2) the client's label distribution. The proposed regularization can
be easily integrated atop existing, state-of-the-art FL algorithms leading to a
further boost in the performance of these off-the-shelf methods. We demonstrate
the efficacy of our proposed FL approach through extensive experiments on
multiple real-world benchmarks (including datasets with common corruptions and
perturbations) and show substantial gains in performance over the
state-of-the-art methods.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Mitigating Test-Time Bias for Fair Image Retrieval. (arXiv:2305.19329v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19329">http://arxiv.org/abs/2305.19329</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19329] Mitigating Test-Time Bias for Fair Image Retrieval](http://arxiv.org/abs/2305.19329) #fair</code></li>
<li>Summary: <p>We address the challenge of generating fair and unbiased image retrieval
results given neutral textual queries (with no explicit gender or race
connotations), while maintaining the utility (performance) of the underlying
vision-language (VL) model. Previous methods aim to disentangle learned
representations of images and text queries from gender and racial
characteristics. However, we show these are inadequate at alleviating bias for
the desired equal representation result, as there usually exists test-time bias
in the target retrieval set. So motivated, we introduce a straightforward
technique, Post-hoc Bias Mitigation (PBM), that post-processes the outputs from
the pre-trained vision-language model. We evaluate our algorithm on real-world
image search datasets, Occupation 1 and 2, as well as two large-scale
image-text datasets, MS-COCO and Flickr30k. Our approach achieves the lowest
bias, compared with various existing bias-mitigation methods, in text-based
image retrieval result while maintaining satisfactory retrieval performance.
The source code is publicly available at
\url{https://anonymous.4open.science/r/Fair_Text_based_Image_Retrieval-D8B2}.
</p></li>
</ul>

<h3>Title: XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech. (arXiv:2305.19709v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19709">http://arxiv.org/abs/2305.19709</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19709] XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech](http://arxiv.org/abs/2305.19709) #fair</code></li>
<li>Summary: <p>We present XPhoneBERT, the first multilingual model pre-trained to learn
phoneme representations for the downstream text-to-speech (TTS) task. Our
XPhoneBERT has the same model architecture as BERT-base, trained using the
RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100
languages and locales. Experimental results show that employing XPhoneBERT as
an input phoneme encoder significantly boosts the performance of a strong
neural TTS model in terms of naturalness and prosody and also helps produce
fairly high-quality speech with limited training data. We publicly release our
pre-trained XPhoneBERT with the hope that it would facilitate future research
and downstream TTS applications for multiple languages. Our XPhoneBERT model is
available at https://github.com/VinAIResearch/XPhoneBERT
</p></li>
</ul>

<h3>Title: Pointwise Representational Similarity. (arXiv:2305.19294v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19294">http://arxiv.org/abs/2305.19294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19294] Pointwise Representational Similarity](http://arxiv.org/abs/2305.19294) #fair</code></li>
<li>Summary: <p>With the increasing reliance on deep neural networks, it is important to
develop ways to better understand their learned representations. Representation
similarity measures have emerged as a popular tool for examining learned
representations However, existing measures only provide aggregate estimates of
similarity at a global level, i.e. over a set of representations for N input
examples. As such, these measures are not well-suited for investigating
representations at a local level, i.e. representations of a single input
example. Local similarity measures are needed, for instance, to understand
which individual input representations are affected by training interventions
to models (e.g. to be more fair and unbiased) or are at greater risk of being
misclassified. In this work, we fill in this gap and propose Pointwise
Normalized Kernel Alignment (PNKA), a measure that quantifies how similarly an
individual input is represented in two representation spaces. Intuitively, PNKA
compares the similarity of an input's neighborhoods across both spaces. Using
our measure, we are able to analyze properties of learned representations at a
finer granularity than what was previously possible. Concretely, we show how
PNKA can be leveraged to develop a deeper understanding of (a) the input
examples that are likely to be misclassified, (b) the concepts encoded by
(individual) neurons in a layer, and (c) the effects of fairness interventions
on learned representations.
</p></li>
</ul>

<h3>Title: Adapting Fairness Interventions to Missing Values. (arXiv:2305.19429v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19429">http://arxiv.org/abs/2305.19429</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19429] Adapting Fairness Interventions to Missing Values](http://arxiv.org/abs/2305.19429) #fair</code></li>
<li>Summary: <p>Missing values in real-world data pose a significant and unique challenge to
algorithmic fairness. Different demographic groups may be unequally affected by
missing data, and the standard procedure for handling missing values where
first data is imputed, then the imputed data is used for classification -- a
procedure referred to as "impute-then-classify" -- can exacerbate
discrimination. In this paper, we analyze how missing values affect algorithmic
fairness. We first prove that training a classifier from imputed data can
significantly worsen the achievable values of group fairness and average
accuracy. This is because imputing data results in the loss of the missing
pattern of the data, which often conveys information about the predictive
label. We present scalable and adaptive algorithms for fair classification with
missing values. These algorithms can be combined with any preexisting
fairness-intervention algorithm to handle all possible missing patterns while
preserving information encoded within the missing patterns. Numerical
experiments with state-of-the-art fairness interventions demonstrate that our
adaptive algorithms consistently achieve higher fairness and accuracy than
impute-then-classify across different datasets.
</p></li>
</ul>

<h3>Title: Doubly Constrained Fair Clustering. (arXiv:2305.19475v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19475">http://arxiv.org/abs/2305.19475</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19475] Doubly Constrained Fair Clustering](http://arxiv.org/abs/2305.19475) #fair</code></li>
<li>Summary: <p>The remarkable attention which fair clustering has received in the last few
years has resulted in a significant number of different notions of fairness.
Despite the fact that these notions are well-justified, they are often
motivated and studied in a disjoint manner where one fairness desideratum is
considered exclusively in isolation from the others. This leaves the
understanding of the relations between different fairness notions as an
important open problem in fair clustering. In this paper, we take the first
step in this direction. Specifically, we consider the two most prominent
demographic representation fairness notions in clustering: (1) Group Fairness
(GF), where the different demographic groups are supposed to have close to
population-level representation in each cluster and (2) Diversity in Center
Selection (DS), where the selected centers are supposed to have close to
population-level representation of each group. We show that given a constant
approximation algorithm for one constraint (GF or DS only) we can obtain a
constant approximation solution that satisfies both constraints simultaneously.
Interestingly, we prove that any given solution that satisfies the GF
constraint can always be post-processed at a bounded degradation to the
clustering cost to additionally satisfy the DS constraint while the reverse is
not true. Furthermore, we show that both GF and DS are incompatible (having an
empty feasibility set in the worst case) with a collection of other
distance-based fairness notions. Finally, we carry experiments to validate our
theoretical findings.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: CVSNet: A Computer Implementation for Central Visual System of The Brain. (arXiv:2305.19492v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19492">http://arxiv.org/abs/2305.19492</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19492] CVSNet: A Computer Implementation for Central Visual System of The Brain](http://arxiv.org/abs/2305.19492) #interpretability</code></li>
<li>Summary: <p>In computer vision, different basic blocks are created around different
matrix operations, and models based on different basic blocks have achieved
good results. Good results achieved in vision tasks grants them rationality.
However, these experimental-based models also make deep learning long
criticized for principle and interpretability. Deep learning originated from
the concept of neurons in neuroscience, but recent designs detached natural
neural networks except for some simple concepts. In this paper, we build an
artificial neural network, CVSNet, which can be seen as a computer
implementation for central visual system of the brain. Each block in CVSNet
represents the same vision information as that in brains. In CVSNet, blocks
differs from each other and visual information flows through three independent
pathways and five different blocks. Thus CVSNet is completely different from
the design of all previous models, in which basic blocks are repeated to build
model and information between channels is mixed at the outset. In ablation
experiment, we show the information extracted by blocks in CVSNet and compare
with previous networks, proving effectiveness and rationality of blocks in
CVSNet from experiment side. And in the experiment of object recognition,
CVSNet achieves comparable results to ConvNets, Vision Transformers and MLPs.
</p></li>
</ul>

<h3>Title: Signal Is Harder To Learn Than Bias: Debiasing with Focal Loss. (arXiv:2305.19671v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19671">http://arxiv.org/abs/2305.19671</a></li>
<li>Code URL: <a href="https://github.com/mvandenhi/signal-is-harder">https://github.com/mvandenhi/signal-is-harder</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19671] Signal Is Harder To Learn Than Bias: Debiasing with Focal Loss](http://arxiv.org/abs/2305.19671) #interpretability</code></li>
<li>Summary: <p>Spurious correlations are everywhere. While humans often do not perceive
them, neural networks are notorious for learning unwanted associations, also
known as biases, instead of the underlying decision rule. As a result,
practitioners are often unaware of the biased decision-making of their
classifiers. Such a biased model based on spurious correlations might not
generalize to unobserved data, leading to unintended, adverse consequences. We
propose Signal is Harder (SiH), a variational-autoencoder-based method that
simultaneously trains a biased and unbiased classifier using a novel,
disentangling reweighting scheme inspired by the focal loss. Using the unbiased
classifier, SiH matches or improves upon the performance of state-of-the-art
debiasing methods. To improve the interpretability of our technique, we propose
a perturbation scheme in the latent space for visualizing the bias that helps
practitioners become aware of the sources of spurious correlations.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Label-Retrieval-Augmented Diffusion Models for Learning from Noisy Labels. (arXiv:2305.19518v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19518">http://arxiv.org/abs/2305.19518</a></li>
<li>Code URL: <a href="https://github.com/puar-playground/lra-diffusion">https://github.com/puar-playground/lra-diffusion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19518] Label-Retrieval-Augmented Diffusion Models for Learning from Noisy Labels](http://arxiv.org/abs/2305.19518) #diffusion</code></li>
<li>Summary: <p>Learning from noisy labels is an important and long-standing problem in
machine learning for real applications. One of the main research lines focuses
on learning a label corrector to purify potential noisy labels. However, these
methods typically rely on strict assumptions and are limited to certain types
of label noise. In this paper, we reformulate the label-noise problem from a
generative-model perspective, $\textit{i.e.}$, labels are generated by
gradually refining an initial random guess. This new perspective immediately
enables existing powerful diffusion models to seamlessly learn the stochastic
generative process. Once the generative uncertainty is modeled, we can perform
classification inference using maximum likelihood estimation of labels. To
mitigate the impact of noisy labels, we propose the
$\textbf{L}$abel-$\textbf{R}$etrieval-$\textbf{A}$ugmented (LRA) diffusion
model, which leverages neighbor consistency to effectively construct
pseudo-clean labels for diffusion training. Our model is flexible and general,
allowing easy incorporation of different types of conditional information,
$\textit{e.g.}$, use of pre-trained models, to further boost model performance.
Extensive experiments are conducted for evaluation. Our model achieves new
state-of-the-art (SOTA) results on all the standard real-world benchmark
datasets. Remarkably, by incorporating conditional information from the
powerful CLIP model, our method can boost the current SOTA accuracy by 10-20
absolute points in many cases.
</p></li>
</ul>

<h3>Title: Improving Handwritten OCR with Training Samples Generated by Glyph Conditional Denoising Diffusion Probabilistic Model. (arXiv:2305.19543v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19543">http://arxiv.org/abs/2305.19543</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19543] Improving Handwritten OCR with Training Samples Generated by Glyph Conditional Denoising Diffusion Probabilistic Model](http://arxiv.org/abs/2305.19543) #diffusion</code></li>
<li>Summary: <p>Constructing a highly accurate handwritten OCR system requires large amounts
of representative training data, which is both time-consuming and expensive to
collect. To mitigate the issue, we propose a denoising diffusion probabilistic
model (DDPM) to generate training samples. This model conditions on a printed
glyph image and creates mappings between printed characters and handwritten
images, thus enabling the generation of photo-realistic handwritten samples
with diverse styles and unseen text contents. However, the text contents in
synthetic images are not always consistent with the glyph conditional images,
leading to unreliable labels of synthetic samples. To address this issue, we
further propose a progressive data filtering strategy to add those samples with
a high confidence of correctness to the training set. Experimental results on
IAM benchmark task show that OCR model trained with augmented DDPM-synthesized
training samples can achieve about 45% relative word error rate reduction
compared with the one trained on real data only.
</p></li>
</ul>

<h3>Title: Boosting Text-to-Image Diffusion Models with Fine-Grained Semantic Rewards. (arXiv:2305.19599v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19599">http://arxiv.org/abs/2305.19599</a></li>
<li>Code URL: <a href="https://github.com/enderfga/finerewards">https://github.com/enderfga/finerewards</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19599] Boosting Text-to-Image Diffusion Models with Fine-Grained Semantic Rewards](http://arxiv.org/abs/2305.19599) #diffusion</code></li>
<li>Summary: <p>Recent advances in text-to-image diffusion models have achieved remarkable
success in generating high-quality, realistic images from given text prompts.
However, previous methods fail to perform accurate modality alignment between
text concepts and generated images due to the lack of fine-level semantic
guidance that successfully diagnoses the modality discrepancy. In this paper,
we propose FineRewards to improve the alignment between text and images in
text-to-image diffusion models by introducing two new fine-grained semantic
rewards: the caption reward and the Semantic Segment Anything (SAM) reward.
From the global semantic view, the caption reward generates a corresponding
detailed caption that depicts all important contents in the synthetic image via
a BLIP-2 model and then calculates the reward score by measuring the similarity
between the generated caption and the given prompt. From the local semantic
view, the SAM reward segments the generated images into local parts with
category labels, and scores the segmented parts by measuring the likelihood of
each category appearing in the prompted scene via a large language model, i.e.,
Vicuna-7B. Additionally, we adopt an assemble reward-ranked learning strategy
to enable the integration of multiple reward functions to jointly guide the
model training. Adapting results of text-to-image models on the MS-COCO
benchmark show that the proposed semantic reward outperforms other baseline
reward functions with a considerable margin on both visual quality and semantic
similarity with the input prompt. Moreover, by adopting the assemble
reward-ranked learning strategy, we further demonstrate that model performance
is further improved when adapting under the unifying of the proposed semantic
reward with the current image rewards.
</p></li>
</ul>

<h3>Title: Spontaneous symmetry breaking in generative diffusion models. (arXiv:2305.19693v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19693">http://arxiv.org/abs/2305.19693</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19693] Spontaneous symmetry breaking in generative diffusion models](http://arxiv.org/abs/2305.19693) #diffusion</code></li>
<li>Summary: <p>Generative diffusion models have recently emerged as a leading approach for
generating high-dimensional data. In this paper, we show that the dynamics of
these models exhibit a spontaneous symmetry breaking that divides the
generative dynamics into two distinct phases: 1) A linear steady-state dynamics
around a central fixed-point and 2) an attractor dynamics directed towards the
data manifold. These two "phases" are separated by the change in stability of
the central fixed-point, with the resulting window of instability being
responsible for the diversity of the generated samples. Using both theoretical
and empirical evidence, we show that an accurate simulation of the early
dynamics does not significantly contribute to the final generation, since early
fluctuations are reverted to the central fixed point. To leverage this insight,
we propose a Gaussian late initialization scheme, which significantly improves
model performance, achieving up to 3x FID improvements on fast samplers, while
also increasing sample diversity (e.g., racial composition of generated CelebA
images). Our work offers a new way to understand the generative dynamics of
diffusion models that has the potential to bring about higher performance and
less biased fast-samplers.
</p></li>
</ul>

<h3>Title: Fine-grained Text Style Transfer with Diffusion-Based Language Models. (arXiv:2305.19512v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19512">http://arxiv.org/abs/2305.19512</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19512] Fine-grained Text Style Transfer with Diffusion-Based Language Models](http://arxiv.org/abs/2305.19512) #diffusion</code></li>
<li>Summary: <p>Diffusion probabilistic models have shown great success in generating
high-quality images controllably, and researchers have tried to utilize this
controllability into text generation domain. Previous works on diffusion-based
language models have shown that they can be trained without external knowledge
(such as pre-trained weights) and still achieve stable performance and
controllability. In this paper, we trained a diffusion-based model on StylePTB
dataset, the standard benchmark for fine-grained text style transfers. The
tasks in StylePTB requires much more refined control over the output text
compared to tasks evaluated in previous works, and our model was able to
achieve state-of-the-art performance on StylePTB on both individual and
compositional transfers. Moreover, our model, trained on limited data from
StylePTB without external knowledge, outperforms previous works that utilized
pretrained weights, embeddings, and external grammar parsers, and this may
indicate that diffusion-based language models have great potential under
low-resource settings.
</p></li>
</ul>

<h3>Title: Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19685">http://arxiv.org/abs/2305.19685</a></li>
<li>Code URL: <a href="https://github.com/elena-orlova/deep-stochastic-mechanics">https://github.com/elena-orlova/deep-stochastic-mechanics</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19685] Deep Stochastic Mechanics](http://arxiv.org/abs/2305.19685) #diffusion</code></li>
<li>Summary: <p>This paper introduces a novel deep-learning-based approach for numerical
simulation of a time-evolving Schr\"odinger equation inspired by stochastic
mechanics and generative diffusion models. Unlike existing approaches, which
exhibit computational complexity that scales exponentially in the problem
dimension, our method allows us to adapt to the latent low-dimensional
structure of the wave function by sampling from the Markovian diffusion.
Depending on the latent dimension, our method may have far lower computational
complexity in higher dimensions. Moreover, we propose novel equations for
stochastic quantum mechanics, resulting in linear computational complexity with
respect to the number of dimensions. Numerical simulations verify our
theoretical findings and show a significant advantage of our method compared to
other deep-learning-based approaches used for quantum mechanics.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Smooth, exact rotational symmetrization for deep learning on point clouds. (arXiv:2305.19302v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19302">http://arxiv.org/abs/2305.19302</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19302] Smooth, exact rotational symmetrization for deep learning on point clouds](http://arxiv.org/abs/2305.19302) #transformer</code></li>
<li>Summary: <p>Point clouds are versatile representations of 3D objects and have found
widespread application in science and engineering. Many successful
deep-learning models have been proposed that use them as input. Some
application domains require incorporating exactly physical constraints,
including chemical and materials modeling which we focus on in this paper.
These constraints include smoothness, and symmetry with respect to
translations, rotations, and permutations of identical particles. Most existing
architectures in other domains do not fulfill simultaneously all of these
requirements and thus are not applicable to atomic-scale simulations. Many of
them, however, can be straightforwardly made to incorporate all the physical
constraints except for rotational symmetry. We propose a general symmetrization
protocol that adds rotational equivariance to any given model while preserving
all the other constraints. As a demonstration of the potential of this idea, we
introduce the Point Edge Transformer (PET) architecture, which is not
intrinsically equivariant but achieves state-of-the-art performance on several
benchmark datasets of molecules and solids. A-posteriori application of our
general protocol makes PET exactly equivariant, with minimal changes to its
accuracy. By alleviating the need to explicitly incorporate rotational symmetry
within the model, our method bridges the gap between the approaches used in
different communities, and simplifies the design of deep-learning schemes for
chemical and materials modeling.
</p></li>
</ul>

<h3>Title: Vision Transformers for Mobile Applications: A Short Survey. (arXiv:2305.19365v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19365">http://arxiv.org/abs/2305.19365</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19365] Vision Transformers for Mobile Applications: A Short Survey](http://arxiv.org/abs/2305.19365) #transformer</code></li>
<li>Summary: <p>Vision Transformers (ViTs) have demonstrated state-of-the-art performance on
many Computer Vision Tasks. Unfortunately, deploying these large-scale ViTs is
resource-consuming and impossible for many mobile devices. While most in the
community are building for larger and larger ViTs, we ask a completely opposite
question: How small can a ViT be within the tradeoffs of accuracy and inference
latency that make it suitable for mobile deployment? We look into a few ViTs
specifically designed for mobile applications and observe that they modify the
transformer's architecture or are built around the combination of CNN and
transformer. Recent work has also attempted to create sparse ViT networks and
proposed alternatives to the attention module. In this paper, we study these
architectures, identify the challenges and analyze what really makes a vision
transformer suitable for mobile applications. We aim to serve as a baseline for
future research direction and hopefully lay the foundation to choose the
exemplary vision transformer architecture for your application running on
mobile devices.
</p></li>
</ul>

<h3>Title: Are Large Kernels Better Teachers than Transformers for ConvNets?. (arXiv:2305.19412v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19412">http://arxiv.org/abs/2305.19412</a></li>
<li>Code URL: <a href="https://github.com/vita-group/slak">https://github.com/vita-group/slak</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19412] Are Large Kernels Better Teachers than Transformers for ConvNets?](http://arxiv.org/abs/2305.19412) #transformer</code></li>
<li>Summary: <p>This paper reveals a new appeal of the recently emerged large-kernel
Convolutional Neural Networks (ConvNets): as the teacher in Knowledge
Distillation (KD) for small-kernel ConvNets. While Transformers have led
state-of-the-art (SOTA) performance in various fields with ever-larger models
and labeled data, small-kernel ConvNets are considered more suitable for
resource-limited applications due to the efficient convolution operation and
compact weight sharing. KD is widely used to boost the performance of
small-kernel ConvNets. However, previous research shows that it is not quite
effective to distill knowledge (e.g., global information) from Transformers to
small-kernel ConvNets, presumably due to their disparate architectures. We
hereby carry out a first-of-its-kind study unveiling that modern large-kernel
ConvNets, a compelling competitor to Vision Transformers, are remarkably more
effective teachers for small-kernel ConvNets, due to more similar
architectures. Our findings are backed up by extensive experiments on both
logit-level and feature-level KD ``out of the box", with no dedicated
architectural nor training recipe modifications. Notably, we obtain the
\textbf{best-ever pure ConvNet} under 30M parameters with \textbf{83.1\%} top-1
accuracy on ImageNet, outperforming current SOTA methods including ConvNeXt V2
and Swin V2. We also find that beneficial characteristics of large-kernel
ConvNets, e.g., larger effective receptive fields, can be seamlessly
transferred to students through this large-to-small kernel distillation. Code
is available at: \url{https://github.com/VITA-Group/SLaK}.
</p></li>
</ul>

<h3>Title: A Multi-Modal Transformer Network for Action Detection. (arXiv:2305.19624v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19624">http://arxiv.org/abs/2305.19624</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19624] A Multi-Modal Transformer Network for Action Detection](http://arxiv.org/abs/2305.19624) #transformer</code></li>
<li>Summary: <p>This paper proposes a novel multi-modal transformer network for detecting
actions in untrimmed videos. To enrich the action features, our transformer
network utilizes a new multi-modal attention mechanism that computes the
correlations between different spatial and motion modalities combinations.
Exploring such correlations for actions has not been attempted previously. To
use the motion and spatial modality more effectively, we suggest an algorithm
that corrects the motion distortion caused by camera movement. Such motion
distortion, common in untrimmed videos, severely reduces the expressive power
of motion features such as optical flow fields. Our proposed algorithm
outperforms the state-of-the-art methods on two public benchmarks, THUMOS14 and
ActivityNet. We also conducted comparative experiments on our new instructional
activity dataset, including a large set of challenging classroom videos
captured from elementary schools.
</p></li>
</ul>

<h3>Title: Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal Representation. (arXiv:2305.19798v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19798">http://arxiv.org/abs/2305.19798</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19798] Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal Representation](http://arxiv.org/abs/2305.19798) #transformer</code></li>
<li>Summary: <p>Recently, a new line of works has emerged to understand and improve
self-attention in Transformers by treating it as a kernel machine. However,
existing works apply the methods for symmetric kernels to the asymmetric
self-attention, resulting in a nontrivial gap between the analytical
understanding and numerical implementation. In this paper, we provide a new
perspective to represent and optimize self-attention through asymmetric Kernel
Singular Value Decomposition (KSVD), which is also motivated by the low-rank
property of self-attention normally observed in deep layers. Through asymmetric
KSVD, $i$) a primal-dual representation of self-attention is formulated, where
the optimization objective is cast to maximize the projection variances in the
attention outputs; $ii$) a novel attention mechanism, i.e., Primal-Attention,
is proposed via the primal representation of KSVD, avoiding explicit
computation of the kernel matrix in the dual; $iii$) with KKT conditions, we
prove that the stationary solution to the KSVD optimization in Primal-Attention
yields a zero-value objective. In this manner, KSVD optimization can be
implemented by simply minimizing a regularization loss, so that low-rank
property is promoted without extra decomposition. Numerical experiments show
state-of-the-art performance of our Primal-Attention with improved efficiency.
Moreover, we demonstrate that the deployed KSVD optimization regularizes
Primal-Attention with a sharper singular value decay than that of the canonical
self-attention, further verifying the great potential of our method. To the
best of our knowledge, this is the first work that provides a primal-dual
representation for the asymmetric kernel in self-attention and successfully
applies it to modeling and optimization.
</p></li>
</ul>

<h3>Title: Blockwise Parallel Transformer for Long Context Large Models. (arXiv:2305.19370v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19370">http://arxiv.org/abs/2305.19370</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19370] Blockwise Parallel Transformer for Long Context Large Models](http://arxiv.org/abs/2305.19370) #transformer</code></li>
<li>Summary: <p>Transformers have emerged as the cornerstone of state-of-the-art natural
language processing models, showcasing exceptional performance across a wide
range of AI applications. However, the memory demands posed by the
self-attention mechanism and the large feedforward network in Transformers
limit their ability to handle long sequences, thereby creating challenges for
tasks involving multiple long sequences or long-term dependencies. We present a
distinct approach, Blockwise Parallel Transformer (BPT), that leverages
blockwise computation of self-attention and feedforward network fusion to
minimize memory costs. By processing longer input sequences while maintaining
memory efficiency, BPT enables training sequences up to 32 times longer than
vanilla Transformers and 2 to 4 times longer than previous memory-efficient
methods. Extensive experiments on language modeling and reinforcement learning
tasks demonstrate the effectiveness of BPT in reducing memory requirements and
improving performance.
</p></li>
</ul>

<h3>Title: The Impact of Positional Encoding on Length Generalization in Transformers. (arXiv:2305.19466v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19466">http://arxiv.org/abs/2305.19466</a></li>
<li>Code URL: <a href="https://github.com/mcgill-nlp/length-generalization">https://github.com/mcgill-nlp/length-generalization</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19466] The Impact of Positional Encoding on Length Generalization in Transformers](http://arxiv.org/abs/2305.19466) #transformer</code></li>
<li>Summary: <p>Length generalization, the ability to generalize from small training context
sizes to larger ones, is a critical challenge in the development of
Transformer-based language models. Positional encoding (PE) has been identified
as a major factor influencing length generalization, but the exact impact of
different PE schemes on extrapolation in downstream tasks remains unclear. In
this paper, we conduct a systematic empirical study comparing the length
generalization performance of decoder-only Transformers with five different
position encoding approaches including Absolute Position Embedding (APE), T5's
Relative PE, ALiBi, and Rotary, in addition to Transformers without positional
encoding (NoPE). Our evaluation encompasses a battery of reasoning and
mathematical tasks. Our findings reveal that the most commonly used positional
encoding methods, such as ALiBi, Rotary, and APE, are not well suited for
length generalization in downstream tasks. More importantly, NoPE outperforms
other explicit positional encoding methods while requiring no additional
computation. We theoretically demonstrate that NoPE can represent both absolute
and relative PEs, but when trained with SGD, it mostly resembles T5's relative
PE attention patterns. Finally, we find that scratchpad is not always helpful
to solve length generalization and its format highly impacts the model's
performance. Overall, our work suggests that explicit position embeddings are
not essential for decoder-only Transformers to generalize well to longer
sequences.
</p></li>
</ul>

<h3>Title: Accurate and Structured Pruning for Efficient Automatic Speech Recognition. (arXiv:2305.19549v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19549">http://arxiv.org/abs/2305.19549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19549] Accurate and Structured Pruning for Efficient Automatic Speech Recognition](http://arxiv.org/abs/2305.19549) #transformer</code></li>
<li>Summary: <p>Automatic Speech Recognition (ASR) has seen remarkable advancements with deep
neural networks, such as Transformer and Conformer. However, these models
typically have large model sizes and high inference costs, posing a challenge
to deploy on resource-limited devices. In this paper, we propose a novel
compression strategy that leverages structured pruning and knowledge
distillation to reduce the model size and inference cost of the Conformer model
while preserving high recognition performance. Our approach utilizes a set of
binary masks to indicate whether to retain or prune each Conformer module, and
employs L0 regularization to learn the optimal mask values. To further enhance
pruning performance, we use a layerwise distillation strategy to transfer
knowledge from unpruned to pruned models. Our method outperforms all pruning
baselines on the widely used LibriSpeech benchmark, achieving a 50% reduction
in model size and a 28% reduction in inference cost with minimal performance
loss.
</p></li>
</ul>

<h3>Title: LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction. (arXiv:2305.19585v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19585">http://arxiv.org/abs/2305.19585</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19585] LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction](http://arxiv.org/abs/2305.19585) #transformer</code></li>
<li>Summary: <p>Transformer encoders contextualize token representations by attending to all
other tokens at each layer, leading to quadratic increase in compute effort
with the input length. In practice, however, the input text of many NLP tasks
can be seen as a sequence of related segments (e.g., the sequence of sentences
within a passage, or the hypothesis and premise in NLI). While attending across
these segments is highly beneficial for many tasks, we hypothesize that this
interaction can be delayed until later encoding stages.
</p></li>
</ul>

<p>To this end, we introduce Layer-Adjustable Interactions in Transformers
(LAIT). Within LAIT, segmented inputs are first encoded independently, and then
jointly. This partial two-tower architecture bridges the gap between a Dual
Encoder's ability to pre-compute representations for segments and a fully
self-attentive Transformer's capacity to model cross-segment attention. The
LAIT framework effectively leverages existing pretrained Transformers and
converts them into the hybrid of the two aforementioned architectures, allowing
for easy and intuitive control over the performance-efficiency tradeoff.
Experimenting on a wide range of NLP tasks, we find LAIT able to reduce 30-50%
of the attention FLOPs on many tasks, while preserving high accuracy; in some
practical settings, LAIT could reduce actual latency by orders of magnitude.
</p>

<h3>Title: SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT. (arXiv:2305.19589v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19589">http://arxiv.org/abs/2305.19589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19589] SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT](http://arxiv.org/abs/2305.19589) #transformer</code></li>
<li>Summary: <p>Second language acquisition (SLA) research has extensively studied
cross-linguistic transfer, the influence of linguistic structure of a speaker's
native language [L1] on the successful acquisition of a foreign language [L2].
Effects of such transfer can be positive (facilitating acquisition) or negative
(impeding acquisition). We find that NLP literature has not given enough
attention to the phenomenon of negative transfer. To understand patterns of
both positive and negative transfer between L1 and L2, we model sequential
second language acquisition in LMs. Further, we build a Mutlilingual Age
Ordered CHILDES (MAO-CHILDES) -- a dataset consisting of 5 typologically
diverse languages, i.e., German, French, Polish, Indonesian, and Japanese -- to
understand the degree to which native Child-Directed Speech (CDS) [L1] can help
or conflict with English language acquisition [L2]. To examine the impact of
native CDS, we use the TILT-based cross lingual transfer learning approach
established by Papadimitriou and Jurafsky (2020) and find that, as in human
SLA, language family distance predicts more negative transfer. Additionally, we
find that conversational speech data shows greater facilitation for language
acquisition than scripted speech data. Our findings call for further research
using our novel Transformer-based SLA models and we would like to encourage it
by releasing our code, data, and models.
</p></li>
</ul>

<h3>Title: Recasting Self-Attention with Holographic Reduced Representations. (arXiv:2305.19534v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19534">http://arxiv.org/abs/2305.19534</a></li>
<li>Code URL: <a href="https://github.com/neuromorphiccomputationresearchprogram/hrrformer">https://github.com/neuromorphiccomputationresearchprogram/hrrformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19534] Recasting Self-Attention with Holographic Reduced Representations](http://arxiv.org/abs/2305.19534) #transformer</code></li>
<li>Summary: <p>In recent years, self-attention has become the dominant paradigm for sequence
modeling in a variety of domains. However, in domains with very long sequence
lengths the $\mathcal{O}(T^2)$ memory and $\mathcal{O}(T^2 H)$ compute costs
can make using transformers infeasible. Motivated by problems in malware
detection, where sequence lengths of $T \geq 100,000$ are a roadblock to deep
learning, we re-cast self-attention using the neuro-symbolic approach of
Holographic Reduced Representations (HRR). In doing so we perform the same
high-level strategy of the standard self-attention: a set of queries matching
against a set of keys, and returning a weighted response of the values for each
key. Implemented as a ``Hrrformer'' we obtain several benefits including
$\mathcal{O}(T H \log H)$ time complexity, $\mathcal{O}(T H)$ space complexity,
and convergence in $10\times$ fewer epochs. Nevertheless, the Hrrformer
achieves near state-of-the-art accuracy on LRA benchmarks and we are able to
learn with just a single layer. Combined, these benefits make our Hrrformer the
first viable Transformer for such long malware classification sequences and up
to $280\times$ faster to train on the Long Range Arena benchmark. Code is
available at
\url{https://github.com/NeuromorphicComputationResearchProgram/Hrrformer}
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: A Unified GAN Framework Regarding Manifold Alignment for Remote Sensing Images Generation. (arXiv:2305.19507v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19507">http://arxiv.org/abs/2305.19507</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19507] A Unified GAN Framework Regarding Manifold Alignment for Remote Sensing Images Generation](http://arxiv.org/abs/2305.19507) #generative</code></li>
<li>Summary: <p>Generative Adversarial Networks (GANs) and their variants have achieved
remarkable success on natural images. It aims to approximate the distribution
of the training datasets. However, their performance degrades when applied to
remote sensing (RS) images, and the discriminator often suffers from the
overfitting problem. In this paper, we examine the differences between natural
and RS images and find that the intrinsic dimensions of RS images are much
lower than those of natural images. Besides, the low-dimensional data manifold
of RS images may exacerbate the uneven sampling of training datasets and
introduce biased information. The discriminator can easily overfit to the
biased training distribution, leading to a faulty generation model, even the
mode collapse problem. While existing GANs focus on the general distribution of
RS datasets, they often neglect the underlying data manifold. In respond, we
propose a learnable information-theoretic measure that preserves the intrinsic
structures of the original data, and establish a unified GAN framework for
manifold alignment in supervised and unsupervised RS image generation.
</p></li>
</ul>

<h3>Title: DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling. (arXiv:2305.19395v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19395">http://arxiv.org/abs/2305.19395</a></li>
<li>Code URL: <a href="https://github.com/night-chen/dygen">https://github.com/night-chen/dygen</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19395] DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling](http://arxiv.org/abs/2305.19395) #generative</code></li>
<li>Summary: <p>Learning from noisy labels is a challenge that arises in many real-world
applications where training data can contain incorrect or corrupted labels.
When fine-tuning language models with noisy labels, models can easily overfit
the label noise, leading to decreased performance. Most existing methods for
learning from noisy labels use static input features for denoising, but these
methods are limited by the information they can provide on true label
distributions and can result in biased or incorrect predictions. In this work,
we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic
patterns in the embedding space during the fine-tuning process of language
models to improve noisy label predictions. DyGen uses the variational
auto-encoding framework to infer the posterior distributions of true labels
from noisy labels and training dynamics. Additionally, a co-regularization
mechanism is used to minimize the impact of potentially noisy labels and
priors. DyGen demonstrates an average accuracy improvement of 3.10% on two
synthetic noise datasets and 1.48% on three real-world noise datasets compared
to the previous state-of-the-art. Extensive experiments and analyses show the
effectiveness of each component in DyGen. Our code is available for
reproducibility on GitHub.
</p></li>
</ul>

<h3>Title: Recursive Metropolis-Hastings Naming Game: Symbol Emergence in a Multi-agent System based on Probabilistic Generative Models. (arXiv:2305.19761v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19761">http://arxiv.org/abs/2305.19761</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19761] Recursive Metropolis-Hastings Naming Game: Symbol Emergence in a Multi-agent System based on Probabilistic Generative Models](http://arxiv.org/abs/2305.19761) #generative</code></li>
<li>Summary: <p>In the studies on symbol emergence and emergent communication in a population
of agents, a computational model was employed in which agents participate in
various language games. Among these, the Metropolis-Hastings naming game (MHNG)
possesses a notable mathematical property: symbol emergence through MHNG is
proven to be a decentralized Bayesian inference of representations shared by
the agents. However, the previously proposed MHNG is limited to a two-agent
scenario. This paper extends MHNG to an N-agent scenario. The main
contributions of this paper are twofold: (1) we propose the recursive
Metropolis-Hastings naming game (RMHNG) as an N-agent version of MHNG and
demonstrate that RMHNG is an approximate Bayesian inference method for the
posterior distribution over a latent variable shared by agents, similar to
MHNG; and (2) we empirically evaluate the performance of RMHNG on synthetic and
real image data, enabling multiple agents to develop and share a symbol system.
Furthermore, we introduce two types of approximations -- one-sample and
limited-length -- to reduce computational complexity while maintaining the
ability to explain communication in a population of agents. The experimental
findings showcased the efficacy of RMHNG as a decentralized Bayesian inference
for approximating the posterior distribution concerning latent variables, which
are jointly shared among agents, akin to MHNG. Moreover, the utilization of
RMHNG elucidated the agents' capacity to exchange symbols. Furthermore, the
study discovered that even the computationally simplified version of RMHNG
could enable symbols to emerge among the agents.
</p></li>
</ul>

<h3>Title: HiGen: Hierarchical Graph Generative Networks. (arXiv:2305.19337v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19337">http://arxiv.org/abs/2305.19337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19337] HiGen: Hierarchical Graph Generative Networks](http://arxiv.org/abs/2305.19337) #generative</code></li>
<li>Summary: <p>Most real-world graphs exhibit a hierarchical structure, which is often
overlooked by existing graph generation methods. To address this limitation, we
propose a novel graph generative network that captures the hierarchical nature
of graphs and successively generates the graph sub-structures in a
coarse-to-fine fashion. At each level of hierarchy, this model generates
communities in parallel, followed by the prediction of cross-edges between
communities using a separate model. This modular approach results in a highly
scalable graph generative network. Moreover, we model the output distribution
of edges in the hierarchical graph with a multinomial distribution and derive a
recursive factorization for this distribution, enabling us to generate
sub-graphs with integer-valued edge weights in an autoregressive approach.
Empirical studies demonstrate that the proposed generative model can
effectively capture both local and global properties of graphs and achieves
state-of-the-art performance in terms of graph quality on various benchmarks.
</p></li>
</ul>

<h3>Title: Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network. (arXiv:2305.19366v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19366">http://arxiv.org/abs/2305.19366</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19366] Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network](http://arxiv.org/abs/2305.19366) #generative</code></li>
<li>Summary: <p>Generative Flow Networks (GFlowNets), a class of generative models over
discrete and structured sample spaces, have been previously applied to the
problem of inferring the marginal posterior distribution over the directed
acyclic graph (DAG) of a Bayesian Network, given a dataset of observations.
Based on recent advances extending this framework to non-discrete sample
spaces, we propose in this paper to approximate the joint posterior over not
only the structure of a Bayesian Network, but also the parameters of its
conditional probability distributions. We use a single GFlowNet whose sampling
policy follows a two-phase process: the DAG is first generated sequentially one
edge at a time, and then the corresponding parameters are picked once the full
structure is known. Since the parameters are included in the posterior
distribution, this leaves more flexibility for the local probability models of
the Bayesian Network, making our approach applicable even to non-linear models
parametrized by neural networks. We show that our method, called JSP-GFN,
offers an accurate approximation of the joint posterior, while comparing
favorably against existing methods on both simulated and real data.
</p></li>
</ul>

<h3>Title: Efficient Training of Energy-Based Models Using Jarzynski Equality. (arXiv:2305.19414v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19414">http://arxiv.org/abs/2305.19414</a></li>
<li>Code URL: <a href="https://github.com/submissionx12/ebms_jarzynski">https://github.com/submissionx12/ebms_jarzynski</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19414] Efficient Training of Energy-Based Models Using Jarzynski Equality](http://arxiv.org/abs/2305.19414) #generative</code></li>
<li>Summary: <p>Energy-based models (EBMs) are generative models inspired by statistical
physics with a wide range of applications in unsupervised learning. Their
performance is best measured by the cross-entropy (CE) of the model
distribution relative to the data distribution. Using the CE as the objective
for training is however challenging because the computation of its gradient
with respect to the model parameters requires sampling the model distribution.
Here we show how results for nonequilibrium thermodynamics based on Jarzynski
equality together with tools from sequential Monte-Carlo sampling can be used
to perform this computation efficiently and avoid the uncontrolled
approximations made using the standard contrastive divergence algorithm.
Specifically, we introduce a modification of the unadjusted Langevin algorithm
(ULA) in which each walker acquires a weight that enables the estimation of the
gradient of the cross-entropy at any step during GD, thereby bypassing sampling
biases induced by slow mixing of ULA. We illustrate these results with
numerical experiments on Gaussian mixture distributions as well as the MNIST
dataset. We show that the proposed approach outperforms methods based on the
contrastive divergence algorithm in all the considered situations.
</p></li>
</ul>

<h3>Title: Replicability in Reinforcement Learning. (arXiv:2305.19562v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19562">http://arxiv.org/abs/2305.19562</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19562] Replicability in Reinforcement Learning](http://arxiv.org/abs/2305.19562) #generative</code></li>
<li>Summary: <p>We initiate the mathematical study of replicability as an algorithmic
property in the context of reinforcement learning (RL). We focus on the
fundamental setting of discounted tabular MDPs with access to a generative
model. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is
replicable if, with high probability, it outputs the exact same policy after
two executions on i.i.d. samples drawn from the generator when its internal
randomness is the same. We first provide an efficient $\rho$-replicable
algorithm for $(\varepsilon, \delta)$-optimal policy estimation with sample and
time complexity $\widetilde
O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$,
where $N$ is the number of state-action pairs. Next, for the subclass of
deterministic algorithms, we provide a lower bound of order
$\Omega\left(\frac{N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right)$.
Then, we study a relaxed version of replicability proposed by Kalavasis et al.
[2023] called TV indistinguishability. We design a computationally efficient TV
indistinguishable algorithm for policy estimation whose sample complexity is
$\widetilde
O\left(\frac{N^2\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$.
At the cost of $\exp(N)$ running time, we transform these TV indistinguishable
algorithms to $\rho$-replicable ones without increasing their sample
complexity. Finally, we introduce the notion of approximate-replicability where
we only require that two outputted policies are close under an appropriate
statistical divergence (e.g., Renyi) and show an improved sample complexity of
$\widetilde
O\left(\frac{N\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$.
</p></li>
</ul>

<h3>Title: End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization. (arXiv:2305.19684v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19684">http://arxiv.org/abs/2305.19684</a></li>
<li>Code URL: <a href="https://github.com/ishohei220/unbiased_dbm">https://github.com/ishohei220/unbiased_dbm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19684] End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization](http://arxiv.org/abs/2305.19684) #generative</code></li>
<li>Summary: <p>We address the problem of biased gradient estimation in deep Boltzmann
machines (DBMs). The existing method to obtain an unbiased estimator uses a
maximal coupling based on a Gibbs sampler, but when the state is
high-dimensional, it takes a long time to converge. In this study, we propose
to use a coupling based on the Metropolis-Hastings (MH) and to initialize the
state around a local mode of the target distribution. Because of the propensity
of MH to reject proposals, the coupling tends to converge in only one step with
a high probability, leading to high efficiency. We find that our method allows
DBMs to be trained in an end-to-end fashion without greedy pretraining. We also
propose some practical techniques to further improve the performance of DBMs.
We empirically demonstrate that our training algorithm enables DBMs to show
comparable generative performance to other deep generative models, achieving
the FID score of 10.33 for MNIST.
</p></li>
</ul>

<h3>Title: Neural Markov Jump Processes. (arXiv:2305.19744v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19744">http://arxiv.org/abs/2305.19744</a></li>
<li>Code URL: <a href="https://github.com/pseifner/neuralmjp">https://github.com/pseifner/neuralmjp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19744] Neural Markov Jump Processes](http://arxiv.org/abs/2305.19744) #generative</code></li>
<li>Summary: <p>Markov jump processes are continuous-time stochastic processes with a wide
range of applications in both natural and social sciences. Despite their
widespread use, inference in these models is highly non-trivial and typically
proceeds via either Monte Carlo or expectation-maximization methods. In this
work we introduce an alternative, variational inference algorithm for Markov
jump processes which relies on neural ordinary differential equations, and is
trainable via back-propagation. Our methodology learns neural, continuous-time
representations of the observed data, that are used to approximate the initial
distribution and time-dependent transition probability rates of the posterior
Markov jump process. The time-independent rates of the prior process are in
contrast trained akin to generative adversarial networks. We test our approach
on synthetic data sampled from ground-truth Markov jump processes, experimental
switching ion channel data and molecular dynamics simulations. Source code to
reproduce our experiments is available online.
</p></li>
</ul>

<h3>Title: Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya. (arXiv:2305.19779v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19779">http://arxiv.org/abs/2305.19779</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19779] Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya](http://arxiv.org/abs/2305.19779) #generative</code></li>
<li>Summary: <p>Model-based disease mapping remains a fundamental policy-informing tool in
public health and disease surveillance with hierarchical Bayesian models being
the current state-of-the-art approach. When working with areal data, e.g.
aggregates at the administrative unit level such as district or province,
routinely used models rely on the adjacency structure of areal units to account
for spatial correlations. The goal of disease surveillance systems is to track
disease outcomes over time, but this provides challenging in situations of
crises, such as political changes, leading to changes of administrative
boundaries. Kenya is an example of such country. Moreover, adjacency-based
approach ignores the continuous nature of spatial processes and cannot solve
the change-of-support problem, i.e. when administrative boundaries change. We
present a novel, practical, and easy to implement solution relying on a
methodology combining deep generative modelling and fully Bayesian inference.
We build on the recent work of PriorVAE able to encode spatial priors over
small areas with variational autoencoders, to map malaria prevalence in Kenya.
We solve the change-of-support problem arising from Kenya changing its district
boundaries in 2010. We draw realisations of the Gaussian Process (GP) prior
over a fine artificial spatial grid representing continuous space and then
aggregate these realisations to the level of administrative boundaries. The
aggregated values are then encoded using the PriorVAE technique. The trained
priors (aggVAE) are then used at the inference stage instead of the GP priors
within a Markov chain Monte Carlo (MCMC) scheme. We demonstrate that it is
possible to use the flexible and appropriate model for areal data based on
aggregation of continuous priors, and that inference is orders of magnitude
faster when using aggVAE than combining the original GP priors and the
aggregation step.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Large language models improve Alzheimer's disease diagnosis using multi-modality data. (arXiv:2305.19280v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19280">http://arxiv.org/abs/2305.19280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19280] Large language models improve Alzheimer's disease diagnosis using multi-modality data](http://arxiv.org/abs/2305.19280) #large language model</code></li>
<li>Summary: <p>In diagnosing challenging conditions such as Alzheimer's disease (AD),
imaging is an important reference. Non-imaging patient data such as patient
information, genetic data, medication information, cognitive and memory tests
also play a very important role in diagnosis. Effect. However, limited by the
ability of artificial intelligence models to mine such information, most of the
existing models only use multi-modal image data, and cannot make full use of
non-image data. We use a currently very popular pre-trained large language
model (LLM) to enhance the model's ability to utilize non-image data, and
achieved SOTA results on the ADNI dataset.
</p></li>
</ul>

<h3>Title: Stable Anisotropic Regularization. (arXiv:2305.19358v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19358">http://arxiv.org/abs/2305.19358</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19358] Stable Anisotropic Regularization](http://arxiv.org/abs/2305.19358) #large language model</code></li>
<li>Summary: <p>Given the success of Large Language Models (LLMs), there has been
considerable interest in studying the properties of model activations. The
literature overwhelmingly agrees that LLM representations are dominated by a
few ``outlier dimensions'' with exceedingly high variance and magnitude.
Several studies in Natural Language Processing (NLP) have sought to mitigate
the impact of such outlier dimensions and force LLMs to be isotropic (i.e.,
have uniform variance across all dimensions in embedding space). Isotropy is
thought to be a desirable property for LLMs that improves model performance and
more closely aligns textual representations with human intuition. However, many
of the claims regarding isotropy in NLP have been based on the average cosine
similarity of embeddings, which has recently been shown to be a flawed measure
of isotropy. In this paper, we propose I-STAR: IsoScore$^{\star}$-based STable
Anisotropic Regularization, a novel regularization method that can be used to
increase or decrease levels of isotropy in embedding space during training.
I-STAR uses IsoScore$^{\star}$, the first accurate measure of isotropy that is
both differentiable and stable on mini-batch computations. In contrast to
several previous works, we find that \textit{decreasing} isotropy in
contextualized embeddings improves performance on the majority of tasks and
models considered in this paper.
</p></li>
</ul>

<h3>Title: PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning. (arXiv:2305.19472v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19472">http://arxiv.org/abs/2305.19472</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19472] PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning](http://arxiv.org/abs/2305.19472) #large language model</code></li>
<li>Summary: <p>Procedural planning, which entails decomposing a high-level goal into a
sequence of temporally ordered steps, is an important yet intricate task for
machines. It involves integrating common-sense knowledge to reason about
complex contextualized situations that are often counterfactual, e.g.
"scheduling a doctor's appointment without a phone". While current approaches
show encouraging results using large language models (LLMs), they are hindered
by drawbacks such as costly API calls and reproducibility issues. In this
paper, we advocate planning using smaller language models. We present PlaSma, a
novel two-pronged approach to endow small language models with procedural
knowledge and (counterfactual) planning capabilities. More concretely, we
develop symbolic procedural knowledge distillation to enhance the implicit
knowledge in small language models and an inference-time algorithm to
facilitate more structured and accurate reasoning. In addition, we introduce a
novel task, Counterfactual Planning, that requires a revision of a plan to cope
with a counterfactual situation. In both the original and counterfactual
setting, we show that orders-of-magnitude smaller models (770M-11B parameters)
can compete and often surpass their larger teacher models' capabilities.
</p></li>
</ul>

<h3>Title: Large Language Models Are Not Abstract Reasoners. (arXiv:2305.19555v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19555">http://arxiv.org/abs/2305.19555</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19555] Large Language Models Are Not Abstract Reasoners](http://arxiv.org/abs/2305.19555) #large language model</code></li>
<li>Summary: <p>Large Language Models have shown tremendous performance on a large variety of
natural language processing tasks, ranging from text comprehension to common
sense reasoning. However, the mechanisms responsible for this success remain
unknown, and it is unclear whether LLMs can achieve human-like cognitive
capabilities or whether these models are still fundamentally limited. Abstract
reasoning is a fundamental task for cognition, consisting of finding and
applying a general pattern from few data. Evaluating deep neural architectures
on this task could give insight into their potential limitations regarding
reasoning and their broad generalisation abilities, yet this is currently an
under-explored area. In this paper, we perform extensive evaluations of
state-of-the-art LLMs on abstract reasoning tasks, showing that they achieve
very limited performance in contrast with other natural language tasks, and we
investigate the reasons for this difference. We apply techniques that have been
shown to improve performance on other NLP tasks and show that in most cases
their impact on abstract reasoning performance is limited. In the course of
this work, we have generated a new benchmark for evaluating language models on
abstract reasoning tasks.
</p></li>
</ul>

<h3>Title: IDAS: Intent Discovery with Abstractive Summarization. (arXiv:2305.19783v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19783">http://arxiv.org/abs/2305.19783</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19783] IDAS: Intent Discovery with Abstractive Summarization](http://arxiv.org/abs/2305.19783) #large language model</code></li>
<li>Summary: <p>Intent discovery is the task of inferring latent intents from a set of
unlabeled utterances, and is a useful step towards the efficient creation of
new conversational agents. We show that recent competitive methods in intent
discovery can be outperformed by clustering utterances based on abstractive
summaries, i.e., "labels", that retain the core elements while removing
non-essential information. We contribute the IDAS approach, which collects a
set of descriptive utterance labels by prompting a Large Language Model,
starting from a well-chosen seed set of prototypical utterances, to bootstrap
an In-Context Learning procedure to generate labels for non-prototypical
utterances. The utterances and their resulting noisy labels are then encoded by
a frozen pre-trained encoder, and subsequently clustered to recover the latent
intents. For the unsupervised task (without any intent labels) IDAS outperforms
the state-of-the-art by up to +7.42% in standard cluster metrics for the
Banking, StackOverflow, and Transport datasets. For the semi-supervised task
(with labels for a subset of intents) IDAS surpasses 2 recent methods on the
CLINC benchmark without even using labeled data.
</p></li>
</ul>

<h3>Title: Explanations as Features: LLM-Based Features for Text-Attributed Graphs. (arXiv:2305.19523v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19523">http://arxiv.org/abs/2305.19523</a></li>
<li>Code URL: <a href="https://github.com/XiaoxinHe/TAPE">https://github.com/XiaoxinHe/TAPE</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19523] Explanations as Features: LLM-Based Features for Text-Attributed Graphs](http://arxiv.org/abs/2305.19523) #large language model</code></li>
<li>Summary: <p>Representation learning on text-attributed graphs (TAGs) has become a
critical research problem in recent years. A typical example of a TAG is a
paper citation graph, where the text of each paper serves as node attributes.
Most graph neural network (GNN) pipelines handle these text attributes by
transforming them into shallow or hand-crafted features, such as skip-gram or
bag-of-words features. Recent efforts have focused on enhancing these pipelines
with language models. With the advent of powerful large language models (LLMs)
such as GPT, which demonstrate an ability to reason and to utilize general
knowledge, there is a growing need for techniques which combine the textual
modelling abilities of LLMs with the structural learning capabilities of GNNs.
Hence, in this work, we focus on leveraging LLMs to capture textual information
as features, which can be used to boost GNN performance on downstream tasks. A
key innovation is our use of \emph{explanations as features}: we prompt an LLM
to perform zero-shot classification and to provide textual explanations for its
decisions, and find that the resulting explanations can be transformed into
useful and informative features to augment downstream GNNs. Through experiments
we show that our enriched features improve the performance of a variety of GNN
models across different datasets. Notably, we achieve top-1 performance on
\texttt{ogbn-arxiv} by a significant margin over the closest baseline even with
$2.88\times$ lower computation time, as well as top-1 performance on TAG
versions of the widely used \texttt{PubMed} and \texttt{Cora}
benchmarks~\footnote{Our codes and datasets are available at:
\url{https://github.com/XiaoxinHe/TAPE}}.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI. (arXiv:2305.19404v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19404">http://arxiv.org/abs/2305.19404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19404] Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI](http://arxiv.org/abs/2305.19404) #segmentation</code></li>
<li>Summary: <p>Deep learning (DL) models for segmenting various anatomical structures have
achieved great success via a static DL model that is trained in a single source
domain. Yet, the static DL model is likely to perform poorly in a continually
evolving environment, requiring appropriate model updates. In an incremental
learning setting, we would expect that well-trained static models are updated,
following continually evolving target domain data -- e.g., additional lesions
or structures of interest -- collected from different sites, without
catastrophic forgetting. This, however, poses challenges, due to distribution
shifts, additional structures not seen during the initial model training, and
the absence of training data in a source domain. To address these challenges,
in this work, we seek to progressively evolve an ``off-the-shelf" trained
segmentation model to diverse datasets with additional anatomical categories in
a unified manner. Specifically, we first propose a divergence-aware dual-flow
module with balanced rigidity and plasticity branches to decouple old and new
tasks, which is guided by continuous batch renormalization. Then, a
complementary pseudo-label training scheme with self-entropy regularized
momentum MixUp decay is developed for adaptive network optimization. We
evaluated our framework on a brain tumor segmentation task with continually
changing target domains -- i.e., new MRI scanners/modalities with incremental
structures. Our framework was able to well retain the discriminability of
previously learned structures, hence enabling the realistic life-long
segmentation model extension along with the widespread accumulation of big
medical data.
</p></li>
</ul>

<h3>Title: PaintSeg: Training-free Segmentation via Painting. (arXiv:2305.19406v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19406">http://arxiv.org/abs/2305.19406</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19406] PaintSeg: Training-free Segmentation via Painting](http://arxiv.org/abs/2305.19406) #segmentation</code></li>
<li>Summary: <p>The paper introduces PaintSeg, a new unsupervised method for segmenting
objects without any training. We propose an adversarial masked contrastive
painting (AMCP) process, which creates a contrast between the original image
and a painted image in which a masked area is painted using off-the-shelf
generative models. During the painting process, inpainting and outpainting are
alternated, with the former masking the foreground and filling in the
background, and the latter masking the background while recovering the missing
part of the foreground object. Inpainting and outpainting, also referred to as
I-step and O-step, allow our method to gradually advance the target
segmentation mask toward the ground truth without supervision or training.
PaintSeg can be configured to work with a variety of prompts, e.g. coarse
masks, boxes, scribbles, and points. Our experimental results demonstrate that
PaintSeg outperforms existing approaches in coarse mask-prompt, box-prompt, and
point-prompt segmentation tasks, providing a training-free solution suitable
for unsupervised segmentation.
</p></li>
</ul>

<h3>Title: Permutation-Aware Action Segmentation via Unsupervised Frame-to-Segment Alignment. (arXiv:2305.19478v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19478">http://arxiv.org/abs/2305.19478</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19478] Permutation-Aware Action Segmentation via Unsupervised Frame-to-Segment Alignment](http://arxiv.org/abs/2305.19478) #segmentation</code></li>
<li>Summary: <p>This paper presents a novel transformer-based framework for unsupervised
activity segmentation which leverages not only frame-level cues but also
segment-level cues. This is in contrast with previous methods which often rely
on frame-level information only. Our approach begins with a frame-level
prediction module which estimates framewise action classes via a transformer
encoder. The frame-level prediction module is trained in an unsupervised manner
via temporal optimal transport. To exploit segment-level information, we
introduce a segment-level prediction module and a frame-to-segment alignment
module. The former includes a transformer decoder for estimating video
transcripts, while the latter matches frame-level features with segment-level
features, yielding permutation-aware segmentation results. Moreover, inspired
by temporal optimal transport, we develop simple-yet-effective pseudo labels
for unsupervised training of the above modules. Our experiments on four public
datasets, i.e., 50 Salads, YouTube Instructions, Breakfast, and Desktop
Assembly show that our approach achieves comparable or better performance than
previous methods in unsupervised activity segmentation.
</p></li>
</ul>

<h3>Title: Inferring and Leveraging Parts from Object Shape for Improving Semantic Image Synthesis. (arXiv:2305.19547v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19547">http://arxiv.org/abs/2305.19547</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19547] Inferring and Leveraging Parts from Object Shape for Improving Semantic Image Synthesis](http://arxiv.org/abs/2305.19547) #segmentation</code></li>
<li>Summary: <p>Despite the progress in semantic image synthesis, it remains a challenging
problem to generate photo-realistic parts from input semantic map. Integrating
part segmentation map can undoubtedly benefit image synthesis, but is
bothersome and inconvenient to be provided by users. To improve part synthesis,
this paper presents to infer Parts from Object ShapE (iPOSE) and leverage it
for improving semantic image synthesis. However, albeit several part
segmentation datasets are available, part annotations are still not provided
for many object categories in semantic image synthesis. To circumvent it, we
resort to few-shot regime to learn a PartNet for predicting the object part map
with the guidance of pre-defined support part maps. PartNet can be readily
generalized to handle a new object category when a small number (e.g., 3) of
support part maps for this category are provided. Furthermore, part semantic
modulation is presented to incorporate both inferred part map and semantic map
for image synthesis. Experiments show that our iPOSE not only generates objects
with rich part details, but also enables to control the image synthesis
flexibly. And our iPOSE performs favorably against the state-of-the-art methods
in terms of quantitative and qualitative evaluation. Our code will be publicly
available at https://github.com/csyxwei/iPOSE.
</p></li>
</ul>

<h3>Title: DeepMerge: Deep Learning-Based Region-Merging for Image Segmentation. (arXiv:2305.19787v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.19787">http://arxiv.org/abs/2305.19787</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.19787] DeepMerge: Deep Learning-Based Region-Merging for Image Segmentation](http://arxiv.org/abs/2305.19787) #segmentation</code></li>
<li>Summary: <p>Accurate segmentation of large areas from very high spatial-resolution (VHR)
remote sensing imagery remains a challenging issue in image analysis. Existing
supervised and unsupervised methods both suffer from the large variance of
object sizes and the difficulty in scale selection, which often result in poor
segmentation accuracies. To address the above challenges, we propose a deep
learning-based region-merging method (DeepMerge) to handle the segmentation in
large VHR images by integrating a Transformer with a multi-level embedding
module, a segment-based feature embedding module and a region-adjacency graph
model. In addition, we propose a modified binary tree sampling method to
generate multi-level inputs from initial segmentation results, serving as
inputs for the DeepMerge model. To our best knowledge, the proposed method is
the first to use deep learning to learn the similarity between adjacent
segments for region-merging. The proposed DeepMerge method is validated using a
remote sensing image of 0.55m resolution covering an area of 5,660 km^2
acquired from Google Earth. The experimental results show that the proposed
DeepMerge with the highest F value (0.9446) and the lowest TE (0.0962) and ED2
(0.8989) is able to correctly segment objects of different sizes and
outperforms all selected competing segmentation methods from both quantitative
and qualitative assessments.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
