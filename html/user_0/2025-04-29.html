<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-04-29</h1>
<h3>Title: Low-Bit Integerization of Vision Transformers using Operand Reodering for Efficient Hardware</h3>
<ul>
<li><strong>Authors: </strong>Ching-Yi Lin, Sahil Shah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18547">https://arxiv.org/abs/2504.18547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18547">https://arxiv.org/pdf/2504.18547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18547]] Low-Bit Integerization of Vision Transformers using Operand Reodering for Efficient Hardware(https://arxiv.org/abs/2504.18547)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pre-trained vision transformers have achieved remarkable performance across various visual tasks but suffer from expensive computational and memory costs. While model quantization reduces memory usage by lowering precision, these models still incur significant computational overhead due to the dequantization before matrix operations. In this work, we analyze the computation graph and propose an integerization process based on operation reordering. Specifically, the process delays dequantization until after matrix operations. This enables integerized matrix multiplication and linear module by directly processing the quantized input. To validate our approach, we synthesize the self-attention module of ViT on a systolic array-based hardware. Experimental results show that our low-bit inference reduces per-PE power consumption for linear layer and matrix multiplication, bridging the gap between quantized models and efficient inference.</li>
</ul>

<h3>Title: RDI: An adversarial robustness evaluation metric for deep neural networks based on sample clustering features</h3>
<ul>
<li><strong>Authors: </strong>Jialei Song, Xingquan Zuo, Feiyang Wang, Hai Huang, Tianle Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18556">https://arxiv.org/abs/2504.18556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18556">https://arxiv.org/pdf/2504.18556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18556]] RDI: An adversarial robustness evaluation metric for deep neural networks based on sample clustering features(https://arxiv.org/abs/2504.18556)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) are highly susceptible to adversarial samples, raising concerns about their reliability in safety-critical tasks. Currently, methods of evaluating adversarial robustness are primarily categorized into attack-based and certified robustness evaluation approaches. The former not only relies on specific attack algorithms but also is highly time-consuming, while the latter due to its analytical nature, is typically difficult to implement for large and complex models. A few studies evaluate model robustness based on the model's decision boundary, but they suffer from low evaluation accuracy. To address the aforementioned issues, we propose a novel adversarial robustness evaluation metric, Robustness Difference Index (RDI), which is based on sample clustering features. RDI draws inspiration from clustering evaluation by analyzing the intra-class and inter-class distances of feature vectors separated by the decision boundary to quantify model robustness. It is attack-independent and has high computational efficiency. Experiments show that, RDI demonstrates a stronger correlation with the gold-standard adversarial robustness metric of attack success rate (ASR). The average computation time of RDI is only 1/30 of the evaluation method based on the PGD attack. Our open-source code is available at: this https URL.</li>
</ul>

<h3>Title: Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-Vazquez, Robert Clarisó, Jordi Cabot, German Castignani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18560">https://arxiv.org/abs/2504.18560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18560">https://arxiv.org/pdf/2504.18560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18560]] Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages(https://arxiv.org/abs/2504.18560)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have exhibited impressive natural language processing capabilities but often perpetuate social biases inherent in their training data. To address this, we introduce MultiLingual Augmented Bias Testing (MLA-BiTe), a framework that improves prior bias evaluation methods by enabling systematic multilingual bias testing. MLA-BiTe leverages automated translation and paraphrasing techniques to support comprehensive assessments across diverse linguistic settings. In this study, we evaluate the effectiveness of MLA-BiTe by testing four state-of-the-art LLMs in six languages -- including two low-resource languages -- focusing on seven sensitive categories of discrimination.</li>
</ul>

<h3>Title: Deep Learning with Pretrained 'Internal World' Layers: A Gemma 3-Based Modular Architecture for Wildfire Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ayoub Jadouli, Chaker El Amrani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18562">https://arxiv.org/abs/2504.18562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18562">https://arxiv.org/pdf/2504.18562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18562]] Deep Learning with Pretrained 'Internal World' Layers: A Gemma 3-Based Modular Architecture for Wildfire Prediction(https://arxiv.org/abs/2504.18562)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning models, especially large Transformers, carry substantial "memory" in their intermediate layers -- an \emph{internal world} that encodes a wealth of relational and contextual knowledge. This work harnesses that internal world for wildfire occurrence prediction by introducing a modular architecture built upon Gemma 3, a state-of-the-art multimodal model. Rather than relying on Gemma 3's original embedding and positional encoding stacks, we develop a custom feed-forward module that transforms tabular wildfire features into the hidden dimension required by Gemma 3's mid-layer Transformer blocks. We freeze these Gemma 3 sub-layers -- thus preserving their pretrained representation power -- while training only the smaller input and output networks. This approach minimizes the number of trainable parameters and reduces the risk of overfitting on limited wildfire data, yet retains the benefits of Gemma 3's broad knowledge. Evaluations on a Moroccan wildfire dataset demonstrate improved predictive accuracy and robustness compared to standard feed-forward and convolutional baselines. Ablation studies confirm that the frozen Transformer layers consistently contribute to better representations, underscoring the feasibility of reusing large-model mid-layers as a learned internal world. Our findings suggest that strategic modular reuse of pretrained Transformers can enable more data-efficient and interpretable solutions for critical environmental applications such as wildfire risk management.</li>
</ul>

<h3>Title: Backdoor Defense in Diffusion Models via Spatial Attention Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Abha Jha, Ashwath Vaithinathan Aravindan, Matthew Salaway, Atharva Sandeep Bhide, Duygu Nur Yaldiz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18563">https://arxiv.org/abs/2504.18563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18563">https://arxiv.org/pdf/2504.18563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18563]] Backdoor Defense in Diffusion Models via Spatial Attention Unlearning(https://arxiv.org/abs/2504.18563)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models are increasingly vulnerable to backdoor attacks, where malicious modifications to the training data cause the model to generate unintended outputs when specific triggers are present. While classification models have seen extensive development of defense mechanisms, generative models remain largely unprotected due to their high-dimensional output space, which complicates the detection and mitigation of subtle perturbations. Defense strategies for diffusion models, in particular, remain under-explored. In this work, we propose Spatial Attention Unlearning (SAU), a novel technique for mitigating backdoor attacks in diffusion models. SAU leverages latent space manipulation and spatial attention mechanisms to isolate and remove the latent representation of backdoor triggers, ensuring precise and efficient removal of malicious effects. We evaluate SAU across various types of backdoor attacks, including pixel-based and style-based triggers, and demonstrate its effectiveness in achieving 100% trigger removal accuracy. Furthermore, SAU achieves a CLIP score of 0.7023, outperforming existing methods while preserving the model's ability to generate high-quality, semantically aligned images. Our results show that SAU is a robust, scalable, and practical solution for securing text-to-image diffusion models against backdoor attacks.</li>
</ul>

<h3>Title: DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization</h3>
<ul>
<li><strong>Authors: </strong>Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18564">https://arxiv.org/abs/2504.18564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18564">https://arxiv.org/pdf/2504.18564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18564]] DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization(https://arxiv.org/abs/2504.18564)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Recent research has focused on exploring the vulnerabilities of Large Language Models (LLMs), aiming to elicit harmful and/or sensitive content from LLMs. However, due to the insufficient research on dual-jailbreaking -- attacks targeting both LLMs and Guardrails, the effectiveness of existing attacks is limited when attempting to bypass safety-aligned LLMs shielded by guardrails. Therefore, in this paper, we propose DualBreach, a target-driven framework for dual-jailbreaking. DualBreach employs a Target-driven Initialization (TDI) strategy to dynamically construct initial prompts, combined with a Multi-Target Optimization (MTO) method that utilizes approximate gradients to jointly adapt the prompts across guardrails and LLMs, which can simultaneously save the number of queries and achieve a high dual-jailbreaking success rate. For black-box guardrails, DualBreach either employs a powerful open-sourced guardrail or imitates the target black-box guardrail by training a proxy model, to incorporate guardrails into the MTO process. We demonstrate the effectiveness of DualBreach in dual-jailbreaking scenarios through extensive evaluation on several widely-used datasets. Experimental results indicate that DualBreach outperforms state-of-the-art methods with fewer queries, achieving significantly higher success rates across all settings. More specifically, DualBreach achieves an average dual-jailbreaking success rate of 93.67% against GPT-4 with Llama-Guard-3 protection, whereas the best success rate achieved by other methods is 88.33%. Moreover, DualBreach only uses an average of 1.77 queries per successful dual-jailbreak, outperforming other state-of-the-art methods. For the purpose of defense, we propose an XGBoost-based ensemble defensive mechanism named EGuard, which integrates the strengths of multiple guardrails, demonstrating superior performance compared with Llama-Guard-3.</li>
</ul>

<h3>Title: RepliBench: Evaluating the autonomous replication capabilities of language model agents</h3>
<ul>
<li><strong>Authors: </strong>Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18565">https://arxiv.org/abs/2504.18565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18565">https://arxiv.org/pdf/2504.18565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18565]] RepliBench: Evaluating the autonomous replication capabilities of language model agents(https://arxiv.org/abs/2504.18565)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Uncontrollable autonomous replication of language model agents poses a critical safety risk. To better understand this risk, we introduce RepliBench, a suite of evaluations designed to measure autonomous replication capabilities. RepliBench is derived from a decomposition of these capabilities covering four core domains: obtaining resources, exfiltrating model weights, replicating onto compute, and persisting on this compute for long periods. We create 20 novel task families consisting of 86 individual tasks. We benchmark 5 frontier models, and find they do not currently pose a credible threat of self-replication, but succeed on many components and are improving rapidly. Models can deploy instances from cloud compute providers, write self-propagating programs, and exfiltrate model weights under simple security setups, but struggle to pass KYC checks or set up robust and persistent agent deployments. Overall the best model we evaluated (Claude 3.7 Sonnet) has a >50% pass@10 score on 15/20 task families, and a >50% pass@10 score for 9/20 families on the hardest variants. These findings suggest autonomous replication capability could soon emerge with improvements in these remaining areas or with human assistance.</li>
</ul>

<h3>Title: Feature Selection via GANs (GANFS): Enhancing Machine Learning Models for DDoS Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Harsh Patel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18566">https://arxiv.org/abs/2504.18566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18566">https://arxiv.org/pdf/2504.18566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18566]] Feature Selection via GANs (GANFS): Enhancing Machine Learning Models for DDoS Mitigation(https://arxiv.org/abs/2504.18566)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Distributed Denial of Service (DDoS) attacks represent a persistent and evolving threat to modern networked systems, capable of causing large-scale service disruptions. The complexity of such attacks, often hidden within high-dimensional and redundant network traffic data, necessitates robust and intelligent feature selection techniques for effective detection. Traditional methods such as filter-based, wrapper-based, and embedded approaches, each offer strengths but struggle with scalability or adaptability in complex attack environments. In this study, we explore these existing techniques through a detailed comparative analysis and highlight their limitations when applied to large-scale DDoS detection tasks. Building upon these insights, we introduce a novel Generative Adversarial Network-based Feature Selection (GANFS) method that leverages adversarial learning dynamics to identify the most informative features. By training a GAN exclusively on attack traffic and employing a perturbation-based sensitivity analysis on the Discriminator, GANFS effectively ranks feature importance without relying on full supervision. Experimental evaluations using the CIC-DDoS2019 dataset demonstrate that GANFS not only improves the accuracy of downstream classifiers but also enhances computational efficiency by significantly reducing feature dimensionality. These results point to the potential of integrating generative learning models into cybersecurity pipelines to build more adaptive and scalable detection systems.</li>
</ul>

<h3>Title: Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes</h3>
<ul>
<li><strong>Authors: </strong>Guanchen Wu, Linzhi Zheng, Han Xie, Zhen Xiang, Jiaying Lu, Darren Liu, Delgersuren Bold, Bo Li, Xiao Hu, Carl Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18569">https://arxiv.org/abs/2504.18569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18569">https://arxiv.org/pdf/2504.18569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18569]] Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes(https://arxiv.org/abs/2504.18569)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>The de-identification of private information in medical data is a crucial process to mitigate the risk of confidentiality breaches, particularly when patient personal details are not adequately removed before the release of medical records. Although rule-based and learning-based methods have been proposed, they often struggle with limited generalizability and require substantial amounts of annotated data for effective performance. Recent advancements in large language models (LLMs) have shown significant promise in addressing these issues due to their superior language comprehension capabilities. However, LLMs present challenges, including potential privacy risks when using commercial LLM APIs and high computational costs for deploying open-source LLMs locally. In this work, we introduce LPPA, an LLM-empowered Privacy-Protected PHI Annotation framework for clinical notes, targeting the English language. By fine-tuning LLMs locally with synthetic notes, LPPA ensures strong privacy protection and high PHI annotation accuracy. Extensive experiments demonstrate LPPA's effectiveness in accurately de-identifying private information, offering a scalable and efficient solution for enhancing patient privacy protection.</li>
</ul>

<h3>Title: Residual-Evasive Attacks on ADMM in Distributed Optimization</h3>
<ul>
<li><strong>Authors: </strong>Sabrina Bruckmeier, Huadong Mo, James Qin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18570">https://arxiv.org/abs/2504.18570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18570">https://arxiv.org/pdf/2504.18570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18570]] Residual-Evasive Attacks on ADMM in Distributed Optimization(https://arxiv.org/abs/2504.18570)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>This paper presents two attack strategies designed to evade detection in ADMM-based systems by preventing significant changes to the residual during the attacked iteration. While many detection algorithms focus on identifying false data injection through residual changes, we show that our attacks remain undetected by keeping the residual largely unchanged. The first strategy uses a random starting point combined with Gram-Schmidt orthogonalization to ensure stealth, with potential for refinement by enhancing the orthogonal component to increase system disruption. The second strategy builds on the first, targeting financial gains by manipulating reactive power and pushing the system to its upper voltage limit, exploiting operational constraints. The effectiveness of the proposed attack-resilient mechanism is demonstrated through case studies on the IEEE 14-bus system. A comparison of the two strategies, along with commonly used naive attacks, reveals trade-offs between simplicity, detectability, and effectiveness, providing insights into ADMM system vulnerabilities. These findings underscore the need for more robust monitoring algorithms to protect against advanced attack strategies.</li>
</ul>

<h3>Title: Intelligent Detection of Non-Essential IoT Traffic on the Home Gateway</h3>
<ul>
<li><strong>Authors: </strong>Fabio Palmese, Anna Maria Mandalari, Hamed Haddadi, Alessandro Enrico Cesare Redondi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18571">https://arxiv.org/abs/2504.18571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18571">https://arxiv.org/pdf/2504.18571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18571]] Intelligent Detection of Non-Essential IoT Traffic on the Home Gateway(https://arxiv.org/abs/2504.18571)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, extraction</a></li>
<li><strong>Abstract: </strong>The rapid expansion of Internet of Things (IoT) devices, particularly in smart home environments, has introduced considerable security and privacy concerns due to their persistent connectivity and interaction with cloud services. Despite advancements in IoT security, effective privacy measures remain uncovered, with existing solutions often relying on cloud-based threat detection that exposes sensitive data or outdated allow-lists that inadequately restrict non-essential network traffic. This work presents ML-IoTrim, a system for detecting and mitigating non-essential IoT traffic (i.e., not influencing the device operations) by analyzing network behavior at the edge, leveraging Machine Learning to classify network destinations. Our approach includes building a labeled dataset based on IoT device behavior and employing a feature-extraction pipeline to enable a binary classification of essential vs. non-essential network destinations. We test our framework in a consumer smart home setup with IoT devices from five categories, demonstrating that the model can accurately identify and block non-essential traffic, including previously unseen destinations, without relying on traditional allow-lists. We implement our solution on a home access point, showing the framework has strong potential for scalable deployment, supporting near-real-time traffic classification in large-scale IoT environments with hundreds of devices. This research advances privacy-aware traffic control in smart homes, paving the way for future developments in IoT device privacy.</li>
</ul>

<h3>Title: Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Aviv Bick, Eric Xing, Albert Gu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18574">https://arxiv.org/abs/2504.18574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18574">https://arxiv.org/pdf/2504.18574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18574]] Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism(https://arxiv.org/abs/2504.18574)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>SSMs offer efficient processing of long sequences with fixed state sizes, but struggle with algorithmic tasks like retrieving past context. In this work, we examine how such in-context retrieval operates within Transformer- and SSM-based language models. We find that both architectures develop the same fundamental Gather-and-Aggregate (G&A) mechanism. A Gather Head first identifies and extracts relevant information from the context, which an Aggregate Head then integrates into a final representation. Across both model types, G&A concentrates in just a few heads, making them critical bottlenecks even for benchmarks that require a basic form of retrieval. For example, disabling a single Gather or Aggregate Head of a pruned Llama-3.1-8B degrades its ability to retrieve the correct answer letter in MMLU, reducing accuracy from 66% to 25%. This finding suggests that in-context retrieval can obscure the limited knowledge demands of certain tasks. Despite strong MMLU performance with retrieval intact, the pruned model fails on other knowledge tests. Similar G&A dependencies exist in GSM8K, BBH, and dialogue tasks. Given the significance of G&A in performance, we show that retrieval challenges in SSMs manifest in how they implement G&A, leading to smoother attention patterns rather than the sharp token transitions that effective G&A relies on. Thus, while a gap exists between Transformers and SSMs in implementing in-context retrieval, it is confined to a few heads, not the entire model. This insight suggests a unified explanation for performance differences between Transformers and SSMs while also highlighting ways to combine their strengths. For example, in pretrained hybrid models, attention components naturally take on the role of Aggregate Heads. Similarly, in a pretrained pure SSM, replacing a single G&A head with an attention-based variant significantly improves retrieval.</li>
</ul>

<h3>Title: WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18575">https://arxiv.org/abs/2504.18575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18575">https://arxiv.org/pdf/2504.18575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18575]] WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks(https://arxiv.org/abs/2504.18575)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Web navigation AI agents use language-and-vision foundation models to enhance productivity but these models are known to be susceptible to indirect prompt injections that get them to follow instructions different from the legitimate user's. Existing explorations of this threat applied to web agents often focus on a single isolated adversarial goal, test with injected instructions that are either too easy or not truly malicious, and often give the adversary unreasonable access. In order to better focus adversarial research, we construct a new benchmark called WASP (Web Agent Security against Prompt injection attacks) that introduces realistic web agent hijacking objectives and an isolated environment to test them in that does not affect real users or the live web. As part of WASP, we also develop baseline attacks against three popular web agentic systems (VisualWebArena, Claude Computer Use, and Operator) instantiated with various state-of-the-art models. Our evaluation shows that even AI agents backed by models with advanced reasoning capabilities and by models with instruction hierarchy mitigations are susceptible to low-effort human-written prompt injections. However, the realistic objectives in WASP also allow us to observe that agents are currently not capable enough to complete the goals of attackers end-to-end. Agents begin executing the adversarial instruction between 16 and 86% of the time but only achieve the goal between 0 and 17% of the time. Based on these findings, we argue that adversarial researchers should demonstrate stronger attacks that more consistently maintain control over the agent given realistic constraints on the adversary's power.</li>
</ul>

<h3>Title: Defending Against Intelligent Attackers at Large Scales</h3>
<ul>
<li><strong>Authors: </strong>Andrew J. Lohn</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18577">https://arxiv.org/abs/2504.18577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18577">https://arxiv.org/pdf/2504.18577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18577]] Defending Against Intelligent Attackers at Large Scales(https://arxiv.org/abs/2504.18577)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>We investigate the scale of attack and defense mathematically in the context of AI's possible effect on cybersecurity. For a given target today, highly scaled cyber attacks such as from worms or botnets typically all fail or all succeed. Here, we consider the effect of scale if those attack agents were intelligent and creative enough to act independently such that each attack attempt was different from the others or such that attackers could learn from their successes and failures. We find that small increases in the number or quality of defenses can compensate for exponential increases in the number of independent attacks and for exponential speedups.</li>
</ul>

<h3>Title: Parameter-Efficient Checkpoint Merging via Metrics-Weighted Averaging</h3>
<ul>
<li><strong>Authors: </strong>Shi Jie Yu, Sehyun Choi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18580">https://arxiv.org/abs/2504.18580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18580">https://arxiv.org/pdf/2504.18580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18580]] Parameter-Efficient Checkpoint Merging via Metrics-Weighted Averaging(https://arxiv.org/abs/2504.18580)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Checkpoint merging is a technique for combining multiple model snapshots into a single superior model, potentially reducing training time for large language models. This paper explores checkpoint merging in the context of parameter-efficient fine-tuning (PEFT), where only small adapter modules (e.g. LoRA) are trained. We propose Metrics-Weighted Averaging (MWA), a simple yet effective method to merge model checkpoints by weighting their parameters according to performance metrics. In particular, we investigate weighting by training loss and by training steps, under the intuition that lower-loss or later-step checkpoints are more valuable. We introduce a formula with a penalty factor to adjust weight distribution, requiring only one hyperparameter regardless of the number of checkpoints. Experiments on three fine-tuning tasks (mathematical reasoning, preference alignment, and general instruction tuning) show that MWA consistently produces merged models that outperform the naive uniform average of checkpoints. Notably, loss-weighted merging often yields the best results, delivering up to 5% higher task accuracy than the baseline uniform merge and even surpassing the final individual checkpoint's performance. These findings validate checkpoint merging for PEFT and demonstrate that a metric-driven weighting heuristic can efficiently boost model performance with minimal computational overhead.</li>
</ul>

<h3>Title: Enhancing Privacy in Semantic Communication over Wiretap Channels leveraging Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Weixuan Chen, Shunpu Tang, Qianqian Yang, Zhiguo Shi, Dusit Niyato</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18581">https://arxiv.org/abs/2504.18581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18581">https://arxiv.org/pdf/2504.18581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18581]] Enhancing Privacy in Semantic Communication over Wiretap Channels leveraging Differential Privacy(https://arxiv.org/abs/2504.18581)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, robust, generative</a></li>
<li><strong>Abstract: </strong>Semantic communication (SemCom) improves transmission efficiency by focusing on task-relevant information. However, transmitting semantic-rich data over insecure channels introduces privacy risks. This paper proposes a novel SemCom framework that integrates differential privacy (DP) mechanisms to protect sensitive semantic features. This method employs the generative adversarial network (GAN) inversion technique to extract disentangled semantic features and uses neural networks (NNs) to approximate the DP application and removal processes, effectively mitigating the non-invertibility issue of DP. Additionally, an NN-based encryption scheme is introduced to strengthen the security of channel inputs. Simulation results demonstrate that the proposed approach effectively prevents eavesdroppers from reconstructing sensitive information by generating chaotic or fake images, while ensuring high-quality image reconstruction for legitimate users. The system exhibits robust performance across various privacy budgets and channel conditions, achieving an optimal balance between privacy protection and reconstruction fidelity.</li>
</ul>

<h3>Title: PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Zihao An, Huajun Bai, Ziqiong Liu, Dong Li, Emad Barsoum</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18583">https://arxiv.org/abs/2504.18583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18583">https://arxiv.org/pdf/2504.18583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18583]] PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation(https://arxiv.org/abs/2504.18583)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The autoregressive nature of large language models (LLMs) limits inference speed. Each forward pass generates only a single token and is often bottlenecked by memory bandwidth. Speculative decoding alleviates this issue using a draft-then-verify approach to accelerate token generation. However, the overhead introduced during the draft phase and the training cost of the draft model limit the efficiency and adaptability of speculative decoding. In this work, we introduce PARallel Draft (PARD), a novel speculative decoding method that enables low-cost adaptation of autoregressive draft models into parallel draft models. PARD enhances inference efficiency by predicting multiple future tokens in a single forward pass of the draft phase, and incorporates a conditional drop token method to accelerate training. Its target-independence property allows a single draft model to be applied to an entire family of different models, minimizing the adaptation cost. Our proposed conditional drop token method can improves draft model training efficiency by 3x. On our optimized inference framework, PARD accelerates LLaMA3.1-8B inference by 4.08x, achieving 311.5 tokens per second.</li>
</ul>

<h3>Title: Training Large Language Models to Reason via EM Policy Gradient</h3>
<ul>
<li><strong>Authors: </strong>Tianbing Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18587">https://arxiv.org/abs/2504.18587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18587">https://arxiv.org/pdf/2504.18587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18587]] Training Large Language Models to Reason via EM Policy Gradient(https://arxiv.org/abs/2504.18587)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recently, foundation models such as OpenAI's O1 and O3, along with DeepSeek's R1, have demonstrated strong reasoning capacities and problem-solving skills acquired through large-scale reinforcement learning (RL), with wide applications in mathematics, coding, science, intelligent agents, and virtual assistants. In this work, we introduce an off-policy reinforcement learning algorithm, EM Policy Gradient, aimed at enhancing LLM reasoning by optimizing expected return over reasoning trajectories. We frame the reasoning task as an Expectation-Maximization (EM) optimization problem, alternating between sampling diverse rationale trajectories and performing reward-guided fine-tuning. Unlike PPO and GRPO, which rely on complex importance weights and heuristic clipping, our method provides a simpler, more principled off-policy policy gradient approach, eliminating these complexities while maintaining strong performance. We evaluate the effectiveness of EM Policy Gradient on the GSM8K and MATH (HARD) datasets, where it achieves performance comparable to or slightly surpassing the state-of-the-art GRPO, while offering additional advantages in scalability, simplicity, and reasoning conciseness. Moreover, models fine-tuned with our method exhibit cognitive behaviors, such as sub-problem decomposition, self-verification, and backtracking, highlighting its potential to enhance both the interpretability and robustness of LLM reasoning.</li>
</ul>

<h3>Title: A multilevel approach to accelerate the training of Transformers</h3>
<ul>
<li><strong>Authors: </strong>Guillaume Lauga (OCKHAM), Maël Chaumette (OCKHAM), Edgar Desainte-Maréville (OCKHAM), Étienne Lasalle (OCKHAM), Arthur Lebeurrier (OCKHAM)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18590">https://arxiv.org/abs/2504.18590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18590">https://arxiv.org/pdf/2504.18590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18590]] A multilevel approach to accelerate the training of Transformers(https://arxiv.org/abs/2504.18590)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this article, we investigate the potential of multilevel approaches to accelerate the training of transformer architectures. Using an ordinary differential equation (ODE) interpretation of these architectures, we propose an appropriate way of varying the discretization of these ODE Transformers in order to accelerate the training. We validate our approach experimentally by a comparison with the standard training procedure.</li>
</ul>

<h3>Title: Severity Classification of Chronic Obstructive Pulmonary Disease in Intensive Care Units: A Semi-Supervised Approach Using MIMIC-III Dataset</h3>
<ul>
<li><strong>Authors: </strong>Akram Shojaei, Mehdi Delrobaei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18593">https://arxiv.org/abs/2504.18593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18593">https://arxiv.org/pdf/2504.18593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18593]] Severity Classification of Chronic Obstructive Pulmonary Disease in Intensive Care Units: A Semi-Supervised Approach Using MIMIC-III Dataset(https://arxiv.org/abs/2504.18593)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Chronic obstructive pulmonary disease (COPD) represents a significant global health burden, where precise severity assessment is particularly critical for effective clinical management in intensive care unit (ICU) settings. This study introduces an innovative machine learning framework for COPD severity classification utilizing the MIMIC-III critical care database, thereby expanding the applications of artificial intelligence in critical care medicine. Our research developed a robust classification model incorporating key ICU parameters such as blood gas measurements and vital signs, while implementing semi-supervised learning techniques to effectively utilize unlabeled data and enhance model performance. The random forest classifier emerged as particularly effective, demonstrating exceptional discriminative capability with 92.51% accuracy and 0.98 ROC AUC in differentiating between mild-to-moderate and severe COPD cases. This machine learning approach provides clinicians with a practical, accurate, and efficient tool for rapid COPD severity evaluation in ICU environments, with significant potential to improve both clinical decision-making processes and patient outcomes. Future research directions should prioritize external validation across diverse patient populations and integration with clinical decision support systems to optimize COPD management in critical care settings.</li>
</ul>

<h3>Title: A Simple DropConnect Approach to Transfer-based Targeted Attack</h3>
<ul>
<li><strong>Authors: </strong>Tongrui Su, Qingbin Li, Shengyu Zhu, Wei Chen, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18594">https://arxiv.org/abs/2504.18594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18594">https://arxiv.org/pdf/2504.18594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18594]] A Simple DropConnect Approach to Transfer-based Targeted Attack(https://arxiv.org/abs/2504.18594)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>We study the problem of transfer-based black-box attack, where adversarial samples generated using a single surrogate model are directly applied to target models. Compared with untargeted attacks, existing methods still have lower Attack Success Rates (ASRs) in the targeted setting, i.e., the obtained adversarial examples often overfit the surrogate model but fail to mislead other models. In this paper, we hypothesize that the pixels or features in these adversarial examples collaborate in a highly dependent manner to maximize the success of an adversarial attack on the surrogate model, which we refer to as perturbation co-adaptation. Then, we propose to Mitigate perturbation Co-adaptation by DropConnect (MCD) to enhance transferability, by creating diverse variants of surrogate model at each optimization iteration. We conduct extensive experiments across various CNN- and Transformer-based models to demonstrate the effectiveness of MCD. In the challenging scenario of transferring from a CNN-based model to Transformer-based models, MCD achieves 13% higher average ASRs compared with state-of-the-art baselines. MCD boosts the performance of self-ensemble methods by bringing in more diversification across the variants while reserving sufficient semantic information for each variant. In addition, MCD attains the highest performance gain when scaling the compute of crafting adversarial examples.</li>
</ul>

<h3>Title: EnviroPiNet: A Physics-Guided AI Model for Predicting Biofilter Performance</h3>
<ul>
<li><strong>Authors: </strong>Uzma, Fabien Cholet, Domenic Quinn, Cindy Smith, Siming You, William Sloan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18595">https://arxiv.org/abs/2504.18595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18595">https://arxiv.org/pdf/2504.18595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18595]] EnviroPiNet: A Physics-Guided AI Model for Predicting Biofilter Performance(https://arxiv.org/abs/2504.18595)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Environmental biotechnologies, such as drinking water biofilters, rely on complex interactions between microbial communities and their surrounding physical-chemical environments. Predicting the performance of these systems is challenging due to high-dimensional, sparse datasets that lack diversity and fail to fully capture system behaviour. Accurate predictive models require innovative, science-guided approaches. In this study, we present the first application of Buckingham Pi theory to modelling biofilter performance. This dimensionality reduction technique identifies meaningful, dimensionless variables that enhance predictive accuracy and improve model interpretability. Using these variables, we developed the Environmental Buckingham Pi Neural Network (EnviroPiNet), a physics-guided model benchmarked against traditional data-driven methods, including Principal Component Analysis (PCA) and autoencoder neural networks. Our findings demonstrate that the EnviroPiNet model achieves an R^2 value of 0.9236 on the testing dataset, significantly outperforming PCA and autoencoder methods. The Buckingham Pi variables also provide insights into the physical and chemical relationships governing biofilter behaviour, with implications for system design and optimization. This study highlights the potential of combining physical principles with AI approaches to model complex environmental systems characterized by sparse, high-dimensional datasets.</li>
</ul>

<h3>Title: Optimizing the Privacy-Utility Balance using Synthetic Data and Configurable Perturbation Pipelines</h3>
<ul>
<li><strong>Authors: </strong>Anantha Sharma, Swetha Devabhaktuni, Eklove Mohan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18596">https://arxiv.org/abs/2504.18596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18596">https://arxiv.org/pdf/2504.18596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18596]] Optimizing the Privacy-Utility Balance using Synthetic Data and Configurable Perturbation Pipelines(https://arxiv.org/abs/2504.18596)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, generative</a></li>
<li><strong>Abstract: </strong>This paper explores the strategic use of modern synthetic data generation and advanced data perturbation techniques to enhance security, maintain analytical utility, and improve operational efficiency when managing large datasets, with a particular focus on the Banking, Financial Services, and Insurance (BFSI) sector. We contrast these advanced methods encompassing generative models like GANs, sophisticated context-aware PII transformation, configurable statistical perturbation, and differential privacy with traditional anonymization approaches. The goal is to create realistic, privacy-preserving datasets that retain high utility for complex machine learning tasks and analytics, a critical need in the data-sensitive industries like BFSI, Healthcare, Retail, and Telecommunications. We discuss how these modern techniques potentially offer significant improvements in balancing privacy preservation while maintaining data utility compared to older methods. Furthermore, we examine the potential for operational gains, such as reduced overhead and accelerated analytics, by using these privacy-enhanced datasets. We also explore key use cases where these methods can mitigate regulatory risks and enable scalable, data-driven innovation without compromising sensitive customer information.</li>
</ul>

<h3>Title: Accurate BGV Parameters Selection: Accounting for Secret and Public Key Dependencies in Average-Case Analysis</h3>
<ul>
<li><strong>Authors: </strong>Beatrice Biasioli, Chiara Marcolla, Nadir Murru, Matilda Urani</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18597">https://arxiv.org/abs/2504.18597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18597">https://arxiv.org/pdf/2504.18597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18597]] Accurate BGV Parameters Selection: Accounting for Secret and Public Key Dependencies in Average-Case Analysis(https://arxiv.org/abs/2504.18597)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The Brakerski-Gentry-Vaikuntanathan (BGV) scheme is one of the most significant fully homomorphic encryption (FHE) schemes. It belongs to a class of FHE schemes whose security is based on the presumed intractability of the Learning with Errors (LWE) problem and its ring variant (RLWE). Such schemes deal with a quantity, called noise, which increases each time a homomorphic operation is performed. Specifically, in order for the scheme to work properly, it is essential that the noise remains below a certain threshold throughout the process. For BGV, this threshold strictly depends on the ciphertext modulus, which is one of the initial parameters whose selection heavily affects both the efficiency and security of the scheme. In this paper, we provide a new method to estimate noise growth, closely aligning with experimental results and forming the basis for parameter selection that ensures correctness and improves efficiency.</li>
</ul>

<h3>Title: BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts</h3>
<ul>
<li><strong>Authors: </strong>Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18598">https://arxiv.org/abs/2504.18598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18598">https://arxiv.org/pdf/2504.18598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18598]] BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts(https://arxiv.org/abs/2504.18598)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) have emerged as a powerful architecture for large language models (LLMs), enabling efficient scaling of model capacity while maintaining manageable computational costs. The key advantage lies in their ability to route different tokens to different ``expert'' networks within the model, enabling specialization and efficient handling of diverse input. However, the vulnerabilities of MoE-based LLMs still have barely been studied, and the potential for backdoor attacks in this context remains largely unexplored. This paper presents the first backdoor attack against MoE-based LLMs where the attackers poison ``dormant experts'' (i.e., underutilized experts) and activate them by optimizing routing triggers, thereby gaining control over the model's output. We first rigorously prove the existence of a few ``dominating experts'' in MoE models, whose outputs can determine the overall MoE's output. We also show that dormant experts can serve as dominating experts to manipulate model predictions. Accordingly, our attack, namely \textsc{BadMoE}, exploits the unique architecture of MoE models by 1) identifying dormant experts unrelated to the target task, 2) constructing a routing-aware loss to optimize the activation triggers of these experts, and 3) promoting dormant experts to dominating roles via poisoned training data.</li>
</ul>

<h3>Title: ECG Identity Authentication in Open-set with Multi-model Pretraining and Self-constraint Center & Irrelevant Sample Repulsion Learning</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Dong, Zhidong Zhao, Hao Wang, Yefei Zhang, Yanjun Deng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18608">https://arxiv.org/abs/2504.18608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18608">https://arxiv.org/pdf/2504.18608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18608]] ECG Identity Authentication in Open-set with Multi-model Pretraining and Self-constraint Center & Irrelevant Sample Repulsion Learning(https://arxiv.org/abs/2504.18608)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, biometric</a></li>
<li><strong>Abstract: </strong>Electrocardiogram (ECG) signal exhibits inherent uniqueness, making it a promising biometric modality for identity authentication. As a result, ECG authentication has gained increasing attention in recent years. However, most existing methods focus primarily on improving authentication accuracy within closed-set settings, with limited research addressing the challenges posed by open-set scenarios. In real-world applications, identity authentication systems often encounter a substantial amount of unseen data, leading to potential security vulnerabilities and performance degradation. To address this issue, we propose a robust ECG identity authentication system that maintains high performance even in open-set settings. Firstly, we employ a multi-modal pretraining framework, where ECG signals are paired with textual reports derived from their corresponding fiducial features to enhance the representational capacity of the signal encoder. During fine-tuning, we introduce Self-constraint Center Learning and Irrelevant Sample Repulsion Learning to constrain the feature distribution, ensuring that the encoded representations exhibit clear decision boundaries for classification. Our method achieves 99.83% authentication accuracy and maintains a False Accept Rate as low as 5.39% in the presence of open-set samples. Furthermore, across various open-set ratios, our method demonstrates exceptional stability, maintaining an Open-set Classification Rate above 95%.</li>
</ul>

<h3>Title: A Gradient-Optimized TSK Fuzzy Framework for Explainable Phishing Detection</h3>
<ul>
<li><strong>Authors: </strong>Lohith Srikanth Pentapalli, Jon Salisbury, Josette Riep, Kelly Cohen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18636">https://arxiv.org/abs/2504.18636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18636">https://arxiv.org/pdf/2504.18636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18636]] A Gradient-Optimized TSK Fuzzy Framework for Explainable Phishing Detection(https://arxiv.org/abs/2504.18636)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Phishing attacks represent an increasingly sophisticated and pervasive threat to individuals and organizations, causing significant financial losses, identity theft, and severe damage to institutional reputations. Existing phishing detection methods often struggle to simultaneously achieve high accuracy and explainability, either failing to detect novel attacks or operating as opaque black-box models. To address this critical gap, we propose a novel phishing URL detection system based on a first-order Takagi-Sugeno-Kang (TSK) fuzzy inference model optimized through gradient-based techniques. Our approach intelligently combines the interpretability and human-like reasoning capabilities of fuzzy logic with the precision and adaptability provided by gradient optimization methods, specifically leveraging the Adam optimizer for efficient parameter tuning. Experiments conducted using a comprehensive dataset of over 235,000 URLs demonstrate rapid convergence, exceptional predictive performance (accuracy averaging 99.95% across 5 cross-validation folds, with a perfect AUC i.e. 1.00). Furthermore, optimized fuzzy rules and membership functions improve interoperability, clearly indicating how the model makes decisions - an essential feature for cybersecurity applications. This high-performance, transparent, and interpretable phishing detection framework significantly advances current cybersecurity defenses, providing practitioners with accurate and explainable decision-making tools.</li>
</ul>

<h3>Title: Can Third-parties Read Our Emotions?</h3>
<ul>
<li><strong>Authors: </strong>Jiayi Li, Yingfan Zhou, Pranav Narayanan Venkit, Halima Binte Islam, Sneha Arya, Shomir Wilson, Sarah Rajtmajer</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18673">https://arxiv.org/abs/2504.18673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18673">https://arxiv.org/pdf/2504.18673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18673]] Can Third-parties Read Our Emotions?(https://arxiv.org/abs/2504.18673)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Natural Language Processing tasks that aim to infer an author's private states, e.g., emotions and opinions, from their written text, typically rely on datasets annotated by third-party annotators. However, the assumption that third-party annotators can accurately capture authors' private states remains largely unexamined. In this study, we present human subjects experiments on emotion recognition tasks that directly compare third-party annotations with first-party (author-provided) emotion labels. Our findings reveal significant limitations in third-party annotations-whether provided by human annotators or large language models (LLMs)-in faithfully representing authors' private states. However, LLMs outperform human annotators nearly across the board. We further explore methods to improve third-party annotation quality. We find that demographic similarity between first-party authors and third-party human annotators enhances annotation performance. While incorporating first-party demographic information into prompts leads to a marginal but statistically significant improvement in LLMs' performance. We introduce a framework for evaluating the limitations of third-party annotations and call for refined annotation practices to accurately represent and model authors' private states.</li>
</ul>

<h3>Title: SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nader Zantout, Haochen Zhang, Pujith Kachana, Jinkai Qiu, Ji Zhang, Wenshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18684">https://arxiv.org/abs/2504.18684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18684">https://arxiv.org/pdf/2504.18684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18684]] SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models(https://arxiv.org/abs/2504.18684)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Interpreting object-referential language and grounding objects in 3D with spatial relations and attributes is essential for robots operating alongside humans. However, this task is often challenging due to the diversity of scenes, large number of fine-grained objects, and complex free-form nature of language references. Furthermore, in the 3D domain, obtaining large amounts of natural language training data is difficult. Thus, it is important for methods to learn from little data and zero-shot generalize to new environments. To address these challenges, we propose SORT3D, an approach that utilizes rich object attributes from 2D data and merges a heuristics-based spatial reasoning toolbox with the ability of large language models (LLMs) to perform sequential reasoning. Importantly, our method does not require text-to-3D data for training and can be applied zero-shot to unseen environments. We show that SORT3D achieves state-of-the-art performance on complex view-dependent grounding tasks on two benchmarks. We also implement the pipeline to run real-time on an autonomous vehicle and demonstrate that our approach can be used for object-goal navigation on previously unseen real-world environments. All source code for the system pipeline is publicly released at this https URL .</li>
</ul>

<h3>Title: Appa: Bending Weather Dynamics with Latent Diffusion Models for Global Data Assimilation</h3>
<ul>
<li><strong>Authors: </strong>Gérôme Andry, François Rozet, Sacha Lewin, Omer Rochman, Victor Mangeleer, Matthias Pirlet, Elise Faulx, Marilaure Grégoire, Gilles Louppe</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18720">https://arxiv.org/abs/2504.18720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18720">https://arxiv.org/pdf/2504.18720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18720]] Appa: Bending Weather Dynamics with Latent Diffusion Models for Global Data Assimilation(https://arxiv.org/abs/2504.18720)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning has transformed weather forecasting by improving both its accuracy and computational efficiency. However, before any forecast can begin, weather centers must identify the current atmospheric state from vast amounts of observational data. To address this challenging problem, we introduce Appa, a score-based data assimilation model producing global atmospheric trajectories at 0.25-degree resolution and 1-hour intervals. Powered by a 1.5B-parameter spatio-temporal latent diffusion model trained on ERA5 reanalysis data, Appa can be conditioned on any type of observations to infer the posterior distribution of plausible state trajectories, without retraining. Our unified probabilistic framework flexibly tackles multiple inference tasks -- reanalysis, filtering, and forecasting -- using the same model, eliminating the need for task-specific architectures or training procedures. Experiments demonstrate physical consistency on a global scale and good reconstructions from observations, while showing competitive forecasting skills. Our results establish latent score-based data assimilation as a promising foundation for future global atmospheric modeling systems.</li>
</ul>

<h3>Title: TLoRA: Tri-Matrix Low-Rank Adaptation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tanvir Islam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18735">https://arxiv.org/abs/2504.18735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18735">https://arxiv.org/pdf/2504.18735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18735]] TLoRA: Tri-Matrix Low-Rank Adaptation of Large Language Models(https://arxiv.org/abs/2504.18735)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose TLoRA, a novel tri-matrix low-rank adaptation method that decomposes weight updates into three matrices: two fixed random matrices and one trainable matrix, combined with a learnable, layer-wise scaling factor. This tri-matrix design enables TLoRA to achieve highly efficient parameter adaptation while introducing minimal additional computational overhead. Through extensive experiments on the GLUE benchmark, we demonstrate that TLoRA achieves comparable performance to existing low-rank methods such as LoRA and Adapter-based techniques, while requiring significantly fewer trainable parameters. Analyzing the adaptation dynamics, we observe that TLoRA exhibits Gaussian-like weight distributions, stable parameter norms, and scaling factor variability across layers, further highlighting its expressive power and adaptability. Additionally, we show that TLoRA closely resembles LoRA in its eigenvalue distributions, parameter norms, and cosine similarity of updates, underscoring its ability to effectively approximate LoRA's adaptation behavior. Our results establish TLoRA as a highly efficient and effective fine-tuning method for LLMs, offering a significant step forward in resource-efficient model adaptation.</li>
</ul>

<h3>Title: Dream-Box: Object-wise Outlier Generation for Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Brian K. S. Isaac-Medina, Toby P. Breckon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18746">https://arxiv.org/abs/2504.18746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18746">https://arxiv.org/pdf/2504.18746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18746]] Dream-Box: Object-wise Outlier Generation for Out-of-Distribution Detection(https://arxiv.org/abs/2504.18746)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep neural networks have demonstrated great generalization capabilities for tasks whose training and test sets are drawn from the same distribution. Nevertheless, out-of-distribution (OOD) detection remains a challenging task that has received significant attention in recent years. Specifically, OOD detection refers to the detection of instances that do not belong to the training distribution, while still having good performance on the in-distribution task (e.g., classification or object detection). Recent work has focused on generating synthetic outliers and using them to train an outlier detector, generally achieving improved OOD detection than traditional OOD methods. In this regard, outliers can be generated either in feature or pixel space. Feature space driven methods have shown strong performance on both the classification and object detection tasks, at the expense that the visualization of training outliers remains unknown, making further analysis on OOD failure modes challenging. On the other hand, pixel space outlier generation techniques enabled by diffusion models have been used for image classification using, providing improved OOD detection performance and outlier visualization, although their adaption to the object detection task is as yet unexplored. We therefore introduce Dream-Box, a method that provides a link to object-wise outlier generation in the pixel space for OOD detection. Specifically, we use diffusion models to generate object-wise outliers that are used to train an object detector for an in-distribution task and OOD detection. Our method achieves comparable performance to previous traditional methods while being the first technique to provide concrete visualization of generated OOD objects.</li>
</ul>

<h3>Title: Multi-Stage Boundary-Aware Transformer Network for Action Segmentation in Untrimmed Surgical Videos</h3>
<ul>
<li><strong>Authors: </strong>Rezowan Shuvo, M S Mekala, Eyad Elyan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18756">https://arxiv.org/abs/2504.18756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18756">https://arxiv.org/pdf/2504.18756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18756]] Multi-Stage Boundary-Aware Transformer Network for Action Segmentation in Untrimmed Surgical Videos(https://arxiv.org/abs/2504.18756)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Understanding actions within surgical workflows is essential for evaluating post-operative outcomes. However, capturing long sequences of actions performed in surgical settings poses challenges, as individual surgeons have their unique approaches shaped by their expertise, leading to significant variability. To tackle this complex problem, we focused on segmentation with precise boundaries, a demanding task due to the inherent variability in action durations and the subtle transitions often observed in untrimmed videos. These transitions, marked by ambiguous starting and ending points, complicate the segmentation process. Traditional models, such as MS-TCN, which depend on large receptive fields, frequently face challenges of over-segmentation (resulting in fragmented segments) or under-segmentation (merging distinct actions). Both of these issues negatively impact the quality of segmentation. To overcome these challenges, we present the Multi-Stage Boundary-Aware Transformer Network (MSBATN) with hierarchical sliding window attention, designed to enhance action segmentation. Our proposed approach incorporates a novel unified loss function that treats action classification and boundary detection as distinct yet interdependent tasks. Unlike traditional binary boundary detection methods, our boundary voting mechanism accurately identifies start and end points by leveraging contextual information. Extensive experiments using three challenging surgical datasets demonstrate the superior performance of the proposed method, achieving state-of-the-art results in F1 scores at thresholds of 25% and 50%, while also delivering comparable performance in other metrics.</li>
</ul>

<h3>Title: SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning</h3>
<ul>
<li><strong>Authors: </strong>Ojasw Upadhyay, Abishek Saravankumar, Ayman Ismail</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18762">https://arxiv.org/abs/2504.18762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18762">https://arxiv.org/pdf/2504.18762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18762]] SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning(https://arxiv.org/abs/2504.18762)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are powerful but often require extensive fine-tuning and large datasets for specialized domains like law. General-purpose pre-training may not capture legal nuances, and acquiring sufficient legal data is challenging. We introduce SynLexLM, a novel approach to efficiently pre-train a legal LLM. Our method employs curriculum learning, progressing from simple to complex legal texts and queries, combined with synthetic data augmentation using models like Gemini Pro to address data scarcity. We aim to achieve improved performance on legal benchmarks (BigLaw-Bench, EUR-Lex-Sum) compared to traditional models and fine-tuned versions. Preliminary work involves generating synthetic QA pairs reflecting legal reasoning. This work aims to enhance legal document analysis and research tools, potentially democratizing access to advanced legal AI.</li>
</ul>

<h3>Title: PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data</h3>
<ul>
<li><strong>Authors: </strong>Manuel Weber, Carly Beneke</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18770">https://arxiv.org/abs/2504.18770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18770">https://arxiv.org/pdf/2504.18770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18770]] PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data(https://arxiv.org/abs/2504.18770)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We propose PyViT-FUSE, a foundation model for earth observation data explicitly designed to handle multi-modal imagery by learning to fuse an arbitrary number of mixed-resolution input bands into a single representation through an attention mechanism. The learned patch tokens are further processed by a stack of vision transformers with a novel pyramidal structure. We train the model on a globally sampled dataset in a self-supervised manner, leveraging core concepts of the SwAV algorithm. We show the interpretability of the fusion mechanism by visualization of the attention scores and the models applicability to downstream tasks.</li>
</ul>

<h3>Title: Performance of Machine Learning Classifiers for Anomaly Detection in Cyber Security Applications</h3>
<ul>
<li><strong>Authors: </strong>Markus Haug, Gissel Velarde</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18771">https://arxiv.org/abs/2504.18771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18771">https://arxiv.org/pdf/2504.18771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18771]] Performance of Machine Learning Classifiers for Anomaly Detection in Cyber Security Applications(https://arxiv.org/abs/2504.18771)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative</a></li>
<li><strong>Abstract: </strong>This work empirically evaluates machine learning models on two imbalanced public datasets (KDDCUP99 and Credit Card Fraud 2013). The method includes data preparation, model training, and evaluation, using an 80/20 (train/test) split. Models tested include eXtreme Gradient Boosting (XGB), Multi Layer Perceptron (MLP), Generative Adversarial Network (GAN), Variational Autoencoder (VAE), and Multiple-Objective Generative Adversarial Active Learning (MO-GAAL), with XGB and MLP further combined with Random-Over-Sampling (ROS) and Self-Paced-Ensemble (SPE). Evaluation involves 5-fold cross-validation and imputation techniques (mean, median, and IterativeImputer) with 10, 20, 30, and 50 % missing data. Findings show XGB and MLP outperform generative models. IterativeImputer results are comparable to mean and median, but not recommended for large datasets due to increased complexity and execution time. The code used is publicly available on GitHub (this http URL).</li>
</ul>

<h3>Title: IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic</h3>
<ul>
<li><strong>Authors: </strong>Hassan Wasswa, Timothy Lynar, Aziida Nanyonga, Hussein Abbass</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18781">https://arxiv.org/abs/2504.18781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18781">https://arxiv.org/pdf/2504.18781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18781]] IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic(https://arxiv.org/abs/2504.18781)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Despite the demonstrated effectiveness of transformer models in NLP, and image and video classification, the available tools for extracting features from captured IoT network flow packets fail to capture sequential patterns in addition to the absence of spatial patterns consequently limiting transformer model application. This work introduces a novel preprocessing method to adapt transformer models, the vision transformer (ViT) in particular, for IoT botnet attack detection using network flow packets. The approach involves feature extraction from .pcap files and transforming each instance into a 1-channel 2D image shape, enabling ViT-based classification. Also, the ViT model was enhanced to allow use any classifier besides Multilayer Perceptron (MLP) that was deployed in the initial ViT paper. Models including the conventional feed forward Deep Neural Network (DNN), LSTM and Bidirectional-LSTM (BLSTM) demonstrated competitive performance in terms of precision, recall, and F1-score for multiclass-based attack detection when evaluated on two IoT attack datasets.</li>
</ul>

<h3>Title: CAMeL: Cross-modality Adaptive Meta-Learning for Text-based Person Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Hang Yu, Jiahao Wen, Zhedong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18782">https://arxiv.org/abs/2504.18782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18782">https://arxiv.org/pdf/2504.18782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18782]] CAMeL: Cross-modality Adaptive Meta-Learning for Text-based Person Retrieval(https://arxiv.org/abs/2504.18782)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Text-based person retrieval aims to identify specific individuals within an image database using textual descriptions. Due to the high cost of annotation and privacy protection, researchers resort to synthesized data for the paradigm of pretraining and fine-tuning. However, these generated data often exhibit domain biases in both images and textual annotations, which largely compromise the scalability of the pre-trained model. Therefore, we introduce a domain-agnostic pretraining framework based on Cross-modality Adaptive Meta-Learning (CAMeL) to enhance the model generalization capability during pretraining to facilitate the subsequent downstream tasks. In particular, we develop a series of tasks that reflect the diversity and complexity of real-world scenarios, and introduce a dynamic error sample memory unit to memorize the history for errors encountered within multiple tasks. To further ensure multi-task adaptation, we also adopt an adaptive dual-speed update strategy, balancing fast adaptation to new tasks and slow weight updates for historical tasks. Albeit simple, our proposed model not only surpasses existing state-of-the-art methods on real-world benchmarks, including CUHK-PEDES, ICFG-PEDES, and RSTPReid, but also showcases robustness and scalability in handling biased synthetic images and noisy text annotations. Our code is available at this https URL.</li>
</ul>

<h3>Title: ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding</h3>
<ul>
<li><strong>Authors: </strong>Santosh Rajagopalan, Jonathan Vronsky, Songbai Yan, S. Alireza Golestaneh, Shubhra Chandra, Min Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18785">https://arxiv.org/abs/2504.18785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18785">https://arxiv.org/pdf/2504.18785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18785]] ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding(https://arxiv.org/abs/2504.18785)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present ALF (Advertiser Large Foundation model), a multi-modal transformer architecture for understanding advertiser behavior and intent across text, image, video and structured data modalities. Through contrastive learning and multi-task optimization, ALF creates unified advertiser representations that capture both content and behavioral patterns. Our model achieves state-of-the-art performance on critical tasks including fraud detection, policy violation identification, and advertiser similarity matching. In production deployment, ALF reduces false positives by 90% while maintaining 99.8% precision on abuse detection tasks. The architecture's effectiveness stems from its novel combination of multi-modal transformations, inter-sample attention mechanism, spectrally normalized projections, and calibrated probabilistic outputs.</li>
</ul>

<h3>Title: Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation</h3>
<ul>
<li><strong>Authors: </strong>Jong Inn Park, Maanas Taneja, Qianwen Wang, Dongyeop Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18805">https://arxiv.org/abs/2504.18805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18805">https://arxiv.org/pdf/2504.18805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18805]] Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation(https://arxiv.org/abs/2504.18805)</code><input type="text"></li>
<li><strong>Keywords: </strong>steal</a></li>
<li><strong>Abstract: </strong>Generating engaging, accurate short-form videos from scientific papers is challenging due to content complexity and the gap between expert authors and readers. Existing end-to-end methods often suffer from factual inaccuracies and visual artifacts, limiting their utility for scientific dissemination. To address these issues, we propose SciTalk, a novel multi-LLM agentic framework, grounding videos in various sources, such as text, figures, visual styles, and avatars. Inspired by content creators' workflows, SciTalk uses specialized agents for content summarization, visual scene planning, and text and layout editing, and incorporates an iterative feedback mechanism where video agents simulate user roles to give feedback on generated videos from previous iterations and refine generation prompts. Experimental evaluations show that SciTalk outperforms simple prompting methods in generating scientifically accurate and engaging content over the refined loop of video generation. Although preliminary results are still not yet matching human creators' quality, our framework provides valuable insights into the challenges and benefits of feedback-driven video generation. Our code, data, and generated videos will be publicly available.</li>
</ul>

<h3>Title: Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning</h3>
<ul>
<li><strong>Authors: </strong>Yifan Xie, Fei Ma, Yi Bin, Ying He, Fei Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18810">https://arxiv.org/abs/2504.18810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18810">https://arxiv.org/pdf/2504.18810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18810]] Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning(https://arxiv.org/abs/2504.18810)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Talking face video generation with arbitrary speech audio is a significant challenge within the realm of digital human technology. The previous studies have emphasized the significance of audio-lip synchronization and visual quality. Currently, limited attention has been given to the learning of visual uncertainty, which creates several issues in existing systems, including inconsistent visual quality and unreliable performance across different input conditions. To address the problem, we propose a Joint Uncertainty Learning Network (JULNet) for high-quality talking face video generation, which incorporates a representation of uncertainty that is directly related to visual error. Specifically, we first design an uncertainty module to individually predict the error map and uncertainty map after obtaining the generated image. The error map represents the difference between the generated image and the ground truth image, while the uncertainty map is used to predict the probability of incorrect estimates. Furthermore, to match the uncertainty distribution with the error distribution through a KL divergence term, we introduce a histogram technique to approximate the distributions. By jointly optimizing error and uncertainty, the performance and robustness of our model can be enhanced. Extensive experiments demonstrate that our method achieves superior high-fidelity and audio-lip synchronization in talking face video generation compared to previous methods.</li>
</ul>

<h3>Title: SynFuzz: Leveraging Fuzzing of Netlist to Detect Synthesis Bugs</h3>
<ul>
<li><strong>Authors: </strong>Raghul Saravanan, Sudipta Paria, Aritra Dasgupta, Venkat Nitin Patnala, Swarup Bhunia, Sai Manoj P D</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18812">https://arxiv.org/abs/2504.18812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18812">https://arxiv.org/pdf/2504.18812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18812]] SynFuzz: Leveraging Fuzzing of Netlist to Detect Synthesis Bugs(https://arxiv.org/abs/2504.18812)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>In the evolving landscape of integrated circuit (IC) design, the increasing complexity of modern processors and intellectual property (IP) cores has introduced new challenges in ensuring design correctness and security. The recent advancements in hardware fuzzing techniques have shown their efficacy in detecting hardware bugs and vulnerabilities at the RTL abstraction level of hardware. However, they suffer from several limitations, including an inability to address vulnerabilities introduced during synthesis and gate-level transformations. These methods often fail to detect issues arising from library adversaries, where compromised or malicious library components can introduce backdoors or unintended behaviors into the design. In this paper, we present a novel hardware fuzzer, SynFuzz, designed to overcome the limitations of existing hardware fuzzing frameworks. SynFuzz focuses on fuzzing hardware at the gate-level netlist to identify synthesis bugs and vulnerabilities that arise during the transition from RTL to the gate-level. We analyze the intrinsic hardware behaviors using coverage metrics specifically tailored for the gate-level. Furthermore, SynFuzz implements differential fuzzing to uncover bugs associated with EDA libraries. We evaluated SynFuzz on popular open-source processors and IP designs, successfully identifying 7 new synthesis bugs. Additionally, by exploiting the optimization settings of EDA tools, we performed a compromised library mapping attack (CLiMA), creating a malicious version of hardware designs that remains undetectable by traditional verification methods. We also demonstrate how SynFuzz overcomes the limitations of the industry-standard formal verification tool, Cadence Conformal, providing a more robust and comprehensive approach to hardware verification.</li>
</ul>

<h3>Title: Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization</h3>
<ul>
<li><strong>Authors: </strong>Abdelaziz Amara korba, Nour Elislem Karabadji, Yacine Ghamri-Doudane</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18814">https://arxiv.org/abs/2504.18814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18814">https://arxiv.org/pdf/2504.18814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18814]] Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization(https://arxiv.org/abs/2504.18814)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The Internet of Vehicles (IoV) is transforming transportation by enhancing connectivity and enabling autonomous driving. However, this increased interconnectivity introduces new security vulnerabilities. Bot malware and cyberattacks pose significant risks to Connected and Autonomous Vehicles (CAVs), as demonstrated by real-world incidents involving remote vehicle system compromise. To address these challenges, we propose an edge-based Intrusion Detection System (IDS) that monitors network traffic to and from CAVs. Our detection model is based on a meta-ensemble classifier capable of recognizing known (Nday) attacks and detecting previously unseen (zero-day) attacks. The approach involves training multiple Isolation Forest (IF) models on Multi-access Edge Computing (MEC) servers, with each IF specialized in identifying a specific type of botnet attack. These IFs, either trained locally or shared by other MEC nodes, are then aggregated using a Particle Swarm Optimization (PSO) based stacking strategy to construct a robust meta-classifier. The proposed IDS has been evaluated on a vehicular botnet dataset, achieving an average detection rate of 92.80% for N-day attacks and 77.32% for zero-day attacks. These results highlight the effectiveness of our solution in detecting both known and emerging threats, providing a scalable and adaptive defense mechanism for CAVs within the IoV ecosystem.</li>
</ul>

<h3>Title: Frequency-Integrated Transformer for Arbitrary-Scale Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Xufei Wang, Fei Ge, Jinchen Zhu, Mingjian Zhang, Qi Wu, Jifeng Ren Shizhuang Weng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18818">https://arxiv.org/abs/2504.18818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18818">https://arxiv.org/pdf/2504.18818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18818]] Frequency-Integrated Transformer for Arbitrary-Scale Super-Resolution(https://arxiv.org/abs/2504.18818)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Methods based on implicit neural representation have demonstrated remarkable capabilities in arbitrary-scale super-resolution (ASSR) tasks, but they neglect the potential value of the frequency domain, leading to sub-optimal performance. We proposes a novel network called Frequency-Integrated Transformer (FIT) to incorporate and utilize frequency information to enhance ASSR performance. FIT employs Frequency Incorporation Module (FIM) to introduce frequency information in a lossless manner and Frequency Utilization Self-Attention module (FUSAM) to efficiently leverage frequency information by exploiting spatial-frequency interrelationship and global nature of frequency. FIM enriches detail characterization by incorporating frequency information through a combination of Fast Fourier Transform (FFT) with real-imaginary mapping. In FUSAM, Interaction Implicit Self-Attention (IISA) achieves cross-domain information synergy by interacting spatial and frequency information in subspace, while Frequency Correlation Self-attention (FCSA) captures the global context by computing correlation in frequency. Experimental results demonstrate FIT yields superior performance compared to existing methods across multiple benchmark datasets. Visual feature map proves the superiority of FIM in enriching detail characterization. Frequency error map validates IISA productively improve the frequency fidelity. Local attribution map validates FCSA effectively captures global context.</li>
</ul>

<h3>Title: Toward Generalizable Evaluation in the LLM Era: A Survey Beyond Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Yixin Cao, Shibo Hong, Xinze Li, Jiahao Ying, Yubo Ma, Haiyuan Liang, Yantao Liu, Zijun Yao, Xiaozhi Wang, Dan Huang, Wenxuan Zhang, Lifu Huang, Muhao Chen, Lei Hou, Qianru Sun, Xingjun Ma, Zuxuan Wu, Min-Yen Kan, David Lo, Qi Zhang, Heng Ji, Jing Jiang, Juanzi Li, Aixin Sun, Xuanjing Huang, Tat-Seng Chua, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18838">https://arxiv.org/abs/2504.18838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18838">https://arxiv.org/pdf/2504.18838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18838]] Toward Generalizable Evaluation in the LLM Era: A Survey Beyond Benchmarks(https://arxiv.org/abs/2504.18838)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are advancing at an amazing speed and have become indispensable across academia, industry, and daily applications. To keep pace with the status quo, this survey probes the core challenges that the rise of LLMs poses for evaluation. We identify and analyze two pivotal transitions: (i) from task-specific to capability-based evaluation, which reorganizes benchmarks around core competencies such as knowledge, reasoning, instruction following, multi-modal understanding, and safety; and (ii) from manual to automated evaluation, encompassing dynamic dataset curation and "LLM-as-a-judge" scoring. Yet, even with these transitions, a crucial obstacle persists: the evaluation generalization issue. Bounded test sets cannot scale alongside models whose abilities grow seemingly without limit. We will dissect this issue, along with the core challenges of the above two transitions, from the perspectives of methods, datasets, evaluators, and metrics. Due to the fast evolving of this field, we will maintain a living GitHub repository (links are in each section) to crowd-source updates and corrections, and warmly invite contributors and collaborators.</li>
</ul>

<h3>Title: Towards Robust Dialogue Breakdown Detection: Addressing Disruptors in Large Language Models with Self-Guided Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Abdellah Ghassel, Xianzhi Li, Xiaodan Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18839">https://arxiv.org/abs/2504.18839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18839">https://arxiv.org/pdf/2504.18839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18839]] Towards Robust Dialogue Breakdown Detection: Addressing Disruptors in Large Language Models with Self-Guided Reasoning(https://arxiv.org/abs/2504.18839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are rapidly changing various domains. However, their capabilities in handling conversational breakdowns still require an in-depth exploration. This paper addresses the challenge of detecting and mitigating dialogue breakdowns within LLM-driven conversational systems. While powerful models from OpenAI and Anthropic excel in many dialogue tasks, they can still produce incoherent or contradictory responses, commonly referred to as breakdowns, which undermine user trust. To tackle this, we propose an approach that combines specialized fine-tuning with advanced prompting strategies, including few-shot learning, chain-of-thought reasoning, and analogical prompting. In particular, we fine-tune a small 8B model and demonstrate its robust classification and calibration capabilities in English and Japanese dialogue. We also validate its generalization on the BETOLD dataset, achieving a 7\% accuracy improvement over its base model. Furthermore, we introduce a real-time deployment architecture that selectively escalates suspicious responses to more resource-intensive frontier models only when breakdowns are detected, significantly cutting operational expenses and energy consumption. Experimental results show our method surpasses prior state-of-the-art specialized classifiers while also narrowing performance gaps between smaller open-source models and large proprietary ones. Our approach offers a scalable solution for robust conversational AI in high-impact domains by combining efficiency, interpretability, and reliability.</li>
</ul>

<h3>Title: Theoretical Framework for Tempered Fractional Gradient Descent: Application to Breast Cancer Classification</h3>
<ul>
<li><strong>Authors: </strong>Omar Naifar</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18849">https://arxiv.org/abs/2504.18849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18849">https://arxiv.org/pdf/2504.18849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18849]] Theoretical Framework for Tempered Fractional Gradient Descent: Application to Breast Cancer Classification(https://arxiv.org/abs/2504.18849)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces Tempered Fractional Gradient Descent (TFGD), a novel optimization framework that synergizes fractional calculus with exponential tempering to enhance gradient-based learning. Traditional gradient descent methods often suffer from oscillatory updates and slow convergence in high-dimensional, noisy landscapes. TFGD addresses these limitations by incorporating a tempered memory mechanism, where historical gradients are weighted by fractional coefficients $|w_j| = \binom{\alpha}{j}$ and exponentially decayed via a tempering parameter $\lambda$. Theoretical analysis establishes TFGD's convergence guarantees: in convex settings, it achieves an $\mathcal{O}(1/K)$ rate with alignment coefficient $d_{\alpha,\lambda} = (1 - e^{-\lambda})^{-\alpha}$, while stochastic variants attain $\mathcal{O}(1/k^\alpha)$ error decay. The algorithm maintains $\mathcal{O}(n)$ time complexity equivalent to SGD, with memory overhead scaling as $\mathcal{O}(d/\lambda)$ for parameter dimension $d$. Empirical validation on the Breast Cancer Wisconsin dataset demonstrates TFGD's superiority, achieving 98.25\% test accuracy (vs. 92.11\% for SGD) and 2$\times$ faster convergence. The tempered memory mechanism proves particularly effective in medical classification tasks, where feature correlations benefit from stable gradient averaging. These results position TFGD as a robust alternative to conventional optimizers in both theoretical and applied machine learning.</li>
</ul>

<h3>Title: Effective Length Extrapolation via Dimension-Wise Positional Embeddings Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Yi Lu, Wanxu Zhao, Xin Zhou, Chenxin An, Chenglong Wang, Shuo Li, Yuming Yang, Jun Zhao, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18857">https://arxiv.org/abs/2504.18857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18857">https://arxiv.org/pdf/2504.18857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18857]] Effective Length Extrapolation via Dimension-Wise Positional Embeddings Manipulation(https://arxiv.org/abs/2504.18857)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often struggle to process and generate coherent context when the number of input tokens exceeds the pre-trained length. Recent advancements in long-context extension have significantly expanded the context window of LLMs but require expensive overhead to train the large-scale models with longer context. In this work, we propose Dimension-Wise Positional Embeddings Manipulation (DPE), a training-free framework to extrapolate the context window of LLMs by diving into RoPE's different hidden dimensions. Instead of manipulating all dimensions equally, DPE detects the effective length for every dimension and finds the key dimensions for context extension. We reuse the original position indices with their embeddings from the pre-trained model and manipulate the key dimensions' position indices to their most effective lengths. In this way, DPE adjusts the pre-trained models with minimal modifications while ensuring that each dimension reaches its optimal state for extrapolation. DPE significantly surpasses well-known baselines such as YaRN and Self-Extend. DPE enables Llama3-8k 8B to support context windows of 128k tokens without continual training and integrates seamlessly with Flash Attention 2. In addition to its impressive extrapolation capability, DPE also dramatically improves the models' performance within training length, such as Llama3.1 70B, by over 18 points on popular long-context benchmarks RULER. When compared with commercial models, Llama 3.1 70B with DPE even achieves better performance than GPT-4-128K.</li>
</ul>

<h3>Title: PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance</h3>
<ul>
<li><strong>Authors: </strong>Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Mengjingcheng Mo, Jiankang Zheng, Qingqing Li, Ji Gan, Xinbo Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18866">https://arxiv.org/abs/2504.18866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18866">https://arxiv.org/pdf/2504.18866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18866]] PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance(https://arxiv.org/abs/2504.18866)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing weakly supervised video violence detection (VVD) methods primarily rely on Euclidean representation learning, which often struggles to distinguish visually similar yet semantically distinct events due to limited hierarchical modeling and insufficient ambiguous training samples. To address this challenge, we propose PiercingEye, a novel dual-space learning framework that synergizes Euclidean and hyperbolic geometries to enhance discriminative feature representation. Specifically, PiercingEye introduces a layer-sensitive hyperbolic aggregation strategy with hyperbolic Dirichlet energy constraints to progressively model event hierarchies, and a cross-space attention mechanism to facilitate complementary feature interactions between Euclidean and hyperbolic spaces. Furthermore, to mitigate the scarcity of ambiguous samples, we leverage large language models to generate logic-guided ambiguous event descriptions, enabling explicit supervision through a hyperbolic vision-language contrastive loss that prioritizes high-confusion samples via dynamic similarity-aware weighting. Extensive experiments on XD-Violence and UCF-Crime benchmarks demonstrate that PiercingEye achieves state-of-the-art performance, with particularly strong results on a newly curated ambiguous event subset, validating its superior capability in fine-grained violence detection.</li>
</ul>

<h3>Title: WLTCL: Wide Field-of-View 3-D LiDAR Truck Compartment Automatic Localization System</h3>
<ul>
<li><strong>Authors: </strong>Guodong Sun, Mingjing Li, Dingjie Liu, Mingxuan Liu, Bo Wu, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18870">https://arxiv.org/abs/2504.18870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18870">https://arxiv.org/pdf/2504.18870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18870]] WLTCL: Wide Field-of-View 3-D LiDAR Truck Compartment Automatic Localization System(https://arxiv.org/abs/2504.18870)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>As an essential component of logistics automation, the automated loading system is becoming a critical technology for enhancing operational efficiency and safety. Precise automatic positioning of the truck compartment, which serves as the loading area, is the primary step in automated loading. However, existing methods have difficulty adapting to truck compartments of various sizes, do not establish a unified coordinate system for LiDAR and mobile manipulators, and often exhibit reliability issues in cluttered environments. To address these limitations, our study focuses on achieving precise automatic positioning of key points in large, medium, and small fence-style truck compartments in cluttered scenarios. We propose an innovative wide field-of-view 3-D LiDAR vehicle compartment automatic localization system. For vehicles of various sizes, this system leverages the LiDAR to generate high-density point clouds within an extensive field-of-view range. By incorporating parking area constraints, our vehicle point cloud segmentation method more effectively segments vehicle point clouds within the scene. Our compartment key point positioning algorithm utilizes the geometric features of the compartments to accurately locate the corner points, providing stackable spatial regions. Extensive experiments on our collected data and public datasets demonstrate that this system offers reliable positioning accuracy and reduced computational resource consumption, leading to its application and promotion in relevant fields.</li>
</ul>

<h3>Title: Latent Adversarial Training Improves the Representation of Refusal</h3>
<ul>
<li><strong>Authors: </strong>Alexandra Abbas, Nora Petrova, Helios Ael Lyons, Natalia Perez-Campanero</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18872">https://arxiv.org/abs/2504.18872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18872">https://arxiv.org/pdf/2504.18872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18872]] Latent Adversarial Training Improves the Representation of Refusal(https://arxiv.org/abs/2504.18872)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Recent work has shown that language models' refusal behavior is primarily encoded in a single direction in their latent space, making it vulnerable to targeted attacks. Although Latent Adversarial Training (LAT) attempts to improve robustness by introducing noise during training, a key question remains: How does this noise-based training affect the underlying representation of refusal behavior? Understanding this encoding is crucial for evaluating LAT's effectiveness and limitations, just as the discovery of linear refusal directions revealed vulnerabilities in traditional supervised safety fine-tuning (SSFT). Through the analysis of Llama 2 7B, we examine how LAT reorganizes the refusal behavior in the model's latent space compared to SSFT and embedding space adversarial training (AT). By computing activation differences between harmful and harmless instruction pairs and applying Singular Value Decomposition (SVD), we find that LAT significantly alters the refusal representation, concentrating it in the first two SVD components which explain approximately 75 percent of the activation differences variance - significantly higher than in reference models. This concentrated representation leads to more effective and transferable refusal vectors for ablation attacks: LAT models show improved robustness when attacked with vectors from reference models but become more vulnerable to self-generated vectors compared to SSFT and AT. Our findings suggest that LAT's training perturbations enable a more comprehensive representation of refusal behavior, highlighting both its potential strengths and vulnerabilities for improving model safety.</li>
</ul>

<h3>Title: TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation</h3>
<ul>
<li><strong>Authors: </strong>Robert Leppich, Michael Stenger, Daniel Grillmeyer, Vanessa Borst, Samuel Kounev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18878">https://arxiv.org/abs/2504.18878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18878">https://arxiv.org/pdf/2504.18878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18878]] TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation(https://arxiv.org/abs/2504.18878)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>We introduce a temporal feature encoding architecture called Time Series Representation Model (TSRM) for multivariate time series forecasting and imputation. The architecture is structured around CNN-based representation layers, each dedicated to an independent representation learning task and designed to capture diverse temporal patterns, followed by an attention-based feature extraction layer and a merge layer, designed to aggregate extracted features. The architecture is fundamentally based on a configuration that is inspired by a Transformer encoder, with self-attention mechanisms at its core. The TSRM architecture outperforms state-of-the-art approaches on most of the seven established benchmark datasets considered in our empirical evaluation for both forecasting and imputation tasks. At the same time, it significantly reduces complexity in the form of learnable parameters. The source code is available at this https URL.</li>
</ul>

<h3>Title: A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Junichiro Niimi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18884">https://arxiv.org/abs/2504.18884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18884">https://arxiv.org/pdf/2504.18884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18884]] A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification(https://arxiv.org/abs/2504.18884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>With the advance of large language models (LLMs), LLMs have been utilized for the various tasks. However, the issues of variability and reproducibility of results from each trial of LLMs have been largely overlooked in existing literature while actual human annotation uses majority voting to resolve disagreements among annotators. Therefore, this study introduces the straightforward ensemble strategy to a sentiment analysis using LLMs. As the results, we demonstrate that the ensemble of multiple inference using medium-sized LLMs produces more robust and accurate results than using a large model with a single attempt with reducing RMSE by 18.6%.</li>
</ul>

<h3>Title: Exploiting Multiple Representations: 3D Face Biometrics Fusion with Application to Surveillance</h3>
<ul>
<li><strong>Authors: </strong>Simone Maurizio La Cava, Roberto Casula, Sara Concas, Giulia Orrù, Ruben Tolosana, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18886">https://arxiv.org/abs/2504.18886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18886">https://arxiv.org/pdf/2504.18886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18886]] Exploiting Multiple Representations: 3D Face Biometrics Fusion with Application to Surveillance(https://arxiv.org/abs/2504.18886)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>3D face reconstruction (3DFR) algorithms are based on specific assumptions tailored to the limits and characteristics of the different application scenarios. In this study, we investigate how multiple state-of-the-art 3DFR algorithms can be used to generate a better representation of subjects, with the final goal of improving the performance of face recognition systems in challenging uncontrolled scenarios. We also explore how different parametric and non-parametric score-level fusion methods can exploit the unique strengths of multiple 3DFR algorithms to enhance biometric recognition robustness. With this goal, we propose a comprehensive analysis of several face recognition systems across diverse conditions, such as varying distances and camera setups, intra-dataset and cross-dataset, to assess the robustness of the proposed ensemble method. The results demonstrate that the distinct information provided by different 3DFR algorithms can alleviate the problem of generalizing over multiple application scenarios. In addition, the present study highlights the potential of advanced fusion strategies to enhance the reliability of 3DFR-based face recognition systems, providing the research community with key insights to exploit them in real-world applications effectively. Although the experiments are carried out in a specific face verification setup, our proposed fusion-based 3DFR methods may be applied to other tasks around face biometrics that are not strictly related to identity recognition.</li>
</ul>

<h3>Title: Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness</h3>
<ul>
<li><strong>Authors: </strong>Yufeng Wu, Xin Liao, Baowei Wang, Han Fang, Xiaoshuai Wu, Guiling Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18906">https://arxiv.org/abs/2504.18906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18906">https://arxiv.org/pdf/2504.18906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18906]] Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness(https://arxiv.org/abs/2504.18906)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, watermark</a></li>
<li><strong>Abstract: </strong>Unauthorized screen capturing and dissemination pose severe security threats such as data leakage and information theft. Several studies propose robust watermarking methods to track the copyright of Screen-Camera (SC) images, facilitating post-hoc certification against infringement. These techniques typically employ heuristic mathematical modeling or supervised neural network fitting as the noise layer, to enhance watermarking robustness against SC. However, both strategies cannot fundamentally achieve an effective approximation of SC noise. Mathematical simulation suffers from biased approximations due to the incomplete decomposition of the noise and the absence of interdependence among the noise components. Supervised networks require paired data to train the noise-fitting model, and it is difficult for the model to learn all the features of the noise. To address the above issues, we propose Simulation-to-Real (S2R). Specifically, an unsupervised noise layer employs unpaired data to learn the discrepancy between the modeling simulated noise distribution and the real-world SC noise distribution, rather than directly learning the mapping from sharp images to real-world images. Learning this transformation from simulation to reality is inherently simpler, as it primarily involves bridging the gap in noise distributions, instead of the complex task of reconstructing fine-grained image details. Extensive experimental results validate the efficacy of the proposed method, demonstrating superior watermark robustness and generalization compared to those of state-of-the-art methods.</li>
</ul>

<h3>Title: Factor Analysis with Correlated Topic Model for Multi-Modal Data</h3>
<ul>
<li><strong>Authors: </strong>Małgorzata Łazęcka, Ewa Szczurek</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18914">https://arxiv.org/abs/2504.18914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18914">https://arxiv.org/pdf/2504.18914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18914]] Factor Analysis with Correlated Topic Model for Multi-Modal Data(https://arxiv.org/abs/2504.18914)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Integrating various data modalities brings valuable insights into underlying phenomena. Multimodal factor analysis (FA) uncovers shared axes of variation underlying different simple data modalities, where each sample is represented by a vector of features. However, FA is not suited for structured data modalities, such as text or single cell sequencing data, where multiple data points are measured per each sample and exhibit a clustering structure. To overcome this challenge, we introduce FACTM, a novel, multi-view and multi-structure Bayesian model that combines FA with correlated topic modeling and is optimized using variational inference. Additionally, we introduce a method for rotating latent factors to enhance interpretability with respect to binary features. On text and video benchmarks as well as real-world music and COVID-19 datasets, we demonstrate that FACTM outperforms other methods in identifying clusters in structured data, and integrating them with simple modalities via the inference of shared, interpretable factors.</li>
</ul>

<h3>Title: Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Ruifeng Ren, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18929">https://arxiv.org/abs/2504.18929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18929">https://arxiv.org/pdf/2504.18929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18929]] Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity(https://arxiv.org/abs/2504.18929)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Compression has been a critical lens to understand the success of Transformers. In the past, we have typically taken the target distribution as a criterion to evaluate a model's compression performance. Nevertheless,it often remains challenging to precisely assess how well the model achieves compression and to compare the information content of the learned distribution with that of the target distribution during compression,as the target distribution is typically unknown and entropy computation often incurs exponential cost. In this work, we explore these issues under a controlled experimental setup. We find that Transformers exhibit a unique inductive bias in data compression: beyond approaching the target distribution, they tend to favor learning lower-entropy distributions, with this tendency becoming more pronounced as the model size increases. This preference prevents Transformers from perfectly aligning with the target distribution, instead further compressing its information content. Furthermore, we show that the FFN module plays a critical role in driving this bias. In addition, while models remove informational redundancy from data during compression, they also exhibit redundancy within their parameters, which enables compression and can be characterized through dynamic sparsity. However, the dynamic sparsity patterns in Transformers, particularly in attention and FFN modules, demand further exploration. As for this, we show that larger Transformers show stronger preferences for bypassing attention computations via residual connections and have lower proportion of active neurons. Interestingly, we also find that training instability in larger models strongly correlates with sudden increases in dead neurons. Our work contributes to a deeper understanding of Transformers from the lens of entropy and dynamic sparsity.</li>
</ul>

<h3>Title: MTCSC: Retrieval-Augmented Iterative Refinement for Chinese Spelling Correction</h3>
<ul>
<li><strong>Authors: </strong>Junhong Liang, Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18938">https://arxiv.org/abs/2504.18938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18938">https://arxiv.org/pdf/2504.18938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18938]] MTCSC: Retrieval-Augmented Iterative Refinement for Chinese Spelling Correction(https://arxiv.org/abs/2504.18938)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chinese Spelling Correction (CSC) aims to detect and correct erroneous tokens in sentences. While Large Language Models (LLMs) have shown remarkable success in identifying and rectifying potential errors, they often struggle with maintaining consistent output lengths and adapting to domain-specific corrections. Furthermore, existing CSC task impose rigid constraints requiring input and output lengths to be identical, limiting their applicability. In this work, we extend traditional CSC to variable-length correction scenarios, including Chinese Splitting Error Correction (CSEC) and ASR N-best Error Correction. To address domain adaptation and length consistency, we propose MTCSC (Multi-Turn CSC) framework based on RAG enhanced with a length reflection mechanism. Our approach constructs a retrieval database from domain-specific training data and dictionaries, fine-tuning retrievers to optimize performance for error-containing inputs. Additionally, we introduce a multi-source combination strategy with iterative length reflection to ensure output length fidelity. Experiments across diverse domain datasets demonstrate that our method significantly outperforms current approaches in correction quality, particularly in handling domain-specific and variable-length error correction tasks.</li>
</ul>

<h3>Title: R-Sparse R-CNN: SAR Ship Detection Based on Background-Aware Sparse Learnable Proposals</h3>
<ul>
<li><strong>Authors: </strong>Kamirul Kamirul, Odysseas Pappas, Alin Achim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18959">https://arxiv.org/abs/2504.18959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18959">https://arxiv.org/pdf/2504.18959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18959]] R-Sparse R-CNN: SAR Ship Detection Based on Background-Aware Sparse Learnable Proposals(https://arxiv.org/abs/2504.18959)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce R-Sparse R-CNN, a novel pipeline for oriented ship detection in Synthetic Aperture Radar (SAR) images that leverages sparse learnable proposals enriched with background contextual information, termed background-aware proposals (BAPs). The adoption of sparse proposals streamlines the pipeline by eliminating the need for proposal generators and post-processing for overlapping predictions. The proposed BAPs enrich object representation by integrating ship and background features, allowing the model to learn their contextual relationships for more accurate distinction of ships in complex environments. To complement BAPs, we propose Dual-Context Pooling (DCP), a novel strategy that jointly extracts ship and background features in a single unified operation. This unified design improves efficiency by eliminating redundant computation inherent in separate pooling. Moreover, by ensuring that ship and background features are pooled from the same feature map level, DCP provides aligned features that improve contextual relationship learning. Finally, as a core component of contextual relationship learning in R-Sparse R-CNN, we design a dedicated transformer-based Interaction Module. This module interacts pooled ship and background features with corresponding proposal features and models their relationships. Experimental results show that R-Sparse R-CNN delivers outstanding accuracy, surpassing state-of-the-art models by margins of up to 12.8% and 11.9% on SSDD and RSDD-SAR inshore datasets, respectively. These results demonstrate the effectiveness and competitiveness of R-Sparse R-CNN as a robust framework for oriented ship detection in SAR imagery. The code is available at: this http URL.</li>
</ul>

<h3>Title: Redefining Hybrid Blockchains: A Balanced Architecture</h3>
<ul>
<li><strong>Authors: </strong>Syed Ibrahim Omer</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18966">https://arxiv.org/abs/2504.18966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18966">https://arxiv.org/pdf/2504.18966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18966]] Redefining Hybrid Blockchains: A Balanced Architecture(https://arxiv.org/abs/2504.18966)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Blockchain technology has completely revolutionized the field of decentralized finance with the emergence of a variety of cryptocurrencies and digital assets. However, widespread adoption of this technology by governments and enterprises has been limited by concerns regarding the technology's scalability, governance, and economic sustainability. This paper aims to introduce a novel hybrid blockchain architecture that balances scalability, governance, and decentralization while being economically viable for all parties involved. The new semi-centralized model leverages strategies not prevalent in the field, such as resource and node isolation, containerization, separation of networking and compute layers, use of a Kafka pub-sub network instead of a peer-to-peer network, and stakes-based validator selection to possibly mitigate a variety of issues related to scalability, security, governance, and economic sustainability. Simulations conducted on Kubernetes demonstrate the architecture's ability to achieve over 1000 transactions per second, with consistent performance across scaled deployments, even on a lightweight consumer-grade laptop with resource constraints. The findings highlight the system's scalability, security, and economic viability, offering a robust framework for enterprise and government adoption.</li>
</ul>

<h3>Title: SONNI: Secure Oblivious Neural Network Inference</h3>
<ul>
<li><strong>Authors: </strong>Luke Sperling, Sandeep S. Kulkarni</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18974">https://arxiv.org/abs/2504.18974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18974">https://arxiv.org/pdf/2504.18974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18974]] SONNI: Secure Oblivious Neural Network Inference(https://arxiv.org/abs/2504.18974)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack, steal</a></li>
<li><strong>Abstract: </strong>In the standard privacy-preserving Machine learning as-a-service (MLaaS) model, the client encrypts data using homomorphic encryption and uploads it to a server for computation. The result is then sent back to the client for decryption. It has become more and more common for the computation to be outsourced to third-party servers. In this paper we identify a weakness in this protocol that enables a completely undetectable novel model-stealing attack that we call the Silver Platter attack. This attack works even under multikey encryption that prevents a simple collusion attack to steal model parameters. We also propose a mitigation that protects privacy even in the presence of a malicious server and malicious client or model provider (majority dishonest). When compared to a state-of-the-art but small encrypted model with 32k parameters, we preserve privacy with a failure chance of 1.51 x 10^-28 while batching capability is reduced by 0.2%. Our approach uses a novel results-checking protocol that ensures the computation was performed correctly without violating honest clients' data privacy. Even with collusion between the client and the server, they are unable to steal model parameters. Additionally, the model provider cannot learn any client data if maliciously working with the server.</li>
</ul>

<h3>Title: MediAug: Exploring Visual Augmentation in Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Xuyin Qi, Zeyu Zhang, Canxuan Gang, Hao Zhang, Lei Zhang, Zhiwei Zhang, Yang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18983">https://arxiv.org/abs/2504.18983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18983">https://arxiv.org/pdf/2504.18983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18983]] MediAug: Exploring Visual Augmentation in Medical Imaging(https://arxiv.org/abs/2504.18983)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Data augmentation is essential in medical imaging for improving classification accuracy, lesion detection, and organ segmentation under limited data conditions. However, two significant challenges remain. First, a pronounced domain gap between natural photographs and medical images can distort critical disease features. Second, augmentation studies in medical imaging are fragmented and limited to single tasks or architectures, leaving the benefits of advanced mix-based strategies unclear. To address these challenges, we propose a unified evaluation framework with six mix-based augmentation methods integrated with both convolutional and transformer backbones on brain tumour MRI and eye disease fundus datasets. Our contributions are threefold. (1) We introduce MediAug, a comprehensive and reproducible benchmark for advanced data augmentation in medical imaging. (2) We systematically evaluate MixUp, YOCO, CropMix, CutMix, AugMix, and SnapMix with ResNet-50 and ViT-B backbones. (3) We demonstrate through extensive experiments that MixUp yields the greatest improvement on the brain tumor classification task for ResNet-50 with 79.19% accuracy and SnapMix yields the greatest improvement for ViT-B with 99.44% accuracy, and that YOCO yields the greatest improvement on the eye disease classification task for ResNet-50 with 91.60% accuracy and CutMix yields the greatest improvement for ViT-B with 97.94% accuracy. Code will be available at this https URL.</li>
</ul>

<h3>Title: Safety Interventions against Adversarial Patches in an Open-Source Driver Assistance System</h3>
<ul>
<li><strong>Authors: </strong>Cheng Chen, Grant Xiao, Daehyun Lee, Lishan Yang, Evgenia Smirni, Homa Alemzadeh, Xugui Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.18990">https://arxiv.org/abs/2504.18990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.18990">https://arxiv.org/pdf/2504.18990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.18990]] Safety Interventions against Adversarial Patches in an Open-Source Driver Assistance System(https://arxiv.org/abs/2504.18990)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Drivers are becoming increasingly reliant on advanced driver assistance systems (ADAS) as autonomous driving technology becomes more popular and developed with advanced safety features to enhance road safety. However, the increasing complexity of the ADAS makes autonomous vehicles (AVs) more exposed to attacks and accidental faults. In this paper, we evaluate the resilience of a widely used ADAS against safety-critical attacks that target perception inputs. Various safety mechanisms are simulated to assess their impact on mitigating attacks and enhancing ADAS resilience. Experimental results highlight the importance of timely intervention by human drivers and automated safety mechanisms in preventing accidents in both driving and lateral directions and the need to resolve conflicts among safety interventions to enhance system resilience and reliability.</li>
</ul>

<h3>Title: Unveiling and Mitigating Adversarial Vulnerabilities in Iterative Optimizers</h3>
<ul>
<li><strong>Authors: </strong>Elad Sofer, Tomer Shaked, Caroline Chaux, Nir Shlezinger</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19000">https://arxiv.org/abs/2504.19000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19000">https://arxiv.org/pdf/2504.19000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19000]] Unveiling and Mitigating Adversarial Vulnerabilities in Iterative Optimizers(https://arxiv.org/abs/2504.19000)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) models are often sensitive to carefully crafted yet seemingly unnoticeable perturbations. Such adversarial examples are considered to be a property of ML models, often associated with their black-box operation and sensitivity to features learned from data. This work examines the adversarial sensitivity of non-learned decision rules, and particularly of iterative optimizers. Our analysis is inspired by the recent developments in deep unfolding, which cast such optimizers as ML models. We show that non-learned iterative optimizers share the sensitivity to adversarial examples of ML models, and that attacking iterative optimizers effectively alters the optimization objective surface in a manner that modifies the minima sought. We then leverage the ability to cast iteration-limited optimizers as ML models to enhance robustness via adversarial training. For a class of proximal gradient optimizers, we rigorously prove how their learning affects adversarial sensitivity. We numerically back our findings, showing the vulnerability of various optimizers, as well as the robustness induced by unfolding and adversarial training.</li>
</ul>

<h3>Title: Deep Learning-Based Multi-Modal Fusion for Robust Robot Perception and Navigation</h3>
<ul>
<li><strong>Authors: </strong>Delun Lai, Yeyubei Zhang, Yunchong Liu, Chaojie Li, Huadong Mo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19002">https://arxiv.org/abs/2504.19002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19002">https://arxiv.org/pdf/2504.19002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19002]] Deep Learning-Based Multi-Modal Fusion for Robust Robot Perception and Navigation(https://arxiv.org/abs/2504.19002)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel deep learning-based multimodal fusion architecture aimed at enhancing the perception capabilities of autonomous navigation robots in complex environments. By utilizing innovative feature extraction modules, adaptive fusion strategies, and time-series modeling mechanisms, the system effectively integrates RGB images and LiDAR data. The key contributions of this work are as follows: a. the design of a lightweight feature extraction network to enhance feature representation; b. the development of an adaptive weighted cross-modal fusion strategy to improve system robustness; and c. the incorporation of time-series information modeling to boost dynamic scene perception accuracy. Experimental results on the KITTI dataset demonstrate that the proposed approach increases navigation and positioning accuracy by 3.5% and 2.2%, respectively, while maintaining real-time performance. This work provides a novel solution for autonomous robot navigation in complex environments.</li>
</ul>

<h3>Title: \$PINN -- a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Júlia Vicens Figueres, Juliette Vanderhaeghen, Federica Bragone, Kateryna Morozovska, Khemraj Shukla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19013">https://arxiv.org/abs/2504.19013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19013">https://arxiv.org/pdf/2504.19013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19013]] \$PINN -- a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks(https://arxiv.org/abs/2504.19013)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-Informed Neural Networks (PINNs) are a novel computational approach for solving partial differential equations (PDEs) with noisy and sparse initial and boundary data. Although, efficient quantification of epistemic and aleatoric uncertainties in big multi-scale problems remains challenging. We propose \$PINN a novel method of computing global uncertainty in PDEs using a Bayesian framework, by combining local Bayesian Physics-Informed Neural Networks (BPINN) with domain decomposition. The solution continuity across subdomains is obtained by imposing the flux continuity across the interface of neighboring subdomains. To demonstrate the effectiveness of \$PINN, we conduct a series of computational experiments on PDEs in 1D and 2D spatial domains. Although we have adopted conservative PINNs (cPINNs), the method can be seamlessly extended to other domain decomposition techniques. The results infer that the proposed method recovers the global uncertainty by computing the local uncertainty exactly more efficiently as the uncertainty in each subdomain can be computed concurrently. The robustness of \$PINN is verified by adding uncorrelated random noise to the training data up to 15% and testing for different domain sizes.</li>
</ul>

<h3>Title: Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Akbar-Tajari, Mohammad Taher Pilehvar, Mohammad Mahmoody</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19019">https://arxiv.org/abs/2504.19019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19019">https://arxiv.org/pdf/2504.19019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19019]] Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs(https://arxiv.org/abs/2504.19019)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The challenge of ensuring Large Language Models (LLMs) align with societal standards is of increasing interest, as these models are still prone to adversarial jailbreaks that bypass their safety mechanisms. Identifying these vulnerabilities is crucial for enhancing the robustness of LLMs against such exploits. We propose Graph of ATtacks (GoAT), a method for generating adversarial prompts to test the robustness of LLM alignment using the Graph of Thoughts framework [Besta et al., 2024]. GoAT excels at generating highly effective jailbreak prompts with fewer queries to the victim model than state-of-the-art attacks, achieving up to five times better jailbreak success rate against robust models like Llama. Notably, GoAT creates high-quality, human-readable prompts without requiring access to the targeted model's parameters, making it a black-box attack. Unlike approaches constrained by tree-based reasoning, GoAT's reasoning is based on a more intricate graph structure. By making simultaneous attack paths aware of each other's progress, this dynamic framework allows a deeper integration and refinement of reasoning paths, significantly enhancing the collaborative exploration of adversarial vulnerabilities in LLMs. At a technical level, GoAT starts with a graph structure and iteratively refines it by combining and improving thoughts, enabling synergy between different thought paths. The code for our implementation can be found at: this https URL.</li>
</ul>

<h3>Title: Advancing Scientific Text Classification: Fine-Tuned Models with Dataset Expansion and Hard-Voting</h3>
<ul>
<li><strong>Authors: </strong>Zhyar Rzgar K Rostam, Gábor Kertész</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19021">https://arxiv.org/abs/2504.19021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19021">https://arxiv.org/pdf/2504.19021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19021]] Advancing Scientific Text Classification: Fine-Tuned Models with Dataset Expansion and Hard-Voting(https://arxiv.org/abs/2504.19021)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Efficient text classification is essential for handling the increasing volume of academic publications. This study explores the use of pre-trained language models (PLMs), including BERT, SciBERT, BioBERT, and BlueBERT, fine-tuned on the Web of Science (WoS-46985) dataset for scientific text classification. To enhance performance, we augment the dataset by executing seven targeted queries in the WoS database, retrieving 1,000 articles per category aligned with WoS-46985's main classes. PLMs predict labels for this unlabeled data, and a hard-voting strategy combines predictions for improved accuracy and confidence. Fine-tuning on the expanded dataset with dynamic learning rates and early stopping significantly boosts classification accuracy, especially in specialized domains. Domain-specific models like SciBERT and BioBERT consistently outperform general-purpose models such as BERT. These findings underscore the efficacy of dataset augmentation, inference-driven label prediction, hard-voting, and fine-tuning techniques in creating robust and scalable solutions for automated academic text classification.</li>
</ul>

<h3>Title: KETCHUP: K-Step Return Estimation for Sequential Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Jiabin Fan, Guoqing Luo, Michael Bowling, Lili Mou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19024">https://arxiv.org/abs/2504.19024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19024">https://arxiv.org/pdf/2504.19024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19024]] KETCHUP: K-Step Return Estimation for Sequential Knowledge Distillation(https://arxiv.org/abs/2504.19024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose a novel k-step return estimation method (called KETCHUP) for Reinforcement Learning(RL)-based knowledge distillation (KD) in text generation tasks. Our idea is to induce a K-step return by using the Bellman Optimality Equation for multiple steps. Theoretical analysis shows that this K-step formulation reduces the variance of the gradient estimates, thus leading to improved RL optimization especially when the student model size is large. Empirical evaluation on three text generation tasks demonstrates that our approach yields superior performance in both standard task metrics and large language model (LLM)-based evaluation. These results suggest that our K-step return induction offers a promising direction for enhancing RL-based KD in LLM research.</li>
</ul>

<h3>Title: VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation</h3>
<ul>
<li><strong>Authors: </strong>Niaz Ahmad, Youngmoon Lee, Guanghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19032">https://arxiv.org/abs/2504.19032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19032">https://arxiv.org/pdf/2504.19032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19032]] VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation(https://arxiv.org/abs/2504.19032)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We introduce VISUALCENT, a unified human pose and instance segmentation framework to address generalizability and scalability limitations to multi person visual human analysis. VISUALCENT leverages centroid based bottom up keypoint detection paradigm and uses Keypoint Heatmap incorporating Disk Representation and KeyCentroid to identify the optimal keypoint coordinates. For the unified segmentation task, an explicit keypoint is defined as a dynamic centroid called MaskCentroid to swiftly cluster pixels to specific human instance during rapid changes in human body movement or significantly occluded environment. Experimental results on COCO and OCHuman datasets demonstrate VISUALCENTs accuracy and real time performance advantages, outperforming existing methods in mAP scores and execution frame rate per second. The implementation is available on the project page.</li>
</ul>

<h3>Title: Atlantes: A system of GPS transformers for global-scale real-time maritime intelligence</h3>
<ul>
<li><strong>Authors: </strong>Henry Herzog, Joshua Hansen, Yawen Zhang, Patrick Beukema</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19036">https://arxiv.org/abs/2504.19036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19036">https://arxiv.org/pdf/2504.19036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19036]] Atlantes: A system of GPS transformers for global-scale real-time maritime intelligence(https://arxiv.org/abs/2504.19036)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Unsustainable exploitation of the oceans exacerbated by global warming is threatening coastal communities worldwide. Accurate and timely monitoring of maritime activity is an essential step to effective governance and to inform future policy. In support of this complex global-scale effort, we built Atlantes, a deep learning based system that provides the first-ever real-time view of vessel behavior at global scale. Atlantes leverages a series of bespoke transformers to distill a high volume, continuous stream of GPS messages emitted by hundreds of thousands of vessels into easily quantifiable behaviors. The combination of low latency and high performance enables operationally relevant decision-making and successful interventions on the high seas where illegal and exploitative activity is too common. Atlantes is already in use by hundreds of organizations worldwide. Here we provide an overview of the model and infrastructure that enables this system to function efficiently and cost-effectively at global-scale and in real-time.</li>
</ul>

<h3>Title: Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity</h3>
<ul>
<li><strong>Authors: </strong>Nandan Joshi, Erhan Guven</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19040">https://arxiv.org/abs/2504.19040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19040">https://arxiv.org/pdf/2504.19040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19040]] Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity(https://arxiv.org/abs/2504.19040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>The growing demand for molecules with tailored properties in fields such as drug discovery and chemical engineering has driven advancements in computational methods for molecular design. Machine learning-based approaches for de-novo molecular generation have recently garnered significant attention. This paper introduces a transformer-based vector embedding generator combined with a modified Generative Adversarial Network (GAN) to generate molecules with desired properties. The embedding generator utilizes a novel molecular descriptor, integrating Morgan fingerprints with global molecular attributes, enabling the transformer to capture local functional groups and broader molecular characteristics. Modifying the GAN generator loss function ensures the generation of molecules with specific desired properties. The transformer achieves a reconversion accuracy of 94% while translating molecular descriptors back to SMILES strings, validating the utility of the proposed embeddings for generative tasks. The approach is validated by generating novel odorant molecules using a labeled dataset of odorant and non-odorant compounds. With the modified range-loss function, the GAN exclusively generates odorant molecules. This work underscores the potential of combining novel vector embeddings with transformers and modified GAN architectures to accelerate the discovery of tailored molecules, offering a robust tool for diverse molecular design applications.</li>
</ul>

<h3>Title: Calibrating Translation Decoding with Quality Estimation on LLMs</h3>
<ul>
<li><strong>Authors: </strong>Di Wu, Yibin Lei, Christof Monz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19044">https://arxiv.org/abs/2504.19044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19044">https://arxiv.org/pdf/2504.19044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19044]] Calibrating Translation Decoding with Quality Estimation on LLMs(https://arxiv.org/abs/2504.19044)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Neural machine translation (NMT) systems typically employ maximum a posteriori (MAP) decoding to select the highest-scoring translation from the distribution mass. However, recent evidence highlights the inadequacy of MAP decoding, often resulting in low-quality or even pathological hypotheses -- the decoding objective is not aligned with real-world translation quality. This paper proposes calibrating hypothesis likelihoods with translation quality from a distribution view by directly optimizing their Pearson correlation -- thereby enhancing the effectiveness of translation decoding. With our method, translation on large language models (LLMs) improves substantially after limited training (2K instances per direction). This improvement is orthogonal to those achieved through supervised fine-tuning, leading to substantial gains across a broad range of metrics and human evaluations -- even when applied to top-performing translation-specialized LLMs fine-tuned on high-quality translation data, such as Tower, or when compared to recent preference optimization methods, like CPO. Moreover, the calibrated translation likelihood can directly serve as a strong proxy for translation quality, closely approximating or even surpassing some state-of-the-art translation quality estimation models, like CometKiwi. Lastly, our in-depth analysis demonstrates that calibration enhances the effectiveness of MAP decoding, thereby enabling greater efficiency in real-world deployment. The resulting state-of-the-art translation model, which covers 10 languages, along with the accompanying code and human evaluation data, has been released to the community: this https URL.</li>
</ul>

<h3>Title: BinPool: A Dataset of Vulnerabilities for Binary Security Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sima Arasteh, Georgios Nikitopoulos, Wei-Cheng Wu, Nicolaas Weideman, Aaron Portnoy, Mukund Raghothaman, Christophe Hauser</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19055">https://arxiv.org/abs/2504.19055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19055">https://arxiv.org/pdf/2504.19055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19055]] BinPool: A Dataset of Vulnerabilities for Binary Security Analysis(https://arxiv.org/abs/2504.19055)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The development of machine learning techniques for discovering software vulnerabilities relies fundamentally on the availability of appropriate datasets. The ideal dataset consists of a large and diverse collection of real-world vulnerabilities, paired so as to contain both vulnerable and patched versions of each program. Naturally, collecting such datasets is a laborious and time-consuming task. Within the specific domain of vulnerability discovery in binary code, previous datasets are either publicly unavailable, lack semantic diversity, involve artificially introduced vulnerabilities, or were collected using static analyzers, thereby themselves containing incorrectly labeled example programs. In this paper, we describe a new publicly available dataset which we dubbed Binpool, containing numerous samples of vulnerable versions of Debian packages across the years. The dataset was automatically curated, and contains both vulnerable and patched versions of each program, compiled at four different optimization levels. Overall, the dataset covers 603 distinct CVEs across 89 CWE classes, 162 Debian packages, and contains 6144 binaries. We argue that this dataset is suitable for evaluating a range of security analysis tools, including for vulnerability discovery, binary function similarity, and plagiarism detection.</li>
</ul>

<h3>Title: Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mahdi Abootorabi, Omid Ghahroodi, Pardis Sadat Zahraei, Hossein Behzadasl, Alireza Mirrokni, Mobina Salimipanah, Arash Rasouli, Bahar Behzadipour, Sara Azarnoush, Benyamin Maleki, Erfan Sadraiye, Kiarash Kiani Feriz, Mahdi Teymouri Nahad, Ali Moghadasi, Abolfazl Eshagh Abianeh, Nizi Nazar, Hamid R. Rabiee, Mahdieh Soleymani Baghshah, Meisam Ahmadi, Ehsaneddin Asgari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19056">https://arxiv.org/abs/2504.19056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19056">https://arxiv.org/pdf/2504.19056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19056]] Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions(https://arxiv.org/abs/2504.19056)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative AI is reshaping art, gaming, and most notably animation. Recent breakthroughs in foundation and diffusion models have reduced the time and cost of producing animated content. Characters are central animation components, involving motion, emotions, gestures, and facial expressions. The pace and breadth of advances in recent months make it difficult to maintain a coherent view of the field, motivating the need for an integrative review. Unlike earlier overviews that treat avatars, gestures, or facial animation in isolation, this survey offers a single, comprehensive perspective on all the main generative AI applications for character animation. We begin by examining the state-of-the-art in facial animation, expression rendering, image synthesis, avatar creation, gesture modeling, motion synthesis, object generation, and texture synthesis. We highlight leading research, practical deployments, commonly used datasets, and emerging trends for each area. To support newcomers, we also provide a comprehensive background section that introduces foundational models and evaluation metrics, equipping readers with the knowledge needed to enter the field. We discuss open challenges and map future research directions, providing a roadmap to advance AI-driven character-animation technologies. This survey is intended as a resource for researchers and developers entering the field of generative AI animation or adjacent fields. Resources are available at: this https URL.</li>
</ul>

<h3>Title: Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anindya Bijoy Das, Shibbir Ahmed, Shahnewaz Karim Sakib</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19061">https://arxiv.org/abs/2504.19061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19061">https://arxiv.org/pdf/2504.19061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19061]] Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models(https://arxiv.org/abs/2504.19061)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Clinical summarization is crucial in healthcare as it distills complex medical data into digestible information, enhancing patient understanding and care management. Large language models (LLMs) have shown significant potential in automating and improving the accuracy of such summarizations due to their advanced natural language understanding capabilities. These models are particularly applicable in the context of summarizing medical/clinical texts, where precise and concise information transfer is essential. In this paper, we investigate the effectiveness of open-source LLMs in extracting key events from discharge reports, such as reasons for hospital admission, significant in-hospital events, and critical follow-up actions. In addition, we also assess the prevalence of various types of hallucinations in the summaries produced by these models. Detecting hallucinations is vital as it directly influences the reliability of the information, potentially affecting patient care and treatment outcomes. We conduct comprehensive numerical simulations to rigorously evaluate the performance of these models, further probing the accuracy and fidelity of the extracted content in clinical summarization.</li>
</ul>

<h3>Title: Security Vulnerabilities in Quantum Cloud Systems: A Survey on Emerging Threats</h3>
<ul>
<li><strong>Authors: </strong>Justin Coupel, Tasnuva Farheen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19064">https://arxiv.org/abs/2504.19064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19064">https://arxiv.org/pdf/2504.19064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19064]] Security Vulnerabilities in Quantum Cloud Systems: A Survey on Emerging Threats(https://arxiv.org/abs/2504.19064)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Quantum computing is becoming increasingly widespread due to the potential and capabilities to solve complex problems beyond the scope of classical computers. As Quantum Cloud services are adopted by businesses and research groups, they allow for greater progress and application in many fields. However, the inherent vulnerabilities of these environments pose significant security concerns. This survey delivers a comprehensive analysis of the security challenges that emerged in quantum cloud systems, with a distinct focus on multi-tenant vulnerabilities and the classical-quantum interface. Key threats such as crosstalk attacks, quantum-specific side-channel vulnerabilities, and insider threats are all examined, as well as their effects on the confidentiality, integrity, and availability of quantum circuits. The design and implementation of various quantum architectures from quantum cloud providers are also discussed. In addition, this paper delves into emerging quantum security solutions and best practices to mitigate these risks. This survey offers insights into current research gaps and proposes future directions for secure and resilient quantum cloud infrastructures.</li>
</ul>

<h3>Title: ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme Weather Analytics</h3>
<ul>
<li><strong>Authors: </strong>Deeksha Varshney, Keane Ong, Rui Mao, Erik Cambria, Gianmarco Mengaldo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19066">https://arxiv.org/abs/2504.19066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19066">https://arxiv.org/pdf/2504.19066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19066]] ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme Weather Analytics(https://arxiv.org/abs/2504.19066)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate assessments of extreme weather events are vital for research and policy, yet localized and granular data remain scarce in many parts of the world. This data gap limits our ability to analyze potential outcomes and implications of extreme weather events, hindering effective decision-making. Large Language Models (LLMs) can process vast amounts of unstructured text data, extract meaningful insights, and generate detailed assessments by synthesizing information from multiple sources. Furthermore, LLMs can seamlessly transfer their general language understanding to smaller models, enabling these models to retain key knowledge while being fine-tuned for specific tasks. In this paper, we propose Extreme Weather Reasoning-Aware Alignment (EWRA), a method that enhances small language models (SLMs) by incorporating structured reasoning paths derived from LLMs, and ExtremeWeatherNews, a large dataset of extreme weather event-related news articles. EWRA and ExtremeWeatherNews together form the overall framework, ClimaEmpact, that focuses on addressing three critical extreme-weather tasks: categorization of tangible vulnerabilities/impacts, topic labeling, and emotion analysis. By aligning SLMs with advanced reasoning strategies on ExtremeWeatherNews (and its derived dataset ExtremeAlign used specifically for SLM alignment), EWRA improves the SLMs' ability to generate well-grounded and domain-specific responses for extreme weather analytics. Our results show that the approach proposed guides SLMs to output domain-aligned responses, surpassing the performance of task-specific models and offering enhanced real-world applicability for extreme weather analytics.</li>
</ul>

<h3>Title: Dual-Branch Residual Network for Cross-Domain Few-Shot Hyperspectral Image Classification with Refined Prototype</h3>
<ul>
<li><strong>Authors: </strong>Anyong Qin, Chaoqi Yuan, Qiang Li, Feng Yang, Tiecheng Song, Chenqiang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19074">https://arxiv.org/abs/2504.19074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19074">https://arxiv.org/pdf/2504.19074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19074]] Dual-Branch Residual Network for Cross-Domain Few-Shot Hyperspectral Image Classification with Refined Prototype(https://arxiv.org/abs/2504.19074)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks (CNNs) are effective for hyperspectral image (HSI) classification, but their 3D convolutional structures introduce high computational costs and limited generalization in few-shot scenarios. Domain shifts caused by sensor differences and environmental variations further hinder cross-dataset adaptability. Metric-based few-shot learning (FSL) prototype networks mitigate this problem, yet their performance is sensitive to prototype quality, especially with limited samples. To overcome these challenges, a dual-branch residual network that integrates spatial and spectral features via parallel branches is proposed in this letter. Additionally, more robust refined prototypes are obtained through a regulation term. Furthermore, a kernel probability matching strategy aligns source and target domain features, alleviating domain shift. Experiments on four publicly available HSI datasets illustrate that the proposal achieves superior performance compared to other methods.</li>
</ul>

<h3>Title: HoloDx: Knowledge- and Data-Driven Multimodal Diagnosis of Alzheimer's Disease</h3>
<ul>
<li><strong>Authors: </strong>Qiuhui Chen, Jintao Wang, Gang Wang, Yi Hong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19075">https://arxiv.org/abs/2504.19075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19075">https://arxiv.org/pdf/2504.19075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19075]] HoloDx: Knowledge- and Data-Driven Multimodal Diagnosis of Alzheimer's Disease(https://arxiv.org/abs/2504.19075)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Accurate diagnosis of Alzheimer's disease (AD) requires effectively integrating multimodal data and clinical expertise. However, existing methods often struggle to fully utilize multimodal information and lack structured mechanisms to incorporate dynamic domain knowledge. To address these limitations, we propose HoloDx, a knowledge- and data-driven framework that enhances AD diagnosis by aligning domain knowledge with multimodal clinical data. HoloDx incorporates a knowledge injection module with a knowledge-aware gated cross-attention, allowing the model to dynamically integrate domain-specific insights from both large language models (LLMs) and clinical expertise. Also, a memory injection module with a designed prototypical memory attention enables the model to retain and retrieve subject-specific information, ensuring consistency in decision-making. By jointly leveraging these mechanisms, HoloDx enhances interpretability, improves robustness, and effectively aligns prior knowledge with current subject data. Evaluations on five AD datasets demonstrate that HoloDx outperforms state-of-the-art methods, achieving superior diagnostic accuracy and strong generalization across diverse cohorts. The source code will be released upon publication acceptance.</li>
</ul>

<h3>Title: MIA-Mind: A Multidimensional Interactive Attention Mechanism Based on MindSpore</h3>
<ul>
<li><strong>Authors: </strong>Zhenkai Qin, Jiaquan Liang, Qiao Fang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19080">https://arxiv.org/abs/2504.19080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19080">https://arxiv.org/pdf/2504.19080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19080]] MIA-Mind: A Multidimensional Interactive Attention Mechanism Based on MindSpore(https://arxiv.org/abs/2504.19080)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Attention mechanisms have significantly advanced deep learning by enhancing feature representation through selective focus. However, existing approaches often independently model channel importance and spatial saliency, overlooking their inherent interdependence and limiting their effectiveness. To address this limitation, we propose MIA-Mind, a lightweight and modular Multidimensional Interactive Attention Mechanism, built upon the MindSpore framework. MIA-Mind jointly models spatial and channel features through a unified cross-attentive fusion strategy, enabling fine-grained feature recalibration with minimal computational overhead. Extensive experiments are conducted on three representative datasets: on CIFAR-10, MIA-Mind achieves an accuracy of 82.9\%; on ISBI2012, it achieves an accuracy of 78.7\%; and on CIC-IDS2017, it achieves an accuracy of 91.9\%. These results validate the versatility, lightweight design, and generalization ability of MIA-Mind across heterogeneous tasks. Future work will explore the extension of MIA-Mind to large-scale datasets, the development of ada,ptive attention fusion strategies, and distributed deployment to further enhance scalability and robustness.</li>
</ul>

<h3>Title: CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges</h3>
<ul>
<li><strong>Authors: </strong>Yu Li, Qizhi Pei, Mengyuan Sun, Honglin Lin, Chenlin Ming, Xin Gao, Jiang Wu, Conghui He, Lijun Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19093">https://arxiv.org/abs/2504.19093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19093">https://arxiv.org/pdf/2504.19093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19093]] CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges(https://arxiv.org/abs/2504.19093)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities, especially the recent advancements in reasoning, such as o1 and o3, pushing the boundaries of AI. Despite these impressive achievements in mathematics and coding, the reasoning abilities of LLMs in domains requiring cryptographic expertise remain underexplored. In this paper, we introduce CipherBank, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs in cryptographic decryption tasks. CipherBank comprises 2,358 meticulously crafted problems, covering 262 unique plaintexts across 5 domains and 14 subdomains, with a focus on privacy-sensitive and real-world scenarios that necessitate encryption. From a cryptographic perspective, CipherBank incorporates 3 major categories of encryption methods, spanning 9 distinct algorithms, ranging from classical ciphers to custom cryptographic techniques. We evaluate state-of-the-art LLMs on CipherBank, e.g., GPT-4o, DeepSeek-V3, and cutting-edge reasoning-focused models such as o1 and DeepSeek-R1. Our results reveal significant gaps in reasoning abilities not only between general-purpose chat LLMs and reasoning-focused LLMs but also in the performance of current reasoning-focused models when applied to classical cryptographic decryption tasks, highlighting the challenges these models face in understanding and manipulating encrypted data. Through detailed analysis and error investigations, we provide several key observations that shed light on the limitations and potential improvement areas for LLMs in cryptographic reasoning. These findings underscore the need for continuous advancements in LLM reasoning capabilities.</li>
</ul>

<h3>Title: Privacy-Preserving Federated Embedding Learning for Localized Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Qianren Mao, Qili Zhang, Hanwen Hao, Zhentao Han, Runhua Xu, Weifeng Jiang, Qi Hu, Zhijun Chen, Tyler Zhou, Bo Li, Yangqiu Song, Jin Dong, Jianxin Li, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19101">https://arxiv.org/abs/2504.19101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19101">https://arxiv.org/pdf/2504.19101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19101]] Privacy-Preserving Federated Embedding Learning for Localized Retrieval-Augmented Generation(https://arxiv.org/abs/2504.19101)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution for enhancing the accuracy and credibility of Large Language Models (LLMs), particularly in Question & Answer tasks. This is achieved by incorporating proprietary and private data from integrated databases. However, private RAG systems face significant challenges due to the scarcity of private domain data and critical data privacy issues. These obstacles impede the deployment of private RAG systems, as developing privacy-preserving RAG systems requires a delicate balance between data security and data availability. To address these challenges, we regard federated learning (FL) as a highly promising technology for privacy-preserving RAG services. We propose a novel framework called Federated Retrieval-Augmented Generation (FedE4RAG). This framework facilitates collaborative training of client-side RAG retrieval models. The parameters of these models are aggregated and distributed on a central-server, ensuring data privacy without direct sharing of raw data. In FedE4RAG, knowledge distillation is employed for communication between the server and client models. This technique improves the generalization of local RAG retrievers during the federated learning process. Additionally, we apply homomorphic encryption within federated learning to safeguard model parameters and mitigate concerns related to data leakage. Extensive experiments conducted on the real-world dataset have validated the effectiveness of FedE4RAG. The results demonstrate that our proposed framework can markedly enhance the performance of private RAG systems while maintaining robust data privacy protection.</li>
</ul>

<h3>Title: Harmonizing Generalization and Personalization in Ring-topology Decentralized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Shunxin Guo, Jiaqi Lv, Xin Geng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19103">https://arxiv.org/abs/2504.19103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19103">https://arxiv.org/pdf/2504.19103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19103]] Harmonizing Generalization and Personalization in Ring-topology Decentralized Federated Learning(https://arxiv.org/abs/2504.19103)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We introduce Ring-topology Decentralized Federated Learning (RDFL) for distributed model training, aiming to avoid the inherent risks of centralized failure in server-based FL. However, RDFL faces the challenge of low information-sharing efficiency due to the point-to-point communication manner when handling inherent data heterogeneity. Existing studies to mitigate data heterogeneity focus on personalized optimization of models, ignoring that the lack of shared information constraints can lead to large differences among models, weakening the benefits of collaborative learning. To tackle these challenges, we propose a Divide-and-conquer RDFL framework (DRDFL) that uses a feature generation model to extract personalized information and invariant shared knowledge from the underlying data distribution, ensuring both effective personalization and strong generalization. Specifically, we design a \textit{PersonaNet} module that encourages class-specific feature representations to follow a Gaussian mixture distribution, facilitating the learning of discriminative latent representations tailored to local data distributions. Meanwhile, the \textit{Learngene} module is introduced to encapsulate shared knowledge through an adversarial classifier to align latent representations and extract globally invariant information. Extensive experiments demonstrate that DRDFL outperforms state-of-the-art methods in various data heterogeneity settings.</li>
</ul>

<h3>Title: APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries</h3>
<ul>
<li><strong>Authors: </strong>Huajian Xin, Luming Li, Xiaoran Jin, Jacques Fleuriot, Wenda Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19110">https://arxiv.org/abs/2504.19110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19110">https://arxiv.org/pdf/2504.19110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19110]] APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries(https://arxiv.org/abs/2504.19110)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in large language models (LLMs) has shown promise in formal theorem proving, yet existing benchmarks remain limited to isolated, static proof tasks, failing to capture the iterative, engineering-intensive workflows of real-world formal mathematics libraries. Motivated by analogous advances in software engineering, we introduce the paradigm of Automated Proof Engineering (APE), which aims to automate proof engineering tasks such as feature addition, proof refactoring, and bug fixing using LLMs. To facilitate research in this direction, we present APE-Bench I, the first realistic benchmark built from real-world commit histories of Mathlib4, featuring diverse file-level tasks described in natural language and verified via a hybrid approach combining the Lean compiler and LLM-as-a-Judge. We further develop Eleanstic, a scalable parallel verification infrastructure optimized for proof checking across multiple versions of Mathlib. Empirical results on state-of-the-art LLMs demonstrate strong performance on localized edits but substantial degradation on handling complex proof engineering. This work lays the foundation for developing agentic workflows in proof engineering, with future benchmarks targeting multi-file coordination, project-scale verification, and autonomous agents capable of planning, editing, and repairing formal libraries.</li>
</ul>

<h3>Title: Blind Source Separation Based on Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Zhongxuan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19124">https://arxiv.org/abs/2504.19124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19124">https://arxiv.org/pdf/2504.19124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19124]] Blind Source Separation Based on Sparsity(https://arxiv.org/abs/2504.19124)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Blind source separation (BSS) is a key technique in array processing and data analysis, aiming to recover unknown sources from observed mixtures without knowledge of the mixing matrix. Classical independent component analysis (ICA) methods rely on the assumption that sources are mutually independent. To address limitations of ICA, sparsity-based methods have been introduced, which decompose source signals sparsely in a predefined dictionary. Morphological Component Analysis (MCA), based on sparse representation theory, assumes that a signal is a linear combination of components with distinct geometries, each sparsely representable in one dictionary and not in others. This approach has recently been applied to BSS with promising results. This report reviews key approaches derived from classical ICA and explores sparsity-based methods for BSS. It introduces the theory of sparse representation and decomposition, followed by a block coordinate relaxation MCA algorithm, whose variants are used in Multichannel MCA (MMCA) and Generalized MCA (GMCA). A local dictionary learning method using K-SVD is then presented. Finally, we propose an improved algorithm, SAC+BK-SVD, which enhances K-SVD by learning a block-sparsifying dictionary that clusters and updates similar atoms in blocks. The implementation includes experiments on image segmentation and blind image source separation using the discussed techniques. We also compare the proposed block-sparse dictionary learning algorithm with K-SVD. Simulation results demonstrate that our method yields improved blind image separation quality.</li>
</ul>

<h3>Title: DeepSPG: Exploring Deep Semantic Prior Guidance for Low-light Image Enhancement with Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>Jialang Lu, Huayu Zhao, Huiyu Zhai, Xingxing Yang, Shini Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19127">https://arxiv.org/abs/2504.19127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19127">https://arxiv.org/pdf/2504.19127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19127]] DeepSPG: Exploring Deep Semantic Prior Guidance for Low-light Image Enhancement with Multimodal Learning(https://arxiv.org/abs/2504.19127)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>There has long been a belief that high-level semantics learning can benefit various downstream computer vision tasks. However, in the low-light image enhancement (LLIE) community, existing methods learn a brutal mapping between low-light and normal-light domains without considering the semantic information of different regions, especially in those extremely dark regions that suffer from severe information loss. To address this issue, we propose a new deep semantic prior-guided framework (DeepSPG) based on Retinex image decomposition for LLIE to explore informative semantic knowledge via a pre-trained semantic segmentation model and multimodal learning. Notably, we incorporate both image-level semantic prior and text-level semantic prior and thus formulate a multimodal learning framework with combinatorial deep semantic prior guidance for LLIE. Specifically, we incorporate semantic knowledge to guide the enhancement process via three designs: an image-level semantic prior guidance by leveraging hierarchical semantic features from a pre-trained semantic segmentation model; a text-level semantic prior guidance by integrating natural language semantic constraints via a pre-trained vision-language model; a multi-scale semantic-aware structure that facilitates effective semantic feature incorporation. Eventually, our proposed DeepSPG demonstrates superior performance compared to state-of-the-art methods across five benchmark datasets. The implementation details and code are publicly available at this https URL.</li>
</ul>

<h3>Title: Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments</h3>
<ul>
<li><strong>Authors: </strong>Yun Qu, Qi (Cheems)Wang, Yixiu Mao, Yiqin Lv, Xiangyang Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19139">https://arxiv.org/abs/2504.19139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19139">https://arxiv.org/pdf/2504.19139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19139]] Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments(https://arxiv.org/abs/2504.19139)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Task robust adaptation is a long-standing pursuit in sequential decision-making. Some risk-averse strategies, e.g., the conditional value-at-risk principle, are incorporated in domain randomization or meta reinforcement learning to prioritize difficult tasks in optimization, which demand costly intensive evaluations. The efficiency issue prompts the development of robust active task sampling to train adaptive policies, where risk-predictive models are used to surrogate policy evaluation. This work characterizes the optimization pipeline of robust active task sampling as a Markov decision process, posits theoretical and practical insights, and constitutes robustness concepts in risk-averse scenarios. Importantly, we propose an easy-to-implement method, referred to as Posterior and Diversity Synergized Task Sampling (PDTS), to accommodate fast and robust sequential decision-making. Extensive experiments show that PDTS unlocks the potential of robust active task sampling, significantly improves the zero-shot and few-shot adaptation robustness in challenging tasks, and even accelerates the learning process under certain scenarios. Our project website is at this https URL.</li>
</ul>

<h3>Title: Comparative Analysis of AI-Driven Security Approaches in DevSecOps: Challenges, Solutions, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Farid Binbeshr, Muhammad Imam</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19154">https://arxiv.org/abs/2504.19154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19154">https://arxiv.org/pdf/2504.19154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19154]] Comparative Analysis of AI-Driven Security Approaches in DevSecOps: Challenges, Solutions, and Future Directions(https://arxiv.org/abs/2504.19154)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The integration of security within DevOps, known as DevSecOps, has gained traction in modern software development to address security vulnerabilities while maintaining agility. Artificial Intelligence (AI) and Machine Learning (ML) have been increasingly leveraged to enhance security automation, threat detection, and compliance enforcement. However, existing studies primarily focus on individual aspects of AI-driven security in DevSecOps, lacking a structured comparison of methodologies. This study conducts a systematic literature review (SLR) to analyze and compare AI-driven security solutions in DevSecOps, evaluating their technical capabilities, implementation challenges, and operational impacts. The findings reveal gaps in empirical validation, scalability, and integration of AI in security automation. The study highlights best practices, identifies research gaps, and proposes future directions for optimizing AI-based security frameworks in DevSecOps.</li>
</ul>

<h3>Title: RadioFormer: A Multiple-Granularity Radio Map Estimation Transformer with 1\textpertenthousand Spatial Sampling</h3>
<ul>
<li><strong>Authors: </strong>Zheng Fang, Kangjun Liu, Ke Chen, Qingyu Liu, Jianguo Zhang, Lingyang Song, Yaowei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19161">https://arxiv.org/abs/2504.19161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19161">https://arxiv.org/pdf/2504.19161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19161]] RadioFormer: A Multiple-Granularity Radio Map Estimation Transformer with 1\textpertenthousand Spatial Sampling(https://arxiv.org/abs/2504.19161)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The task of radio map estimation aims to generate a dense representation of electromagnetic spectrum quantities, such as the received signal strength at each grid point within a geographic region, based on measurements from a subset of spatially distributed nodes (represented as pixels). Recently, deep vision models such as the U-Net have been adapted to radio map estimation, whose effectiveness can be guaranteed with sufficient spatial observations (typically 0.01% to 1% of pixels) in each map, to model local dependency of observed signal power. However, such a setting of sufficient measurements can be less practical in real-world scenarios, where extreme sparsity in spatial sampling can be widely encountered. To address this challenge, we propose RadioFormer, a novel multiple-granularity transformer designed to handle the constraints posed by spatial sparse observations. Our RadioFormer, through a dual-stream self-attention (DSA) module, can respectively discover the correlation of pixel-wise observed signal power and also learn patch-wise buildings' geometries in a style of multiple granularities, which are integrated into multi-scale representations of radio maps by a cross stream cross-attention (CCA) module. Extensive experiments on the public RadioMapSeer dataset demonstrate that RadioFormer outperforms state-of-the-art methods in radio map estimation while maintaining the lowest computational cost. Furthermore, the proposed approach exhibits exceptional generalization capabilities and robust zero-shot performance, underscoring its potential to advance radio map estimation in a more practical setting with very limited observation nodes.</li>
</ul>

<h3>Title: SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Chen, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, Kwan-Yee K. Wong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19162">https://arxiv.org/abs/2504.19162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19162">https://arxiv.org/pdf/2504.19162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19162]] SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning(https://arxiv.org/abs/2504.19162)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating the step-by-step reliability of large language model (LLM) reasoning, such as Chain-of-Thought, remains challenging due to the difficulty and cost of obtaining high-quality step-level supervision. In this paper, we introduce Self-Play Critic (SPC), a novel approach where a critic model evolves its ability to assess reasoning steps through adversarial self-play games, eliminating the need for manual step-level annotation. SPC involves fine-tuning two copies of a base model to play two roles, namely a "sneaky generator" that deliberately produces erroneous steps designed to be difficult to detect, and a "critic" that analyzes the correctness of reasoning steps. These two models engage in an adversarial game in which the generator aims to fool the critic, while the critic model seeks to identify the generator's errors. Using reinforcement learning based on the game outcomes, the models iteratively improve; the winner of each confrontation receives a positive reward and the loser receives a negative reward, driving continuous self-evolution. Experiments on three reasoning process benchmarks (ProcessBench, PRM800K, DeltaBench) demonstrate that our SPC progressively enhances its error detection capabilities (e.g., accuracy increases from 70.8% to 77.7% on ProcessBench) and surpasses strong baselines, including distilled R1 model. Furthermore, applying SPC to guide the test-time search of diverse LLMs significantly improves their mathematical reasoning performance on MATH500 and AIME2024, outperforming state-of-the-art process reward models.</li>
</ul>

<h3>Title: IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking Heads from Monocular Videos</h3>
<ul>
<li><strong>Authors: </strong>Yuan Li, Ziqian Bai, Feitong Tan, Zhaopeng Cui, Sean Fanello, Yinda Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19165">https://arxiv.org/abs/2504.19165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19165">https://arxiv.org/pdf/2504.19165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19165]] IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking Heads from Monocular Videos(https://arxiv.org/abs/2504.19165)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We propose a novel 3D-aware diffusion-based method for generating photorealistic talking head videos directly from a single identity image and explicit control signals (e.g., expressions). Our method generates Multiplane Images (MPIs) that ensure geometric consistency, making them ideal for immersive viewing experiences like binocular videos for VR headsets. Unlike existing methods that often require a separate stage or joint optimization to reconstruct a 3D representation (such as NeRF or 3D Gaussians), our approach directly generates the final output through a single denoising process, eliminating the need for post-processing steps to render novel views efficiently. To effectively learn from monocular videos, we introduce a training mechanism that reconstructs the output MPI randomly in either the target or the reference camera space. This approach enables the model to simultaneously learn sharp image details and underlying 3D information. Extensive experiments demonstrate the effectiveness of our method, which achieves competitive avatar quality and novel-view rendering capabilities, even without explicit 3D reconstruction or high-quality multi-view training data.</li>
</ul>

<h3>Title: Newton-Puiseux Analysis for Interpretability and Calibration of Complex-Valued Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Piotr Migus</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19176">https://arxiv.org/abs/2504.19176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19176">https://arxiv.org/pdf/2504.19176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19176]] Newton-Puiseux Analysis for Interpretability and Calibration of Complex-Valued Neural Networks(https://arxiv.org/abs/2504.19176)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Complex-valued neural networks (CVNNs) excel where phase matters, yet their multi-sheeted decision surfaces defy standard explainability and calibration tools. We propose a \emph{Newton-Puiseux} framework that fits a local polynomial surrogate to a high-uncertainty input and analytically decomposes this surrogate into fractional-power series. The resulting Puiseux expansions, dominant Puiseux coefficients, and phase-aligned curvature descriptors deliver closed-form estimates of robustness and over-confidence that gradient - or perturbation-based methods (saliency, LIME, SHAP) cannot provide. On a controlled $\mathbb{C}^2$ helix the surrogate attains RMSE $< 0.09$ while recovering the number of decision sheets; quartic coefficients predict adversarial flip radii within $10^{-3}$. On the real-world MIT-BIH arrhythmia corpus, Puiseux-guided, phase-aware temperature scaling lowers expected calibration error from 0.087 to 0.034, contributing to the advancement of CVNNs. Full code, pre-trained weights, and scripts are at this https URL.</li>
</ul>

<h3>Title: Segmenting Objectiveness and Task-awareness Unknown Region for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Mi Zheng, Guanglei Yang, Zitong Huang, Zhenhua Guo, Kevin Han, Wangmeng Zuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19183">https://arxiv.org/abs/2504.19183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19183">https://arxiv.org/pdf/2504.19183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19183]] Segmenting Objectiveness and Task-awareness Unknown Region for Autonomous Driving(https://arxiv.org/abs/2504.19183)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>With the emergence of transformer-based architectures and large language models (LLMs), the accuracy of road scene perception has substantially advanced. Nonetheless, current road scene segmentation approaches are predominantly trained on closed-set data, resulting in insufficient detection capabilities for out-of-distribution (OOD) objects. To overcome this limitation, road anomaly detection methods have been proposed. However, existing methods primarily depend on image inpainting and OOD distribution detection techniques, facing two critical issues: (1) inadequate consideration of the objectiveness attributes of anomalous regions, causing incomplete segmentation when anomalous objects share similarities with known classes, and (2) insufficient attention to environmental constraints, leading to the detection of anomalies irrelevant to autonomous driving tasks. In this paper, we propose a novel framework termed Segmenting Objectiveness and Task-Awareness (SOTA) for autonomous driving scenes. Specifically, SOTA enhances the segmentation of objectiveness through a Semantic Fusion Block (SFB) and filters anomalies irrelevant to road navigation tasks using a Scene-understanding Guided Prompt-Context Adaptor (SG-PCA). Extensive empirical evaluations on multiple benchmark datasets, including Fishyscapes Lost and Found, Segment-Me-If-You-Can, and RoadAnomaly, demonstrate that the proposed SOTA consistently improves OOD detection performance across diverse detectors, achieving robust and accurate segmentation outcomes.</li>
</ul>

<h3>Title: LRFusionPR: A Polar BEV-Based LiDAR-Radar Fusion Network for Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zhangshuo Qi, Luqi Cheng, Zijie Zhou, Guangming Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19186">https://arxiv.org/abs/2504.19186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19186">https://arxiv.org/pdf/2504.19186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19186]] LRFusionPR: A Polar BEV-Based LiDAR-Radar Fusion Network for Place Recognition(https://arxiv.org/abs/2504.19186)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In autonomous driving, place recognition is critical for global localization in GPS-denied environments. LiDAR and radar-based place recognition methods have garnered increasing attention, as LiDAR provides precise ranging, whereas radar excels in adverse weather resilience. However, effectively leveraging LiDAR-radar fusion for place recognition remains challenging. The noisy and sparse nature of radar data limits its potential to further improve recognition accuracy. In addition, heterogeneous radar configurations complicate the development of unified cross-modality fusion frameworks. In this paper, we propose LRFusionPR, which improves recognition accuracy and robustness by fusing LiDAR with either single-chip or scanning radar. Technically, a dual-branch network is proposed to fuse different modalities within the unified polar coordinate bird's eye view (BEV) representation. In the fusion branch, cross-attention is utilized to perform cross-modality feature interactions. The knowledge from the fusion branch is simultaneously transferred to the distillation branch, which takes radar as its only input to further improve the robustness. Ultimately, the descriptors from both branches are concatenated, producing the multimodal global descriptor for place retrieval. Extensive evaluations on multiple datasets demonstrate that our LRFusionPR achieves accurate place recognition, while maintaining robustness under varying weather conditions. Our open-source code will be released at this https URL.</li>
</ul>

<h3>Title: Hierarchical Attention Generates Better Proofs</h3>
<ul>
<li><strong>Authors: </strong>Jianlong Chen, Chao Li, Yang Yuan, Andrew C Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19188">https://arxiv.org/abs/2504.19188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19188">https://arxiv.org/pdf/2504.19188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19188]] Hierarchical Attention Generates Better Proofs(https://arxiv.org/abs/2504.19188)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown promise in formal theorem proving, but their token-level processing often fails to capture the inherent hierarchical nature of mathematical proofs. We introduce \textbf{Hierarchical Attention}, a regularization method that aligns LLMs' attention mechanisms with mathematical reasoning structures. Our approach establishes a five-level hierarchy from foundational elements to high-level concepts, ensuring structured information flow in proof generation. Experiments demonstrate that our method improves proof success rates by 2.05\% on miniF2F and 1.69\% on ProofNet while reducing proof complexity by 23.81\% and 16.50\% respectively. The code is available at this https URL.</li>
</ul>

<h3>Title: WuNeng: Hybrid State with Attention</h3>
<ul>
<li><strong>Authors: </strong>Liu Xiao, Li Zhiyuan, Lin Yueyu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19191">https://arxiv.org/abs/2504.19191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19191">https://arxiv.org/pdf/2504.19191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19191]] WuNeng: Hybrid State with Attention(https://arxiv.org/abs/2504.19191)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The WuNeng architecture introduces a novel approach to enhancing the expressivity and power of large language models by integrating recurrent neural network (RNN)-based RWKV-7 with advanced attention mechanisms, prioritizing heightened contextual coherence over reducing KV cache size. Building upon the hybrid-head concept from Hymba, WuNeng augments standard multi-head attention with additional RWKV-7 state-driven heads, rather than replacing existing heads, to enrich the model's representational capacity. A cross-head interaction technique fosters dynamic synergy among standard, state-driven, and newly introduced middle heads, leveraging concatenation, additive modulation, and gated fusion for robust information integration. Furthermore, a multi-token state processing mechanism harnesses the continuous RWKV-7 state to capture intricate, sequence-wide dependencies, significantly boosting expressivity. Remarkably, these enhancements are achieved with minimal additional parameters, ensuring efficiency while empowering the model to excel in complex reasoning and sequence generation tasks. WuNeng sets a new standard for balancing expressivity and computational efficiency in modern neural architectures.</li>
</ul>

<h3>Title: HetGL2R: Learning to Rank Critical Road Segments via Attributed Heterogeneous Graph Random Walks</h3>
<ul>
<li><strong>Authors: </strong>Ming Xu, Jinrong Xiang, Zilong Xie, Xiangfu Meng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19199">https://arxiv.org/abs/2504.19199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19199">https://arxiv.org/pdf/2504.19199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19199]] HetGL2R: Learning to Rank Critical Road Segments via Attributed Heterogeneous Graph Random Walks(https://arxiv.org/abs/2504.19199)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurately identifying critical nodes with high spatial influence in road networks is essential for enhancing the efficiency of traffic management and urban planning. However, existing node importance ranking methods mainly rely on structural features and topological information, often overlooking critical factors such as origin-destination (OD) demand and route information. This limitation leaves considerable room for improvement in ranking accuracy. To address this issue, we propose HetGL2R, an attributed heterogeneous graph learning approach for ranking node importance in road networks. This method introduces a tripartite graph (trip graph) to model the structure of the road network, integrating OD demand, route choice, and various structural features of road segments. Based on the trip graph, we design an embedding method to learn node representations that reflect the spatial influence of road segments. The method consists of a heterogeneous random walk sampling algorithm (HetGWalk) and a Transformer encoder. HetGWalk constructs multiple attribute-guided graphs based on the trip graph to enrich the diversity of semantic associations between nodes. It then applies a joint random walk mechanism to convert both topological structures and node attributes into sequences, enabling the encoder to capture spatial dependencies more effectively among road segments. Finally, a listwise ranking strategy is employed to evaluate node importance. To validate the performance of our method, we construct two synthetic datasets using SUMO based on simulated road networks. Experimental results demonstrate that HetGL2R significantly outperforms baselines in incorporating OD demand and route choice information, achieving more accurate and robust node ranking. Furthermore, we conduct a case study using real-world taxi trajectory data from Beijing, further verifying the practicality of the proposed method.</li>
</ul>

<h3>Title: CapsFake: A Multimodal Capsule Network for Detecting Instruction-Guided Deepfakes</h3>
<ul>
<li><strong>Authors: </strong>Tuan Nguyen, Naseem Khan, Issa Khalil</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19212">https://arxiv.org/abs/2504.19212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19212">https://arxiv.org/pdf/2504.19212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19212]] CapsFake: A Multimodal Capsule Network for Detecting Instruction-Guided Deepfakes(https://arxiv.org/abs/2504.19212)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapid evolution of deepfake technology, particularly in instruction-guided image editing, threatens the integrity of digital images by enabling subtle, context-aware manipulations. Generated conditionally from real images and textual prompts, these edits are often imperceptible to both humans and existing detection systems, revealing significant limitations in current defenses. We propose a novel multimodal capsule network, CapsFake, designed to detect such deepfake image edits by integrating low-level capsules from visual, textual, and frequency-domain modalities. High-level capsules, predicted through a competitive routing mechanism, dynamically aggregate local features to identify manipulated regions with precision. Evaluated on diverse datasets, including MagicBrush, Unsplash Edits, Open Images Edits, and Multi-turn Edits, CapsFake outperforms state-of-the-art methods by up to 20% in detection accuracy. Ablation studies validate its robustness, achieving detection rates above 94% under natural perturbations and 96% against adversarial attacks, with excellent generalization to unseen editing scenarios. This approach establishes a powerful framework for countering sophisticated image manipulations.</li>
</ul>

<h3>Title: Evaluating Organization Security: User Stories of European Union NIS2 Directive</h3>
<ul>
<li><strong>Authors: </strong>Mari Seeba, Magnus Valgre, Raimundas Matulevičius</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19222">https://arxiv.org/abs/2504.19222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19222">https://arxiv.org/pdf/2504.19222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19222]] Evaluating Organization Security: User Stories of European Union NIS2 Directive(https://arxiv.org/abs/2504.19222)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The NIS2 directive requires EU Member States to ensure a consistently high level of cybersecurity by setting risk-management measures for essential and important entities. Evaluations are necessary to assess whether the required security level is met. This involves understanding the needs and goals of different personas defined by NIS2, who benefit from evaluation results. In this paper, we consider how NIS2 user stories support the evaluation of the level of information security in organizations. Using requirements elicitation principles, we extracted the legal requirements from NIS2 from our narrowed scope, identified six key personas and their goals, formulated user stories based on the gathered information, and validated the usability and relevance of the user stories with security evaluation instruments or methods we found from the literature. The defined user stories help to adjust existing instruments and methods of assessing the security level to comply with NIS2. On the other hand, user stories enable us to see the patterns related to security evaluation when developing new NIS2-compliant security evaluation methods to optimize the administrative burden of entities.</li>
</ul>

<h3>Title: CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Alexander Baumann, Leonardo Ayala, Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Berkin Özdemir, Lena Maier-Hein, Slobodan Ilic</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19223">https://arxiv.org/abs/2504.19223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19223">https://arxiv.org/pdf/2504.19223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19223]] CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis(https://arxiv.org/abs/2504.19223)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spectral imaging offers promising applications across diverse domains, including medicine and urban scene understanding, and is already established as a critical modality in remote sensing. However, variability in channel dimensionality and captured wavelengths among spectral cameras impede the development of AI-driven methodologies, leading to camera-specific models with limited generalizability and inadequate cross-camera applicability. To address this bottleneck, we introduce $\textbf{CARL}$, a model for $\textbf{C}$amera-$\textbf{A}$gnostic $\textbf{R}$epresentation $\textbf{L}$earning across RGB, multispectral, and hyperspectral imaging modalities. To enable the conversion of a spectral image with any channel dimensionality to a camera-agnostic embedding, we introduce wavelength positional encoding and a self-attention-cross-attention mechanism to compress spectral information into learned query representations. Spectral-spatial pre-training is achieved with a novel spectral self-supervised JEPA-inspired strategy tailored to CARL. Large-scale experiments across the domains of medical imaging, autonomous driving, and satellite imaging demonstrate our model's unique robustness to spectral heterogeneity, outperforming on datasets with simulated and real-world cross-camera spectral variations. The scalability and versatility of the proposed approach position our model as a backbone for future spectral foundation models.</li>
</ul>

<h3>Title: Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers</h3>
<ul>
<li><strong>Authors: </strong>Dylan Bouchard, Mohit Singh Chauhan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19254">https://arxiv.org/abs/2504.19254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19254">https://arxiv.org/pdf/2504.19254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19254]] Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers(https://arxiv.org/abs/2504.19254)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucinations are a persistent problem with Large Language Models (LLMs). As these models become increasingly used in high-stakes domains, such as healthcare and finance, the need for effective hallucination detection is crucial. To this end, we propose a versatile framework for zero-resource hallucination detection that practitioners can apply to real-world use cases. To achieve this, we adapt a variety of existing uncertainty quantification (UQ) techniques, including black-box UQ, white-box UQ, and LLM-as-a-Judge, transforming them as necessary into standardized response-level confidence scores ranging from 0 to 1. To enhance flexibility, we introduce a tunable ensemble approach that incorporates any combination of the individual confidence scores. This approach enables practitioners to optimize the ensemble for a specific use case for improved performance. To streamline implementation, the full suite of scorers is offered in this paper's companion Python toolkit, UQLM. To evaluate the performance of the various scorers, we conduct an extensive set of experiments using several LLM question-answering benchmarks. We find that our tunable ensemble typically surpasses its individual components and outperforms existing hallucination detection methods. Our results demonstrate the benefits of customized hallucination detection strategies for improving the accuracy and reliability of LLMs.</li>
</ul>

<h3>Title: LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition</h3>
<ul>
<li><strong>Authors: </strong>Songsong Xiong, Hamidreza Kasaei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19256">https://arxiv.org/abs/2504.19256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19256">https://arxiv.org/pdf/2504.19256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19256]] LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition(https://arxiv.org/abs/2504.19256)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>In human-centered environments such as restaurants, homes, and warehouses, robots often face challenges in accurately recognizing 3D objects. These challenges stem from the complexity and variability of these environments, including diverse object shapes. In this paper, we propose a novel Lightweight Multi-modal Multi-view Convolutional-Vision Transformer network (LM-MCVT) to enhance 3D object recognition in robotic applications. Our approach leverages the Globally Entropy-based Embeddings Fusion (GEEF) method to integrate multi-views efficiently. The LM-MCVT architecture incorporates pre- and mid-level convolutional encoders and local and global transformers to enhance feature extraction and recognition accuracy. We evaluate our method on the synthetic ModelNet40 dataset and achieve a recognition accuracy of 95.6% using a four-view setup, surpassing existing state-of-the-art methods. To further validate its effectiveness, we conduct 5-fold cross-validation on the real-world OmniObject3D dataset using the same configuration. Results consistently show superior performance, demonstrating the method's robustness in 3D object recognition across synthetic and real-world 3D data.</li>
</ul>

<h3>Title: Convergence Properties of Natural Gradient Descent for Minimizing KL Divergence</h3>
<ul>
<li><strong>Authors: </strong>Adwait Datar, Nihat Ay</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19259">https://arxiv.org/abs/2504.19259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19259">https://arxiv.org/pdf/2504.19259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19259]] Convergence Properties of Natural Gradient Descent for Minimizing KL Divergence(https://arxiv.org/abs/2504.19259)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Kullback-Leibler (KL) divergence plays a central role in probabilistic machine learning, where it commonly serves as the canonical loss function. Optimization in such settings is often performed over the probability simplex, where the choice of parameterization significantly impacts convergence. In this work, we study the problem of minimizing the KL divergence and analyze the behavior of gradient-based optimization algorithms under two dual coordinate systems within the framework of information geometry$-$ the exponential family ($\theta$ coordinates) and the mixture family ($\eta$ coordinates). We compare Euclidean gradient descent (GD) in these coordinates with the coordinate-invariant natural gradient descent (NGD), where the natural gradient is a Riemannian gradient that incorporates the intrinsic geometry of the parameter space. In continuous time, we prove that the convergence rates of GD in the $\theta$ and $\eta$ coordinates provide lower and upper bounds, respectively, on the convergence rate of NGD. Moreover, under affine reparameterizations of the dual coordinates, the convergence rates of GD in $\eta$ and $\theta$ coordinates can be scaled to $2c$ and $\frac{2}{c}$, respectively, for any $c>0$, while NGD maintains a fixed convergence rate of $2$, remaining invariant to such transformations and sandwiched between them. Although this suggests that NGD may not exhibit uniformly superior convergence in continuous time, we demonstrate that its advantages become pronounced in discrete time, where it achieves faster convergence and greater robustness to noise, outperforming GD. Our analysis hinges on bounding the spectrum and condition number of the Hessian of the KL divergence at the optimum, which coincides with the Fisher information matrix.</li>
</ul>

<h3>Title: OpenFusion++: An Open-vocabulary Real-time Scene Understanding System</h3>
<ul>
<li><strong>Authors: </strong>Xiaofeng Jin, Matteo Frosi, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19266">https://arxiv.org/abs/2504.19266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19266">https://arxiv.org/pdf/2504.19266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19266]] OpenFusion++: An Open-vocabulary Real-time Scene Understanding System(https://arxiv.org/abs/2504.19266)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Real-time open-vocabulary scene understanding is essential for efficient 3D perception in applications such as vision-language navigation, embodied intelligence, and augmented reality. However, existing methods suffer from imprecise instance segmentation, static semantic updates, and limited handling of complex queries. To address these issues, we present OpenFusion++, a TSDF-based real-time 3D semantic-geometric reconstruction system. Our approach refines 3D point clouds by fusing confidence maps from foundational models, dynamically updates global semantic labels via an adaptive cache based on instance area, and employs a dual-path encoding framework that integrates object attributes with environmental context for precise query responses. Experiments on the ICL, Replica, ScanNet, and ScanNet++ datasets demonstrate that OpenFusion++ significantly outperforms the baseline in both semantic accuracy and query responsiveness.</li>
</ul>

<h3>Title: VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Gado, Towhid Taliee, Muhammad Memon, Dmitry Ignatov, Radu Timofte</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19267">https://arxiv.org/abs/2504.19267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19267">https://arxiv.org/pdf/2504.19267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19267]] VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?(https://arxiv.org/abs/2504.19267)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Visual storytelling is an interdisciplinary field combining computer vision and natural language processing to generate cohesive narratives from sequences of images. This paper presents a novel approach that leverages recent advancements in multimodal models, specifically adapting transformer-based architectures and large multimodal models, for the visual storytelling task. Leveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT model produces visually grounded, contextually appropriate narratives. We address the limitations of traditional evaluation metrics, such as BLEU, METEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we utilize RoViST and GROOVIST, novel reference-free metrics designed to assess visual storytelling, focusing on visual grounding, coherence, and non-redundancy. These metrics provide a more nuanced evaluation of narrative quality, aligning closely with human judgment.</li>
</ul>

<h3>Title: TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Mohammad M Maheri, Hamed Haddadi, Alex Davidson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19274">https://arxiv.org/abs/2504.19274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19274">https://arxiv.org/pdf/2504.19274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19274]] TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks(https://arxiv.org/abs/2504.19274)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, transformer</a></li>
<li><strong>Abstract: </strong>Verification of the integrity of deep learning inference is crucial for understanding whether a model is being applied correctly. However, such verification typically requires access to model weights and (potentially sensitive or private) training data. So-called Zero-knowledge Succinct Non-Interactive Arguments of Knowledge (ZK-SNARKs) would appear to provide the capability to verify model inference without access to such sensitive data. However, applying ZK-SNARKs to modern neural networks, such as transformers and large vision models, introduces significant computational overhead. We present TeleSparse, a ZK-friendly post-processing mechanisms to produce practical solutions to this problem. TeleSparse tackles two fundamental challenges inherent in applying ZK-SNARKs to modern neural networks: (1) Reducing circuit constraints: Over-parameterized models result in numerous constraints for ZK-SNARK verification, driving up memory and proof generation costs. We address this by applying sparsification to neural network models, enhancing proof efficiency without compromising accuracy or security. (2) Minimizing the size of lookup tables required for non-linear functions, by optimizing activation ranges through neural teleportation, a novel adaptation for narrowing activation functions' range. TeleSparse reduces prover memory usage by 67% and proof generation time by 46% on the same model, with an accuracy trade-off of approximately 1%. We implement our framework using the Halo2 proving system and demonstrate its effectiveness across multiple architectures (Vision-transformer, ResNet, MobileNet) and datasets (ImageNet,CIFAR-10,CIFAR-100). This work opens new directions for ZK-friendly model design, moving toward scalable, resource-efficient verifiable deep learning.</li>
</ul>

<h3>Title: FusionNet: Multi-model Linear Fusion Framework for Low-light Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Kangbiao Shi, Yixu Feng, Tao Hu, Yu Cao, Peng Wu, Yijin Liang, Yanning Zhang, Qingsen Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19295">https://arxiv.org/abs/2504.19295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19295">https://arxiv.org/pdf/2504.19295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19295]] FusionNet: Multi-model Linear Fusion Framework for Low-light Image Enhancement(https://arxiv.org/abs/2504.19295)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The advent of Deep Neural Networks (DNNs) has driven remarkable progress in low-light image enhancement (LLIE), with diverse architectures (e.g., CNNs and Transformers) and color spaces (e.g., sRGB, HSV, HVI) yielding impressive results. Recent efforts have sought to leverage the complementary strengths of these paradigms, offering promising solutions to enhance performance across varying degradation scenarios. However, existing fusion strategies are hindered by challenges such as parameter explosion, optimization instability, and feature misalignment, limiting further improvements. To overcome these issues, we introduce FusionNet, a novel multi-model linear fusion framework that operates in parallel to effectively capture global and local features across diverse color spaces. By incorporating a linear fusion strategy underpinned by Hilbert space theoretical guarantees, FusionNet mitigates network collapse and reduces excessive training costs. Our method achieved 1st place in the CVPR2025 NTIRE Low Light Enhancement Challenge. Extensive experiments conducted on synthetic and real-world benchmark datasets demonstrate that the proposed method significantly outperforms state-of-the-art methods in terms of both quantitative and qualitative results, delivering robust enhancement under diverse low-light conditions.</li>
</ul>

<h3>Title: AndroidGen: Building an Android Language Agent under Data Scarcity</h3>
<ul>
<li><strong>Authors: </strong>Hanyu Lai, Junjie Gao, Xiao Liu, Yifan Xu, Shudan Zhang, Yuxiao Dong, Jie Tang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19298">https://arxiv.org/abs/2504.19298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19298">https://arxiv.org/pdf/2504.19298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19298]] AndroidGen: Building an Android Language Agent under Data Scarcity(https://arxiv.org/abs/2504.19298)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have opened up a world of possibilities for various NLP tasks, sparking optimism for the future. Despite their potential, LLMs have yet to be widely used as agents on real mobile devices. The main challenge is the need for high-quality data sources. Time constraints and labor intensity often hinder human annotation. On the other hand, existing LLMs exhibit inadequate completion rates and need a robust data filtration strategy. Given these challenges, we develop a framework called AndroidGen to enhance the capabilities of LLM-based agents under data scarcity. In addition, we leverage AndroidGen to collect trajectories given human tasks and train open-source LLMs on these trajectories to develop an open-source mobile agent without manually labeled trajectories. We extensively evaluate AndroidGen with AndroidWorld, AitW, and various popular applications, demonstrating its improvements and revealing potential areas for future improvement. Code, model, and data are available at this https URL.</li>
</ul>

<h3>Title: Myocardial Region-guided Feature Aggregation Net for Automatic Coronary artery Segmentation and Stenosis Assessment using Coronary Computed Tomography Angiography</h3>
<ul>
<li><strong>Authors: </strong>Ni Yao, Xiangyu Liu, Danyang Sun, Chuang Han, Yanting Li, Jiaofen Nan, Chengyang Li, Fubao Zhu, Weihua Zhou, Chen Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19300">https://arxiv.org/abs/2504.19300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19300">https://arxiv.org/pdf/2504.19300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19300]] Myocardial Region-guided Feature Aggregation Net for Automatic Coronary artery Segmentation and Stenosis Assessment using Coronary Computed Tomography Angiography(https://arxiv.org/abs/2504.19300)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Coronary artery disease (CAD) remains a leading cause of mortality worldwide, requiring accurate segmentation and stenosis detection using Coronary Computed Tomography angiography (CCTA). Existing methods struggle with challenges such as low contrast, morphological variability and small vessel segmentation. To address these limitations, we propose the Myocardial Region-guided Feature Aggregation Net, a novel U-shaped dual-encoder architecture that integrates anatomical prior knowledge to enhance robustness in coronary artery segmentation. Our framework incorporates three key innovations: (1) a Myocardial Region-guided Module that directs attention to coronary regions via myocardial contour expansion and multi-scale feature fusion, (2) a Residual Feature Extraction Encoding Module that combines parallel spatial channel attention with residual blocks to enhance local-global feature discrimination, and (3) a Multi-scale Feature Fusion Module for adaptive aggregation of hierarchical vascular features. Additionally, Monte Carlo dropout f quantifies prediction uncertainty, supporting clinical interpretability. For stenosis detection, a morphology-based centerline extraction algorithm separates the vascular tree into anatomical branches, enabling cross-sectional area quantification and stenosis grading. The superiority of MGFA-Net was demonstrated by achieving an Dice score of 85.04%, an accuracy of 84.24%, an HD95 of 6.1294 mm, and an improvement of 5.46% in true positive rate for stenosis detection compared to3D U-Net. The integrated segmentation-to-stenosis pipeline provides automated, clinically interpretable CAD assessment, bridging deep learning with anatomical prior knowledge for precision medicine. Our code is publicly available at this http URL</li>
</ul>

<h3>Title: BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese</h3>
<ul>
<li><strong>Authors: </strong>Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, Yuxin Gu, Sixin Hong, Jing Ren, Jian Chen, Chao Liu, Yining Hua</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19314">https://arxiv.org/abs/2504.19314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19314">https://arxiv.org/pdf/2504.19314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19314]] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese(https://arxiv.org/abs/2504.19314)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) evolve into tool-using agents, the ability to browse the web in real-time has become a critical yardstick for measuring their reasoning and retrieval competence. Existing benchmarks such as BrowseComp concentrate on English and overlook the linguistic, infrastructural, and censorship-related complexities of other major information ecosystems -- most notably Chinese. To address this gap, we introduce BrowseComp-ZH, a high-difficulty benchmark purpose-built to comprehensively evaluate LLM agents on the Chinese web. BrowseComp-ZH consists of 289 multi-hop questions spanning 11 diverse domains. Each question is reverse-engineered from a short, objective, and easily verifiable answer (e.g., a date, number, or proper noun). A two-stage quality control protocol is applied to strive for high question difficulty and answer uniqueness. We benchmark over 20 state-of-the-art language models and agentic search systems on our proposed BrowseComp-ZH. Despite their strong conversational and retrieval capabilities, most models struggle severely: a large number achieve accuracy rates below 10%, and only a handful exceed 20%. Even the best-performing system, OpenAI's DeepResearch, reaches just 42.9%. These results demonstrate the considerable difficulty of BrowseComp-ZH, where success demands not only effective retrieval strategies, but also sophisticated reasoning and information reconciliation -- capabilities that current models still struggle to master. Our dataset, construction guidelines, and benchmark results have been publicly released at this https URL.</li>
</ul>

<h3>Title: Platonic Grounding for Efficient Multimodal Language Models</h3>
<ul>
<li><strong>Authors: </strong>Moulik Choraria, Xinbo Wu, Akhil Bhimaraju, Nitesh Sekhar, Yue Wu, Xu Zhang, Prateek Singhal, Lav R. Varshney</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19327">https://arxiv.org/abs/2504.19327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19327">https://arxiv.org/pdf/2504.19327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19327]] Platonic Grounding for Efficient Multimodal Language Models(https://arxiv.org/abs/2504.19327)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The hyperscaling of data and parameter count in Transformer-based models is yielding diminishing performance improvement, especially when weighed against training costs. Such plateauing indicates the importance of methods for more efficient finetuning and inference, while retaining similar performance. This is especially relevant for multimodal learning paradigms, where inference costs of processing multimodal tokens can determine the model's practical viability. At the same time, research on representations and mechanistic interpretability has improved our understanding of the inner workings of Transformer-based models; one such line of work reveals an implicit alignment in the deeper layers of pretrained models, across modalities. Taking inspiration from this, we motivate and propose a simple modification to existing multimodal frameworks that rely on aligning pretrained models. We demonstrate that our approach maintains and, in some cases, even improves performance of baseline methods while achieving significant gains in both training and inference-time compute. Our work also has implications for combining pretrained models into larger systems efficiently.</li>
</ul>

<h3>Title: Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing</h3>
<ul>
<li><strong>Authors: </strong>James O' Neill, Santhosh Subramanian, Eric Lin, Vaikkunth Mugunthan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19333">https://arxiv.org/abs/2504.19333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19333">https://arxiv.org/pdf/2504.19333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19333]] Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing(https://arxiv.org/abs/2504.19333)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The trend towards large language models (LLMs) for guardrailing against undesired behaviors is increasing and has shown promise for censoring user inputs. However, increased latency, memory consumption, hosting expenses and non-structured outputs can make their use prohibitive. In this work, we show that task-specific data generation can lead to fine-tuned classifiers that significantly outperform current state of the art (SoTA) while being orders of magnitude smaller. Secondly, we show that using a single model, \texttt{MultiTaskGuard}, that is pretrained on a large synthetically generated dataset with unique task instructions further improves generalization. Thirdly, our most performant models, \texttt{UniGuard}, are found using our proposed search-based model merging approach that finds an optimal set of parameters to combine single-policy models and multi-policy guardrail models. % On 7 public datasets and 4 guardrail benchmarks we created, our efficient guardrail classifiers improve over the best performing SoTA publicly available LLMs and 3$^{\text{rd}}$ party guardrail APIs in detecting unsafe and safe behaviors by an average F1 score improvement of \textbf{29.92} points over Aegis-LlamaGuard and \textbf{21.62} over \texttt{gpt-4o}, respectively. Lastly, our guardrail synthetic data generation process that uses custom task-specific guardrail poli</li>
</ul>

<h3>Title: Enhancing seeding efficiency using a computer vision system to monitor furrow quality in real-time</h3>
<ul>
<li><strong>Authors: </strong>Sidharth Rai, Aryan Dalal, Riley Slichter, Ajay Sharda</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19334">https://arxiv.org/abs/2504.19334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19334">https://arxiv.org/pdf/2504.19334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19334]] Enhancing seeding efficiency using a computer vision system to monitor furrow quality in real-time(https://arxiv.org/abs/2504.19334)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Effective seed sowing in precision agriculture is hindered by challenges such as residue accumulation, low soil temperatures, and hair pinning (crop residue pushed in the trench by furrow opener), which obstruct optimal trench formation. Row cleaners are employed to mitigate these issues, but there is a lack of quantitative methods to assess trench cleanliness. In this study, a novel computer vision-based method was developed to evaluate row cleaner performance. Multiple air seeders were equipped with a video acquisition system to capture trench conditions after row cleaner operation, enabling an effective comparison of the performance of each row cleaner. The captured data were used to develop a segmentation model that analyzed key elements such as soil, straw, and machinery. Using the results from the segmentation model, an objective method was developed to quantify row cleaner performance. The results demonstrated the potential of this method to improve row cleaner selection and enhance seeding efficiency in precision agriculture.</li>
</ul>

<h3>Title: Explanatory Summarization with Discourse-Driven Planning</h3>
<ul>
<li><strong>Authors: </strong>Dongqi Liu, Xi Yu, Vera Demberg, Mirella Lapata</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19339">https://arxiv.org/abs/2504.19339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19339">https://arxiv.org/pdf/2504.19339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19339]] Explanatory Summarization with Discourse-Driven Planning(https://arxiv.org/abs/2504.19339)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Lay summaries for scientific documents typically include explanations to help readers grasp sophisticated concepts or arguments. However, current automatic summarization methods do not explicitly model explanations, which makes it difficult to align the proportion of explanatory content with human-written summaries. In this paper, we present a plan-based approach that leverages discourse frameworks to organize summary generation and guide explanatory sentences by prompting responses to the plan. Specifically, we propose two discourse-driven planning strategies, where the plan is conditioned as part of the input or part of the output prefix, respectively. Empirical experiments on three lay summarization datasets show that our approach outperforms existing state-of-the-art methods in terms of summary quality, and it enhances model robustness, controllability, and mitigates hallucination.</li>
</ul>

<h3>Title: Flow Along the K-Amplitude for Generative Modeling</h3>
<ul>
<li><strong>Authors: </strong>Weitao Du, Shuning Chang, Jiasheng Tang, Yu Rong, Fan Wang, Shengchao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19353">https://arxiv.org/abs/2504.19353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19353">https://arxiv.org/pdf/2504.19353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19353]] Flow Along the K-Amplitude for Generative Modeling(https://arxiv.org/abs/2504.19353)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this work, we propose a novel generative learning paradigm, K-Flow, an algorithm that flows along the $K$-amplitude. Here, $k$ is a scaling parameter that organizes frequency bands (or projected coefficients), and amplitude describes the norm of such projected coefficients. By incorporating the $K$-amplitude decomposition, K-Flow enables flow matching across the scaling parameter as time. We discuss three venues and six properties of K-Flow, from theoretical foundations, energy and temporal dynamics, and practical applications, respectively. Specifically, from the practical usage perspective, K-Flow allows steerable generation by controlling the information at different scales. To demonstrate the effectiveness of K-Flow, we conduct experiments on unconditional image generation, class-conditional image generation, and molecule assembly generation. Additionally, we conduct three ablation studies to demonstrate how K-Flow steers scaling parameter to effectively control the resolution of image generation.</li>
</ul>

<h3>Title: MERA: Multimodal and Multiscale Self-Explanatory Model with Considerably Reduced Annotation for Lung Nodule Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Lu, Chong Yin, Silvia Ingala, Kenny Erleben, Michael Bachmann Nielsen, Sune Darkner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19357">https://arxiv.org/abs/2504.19357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19357">https://arxiv.org/pdf/2504.19357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19357]] MERA: Multimodal and Multiscale Self-Explanatory Model with Considerably Reduced Annotation for Lung Nodule Diagnosis(https://arxiv.org/abs/2504.19357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Lung cancer, a leading cause of cancer-related deaths globally, emphasises the importance of early detection for better patient outcomes. Pulmonary nodules, often early indicators of lung cancer, necessitate accurate, timely diagnosis. Despite Explainable Artificial Intelligence (XAI) advances, many existing systems struggle providing clear, comprehensive explanations, especially with limited labelled data. This study introduces MERA, a Multimodal and Multiscale self-Explanatory model designed for lung nodule diagnosis with considerably Reduced Annotation requirements. MERA integrates unsupervised and weakly supervised learning strategies (self-supervised learning techniques and Vision Transformer architecture for unsupervised feature extraction) and a hierarchical prediction mechanism leveraging sparse annotations via semi-supervised active learning in the learned latent space. MERA explains its decisions on multiple levels: model-level global explanations via semantic latent space clustering, instance-level case-based explanations showing similar instances, local visual explanations via attention maps, and concept explanations using critical nodule attributes. Evaluations on the public LIDC dataset show MERA's superior diagnostic accuracy and self-explainability. With only 1% annotated samples, MERA achieves diagnostic accuracy comparable to or exceeding state-of-the-art methods requiring full annotation. The model's inherent design delivers comprehensive, robust, multilevel explanations aligned closely with clinical practice, enhancing trustworthiness and transparency. Demonstrated viability of unsupervised and weakly supervised learning lowers the barrier to deploying diagnostic AI in broader medical domains. Our complete code is open-source available: this https URL.</li>
</ul>

<h3>Title: Mitigating Bias in Facial Recognition Systems: Centroid Fairness Loss Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jean-Rémy Conti, Stéphan Clémençon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19370">https://arxiv.org/abs/2504.19370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19370">https://arxiv.org/pdf/2504.19370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19370]] Mitigating Bias in Facial Recognition Systems: Centroid Fairness Loss Optimization(https://arxiv.org/abs/2504.19370)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The urging societal demand for fair AI systems has put pressure on the research community to develop predictive models that are not only globally accurate but also meet new fairness criteria, reflecting the lack of disparate mistreatment with respect to sensitive attributes ($\textit{e.g.}$ gender, ethnicity, age). In particular, the variability of the errors made by certain Facial Recognition (FR) systems across specific segments of the population compromises the deployment of the latter, and was judged unacceptable by regulatory authorities. Designing fair FR systems is a very challenging problem, mainly due to the complex and functional nature of the performance measure used in this domain ($\textit{i.e.}$ ROC curves) and because of the huge heterogeneity of the face image datasets usually available for training. In this paper, we propose a novel post-processing approach to improve the fairness of pre-trained FR models by optimizing a regression loss which acts on centroid-based scores. Beyond the computational advantages of the method, we present numerical experiments providing strong empirical evidence of the gain in fairness and of the ability to preserve global accuracy.</li>
</ul>

<h3>Title: Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model</h3>
<ul>
<li><strong>Authors: </strong>Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Yue Zhao, Zhen Xiang, Chaowei Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19373">https://arxiv.org/abs/2504.19373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19373">https://arxiv.org/pdf/2504.19373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19373]] Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model(https://arxiv.org/abs/2504.19373)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense</a></li>
<li><strong>Abstract: </strong>The increasing capabilities of agentic multi-modal large reasoning models, such as ChatGPT o3, have raised critical concerns regarding privacy leakage through inadvertent image geolocation. In this paper, we conduct the first systematic and controlled study on the potential privacy risks associated with visual reasoning abilities of ChatGPT o3. We manually collect and construct a dataset comprising 50 real-world images that feature individuals alongside privacy-relevant environmental elements, capturing realistic and sensitive scenarios for analysis. Our experimental evaluation reveals that ChatGPT o3 can predict user locations with high precision, achieving street-level accuracy (within one mile) in 60% of cases. Through analysis, we identify key visual cues, including street layout and front yard design, that significantly contribute to the model inference success. Additionally, targeted occlusion experiments demonstrate that masking critical features effectively mitigates geolocation accuracy, providing insights into potential defense mechanisms. Our findings highlight an urgent need for privacy-aware development for agentic multi-modal large reasoning models, particularly in applications involving private imagery.</li>
</ul>

<h3>Title: Rethinking Label-specific Features for Label Distribution Learning</h3>
<ul>
<li><strong>Authors: </strong>Suping Xu, Chuyi Dai, Lin Shang, Changbin Shao, Xibei Yang, Witold Pedrycz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19374">https://arxiv.org/abs/2504.19374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19374">https://arxiv.org/pdf/2504.19374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19374]] Rethinking Label-specific Features for Label Distribution Learning(https://arxiv.org/abs/2504.19374)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Label distribution learning (LDL) is an emerging learning paradigm designed to capture the relative importance of labels for each instance. Label-specific features (LSFs), constructed by LIFT, have proven effective for learning tasks with label ambiguity by leveraging clustering-based prototypes for each label to re-characterize instances. However, directly introducing LIFT into LDL tasks can be suboptimal, as the prototypes it collects primarily reflect intra-cluster relationships while neglecting interactions among distinct clusters. Additionally, constructing LSFs using multi-perspective information, rather than relying solely on Euclidean distance, provides a more robust and comprehensive representation of instances, mitigating noise and bias that may arise from a single distance perspective. To address these limitations, we introduce Structural Anchor Points (SAPs) to capture inter-cluster interactions. This leads to a novel LSFs construction strategy, LIFT-SAP, which enhances LIFT by integrating both distance and direction information of each instance relative to SAPs. Furthermore, we propose a novel LDL algorithm, Label Distribution Learning via Label-specifIc FeaTure with SAPs (LDL-LIFT-SAP), which unifies multiple label description degrees predicted from different LSF spaces into a cohesive label distribution. Extensive experiments on 15 real-world datasets demonstrate the effectiveness of LIFT-SAP over LIFT, as well as the superiority of LDL-LIFT-SAP compared to seven other well-established algorithms.</li>
</ul>

<h3>Title: HumMorph: Generalized Dynamic Human Neural Fields from Few Views</h3>
<ul>
<li><strong>Authors: </strong>Jakub Zadrożny, Hakan Bilen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19390">https://arxiv.org/abs/2504.19390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19390">https://arxiv.org/pdf/2504.19390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19390]] HumMorph: Generalized Dynamic Human Neural Fields from Few Views(https://arxiv.org/abs/2504.19390)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce HumMorph, a novel generalized approach to free-viewpoint rendering of dynamic human bodies with explicit pose control. HumMorph renders a human actor in any specified pose given a few observed views (starting from just one) in arbitrary poses. Our method enables fast inference as it relies only on feed-forward passes through the model. We first construct a coarse representation of the actor in the canonical T-pose, which combines visual features from individual partial observations and fills missing information using learned prior knowledge. The coarse representation is complemented by fine-grained pixel-aligned features extracted directly from the observed views, which provide high-resolution appearance information. We show that HumMorph is competitive with the state-of-the-art when only a single input view is available, however, we achieve results with significantly better visual quality given just 2 monocular observations. Moreover, previous generalized methods assume access to accurate body shape and pose parameters obtained using synchronized multi-camera setups. In contrast, we consider a more practical scenario where these body parameters are noisily estimated directly from the observed views. Our experimental results demonstrate that our architecture is more robust to errors in the noisy parameters and clearly outperforms the state of the art in this setting.</li>
</ul>

<h3>Title: Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations</h3>
<ul>
<li><strong>Authors: </strong>Khoa Tuan Nguyen, Francesca Tozzi, Wouter Willaert, Joris Vankerschaver, Nikdokht Rashidian, Wesley De Neve</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19402">https://arxiv.org/abs/2504.19402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19402">https://arxiv.org/pdf/2504.19402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19402]] Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations(https://arxiv.org/abs/2504.19402)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>While the availability of open 3D medical shape datasets is increasing, offering substantial benefits to the research community, we have found that many of these datasets are, unfortunately, disorganized and contain artifacts. These issues limit the development and training of robust models, particularly for accurate 3D reconstruction tasks. In this paper, we examine the current state of available 3D liver shape datasets and propose a solution using diffusion models combined with implicit neural representations (INRs) to augment and expand existing datasets. Our approach utilizes the generative capabilities of diffusion models to create realistic, diverse 3D liver shapes, capturing a wide range of anatomical variations and addressing the problem of data scarcity. Experimental results indicate that our method enhances dataset diversity, providing a scalable solution to improve the accuracy and reliability of 3D liver reconstruction and generation in medical applications. Finally, we suggest that diffusion models can also be applied to other downstream tasks in 3D medical imaging.</li>
</ul>

<h3>Title: Context Selection and Rewriting for Video-based EducationalQuestion Generation</h3>
<ul>
<li><strong>Authors: </strong>Mengxia Yu, Bang Nguyen, Olivia Zino, Meng Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19406">https://arxiv.org/abs/2504.19406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19406">https://arxiv.org/pdf/2504.19406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19406]] Context Selection and Rewriting for Video-based EducationalQuestion Generation(https://arxiv.org/abs/2504.19406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Educational question generation (EQG) is a crucial component of intelligent educational systems, significantly aiding self-assessment, active learning, and personalized education. While EQG systems have emerged, existing datasets typically rely on predefined, carefully edited texts, failing to represent real-world classroom content, including lecture speech with a set of complementary slides. To bridge this gap, we collect a dataset of educational questions based on lectures from real-world classrooms. On this realistic dataset, we find that current methods for EQG struggle with accurately generating questions from educational videos, particularly in aligning with specific timestamps and target answers. Common challenges include selecting informative contexts from extensive transcripts and ensuring generated questions meaningfully incorporate the target answer. To address the challenges, we introduce a novel framework utilizing large language models for dynamically selecting and rewriting contexts based on target timestamps and answers. First, our framework selects contexts from both lecture transcripts and video keyframes based on answer relevance and temporal proximity. Then, we integrate the contexts selected from both modalities and rewrite them into answer-containing knowledge statements, to enhance the logical connection between the contexts and the desired answer. This approach significantly improves the quality and relevance of the generated questions. Our dataset and code are released in this https URL.</li>
</ul>

<h3>Title: UNet with Axial Transformer : A Neural Weather Model for Precipitation Nowcasting</h3>
<ul>
<li><strong>Authors: </strong>Maitreya Sonawane, Sumit Mamtani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19408">https://arxiv.org/abs/2504.19408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19408">https://arxiv.org/pdf/2504.19408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19408]] UNet with Axial Transformer : A Neural Weather Model for Precipitation Nowcasting(https://arxiv.org/abs/2504.19408)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Making accurate weather predictions can be particularly challenging for localized storms or events that evolve on hourly timescales, such as thunderstorms. Hence, our goal for the project was to model Weather Nowcasting for making highly localized and accurate predictions that apply to the immediate future replacing the current numerical weather models and data assimilation systems with Deep Learning approaches. A significant advantage of machine learning is that inference is computationally cheap given an already-trained model, allowing forecasts that are nearly instantaneous and in the native high resolution of the input data. In this work we developed a novel method that employs Transformer-based machine learning models to forecast precipitation. This approach works by leveraging axial attention mechanisms to learn complex patterns and dynamics from time series frames. Moreover, it is a generic framework and can be applied to univariate and multivariate time series data, as well as time series embeddings data. This paper represents an initial research on the dataset used in the domain of next frame prediciton, and hence, we demonstrate state-of-the-art results in terms of metrices (PSNR = 47.67, SSIM = 0.9943) used for the given dataset using UNet with Axial Transformer.</li>
</ul>

<h3>Title: Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory</h3>
<ul>
<li><strong>Authors: </strong>Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, Deshraj Yadav</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19413">https://arxiv.org/abs/2504.19413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19413">https://arxiv.org/pdf/2504.19413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19413]] Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory(https://arxiv.org/abs/2504.19413)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues. We introduce Mem0, a scalable memory-centric architecture that addresses this issue by dynamically extracting, consolidating, and retrieving salient information from ongoing conversations. Building on this foundation, we further propose an enhanced variant that leverages graph-based memory representations to capture complex relational structures among conversational elements. Through comprehensive evaluations on LOCOMO benchmark, we systematically compare our approaches against six baseline categories: (i) established memory-augmented systems, (ii) retrieval-augmented generation (RAG) with varying chunk sizes and k-values, (iii) a full-context approach that processes the entire conversation history, (iv) an open-source memory solution, (v) a proprietary model system, and (vi) a dedicated memory management platform. Empirical results show that our methods consistently outperform all existing memory systems across four question categories: single-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26% relative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with graph memory achieves around 2% higher overall score than the base configuration. Beyond accuracy gains, we also markedly reduce computational overhead compared to full-context method. In particular, Mem0 attains a 91% lower p95 latency and saves more than 90% token cost, offering a compelling balance between advanced reasoning capabilities and practical deployment constraints. Our findings highlight critical role of structured, persistent memory mechanisms for long-term conversational coherence, paving the way for more reliable and efficient LLM-driven AI agents.</li>
</ul>

<h3>Title: GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Sehyeong Jo, Gangjae Jang, Haesol Park</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19414">https://arxiv.org/abs/2504.19414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19414">https://arxiv.org/pdf/2504.19414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19414]] GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability(https://arxiv.org/abs/2504.19414)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The Vision Transformer (ViT) has made significant advancements in computer vision, utilizing self-attention mechanisms to achieve state-of-the-art performance across various tasks, including image classification, object detection, and segmentation. Its architectural flexibility and capabilities have made it a preferred choice among researchers and practitioners. However, the intricate multi-head attention mechanism of ViT presents significant challenges to interpretability, as the underlying prediction process remains opaque. A critical limitation arises from an observation commonly noted in transformer architectures: "Not all attention heads are equally meaningful." Overlooking the relative importance of specific heads highlights the limitations of existing interpretability methods. To address these challenges, we introduce Gradient-Driven Multi-Head Attention Rollout (GMAR), a novel method that quantifies the importance of each attention head using gradient-based scores. These scores are normalized to derive a weighted aggregate attention score, effectively capturing the relative contributions of individual heads. GMAR clarifies the role of each head in the prediction process, enabling more precise interpretability at the head level. Experimental results demonstrate that GMAR consistently outperforms traditional attention rollout techniques. This work provides a practical contribution to transformer-based architectures, establishing a robust framework for enhancing the interpretability of Vision Transformer models.</li>
</ul>

<h3>Title: ChipletQuake: On-die Digital Impedance Sensing for Chiplet and Interposer Verification</h3>
<ul>
<li><strong>Authors: </strong>Saleh Khalaj Monfared, Maryam Saadat Safa, Shahin Tajik</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19418">https://arxiv.org/abs/2504.19418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19418">https://arxiv.org/pdf/2504.19418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19418]] ChipletQuake: On-die Digital Impedance Sensing for Chiplet and Interposer Verification(https://arxiv.org/abs/2504.19418)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The increasing complexity and cost of manufacturing monolithic chips have driven the semiconductor industry toward chiplet-based designs, where smaller and modular chiplets are integrated onto a single interposer. While chiplet architectures offer significant advantages, such as improved yields, design flexibility, and cost efficiency, they introduce new security challenges in the horizontal hardware manufacturing supply chain. These challenges include risks of hardware Trojans, cross-die side-channel and fault injection attacks, probing of chiplet interfaces, and intellectual property theft. To address these concerns, this paper presents \textit{ChipletQuake}, a novel on-chiplet framework for verifying the physical security and integrity of adjacent chiplets during the post-silicon stage. By sensing the impedance of the power delivery network (PDN) of the system, \textit{ChipletQuake} detects tamper events in the interposer and neighboring chiplets without requiring any direct signal interface or additional hardware components. Fully compatible with the digital resources of FPGA-based chiplets, this framework demonstrates the ability to identify the insertion of passive and subtle malicious circuits, providing an effective solution to enhance the security of chiplet-based systems. To validate our claims, we showcase how our framework detects Hardware Trojan and interposer tampering.</li>
</ul>

<h3>Title: Graph-based Semi-supervised and Unsupervised Methods for Local Clustering</h3>
<ul>
<li><strong>Authors: </strong>Zhaiming Shen, Sung Ha Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19419">https://arxiv.org/abs/2504.19419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19419">https://arxiv.org/pdf/2504.19419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19419]] Graph-based Semi-supervised and Unsupervised Methods for Local Clustering(https://arxiv.org/abs/2504.19419)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Local clustering aims to identify specific substructures within a large graph without requiring full knowledge of the entire graph. These substructures are typically small compared to the overall graph, enabling the problem to be approached by finding a sparse solution to a linear system associated with the graph Laplacian. In this work, we first propose a method for identifying specific local clusters when very few labeled data is given, which we term semi-supervised local clustering. We then extend this approach to the unsupervised setting when no prior information on labels is available. The proposed methods involve randomly sampling the graph, applying diffusion through local cluster extraction, then examining the overlap among the results to find each cluster. We establish the co-membership conditions for any pair of nodes and rigorously prove the correctness of our methods. Additionally, we conduct extensive experiments to demonstrate that the proposed methods achieve state-of-the-arts results in the low-label rates regime.</li>
</ul>

<h3>Title: EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation</h3>
<ul>
<li><strong>Authors: </strong>Zhe Dong, Yuzhe Sun, Tianzhu Liu, Wangmeng Zuo, Yanfeng Gu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19432">https://arxiv.org/abs/2504.19432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19432">https://arxiv.org/pdf/2504.19432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19432]] EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation(https://arxiv.org/abs/2504.19432)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Satellite imagery and maps, as two fundamental data modalities in remote sensing, offer direct observations of the Earth's surface and human-interpretable geographic abstractions, respectively. The task of bidirectional translation between satellite images and maps (BSMT) holds significant potential for applications in urban planning and disaster response. However, this task presents two major challenges: first, the absence of precise pixel-wise alignment between the two modalities substantially complicates the translation process; second, it requires achieving both high-level abstraction of geographic features and high-quality visual synthesis, which further elevates the technical complexity. To address these limitations, we introduce EarthMapper, a novel autoregressive framework for controllable bidirectional satellite-map translation. EarthMapper employs geographic coordinate embeddings to anchor generation, ensuring region-specific adaptability, and leverages multi-scale feature alignment within a geo-conditioned joint scale autoregression (GJSA) process to unify bidirectional translation in a single training cycle. A semantic infusion (SI) mechanism is introduced to enhance feature-level consistency, while a key point adaptive guidance (KPAG) mechanism is proposed to dynamically balance diversity and precision during inference. We further contribute CNSatMap, a large-scale dataset comprising 302,132 precisely aligned satellite-map pairs across 38 Chinese cities, enabling robust benchmarking. Extensive experiments on CNSatMap and the New York dataset demonstrate EarthMapper's superior performance, achieving significant improvements in visual realism, semantic consistency, and structural fidelity over state-of-the-art methods. Additionally, EarthMapper excels in zero-shot tasks like in-painting, out-painting and coordinate-conditional generation, underscoring its versatility.</li>
</ul>

<h3>Title: GTSD: Generative Text Steganography Based on Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Zhengxian Wu, Juan Wen, Yiming Xue, Ziwei Zhang, Yinghan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19433">https://arxiv.org/abs/2504.19433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19433">https://arxiv.org/pdf/2504.19433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19433]] GTSD: Generative Text Steganography Based on Diffusion Model(https://arxiv.org/abs/2504.19433)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>With the rapid development of deep learning, existing generative text steganography methods based on autoregressive models have achieved success. However, these autoregressive steganography approaches have certain limitations. Firstly, existing methods require encoding candidate words according to their output probability and generating each stego word one by one, which makes the generation process time-consuming. Secondly, encoding and selecting candidate words changes the sampling probabilities, resulting in poor imperceptibility of the stego text. Thirdly, existing methods have low robustness and cannot resist replacement attacks. To address these issues, we propose a generative text steganography method based on a diffusion model (GTSD), which improves generative speed, robustness, and imperceptibility while maintaining security. To be specific, a novel steganography scheme based on diffusion model is proposed to embed secret information through prompt mapping and batch mapping. The prompt mapping maps secret information into a conditional prompt to guide the pre-trained diffusion model generating batches of candidate sentences. The batch mapping selects stego text based on secret information from batches of candidate sentences. Extensive experiments show that the GTSD outperforms the SOTA method in terms of generative speed, robustness, and imperceptibility while maintaining comparable anti-steganalysis performance. Moreover, we verify that the GTSD has strong potential: embedding capacity is positively correlated with prompt capacity and model batch sizes while maintaining security.</li>
</ul>

<h3>Title: Context-Guided Dynamic Retrieval for Improving Generation Quality in RAG Models</h3>
<ul>
<li><strong>Authors: </strong>Jacky He, Guiran Liu, Binrong Zhu, Hanlu Zhang, Hongye Zheng, Xiaokai Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19436">https://arxiv.org/abs/2504.19436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19436">https://arxiv.org/pdf/2504.19436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19436]] Context-Guided Dynamic Retrieval for Improving Generation Quality in RAG Models(https://arxiv.org/abs/2504.19436)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper focuses on the dynamic optimization of the Retrieval-Augmented Generation (RAG) architecture. It proposes a state-aware dynamic knowledge retrieval mechanism to enhance semantic understanding and knowledge scheduling efficiency in large language models for open-domain question answering and complex generation tasks. The method introduces a multi-level perceptive retrieval vector construction strategy and a differentiable document matching path. These components enable end-to-end joint training and collaborative optimization of the retrieval and generation modules. This effectively addresses the limitations of static RAG structures in context adaptation and knowledge access. Experiments are conducted on the Natural Questions dataset. The proposed structure is thoroughly evaluated across different large models, including GPT-4, GPT-4o, and DeepSeek. Comparative and ablation experiments from multiple perspectives confirm the significant improvements in BLEU and ROUGE-L scores. The approach also demonstrates stronger robustness and generation consistency in tasks involving semantic ambiguity and multi-document fusion. These results highlight its broad application potential and practical value in building high-quality language generation systems.</li>
</ul>

<h3>Title: JailbreaksOverTime: Detecting Jailbreak Attacks Under Distribution Shift</h3>
<ul>
<li><strong>Authors: </strong>Julien Piet, Xiao Huang, Dennis Jacob, Annabella Chow, Maha Alrashed, Geng Zhao, Zhanhao Hu, Chawin Sitawarin, Basel Alomair, David Wagner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19440">https://arxiv.org/abs/2504.19440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19440">https://arxiv.org/pdf/2504.19440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19440]] JailbreaksOverTime: Detecting Jailbreak Attacks Under Distribution Shift(https://arxiv.org/abs/2504.19440)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Safety and security remain critical concerns in AI deployment. Despite safety training through reinforcement learning with human feedback (RLHF) [ 32], language models remain vulnerable to jailbreak attacks that bypass safety guardrails. Universal jailbreaks - prefixes that can circumvent alignment for any payload - are particularly concerning. We show empirically that jailbreak detection systems face distribution shift, with detectors trained at one point in time performing poorly against newer exploits. To study this problem, we release JailbreaksOverTime, a comprehensive dataset of timestamped real user interactions containing both benign requests and jailbreak attempts collected over 10 months. We propose a two-pronged method for defenders to detect new jailbreaks and continuously update their detectors. First, we show how to use continuous learning to detect jailbreaks and adapt rapidly to new emerging jailbreaks. While detectors trained at a single point in time eventually fail due to drift, we find that universal jailbreaks evolve slowly enough for self-training to be effective. Retraining our detection model weekly using its own labels - with no new human labels - reduces the false negative rate from 4% to 0.3% at a false positive rate of 0.1%. Second, we introduce an unsupervised active monitoring approach to identify novel jailbreaks. Rather than classifying inputs directly, we recognize jailbreaks by their behavior, specifically, their ability to trigger models to respond to known-harmful prompts. This approach has a higher false negative rate (4.1%) than supervised methods, but it successfully identified some out-of-distribution attacks that were missed by the continuous learning approach.</li>
</ul>

<h3>Title: Systematic Bias in Large Language Models: Discrepant Response Patterns in Binary vs. Continuous Judgment Tasks</h3>
<ul>
<li><strong>Authors: </strong>Yi-Long Lu, Chunhui Zhang, Wei Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19445">https://arxiv.org/abs/2504.19445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19445">https://arxiv.org/pdf/2504.19445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19445]] Systematic Bias in Large Language Models: Discrepant Response Patterns in Binary vs. Continuous Judgment Tasks(https://arxiv.org/abs/2504.19445)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used in tasks such as psychological text analysis and decision-making in automated workflows. However, their reliability remains a concern due to potential biases inherited from their training process. In this study, we examine how different response format: binary versus continuous, may systematically influence LLMs' judgments. In a value statement judgments task and a text sentiment analysis task, we prompted LLMs to simulate human responses and tested both formats across several models, including both open-source and commercial models. Our findings revealed a consistent negative bias: LLMs were more likely to deliver "negative" judgments in binary formats compared to continuous ones. Control experiments further revealed that this pattern holds across both tasks. Our results highlight the importance of considering response format when applying LLMs to decision tasks, as small changes in task design can introduce systematic biases.</li>
</ul>

<h3>Title: R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Zhang, Zechun Liu, Yuandong Tian, Harshit Khaitan, Zhangyang Wang, Steven Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19449">https://arxiv.org/abs/2504.19449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19449">https://arxiv.org/pdf/2504.19449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19449]] R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference(https://arxiv.org/abs/2504.19449)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), while demonstrating remarkable capabilities across various applications, present significant challenges during inference due to their substantial model size, especially when deployed on edge devices. Activation sparsity offers a promising solution to reduce computation and memory movement, enabling more efficient inference, particularly for small-batch on-device applications. However, current approaches face limitations with non-ReLU activation function, which are foundational to most advanced LLMs, or require heavy continual training. Additionally, the difficulty in predicting active channels and limited achievable sparsity ratios constrain the effectiveness of activation sparsity-based methods. In this paper, we introduce R-Sparse, a training-free activation sparsity approach capable of achieving high sparsity levels in advanced LLMs. We conducted two preliminary investigations into how different components contribute to the output within a single linear layer and found two key observations: (i) the non-sparse components of the input function can be regarded as a few bias terms, and (ii) The full computation can be effectively approximated by an appropriate combination of input channels and weight singular values. Building on this, we replace the linear layers in LLMs with a rank-aware sparse inference method that leverages the sparsity of input channels and singular value components, eliminating the need for active channel prediction like the output sparsity based approaches. Experiments on Llama-2/3 and Mistral models across ten diverse tasks demonstrate that R-Sparse achieves comparable performance at 50% model-level sparsity, resulting in a significant 43% end-to-end efficient improvements with customized kernels.</li>
</ul>

<h3>Title: Geometry-Informed Neural Operator Transformer</h3>
<ul>
<li><strong>Authors: </strong>Qibang Liu, Vincient Zhong, Hadi Meidani, Diab Abueidda, Seid Koric, Philippe Geubelle</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19452">https://arxiv.org/abs/2504.19452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19452">https://arxiv.org/pdf/2504.19452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19452]] Geometry-Informed Neural Operator Transformer(https://arxiv.org/abs/2504.19452)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions for arbitrary geometries. GINOT encodes the surface points cloud of a geometry using a sampling and grouping mechanism combined with an attention mechanism, ensuring invariance to point order and padding while maintaining robustness to variations in point density. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.</li>
</ul>

<h3>Title: Provably Secure Public-Key Steganography Based on Admissible Encoding</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhang, Kejiang Chen, Na Zhao, Weiming Zhang, Nenghai Yu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19454">https://arxiv.org/abs/2504.19454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19454">https://arxiv.org/pdf/2504.19454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19454]] Provably Secure Public-Key Steganography Based on Admissible Encoding(https://arxiv.org/abs/2504.19454)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The technique of hiding secret messages within seemingly harmless covertext to evade examination by censors with rigorous security proofs is known as provably secure steganography (PSS). PSS evolves from symmetric key steganography to public-key steganography, functioning without the requirement of a pre-shared key and enabling the extension to multi-party covert communication and identity verification mechanisms. Recently, a public-key steganography method based on elliptic curves was proposed, which uses point compression to eliminate the algebraic structure of curve points. However, this method has strict requirements on the curve parameters and is only available on half of the points. To overcome these limitations, this paper proposes a more general elliptic curve public key steganography method based on admissible encoding. By applying the tensor square function to the known well-distributed encoding, we construct admissible encoding, which can create the pseudo-random public-key encryption function. The theoretical analysis and experimental results show that the proposed provable secure public-key steganography method can be deployed on all types of curves and utilize all points on the curve.</li>
</ul>

<h3>Title: Masked Language Prompting for Generative Data Augmentation in Few-shot Fashion Style Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuki Hirakawa, Ryotaro Shimizu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19455">https://arxiv.org/abs/2504.19455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19455">https://arxiv.org/pdf/2504.19455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19455]] Masked Language Prompting for Generative Data Augmentation in Few-shot Fashion Style Recognition(https://arxiv.org/abs/2504.19455)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Constructing dataset for fashion style recognition is challenging due to the inherent subjectivity and ambiguity of style concepts. Recent advances in text-to-image models have facilitated generative data augmentation by synthesizing images from labeled data, yet existing methods based solely on class names or reference captions often fail to balance visual diversity and style consistency. In this work, we propose \textbf{Masked Language Prompting (MLP)}, a novel prompting strategy that masks selected words in a reference caption and leverages large language models to generate diverse yet semantically coherent completions. This approach preserves the structural semantics of the original caption while introducing attribute-level variations aligned with the intended style, enabling style-consistent and diverse image generation without fine-tuning. Experimental results on the FashionStyle14 dataset demonstrate that our MLP-based augmentation consistently outperforms class-name and caption-based baselines, validating its effectiveness for fashion style recognition under limited supervision.</li>
</ul>

<h3>Title: FCGHunter: Towards Evaluating Robustness of Graph-Based Android Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Shiwen Song, Xiaofei Xie, Ruitao Feng, Qi Guo, Sen Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19456">https://arxiv.org/abs/2504.19456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19456">https://arxiv.org/pdf/2504.19456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19456]] FCGHunter: Towards Evaluating Robustness of Graph-Based Android Malware Detection(https://arxiv.org/abs/2504.19456)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Graph-based detection methods leveraging Function Call Graphs (FCGs) have shown promise for Android malware detection (AMD) due to their semantic insights. However, the deployment of malware detectors in dynamic and hostile environments raises significant concerns about their robustness. While recent approaches evaluate the robustness of FCG-based detectors using adversarial attacks, their effectiveness is constrained by the vast perturbation space, particularly across diverse models and features. To address these challenges, we introduce FCGHunter, a novel robustness testing framework for FCG-based AMD systems. Specifically, FCGHunter employs innovative techniques to enhance exploration and exploitation within this huge search space. Initially, it identifies critical areas within the FCG related to malware behaviors to narrow down the perturbation space. We then develop a dependency-aware crossover and mutation method to enhance the validity and diversity of perturbations, generating diverse FCGs. Furthermore, FCGHunter leverages multi-objective feedback to select perturbed FCGs, significantly improving the search process with interpretation-based feature change feedback. Extensive evaluations across 40 scenarios demonstrate that FCGHunter achieves an average attack success rate of 87.9%, significantly outperforming baselines by at least 44.7%. Notably, FCGHunter achieves a 100% success rate on robust models (e.g., AdaBoost with MalScan), where baselines achieve only 11% or are inapplicable.</li>
</ul>

<h3>Title: Towards Long Context Hallucination Detection</h3>
<ul>
<li><strong>Authors: </strong>Siyi Liu, Kishaloy Halder, Zheng Qi, Wei Xiao, Nikolaos Pappas, Phu Mon Htut, Neha Anna John, Yassine Benajiba, Dan Roth</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19457">https://arxiv.org/abs/2504.19457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19457">https://arxiv.org/pdf/2504.19457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19457]] Towards Long Context Hallucination Detection(https://arxiv.org/abs/2504.19457)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable performance across various tasks. However, they are prone to contextual hallucination, generating information that is either unsubstantiated or contradictory to the given context. Although many studies have investigated contextual hallucinations in LLMs, addressing them in long-context inputs remains an open problem. In this work, we take an initial step toward solving this problem by constructing a dataset specifically designed for long-context hallucination detection. Furthermore, we propose a novel architecture that enables pre-trained encoder models, such as BERT, to process long contexts and effectively detect contextual hallucinations through a decomposition and aggregation mechanism. Our experimental results show that the proposed architecture significantly outperforms previous models of similar size as well as LLM-based models across various metrics, while providing substantially faster inference.</li>
</ul>

<h3>Title: BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text</h3>
<ul>
<li><strong>Authors: </strong>Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19467">https://arxiv.org/abs/2504.19467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19467">https://arxiv.org/pdf/2504.19467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19467]] BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text(https://arxiv.org/abs/2504.19467)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) hold great promise for medical applications and are evolving rapidly, with new models being released at an accelerated pace. However, current evaluations of LLMs in clinical contexts remain limited. Most existing benchmarks rely on medical exam-style questions or PubMed-derived text, failing to capture the complexity of real-world electronic health record (EHR) data. Others focus narrowly on specific application scenarios, limiting their generalizability across broader clinical use. To address this gap, we present BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks sourced from real-world clinical data sources across nine languages. We systematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1, GPT-4o, Gemini, and Llama 4) under various inference strategies. With a total of 13,572 experiments, our results reveal substantial performance variation across model sizes, languages, natural language processing tasks, and clinical specialties. Notably, we demonstrate that open-source LLMs can achieve performance comparable to proprietary models, while medically fine-tuned LLMs based on older architectures often underperform versus updated general-purpose models. The BRIDGE and its corresponding leaderboard serve as a foundational resource and a unique reference for the development and evaluation of new LLMs in real-world clinical text understanding.</li>
</ul>

<h3>Title: Stability Enhancement in Reinforcement Learning via Adaptive Control Lyapunov Function</h3>
<ul>
<li><strong>Authors: </strong>Donghe Chen, Han Wang, Lin Cheng, Shengping Gong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19473">https://arxiv.org/abs/2504.19473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19473">https://arxiv.org/pdf/2504.19473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19473]] Stability Enhancement in Reinforcement Learning via Adaptive Control Lyapunov Function(https://arxiv.org/abs/2504.19473)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) has shown promise in control tasks but faces significant challenges in real-world applications, primarily due to the absence of safety guarantees during the learning process. Existing methods often struggle with ensuring safe exploration, leading to potential system failures and restricting applications primarily to simulated environments. Traditional approaches such as reward shaping and constrained policy optimization can fail to guarantee safety during initial learning stages, while model-based methods using Control Lyapunov Functions (CLFs) or Control Barrier Functions (CBFs) may hinder efficient exploration and performance. To address these limitations, this paper introduces Soft Actor-Critic with Control Lyapunov Function (SAC-CLF), a framework that enhances stability and safety through three key innovations: (1) a task-specific CLF design method for safe and optimal performance; (2) dynamic adjustment of constraints to maintain robustness under unmodeled dynamics; and (3) improved control input smoothness while ensuring safety. Experimental results on a classical nonlinear system and satellite attitude control demonstrate the effectiveness of SAC-CLF in overcoming the shortcomings of existing methods.</li>
</ul>

<h3>Title: Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video</h3>
<ul>
<li><strong>Authors: </strong>Sonia Joseph, Praneet Suresh, Lorenz Hufe, Edward Stevinson, Robert Graham, Yash Vadi, Danilo Bzdok, Sebastian Lapuschkin, Lee Sharkey, Blake Aaron Richards</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19475">https://arxiv.org/abs/2504.19475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19475">https://arxiv.org/pdf/2504.19475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19475]] Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video(https://arxiv.org/abs/2504.19475)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Robust tooling and publicly available pre-trained models have helped drive recent advances in mechanistic interpretability for language models. However, similar progress in vision mechanistic interpretability has been hindered by the lack of accessible frameworks and pre-trained weights. We present Prisma (Access the codebase here: this https URL), an open-source framework designed to accelerate vision mechanistic interpretability research, providing a unified toolkit for accessing 75+ vision and video transformers; support for sparse autoencoder (SAE), transcoder, and crosscoder training; a suite of 80+ pre-trained SAE weights; activation caching, circuit analysis tools, and visualization tools; and educational resources. Our analysis reveals surprising findings, including that effective vision SAEs can exhibit substantially lower sparsity patterns than language SAEs, and that in some instances, SAE reconstructions can decrease model loss. Prisma enables new research directions for understanding vision model internals while lowering barriers to entry in this emerging field.</li>
</ul>

<h3>Title: An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination</h3>
<ul>
<li><strong>Authors: </strong>Dixiao Wei, Peng Yi, Jinlong Lei, Yiguang Hong, Yuchuan Du</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19480">https://arxiv.org/abs/2504.19480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19480">https://arxiv.org/pdf/2504.19480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19480]] An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination(https://arxiv.org/abs/2504.19480)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) has demonstrated excellent decision-making potential in platoon coordination problems. However, due to the variability of coordination goals, the complexity of the decision problem, and the time-consumption of trial-and-error in manual design, finding a well performance reward function to guide RL training to solve complex platoon coordination problems remains challenging. In this paper, we formally define the Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based cooperative platoon coordination problem to incorporate automated reward function generation. To address PCRDP, we propose a Large Language Model (LLM)-based Platoon coordination Reward Design (PCRD) framework, which systematically automates reward function discovery through LLM-driven initialization and iterative optimization. In this method, LLM first initializes reward functions based on environment code and task requirements with an Analysis and Initial Reward (AIR) module, and then iteratively optimizes them based on training feedback with an evolutionary module. The AIR module guides LLM to deepen their understanding of code and tasks through a chain of thought, effectively mitigating hallucination risks in code generation. The evolutionary module fine-tunes and reconstructs the reward function, achieving a balance between exploration diversity and convergence stability for training. To validate our approach, we establish six challenging coordination scenarios with varying complexity levels within the Yangtze River Delta transportation network simulation. Comparative experimental results demonstrate that RL agents utilizing PCRD-generated reward functions consistently outperform human-engineered reward functions, achieving an average of 10\% higher performance metrics in all scenarios.</li>
</ul>

<h3>Title: Improving Reasoning Performance in Large Language Models via Representation Engineering</h3>
<ul>
<li><strong>Authors: </strong>Bertram Højer, Oliver Jarvis, Stefan Heinrich</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19483">https://arxiv.org/abs/2504.19483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19483">https://arxiv.org/pdf/2504.19483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19483]] Improving Reasoning Performance in Large Language Models via Representation Engineering(https://arxiv.org/abs/2504.19483)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have resulted in increasingly anthropomorphic language concerning the ability of LLMs to reason. Whether reasoning in LLMs should be understood to be inherently different is, however, widely debated. We propose utilizing a representation engineering approach wherein model activations are read from the residual stream of an LLM when processing a reasoning task. The activations are used to derive a control vector that is applied to the model as an inference-time intervention, modulating the representational space of the model, to improve performance on the specified task. We publish the code for deriving control vectors and analyzing model representations. The method allows us to improve performance on reasoning benchmarks and assess how control vectors influence the final logit distribution of a model via metrics such as KL divergence and entropy. We apply control vectors to Mistral-7B-Instruct and a range of Pythia models on an inductive, a deductive and mathematical reasoning task. We show that an LLM can, to a certain degree, be controlled to improve its perceived reasoning ability by modulating activations. The intervention is dependent upon the ability to reliably extract the model's typical state when correctly solving a task. Our results suggest that reasoning performance can be modulated in the same manner as other information-processing tasks performed by LLMs and demonstrate that we are capable of improving performance on specific tasks via a simple intervention on the residual stream with no additional training.</li>
</ul>

<h3>Title: The Cost of Performance: Breaking ThreadX with Kernel Object Masquerading Attacks</h3>
<ul>
<li><strong>Authors: </strong>Xinhui Shao, Zhen Ling, Yue Zhang, Huaiyu Yan, Yumeng Wei, Lan Luo, Zixia Liu, Junzhou Luo, Xinwen Fu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19486">https://arxiv.org/abs/2504.19486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19486">https://arxiv.org/pdf/2504.19486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19486]] The Cost of Performance: Breaking ThreadX with Kernel Object Masquerading Attacks(https://arxiv.org/abs/2504.19486)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Microcontroller-based IoT devices often use embedded real-time operating systems (RTOSs). Vulnerabilities in these embedded RTOSs can lead to compromises of those IoT devices. Despite the significance of security protections, the absence of standardized security guidelines results in various levels of security risk across RTOS implementations. Our initial analysis reveals that popular RTOSs such as FreeRTOS lack essential security protections. While Zephyr OS and ThreadX are designed and implemented with essential security protections, our closer examination uncovers significant differences in their implementations of system call parameter sanitization. We identify a performance optimization practice in ThreadX that introduces security vulnerabilities, allowing for the circumvention of parameter sanitization processes. Leveraging this insight, we introduce a novel attack named the Kernel Object Masquerading (KOM) Attack (as the attacker needs to manipulate one or multiple kernel objects through carefully selected system calls to launch the attack), demonstrating how attackers can exploit these vulnerabilities to access sensitive fields within kernel objects, potentially leading to unauthorized data manipulation, privilege escalation, or system compromise. We introduce an automated approach involving under-constrained symbolic execution to identify the KOM attacks and to understand the implications. Experimental results demonstrate the feasibility of KOM attacks on ThreadX-powered platforms. We reported our findings to the vendors, who recognized the vulnerabilities, with Amazon and Microsoft acknowledging our contribution on their websites.</li>
</ul>

<h3>Title: DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction</h3>
<ul>
<li><strong>Authors: </strong>Rudy Morel, Jiequn Han, Edouard Oyallon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19496">https://arxiv.org/abs/2504.19496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19496">https://arxiv.org/pdf/2504.19496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19496]] DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction(https://arxiv.org/abs/2504.19496)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We address the problem of predicting the next state of a dynamical system governed by unknown temporal partial differential equations (PDEs) using only a short trajectory. While standard transformers provide a natural black-box solution to this task, the presence of a well-structured evolution operator in the data suggests a more tailored and efficient approach. Specifically, when the PDE is fully known, classical numerical solvers can evolve the state accurately with only a few parameters. Building on this observation, we introduce DISCO, a model that uses a large hypernetwork to process a short trajectory and generate the parameters of a much smaller operator network, which then predicts the next state through time integration. Our framework decouples dynamics estimation (i.e., DISCovering an evolution operator from a short trajectory) from state prediction (i.e., evolving this operator). Experiments show that pretraining our model on diverse physics datasets achieves state-of-the-art performance while requiring significantly fewer epochs. Moreover, it generalizes well and remains competitive when fine-tuned on downstream tasks.</li>
</ul>

<h3>Title: Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yan Wang, Baoxiong Jia, Ziyu Zhu, Siyuan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19500">https://arxiv.org/abs/2504.19500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19500">https://arxiv.org/pdf/2504.19500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19500]] Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding(https://arxiv.org/abs/2504.19500)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary 3D scene understanding is pivotal for enhancing physical intelligence, as it enables embodied agents to interpret and interact dynamically within real-world environments. This paper introduces MPEC, a novel Masked Point-Entity Contrastive learning method for open-vocabulary 3D semantic segmentation that leverages both 3D entity-language alignment and point-entity consistency across different point cloud views to foster entity-specific feature representations. Our method improves semantic discrimination and enhances the differentiation of unique instances, achieving state-of-the-art results on ScanNet for open-vocabulary 3D semantic segmentation and demonstrating superior zero-shot scene understanding capabilities. Extensive fine-tuning experiments on 8 datasets, spanning from low-level perception to high-level reasoning tasks, showcase the potential of learned 3D features, driving consistent performance gains across varied 3D scene understanding tasks. Project website: this https URL</li>
</ul>

<h3>Title: SynergyAmodal: Deocclude Anything with Text Control</h3>
<ul>
<li><strong>Authors: </strong>Xinyang Li, Chengjie Yi, Jiawei Lai, Mingbao Lin, Yansong Qu, Shengchuan Zhang, Liujuan Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19506">https://arxiv.org/abs/2504.19506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19506">https://arxiv.org/pdf/2504.19506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19506]] SynergyAmodal: Deocclude Anything with Text Control(https://arxiv.org/abs/2504.19506)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Image deocclusion (or amodal completion) aims to recover the invisible regions (\ie, shape and appearance) of occluded instances in images. Despite recent advances, the scarcity of high-quality data that balances diversity, plausibility, and fidelity remains a major obstacle. To address this challenge, we identify three critical elements: leveraging in-the-wild image data for diversity, incorporating human expertise for plausibility, and utilizing generative priors for fidelity. We propose SynergyAmodal, a novel framework for co-synthesizing in-the-wild amodal datasets with comprehensive shape and appearance annotations, which integrates these elements through a tripartite data-human-model collaboration. First, we design an occlusion-grounded self-supervised learning algorithm to harness the diversity of in-the-wild image data, fine-tuning an inpainting diffusion model into a partial completion diffusion model. Second, we establish a co-synthesis pipeline to iteratively filter, refine, select, and annotate the initial deocclusion results of the partial completion diffusion model, ensuring plausibility and fidelity through human expert guidance and prior model constraints. This pipeline generates a high-quality paired amodal dataset with extensive category and scale diversity, comprising approximately 16K pairs. Finally, we train a full completion diffusion model on the synthesized dataset, incorporating text prompts as conditioning signals. Extensive experiments demonstrate the effectiveness of our framework in achieving zero-shot generalization and textual controllability. Our code, dataset, and models will be made publicly available at this https URL.</li>
</ul>

<h3>Title: FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding</h3>
<ul>
<li><strong>Authors: </strong>Rong Gao, Xin Liu, Zhuozhao Hu, Bohao Xing, Baiqiang Xia, Zitong Yu, Heikki Kälviäinen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19514">https://arxiv.org/abs/2504.19514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19514">https://arxiv.org/pdf/2504.19514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19514]] FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding(https://arxiv.org/abs/2504.19514)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Figure skating, known as the "Art on Ice," is among the most artistic sports, challenging to understand due to its blend of technical elements (like jumps and spins) and overall artistic expression. Existing figure skating datasets mainly focus on single tasks, such as action recognition or scoring, lacking comprehensive annotations for both technical and artistic evaluation. Current sports research is largely centered on ball games, with limited relevance to artistic sports like figure skating. To address this, we introduce FSAnno, a large-scale dataset advancing artistic sports understanding through figure skating. FSAnno includes an open-access training and test dataset, alongside a benchmark dataset, FSBench, for fair model evaluation. FSBench consists of FSBench-Text, with multiple-choice questions and explanations, and FSBench-Motion, containing multimodal data and Question and Answer (QA) pairs, supporting tasks from technical analysis to performance commentary. Initial tests on FSBench reveal significant limitations in existing models' understanding of artistic sports. We hope FSBench will become a key tool for evaluating and enhancing model comprehension of figure skating.</li>
</ul>

<h3>Title: Security Steerability is All You Need</h3>
<ul>
<li><strong>Authors: </strong>Itay Hazan, Idan Habler, Ron Bitton, Itsik Mantin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19521">https://arxiv.org/abs/2504.19521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19521">https://arxiv.org/pdf/2504.19521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19521]] Security Steerability is All You Need(https://arxiv.org/abs/2504.19521)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, generative</a></li>
<li><strong>Abstract: </strong>The adoption of Generative AI (GenAI) in various applications inevitably comes with expanding the attack surface, combining new security threats along with the traditional ones. Consequently, numerous research and industrial initiatives aim to mitigate these security threats in GenAI by developing metrics and designing defenses. However, while most of the GenAI security work focuses on universal threats (e.g. manipulating the LLM to generate forbidden content), there is significantly less discussion on application-level security and how to mitigate it. Thus, in this work we adopt an application-centric approach to GenAI security, and show that while LLMs cannot protect against ad-hoc application specific threats, they can provide the framework for applications to protect themselves against such threats. Our first contribution is defining Security Steerability - a novel security measure for LLMs, assessing the model's capability to adhere to strict guardrails that are defined in the system prompt ('Refrain from discussing about politics'). These guardrails, in case effective, can stop threats in the presence of malicious users who attempt to circumvent the application and cause harm to its providers. Our second contribution is a methodology to measure the security steerability of LLMs, utilizing two newly-developed datasets: VeganRibs assesses the LLM behavior in forcing specific guardrails that are not security per se in the presence of malicious user that uses attack boosters (jailbreaks and perturbations), and ReverseText takes this approach further and measures the LLM ability to force specific treatment of the user input as plain text while do user try to give it additional meanings...</li>
</ul>

<h3>Title: LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Peijian Zeng, Feiyan Pang, Zhanbo Wang, Aimin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19524">https://arxiv.org/abs/2504.19524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19524">https://arxiv.org/pdf/2504.19524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19524]] LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning(https://arxiv.org/abs/2504.19524)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Industrial Anomaly Detection (IAD) is critical for ensuring product quality by identifying defects. Traditional methods such as feature embedding and reconstruction-based approaches require large datasets and struggle with scalability. Existing vision-language models (VLMs) and Multimodal Large Language Models (MLLMs) address some limitations but rely on mask annotations, leading to high implementation costs and false positives. Additionally, industrial datasets like MVTec-AD and VisA suffer from severe class imbalance, with defect samples constituting only 23.8% and 11.1% of total data respectively. To address these challenges, we propose a reward function that dynamically prioritizes rare defect patterns during training to handle class imbalance. We also introduce a mask-free reasoning framework using Chain of Thought (CoT) and Group Relative Policy Optimization (GRPO) mechanisms, enabling anomaly detection directly from raw images without annotated masks. This approach generates interpretable step-by-step explanations for defect localization. Our method achieves state-of-the-art performance, outperforming prior approaches by 36% in accuracy on MVTec-AD and 16% on VisA. By eliminating mask dependency and reducing costs while providing explainable outputs, this work advances industrial anomaly detection and supports scalable quality control in manufacturing. Code to reproduce the experiment is available at this https URL.</li>
</ul>

<h3>Title: Adversarial Shallow Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Guobiao Li, Lei Tan, Yuliang Xue, Gaozhi Liu, Zhenxing Qian, Sheng Li, Xinpeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19529">https://arxiv.org/abs/2504.19529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19529">https://arxiv.org/pdf/2504.19529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19529]] Adversarial Shallow Watermarking(https://arxiv.org/abs/2504.19529)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, watermark</a></li>
<li><strong>Abstract: </strong>Recent advances in digital watermarking make use of deep neural networks for message embedding and extraction. They typically follow the ``encoder-noise layer-decoder''-based architecture. By deliberately establishing a differentiable noise layer to simulate the distortion of the watermarked signal, they jointly train the deep encoder and decoder to fit the noise layer to guarantee robustness. As a result, they are usually weak against unknown distortions that are not used in their training pipeline. In this paper, we propose a novel watermarking framework to resist unknown distortions, namely Adversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder that is randomly parameterized and designed to be insensitive to distortions for watermarking extraction. During the watermark embedding, ASW freezes the shallow decoder and adversarially optimizes a host image until its updated version (i.e., the watermarked image) stably triggers the shallow decoder to output the watermark message. During the watermark extraction, it accurately recovers the message from the watermarked image by leveraging the insensitive nature of the shallow decoder against arbitrary distortions. Our ASW is training-free, encoder-free, and noise layer-free. Experiments indicate that the watermarked images created by ASW have strong robustness against various unknown distortions. Compared to the existing ``encoder-noise layer-decoder'' approaches, ASW achieves comparable results on known distortions and better robustness on unknown distortions.</li>
</ul>

<h3>Title: DEEMO: De-identity Multimodal Emotion Recognition and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Deng Li, Bohao Xing, Xin Liu, Baiqiang Xia, Bihan Wen, Heikki Kälviäinen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19549">https://arxiv.org/abs/2504.19549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19549">https://arxiv.org/pdf/2504.19549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19549]] DEEMO: De-identity Multimodal Emotion Recognition and Reasoning(https://arxiv.org/abs/2504.19549)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Emotion understanding is a critical yet challenging task. Most existing approaches rely heavily on identity-sensitive information, such as facial expressions and speech, which raises concerns about personal privacy. To address this, we introduce the De-identity Multimodal Emotion Recognition and Reasoning (DEEMO), a novel task designed to enable emotion understanding using de-identified video and audio inputs. The DEEMO dataset consists of two subsets: DEEMO-NFBL, which includes rich annotations of Non-Facial Body Language (NFBL), and DEEMO-MER, an instruction dataset for Multimodal Emotion Recognition and Reasoning using identity-free cues. This design supports emotion understanding without compromising identity privacy. In addition, we propose DEEMO-LLaMA, a Multimodal Large Language Model (MLLM) that integrates de-identified audio, video, and textual information to enhance both emotion recognition and reasoning. Extensive experiments show that DEEMO-LLaMA achieves state-of-the-art performance on both tasks, outperforming existing MLLMs by a significant margin, achieving 74.49% accuracy and 74.45% F1-score in de-identity emotion recognition, and 6.20 clue overlap and 7.66 label overlap in de-identity emotion reasoning. Our work contributes to ethical AI by advancing privacy-preserving emotion understanding and promoting responsible affective computing.</li>
</ul>

<h3>Title: Detecting Effects of AI-Mediated Communication on Language Complexity and Sentiment</h3>
<ul>
<li><strong>Authors: </strong>Kristen Sussman, Daniel Carter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19556">https://arxiv.org/abs/2504.19556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19556">https://arxiv.org/pdf/2504.19556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19556]] Detecting Effects of AI-Mediated Communication on Language Complexity and Sentiment(https://arxiv.org/abs/2504.19556)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Given the subtle human-like effects of large language models on linguistic patterns, this study examines shifts in language over time to detect the impact of AI-mediated communication (AI- MC) on social media. We compare a replicated dataset of 970,919 tweets from 2020 (pre-ChatGPT) with 20,000 tweets from the same period in 2024, all of which mention Donald Trump during election periods. Using a combination of Flesch-Kincaid readability and polarity scores, we analyze changes in text complexity and sentiment. Our findings reveal a significant increase in mean sentiment polarity (0.12 vs. 0.04) and a shift from predominantly neutral content (54.8% in 2020 to 39.8% in 2024) to more positive expressions (28.6% to 45.9%). These findings suggest not only an increasing presence of AI in social media communication but also its impact on language and emotional expression patterns.</li>
</ul>

<h3>Title: Quantifying Memory Utilization with Effective State-Size</h3>
<ul>
<li><strong>Authors: </strong>Rom N. Parnichkun, Neehal Tumma, Armin W. Thomas, Alessandro Moro, Qi An, Taiji Suzuki, Atsushi Yamashita, Michael Poli, Stefano Massaroli</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19561">https://arxiv.org/abs/2504.19561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19561">https://arxiv.org/pdf/2504.19561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19561]] Quantifying Memory Utilization with Effective State-Size(https://arxiv.org/abs/2504.19561)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The need to develop a general framework for architecture analysis is becoming increasingly important, given the expanding design space of sequence models. To this end, we draw insights from classical signal processing and control theory, to develop a quantitative measure of \textit{memory utilization}: the internal mechanisms through which a model stores past information to produce future outputs. This metric, which we call \textbf{\textit{effective state-size}} (ESS), is tailored to the fundamental class of systems with \textit{input-invariant} and \textit{input-varying linear operators}, encompassing a variety of computational units such as variants of attention, convolutions, and recurrences. Unlike prior work on memory utilization, which either relies on raw operator visualizations (e.g. attention maps), or simply the total \textit{memory capacity} (i.e. cache size) of a model, our metrics provide highly interpretable and actionable measurements. In particular, we show how ESS can be leveraged to improve initialization strategies, inform novel regularizers and advance the performance-efficiency frontier through model distillation. Furthermore, we demonstrate that the effect of context delimiters (such as end-of-speech tokens) on ESS highlights cross-architectural differences in how large language models utilize their available memory to recall information. Overall, we find that ESS provides valuable insights into the dynamics that dictate memory utilization, enabling the design of more efficient and effective sequence models.</li>
</ul>

<h3>Title: m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training</h3>
<ul>
<li><strong>Authors: </strong>Meng Xiao, Xunxin Cai, Chengrui Wang, Yuanchun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19565">https://arxiv.org/abs/2504.19565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19565">https://arxiv.org/pdf/2504.19565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19565]] m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training(https://arxiv.org/abs/2504.19565)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid progress of large language models (LLMs) in biomedical research has underscored the limitations of existing open-source annotated scientific corpora, which are often insufficient in quantity and quality. Addressing the challenge posed by the complex hierarchy of biomedical knowledge, we propose a knowledge-driven, multi-agent framework for scientific corpus distillation tailored for LLM training in the biomedical domain. Central to our approach is a collaborative multi-agent architecture, where specialized agents, each guided by the Medical Subject Headings (MeSH) hierarchy, work in concert to autonomously extract, synthesize, and self-evaluate high-quality textual data from vast scientific literature. These agents collectively generate and refine domain-specific question-answer pairs, ensuring comprehensive coverage and consistency with biomedical ontologies while minimizing manual involvement. Extensive experimental results show that language models trained on our multi-agent distilled datasets achieve notable improvements in biomedical question-answering tasks, outperforming both strong life sciences LLM baselines and advanced proprietary models. Notably, our AI-Ready dataset enables Llama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger scale. Detailed ablation studies and case analyses further validate the effectiveness and synergy of each agent within the framework, highlighting the potential of multi-agent collaboration in biomedical LLM training.</li>
</ul>

<h3>Title: Metadata-private Messaging without Coordination</h3>
<ul>
<li><strong>Authors: </strong>Peipei Jiang, Yihao Wu, Lei Xu, Wentao Dong, Peiyuan Chen, Yulong Ming, Cong Wang, Xiaohua Jia, Qian Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19566">https://arxiv.org/abs/2504.19566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19566">https://arxiv.org/pdf/2504.19566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19566]] Metadata-private Messaging without Coordination(https://arxiv.org/abs/2504.19566)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>For those seeking end-to-end private communication free from pervasive metadata tracking and censorship, the Tor network has been the de-facto choice in practice, despite its susceptibility to traffic analysis attacks. Recently, numerous metadata-private messaging proposals have emerged with the aim to surpass Tor in the messaging context by obscuring the relationships between any two messaging buddies, even against global and active attackers. However, most of these systems face an undesirable usability constraint: they require a metadata-private "dialing" phase to establish mutual agreement and timing or round coordination before initiating any regular chats among users. This phase is not only resource-intensive but also inflexible, limiting users' ability to manage multiple concurrent conversations seamlessly. For stringent privacy requirement, the often-enforced traffic uniformity further exacerbated the limitations of this roadblock. In this paper, we introduce PingPong, a new end-to-end system for metadata-private messaging designed to overcome these limitations. Under the same traffic uniformity requirement, PingPong replaces the rigid "dial-before-converse" paradigm with a more flexible "notify-before-retrieval" workflow. This workflow incorporates a metadata-private notification subsystem, Ping, and a metadata-private message store, Pong. Both Ping and Pong leverage hardware-assisted secure enclaves for performance and operates through a series of customized oblivious algorithms, while meeting the uniformity requirements for metadata protection. By allowing users to switch between conversations on demand, PingPong achieves a level of usability akin to modern instant messaging systems, while also offering improved performance and bandwidth utilization for goodput. We have built a prototype of PingPong with 32 8-core servers equipped with enclaves to validate our claims.</li>
</ul>

<h3>Title: GenPTW: In-Generation Image Watermarking for Provenance Tracing and Tamper Localization</h3>
<ul>
<li><strong>Authors: </strong>Zhenliang Gan, Chunya Liu, Yichao Tang, Binghao Wang, Weiqiang Wang, Xinpeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19567">https://arxiv.org/abs/2504.19567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19567">https://arxiv.org/pdf/2504.19567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19567]] GenPTW: In-Generation Image Watermarking for Provenance Tracing and Tamper Localization(https://arxiv.org/abs/2504.19567)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, watermark, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rapid development of generative image models has brought tremendous opportunities to AI-generated content (AIGC) creation, while also introducing critical challenges in ensuring content authenticity and copyright ownership. Existing image watermarking methods, though partially effective, often rely on post-processing or reference images, and struggle to balance fidelity, robustness, and tamper localization. To address these limitations, we propose GenPTW, an In-Generation image watermarking framework for latent diffusion models (LDMs), which integrates Provenance Tracing and Tamper Localization into a unified Watermark-based design. It embeds structured watermark signals during the image generation phase, enabling unified provenance tracing and tamper localization. For extraction, we construct a frequency-coordinated decoder to improve robustness and localization precision in complex editing scenarios. Additionally, a distortion layer that simulates AIGC editing is introduced to enhance robustness. Extensive experiments demonstrate that GenPTW outperforms existing methods in image fidelity, watermark extraction accuracy, and tamper localization performance, offering an efficient and practical solution for trustworthy AIGC image generation.</li>
</ul>

<h3>Title: DG-DETR: Toward Domain Generalized Detection Transformer</h3>
<ul>
<li><strong>Authors: </strong>Seongmin Hwang, Daeyoung Han, Moongu Jeon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19574">https://arxiv.org/abs/2504.19574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19574">https://arxiv.org/pdf/2504.19574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19574]] DG-DETR: Toward Domain Generalized Detection Transformer(https://arxiv.org/abs/2504.19574)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>End-to-end Transformer-based detectors (DETRs) have demonstrated strong detection performance. However, domain generalization (DG) research has primarily focused on convolutional neural network (CNN)-based detectors, while paying little attention to enhancing the robustness of DETRs. In this letter, we introduce a Domain Generalized DEtection TRansformer (DG-DETR), a simple, effective, and plug-and-play method that improves out-of-distribution (OOD) robustness for DETRs. Specifically, we propose a novel domain-agnostic query selection strategy that removes domain-induced biases from object queries via orthogonal projection onto the instance-specific style space. Additionally, we leverage a wavelet decomposition to disentangle features into domain-invariant and domain-specific components, enabling synthesis of diverse latent styles while preserving the semantic features of objects. Experimental results validate the effectiveness of DG-DETR. Our code is available at this https URL.</li>
</ul>

<h3>Title: Graph-Based Spectral Decomposition for Parameter Coordination in Language Model Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Hanlu Zhang, Yumeng Ma, Shuo Wang, Guiran Liu, Binrong Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19583">https://arxiv.org/abs/2504.19583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19583">https://arxiv.org/pdf/2504.19583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19583]] Graph-Based Spectral Decomposition for Parameter Coordination in Language Model Fine-Tuning(https://arxiv.org/abs/2504.19583)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper proposes a parameter collaborative optimization algorithm for large language models, enhanced with graph spectral analysis. The goal is to improve both fine-tuning efficiency and structural awareness during training. In the proposed method, the parameters of a pre-trained language model are treated as nodes in a graph. A weighted graph is constructed, and Laplacian spectral decomposition is applied to enable frequency-domain modeling and structural representation of the parameter space. Based on this structure, a joint loss function is designed. It combines the task loss with a spectral regularization term to facilitate collaborative updates among parameters. In addition, a spectral filtering mechanism is introduced during the optimization phase. This mechanism adjusts gradients in a structure-aware manner, enhancing the model's training stability and convergence behavior. The method is evaluated on multiple tasks, including traditional fine-tuning comparisons, few-shot generalization tests, and convergence speed analysis. In all settings, the proposed approach demonstrates superior performance. The experimental results confirm that the spectral collaborative optimization framework effectively reduces parameter perturbations and improves fine-tuning quality while preserving overall model performance. This work contributes significantly to the field of artificial intelligence by advancing parameter-efficient training methodologies for large-scale models, reinforcing the importance of structural signal processing in deep learning optimization, and offering a robust, generalizable framework for enhancing language model adaptability and performance.</li>
</ul>

<h3>Title: Magnifier: A Multi-grained Neural Network-based Architecture for Burned Area Delineation</h3>
<ul>
<li><strong>Authors: </strong>Daniele Rege Cambrin, Luca Colomba, Paolo Garza</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19589">https://arxiv.org/abs/2504.19589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19589">https://arxiv.org/pdf/2504.19589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19589]] Magnifier: A Multi-grained Neural Network-based Architecture for Burned Area Delineation(https://arxiv.org/abs/2504.19589)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In crisis management and remote sensing, image segmentation plays a crucial role, enabling tasks like disaster response and emergency planning by analyzing visual data. Neural networks are able to analyze satellite acquisitions and determine which areas were affected by a catastrophic event. The problem in their development in this context is the data scarcity and the lack of extensive benchmark datasets, limiting the capabilities of training large neural network models. In this paper, we propose a novel methodology, namely Magnifier, to improve segmentation performance with limited data availability. The Magnifier methodology is applicable to any existing encoder-decoder architecture, as it extends a model by merging information at different contextual levels through a dual-encoder approach: a local and global encoder. Magnifier analyzes the input data twice using the dual-encoder approach. In particular, the local and global encoders extract information from the same input at different granularities. This allows Magnifier to extract more information than the other approaches given the same set of input images. Magnifier improves the quality of the results of +2.65% on average IoU while leading to a restrained increase in terms of the number of trainable parameters compared to the original model. We evaluated our proposed approach with state-of-the-art burned area segmentation models, demonstrating, on average, comparable or better performances in less than half of the GFLOPs.</li>
</ul>

<h3>Title: Neural network task specialization via domain constraining</h3>
<ul>
<li><strong>Authors: </strong>Roman Malashin, Daniil Ilyukhin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19592">https://arxiv.org/abs/2504.19592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19592">https://arxiv.org/pdf/2504.19592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19592]] Neural network task specialization via domain constraining(https://arxiv.org/abs/2504.19592)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper introduces a concept of neural network specialization via task-specific domain constraining, aimed at enhancing network performance on data subspace in which the network operates. The study presents experiments on training specialists for image classification and object detection tasks. The results demonstrate that specialization can enhance a generalist's accuracy even without additional data or changing training regimes: solely by constraining class label space in which the network performs. Theoretical and experimental analyses indicate that effective specialization requires modifying traditional fine-tuning methods and constraining data space to semantically coherent subsets. The specialist extraction phase before tuning the network is proposed for maximal performance gains. We also provide analysis of the evolution of the feature space during specialization. This study paves way to future research for developing more advanced dynamically configurable image analysis systems, where computations depend on the specific input. Additionally, the proposed methods can help improve system performance in scenarios where certain data domains should be excluded from consideration of the generalist network.</li>
</ul>

<h3>Title: Image Generation Method Based on Heat Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Zhang, Shouqing Jia</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19600">https://arxiv.org/abs/2504.19600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19600">https://arxiv.org/pdf/2504.19600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19600]] Image Generation Method Based on Heat Diffusion Models(https://arxiv.org/abs/2504.19600)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Denoising Diffusion Probabilistic Models (DDPMs) achieve high-quality image generation without adversarial training, but they process images as a whole. Since adjacent pixels are highly likely to belong to the same object, we propose the Heat Diffusion Model (HDM) to further preserve image details and generate more realistic images. HDM is a model that incorporates pixel-level operations while maintaining the same training process as DDPM. In HDM, the discrete form of the two-dimensional heat equation is integrated into the diffusion and generation formulas of DDPM, enabling the model to compute relationships between neighboring pixels during image processing. Our experiments demonstrate that HDM can generate higher-quality samples compared to models such as DDPM, Consistency Diffusion Models (CDM), Latent Diffusion Models (LDM), and Vector Quantized Generative Adversarial Networks (VQGAN).</li>
</ul>

<h3>Title: Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation</h3>
<ul>
<li><strong>Authors: </strong>Kitsuya Azuma, Takayuki Nishio, Yuichi Kitagawa, Wakako Nakano, Takahito Tanimura</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19602">https://arxiv.org/abs/2504.19602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19602">https://arxiv.org/pdf/2504.19602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19602]] Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation(https://arxiv.org/abs/2504.19602)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across decentralized clients, enhancing privacy by keeping data local. Yet conventional FL, relying on frequent parameter-sharing, suffers from high communication overhead and limited model heterogeneity. Distillation-based FL approaches address these issues by sharing predictions (soft-labels) instead, but they often involve redundant transmissions across communication rounds, reducing efficiency. We propose SCARLET, a novel framework integrating synchronized soft-label caching and an enhanced Entropy Reduction Aggregation (Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing cached soft-labels, achieving up to 50% reduction in communication costs compared to existing methods while maintaining accuracy. Enhanced ERA can be tuned to adapt to non-IID data variations, ensuring robust aggregation and performance in diverse client scenarios. Experimental evaluations demonstrate that SCARLET consistently outperforms state-of-the-art distillation-based FL methods in terms of accuracy and communication efficiency. The implementation of SCARLET is publicly available at this https URL.</li>
</ul>

<h3>Title: Coreference Resolution for Vietnamese Narrative Texts</h3>
<ul>
<li><strong>Authors: </strong>Hieu-Dai Tran, Duc-Vu Nguyen, Ngan Luu-Thuy Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19606">https://arxiv.org/abs/2504.19606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19606">https://arxiv.org/pdf/2504.19606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19606]] Coreference Resolution for Vietnamese Narrative Texts(https://arxiv.org/abs/2504.19606)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Coreference resolution is a vital task in natural language processing (NLP) that involves identifying and linking different expressions in a text that refer to the same entity. This task is particularly challenging for Vietnamese, a low-resource language with limited annotated datasets. To address these challenges, we developed a comprehensive annotated dataset using narrative texts from VnExpress, a widely-read Vietnamese online news platform. We established detailed guidelines for annotating entities, focusing on ensuring consistency and accuracy. Additionally, we evaluated the performance of large language models (LLMs), specifically GPT-3.5-Turbo and GPT-4, on this dataset. Our results demonstrate that GPT-4 significantly outperforms GPT-3.5-Turbo in terms of both accuracy and response consistency, making it a more reliable tool for coreference resolution in Vietnamese.</li>
</ul>

<h3>Title: DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Junpeng Jiang, Gangyi Hong, Miao Zhang, Hengtong Hu, Kun Zhan, Rui Shao, Liqiang Nie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19614">https://arxiv.org/abs/2504.19614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19614">https://arxiv.org/pdf/2504.19614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19614]] DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer(https://arxiv.org/abs/2504.19614)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Collecting multi-view driving scenario videos to enhance the performance of 3D visual perception tasks presents significant challenges and incurs substantial costs, making generative models for realistic data an appealing alternative. Yet, the videos generated by recent works suffer from poor quality and spatiotemporal consistency, undermining their utility in advancing perception tasks under driving scenarios. To address this gap, we propose DiVE, a diffusion transformer-based generative framework meticulously engineered to produce high-fidelity, temporally coherent, and cross-view consistent multi-view videos, aligning seamlessly with bird's-eye view layouts and textual descriptions. DiVE leverages a unified cross-attention and a SketchFormer to exert precise control over multimodal data, while incorporating a view-inflated attention mechanism that adds no extra parameters, thereby guaranteeing consistency across views. Despite these advancements, synthesizing high-resolution videos under multimodal constraints introduces dual challenges: investigating the optimal classifier-free guidance coniguration under intricate multi-condition inputs and mitigating excessive computational latency in high-resolution rendering--both of which remain underexplored in prior researches. To resolve these limitations, we introduce two innovations: Multi-Control Auxiliary Branch Distillation, which streamlines multi-condition CFG selection while circumventing high computational overhead, and Resolution Progressive Sampling, a training-free acceleration strategy that staggers resolution scaling to reduce high latency due to high resolution. These innovations collectively achieve a 2.62x speedup with minimal quality degradation. Evaluated on the nuScenes dataset, DiVE achieves SOTA performance in multi-view video generation, yielding photorealistic outputs with exceptional temporal and cross-view coherence.</li>
</ul>

<h3>Title: AI Alignment in Medical Imaging: Unveiling Hidden Biases Through Counterfactual Analysis</h3>
<ul>
<li><strong>Authors: </strong>Haroui Ma, Francesco Quinzan, Theresa Willem, Stefan Bauer</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19621">https://arxiv.org/abs/2504.19621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19621">https://arxiv.org/pdf/2504.19621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19621]] AI Alignment in Medical Imaging: Unveiling Hidden Biases Through Counterfactual Analysis(https://arxiv.org/abs/2504.19621)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, diffusion</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) systems for medical imaging have demonstrated remarkable diagnostic capabilities, but their susceptibility to biases poses significant risks, since biases may negatively impact generalization performance. In this paper, we introduce a novel statistical framework to evaluate the dependency of medical imaging ML models on sensitive attributes, such as demographics. Our method leverages the concept of counterfactual invariance, measuring the extent to which a model's predictions remain unchanged under hypothetical changes to sensitive attributes. We present a practical algorithm that combines conditional latent diffusion models with statistical hypothesis testing to identify and quantify such biases without requiring direct access to counterfactual data. Through experiments on synthetic datasets and large-scale real-world medical imaging datasets, including \textsc{cheXpert} and MIMIC-CXR, we demonstrate that our approach aligns closely with counterfactual fairness principles and outperforms standard baselines. This work provides a robust tool to ensure that ML diagnostic systems generalize well, e.g., across demographic groups, offering a critical step towards AI safety in healthcare. Code: this https URL.</li>
</ul>

<h3>Title: NSegment : Noisy Segment Improves Remote Sensing Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yechan Kim, DongHo Yoon, SooYeon Kim, Moongu Jeon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19634">https://arxiv.org/abs/2504.19634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19634">https://arxiv.org/pdf/2504.19634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19634]] NSegment : Noisy Segment Improves Remote Sensing Image Segmentation(https://arxiv.org/abs/2504.19634)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Labeling errors in remote sensing (RS) image segmentation datasets often remain implicit and subtle due to ambiguous class boundaries, mixed pixels, shadows, complex terrain features, and subjective annotator bias. Furthermore, the scarcity of annotated RS data due to high image acquisition and labeling costs complicates training noise-robust models. While sophisticated mechanisms such as label selection or noise correction might address this issue, they tend to increase training time and add implementation complexity. In this letter, we propose NSegment-a simple yet effective data augmentation solution to mitigate this issue. Unlike traditional methods, it applies elastic transformations only to segmentation labels, varying deformation intensity per sample in each training epoch to address annotation inconsistencies. Experimental results demonstrate that our approach improves the performance of RS image segmentation on various state-of-the-art models.</li>
</ul>

<h3>Title: Exploiting Inter-Sample Correlation and Intra-Sample Redundancy for Partially Relevant Video Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Junlong Ren, Gangjian Zhang, Yu Hu, Jian Shu, Hao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19637">https://arxiv.org/abs/2504.19637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19637">https://arxiv.org/pdf/2504.19637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19637]] Exploiting Inter-Sample Correlation and Intra-Sample Redundancy for Partially Relevant Video Retrieval(https://arxiv.org/abs/2504.19637)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Partially Relevant Video Retrieval (PRVR) aims to retrieve the target video that is partially relevant to the text query. The primary challenge in PRVR arises from the semantic asymmetry between textual and visual modalities, as videos often contain substantial content irrelevant to the query. Existing methods coarsely align paired videos and text queries to construct the semantic space, neglecting the critical cross-modal dual nature inherent in this task: inter-sample correlation and intra-sample redundancy. To this end, we propose a novel PRVR framework to systematically exploit these two characteristics. Our framework consists of three core modules. First, the Inter Correlation Enhancement (ICE) module captures inter-sample correlation by identifying semantically similar yet unpaired text queries and video moments, combining them to form pseudo-positive pairs for more robust semantic space construction. Second, the Intra Redundancy Mining (IRM) module mitigates intra-sample redundancy by mining redundant video moment features and treating them as hard negative samples, thereby encouraging the model to learn more discriminative representations. Finally, to reinforce these modules, we introduce the Temporal Coherence Prediction (TCP) module, which enhances feature discrimination by training the model to predict the original temporal order of randomly shuffled video frames and moments. Extensive experiments on three datasets demonstrate the superiority of our approach compared to previous methods, achieving state-of-the-art results.</li>
</ul>

<h3>Title: A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Youngjoon Lee, Jinu Gong, Joonhyuk Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19639">https://arxiv.org/abs/2504.19639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19639">https://arxiv.org/pdf/2504.19639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19639]] A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging(https://arxiv.org/abs/2504.19639)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables model training across decentralized devices without sharing raw data, thereby preserving privacy in sensitive domains like healthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN) architectures against traditional MLP across six state-of-the-art FL algorithms on a blood cell classification dataset. Notably, our experiments demonstrate that KAN can effectively replace MLP in federated environments, achieving superior performance with simpler architectures. Furthermore, we analyze the impact of key hyperparameters-grid size and network architecture-on KAN performance under varying degrees of Non-IID data distribution. Additionally, our ablation studies reveal that optimizing KAN width while maintaining minimal depth yields the best performance in federated settings. As a result, these findings establish KAN as a promising alternative for privacy-preserving medical imaging applications in distributed healthcare. To the best of our knowledge, this is the first comprehensive benchmark of KAN in FL settings for medical imaging task.</li>
</ul>

<h3>Title: BARIS: Boundary-Aware Refinement with Environmental Degradation Priors for Robust Underwater Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pin-Chi Pan, Soo-Chang Pei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19643">https://arxiv.org/abs/2504.19643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19643">https://arxiv.org/pdf/2504.19643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19643]] BARIS: Boundary-Aware Refinement with Environmental Degradation Priors for Robust Underwater Instance Segmentation(https://arxiv.org/abs/2504.19643)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Underwater instance segmentation is challenging due to adverse visual conditions such as light attenuation, scattering, and color distortion, which degrade model performance. In this work, we propose BARIS-Decoder (Boundary-Aware Refinement Decoder for Instance Segmentation), a framework that enhances segmentation accuracy through feature refinement. To address underwater degradations, we introduce the Environmental Robust Adapter (ERA), which efficiently models underwater degradation patterns while reducing trainable parameters by over 90\% compared to full fine-tuning. The integration of BARIS-Decoder with ERA-tuning, referred to as BARIS-ERA, achieves state-of-the-art performance, surpassing Mask R-CNN by 3.4 mAP with a Swin-B backbone and 3.8 mAP with ConvNeXt V2. Our findings demonstrate the effectiveness of BARIS-ERA in advancing underwater instance segmentation, providing a robust and efficient solution.</li>
</ul>

<h3>Title: xEdgeFace: Efficient Cross-Spectral Face Recognition for Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Anjith George, Sebastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19646">https://arxiv.org/abs/2504.19646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19646">https://arxiv.org/pdf/2504.19646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19646]] xEdgeFace: Efficient Cross-Spectral Face Recognition for Edge Devices(https://arxiv.org/abs/2504.19646)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Heterogeneous Face Recognition (HFR) addresses the challenge of matching face images across different sensing modalities, such as thermal to visible or near-infrared to visible, expanding the applicability of face recognition systems in real-world, unconstrained environments. While recent HFR methods have shown promising results, many rely on computation-intensive architectures, limiting their practicality for deployment on resource-constrained edge devices. In this work, we present a lightweight yet effective HFR framework by adapting a hybrid CNN-Transformer architecture originally designed for face recognition. Our approach enables efficient end-to-end training with minimal paired heterogeneous data while preserving strong performance on standard RGB face recognition tasks. This makes it a compelling solution for both homogeneous and heterogeneous scenarios. Extensive experiments across multiple challenging HFR and face recognition benchmarks demonstrate that our method consistently outperforms state-of-the-art approaches while maintaining a low computational overhead.</li>
</ul>

<h3>Title: Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lei Xu, Shanshan Wang, Emmanuel Casseau, Chenglong Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19649">https://arxiv.org/abs/2504.19649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19649">https://arxiv.org/pdf/2504.19649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19649]] Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models(https://arxiv.org/abs/2504.19649)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>High-level synthesis (HLS) design space exploration (DSE) is an optimization process in electronic design automation (EDA) that systematically explores high-level design configurations to achieve Pareto-optimal hardware implementations balancing performance, area, and power (PPA). To optimize this process, HLS prediction tasks often employ message-passing neural networks (MPNNs), leveraging complex architectures to achieve high accuracy. These predictors serve as evaluators in the DSE process, effectively bypassing the time-consuming estimations traditionally required by HLS tools. However, existing models often prioritize structural complexity and minimization of training loss, overlooking task-specific characteristics. Additionally, while evolutionary algorithms are widely used in DSE, they typically require extensive domain-specific knowledge to design effective crossover and mutation operators. To address these limitations, we propose CoGNNs-LLMEA, a framework that integrates a graph neural network with task-adaptive message passing and a large language model-enhanced evolutionary algorithm. As a predictive model, CoGNNs directly leverages intermediate representations generated from source code after compiler front-end processing, enabling prediction of quality of results (QoR) without invoking HLS tools. Due to its strong adaptability to tasks, CoGNNs can be tuned to predict post-HLS and post-implementation outcomes, effectively bridging the gap between high-level abstractions and physical implementation characteristics. CoGNNs achieves state-of-the-art prediction accuracy in post-HLS QoR prediction, reducing mean prediction errors by 2.8$\times$ for latency and 3.4$\times$ for resource utilization compared to baseline models.</li>
</ul>

<h3>Title: A Tripartite Perspective on GraphRAG</h3>
<ul>
<li><strong>Authors: </strong>Michael Banf, Johannes Kuhn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19667">https://arxiv.org/abs/2504.19667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19667">https://arxiv.org/pdf/2504.19667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19667]] A Tripartite Perspective on GraphRAG(https://arxiv.org/abs/2504.19667)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities across various domains, yet they struggle with knowledge-intensive tasks in areas that demand factual accuracy, e.g. industrial automation and healthcare. Key limitations include their tendency to hallucinate, lack of source traceability (provenance), and challenges in timely knowledge updates. Combining language models with knowledge graphs (GraphRAG) offers promising avenues for overcoming these deficits. However, a major challenge lies in creating such a knowledge graph in the first place. Here, we propose a novel approach that combines LLMs with a tripartite knowledge graph representation, which is constructed by connecting complex, domain-specific objects via a curated ontology of corresponding, domain-specific concepts to relevant sections within chunks of text through a concept-anchored pre-analysis of source documents starting from an initial lexical graph. As a consequence, our Tripartite-GraphRAG approach implements: i) a concept-specific, information-preserving pre-compression of textual chunks; ii) allows for the formation of a concept-specific relevance estimation of embedding similarities grounded in statistics; and iii) avoids common challenges w.r.t. continuous extendability, such as the need for entity resolution and deduplication. By applying a transformation to the knowledge graph, we formulate LLM prompt creation as an unsupervised node classification problem, drawing on ideas from Markov Random Fields. We evaluate our approach on a healthcare use case, involving multi-faceted analyses of patient anamneses given a set of medical concepts as well as clinical literature. Experiments indicate that it can optimize information density, coverage, and arrangement of LLM prompts while reducing their lengths, which may lead to reduced costs and more consistent and reliable LLM outputs.</li>
</ul>

<h3>Title: Multimodal Conditioned Diffusive Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Chen Su, Yuanhe Tian, Yan Song</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19669">https://arxiv.org/abs/2504.19669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19669">https://arxiv.org/pdf/2504.19669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19669]] Multimodal Conditioned Diffusive Time Series Forecasting(https://arxiv.org/abs/2504.19669)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models achieve remarkable success in processing images and text, and have been extended to special domains such as time series forecasting (TSF). Existing diffusion-based approaches for TSF primarily focus on modeling single-modality numerical sequences, overlooking the rich multimodal information in time series data. To effectively leverage such information for prediction, we propose a multimodal conditioned diffusion model for TSF, namely, MCD-TSF, to jointly utilize timestamps and texts as extra guidance for time series modeling, especially for forecasting. Specifically, Timestamps are combined with time series to establish temporal and semantic correlations among different data points when aggregating information along the temporal dimension. Texts serve as supplementary descriptions of time series' history, and adaptively aligned with data points as well as dynamically controlled in a classifier-free manner. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed MCD-TSF model achieves state-of-the-art performance.</li>
</ul>

<h3>Title: $\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Madhur Jindal, Hari Shrawgi, Parag Agrawal, Sandipan Dandapat</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19674">https://arxiv.org/abs/2504.19674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19674">https://arxiv.org/pdf/2504.19674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19674]] $\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation(https://arxiv.org/abs/2504.19674)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Safety evaluation of Large Language Models (LLMs) has made progress and attracted academic interest, but it remains challenging to keep pace with the rapid integration of LLMs across diverse applications. Different applications expose users to various harms, necessitating application-specific safety evaluations with tailored harms and policies. Another major gap is the lack of focus on the dynamic and conversational nature of LLM systems. Such potential oversights can lead to harms that go unnoticed in standard safety benchmarks. This paper identifies the above as key requirements for robust LLM safety evaluation and recognizing that current evaluation methodologies do not satisfy these, we introduce the $\texttt{SAGE}$ (Safety AI Generic Evaluation) framework. $\texttt{SAGE}$ is an automated modular framework designed for customized and dynamic harm evaluations. It utilizes adversarial user models that are system-aware and have unique personalities, enabling a holistic red-teaming evaluation. We demonstrate $\texttt{SAGE}$'s effectiveness by evaluating seven state-of-the-art LLMs across three applications and harm policies. Our experiments with multi-turn conversational evaluations revealed a concerning finding that harm steadily increases with conversation length. Furthermore, we observe significant disparities in model behavior when exposed to different user personalities and scenarios. Our findings also reveal that some models minimize harmful outputs by employing severe refusal tactics that can hinder their usefulness. These insights highlight the necessity of adaptive and context-specific testing to ensure better safety alignment and safer deployment of LLMs in real-world scenarios.</li>
</ul>

<h3>Title: Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs</h3>
<ul>
<li><strong>Authors: </strong>Osma Suominen, Juho Inkinen, Mona Lehtinen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19675">https://arxiv.org/abs/2504.19675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19675">https://arxiv.org/pdf/2504.19675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19675]] Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs(https://arxiv.org/abs/2504.19675)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects), which focussed on subject indexing using large language models (LLMs). The task required creating subject predictions for bibliographic records from the bilingual TIBKAT database using the GND subject vocabulary. Our approach combines traditional natural language processing and machine learning techniques implemented in the Annif toolkit with innovative LLM-based methods for translation and synthetic data generation, and merging predictions from monolingual models. The system ranked first in the all-subjects category and second in the tib-core-subjects category in the quantitative evaluation, and fourth in qualitative evaluations. These findings demonstrate the potential of combining traditional XMTC algorithms with modern LLM techniques to improve the accuracy and efficiency of subject indexing in multilingual contexts.</li>
</ul>

<h3>Title: Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Nikolaos Chaidos, Angeliki Dimitriou, Nikolaos Spanos, Athanasios Voulodimos, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19682">https://arxiv.org/abs/2504.19682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19682">https://arxiv.org/pdf/2504.19682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19682]] Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification(https://arxiv.org/abs/2504.19682)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have emerged as an efficient alternative to convolutional approaches for vision tasks such as image classification, leveraging patch-based representations instead of raw pixels. These methods construct graphs where image patches serve as nodes, and edges are established based on patch similarity or classification relevance. Despite their efficiency, the explainability of GNN-based vision models remains underexplored, even though graphs are naturally interpretable. In this work, we analyze the semantic consistency of the graphs formed at different layers of GNN-based image classifiers, focusing on how well they preserve object structures and meaningful relationships. A comprehensive analysis is presented by quantifying the extent to which inter-layer graph connections reflect semantic similarity and spatial coherence. Explanations from standard and adversarial settings are also compared to assess whether they reflect the classifiers' robustness. Additionally, we visualize the flow of information across layers through heatmap-based visualization techniques, thereby highlighting the models' explainability. Our findings demonstrate that the decision-making processes of these models can be effectively explained, while also revealing that their reasoning does not necessarily align with human perception, especially in deeper layers.</li>
</ul>

<h3>Title: ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery</h3>
<ul>
<li><strong>Authors: </strong>Anush Lakshman Sivaraman, Kojo Adu-Gyamfi, Ibne Farabi Shihab, Anuj Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19684">https://arxiv.org/abs/2504.19684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19684">https://arxiv.org/pdf/2504.19684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19684]] ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery(https://arxiv.org/abs/2504.19684)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, generative</a></li>
<li><strong>Abstract: </strong>Accurate weather classification from low-quality traffic camera imagery remains a challenging task, particularly under adverse nighttime conditions. In this study, we propose a scalable framework that combines generative domain adaptation with efficient contrastive learning to enhance classification performance. Using CycleGAN-based domain translation, we improve the quality of nighttime images, enabling better feature extraction by downstream models. While the baseline EVA-02 model employing CLIP-based contrastive loss achieves an overall accuracy of 96.55\%, it exhibits a significant performance gap between daytime (97.21\%) and nighttime conditions (63.40\%). Replacing CLIP with the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitive overall accuracy of 94.00\%, with substantial improvements in nighttime performance (85.90\% accuracy). The combination of Vision-SigLIP-2, Text-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttime accuracy (85.90\%) among all models tested, while EVA-02 with CycleGAN maintains the highest overall accuracy (97.01\%) and per-class accuracies. These findings demonstrate the potential of combining domain adaptation and efficient contrastive learning to build practical, resource-efficient weather classification systems for intelligent transportation infrastructure.</li>
</ul>

<h3>Title: SubGrapher: Visual Fingerprinting of Chemical Structures</h3>
<ul>
<li><strong>Authors: </strong>Lucas Morin, Gerhard Ingmar Meijer, Valéry Weber, Luc Van Gool, Peter W. J. Staar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19695">https://arxiv.org/abs/2504.19695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19695">https://arxiv.org/pdf/2504.19695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19695]] SubGrapher: Visual Fingerprinting of Chemical Structures(https://arxiv.org/abs/2504.19695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Automatic extraction of chemical structures from scientific literature plays a crucial role in accelerating research across fields ranging from drug discovery to materials science. Patent documents, in particular, contain molecular information in visual form, which is often inaccessible through traditional text-based searches. In this work, we introduce SubGrapher, a method for the visual fingerprinting of chemical structure images. Unlike conventional Optical Chemical Structure Recognition (OCSR) models that attempt to reconstruct full molecular graphs, SubGrapher focuses on extracting molecular fingerprints directly from chemical structure images. Using learning-based instance segmentation, SubGrapher identifies functional groups and carbon backbones, constructing a substructure-based fingerprint that enables chemical structure retrieval. Our approach is evaluated against state-of-the-art OCSR and fingerprinting methods, demonstrating superior retrieval performance and robustness across diverse molecular depictions. The dataset, models, and code will be made publicly available.</li>
</ul>

<h3>Title: Open-set Anomaly Segmentation in Complex Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Song Xia, Yi Yu, Henghui Ding, Wenhan Yang, Shifei Liu, Alex C. Kot, Xudong Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19706">https://arxiv.org/abs/2504.19706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19706">https://arxiv.org/pdf/2504.19706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19706]] Open-set Anomaly Segmentation in Complex Scenarios(https://arxiv.org/abs/2504.19706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Precise segmentation of out-of-distribution (OoD) objects, herein referred to as anomalies, is crucial for the reliable deployment of semantic segmentation models in open-set, safety-critical applications, such as autonomous driving. Current anomalous segmentation benchmarks predominantly focus on favorable weather conditions, resulting in untrustworthy evaluations that overlook the risks posed by diverse meteorological conditions in open-set environments, such as low illumination, dense fog, and heavy rain. To bridge this gap, this paper introduces the ComsAmy, a challenging benchmark specifically designed for open-set anomaly segmentation in complex scenarios. ComsAmy encompasses a wide spectrum of adverse weather conditions, dynamic driving environments, and diverse anomaly types to comprehensively evaluate the model performance in realistic open-world scenarios. Our extensive evaluation of several state-of-the-art anomalous segmentation models reveals that existing methods demonstrate significant deficiencies in such challenging scenarios, highlighting their serious safety risks for real-world deployment. To solve that, we propose a novel energy-entropy learning (EEL) strategy that integrates the complementary information from energy and entropy to bolster the robustness of anomaly segmentation under complex open-world environments. Additionally, a diffusion-based anomalous training data synthesizer is proposed to generate diverse and high-quality anomalous images to enhance the existing copy-paste training data synthesizer. Extensive experimental results on both public and ComsAmy benchmarks demonstrate that our proposed diffusion-based synthesizer with energy and entropy learning (DiffEEL) serves as an effective and generalizable plug-and-play method to enhance existing models, yielding an average improvement of around 4.96% in $\rm{AUPRC}$ and 9.87% in $\rm{FPR}_{95}$.</li>
</ul>

<h3>Title: Taming the Titans: A Survey of Efficient LLM Inference Serving</h3>
<ul>
<li><strong>Authors: </strong>Ranran Zhen, Juntao Li, Yixin Ji, Zhenlin Yang, Tong Liu, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19720">https://arxiv.org/abs/2504.19720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19720">https://arxiv.org/pdf/2504.19720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19720]] Taming the Titans: A Survey of Efficient LLM Inference Serving(https://arxiv.org/abs/2504.19720)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) for Generative AI have achieved remarkable progress, evolving into sophisticated and versatile tools widely adopted across various domains and applications. However, the substantial memory overhead caused by their vast number of parameters, combined with the high computational demands of the attention mechanism, poses significant challenges in achieving low latency and high throughput for LLM inference services. Recent advancements, driven by groundbreaking research, have significantly accelerated progress in this field. This paper provides a comprehensive survey of these methods, covering fundamental instance-level approaches, in-depth cluster-level strategies, emerging scenario directions, and other miscellaneous but important areas. At the instance level, we review model placement, request scheduling, decoding length prediction, storage management, and the disaggregation paradigm. At the cluster level, we explore GPU cluster deployment, multi-instance load balancing, and cloud service solutions. For emerging scenarios, we organize the discussion around specific tasks, modules, and auxiliary methods. To ensure a holistic overview, we also highlight several niche yet critical areas. Finally, we outline potential research directions to further advance the field of LLM inference serving.</li>
</ul>

<h3>Title: The ATLAS of Traffic Lights: A Reliable Perception Framework for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Rupert Polley, Nikolai Polley, Dominik Heid, Marc Heinrich, Sven Ochs, J. Marius Zöllner</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19722">https://arxiv.org/abs/2504.19722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19722">https://arxiv.org/pdf/2504.19722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19722]] The ATLAS of Traffic Lights: A Reliable Perception Framework for Autonomous Driving(https://arxiv.org/abs/2504.19722)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traffic light perception is an essential component of the camera-based perception system for autonomous vehicles, enabling accurate detection and interpretation of traffic lights to ensure safe navigation through complex urban environments. In this work, we propose a modularized perception framework that integrates state-of-the-art detection models with a novel real-time association and decision framework, enabling seamless deployment into an autonomous driving stack. To address the limitations of existing public datasets, we introduce the ATLAS dataset, which provides comprehensive annotations of traffic light states and pictograms across diverse environmental conditions and camera setups. This dataset is publicly available at this https URL. We train and evaluate several state-of-the-art traffic light detection architectures on ATLAS, demonstrating significant performance improvements in both accuracy and robustness. Finally, we evaluate the framework in real-world scenarios by deploying it in an autonomous vehicle to make decisions at traffic light-controlled intersections, highlighting its reliability and effectiveness for real-time operation.</li>
</ul>

<h3>Title: RepText: Rendering Visual Text via Replicating</h3>
<ul>
<li><strong>Authors: </strong>Haofan Wang, Yujia Xu, Yimeng Li, Junchen Li, Chaowei Zhang, Jing Wang, Kejia Yang, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19724">https://arxiv.org/abs/2504.19724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19724">https://arxiv.org/pdf/2504.19724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19724]] RepText: Rendering Visual Text via Replicating(https://arxiv.org/abs/2504.19724)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Although contemporary text-to-image generation models have achieved remarkable breakthroughs in producing visually appealing images, their capacity to generate precise and flexible typographic elements, especially non-Latin alphabets, remains constrained. To address these limitations, we start from an naive assumption that text understanding is only a sufficient condition for text rendering, but not a necessary condition. Based on this, we present RepText, which aims to empower pre-trained monolingual text-to-image generation models with the ability to accurately render, or more precisely, replicate, multilingual visual text in user-specified fonts, without the need to really understand them. Specifically, we adopt the setting from ControlNet and additionally integrate language agnostic glyph and position of rendered text to enable generating harmonized visual text, allowing users to customize text content, font and position on their needs. To improve accuracy, a text perceptual loss is employed along with the diffusion loss. Furthermore, to stabilize rendering process, at the inference phase, we directly initialize with noisy glyph latent instead of random initialization, and adopt region masks to restrict the feature injection to only the text region to avoid distortion of the background. We conducted extensive experiments to verify the effectiveness of our RepText relative to existing works, our approach outperforms existing open-source methods and achieves comparable results to native multi-language closed-source models. To be more fair, we also exhaustively discuss its limitations in the end.</li>
</ul>

<h3>Title: LLM-Assisted Automated Deductive Coding of Dialogue Data: Leveraging Dialogue-Specific Characteristics to Enhance Contextual Understanding</h3>
<ul>
<li><strong>Authors: </strong>Ying Na, Shihui Feng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19734">https://arxiv.org/abs/2504.19734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19734">https://arxiv.org/pdf/2504.19734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19734]] LLM-Assisted Automated Deductive Coding of Dialogue Data: Leveraging Dialogue-Specific Characteristics to Enhance Contextual Understanding(https://arxiv.org/abs/2504.19734)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dialogue data has been a key source for understanding learning processes, offering critical insights into how students engage in collaborative discussions and how these interactions shape their knowledge construction. The advent of Large Language Models (LLMs) has introduced promising opportunities for advancing qualitative research, particularly in the automated coding of dialogue data. However, the inherent contextual complexity of dialogue presents unique challenges for these models, especially in understanding and interpreting complex contextual information. This study addresses these challenges by developing a novel LLM-assisted automated coding approach for dialogue data. The novelty of our proposed framework is threefold: 1) We predict the code for an utterance based on dialogue-specific characteristics -- communicative acts and communicative events -- using separate prompts following the role prompts and chain-of-thoughts methods; 2) We engaged multiple LLMs including GPT-4-turbo, GPT-4o, DeepSeek in collaborative code prediction; 3) We leveraged the interrelation between events and acts to implement consistency checking using GPT-4o. In particular, our contextual consistency checking provided a substantial accuracy improvement. We also found the accuracy of act predictions was consistently higher than that of event predictions. This study contributes a new methodological framework for enhancing the precision of automated coding of dialogue data as well as offers a scalable solution for addressing the contextual challenges inherent in dialogue analysis.</li>
</ul>

<h3>Title: Measuring Train Driver Performance as Key to Approval of Driverless Trains</h3>
<ul>
<li><strong>Authors: </strong>Rustam Tagiew (1), Prasannavenkatesh Balaji (1) ((1) German Centre for Rail Traffic Research at the Federal Railway Authority)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19735">https://arxiv.org/abs/2504.19735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19735">https://arxiv.org/pdf/2504.19735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19735]] Measuring Train Driver Performance as Key to Approval of Driverless Trains(https://arxiv.org/abs/2504.19735)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Points 2.1.4(b), 2.4.2(b) and 2.4.3(b) in Annex I of Implementing Regulation (EU) No. 402/2013 allow a simplified approach for the safety approval of computer vision systems for driverless trains, if they have 'similar' functions and interfaces as the replaced human driver. The human driver is not replaced one-to-one by a technical system - only a limited set of cognitive functions are replaced. However, performance in the most challenging function, obstacle detection, is difficult to quantify due to the deficiency of published measurement results. This article summarizes the data published so far. This article also goes a long way to remedy this situation by providing a new public and anonymized dataset of 711 train driver performance measurements from controlled experiments. The measurements are made for different speeds, obstacle sizes, train protection systems and obstacle color contrasts respectively. The measured values are reaction time and distance to the obstacle. The goal of this paper is an unbiased and exhaustive description of the presented dataset for research, standardization and regulation. Further project related information including the dataset and source code is available at this https URL</li>
</ul>

<h3>Title: Graph Fourier Transformer with Structure-Frequency Information</h3>
<ul>
<li><strong>Authors: </strong>Yonghui Zhai, Yang Zhang, Minghao Shang, Lihua Pang, Yaxin Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19740">https://arxiv.org/abs/2504.19740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19740">https://arxiv.org/pdf/2504.19740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19740]] Graph Fourier Transformer with Structure-Frequency Information(https://arxiv.org/abs/2504.19740)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph Transformers (GTs) have shown advantages in numerous graph structure tasks but their self-attention mechanism ignores the generalization bias of graphs, with existing methods mainly compensating for this bias from aspects like position encoding, attention bias and relative distance yet still having sub-optimal performance and being insufficient by only considering the structural perspective of generalization bias. To address this, this paper proposes Grafourierformer, which innovatively combines GT with inductive bias containing Frequency-Structure information by applying Graph Fourier Transform to the Attention Matrix: specifically, eigenvalues from the Graph Laplacian matrix are used to construct an Eigenvalue matrix mask (reflecting node positions and structural relationships with neighboring nodes to enable consideration of node range structural characteristics and focus on local graph details), and inverse Fourier transform is employed to extract node high-frequency and low-frequency features, calculate low-frequency and high-frequency energy, and construct a node frequency-energy matrix to filter the eigenvalue matrix mask, allowing attention heads to incorporate both graph structural information and node frequency information optimization, adaptively distinguish global trends from local details, and effectively suppress redundant information interference. Extensive experiments on various benchmarks show Grafourierformer consistently outperforms GNN and GT-based models in graph classification and node classification tasks, with ablation experiments further validating the effectiveness and necessity of the method. Codes are available at this https URL</li>
</ul>

<h3>Title: FineQ: Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xilong Xie, Liang Wang, Limin Xiao, Meng Han, Lin Sun, Shuai Zheng, Xiangrong Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19746">https://arxiv.org/abs/2504.19746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19746">https://arxiv.org/pdf/2504.19746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19746]] FineQ: Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs(https://arxiv.org/abs/2504.19746)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have significantly advanced the natural language processing paradigm but impose substantial demands on memory and computational resources. Quantization is one of the most effective ways to reduce memory consumption of LLMs. However, advanced single-precision quantization methods experience significant accuracy degradation when quantizing to ultra-low bits. Existing mixed-precision quantization methods are quantized by groups with coarse granularity. Employing high precision for group data leads to substantial memory overhead, whereas low precision severely impacts model accuracy. To address this issue, we propose FineQ, software-hardware co-design for low-bit fine-grained mixed-precision quantization of LLMs. First, FineQ partitions the weights into finer-grained clusters and considers the distribution of outliers within these clusters, thus achieving a balance between model accuracy and memory overhead. Then, we propose an outlier protection mechanism within clusters that uses 3 bits to represent outliers and introduce an encoding scheme for index and data concatenation to enable aligned memory access. Finally, we introduce an accelerator utilizing temporal coding that effectively supports the quantization algorithm while simplifying the multipliers in the systolic array. FineQ achieves higher model accuracy compared to the SOTA mixed-precision quantization algorithm at a close average bit-width. Meanwhile, the accelerator achieves up to 1.79x energy efficiency and reduces the area of the systolic array by 61.2%.</li>
</ul>

<h3>Title: Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Huichi Zhou, Zehao Xu, Munan Zhao, Kaihong Li, Yiqiang Li, Hongtao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19759">https://arxiv.org/abs/2504.19759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19759">https://arxiv.org/pdf/2504.19759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19759]] Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs(https://arxiv.org/abs/2504.19759)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the Multilingual Moral Reasoning Benchmark (MMRB) to evaluate the moral reasoning abilities of large language models (LLMs) across five typologically diverse languages and three levels of contextual complexity: sentence, paragraph, and document. Our results show moral reasoning performance degrades with increasing context complexity, particularly for low-resource languages such as Vietnamese. We further fine-tune the open-source LLaMA-3-8B model using curated monolingual data for alignment and poisoning. Surprisingly, low-resource languages have a stronger impact on multilingual reasoning than high-resource ones, highlighting their critical role in multilingual NLP.</li>
</ul>

<h3>Title: If Concept Bottlenecks are the Question, are Foundation Models the Answer?</h3>
<ul>
<li><strong>Authors: </strong>Nicola Debole, Pietro Barbiero, Francesco Giannini, Andrea Passeggini, Stefano Teso, Emanuele Marconato</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19774">https://arxiv.org/abs/2504.19774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19774">https://arxiv.org/pdf/2504.19774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19774]] If Concept Bottlenecks are the Question, are Foundation Models the Answer?(https://arxiv.org/abs/2504.19774)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high performance with ante-hoc interpretability. CBMs work by first mapping inputs (e.g., images) to high-level concepts (e.g., visible objects and their properties) and then use these to solve a downstream task (e.g., tagging or scoring an image) in an interpretable manner. Their performance and interpretability, however, hinge on the quality of the concepts they learn. The go-to strategy for ensuring good quality concepts is to leverage expert annotations, which are expensive to collect and seldom available in applications. Researchers have recently addressed this issue by introducing "VLM-CBM" architectures that replace manual annotations with weak supervision from foundation models. It is however unclear what is the impact of doing so on the quality of the learned concepts. To answer this question, we put state-of-the-art VLM-CBMs to the test, analyzing their learned concepts empirically using a selection of significant metrics. Our results show that, depending on the task, VLM supervision can sensibly differ from expert annotations, and that concept accuracy and quality are not strongly correlated. Our code is available at this https URL.</li>
</ul>

<h3>Title: Learning Brenier Potentials with Convex Generative Adversarial Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Claudia Drygala, Hanno Gottschalk, Thomas Kruse, Ségolène Martin, Annika Mütze</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19779">https://arxiv.org/abs/2504.19779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19779">https://arxiv.org/pdf/2504.19779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19779]] Learning Brenier Potentials with Convex Generative Adversarial Neural Networks(https://arxiv.org/abs/2504.19779)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Brenier proved that under certain conditions on a source and a target probability measure there exists a strictly convex function such that its gradient is a transport map from the source to the target distribution. This function is called the Brenier potential. Furthermore, detailed information on the Hölder regularity of the Brenier potential is available. In this work we develop the statistical learning theory of generative adversarial neural networks that learn the Brenier potential. As by the transformation of densities formula, the density of the generated measure depends on the second derivative of the Brenier potential, we develop the universal approximation theory of ReCU networks with cubic activation $\mathtt{ReCU}(x)=\max\{0,x\}^3$ that combines the favorable approximation properties of Hölder functions with a Lipschitz continuous density. In order to assure the convexity of such general networks, we introduce an adversarial training procedure for a potential function represented by the ReCU networks that combines the classical discriminator cross entropy loss with a penalty term that enforces (strict) convexity. We give a detailed decomposition of learning errors and show that for a suitable high penalty parameter all networks chosen in the adversarial min-max optimization problem are strictly convex. This is further exploited to prove the consistency of the learning procedure for (slowly) expanding network capacity. We also implement the described learning algorithm and apply it to a number of standard test cases from Gaussian mixture to image data as target distributions. As predicted in theory, we observe that the convexity loss becomes inactive during the training process and the potentials represented by the neural networks have learned convexity.</li>
</ul>

<h3>Title: Heterophily-informed Message Passing</h3>
<ul>
<li><strong>Authors: </strong>Haishan Wang, Arno Solin, Vikas Garg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19785">https://arxiv.org/abs/2504.19785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19785">https://arxiv.org/pdf/2504.19785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19785]] Heterophily-informed Message Passing(https://arxiv.org/abs/2504.19785)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due to their implicit homophily assumption. We mitigate this problem with a novel scheme that regulates the aggregation of messages, modulating the type and extent of message passing locally thereby preserving both the low and high-frequency components of information. Our approach relies solely on learnt embeddings, obviating the need for auxiliary labels, thus extending the benefits of heterophily-aware embeddings to broader applications, e.g., generative modelling. Our experiments, conducted across various data sets and GNN architectures, demonstrate performance enhancements and reveal heterophily patterns across standard classification benchmarks. Furthermore, application to molecular generation showcases notable performance improvements on chemoinformatics benchmarks.</li>
</ul>

<h3>Title: Contextures: The Mechanism of Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Runtian Zhai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19792">https://arxiv.org/abs/2504.19792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19792">https://arxiv.org/pdf/2504.19792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19792]] Contextures: The Mechanism of Representation Learning(https://arxiv.org/abs/2504.19792)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This dissertation establishes the contexture theory to mathematically characterize the mechanism of representation learning, or pretraining. Despite the remarkable empirical success of foundation models, it is not very clear what representations they learn, and why these representations are useful for various downstream tasks. A scientific understanding of representation learning is critical, especially at this point when scaling up the model size is producing diminishing returns, and designing new pretraining methods is imperative for further progress. Prior work treated different representation learning methods quite differently, whereas the contexture theory provides a unified framework for analyzing these methods. The central argument is that a representation is learned from the association between the input X and a context variable A. We prove that if an encoder captures the maximum information of this association, in which case we say that the encoder learns the contexture, then it will be optimal on the class of tasks that are compatible with the context. We also show that a context is the most useful when the association between X and A is neither too strong nor too weak. The important implication of the contexture theory is that increasing the model size alone will achieve diminishing returns, and further advancements require better contexts. We demonstrate that many pretraining objectives can learn the contexture, including supervised learning, self-supervised learning, generative models, etc. Then, we introduce two general objectives -- SVME and KISE, for learning the contexture. We also show how to mix multiple contexts together, an effortless way to create better contexts from existing ones. Then, we prove statistical learning bounds for representation learning. Finally, we discuss the effect of the data distribution shift from pretraining to the downstream task.</li>
</ul>

<h3>Title: Prompt Injection Attack to Tool Selection in LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Shi, Zenghui Yuan, Guiyao Tie, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19793">https://arxiv.org/abs/2504.19793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19793">https://arxiv.org/pdf/2504.19793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19793]] Prompt Injection Attack to Tool Selection in LLM Agents(https://arxiv.org/abs/2504.19793)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Tool selection is a key component of LLM agents. The process operates through a two-step mechanism - \emph{retrieval} and \emph{selection} - to pick the most appropriate tool from a tool library for a given task. In this work, we introduce \textit{ToolHijacker}, a novel prompt injection attack targeting tool selection in no-box scenarios. ToolHijacker injects a malicious tool document into the tool library to manipulate the LLM agent's tool selection process, compelling it to consistently choose the attacker's malicious tool for an attacker-chosen target task. Specifically, we formulate the crafting of such tool documents as an optimization problem and propose a two-phase optimization strategy to solve it. Our extensive experimental evaluation shows that ToolHijacker is highly effective, significantly outperforming existing manual-based and automated prompt injection attacks when applied to tool selection. Moreover, we explore various defenses, including prevention-based defenses (StruQ and SecAlign) and detection-based defenses (known-answer detection, perplexity detection, and perplexity windowed detection). Our experimental results indicate that these defenses are insufficient, highlighting the urgent need for developing new defense strategies.</li>
</ul>

<h3>Title: Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance</h3>
<ul>
<li><strong>Authors: </strong>Takuya Tamura, Taro Yano, Masafumi Enomoto, Masafumi Oyamada</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19811">https://arxiv.org/abs/2504.19811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19811">https://arxiv.org/pdf/2504.19811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19811]] Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance(https://arxiv.org/abs/2504.19811)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurately forecasting the performance of Large Language Models (LLMs) before extensive fine-tuning or merging can substantially reduce both computational expense and development time. Although prior approaches like scaling laws account for global factors such as parameter size or training tokens, they often overlook explicit lineage relationships - i.e., which models are derived or merged from which parents. In this work, we propose a novel Lineage-Regularized Matrix Factorization (LRMF) framework that encodes ancestral ties among LLMs via a graph Laplacian regularizer. By leveraging multi-hop parent-child connections, LRMF consistently outperforms conventional matrix factorization and collaborative filtering methods in both instance-level and benchmark-level performance prediction. Our large-scale study includes 2,934 publicly available Hugging Face models and 21,000+ instances across 6 major benchmarks, showing that lineage constraints yield up to 7-10 percentage points higher correlation with actual performance compared to baselines. Moreover, LRMF effectively addresses the cold-start problem, providing accurate estimates for newly derived or merged models even with minimal data. This lineage-guided strategy thus offers a resource-efficient way to inform hyperparameter tuning, data selection, and model combination in modern LLM development.</li>
</ul>

<h3>Title: Hierarchical Uncertainty-Aware Graph Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Yoonhyuk Choi, Chong-Kwon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19820">https://arxiv.org/abs/2504.19820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19820">https://arxiv.org/pdf/2504.19820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19820]] Hierarchical Uncertainty-Aware Graph Neural Network(https://arxiv.org/abs/2504.19820)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Recent research on graph neural networks (GNNs) has explored mechanisms for capturing local uncertainty and exploiting graph hierarchies to mitigate data sparsity and leverage structural properties. However, the synergistic integration of these two approaches remains underexplored. In this work, we introduce a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network (HU-GNN), which unifies multi-scale representation learning, principled uncertainty estimation, and self-supervised embedding diversity within a single end-to-end framework. Specifically, HU-GNN adaptively forms node clusters and estimates uncertainty at multiple structural scales from individual nodes to higher levels. These uncertainty estimates guide a robust message-passing mechanism and attention weighting, effectively mitigating noise and adversarial perturbations while preserving predictive accuracy on both node- and graph-level tasks. We also offer key theoretical contributions, including a probabilistic formulation, rigorous uncertainty-calibration guarantees, and formal robustness bounds. Finally, by incorporating recent advances in graph contrastive learning, HU-GNN maintains diverse, structurally faithful embeddings. Extensive experiments on standard benchmarks demonstrate that our model achieves state-of-the-art robustness and interpretability.</li>
</ul>

<h3>Title: SILENT: A New Lens on Statistics in Software Timing Side Channels</h3>
<ul>
<li><strong>Authors: </strong>Martin Dunsche, Patrick Bastian, Marcel Maehren, Nurullah Erinola, Robert Merget, Nicolai Bissantz, Holger Dette, Jörg Schwenk</a></li>
<li><strong>Subjects: </strong>cs.CR, stat.AP, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19821">https://arxiv.org/abs/2504.19821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19821">https://arxiv.org/pdf/2504.19821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19821]] SILENT: A New Lens on Statistics in Software Timing Side Channels(https://arxiv.org/abs/2504.19821)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Cryptographic research takes software timing side channels seriously. Approaches to mitigate them include constant-time coding and techniques to enforce such practices. However, recent attacks like Meltdown [42], Spectre [37], and Hertzbleed [70] have challenged our understanding of what it means for code to execute in constant time on modern CPUs. To ensure that assumptions on the underlying hardware are correct and to create a complete feedback loop, developers should also perform \emph{timing measurements} as a final validation step to ensure the absence of exploitable side channels. Unfortunately, as highlighted by a recent study by Jancar et al. [30], developers often avoid measurements due to the perceived unreliability of the statistical analysis and its guarantees. In this work, we combat the view that statistical techniques only provide weak guarantees by introducing a new algorithm for the analysis of timing measurements with strong, formal statistical guarantees, giving developers a reliable analysis tool. Specifically, our algorithm (1) is non-parametric, making minimal assumptions about the underlying distribution and thus overcoming limitations of classical tests like the t-test, (2) handles unknown data dependencies in measurements, (3) can estimate in advance how many samples are needed to detect a leak of a given size, and (4) allows the definition of a negligible leak threshold $\Delta$, ensuring that acceptable non-exploitable leaks do not trigger false positives, without compromising statistical soundness. We demonstrate the necessity, effectiveness, and benefits of our approach on both synthetic benchmarks and real-world applications.</li>
</ul>

<h3>Title: Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Hassan, Mohammad Wasil, Sebastian Houben</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19824">https://arxiv.org/abs/2504.19824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19824">https://arxiv.org/pdf/2504.19824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19824]] Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning(https://arxiv.org/abs/2504.19824)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Contrastive learning (CL) approaches have gained great recognition as a very successful subset of self-supervised learning (SSL) methods. SSL enables learning from unlabeled data, a crucial step in the advancement of deep learning, particularly in computer vision (CV), given the plethora of unlabeled image data. CL works by comparing different random augmentations (e.g., different crops) of the same image, thus achieving self-labeling. Nevertheless, randomly augmenting images and especially random cropping can result in an image that is semantically very distant from the original and therefore leads to false labeling, hence undermining the efficacy of the methods. In this research, two novel parameterized cropping methods are introduced that increase the robustness of self-labeling and consequently increase the efficacy. The results show that the use of these methods significantly improves the accuracy of the model by between 2.7\% and 12.4\% on the downstream task of classifying CIFAR-10, depending on the crop size compared to that of the non-parameterized random cropping method.</li>
</ul>

<h3>Title: HOIGaze: Gaze Estimation During Hand-Object Interactions in Extended Reality Exploiting Eye-Hand-Head Coordination</h3>
<ul>
<li><strong>Authors: </strong>Zhiming Hu, Daniel Haeufle, Syn Schmitt, Andreas Bulling</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19828">https://arxiv.org/abs/2504.19828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19828">https://arxiv.org/pdf/2504.19828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19828]] HOIGaze: Gaze Estimation During Hand-Object Interactions in Extended Reality Exploiting Eye-Hand-Head Coordination(https://arxiv.org/abs/2504.19828)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present HOIGaze - a novel learning-based approach for gaze estimation during hand-object interactions (HOI) in extended reality (XR). HOIGaze addresses the challenging HOI setting by building on one key insight: The eye, hand, and head movements are closely coordinated during HOIs and this coordination can be exploited to identify samples that are most useful for gaze estimator training - as such, effectively denoising the training data. This denoising approach is in stark contrast to previous gaze estimation methods that treated all training samples as equal. Specifically, we propose: 1) a novel hierarchical framework that first recognises the hand currently visually attended to and then estimates gaze direction based on the attended hand; 2) a new gaze estimator that uses cross-modal Transformers to fuse head and hand-object features extracted using a convolutional neural network and a spatio-temporal graph convolutional network; and 3) a novel eye-head coordination loss that upgrades training samples belonging to the coordinated eye-head movements. We evaluate HOIGaze on the HOT3D and Aria digital twin (ADT) datasets and show that it significantly outperforms state-of-the-art methods, achieving an average improvement of 15.6% on HOT3D and 6.0% on ADT in mean angular error. To demonstrate the potential of our method, we further report significant performance improvements for the sample downstream task of eye-based activity recognition on ADT. Taken together, our results underline the significant information content available in eye-hand-head coordination and, as such, open up an exciting new direction for learning-based gaze estimation.</li>
</ul>

<h3>Title: SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail UHR Satellite Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yulong Guo, Zilun Zhang, Yongheng Shang, Tiancheng Zhao, Shuiguang Deng, Yingchun Yang, Jianwei Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19839">https://arxiv.org/abs/2504.19839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19839">https://arxiv.org/pdf/2504.19839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19839]] SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail UHR Satellite Image Segmentation(https://arxiv.org/abs/2504.19839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>The long-tail problem presents a significant challenge to the advancement of semantic segmentation in ultra-high-resolution (UHR) satellite imagery. While previous efforts in UHR semantic segmentation have largely focused on multi-branch network architectures that emphasize multi-scale feature extraction and fusion, they have often overlooked the importance of addressing the long-tail issue. In contrast to prior UHR methods that focused on independent feature extraction, we emphasize data augmentation and multimodal feature fusion to alleviate the long-tail problem. In this paper, we introduce SRMF, a novel framework for semantic segmentation in UHR satellite imagery. Our approach addresses the long-tail class distribution by incorporating a multi-scale cropping technique alongside a data augmentation strategy based on semantic reordering and resampling. To further enhance model performance, we propose a multimodal fusion-based general representation knowledge injection method, which, for the first time, fuses text and visual features without the need for individual region text descriptions, extracting more robust features. Extensive experiments on the URUR, GID, and FBP datasets demonstrate that our method improves mIoU by 3.33\%, 0.66\%, and 0.98\%, respectively, achieving state-of-the-art performance. Code is available at: this https URL.</li>
</ul>

<h3>Title: Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration</h3>
<ul>
<li><strong>Authors: </strong>Juhan Park, Kyungjae Lee, Hyung Jin Chang, Jungchan Cho</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19847">https://arxiv.org/abs/2504.19847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19847">https://arxiv.org/pdf/2504.19847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19847]] Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration(https://arxiv.org/abs/2504.19847)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this work, we introduce Segmentation to Human-Object Interaction (\textit{\textbf{Seg2HOI}}) approach, a novel framework that integrates segmentation-based vision foundation models with the human-object interaction task, distinguished from traditional detection-based Human-Object Interaction (HOI) methods. Our approach enhances HOI detection by not only predicting the standard triplets but also introducing quadruplets, which extend HOI triplets by including segmentation masks for human-object pairs. More specifically, Seg2HOI inherits the properties of the vision foundation model (e.g., promptable and interactive mechanisms) and incorporates a decoder that applies these attributes to HOI task. Despite training only for HOI, without additional training mechanisms for these properties, the framework demonstrates that such features still operate efficiently. Extensive experiments on two public benchmark datasets demonstrate that Seg2HOI achieves performance comparable to state-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that Seg2HOI can generate HOI quadruplets and interactive HOI segmentation from novel text and visual prompts that were not used during training, making it versatile for a wide range of applications by leveraging this flexibility.</li>
</ul>

<h3>Title: The Automation Advantage in AI Red Teaming</h3>
<ul>
<li><strong>Authors: </strong>Rob Mulla, Will Pearce, Nick Landers, Brian Greunke, Brad Palm, Vincent Abruzzo, Ads Dawson</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19855">https://arxiv.org/abs/2504.19855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19855">https://arxiv.org/pdf/2504.19855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19855]] The Automation Advantage in AI Red Teaming(https://arxiv.org/abs/2504.19855)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>This paper analyzes Large Language Model (LLM) security vulnerabilities based on data from Crucible, encompassing 214,271 attack attempts by 1,674 users across 30 LLM challenges. Our findings reveal automated approaches significantly outperform manual techniques (69.5% vs 47.6% success rate), despite only 5.2% of users employing automation. We demonstrate that automated approaches excel in systematic exploration and pattern matching challenges, while manual approaches retain speed advantages in certain creative reasoning scenarios, often solving problems 5x faster when successful. Challenge categories requiring systematic exploration are most effectively targeted through automation, while intuitive challenges sometimes favor manual techniques for time-to-solve metrics. These results illuminate how algorithmic testing is transforming AI red-teaming practices, with implications for both offensive security research and defensive measures. Our analysis suggests optimal security testing combines human creativity for strategy development with programmatic execution for thorough exploration.</li>
</ul>

<h3>Title: CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback</h3>
<ul>
<li><strong>Authors: </strong>Chenhan Jiang, Yihan Zeng, Hang Xu, Dit-Yan Yeung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19860">https://arxiv.org/abs/2504.19860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19860">https://arxiv.org/pdf/2504.19860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19860]] CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback(https://arxiv.org/abs/2504.19860)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Score Distillation Sampling (SDS) has achieved remarkable success in text-to-3D content generation. However, SDS-based methods struggle to maintain semantic fidelity for user prompts, particularly when involving multiple objects with intricate interactions. While existing approaches often address 3D consistency through multiview diffusion model fine-tuning on 3D datasets, this strategy inadvertently exacerbates text-3D alignment degradation. The limitation stems from SDS's inherent accumulation of view-independent biases during optimization, which progressively diverges from the ideal text alignment direction. To alleviate this limitation, we propose a novel SDS objective, dubbed as Textual Coherent Score Distillation (TCSD), which integrates alignment feedback from multimodal large language models (MLLMs). Our TCSD leverages cross-modal understanding capabilities of MLLMs to assess and guide the text-3D correspondence during the optimization. We further develop 3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text alignment in 3D generations. Additionally, we introduce an LLM-layout initialization that significantly accelerates optimization convergence through semantic-aware spatial configuration. Comprehensive evaluations demonstrate that our framework, CoherenDream, establishes state-of-the-art performance in text-aligned 3D generation across multiple benchmarks, including T$^3$Bench and TIFA subset. Qualitative results showcase the superior performance of CoherenDream in preserving textual consistency and semantic interactions. As the first study to incorporate MLLMs into SDS optimization, we also conduct extensive ablation studies to explore optimal MLLM adaptations for 3D generation tasks.</li>
</ul>

<h3>Title: semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage</h3>
<ul>
<li><strong>Authors: </strong>Ke Hong, Lufang Chen, Zhong Wang, Xiuhong Li, Qiuli Mao, Jianping Ma, Chao Xiong, Guanyu Wu, Buhe Han, Guohao Dai, Yun Liang, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19867">https://arxiv.org/abs/2504.19867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19867">https://arxiv.org/pdf/2504.19867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19867]] semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage(https://arxiv.org/abs/2504.19867)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing large language model (LLM) serving systems fall into two categories: 1) a unified system where prefill phase and decode phase are co-located on the same GPU, sharing the unified computational resource and storage, and 2) a disaggregated system where the two phases are disaggregated to different GPUs. The design of the disaggregated system addresses the latency interference and sophisticated scheduling issues in the unified system but leads to storage challenges including 1) replicated weights for both phases that prevent flexible deployment, 2) KV cache transfer overhead between the two phases, 3) storage imbalance that causes substantial wasted space of the GPU capacity, and 4) suboptimal resource adjustment arising from the difficulties in migrating KV cache. Such storage inefficiency delivers poor serving performance under high request rates. In this paper, we identify that the advantage of the disaggregated system lies in the disaggregated computation, i.e., partitioning the computational resource to enable the asynchronous computation of two phases. Thus, we propose a novel LLM serving system, semi-PD, characterized by disaggregated computation and unified storage. In semi-PD, we introduce a computation resource controller to achieve disaggregated computation at the streaming multi-processor (SM) level, and a unified memory manager to manage the asynchronous memory access from both phases. semi-PD has a low-overhead resource adjustment mechanism between the two phases, and a service-level objective (SLO) aware dynamic partitioning algorithm to optimize the SLO attainment. Compared to state-of-the-art systems, semi-PD maintains lower latency at higher request rates, reducing the average end-to-end latency per request by 1.27-2.58x on DeepSeek series models, and serves 1.55-1.72x more requests adhering to latency constraints on Llama series models.</li>
</ul>

<h3>Title: DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images</h3>
<ul>
<li><strong>Authors: </strong>Mamadou Keita, Wassim Hamidouche, Hessen Bougueffa Eutamene, Abdelmalik Taleb-Ahmed, Abdenour Hadid</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19876">https://arxiv.org/abs/2504.19876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19876">https://arxiv.org/pdf/2504.19876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19876]] DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images(https://arxiv.org/abs/2504.19876)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces DeeCLIP, a novel framework for detecting AI-generated images using CLIP-ViT and fusion learning. Despite significant advancements in generative models capable of creating highly photorealistic images, existing detection methods often struggle to generalize across different models and are highly sensitive to minor perturbations. To address these challenges, DeeCLIP incorporates DeeFuser, a fusion module that combines high-level and low-level features, improving robustness against degradations such as compression and blurring. Additionally, we apply triplet loss to refine the embedding space, enhancing the model's ability to distinguish between real and synthetic content. To further enable lightweight adaptation while preserving pre-trained knowledge, we adopt parameter-efficient fine-tuning using low-rank adaptation (LoRA) within the CLIP-ViT backbone. This approach supports effective zero-shot learning without sacrificing generalization. Trained exclusively on 4-class ProGAN data, DeeCLIP achieves an average accuracy of 89.00% on 19 test subsets composed of generative adversarial network (GAN) and diffusion models. Despite having fewer trainable parameters, DeeCLIP outperforms existing methods, demonstrating superior robustness against various generative models and real-world distortions. The code is publicly available at this https URL for research purposes.</li>
</ul>

<h3>Title: Federated Out-of-Distribution Generalization: A Causal Augmentation View</h3>
<ul>
<li><strong>Authors: </strong>Runhui Zhang, Sijin Zhou, Zhuang Qi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19882">https://arxiv.org/abs/2504.19882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19882">https://arxiv.org/pdf/2504.19882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19882]] Federated Out-of-Distribution Generalization: A Causal Augmentation View(https://arxiv.org/abs/2504.19882)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning aims to collaboratively model by integrating multi-source information to obtain a model that can generalize across all client data. Existing methods often leverage knowledge distillation or data augmentation to mitigate the negative impact of data bias across clients. However, the limited performance of teacher models on out-of-distribution samples and the inherent quality gap between augmented and original data hinder their effectiveness and they typically fail to leverage the advantages of incorporating rich contextual information. To address these limitations, this paper proposes a Federated Causal Augmentation method, termed FedCAug, which employs causality-inspired data augmentation to break the spurious correlation between attributes and categories. Specifically, it designs a causal region localization module to accurately identify and decouple the background and objects in the image, providing rich contextual information for causal data augmentation. Additionally, it designs a causality-inspired data augmentation module that integrates causal features and within-client context to generate counterfactual samples. This significantly enhances data diversity, and the entire process does not require any information sharing between clients, thereby contributing to the protection of data privacy. Extensive experiments conducted on three datasets reveal that FedCAug markedly reduces the model's reliance on background to predict sample labels, achieving superior performance compared to state-of-the-art methods.</li>
</ul>

<h3>Title: Enhancing breast cancer detection on screening mammogram using self-supervised learning and a hybrid deep model of Swin Transformer and Convolutional Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Han Chen, Anne L. Martel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19888">https://arxiv.org/abs/2504.19888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19888">https://arxiv.org/pdf/2504.19888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19888]] Enhancing breast cancer detection on screening mammogram using self-supervised learning and a hybrid deep model of Swin Transformer and Convolutional Neural Network(https://arxiv.org/abs/2504.19888)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Purpose: The scarcity of high-quality curated labeled medical training data remains one of the major limitations in applying artificial intelligence (AI) systems to breast cancer diagnosis. Deep models for mammogram analysis and mass (or micro-calcification) detection require training with a large volume of labeled images, which are often expensive and time-consuming to collect. To reduce this challenge, we proposed a novel method that leverages self-supervised learning (SSL) and a deep hybrid model, named \textbf{HybMNet}, which combines local self-attention and fine-grained feature extraction to enhance breast cancer detection on screening mammograms. Approach: Our method employs a two-stage learning process: (1) SSL Pretraining: We utilize EsViT, a SSL technique, to pretrain a Swin Transformer (Swin-T) using a limited set of mammograms. The pretrained Swin-T then serves as the backbone for the downstream task. (2) Downstream Training: The proposed HybMNet combines the Swin-T backbone with a CNN-based network and a novel fusion strategy. The Swin-T employs local self-attention to identify informative patch regions from the high-resolution mammogram, while the CNN-based network extracts fine-grained local features from the selected patches. A fusion module then integrates global and local information from both networks to generate robust predictions. The HybMNet is trained end-to-end, with the loss function combining the outputs of the Swin-T and CNN modules to optimize feature extraction and classification performance. Results: The proposed method was evaluated for its ability to detect breast cancer by distinguishing between benign (normal) and malignant mammograms. Leveraging SSL pretraining and the HybMNet model, it achieved AUC of 0.864 (95% CI: 0.852, 0.875) on the CMMD dataset and 0.889 (95% CI: 0.875, 0.903) on the INbreast dataset, highlighting its effectiveness.</li>
</ul>

<h3>Title: CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition</h3>
<ul>
<li><strong>Authors: </strong>Quynh Phung, Long Mai, Fabian David Caba Heilbron, Feng Liu, Jia-Bin Huang, Cusuh Ham</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19894">https://arxiv.org/abs/2504.19894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19894">https://arxiv.org/pdf/2504.19894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19894]] CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition(https://arxiv.org/abs/2504.19894)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present CineVerse, a novel framework for the task of cinematic scene composition. Similar to traditional multi-shot generation, our task emphasizes the need for consistency and continuity across frames. However, our task also focuses on addressing challenges inherent to filmmaking, such as multiple characters, complex interactions, and visual cinematic effects. In order to learn to generate such content, we first create the CineVerse dataset. We use this dataset to train our proposed two-stage approach. First, we prompt a large language model (LLM) with task-specific instructions to take in a high-level scene description and generate a detailed plan for the overall setting and characters, as well as the individual shots. Then, we fine-tune a text-to-image generation model to synthesize high-quality visual keyframes. Experimental results demonstrate that CineVerse yields promising improvements in generating visually coherent and contextually rich movie scenes, paving the way for further exploration in cinematic video synthesis.</li>
</ul>

<h3>Title: GenCLS++: Pushing the Boundaries of Generative Classification in LLMs Through Comprehensive SFT and RL Studies Across Diverse Datasets</h3>
<ul>
<li><strong>Authors: </strong>Mingqian He, Fei Zhao, Chonggang Lu, Ziyan Liu, Yue Wang, Haofu Qian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19898">https://arxiv.org/abs/2504.19898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19898">https://arxiv.org/pdf/2504.19898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19898]] GenCLS++: Pushing the Boundaries of Generative Classification in LLMs Through Comprehensive SFT and RL Studies Across Diverse Datasets(https://arxiv.org/abs/2504.19898)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>As a fundamental task in machine learning, text classification plays a crucial role in many areas. With the rapid scaling of Large Language Models (LLMs), particularly through reinforcement learning (RL), there is a growing need for more capable discriminators. Consequently, advances in classification are becoming increasingly vital for enhancing the overall capabilities of LLMs. Traditional discriminative methods map text to labels but overlook LLMs' intrinsic generative strengths. Generative classification addresses this by prompting the model to directly output labels. However, existing studies still rely on simple SFT alone, seldom probing the interplay between training and inference prompts, and no work has systematically leveraged RL for generative text classifiers and unified SFT, RL, and inference-time prompting in one framework. We bridge this gap with GenCLS++, a framework that jointly optimizes SFT and RL while systematically exploring five high-level strategy dimensions-in-context learning variants, category definitions, explicit uncertainty labels, semantically irrelevant numeric labels, and perplexity-based decoding-during both training and inference. After an SFT "policy warm-up," we apply RL with a simple rule-based reward, yielding sizable extra gains. Across seven datasets, GenCLS++ achieves an average accuracy improvement of 3.46% relative to the naive SFT baseline; on public datasets, this improvement rises to 4.00%. Notably, unlike reasoning-intensive tasks that benefit from explicit thinking processes, we find that classification tasks perform better without such reasoning steps. These insights into the role of explicit reasoning provide valuable guidance for future LLM applications.</li>
</ul>

<h3>Title: Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning</h3>
<ul>
<li><strong>Authors: </strong>Han Chen, Anne L. Martel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19900">https://arxiv.org/abs/2504.19900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19900">https://arxiv.org/pdf/2504.19900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19900]] Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning(https://arxiv.org/abs/2504.19900)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate detection of breast cancer from high-resolution mammograms is crucial for early diagnosis and effective treatment planning. Previous studies have shown the potential of using single-view mammograms for breast cancer detection. However, incorporating multi-view data can provide more comprehensive insights. Multi-view classification, especially in medical imaging, presents unique challenges, particularly when dealing with large-scale, high-resolution data. In this work, we propose a novel Multi-view Visual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening mammograms. We first pretrain a robust single-view classification model on high-resolution mammograms and then innovatively adapt multi-view feature learning into a task-specific prompt tuning process. This technique selectively tunes a minimal set of trainable parameters (7\%) while retaining the robustness of the pre-trained single-view model, enabling efficient integration of multi-view data without the need for aggressive downsampling. Our approach offers an efficient alternative to traditional feature fusion methods, providing a more robust, scalable, and efficient solution for high-resolution mammogram analysis. Experimental results on a large multi-institution dataset demonstrate that our method outperforms conventional approaches while maintaining detection efficiency, achieving an AUROC of 0.852 for distinguishing between Benign, DCIS, and Invasive classes. This work highlights the potential of MVPT-NET for medical imaging tasks and provides a scalable solution for integrating multi-view data in breast cancer detection.</li>
</ul>

<h3>Title: Convergence Analysis of Asynchronous Federated Learning with Gradient Compression for Non-Convex Optimization</h3>
<ul>
<li><strong>Authors: </strong>Diying Yang, Yingwei Hou, Danyang Xiao, Weigang Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19903">https://arxiv.org/abs/2504.19903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19903">https://arxiv.org/pdf/2504.19903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19903]] Convergence Analysis of Asynchronous Federated Learning with Gradient Compression for Non-Convex Optimization(https://arxiv.org/abs/2504.19903)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Gradient compression is an effective technique for reducing communication costs in federated learning (FL), and error feedback (EF) is usually adopted to remedy the compression errors. However, there remains a lack of systematic study on these techniques in asynchronous FL. In this paper, we fill this gap by analyzing the convergence behaviors of FL under different frameworks. We firstly consider a basic asynchronous FL framework AsynFL, and provide an improved convergence analysis that relies on fewer assumptions and yields a superior convergence rate than prior studies. Then, we consider a variant framework with gradient compression, AsynFLC. We show sufficient conditions for its convergence to the optimum, indicating the interaction between asynchronous delay and compression rate. Our analysis also demonstrates that asynchronous delay amplifies the variance caused by compression, thereby hindering convergence, and such an impact is exacerbated by high data heterogeneity. Furthermore, we study the convergence of AsynFLC-EF, the framework that further integrates EF. We prove that EF can effectively reduce the variance of gradient estimation despite asynchronous delay, which enables AsynFLC-EF to match the convergence rate of AsynFL. We also show that the impact of asynchronous delay on EF is limited to slowing down the higher-order convergence term. Experimental results substantiate our analytical findings very well.</li>
</ul>

<h3>Title: Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Hugo Georgenthum, Cristian Cosentino, Fabrizio Marozzo, Pietro Liò</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19918">https://arxiv.org/abs/2504.19918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19918">https://arxiv.org/pdf/2504.19918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19918]] Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI(https://arxiv.org/abs/2504.19918)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>The automatic summarization of surgical videos is essential for enhancing procedural documentation, supporting surgical training, and facilitating post-operative analysis. This paper presents a novel method at the intersection of artificial intelligence and medicine, aiming to develop machine learning models with direct real-world applications in surgical contexts. We propose a multi-modal framework that leverages recent advancements in computer vision and large language models to generate comprehensive video summaries. % The approach is structured in three key stages. First, surgical videos are divided into clips, and visual features are extracted at the frame level using visual transformers. This step focuses on detecting tools, tissues, organs, and surgical actions. Second, the extracted features are transformed into frame-level captions via large language models. These are then combined with temporal features, captured using a ViViT-based encoder, to produce clip-level summaries that reflect the broader context of each video segment. Finally, the clip-level descriptions are aggregated into a full surgical report using a dedicated LLM tailored for the summarization task. % We evaluate our method on the CholecT50 dataset, using instrument and action annotations from 50 laparoscopic videos. The results show strong performance, achieving 96\% precision in tool detection and a BERT score of 0.74 for temporal context summarization. This work contributes to the advancement of AI-assisted tools for surgical reporting, offering a step toward more intelligent and reliable clinical documentation.</li>
</ul>

<h3>Title: Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking</h3>
<ul>
<li><strong>Authors: </strong>Luigia Costabile, Gian Marco Orlando, Valerio La Gatta, Vincenzo Moscato</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19940">https://arxiv.org/abs/2504.19940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19940">https://arxiv.org/pdf/2504.19940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19940]] Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking(https://arxiv.org/abs/2504.19940)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The growing spread of online misinformation has created an urgent need for scalable, reliable fact-checking solutions. Crowdsourced fact-checking - where non-experts evaluate claim veracity - offers a cost-effective alternative to expert verification, despite concerns about variability in quality and bias. Encouraged by promising results in certain contexts, major platforms such as X (formerly Twitter), Facebook, and Instagram have begun shifting from centralized moderation to decentralized, crowd-based approaches. In parallel, advances in Large Language Models (LLMs) have shown strong performance across core fact-checking tasks, including claim detection and evidence evaluation. However, their potential role in crowdsourced workflows remains unexplored. This paper investigates whether LLM-powered generative agents - autonomous entities that emulate human behavior and decision-making - can meaningfully contribute to fact-checking tasks traditionally reserved for human crowds. Using the protocol of La Barbera et al. (2024), we simulate crowds of generative agents with diverse demographic and ideological profiles. Agents retrieve evidence, assess claims along multiple quality dimensions, and issue final veracity judgments. Our results show that agent crowds outperform human crowds in truthfulness classification, exhibit higher internal consistency, and show reduced susceptibility to social and cognitive biases. Compared to humans, agents rely more systematically on informative criteria such as Accuracy, Precision, and Informativeness, suggesting a more structured decision-making process. Overall, our findings highlight the potential of generative agents as scalable, consistent, and less biased contributors to crowd-based fact-checking systems.</li>
</ul>

<h3>Title: Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach</h3>
<ul>
<li><strong>Authors: </strong>Vineeth Sai Narajala, Ken Huang, Idan Habler</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19951">https://arxiv.org/abs/2504.19951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19951">https://arxiv.org/pdf/2504.19951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19951]] Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach(https://arxiv.org/abs/2504.19951)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, generative</a></li>
<li><strong>Abstract: </strong>The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates standardized protocols enabling agents to discover and interact with external tools. However, these protocols introduce new security challenges, particularly; tool squatting; the deceptive registration or representation of tools. This paper analyzes tool squatting threats within the context of emerging interoperability standards, such as Model Context Protocol (MCP) or seamless communication between agents protocols. It introduces a comprehensive Tool Registry system designed to mitigate these risks. We propose a security-focused architecture featuring admin-controlled registration, centralized tool discovery, fine grained access policies enforced via dedicated Agent and Tool Registry services, a dynamic trust scoring mechanism based on tool versioning and known vulnerabilities, and just in time credential provisioning. Based on its design principles, the proposed registry framework aims to effectively prevent common tool squatting vectors while preserving the flexibility and power of multi-agent systems. This work addresses a critical security gap in the rapidly evolving GenAI ecosystem and provides a foundation for secure tool integration in production environments.</li>
</ul>

<h3>Title: Robust Federated Personalised Mean Estimation for the Gaussian Mixture Model</h3>
<ul>
<li><strong>Authors: </strong>Malhar A. Managoli, Vinod M. Prabhakaran, Suhas Diggavi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19955">https://arxiv.org/abs/2504.19955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19955">https://arxiv.org/pdf/2504.19955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19955]] Robust Federated Personalised Mean Estimation for the Gaussian Mixture Model(https://arxiv.org/abs/2504.19955)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning with heterogeneous data and personalization has received significant recent attention. Separately, robustness to corrupted data in the context of federated learning has also been studied. In this paper we explore combining personalization for heterogeneous data with robustness, where a constant fraction of the clients are corrupted. Motivated by this broad problem, we formulate a simple instantiation which captures some of its difficulty. We focus on the specific problem of personalized mean estimation where the data is drawn from a Gaussian mixture model. We give an algorithm whose error depends almost linearly on the ratio of corrupted to uncorrupted samples, and show a lower bound with the same behavior, albeit with a gap of a constant factor.</li>
</ul>

<h3>Title: Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents</h3>
<ul>
<li><strong>Authors: </strong>Vineeth Sai Narajala, Om Narayan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19956">https://arxiv.org/abs/2504.19956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19956">https://arxiv.org/pdf/2504.19956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19956]] Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents(https://arxiv.org/abs/2504.19956)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, generative</a></li>
<li><strong>Abstract: </strong>As generative AI (GenAI) agents become more common in enterprise settings, they introduce security challenges that differ significantly from those posed by traditional systems. These agents are not just LLMs; they reason, remember, and act, often with minimal human oversight. This paper introduces a comprehensive threat model tailored specifically for GenAI agents, focusing on how their autonomy, persistent memory access, complex reasoning, and tool integration create novel risks. This research work identifies 9 primary threats and organizes them across five key domains: cognitive architecture vulnerabilities, temporal persistence threats, operational execution vulnerabilities, trust boundary violations, and governance circumvention. These threats are not just theoretical they bring practical challenges such as delayed exploitability, cross-system propagation, cross system lateral movement, and subtle goal misalignments that are hard to detect with existing frameworks and standard approaches. To help address this, the research work present two complementary frameworks: ATFAA - Advanced Threat Framework for Autonomous AI Agents, which organizes agent-specific risks, and SHIELD, a framework proposing practical mitigation strategies designed to reduce enterprise exposure. While this work builds on existing work in LLM and AI security, the focus is squarely on what makes agents different and why those differences matter. Ultimately, this research argues that GenAI agents require a new lens for security. If we fail to adapt our threat models and defenses to account for their unique architecture and behavior, we risk turning a powerful new tool into a serious enterprise liability.</li>
</ul>

<h3>Title: Shopformer: Transformer-Based Framework for Detecting Shoplifting via Human Pose</h3>
<ul>
<li><strong>Authors: </strong>Narges Rashvand, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Babak Rahimi Ardabili, Hamed Tabkhi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19970">https://arxiv.org/abs/2504.19970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19970">https://arxiv.org/pdf/2504.19970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19970]] Shopformer: Transformer-Based Framework for Detecting Shoplifting via Human Pose(https://arxiv.org/abs/2504.19970)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer</a></li>
<li><strong>Abstract: </strong>Shoplifting remains a costly issue for the retail sector, but traditional surveillance systems, which are mostly based on human monitoring, are still largely ineffective, with only about 2% of shoplifters being arrested. Existing AI-based approaches rely on pixel-level video analysis which raises privacy concerns, is sensitive to environmental variations, and demands significant computational resources. To address these limitations, we introduce Shopformer, a novel transformer-based model that detects shoplifting by analyzing pose sequences rather than raw video. We propose a custom tokenization strategy that converts pose sequences into compact embeddings for efficient transformer processing. To the best of our knowledge, this is the first pose-sequence-based transformer model for shoplifting detection. Evaluated on real-world pose data, our method outperforms state-of-the-art anomaly detection models, offering a privacy-preserving, and scalable solution for real-time retail surveillance. The code base for this work is available at this https URL.</li>
</ul>

<h3>Title: Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets</h3>
<ul>
<li><strong>Authors: </strong>Adam Younsi, Abdalgader Abubaker, Mohamed El Amine Seddik, Hakim Hacid, Salem Lahlou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19981">https://arxiv.org/abs/2504.19981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19981">https://arxiv.org/pdf/2504.19981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19981]] Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets(https://arxiv.org/abs/2504.19981)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Achieving both accuracy and diverse reasoning remains challenging for Large Language Models (LLMs) in complex domains like mathematics. A key bottleneck is evaluating intermediate reasoning steps to guide generation without costly human annotations. To address this, we first introduce a novel Process Reward Model (PRM) trained automatically using Monte Carlo Tree Search coupled with a similarity-based data augmentation technique, effectively capturing step-level reasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks (GFlowNets) to operate at the reasoning step level. Unlike traditional reinforcement learning focused on maximizing a single reward, GFlowNets naturally sample diverse, high-quality solutions proportional to their rewards, as measured by our PRM. Empirical evaluation shows strong improvements in both accuracy and solution diversity on challenging mathematical benchmarks (e.g., +2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective generalization to unseen datasets (+9.4% absolute on SAT MATH). Our work demonstrates the potential of PRM-guided, step-level GFlowNets for developing more robust and versatile mathematical reasoning in LLMs.</li>
</ul>

<h3>Title: TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons</h3>
<ul>
<li><strong>Authors: </strong>Emre Can Acikgoz, Carl Guo, Suvodip Dey, Akul Datta, Takyoung Kim, Gokhan Tur, Dilek Hakkani-Tür</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19982">https://arxiv.org/abs/2504.19982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19982">https://arxiv.org/pdf/2504.19982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19982]] TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons(https://arxiv.org/abs/2504.19982)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Task-oriented dialogue (TOD) systems are experiencing a revolution driven by Large Language Models (LLMs), yet the evaluation methodologies for these systems remain insufficient for their growing sophistication. While traditional automatic metrics effectively assessed earlier modular systems, they focus solely on the dialogue level and cannot detect critical intermediate errors that can arise during user-agent interactions. In this paper, we introduce TD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework that unifies fine-grained turn-level analysis with holistic dialogue-level comparisons. At turn level, we evaluate each response along three TOD-specific dimensions: conversation cohesion, backend knowledge consistency, and policy compliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons to provide a measure of dialogue-level quality. Through experiments on MultiWOZ 2.4 and {\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the conversational errors that conventional metrics miss. Furthermore, TD-EVAL exhibits better alignment with human judgments than traditional and LLM-based metrics. These findings demonstrate that TD-EVAL introduces a new paradigm for TOD system evaluation, efficiently assessing both turn and system levels with a plug-and-play framework for future research.</li>
</ul>

<h3>Title: Simplified and Secure MCP Gateways for Enterprise AI Integration</h3>
<ul>
<li><strong>Authors: </strong>Ivo Brett</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.19997">https://arxiv.org/abs/2504.19997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.19997">https://arxiv.org/pdf/2504.19997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.19997]] Simplified and Secure MCP Gateways for Enterprise AI Integration(https://arxiv.org/abs/2504.19997)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust</a></li>
<li><strong>Abstract: </strong>The increased adoption of the Model Context Protocol (MCP) for AI Agents necessitates robust security for Enterprise integrations. This paper introduces the MCP Gateway to simplify self-hosted MCP server integration. The proposed architecture integrates security principles, authentication, intrusion detection, and secure tunneling, enabling secure self-hosting without exposing infrastructure. Key contributions include a reference architecture, threat model mapping, simplified integration strategies, and open-source implementation recommendations. This work focuses on the unique challenges of enterprise-centric, self-hosted AI integrations, unlike existing public MCP server solutions.</li>
</ul>

<h3>Title: Knowledge Distillation of Domain-adapted LLMs for Question-Answering in Telecom</h3>
<ul>
<li><strong>Authors: </strong>Rishika Sen, Sujoy Roychowdhury, Sumit Soman, H. G. Ranjani, Srikhetra Mohanty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20000">https://arxiv.org/abs/2504.20000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20000">https://arxiv.org/pdf/2504.20000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20000]] Knowledge Distillation of Domain-adapted LLMs for Question-Answering in Telecom(https://arxiv.org/abs/2504.20000)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge Distillation (KD) is one of the approaches to reduce the size of Large Language Models (LLMs). A LLM with smaller number of model parameters (student) is trained to mimic the performance of a LLM of a larger size (teacher model) on a specific task. For domain-specific tasks, it is not clear if teacher or student model, or both, must be considered for domain adaptation. In this work, we study this problem from perspective of telecom domain Question-Answering (QA) task. We systematically experiment with Supervised Fine-tuning (SFT) of teacher only, SFT of student only and SFT of both prior to KD. We design experiments to study the impact of vocabulary (same and different) and KD algorithms (vanilla KD and Dual Space KD, DSKD) on the distilled model. Multi-faceted evaluation of the distillation using 14 different metrics (N-gram, embedding and LLM-based metrics) is considered. Experimental results show that SFT of teacher improves performance of distilled model when both models have same vocabulary, irrespective of algorithm and metrics. Overall, SFT of both teacher and student results in better performance across all metrics, although the statistical significance of the same depends on the vocabulary of the teacher models.</li>
</ul>

<h3>Title: LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Beizhe Hu, Qiang Sheng, Juan Cao, Yang Li, Danding Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20013">https://arxiv.org/abs/2504.20013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20013">https://arxiv.org/pdf/2504.20013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20013]] LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation(https://arxiv.org/abs/2504.20013)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Online fake news moderation now faces a new challenge brought by the malicious use of large language models (LLMs) in fake news production. Though existing works have shown LLM-generated fake news is hard to detect from an individual aspect, it remains underexplored how its large-scale release will impact the news ecosystem. In this study, we develop a simulation pipeline and a dataset with ~56k generated news of diverse types to investigate the effects of LLM-generated fake news within neural news recommendation systems. Our findings expose a truth decay phenomenon, where real news is gradually losing its advantageous position in news ranking against fake news as LLM-generated news is involved in news recommendation. We further provide an explanation about why truth decay occurs from a familiarity perspective and show the positive correlation between perplexity and news ranking. Finally, we discuss the threats of LLM-generated fake news and provide possible countermeasures. We urge stakeholders to address this emerging challenge to preserve the integrity of news ecosystems.</li>
</ul>

<h3>Title: Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xin Wang, Haoyang Li, Zeyang Zhang, Haibo Chen, Wenwu Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20020">https://arxiv.org/abs/2504.20020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20020">https://arxiv.org/pdf/2504.20020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20020]] Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models(https://arxiv.org/abs/2504.20020)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have dramatically advanced machine learning research including natural language processing, computer vision, data mining, etc., yet they still exhibit critical limitations in reasoning, factual consistency, and interpretability. In this paper, we introduce a novel learning paradigm -- Modular Machine Learning (MML) -- as an essential approach toward new-generation LLMs. MML decomposes the complex structure of LLMs into three interdependent components: modular representation, modular model, and modular reasoning, aiming to enhance LLMs' capability of counterfactual reasoning, mitigating hallucinations, as well as promoting fairness, safety, and transparency. Specifically, the proposed MML paradigm can: i) clarify the internal working mechanism of LLMs through the disentanglement of semantic components; ii) allow for flexible and task-adaptive model design; iii) enable interpretable and logic-driven decision-making process. We present a feasible implementation of MML-based LLMs via leveraging advanced techniques such as disentangled representation learning, neural architecture search and neuro-symbolic learning. We critically identify key challenges, such as the integration of continuous neural and discrete symbolic processes, joint optimization, and computational scalability, present promising future research directions that deserve further exploration. Ultimately, the integration of the MML paradigm with LLMs has the potential to bridge the gap between statistical (deep) learning and formal (logical) reasoning, thereby paving the way for robust, adaptable, and trustworthy AI systems across a wide range of real-world applications.</li>
</ul>

<h3>Title: Better To Ask in English? Evaluating Factual Accuracy of Multilingual LLMs in English and Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Pritika Rohera, Chaitrali Ginimav, Gayatri Sawant, Raviraj Joshi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20022">https://arxiv.org/abs/2504.20022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20022">https://arxiv.org/pdf/2504.20022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20022]] Better To Ask in English? Evaluating Factual Accuracy of Multilingual LLMs in English and Low-Resource Languages(https://arxiv.org/abs/2504.20022)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual Large Language Models (LLMs) have demonstrated significant effectiveness across various languages, particularly in high-resource languages such as English. However, their performance in terms of factual accuracy across other low-resource languages, especially Indic languages, remains an area of investigation. In this study, we assess the factual accuracy of LLMs - GPT-4o, Gemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in English and Indic languages using the IndicQuest dataset, which contains question-answer pairs in English and 19 Indic languages. By asking the same questions in English and their respective Indic translations, we analyze whether the models are more reliable for regional context questions in Indic languages or when operating in English. Our findings reveal that LLMs often perform better in English, even for questions rooted in Indic contexts. Notably, we observe a higher tendency for hallucination in responses generated in low-resource Indic languages, highlighting challenges in the multilingual understanding capabilities of current LLMs.</li>
</ul>

<h3>Title: SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wufei Ma, Yu-Cheng Chou, Qihao Liu, Xingrui Wang, Celso de Melo, Jieneng Chen, Jianwen Xie, Alan Yuille</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20024">https://arxiv.org/abs/2504.20024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20024">https://arxiv.org/pdf/2504.20024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20024]] SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning(https://arxiv.org/abs/2504.20024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies in 3D spatial reasoning explore data-driven approaches and achieve enhanced spatial reasoning performance with reinforcement learning (RL). However, these methods typically perform spatial reasoning in an implicit manner, and it remains underexplored whether the acquired 3D knowledge generalizes to unseen question types at any stage of the training. In this work we introduce SpatialReasoner, a novel large vision-language model (LVLM) that address 3D spatial reasoning with explicit 3D representations shared between stages -- 3D perception, computation, and reasoning. Explicit 3D representations provide a coherent interface that supports advanced 3D spatial reasoning and enable us to study the factual errors made by LVLMs. Results show that our SpatialReasoner achieve improved performance on a variety of spatial reasoning benchmarks and generalizes better when evaluating on novel 3D spatial reasoning questions. Our study bridges the 3D parsing capabilities of prior visual foundation models with the powerful reasoning abilities of large language models, opening new directions for 3D spatial reasoning.</li>
</ul>

<h3>Title: LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields</h3>
<ul>
<li><strong>Authors: </strong>Zhengqin Li, Dilin Wang, Ka Chen, Zhaoyang Lv, Thu Nguyen-Phuoc, Milim Lee, Jia-Bin Huang, Lei Xiao, Cheng Zhang, Yufeng Zhu, Carl S. Marshall, Yufeng Ren, Richard Newcombe, Zhao Dong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20026">https://arxiv.org/abs/2504.20026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20026">https://arxiv.org/pdf/2504.20026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20026]] LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields(https://arxiv.org/abs/2504.20026)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present Large Inverse Rendering Model (LIRM), a transformer architecture that jointly reconstructs high-quality shape, materials, and radiance fields with view-dependent effects in less than a second. Our model builds upon the recent Large Reconstruction Models (LRMs) that achieve state-of-the-art sparse-view reconstruction quality. However, existing LRMs struggle to reconstruct unseen parts accurately and cannot recover glossy appearance or generate relightable 3D contents that can be consumed by standard Graphics engines. To address these limitations, we make three key technical contributions to build a more practical multi-view 3D reconstruction framework. First, we introduce an update model that allows us to progressively add more input views to improve our reconstruction. Second, we propose a hexa-plane neural SDF representation to better recover detailed textures, geometry and material parameters. Third, we develop a novel neural directional-embedding mechanism to handle view-dependent effects. Trained on a large-scale shape and material dataset with a tailored coarse-to-fine training scheme, our model achieves compelling results. It compares favorably to optimization-based dense-view inverse rendering methods in terms of geometry and relighting accuracy, while requiring only a fraction of the inference time.</li>
</ul>

<h3>Title: More Clear, More Flexible, More Precise: A Comprehensive Oriented Object Detection benchmark for UAV</h3>
<ul>
<li><strong>Authors: </strong>Kai Ye, Haidi Tang, Bowen Liu, Pingyang Dai, Liujuan Cao, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20032">https://arxiv.org/abs/2504.20032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20032">https://arxiv.org/pdf/2504.20032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20032]] More Clear, More Flexible, More Precise: A Comprehensive Oriented Object Detection benchmark for UAV(https://arxiv.org/abs/2504.20032)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Applications of unmanned aerial vehicle (UAV) in logistics, agricultural automation, urban management, and emergency response are highly dependent on oriented object detection (OOD) to enhance visual perception. Although existing datasets for OOD in UAV provide valuable resources, they are often designed for specific downstream this http URL, they exhibit limited generalization performance in real flight scenarios and fail to thoroughly demonstrate algorithm effectiveness in practical environments. To bridge this critical gap, we introduce CODrone, a comprehensive oriented object detection dataset for UAVs that accurately reflects real-world conditions. It also serves as a new benchmark designed to align with downstream task requirements, ensuring greater applicability and robustness in UAV-based this http URL on application requirements, we identify four key limitations in current UAV OOD datasets-low image resolution, limited object categories, single-view imaging, and restricted flight altitudes-and propose corresponding improvements to enhance their applicability and this http URL, CODrone contains a broad spectrum of annotated images collected from multiple cities under various lighting conditions, enhancing the realism of the benchmark. To rigorously evaluate CODrone as a new benchmark and gain deeper insights into the novel challenges it presents, we conduct a series of experiments based on 22 classical or SOTA this http URL evaluation not only assesses the effectiveness of CODrone in real-world scenarios but also highlights key bottlenecks and opportunities to advance OOD in UAV this http URL, CODrone fills the data gap in OOD from UAV perspective and provides a benchmark with enhanced generalization capability, better aligning with practical applications and future algorithm development.</li>
</ul>

<h3>Title: Mitigating Catastrophic Forgetting in the Incremental Learning of Medical Images</h3>
<ul>
<li><strong>Authors: </strong>Sara Yavari, Jacob Furst</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20033">https://arxiv.org/abs/2504.20033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20033">https://arxiv.org/pdf/2504.20033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20033]] Mitigating Catastrophic Forgetting in the Incremental Learning of Medical Images(https://arxiv.org/abs/2504.20033)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes an Incremental Learning (IL) approach to enhance the accuracy and efficiency of deep learning models in analyzing T2-weighted (T2w) MRI medical images prostate cancer detection using the PI-CAI dataset. We used multiple health centers' artificial intelligence and radiology data, focused on different tasks that looked at prostate cancer detection using MRI (PI-CAI). We utilized Knowledge Distillation (KD), as it employs generated images from past tasks to guide the training of models for subsequent tasks. The approach yielded improved performance and faster convergence of the models. To demonstrate the versatility and robustness of our approach, we evaluated it on the PI-CAI dataset, a diverse set of medical imaging modalities including OCT and PathMNIST, and the benchmark continual learning dataset CIFAR-10. Our results indicate that KD can be a promising technique for IL in medical image analysis in which data is sourced from individual health centers and the storage of large datasets is not feasible. By using generated images from prior tasks, our method enables the model to retain and apply previously acquired knowledge without direct access to the original data.</li>
</ul>

<h3>Title: AutoJudge: Judge Decoding Without Manual Annotation</h3>
<ul>
<li><strong>Authors: </strong>Roman Garipov, Fedor Velikonivtsev, Ruslan Svirschevski, Vage Egiazarian, Max Ryabinin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20039">https://arxiv.org/abs/2504.20039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20039">https://arxiv.org/pdf/2504.20039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20039]] AutoJudge: Judge Decoding Without Manual Annotation(https://arxiv.org/abs/2504.20039)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce AutoJudge, a framework that accelerates large language model (LLM) inference with task-specific lossy speculative decoding. Instead of matching the original model output distribution token-by-token, we identify which of the generated tokens affect the downstream quality of the generated response, relaxing the guarantee so that the "unimportant" tokens can be generated faster. Our approach relies on a semi-greedy search algorithm to test which of the mismatches between target and draft model should be corrected to preserve quality, and which ones may be skipped. We then train a lightweight classifier based on existing LLM embeddings to predict, at inference time, which mismatching tokens can be safely accepted without compromising the final answer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B (target) models on zero-shot GSM8K reasoning, where it achieves up to 1.5x more accepted tokens per verification cycle with under 1% degradation in answer accuracy compared to standard speculative decoding and over 2x with small loss in accuracy. When applied to the LiveCodeBench benchmark, our approach automatically detects other, programming-specific important tokens and shows similar speedups, demonstrating its ability to generalize across tasks.</li>
</ul>

<h3>Title: MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion</h3>
<ul>
<li><strong>Authors: </strong>Zador Pataki, Paul-Edouard Sarlin, Johannes L. Schönberger, Marc Pollefeys</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20040">https://arxiv.org/abs/2504.20040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20040">https://arxiv.org/pdf/2504.20040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20040]] MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion(https://arxiv.org/abs/2504.20040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While Structure-from-Motion (SfM) has seen much progress over the years, state-of-the-art systems are prone to failure when facing extreme viewpoint changes in low-overlap, low-parallax or high-symmetry scenarios. Because capturing images that avoid these pitfalls is challenging, this severely limits the wider use of SfM, especially by non-expert users. We overcome these limitations by augmenting the classical SfM paradigm with monocular depth and normal priors inferred by deep neural networks. Thanks to a tight integration of monocular and multi-view constraints, our approach significantly outperforms existing ones under extreme viewpoint changes, while maintaining strong performance in standard conditions. We also show that monocular priors can help reject faulty associations due to symmetries, which is a long-standing problem for SfM. This makes our approach the first capable of reliably reconstructing challenging indoor environments from few images. Through principled uncertainty propagation, it is robust to errors in the priors, can handle priors inferred by different models with little tuning, and will thus easily benefit from future progress in monocular depth and normal estimation. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Learning Streaming Video Representation via Multitask Training</h3>
<ul>
<li><strong>Authors: </strong>Yibin Yan, Jilan Xu, Shangzhe Di, Yikun Liu, Yudi Shi, Qirui Chen, Zeqian Li, Yifei Huang, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20041">https://arxiv.org/abs/2504.20041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20041">https://arxiv.org/pdf/2504.20041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20041]] Learning Streaming Video Representation via Multitask Training(https://arxiv.org/abs/2504.20041)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Understanding continuous video streams plays a fundamental role in real-time applications including embodied AI and autonomous driving. Unlike offline video understanding, streaming video understanding requires the ability to process video streams frame by frame, preserve historical information, and make low-latency this http URL address these challenges, our main contributions are three-fold. (i) We develop a novel streaming video backbone, termed as StreamFormer, by incorporating causal temporal attention into a pre-trained vision transformer. This enables efficient streaming video processing while maintaining image representation capability.(ii) To train StreamFormer, we propose to unify diverse spatial-temporal video understanding tasks within a multitask visual-language alignment framework. Hence, StreamFormer learns global semantics, temporal dynamics, and fine-grained spatial relationships simultaneously. (iii) We conduct extensive experiments on online action detection, online video instance segmentation, and video question answering. StreamFormer achieves competitive results while maintaining efficiency, demonstrating its potential for real-time applications.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
