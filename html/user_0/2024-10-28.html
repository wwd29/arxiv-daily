<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-10-28</h1>
<h3>Title: VehicleSDF: A 3D generative model for constrained engineering design via surrogate modeling</h3>
<ul>
<li><strong>Authors: </strong>Hayata Morita, Kohei Shintani, Chenyang Yuan, Frank Permenter</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.18986">https://arxiv.org/abs/2410.18986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.18986">https://arxiv.org/pdf/2410.18986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.18986]] VehicleSDF: A 3D generative model for constrained engineering design via surrogate modeling(https://arxiv.org/abs/2410.18986)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>A main challenge in mechanical design is to efficiently explore the design space while satisfying engineering constraints. This work explores the use of 3D generative models to explore the design space in the context of vehicle development, while estimating and enforcing engineering constraints. Specifically, we generate diverse 3D models of cars that meet a given set of geometric specifications, while also obtaining quick estimates of performance parameters such as aerodynamic drag. For this, we employ a data-driven approach (using the ShapeNet dataset) to train VehicleSDF, a DeepSDF based model that represents potential designs in a latent space witch can be decoded into a 3D model. We then train surrogate models to estimate engineering parameters from this latent space representation, enabling us to efficiently optimize latent vectors to match specifications. Our experiments show that we can generate diverse 3D models while matching the specified geometric parameters. Finally, we demonstrate that other performance parameters such as aerodynamic drag can be estimated in a differentiable pipeline.</li>
</ul>

<h3>Title: Generative Topology for Shape Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Ernst RÃ¶ell, Bastian Rieck</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.18987">https://arxiv.org/abs/2410.18987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.18987">https://arxiv.org/pdf/2410.18987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.18987]] Generative Topology for Shape Synthesis(https://arxiv.org/abs/2410.18987)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The Euler Characteristic Transform (ECT) is a powerful invariant for assessing geometrical and topological characteristics of a large variety of objects, including graphs and embedded simplicial complexes. Although the ECT is invertible in theory, no explicit algorithm for general data sets exists. In this paper, we address this lack and demonstrate that it is possible to learn the inversion, permitting us to develop a novel framework for shape generation tasks on point clouds. Our model exhibits high quality in reconstruction and generation tasks, affords efficient latent-space interpolation, and is orders of magnitude faster than existing methods.</li>
</ul>

<h3>Title: Make LLMs better zero-shot reasoners: Structure-orientated autonomous reasoning</h3>
<ul>
<li><strong>Authors: </strong>Pengfei He, Zitao Li, Yue Xing, Yaling Li, Jiliang Tang, Bolin Ding</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19000">https://arxiv.org/abs/2410.19000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19000">https://arxiv.org/pdf/2410.19000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19000]] Make LLMs better zero-shot reasoners: Structure-orientated autonomous reasoning(https://arxiv.org/abs/2410.19000)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Zero-shot reasoning methods with Large Language Models (LLMs) offer significant advantages including great generalization to novel tasks and reduced dependency on human-crafted examples. However, the current zero-shot methods still have limitations in complex tasks, e.g., answering questions that require multi-step reasoning. In this paper, we address this limitation by introducing a novel structure-oriented analysis method to help LLMs better understand the question and guide the problem-solving process of LLMs. We first demonstrate how the existing reasoning strategies, Chain-of-Thought and ReAct, can benefit from our structure-oriented analysis. In addition to empirical investigations, we leverage the probabilistic graphical model to theoretically explain why our structure-oriented analysis can improve the LLM reasoning process. To further improve the reliability in complex question-answering tasks, we propose a multi-agent reasoning system, Structure-oriented Autonomous Reasoning Agents (SARA), that can better enforce the reasoning process following our structure-oriented analysis by refinement techniques and is equipped with external knowledge retrieval capability to reduce factual errors. Extensive experiments verify the effectiveness of the proposed reasoning system. Surprisingly, in some cases, the system even surpasses few-shot methods. Finally, the system not only improves reasoning accuracy in complex tasks but also demonstrates robustness against potential attacks that corrupt the reasoning process.</li>
</ul>

<h3>Title: Whither Bias Goes, I Will Go: An Integrative, Systematic Review of Algorithmic Bias Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Louis Hickman, Christopher Huynh, Jessica Gass, Brandon Booth, Jason Kuruzovich, Louis Tay</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19003">https://arxiv.org/abs/2410.19003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19003">https://arxiv.org/pdf/2410.19003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19003]] Whither Bias Goes, I Will Go: An Integrative, Systematic Review of Algorithmic Bias Mitigation(https://arxiv.org/abs/2410.19003)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) models are increasingly used for personnel assessment and selection (e.g., resume screeners, automatically scored interviews). However, concerns have been raised throughout society that ML assessments may be biased and perpetuate or exacerbate inequality. Although organizational researchers have begun investigating ML assessments from traditional psychometric and legal perspectives, there is a need to understand, clarify, and integrate fairness operationalizations and algorithmic bias mitigation methods from the computer science, data science, and organizational research literatures. We present a four-stage model of developing ML assessments and applying bias mitigation methods, including 1) generating the training data, 2) training the model, 3) testing the model, and 4) deploying the model. When introducing the four-stage model, we describe potential sources of bias and unfairness at each stage. Then, we systematically review definitions and operationalizations of algorithmic bias, legal requirements governing personnel selection from the United States and Europe, and research on algorithmic bias mitigation across multiple domains and integrate these findings into our framework. Our review provides insights for both research and practice by elucidating possible mechanisms of algorithmic bias while identifying which bias mitigation methods are legal and effective. This integrative framework also reveals gaps in the knowledge of algorithmic bias mitigation that should be addressed by future collaborative research between organizational researchers, computer scientists, and data scientists. We provide recommendations for developing and deploying ML assessments, as well as recommendations for future research into algorithmic bias and fairness.</li>
</ul>

<h3>Title: Dual Space Training for GANs: A Pathway to Efficient and Creative Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Beka Modrekiladze</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19009">https://arxiv.org/abs/2410.19009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19009">https://arxiv.org/pdf/2410.19009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19009]] Dual Space Training for GANs: A Pathway to Efficient and Creative Generative Models(https://arxiv.org/abs/2410.19009)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Adversarial Networks (GANs) have demonstrated remarkable advancements in generative modeling; however, their training is often resource-intensive, requiring extensive computational time and hundreds of thousands of epochs. This paper proposes a novel optimization approach that transforms the training process by operating within a dual space of the initial data using invertible mappings, specifically autoencoders. By training GANs on the encoded representations in the dual space, which encapsulate the most salient features of the data, the generative process becomes significantly more efficient and potentially reveals underlying patterns beyond human recognition. This approach not only enhances training speed and resource usage but also explores the philosophical question of whether models can generate insights that transcend the human intelligence while being limited by the human-generated data.</li>
</ul>

<h3>Title: Privacy-Computation trade-offs in Private Repetition and Metaselection</h3>
<ul>
<li><strong>Authors: </strong>Kunal Talwar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DS, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19012">https://arxiv.org/abs/2410.19012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19012">https://arxiv.org/pdf/2410.19012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19012]] Privacy-Computation trade-offs in Private Repetition and Metaselection(https://arxiv.org/abs/2410.19012)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>A Private Repetition algorithm takes as input a differentially private algorithm with constant success probability and boosts it to one that succeeds with high probability. These algorithms are closely related to private metaselection algorithms that compete with the best of many private algorithms, and private hyperparameter tuning algorithms that compete with the best hyperparameter settings for a private learning algorithm. Existing algorithms for these tasks pay either a large overhead in privacy cost, or a large overhead in computational cost. In this work, we show strong lower bounds for problems of this kind, showing in particular that for any algorithm that preserves the privacy cost up to a constant factor, the failure probability can only fall polynomially in the computational overhead. This is in stark contrast with the non-private setting, where the failure probability falls exponentially in the computational overhead. By carefully combining existing algorithms for metaselection, we prove computation-privacy tradeoffs that nearly match our lower bounds.</li>
</ul>

<h3>Title: IBAC Mathematics and Mechanics: The Case for 'Integer Based Access Control' of Data Security in the Age of AI and AI Automation</h3>
<ul>
<li><strong>Authors: </strong>Mark Stocks</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19021">https://arxiv.org/abs/2410.19021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19021">https://arxiv.org/pdf/2410.19021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19021]] IBAC Mathematics and Mechanics: The Case for 'Integer Based Access Control' of Data Security in the Age of AI and AI Automation(https://arxiv.org/abs/2410.19021)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, federate</a></li>
<li><strong>Abstract: </strong>Current methods for data access control, especially regarding AI and AI automation, face unique challenges in ensuring appropriate data access. We introduce Integer-Based Access Control (IBAC), addressing the limitations of Role-Based Access Control (RBAC) and Attribute-Based Access Control (ABAC). IBAC's mathematical foundations enable its application to relational and NoSQL databases, as well as document authorization. We demonstrate IBAC's suitability for filtering relational database row-level information and AI and NLP access based on separation of duty, supporting both "need to know" and "need to share" data restrictions. IBAC uses security tokens, which are integers representing aggregated security attributes. These tokens maintain orthogonality across encoded attributes but are stored as integers for fast real-time vector comparison and efficient dominance testing. This mechanism allows high-speed row-level result filtering, ensuring unauthorized records are excluded before results reach the requester. We extend the Bell-LaPadula model by incorporating a "process constraint," overcoming RBAC and ABAC limitations with reduced complexity, increased flexibility, and enhanced performance in data filtering. Our theorems demonstrate the extended Dominance relationship, facilitating rapid federated authorization across diverse databases and file systems. This work reaffirms the practical strength of the Bell-LaPadula model in data security through (1) our mathematical extension, (2) a novel IBAC security attribute encoding scheme, and (3) a simplified dominance testing mechanism for security tokens without decoding.</li>
</ul>

<h3>Title: Large Language Models for Financial Aid in Financial Time-series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Md Khairul Islam, Ayush Karmacharya, Timothy Sue, Judy Fox</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19025">https://arxiv.org/abs/2410.19025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19025">https://arxiv.org/pdf/2410.19025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19025]] Large Language Models for Financial Aid in Financial Time-series Forecasting(https://arxiv.org/abs/2410.19025)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Considering the difficulty of financial time series forecasting in financial aid, much of the current research focuses on leveraging big data analytics in financial services. One modern approach is to utilize "predictive analysis", analogous to forecasting financial trends. However, many of these time series data in Financial Aid (FA) pose unique challenges due to limited historical datasets and high dimensional financial information, which hinder the development of effective predictive models that balance accuracy with efficient runtime and memory usage. Pre-trained foundation models are employed to address these challenging tasks. We use state-of-the-art time series models including pre-trained LLMs (GPT-2 as the backbone), transformers, and linear models to demonstrate their ability to outperform traditional approaches, even with minimal ("few-shot") or no fine-tuning ("zero-shot"). Our benchmark study, which includes financial aid with seven other time series tasks, shows the potential of using LLMs for scarce financial datasets.</li>
</ul>

<h3>Title: Mixture of Parrots: Experts improve memorization more than reasoning</h3>
<ul>
<li><strong>Authors: </strong>Samy Jelassi, Clara Mohri, David Brandfonbrener, Alex Gu, Nikhil Vyas, Nikhil Anand, David Alvarez-Melis, Yuanzhi Li, Sham M. Kakade, Eran Malach</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19034">https://arxiv.org/abs/2410.19034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19034">https://arxiv.org/pdf/2410.19034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19034]] Mixture of Parrots: Experts improve memorization more than reasoning(https://arxiv.org/abs/2410.19034)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Mixture-of-Experts (MoE) architecture enables a significant increase in the total number of model parameters with minimal computational overhead. However, it is not clear what performance tradeoffs, if any, exist between MoEs and standard dense transformers. In this paper, we show that as we increase the number of experts (while fixing the number of active parameters), the memorization performance consistently increases while the reasoning capabilities saturate. We begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph problems that cannot be solved by any number of experts of a certain width; however, the same task can be easily solved by a dense model with a slightly larger width. On the other hand, we find that on memory-intensive tasks, MoEs can effectively leverage a small number of active parameters with a large number of experts to memorize the data. We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks. Lastly, we pre-train a series of MoEs and dense transformers and evaluate them on commonly used benchmarks in math and natural language. We find that increasing the number of experts helps solve knowledge-intensive tasks, but fails to yield the same benefits for reasoning tasks.</li>
</ul>

<h3>Title: An Investigation on Machine Learning Predictive Accuracy Improvement and Uncertainty Reduction using VAE-based Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Farah Alsafadi, Mahmoud Yaseen, Xu Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19063">https://arxiv.org/abs/2410.19063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19063">https://arxiv.org/pdf/2410.19063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19063]] An Investigation on Machine Learning Predictive Accuracy Improvement and Uncertainty Reduction using VAE-based Data Augmentation(https://arxiv.org/abs/2410.19063)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The confluence of ultrafast computers with large memory, rapid progress in Machine Learning (ML) algorithms, and the availability of large datasets place multiple engineering fields at the threshold of dramatic progress. However, a unique challenge in nuclear engineering is data scarcity because experimentation on nuclear systems is usually more expensive and time-consuming than most other disciplines. One potential way to resolve the data scarcity issue is deep generative learning, which uses certain ML models to learn the underlying distribution of existing data and generate synthetic samples that resemble the real data. In this way, one can significantly expand the dataset to train more accurate predictive ML models. In this study, our objective is to evaluate the effectiveness of data augmentation using variational autoencoder (VAE)-based deep generative models. We investigated whether the data augmentation leads to improved accuracy in the predictions of a deep neural network (DNN) model trained using the augmented data. Additionally, the DNN prediction uncertainties are quantified using Bayesian Neural Networks (BNN) and conformal prediction (CP) to assess the impact on predictive uncertainty reduction. To test the proposed methodology, we used TRACE simulations of steady-state void fraction data based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark. We found that augmenting the training dataset using VAEs has improved the DNN model's predictive accuracy, improved the prediction confidence intervals, and reduced the prediction uncertainties.</li>
</ul>

<h3>Title: BIFR\"OST: 3D-Aware Image compositing with Language Instructions</h3>
<ul>
<li><strong>Authors: </strong>Lingxiao Li, Kaixiong Gong, Weihong Li, Xili Dai, Tao Chen, Xiaojun Yuan, Xiangyu Yue</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19079">https://arxiv.org/abs/2410.19079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19079">https://arxiv.org/pdf/2410.19079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19079]] BIFR\"OST: 3D-Aware Image compositing with Language Instructions(https://arxiv.org/abs/2410.19079)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces BifrÃ¶st, a novel 3D-aware framework that is built upon diffusion models to perform instruction-based image composition. Previous methods concentrate on image compositing at the 2D level, which fall short in handling complex spatial relationships ($\textit{e.g.}$, occlusion). BifrÃ¶st addresses these issues by training MLLM as a 2.5D location predictor and integrating depth maps as an extra condition during the generation process to bridge the gap between 2D and 3D, which enhances spatial comprehension and supports sophisticated spatial interactions. Our method begins by fine-tuning MLLM with a custom counterfactual dataset to predict 2.5D object locations in complex backgrounds from language instructions. Then, the image-compositing model is uniquely designed to process multiple types of input features, enabling it to perform high-fidelity image compositions that consider occlusion, depth blur, and image harmonization. Extensive qualitative and quantitative evaluations demonstrate that BifrÃ¶st significantly outperforms existing methods, providing a robust solution for generating realistically composed images in scenarios demanding intricate spatial understanding. This work not only pushes the boundaries of generative image compositing but also reduces reliance on expensive annotated datasets by effectively utilizing existing resources in innovative ways.</li>
</ul>

<h3>Title: FastSurvival: Hidden Computational Blessings in Training Cox Proportional Hazards Models</h3>
<ul>
<li><strong>Authors: </strong>Jiachang Liu, Rui Zhang, Cynthia Rudin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19081">https://arxiv.org/abs/2410.19081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19081">https://arxiv.org/pdf/2410.19081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19081]] FastSurvival: Hidden Computational Blessings in Training Cox Proportional Hazards Models(https://arxiv.org/abs/2410.19081)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Survival analysis is an important research topic with applications in healthcare, business, and manufacturing. One essential tool in this area is the Cox proportional hazards (CPH) model, which is widely used for its interpretability, flexibility, and predictive performance. However, for modern data science challenges such as high dimensionality (both $n$ and $p$) and high feature correlations, current algorithms to train the CPH model have drawbacks, preventing us from using the CPH model at its full potential. The root cause is that the current algorithms, based on the Newton method, have trouble converging due to vanishing second order derivatives when outside the local region of the minimizer. To circumvent this problem, we propose new optimization methods by constructing and minimizing surrogate functions that exploit hidden mathematical structures of the CPH model. Our new methods are easy to implement and ensure monotonic loss decrease and global convergence. Empirically, we verify the computational efficiency of our methods. As a direct application, we show how our optimization methods can be used to solve the cardinality-constrained CPH problem, producing very sparse high-quality models that were not previously practical to construct. We list several extensions that our breakthrough enables, including optimization opportunities, theoretical questions on CPH's mathematical structure, as well as other CPH-related applications.</li>
</ul>

<h3>Title: GCoder: Improving Large Language Model for Generalized Graph Problem Solving</h3>
<ul>
<li><strong>Authors: </strong>Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19084">https://arxiv.org/abs/2410.19084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19084">https://arxiv.org/pdf/2410.19084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19084]] GCoder: Improving Large Language Model for Generalized Graph Problem Solving(https://arxiv.org/abs/2410.19084)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong reasoning abilities, making them suitable for complex tasks such as graph computation. Traditional reasoning steps paradigm for graph problems is hindered by unverifiable steps, limited long-term reasoning, and poor generalization to graph variations. To overcome these limitations, we introduce GCoder, a code-based LLM designed to enhance problem-solving in generalized graph computation problems. Our method involves constructing an extensive training dataset, GraphWild, featuring diverse graph formats and algorithms. We employ a multi-stage training process, including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid retrieval technique is used to augment performance. Experiments demonstrate that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42% across various graph computational problems. Furthermore, GCoder efficiently manages large-scale graphs with millions of nodes and diverse input formats, overcoming the limitations of previous models focused on the reasoning steps paradigm. This advancement paves the way for more intuitive and effective graph problem-solving using LLMs. Code and data are available at here: this https URL.</li>
</ul>

<h3>Title: A Counterexample in Cross-Correlation Template Matching</h3>
<ul>
<li><strong>Authors: </strong>Serap A. Savari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19085">https://arxiv.org/abs/2410.19085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19085">https://arxiv.org/pdf/2410.19085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19085]] A Counterexample in Cross-Correlation Template Matching(https://arxiv.org/abs/2410.19085)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Sampling and quantization are standard practices in signal and image processing, but a theoretical understanding of their impact is incomplete. We consider discrete image registration when the underlying function is a one-dimensional spatially-limited piecewise constant function. For ideal noiseless sampling the number of samples from each region of the support of the function generally depends on the placement of the sampling grid. Therefore, if the samples of the function are noisy, then image registration requires alignment and segmentation of the data sequences. One popular strategy for aligning images is selecting the maximum from cross-correlation template matching. To motivate more robust and accurate approaches which also address segmentation, we provide an example of a one-dimensional spatially-limited piecewise constant function for which the cross-correlation technique can perform poorly on noisy samples. While earlier approaches to improve the method involve normalization, our example suggests a novel strategy in our setting. Difference sequences, thresholding, and dynamic programming are well-known techniques in image processing. We prove that they are tools to correctly align and segment noisy data sequences under some conditions on the noise. We also address some of the potential difficulties that could arise in a more general case.</li>
</ul>

<h3>Title: Watermarking Large Language Models and the Generated Content: Opportunities and Challenges</h3>
<ul>
<li><strong>Authors: </strong>Ruisi Zhang, Farinaz Koushanfar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19096">https://arxiv.org/abs/2410.19096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19096">https://arxiv.org/pdf/2410.19096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19096]] Watermarking Large Language Models and the Generated Content: Opportunities and Challenges(https://arxiv.org/abs/2410.19096)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, watermark, generative, large language model</a></li>
<li><strong>Abstract: </strong>The widely adopted and powerful generative large language models (LLMs) have raised concerns about intellectual property rights violations and the spread of machine-generated misinformation. Watermarking serves as a promising approch to establish ownership, prevent unauthorized use, and trace the origins of LLM-generated content. This paper summarizes and shares the challenges and opportunities we found when watermarking LLMs. We begin by introducing techniques for watermarking LLMs themselves under different threat models and scenarios. Next, we investigate watermarking methods designed for the content generated by LLMs, assessing their effectiveness and resilience against various attacks. We also highlight the importance of watermarking domain-specific models and data, such as those used in code generation, chip design, and medical applications. Furthermore, we explore methods like hardware acceleration to improve the efficiency of the watermarking process. Finally, we discuss the limitations of current approaches and outline future research directions for the responsible use and protection of these generative AI tools.</li>
</ul>

<h3>Title: TesseraQ: Ultra Low-Bit LLM Post-Training Quantization with Block Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Li, Priyadarshini Panda</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19103">https://arxiv.org/abs/2410.19103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19103">https://arxiv.org/pdf/2410.19103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19103]] TesseraQ: Ultra Low-Bit LLM Post-Training Quantization with Block Reconstruction(https://arxiv.org/abs/2410.19103)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized natural language processing, albeit at the cost of immense memory and computation requirements. Post-training quantization (PTQ) is becoming the de facto method to reduce the memory footprint and improve the inference throughput of LLMs. In this work, we aim to push the upper limit of LLM PTQ by optimizing the weight rounding parameters with the block reconstruction technique, a predominant method in previous vision models. We propose TesseraQ, a new state-of-the-art PTQ technique, to quantize the weights of LLMs to ultra-low bits. To effectively optimize the rounding in LLMs and stabilize the reconstruction process, we introduce progressive adaptive rounding. This approach iteratively transits the soft rounding variables to hard variables during the reconstruction process. Additionally, we optimize the dequantization scale parameters to fully leverage the block reconstruction technique. We demonstrate that TesseraQ can be seamlessly integrated with existing scaling or clipping-based PTQ algorithms such as AWQ and OmniQuant, significantly enhancing their performance and establishing a new state-of-the-art. For instance, when compared to AWQ, TesseraQ improves the wikitext2 perplexity from 14.65 to 6.82 and average downstream accuracy from 50.52 to 59.27 with 2-bit weight-only quantization of LLaMA-2-7B. Across a range of quantization schemes, including W2A16, W3A16, W3A3, and W4A4, TesseraQ consistently exhibits superior performance.</li>
</ul>

<h3>Title: LanFL: Differentially Private Federated Learning with Large Language Models using Synthetic Samples</h3>
<ul>
<li><strong>Authors: </strong>Huiyu Wu, Diego Klabjan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19114">https://arxiv.org/abs/2410.19114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19114">https://arxiv.org/pdf/2410.19114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19114]] LanFL: Differentially Private Federated Learning with Large Language Models using Synthetic Samples(https://arxiv.org/abs/2410.19114)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a collaborative, privacy-preserving machine learning framework that enables multiple participants to train a single global model. However, the recent advent of powerful Large Language Models (LLMs) with tens to hundreds of billions of parameters makes the naive application of traditional FL methods to LLMs impractical due to high computational and communication costs. Furthermore, end users of LLMs often lack access to full architectures and weights of the models, making it impossible for participants to fine-tune these models directly. This paper introduces a novel FL scheme for LLMs, named LanFL, which is purely prompt-based and treats the underlying LLMs as black boxes. We have developed a differentially private synthetic sample generation mechanism to facilitate knowledge sharing among participants, along with a prompt optimization scheme that enables learning from synthetic samples. Our extensive experiments demonstrate that LanFL successfully facilitates learning among participants while preserving the privacy of local datasets across various tasks.</li>
</ul>

<h3>Title: MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision</h3>
<ul>
<li><strong>Authors: </strong>Ruicheng Wang, Sicheng Xu, Cassie Dai, Jianfeng Xiang, Yu Deng, Xin Tong, Jiaolong Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19115">https://arxiv.org/abs/2410.19115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19115">https://arxiv.org/pdf/2410.19115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19115]] MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision(https://arxiv.org/abs/2410.19115)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present MoGe, a powerful model for recovering 3D geometry from monocular open-domain images. Given a single image, our model directly predicts a 3D point map of the captured scene with an affine-invariant representation, which is agnostic to true global scale and shift. This new representation precludes ambiguous supervision in training and facilitate effective geometry learning. Furthermore, we propose a set of novel global and local geometry supervisions that empower the model to learn high-quality geometry. These include a robust, optimal, and efficient point cloud alignment solver for accurate global shape learning, and a multi-scale local geometry loss promoting precise local geometry supervision. We train our model on a large, mixed dataset and demonstrate its strong generalizability and high accuracy. In our comprehensive evaluation on diverse unseen datasets, our model significantly outperforms state-of-the-art methods across all tasks, including monocular estimation of 3D point map, depth map, and camera field of view. Code and models will be released on our project page.</li>
</ul>

<h3>Title: LLM Tree Search</h3>
<ul>
<li><strong>Authors: </strong>Dylan Wilson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19117">https://arxiv.org/abs/2410.19117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19117">https://arxiv.org/pdf/2410.19117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19117]] LLM Tree Search(https://arxiv.org/abs/2410.19117)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This project aims to investigate a novel sequence generation method inspired by the AlphaGo paradigm, adapting it for use with large language models (LLMs). The proposed approach involves creating search trees of different possible completions and evaluating these completions based on model confidence. By considering various paths in the search tree and scoring them according to the model's confidence in each completion, we can generate diverse and high-quality sequences. This research explores the implementation of this paradigm by using confidence as a proxy for response quality akin to beam search \citep{vijayakumar2016diverse}. The primary goal of this paper is to outline the paradigm and demonstrate its potential, rather than focusing on achieving perfect results. The paper will outline the reasons why we believe this paradigm has the potential to improve LLMs in the following manners: 1) increase output quality, 2) decrease errors, 3) eliminate or reduce the compound error problems, 4) generate diverse and creative completions, 5) allow for iterative problem-solving, and 6) self-training. We expect this approach to yield a set of diverse and coherent sequences, offering insights into balancing exploration and exploitation in sequence generation. Potential applications include creative text generation tasks, such as storytelling and content creation, as well as other natural language processing domains, like machine translation and automated summarization. The goal is that the model will be far more effective as it will be able to consider many possible variations allowing it to find the ideal completion. This research aims to contribute to the understanding of effective search strategies in sequence generation and their impact on generating high-quality, varied textual outputs.</li>
</ul>

<h3>Title: Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design</h3>
<ul>
<li><strong>Authors: </strong>Ruisi Cai, Yeonju Ro, Geon-Woo Kim, Peihao Wang, Babak Ehteshami Bejnordi, Aditya Akella, Zhangyang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19123">https://arxiv.org/abs/2410.19123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19123">https://arxiv.org/pdf/2410.19123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19123]] Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design(https://arxiv.org/abs/2410.19123)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of large language models (LLMs) has led to the adoption of Mixture-of-Experts (MoE) architectures that dynamically leverage specialized subnetworks for improved efficiency and performance. Despite their benefits, MoE models face significant challenges during inference, including inefficient memory management and suboptimal batching, due to misaligned design choices between the model architecture and the system policies. Furthermore, the conventional approach of training MoEs from scratch is increasingly prohibitive in terms of cost. In this paper, we propose a novel framework Read-ME that transforms pre-trained dense LLMs into smaller MoE models (in contrast to "upcycling" generalist MoEs), avoiding the high costs of ground-up training. Our approach employs activation sparsity to extract experts. To compose experts, we examine the widely-adopted layer-wise router design and show its redundancy, and thus we introduce the pre-gating router decoupled from the MoE backbone that facilitates system-friendly pre-computing and lookahead scheduling, enhancing expert-aware batching and caching. Our codesign therefore addresses critical gaps on both the algorithmic and system fronts, establishing a scalable and efficient alternative for LLM inference in resource-constrained settings. Read-ME outperforms other popular open-source dense models of similar scales, achieving improvements of up to 10.1% on MMLU, and improving mean end-to-end latency up to 6.1%. Codes are available at: this https URL.</li>
</ul>

<h3>Title: Retrieving Implicit and Explicit Emotional Events Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guimin Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19128">https://arxiv.org/abs/2410.19128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19128">https://arxiv.org/pdf/2410.19128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19128]] Retrieving Implicit and Explicit Emotional Events Using Large Language Models(https://arxiv.org/abs/2410.19128)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have garnered significant attention in recent years due to their impressive performance. While considerable research has evaluated these models from various perspectives, the extent to which LLMs can perform implicit and explicit emotion retrieval remains largely unexplored. To address this gap, this study investigates LLMs' emotion retrieval capabilities in commonsense. Through extensive experiments involving multiple models, we systematically evaluate the ability of LLMs on emotion retrieval. Specifically, we propose a supervised contrastive probing method to verify LLMs' performance for implicit and explicit emotion retrieval, as well as the diversity of the emotional events they retrieve. The results offer valuable insights into the strengths and limitations of LLMs in handling emotion retrieval.</li>
</ul>

<h3>Title: Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haowei Yang, Mingxiu Sui, Shaobo Liu, Xinyue Qian, Zhaoyang Zhang, Bingying Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19130">https://arxiv.org/abs/2410.19130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19130">https://arxiv.org/pdf/2410.19130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19130]] Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models(https://arxiv.org/abs/2410.19130)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, federate, large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development of natural language processing technology, large language models have demonstrated exceptional performance in various application scenarios. However, training these models requires significant computational resources and data processing capabilities. Cross-cloud federated training offers a new approach to addressing the resource bottlenecks of a single cloud platform, allowing the computational resources of multiple clouds to collaboratively complete the training tasks of large models. This study analyzes the key technologies of cross-cloud federated training, including data partitioning and distribution, communication optimization, model aggregation algorithms, and the compatibility of heterogeneous cloud platforms. Additionally, the study examines data security and privacy protection strategies in cross-cloud training, particularly the application of data encryption and differential privacy techniques. Through experimental validation, the proposed technical framework demonstrates enhanced training efficiency, ensured data security, and reduced training costs, highlighting the broad application prospects of cross-cloud federated training.</li>
</ul>

<h3>Title: AlignCap: Aligning Speech Emotion Captioning to Human Preferences</h3>
<ul>
<li><strong>Authors: </strong>Ziqi Liang, Haoxiang Shi, Hanhui Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19134">https://arxiv.org/abs/2410.19134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19134">https://arxiv.org/pdf/2410.19134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19134]] AlignCap: Aligning Speech Emotion Captioning to Human Preferences(https://arxiv.org/abs/2410.19134)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speech Emotion Captioning (SEC) has gradually become an active research task. The emotional content conveyed through human speech are often complex, and classifying them into fixed categories may not be enough to fully capture speech emotions. Describing speech emotions through natural language may be a more effective approach. However, existing SEC methods often produce hallucinations and lose generalization on unseen speech. To overcome these problems, we propose AlignCap, which Aligning Speech Emotion Captioning to Human Preferences based on large language model (LLM) with two properties: 1) Speech-Text Alignment, which minimizing the divergence between the LLM's response prediction distributions for speech and text inputs using knowledge distillation (KD) Regularization. 2) Human Preference Alignment, where we design Preference Optimization (PO) Regularization to eliminate factuality and faithfulness hallucinations. We also extract emotional clues as a prompt for enriching fine-grained information under KD-Regularization. Experiments demonstrate that AlignCap presents stronger performance to other state-of-the-art methods on Zero-shot SEC task.</li>
</ul>

<h3>Title: Context-Aware Trajectory Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Haoji Hu, Jina Kim, Jinwei Zhou, Sofia Kirsanova, JangHyeon Lee, Yao-Yi Chiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19136">https://arxiv.org/abs/2410.19136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19136">https://arxiv.org/pdf/2410.19136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19136]] Context-Aware Trajectory Anomaly Detection(https://arxiv.org/abs/2410.19136)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Trajectory anomaly detection is crucial for effective decision-making in urban and human mobility management. Existing methods of trajectory anomaly detection generally focus on training a trajectory generative model and evaluating the likelihood of reconstructing a given trajectory. However, previous work often lacks important contextual information on the trajectory, such as the agent's information (e.g., agent ID) or geographic information (e.g., Points of Interest (POI)), which could provide additional information on accurately capturing anomalous behaviors. To fill this gap, we propose a context-aware anomaly detection approach that models contextual information related to trajectories. The proposed method is based on a trajectory reconstruction framework guided by contextual factors such as agent ID and contextual POI embedding. The injection of contextual information aims to improve the performance of anomaly detection. We conducted experiments in two cities and demonstrated that the proposed approach significantly outperformed existing methods by effectively modeling contextual information. Overall, this paper paves a new direction for advancing trajectory anomaly detection.</li>
</ul>

<h3>Title: Structured Diffusion Models with Mixture of Gaussians as Prior Distribution</h3>
<ul>
<li><strong>Authors: </strong>Nanshan Jia, Tingyu Zhu, Haoyu Liu, Zeyu Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19149">https://arxiv.org/abs/2410.19149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19149">https://arxiv.org/pdf/2410.19149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19149]] Structured Diffusion Models with Mixture of Gaussians as Prior Distribution(https://arxiv.org/abs/2410.19149)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We propose a class of structured diffusion models, in which the prior distribution is chosen as a mixture of Gaussians, rather than a standard Gaussian distribution. The specific mixed Gaussian distribution, as prior, can be chosen to incorporate certain structured information of the data. We develop a simple-to-implement training procedure that smoothly accommodates the use of mixed Gaussian as prior. Theory is provided to quantify the benefits of our proposed models, compared to the classical diffusion models. Numerical experiments with synthetic, image and operational data are conducted to show comparative advantages of our model. Our method is shown to be robust to mis-specifications and in particular suits situations where training resources are limited or faster training in real time is desired.</li>
</ul>

<h3>Title: Learning Coupled Subspaces for Multi-Condition Spike Data</h3>
<ul>
<li><strong>Authors: </strong>Yididiya Y. Nadew, Xuhui Fan, Christopher J. Quinn</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19153">https://arxiv.org/abs/2410.19153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19153">https://arxiv.org/pdf/2410.19153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19153]] Learning Coupled Subspaces for Multi-Condition Spike Data(https://arxiv.org/abs/2410.19153)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In neuroscience, researchers typically conduct experiments under multiple conditions to acquire neural responses in the form of high-dimensional spike train datasets. Analysing high-dimensional spike data is a challenging statistical problem. To this end, Gaussian process factor analysis (GPFA), a popular class of latent variable models has been proposed. GPFA extracts smooth, low-dimensional latent trajectories underlying high-dimensional spike train datasets. However, such analyses are often done separately for each experimental condition, contrary to the nature of neural datasets, which contain recordings under multiple experimental conditions. Exploiting the parametric nature of these conditions, we propose a multi-condition GPFA model and inference procedure to learn the underlying latent structure in the corresponding datasets in sample-efficient manner. In particular, we propose a non-parametric Bayesian approach to learn a smooth tuning function over the experiment condition space. Our approach not only boosts model accuracy and is faster, but also improves model interpretability compared to approaches that separately fit models for each experimental condition.</li>
</ul>

<h3>Title: Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use</h3>
<ul>
<li><strong>Authors: </strong>Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19155">https://arxiv.org/abs/2410.19155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19155">https://arxiv.org/pdf/2410.19155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19155]] Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use(https://arxiv.org/abs/2410.19155)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Adverse Drug Reactions (ADRs) from psychiatric medications are the leading cause of hospitalizations among mental health patients. With healthcare systems and online communities facing limitations in resolving ADR-related issues, Large Language Models (LLMs) have the potential to fill this gap. Despite the increasing capabilities of LLMs, past research has not explored their capabilities in detecting ADRs related to psychiatric medications or in providing effective harm reduction strategies. To address this, we introduce the Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment (ADRA) framework to systematically evaluate LLM performance in detecting ADR expressions and delivering expert-aligned mitigation strategies. Our analyses show that LLMs struggle with understanding the nuances of ADRs and differentiating between types of ADRs. While LLMs align with experts in terms of expressed emotions and tone of the text, their responses are more complex, harder to read, and only 70.86% aligned with expert strategies. Furthermore, they provide less actionable advice by a margin of 12.32% on average. Our work provides a comprehensive benchmark and evaluation framework for assessing LLMs in strategy-driven tasks within high-risk domains.</li>
</ul>

<h3>Title: Adversarial Attacks on Large Language Models Using Regularized Relaxation</h3>
<ul>
<li><strong>Authors: </strong>Samuel Jacob Chacko, Sajib Biswas, Chashi Mahiul Islam, Fatema Tabassum Liza, Xiuwen Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19160">https://arxiv.org/abs/2410.19160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19160">https://arxiv.org/pdf/2410.19160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19160]] Adversarial Attacks on Large Language Models Using Regularized Relaxation(https://arxiv.org/abs/2410.19160)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>As powerful Large Language Models (LLMs) are now widely used for numerous practical applications, their safety is of critical importance. While alignment techniques have significantly improved overall safety, LLMs remain vulnerable to carefully crafted adversarial inputs. Consequently, adversarial attack methods are extensively used to study and understand these vulnerabilities. However, current attack methods face significant limitations. Those relying on optimizing discrete tokens suffer from limited efficiency, while continuous optimization techniques fail to generate valid tokens from the model's vocabulary, rendering them impractical for real-world applications. In this paper, we propose a novel technique for adversarial attacks that overcomes these limitations by leveraging regularized gradients with continuous optimization methods. Our approach is two orders of magnitude faster than the state-of-the-art greedy coordinate gradient-based method, significantly improving the attack success rate on aligned language models. Moreover, it generates valid tokens, addressing a fundamental limitation of existing continuous optimization methods. We demonstrate the effectiveness of our attack on five state-of-the-art LLMs using four datasets.</li>
</ul>

<h3>Title: DCT-HistoTransformer: Efficient Lightweight Vision Transformer with DCT Integration for histopathological image analysis</h3>
<ul>
<li><strong>Authors: </strong>Mahtab Ranjbar (1), Mehdi Mohebbi (1), Mahdi Cherakhloo (2), Bijan Vosoughi. Vahdat (2) ((1) Department of Mathematical and Computer Sciences, Kharazmi University, (2) Department of Medical Engineering, Electrical Engineering Department, Sharif University of Technology)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19166">https://arxiv.org/abs/2410.19166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19166">https://arxiv.org/pdf/2410.19166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19166]] DCT-HistoTransformer: Efficient Lightweight Vision Transformer with DCT Integration for histopathological image analysis(https://arxiv.org/abs/2410.19166)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, the integration of advanced imaging techniques and deep learning methods has significantly advanced computer-aided diagnosis (CAD) systems for breast cancer detection and classification. Transformers, which have shown great promise in computer vision, are now being applied to medical image analysis. However, their application to histopathological images presents challenges due to the need for extensive manual annotations of whole-slide images (WSIs), as these models require large amounts of data to work effectively, which is costly and time-consuming. Furthermore, the quadratic computational cost of Vision Transformers (ViTs) is particularly prohibitive for large, high-resolution histopathological images, especially on edge devices with limited computational resources. In this study, we introduce a novel lightweight breast cancer classification approach using transformers that operates effectively without large datasets. By incorporating parallel processing pathways for Discrete Cosine Transform (DCT) Attention and MobileConv, we convert image data from the spatial domain to the frequency domain to utilize the benefits such as filtering out high frequencies in the image, which reduces computational cost. This demonstrates the potential of our approach to improve breast cancer classification in histopathological images, offering a more efficient solution with reduced reliance on extensive annotated datasets. Our proposed model achieves an accuracy of 96.00% $\pm$ 0.48% for binary classification and 87.85% $\pm$ 0.93% for multiclass classification, which is comparable to state-of-the-art models while significantly reducing computational costs. This demonstrates the potential of our approach to improve breast cancer classification in histopathological images, offering a more efficient solution with reduced reliance on extensive annotated datasets.</li>
</ul>

<h3>Title: Noise Adaption Network for Morse Code Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Xiaxia Wang, XueSong Leng, Guoping Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19180">https://arxiv.org/abs/2410.19180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19180">https://arxiv.org/pdf/2410.19180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19180]] Noise Adaption Network for Morse Code Image Classification(https://arxiv.org/abs/2410.19180)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction</a></li>
<li><strong>Abstract: </strong>The escalating significance of information security has underscored the per-vasive role of encryption technology in safeguarding communication con-tent. Morse code, a well-established and effective encryption method, has found widespread application in telegraph communication and various do-mains. However, the transmission of Morse code images faces challenges due to diverse noises and distortions, thereby hindering comprehensive clas-sification outcomes. Existing methodologies predominantly concentrate on categorizing Morse code images affected by a single type of noise, neglecting the multitude of scenarios that noise pollution can generate. To overcome this limitation, we propose a novel two-stage approach, termed the Noise Adaptation Network (NANet), for Morse code image classification. Our method involves exclusive training on pristine images while adapting to noisy ones through the extraction of critical information unaffected by noise. In the initial stage, we introduce a U-shaped network structure designed to learn representative features and denoise images. Subsequently, the second stage employs a deep convolutional neural network for classification. By leveraging the denoising module from the first stage, our approach achieves enhanced accuracy and robustness in the subsequent classification phase. We conducted an evaluation of our approach on a diverse dataset, encom-passing Gaussian, salt-and-pepper, and uniform noise variations. The results convincingly demonstrate the superiority of our methodology over existing approaches. The datasets are available on this https URL</li>
</ul>

<h3>Title: No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts</h3>
<ul>
<li><strong>Authors: </strong>Israel Fama, BÃ¡rbara Bueno, Alexandre Alcoforado, Thomas Palmeira Ferraz, Arnold Moya, Anna Helena Reali Costa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19184">https://arxiv.org/abs/2410.19184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19184">https://arxiv.org/pdf/2410.19184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19184]] No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts(https://arxiv.org/abs/2410.19184)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In a context where the Brazilian judiciary system, the largest in the world, faces a crisis due to the slow processing of millions of cases, it becomes imperative to develop efficient methods for analyzing legal texts. We introduce uBERT, a hybrid model that combines Transformer and Recurrent Neural Network architectures to effectively handle long legal texts. Our approach processes the full text regardless of its length while maintaining reasonable computational overhead. Our experiments demonstrate that uBERT achieves superior performance compared to BERT+LSTM when overlapping input is used and is significantly faster than ULMFiT for processing long legal documents.</li>
</ul>

<h3>Title: Review of wavelet-based unsupervised texture segmentation, advantage of adaptive wavelets</h3>
<ul>
<li><strong>Authors: </strong>Yuan Huang, Valentin De Bortoli, Fugen Zhou, Jerome Gilles</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19191">https://arxiv.org/abs/2410.19191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19191">https://arxiv.org/pdf/2410.19191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19191]] Review of wavelet-based unsupervised texture segmentation, advantage of adaptive wavelets(https://arxiv.org/abs/2410.19191)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Wavelet-based segmentation approaches are widely used for texture segmentation purposes because of their ability to characterize different textures. In this paper, we assess the influence of the chosen wavelet and propose to use the recently introduced empirical wavelets. We show that the adaptability of the empirical wavelet permits to reach better results than classic wavelets. In order to focus only on the textural information, we also propose to perform a cartoon + texture decomposition step before applying the segmentation algorithm. The proposed method is tested on six classic benchmarks, based on several popular texture images.</li>
</ul>

<h3>Title: Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media</h3>
<ul>
<li><strong>Authors: </strong>Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19193">https://arxiv.org/abs/2410.19193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19193">https://arxiv.org/pdf/2410.19193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19193]] Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media(https://arxiv.org/abs/2410.19193)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Disinformation on social media poses both societal and technical challenges. While previous studies have integrated textual information into propagation networks, they have yet to fully leverage the advancements in Transformer-based language models for high-quality contextual text representations. This work investigates the impact of incorporating textual features into Graph Neural Networks (GNNs) for fake news detection. Our experiments demonstrate that contextual representations improve performance by 9.3% in Macro F1 over static ones and 33.8% over GNNs without textual features. However, noisy data augmentation degrades performance and increases instability. We expect our methodology to open avenues for further research, and all code is made publicly available.</li>
</ul>

<h3>Title: Classifying Bicycle Infrastructure Using On-Bike Street-Level Images</h3>
<ul>
<li><strong>Authors: </strong>Kal Backman, Ben Beck, Dana KuliÄ</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19194">https://arxiv.org/abs/2410.19194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19194">https://arxiv.org/pdf/2410.19194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19194]] Classifying Bicycle Infrastructure Using On-Bike Street-Level Images(https://arxiv.org/abs/2410.19194)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While cycling offers an attractive option for sustainable transportation, many potential cyclists are discouraged from taking up cycling due to the lack of suitable and safe infrastructure. Efficiently mapping cycling infrastructure across entire cities is necessary to advance our understanding of how to provide connected networks of high-quality infrastructure. Therefore we propose a system capable of classifying available cycling infrastructure from on-bike smartphone camera data. The system receives an image sequence as input, temporally analyzing the sequence to account for sparsity of signage. The model outputs cycling infrastructure class labels defined by a hierarchical classification system. Data is collected via participant cyclists covering 7,006Km across the Greater Melbourne region that is automatically labeled via a GPS and OpenStreetMap database matching algorithm. The proposed model achieved an accuracy of 95.38%, an increase in performance of 7.55% compared to the non-temporal model. The model demonstrated robustness to extreme absence of image features where the model lost only 6.6% in accuracy after 90% of images being replaced with blank images. This work is the first to classify cycling infrastructure using only street-level imagery collected from bike-mounted mobile phone cameras, while demonstrating robustness to feature sparsity via long temporal sequence analysis.</li>
</ul>

<h3>Title: Label Set Optimization via Activation Distribution Kurtosis for Zero-shot Classification with Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Yue Li, Zhixue Zhao, Carolina Scarton</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19195">https://arxiv.org/abs/2410.19195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19195">https://arxiv.org/pdf/2410.19195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19195]] Label Set Optimization via Activation Distribution Kurtosis for Zero-shot Classification with Generative Models(https://arxiv.org/abs/2410.19195)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) performance is known to be sensitive to the prompt design, yet the impact of class label options in zero-shot classification has been largely overlooked. This study presents the first comprehensive empirical study investigating how label option (e.g., lexical choice, order, and elaboration) influences zero-shot ICL classification performance. Our findings reveal that lexical choices for label names (e.g., agree this http URL in stance classification) play an important role, with effects also linked to label orders. An analysis of the model internal states further shows that optimal label names tend to activate fewer outlier neurons in the feed forward network. Based on this observation, we propose Label set Optimization via Activation Distribution kurtosiS (LOADS), a post-hoc approach requiring no gradient propagation. LOADS not only demonstrates effectiveness with only 100 unlabelled samples across different model types and sizes, but also shows cross-lingual transferability.</li>
</ul>

<h3>Title: Binary Classification: Is Boosting stronger than Bagging?</h3>
<ul>
<li><strong>Authors: </strong>Dimitris Bertsimas, Vasiliki Stoumpou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19200">https://arxiv.org/abs/2410.19200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19200">https://arxiv.org/pdf/2410.19200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19200]] Binary Classification: Is Boosting stronger than Bagging?(https://arxiv.org/abs/2410.19200)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Random Forests have been one of the most popular bagging methods in the past few decades, especially due to their success at handling tabular datasets. They have been extensively studied and compared to boosting models, like XGBoost, which are generally considered more performant. Random Forests adopt several simplistic assumptions, such that all samples and all trees that form the forest are equally important for building the final model. We introduce Enhanced Random Forests, an extension of vanilla Random Forests with extra functionalities and adaptive sample and model weighting. We develop an iterative algorithm for adapting the training sample weights, by favoring the hardest examples, and an approach for finding personalized tree weighting schemes for each new sample. Our method significantly improves upon regular Random Forests across 15 different binary classification datasets and considerably outperforms other tree methods, including XGBoost, when run with default hyperparameters, which indicates the robustness of our approach across datasets, without the need for extensive hyperparameter tuning. Our tree-weighting methodology results in enhanced or comparable performance to the uniformly weighted ensemble, and is, more importantly, leveraged to define importance scores for trees based on their contributions to classifying each new sample. This enables us to only focus on a small number of trees as the main models that define the outcome of a new sample and, thus, to partially recover interpretability, which is critically missing from both bagging and boosting methods. In binary classification problems, the proposed extensions and the corresponding results suggest the equivalence of bagging and boosting methods in performance, and the edge of bagging in interpretability by leveraging a few learners of the ensemble, which is not an option in the less explainable boosting methods.</li>
</ul>

<h3>Title: Inference time LLM alignment in single and multidomain preference spectrum</h3>
<ul>
<li><strong>Authors: </strong>Sadat Shahriar, Zheng Qi, Nikolaos Pappas, Srikanth Doss, Monica Sunkara, Kishaloy Halder, Manuel Mager, Yassine Benajiba</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19206">https://arxiv.org/abs/2410.19206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19206">https://arxiv.org/pdf/2410.19206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19206]] Inference time LLM alignment in single and multidomain preference spectrum(https://arxiv.org/abs/2410.19206)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning Large Language Models (LLM) to address subjectivity and nuanced preference levels requires adequate flexibility and control, which can be a resource-intensive and time-consuming procedure. Existing training-time alignment methods require full re-training when a change is needed and inference-time ones typically require access to the reward model at each inference step. To address these limitations, we introduce inference-time model alignment method that learns encoded representations of preference dimensions, called \textit{Alignment Vectors} (AV). These representations are computed by subtraction of the base model from the aligned model as in model editing enabling dynamically adjusting the model behavior during inference through simple linear operations. Even though the preference dimensions can span various granularity levels, here we focus on three gradual response levels across three specialized domains: medical, legal, and financial, exemplifying its practical potential. This new alignment paradigm introduces adjustable preference knobs during inference, allowing users to tailor their LLM outputs while reducing the inference cost by half compared to the prompt engineering approach. Additionally, we find that AVs are transferable across different fine-tuning stages of the same model, demonstrating their flexibility. AVs also facilitate multidomain, diverse preference alignment, making the process 12x faster than the retraining approach.</li>
</ul>

<h3>Title: Equitable Federated Learning with Activation Clustering</h3>
<ul>
<li><strong>Authors: </strong>Antesh Upadhyay, Abolfazl Hashemi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19207">https://arxiv.org/abs/2410.19207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19207">https://arxiv.org/pdf/2410.19207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19207]] Equitable Federated Learning with Activation Clustering(https://arxiv.org/abs/2410.19207)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a prominent distributed learning paradigm that incorporates collaboration among diverse clients, promotes data locality, and thus ensures privacy. These clients have their own technological, cultural, and other biases in the process of data generation. However, the present standard often ignores this bias/heterogeneity, perpetuating bias against certain groups rather than mitigating it. In response to this concern, we propose an equitable clustering-based framework where the clients are categorized/clustered based on how similar they are to each other. We propose a unique way to construct the similarity matrix that uses activation vectors. Furthermore, we propose a client weighing mechanism to ensure that each cluster receives equal importance and establish $O(1/\sqrt{K})$ rate of convergence to reach an $\epsilon-$stationary solution. We assess the effectiveness of our proposed strategy against common baselines, demonstrating its efficacy in terms of reducing the bias existing amongst various client clusters and consequently ameliorating algorithmic bias against specific groups.</li>
</ul>

<h3>Title: Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management</h3>
<ul>
<li><strong>Authors: </strong>Zhen Xu, Jingming Pan, Siyuan Han, Hongju Ouyang, Yuan Chen, Mohan Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19211">https://arxiv.org/abs/2410.19211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19211">https://arxiv.org/pdf/2410.19211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19211]] Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management(https://arxiv.org/abs/2410.19211)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With the global economic integration and the high interconnection of financial markets, financial institutions are facing unprecedented challenges, especially liquidity risk. This paper proposes a liquidity coverage ratio (LCR) prediction model based on the gated recurrent unit (GRU) network to help financial institutions manage their liquidity risk more effectively. By utilizing the GRU network in deep learning technology, the model can automatically learn complex patterns from historical data and accurately predict LCR for a period of time in the future. The experimental results show that compared with traditional methods, the GRU model proposed in this study shows significant advantages in mean absolute error (MAE), proving its higher accuracy and robustness. This not only provides financial institutions with a more reliable liquidity risk management tool but also provides support for regulators to formulate more scientific and reasonable policies, which helps to improve the stability of the entire financial system.</li>
</ul>

<h3>Title: No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Changlong Wu, Ananth Grama, Wojciech Szpankowski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19217">https://arxiv.org/abs/2410.19217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19217">https://arxiv.org/pdf/2410.19217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19217]] No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models(https://arxiv.org/abs/2410.19217)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative models have shown impressive capabilities in synthesizing high-quality outputs across various domains. However, a persistent challenge is the occurrence of "hallucinations", where the model produces outputs that are plausible but invalid. While empirical strategies have been explored to mitigate this issue, a rigorous theoretical understanding remains elusive. In this paper, we develop a theoretical framework to analyze the learnability of non-hallucinating generative models from a learning-theoretic perspective. Our results reveal that non-hallucinating learning is statistically impossible when relying solely on the training dataset, even for a hypothesis class of size two and when the entire training set is truthful. To overcome these limitations, we show that incorporating inductive biases aligned with the actual facts into the learning process is essential. We provide a systematic approach to achieve this by restricting the facts set to a concept class of finite VC-dimension and demonstrate its effectiveness under various learning paradigms. Although our findings are primarily conceptual, they represent a first step towards a principled approach to addressing hallucinations in learning generative models.</li>
</ul>

<h3>Title: An Undeniable Signature Scheme Utilizing Module Lattices</h3>
<ul>
<li><strong>Authors: </strong>Kunal Dey, Mansi Goyal, Bupendra Singh, Aditi Kar Gangopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19220">https://arxiv.org/abs/2410.19220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19220">https://arxiv.org/pdf/2410.19220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19220]] An Undeniable Signature Scheme Utilizing Module Lattices(https://arxiv.org/abs/2410.19220)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>An undeniable signature scheme is type of digital signature where the signer retains control over the signature's verifiability. Therefore with the approval of the signer, only an authenticated verifier can verify the signature. In this work, we develop a module lattice-based post-quantum undeniable signature system. Our method is based on the GPV framework utilizing module lattices, with the security assured by the hardness of the SIS and LWE problems. We have thoroughly proved all the desired securities for the proposed scheme. Finally, we have implemented our protocol for different sets of parameters. The purpose of opting a module variant rather than a ring variant is to provide greater flexibility in selecting parameters.</li>
</ul>

<h3>Title: Can Stories Help LLMs Reason? Curating Information Space Through Narrative</h3>
<ul>
<li><strong>Authors: </strong>Vahid Sadiri Javadi, Johanne R. Trippas, Yash Kumar Lal, Lucie Flek</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19221">https://arxiv.org/abs/2410.19221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19221">https://arxiv.org/pdf/2410.19221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19221]] Can Stories Help LLMs Reason? Curating Information Space Through Narrative(https://arxiv.org/abs/2410.19221)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Narratives are widely recognized as a powerful tool for structuring information and facilitating comprehension of complex ideas in various domains such as science communication. This paper investigates whether incorporating narrative elements can assist Large Language Models (LLMs) in solving complex problems more effectively. We propose a novel approach, Story of Thought (SoT), integrating narrative structures into prompting techniques for problem-solving. This approach involves constructing narratives around problem statements and creating a framework to identify and organize relevant information. Our experiments show that using various LLMs with SoT consistently surpasses using them with other techniques on physics, chemistry, math, and biology questions in both the GPQA and JEEBench datasets. The narrative-based information curation process in SoT enhances problem comprehension by contextualizing critical in-domain information and highlighting causal relationships within the problem space.</li>
</ul>

<h3>Title: Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision</h3>
<ul>
<li><strong>Authors: </strong>Aayush Shah, Chakradhar Guntuboina, Amir Barati Farimani</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19222">https://arxiv.org/abs/2410.19222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19222">https://arxiv.org/pdf/2410.19222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19222]] Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision(https://arxiv.org/abs/2410.19222)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>In recent years, natural language processing (NLP) models have demonstrated remarkable capabilities in various domains beyond traditional text generation. In this work, we introduce PeptideGPT, a protein language model tailored to generate protein sequences with distinct properties: hemolytic activity, solubility, and non-fouling characteristics. To facilitate a rigorous evaluation of these generated sequences, we established a comprehensive evaluation pipeline consisting of ideas from bioinformatics to retain valid proteins with ordered structures. First, we rank the generated sequences based on their perplexity scores, then we filter out those lying outside the permissible convex hull of proteins. Finally, we predict the structure using ESMFold and select the proteins with pLDDT values greater than 70 to ensure ordered structure. The properties of generated sequences are evaluated using task-specific classifiers - PeptideBERT and HAPPENN. We achieved an accuracy of 76.26% in hemolytic, 72.46% in non-hemolytic, 78.84% in non-fouling, and 68.06% in solubility protein generation. Our experimental results demonstrate the effectiveness of PeptideGPT in de novo protein design and underscore the potential of leveraging NLP-based approaches for paving the way for future innovations and breakthroughs in synthetic biology and bioinformatics. Codes, models, and data used in this study are freely available at: this https URL.</li>
</ul>

<h3>Title: Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors</h3>
<ul>
<li><strong>Authors: </strong>Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19230">https://arxiv.org/abs/2410.19230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19230">https://arxiv.org/pdf/2410.19230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19230]] Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors(https://arxiv.org/abs/2410.19230)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The advent of large language models (LLMs) has revolutionized the field of text generation, producing outputs that closely mimic human-like writing. Although academic and industrial institutions have developed detectors to prevent the malicious usage of LLM-generated texts, other research has doubt about the robustness of these systems. To stress test these detectors, we introduce a proxy-attack strategy that effortlessly compromises LLMs, causing them to produce outputs that align with human-written text and mislead detection systems. Our method attacks the source model by leveraging a reinforcement learning (RL) fine-tuned humanized small language model (SLM) in the decoding phase. Through an in-depth analysis, we demonstrate that our attack strategy is capable of generating responses that are indistinguishable to detectors, preventing them from differentiating between machine-generated and human-written text. We conduct systematic evaluations on extensive datasets using proxy-attacked open-source models, including Llama2-13B, Llama3-70B, and Mixtral-8*7B in both white- and black-box settings. Our findings show that the proxy-attack strategy effectively deceives the leading detectors, resulting in an average AUROC drop of 70.4% across multiple datasets, with a maximum drop of 90.3% on a single dataset. Furthermore, in cross-discipline scenarios, our strategy also bypasses these detectors, leading to a significant relative decrease of up to 90.9%, while in cross-language scenario, the drop reaches 91.3%. Despite our proxy-attack strategy successfully bypassing the detectors with such significant relative drops, we find that the generation quality of the attacked models remains preserved, even within a modest utility budget, when compared to the text produced by the original, unattacked source model.</li>
</ul>

<h3>Title: Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use</h3>
<ul>
<li><strong>Authors: </strong>Menna Fateen, Tsunenori Mine</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19231">https://arxiv.org/abs/2410.19231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19231">https://arxiv.org/pdf/2410.19231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19231]] Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use(https://arxiv.org/abs/2410.19231)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have shown promise for scalable educational applications, but their use in dialog-based tutoring systems remains challenging due to the need for effective pedagogical strategies and the high costs associated with expert-curated datasets. Our study explores the use of smaller, more affordable LLMs for one-on-one tutoring in the context of solving reading comprehension problems. We developed a synthetic tutoring dialog dataset, evaluated by human teachers, and fine-tuned a smaller LLM using this dataset. Furthermore, we conducted an interactive experiment comparing the performance of the fine-tuned model with a larger model in real-world tutoring scenarios. Our results show that the fine-tuned model performs on par with the larger model but at a lower cost, demonstrating a viable, cost-effective approach for implementing LLM-based tutoring systems in educational settings.</li>
</ul>

<h3>Title: Prompting Continual Person Search</h3>
<ul>
<li><strong>Authors: </strong>Pengcheng Zhang, Xiaohan Yu, Xiao Bai, Jin Zheng, Xin Ning</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19239">https://arxiv.org/abs/2410.19239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19239">https://arxiv.org/pdf/2410.19239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19239]] Prompting Continual Person Search(https://arxiv.org/abs/2410.19239)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The development of person search techniques has been greatly promoted in recent years for its superior practicality and challenging goals. Despite their significant progress, existing person search models still lack the ability to continually learn from increaseing real-world data and adaptively process input from different domains. To this end, this work introduces the continual person search task that sequentially learns on multiple domains and then performs person search on all seen domains. This requires balancing the stability and plasticity of the model to continually learn new knowledge without catastrophic forgetting. For this, we propose a Prompt-based Continual Person Search (PoPS) model in this paper. First, we design a compositional person search transformer to construct an effective pre-trained transformer without exhaustive pre-training from scratch on large-scale person search data. This serves as the fundamental for prompt-based continual learning. On top of that, we design a domain incremental prompt pool with a diverse attribute matching module. For each domain, we independently learn a set of prompts to encode the domain-oriented knowledge. Meanwhile, we jointly learn a group of diverse attribute projections and prototype embeddings to capture discriminative domain attributes. By matching an input image with the learned attributes across domains, the learned prompts can be properly selected for model inference. Extensive experiments are conducted to validate the proposed method for continual person search. The source code is available at this https URL.</li>
</ul>

<h3>Title: Enhancing Exchange Rate Forecasting with Explainable Deep Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Shuchen Meng, Andi Chen, Chihang Wang, Mengyao Zheng, Fangyu Wu, Xupeng Chen, Haowei Ni, Panfeng Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19241">https://arxiv.org/abs/2410.19241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19241">https://arxiv.org/pdf/2410.19241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19241]] Enhancing Exchange Rate Forecasting with Explainable Deep Learning Models(https://arxiv.org/abs/2410.19241)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Accurate exchange rate prediction is fundamental to financial stability and international trade, positioning it as a critical focus in economic and financial research. Traditional forecasting models often falter when addressing the inherent complexities and non-linearities of exchange rate data. This study explores the application of advanced deep learning models, including LSTM, CNN, and transformer-based architectures, to enhance the predictive accuracy of the RMB/USD exchange rate. Utilizing 40 features across 6 categories, the analysis identifies TSMixer as the most effective model for this task. A rigorous feature selection process emphasizes the inclusion of key economic indicators, such as China-U.S. trade volumes and exchange rates of other major currencies like the euro-RMB and yen-dollar pairs. The integration of grad-CAM visualization techniques further enhances model interpretability, allowing for clearer identification of the most influential features and bolstering the credibility of the predictions. These findings underscore the pivotal role of fundamental economic data in exchange rate forecasting and highlight the substantial potential of machine learning models to deliver more accurate and reliable predictions, thereby serving as a valuable tool for financial analysis and decision-making.</li>
</ul>

<h3>Title: The Reopening of Pandora's Box: Analyzing the Role of LLMs in the Evolving Battle Against AI-Generated Fake News</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Wang, Wenbo Zhang, Sai Koneru, Hangzhi Guo, Bonam Mingole, S. Shyam Sundar, Sarah Rajtmajer, Amulya Yadav</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19250">https://arxiv.org/abs/2410.19250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19250">https://arxiv.org/pdf/2410.19250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19250]] The Reopening of Pandora's Box: Analyzing the Role of LLMs in the Evolving Battle Against AI-Generated Fake News(https://arxiv.org/abs/2410.19250)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rise of AI-generated content spewed at scale from large language models (LLMs), genuine concerns about the spread of fake news have intensified. The perceived ability of LLMs to produce convincing fake news at scale poses new challenges for both human and automated fake news detection systems. To address this gap, this work presents the findings from a university-level competition which aimed to explore how LLMs can be used by humans to create fake news, and to assess the ability of human annotators and AI models to detect it. A total of 110 participants used LLMs to create 252 unique fake news stories, and 84 annotators participated in the detection tasks. Our findings indicate that LLMs are ~68% more effective at detecting real news than humans. However, for fake news detection, the performance of LLMs and humans remains comparable (~60% accuracy). Additionally, we examine the impact of visual elements (e.g., pictures) in news on the accuracy of detecting fake news stories. Finally, we also examine various strategies used by fake news creators to enhance the credibility of their AI-generated content. This work highlights the increasing complexity of detecting AI-generated fake news, particularly in collaborative human-AI settings.</li>
</ul>

<h3>Title: Spatioformer: A Geo-encoded Transformer for Large-Scale Plant Species Richness Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yiqing Guo, Karel Mokany, Shaun R. Levick, Jinyan Yang, Peyman Moghadam</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19256">https://arxiv.org/abs/2410.19256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19256">https://arxiv.org/pdf/2410.19256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19256]] Spatioformer: A Geo-encoded Transformer for Large-Scale Plant Species Richness Prediction(https://arxiv.org/abs/2410.19256)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Earth observation data have shown promise in predicting species richness of vascular plants ($\alpha$-diversity), but extending this approach to large spatial scales is challenging because geographically distant regions may exhibit different compositions of plant species ($\beta$-diversity), resulting in a location-dependent relationship between richness and spectral measurements. In order to handle such geolocation dependency, we propose Spatioformer, where a novel geolocation encoder is coupled with the transformer model to encode geolocation context into remote sensing imagery. The Spatioformer model compares favourably to state-of-the-art models in richness predictions on a large-scale ground-truth richness dataset (HAVPlot) that consists of 68,170 in-situ richness samples covering diverse landscapes across Australia. The results demonstrate that geolocational information is advantageous in predicting species richness from satellite observations over large spatial scales. With Spatioformer, plant species richness maps over Australia are compiled from Landsat archive for the years from 2015 to 2023. The richness maps produced in this study reveal the spatiotemporal dynamics of plant species richness in Australia, providing supporting evidence to inform effective planning and policy development for plant diversity conservation. Regions of high richness prediction uncertainties are identified, highlighting the need for future in-situ surveys to be conducted in these areas to enhance the prediction accuracy.</li>
</ul>

<h3>Title: Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yu Fu, Zefan Cai, Abedelkadir Asi, Wayne Xiong, Yue Dong, Wen Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19258">https://arxiv.org/abs/2410.19258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19258">https://arxiv.org/pdf/2410.19258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19258]] Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning(https://arxiv.org/abs/2410.19258)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Key-Value (KV) caching is a common technique to enhance the computational efficiency of Large Language Models (LLMs), but its memory overhead grows rapidly with input length. Prior work has shown that not all tokens are equally important for text generation, proposing layer-level KV cache compression to selectively retain key information. Recognizing the distinct roles of attention heads in generation, we propose HeadKV, a head-level KV cache compression method, and HeadKV-R2, which leverages a novel contextual reasoning ability estimation for compression. Our approach operates at the level of individual heads, estimating their importance for contextual QA tasks that require both retrieval and reasoning capabilities. Extensive experiments across diverse benchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct, Mistral-7B-Instruct), and long-context abilities tests demonstrate that our head-level KV cache compression significantly outperforms strong baselines, particularly in low-resource settings (KV size = 64 & 128). Notably, our method retains just 1.5% of the KV cache while achieving 97% of the performance of the full KV cache on the contextual question answering benchmark.</li>
</ul>

<h3>Title: Coordinated Reply Attacks in Influence Operations: Characterization and Detection</h3>
<ul>
<li><strong>Authors: </strong>Manita Pote, TuÄrulcan Elmas, Alessandro Flammini, Filippo Menczer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19272">https://arxiv.org/abs/2410.19272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19272">https://arxiv.org/pdf/2410.19272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19272]] Coordinated Reply Attacks in Influence Operations: Characterization and Detection(https://arxiv.org/abs/2410.19272)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Coordinated reply attacks are a tactic observed in online influence operations and other coordinated campaigns to support or harass targeted individuals, or influence them or their followers. Despite its potential to influence the public, past studies have yet to analyze or provide a methodology to detect this tactic. In this study, we characterize coordinated reply attacks in the context of influence operations on Twitter. Our analysis reveals that the primary targets of these attacks are influential people such as journalists, news media, state officials, and politicians. We propose two supervised machine-learning models, one to classify tweets to determine whether they are targeted by a reply attack, and one to classify accounts that reply to a targeted tweet to determine whether they are part of a coordinated attack. The classifiers achieve AUC scores of 0.88 and 0.97, respectively. These results indicate that accounts involved in reply attacks can be detected, and the targeted accounts themselves can serve as sensors for influence operation detection.</li>
</ul>

<h3>Title: Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management</h3>
<ul>
<li><strong>Authors: </strong>Tuowei Wang, Ruwen Fan, Minxing Huang, Zixu Hao, Kun Li, Ting Cao, Youyou Lu, Yaoxue Zhang, Ju Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.OS, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19274">https://arxiv.org/abs/2410.19274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19274">https://arxiv.org/pdf/2410.19274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19274]] Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management(https://arxiv.org/abs/2410.19274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success across various domains, yet deploying them on mobile devices remains an arduous challenge due to their extensive computational and memory demands. While lightweight LLMs have been developed to fit mobile environments, they suffer from degraded model accuracy. In contrast, sparsity-based techniques minimize DRAM usage by selectively transferring only relevant neurons to DRAM while retaining the full model in external storage, such as flash. However, such approaches are critically limited by numerous I/O operations, particularly on smartphones with severe IOPS constraints. In this paper, we propose Ripple, a novel approach that accelerates LLM inference on smartphones by optimizing neuron placement in flash memory. Ripple leverages the concept of Neuron Co-Activation, where neurons frequently activated together are linked to facilitate continuous read access and optimize data transfer efficiency. Our approach incorporates a two-stage solution: an offline stage that reorganizes neuron placement based on co-activation patterns, and an online stage that employs tailored data access and caching strategies to align well with hardware characteristics. Evaluations conducted on a variety of smartphones and LLMs demonstrate that Ripple achieves up to 5.93x improvements in I/O latency compared to the state-of-the-art. As the first solution to optimize storage placement under sparsity, Ripple explores a new optimization space at the intersection of sparsity-driven algorithm and storage-level system co-design in LLM inference.</li>
</ul>

<h3>Title: A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Pei, Jianqi Yan, Jin Yan, Bailing Yang, Ziyuan Li, Lin Zhang, Xin Liu, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19291">https://arxiv.org/abs/2410.19291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19291">https://arxiv.org/pdf/2410.19291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19291]] A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images(https://arxiv.org/abs/2410.19291)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Stock price fluctuations are influenced by a variety of factors, including macroeconomic conditions, government policies, and market sentiment, which together make price movements complex and difficult to predict. Despite many studies aimed at enhancing stock price prediction models, challenges such as data noise, model overfitting, and lack of interpretability are still encountered. To address these issues and improve prediction accuracy, this paper proposes a novel method, named Sequence-based Multiscale Fusion Regression Convolutional Neural Network (SMSFR-CNN), for predicting stock price movements in the China A-share market. By utilizing CNN to learn sequential features and combining them with image features, we improve the accuracy of stock trend prediction on the A-share market stock dataset. This approach reduces the search space for image features, stabilizes, and accelerates the training process. Extensive comparative experiments on 4,454 A-share stocks show that the proposed model achieves 61.15% for positive predictive value and 63.37% for negative predictive value of the stock price trend over the next 5 days, resulting in a total profit of 165.09%.</li>
</ul>

<h3>Title: Flow Generator Matching</h3>
<ul>
<li><strong>Authors: </strong>Zemin Huang, Zhengyang Geng, Weijian Luo, Guo-jun Qi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19310">https://arxiv.org/abs/2410.19310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19310">https://arxiv.org/pdf/2410.19310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19310]] Flow Generator Matching(https://arxiv.org/abs/2410.19310)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In the realm of Artificial Intelligence Generated Content (AIGC), flow-matching models have emerged as a powerhouse, achieving success due to their robust theoretical underpinnings and solid ability for large-scale generative modeling. These models have demonstrated state-of-the-art performance, but their brilliance comes at a cost. The process of sampling from these models is notoriously demanding on computational resources, as it necessitates the use of multi-step numerical ordinary differential equations (ODEs). Against this backdrop, this paper presents a novel solution with theoretical guarantees in the form of Flow Generator Matching (FGM), an innovative approach designed to accelerate the sampling of flow-matching models into a one-step generation, while maintaining the original performance. On the CIFAR10 unconditional generation benchmark, our one-step FGM model achieves a new record FrÃ©chet Inception Distance (FID) score of 3.08 among few-step flow-matching-based models, outperforming original 50-step flow-matching models. Furthermore, we use the FGM to distill the Stable Diffusion 3, a leading text-to-image flow-matching model based on the MM-DiT architecture. The resulting MM-DiT-FGM one-step text-to-image model demonstrates outstanding industry-level performance. When evaluated on the GenEval benchmark, MM-DiT-FGM has delivered remarkable generating qualities, rivaling other multi-step models in light of the efficiency of a single generation step.</li>
</ul>

<h3>Title: COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training</h3>
<ul>
<li><strong>Authors: </strong>Haocheng Xi, Han Cai, Ligeng Zhu, Yao Lu, Kurt Keutzer, Jianfei Chen, Song Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19313">https://arxiv.org/abs/2410.19313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19313">https://arxiv.org/pdf/2410.19313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19313]] COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training(https://arxiv.org/abs/2410.19313)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>FP8 training has emerged as a promising method for improving training efficiency. Existing frameworks accelerate training by applying FP8 computation to linear layers while leaving optimizer states and activations in higher precision, which fails to fully optimize memory usage. This paper introduces COAT (Compressing Optimizer States and Activations for FP8 Training), a novel FP8 training framework designed to significantly reduce memory footprint when training large models. COAT addresses current limitations through two key innovations: (1) Dynamic Range Expansion, which aligns optimizer state distributions more closely with the FP8 representation range, thereby reducing quantization error, and (2) Mixed-Granularity Activation Quantization, which optimizes activation memory using a combination of per-tensor and per-group quantization strategies. Experiments demonstrate that COAT effectively reduces end-to-end training memory footprint by 1.54x compared to BF16 while achieving nearly lossless performance across various tasks, such as Large Language Model pretraining and fine-tuning and Vision Language Model training. COAT also achieves a 1.43x end-to-end training speedup compared to BF16, performing on par with or surpassing TransformerEngine's speedup. COAT enables efficient full-parameter training of large models on fewer GPUs, and facilitates doubling the batch size in distributed training settings, providing a practical solution for scaling large-scale model training. The code is available at this https URL.</li>
</ul>

<h3>Title: FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zhiting Fan, Ruizhe Chen, Tianxiang Hu, Zuozhu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19317">https://arxiv.org/abs/2410.19317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19317">https://arxiv.org/pdf/2410.19317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19317]] FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs(https://arxiv.org/abs/2410.19317)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>The growing use of large language model (LLM)-based chatbots has raised concerns about fairness. Fairness issues in LLMs can lead to severe consequences, such as bias amplification, discrimination, and harm to marginalized communities. While existing fairness benchmarks mainly focus on single-turn dialogues, multi-turn scenarios, which in fact better reflect real-world conversations, present greater challenges due to conversational complexity and potential bias accumulation. In this paper, we propose a comprehensive fairness benchmark for LLMs in multi-turn dialogue scenarios, \textbf{FairMT-Bench}. Specifically, we formulate a task taxonomy targeting LLM fairness capabilities across three stages: context understanding, user interaction, and instruction trade-offs, with each stage comprising two tasks. To ensure coverage of diverse bias types and attributes, we draw from existing fairness datasets and employ our template to construct a multi-turn dialogue dataset, \texttt{FairMT-10K}. For evaluation, GPT-4 is applied, alongside bias classifiers including Llama-Guard-3 and human validation to ensure robustness. Experiments and analyses on \texttt{FairMT-10K} reveal that in multi-turn dialogue scenarios, current LLMs are more likely to generate biased responses, and there is significant variation in performance across different tasks and models. Based on this, we curate a challenging dataset, \texttt{FairMT-1K}, and test 15 current state-of-the-art (SOTA) LLMs on this dataset. The results show the current state of fairness in LLMs and showcase the utility of this novel approach for assessing fairness in more realistic multi-turn dialogue contexts, calling for future work to focus on LLM fairness improvement and the adoption of \texttt{FairMT-1K} in such efforts.</li>
</ul>

<h3>Title: Two are better than one: Context window extension with multi-grained self-injection</h3>
<ul>
<li><strong>Authors: </strong>Wei Han, Pan Zhou, Soujanya Poria, Shuicheng Yan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19318">https://arxiv.org/abs/2410.19318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19318">https://arxiv.org/pdf/2410.19318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19318]] Two are better than one: Context window extension with multi-grained self-injection(https://arxiv.org/abs/2410.19318)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The limited context window of contemporary large language models (LLMs) remains a huge barrier to their broader application across various domains. While continual pre-training on long-context data is a straightforward and effective solution, it incurs substantial costs in terms of data acquisition and computational resources. To alleviate this issue, we propose SharedLLM, a novel approach grounded in the design philosophy of multi-grained context compression and query-aware information retrieval. SharedLLM is composed of two short-context LLMs such as LLaMA-2, termed upper model and lower model. The lower model functions as a compressor while the upper model acts as a decoder. The upper model receives compressed, multi-grained context information from the lower model and performs context-aware modeling on the running text. Information transfer between the compressor and decoder occurs only at the lowest layers to refrain from long forward paths in the lower model and redundant cross-attention modules in the upper model. Based on this architecture, we introduce a specialized tree-style data structure to efficiently encode, store and retrieve multi-grained contextual information for text chunks. This structure, combined with a search algorithm, enables rapid encoding and retrieval of relevant information from various levels of the tree based on the input query. This entire process, wherein the sender and receiver are derived from the same LLM layer, is referred to as self-injection.</li>
</ul>

<h3>Title: Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion</h3>
<ul>
<li><strong>Authors: </strong>Emiel Hoogeboom, Thomas Mensink, Jonathan Heek, Kay Lamerigts, Ruiqi Gao, Tim Salimans</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19324">https://arxiv.org/abs/2410.19324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19324">https://arxiv.org/pdf/2410.19324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19324]] Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion(https://arxiv.org/abs/2410.19324)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Latent diffusion models have become the popular choice for scaling up diffusion models for high resolution image synthesis. Compared to pixel-space models that are trained end-to-end, latent models are perceived to be more efficient and to produce higher image quality at high resolution. Here we challenge these notions, and show that pixel-space models can in fact be very competitive to latent approaches both in quality and efficiency, achieving 1.5 FID on ImageNet512 and new SOTA results on ImageNet128 and ImageNet256. We present a simple recipe for scaling end-to-end pixel-space diffusion models to high resolutions. 1: Use the sigmoid loss (Kingma & Gao, 2023) with our prescribed hyper-parameters. 2: Use our simplified memory-efficient architecture with fewer skip-connections. 3: Scale the model to favor processing the image at high resolution with fewer parameters, rather than using more parameters but at a lower resolution. When combining these three steps with recently proposed tricks like guidance intervals, we obtain a family of pixel-space diffusion models we call Simple Diffusion v2 (SiD2).</li>
</ul>

<h3>Title: Privacy-preserving server-supported decryption</h3>
<ul>
<li><strong>Authors: </strong>Peeter Laud, Alisa Pankova, Jelizaveta Vakarjuk</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19338">https://arxiv.org/abs/2410.19338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19338">https://arxiv.org/pdf/2410.19338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19338]] Privacy-preserving server-supported decryption(https://arxiv.org/abs/2410.19338)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>In this paper, we consider encryption systems with two-out-of-two threshold decryption, where one of the parties (the client) initiates the decryption and the other one (the server) assists. Existing threshold decryption schemes disclose to the server the ciphertext that is being decrypted. We give a construction, where the identity of the ciphertext is not leaked to the server, and the client's privacy is thus preserved. While showing the security of this construction, we run into the issue of defining the security of a scheme with blindly assisted decryption. We discuss previously proposed security definitions for similar cryptographic functionalities and argue why they do not capture the expected meaning of security. We propose an ideal functionality for the encryption with server-supported blind threshold decryption in the universal composability model, carefully balancing between the meaning of privacy, and the ability to implement it. We construct a protocol and show that it is a secure implementation of the proposed functionality in the random oracle model.</li>
</ul>

<h3>Title: AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Mou, Jingcong Liang, Jiayu Lin, Xinnong Zhang, Xiawei Liu, Shiyue Yang, Rong Ye, Lei Chen, Haoyu Kuang, Xuanjing Huang, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19346">https://arxiv.org/abs/2410.19346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19346">https://arxiv.org/pdf/2410.19346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19346]] AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios(https://arxiv.org/abs/2410.19346)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly leveraged to empower autonomous agents to simulate human beings in various fields of behavioral research. However, evaluating their capacity to navigate complex social interactions remains a challenge. Previous studies face limitations due to insufficient scenario diversity, complexity, and a single-perspective focus. To this end, we introduce AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense employs a bottom-up approach to create 1,225 diverse social scenarios constructed from extensive scripts. We evaluate LLM-driven agents through multi-turn interactions, emphasizing both goal completion and implicit reasoning. We analyze goals using ERG theory and conduct comprehensive experiments. Our findings highlight that LLMs struggle with goals in complex social scenarios, especially high-level growth needs, and even GPT-4o requires improvement in private information reasoning.</li>
</ul>

<h3>Title: Interpreting Neural Networks through Mahalanobis Distance</h3>
<ul>
<li><strong>Authors: </strong>Alan Oursland</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19352">https://arxiv.org/abs/2410.19352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19352">https://arxiv.org/pdf/2410.19352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19352]] Interpreting Neural Networks through Mahalanobis Distance(https://arxiv.org/abs/2410.19352)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper introduces a theoretical framework that connects neural network linear layers with the Mahalanobis distance, offering a new perspective on neural network interpretability. While previous studies have explored activation functions primarily for performance optimization, our work interprets these functions through statistical distance measures, a less explored area in neural network research. By establishing this connection, we provide a foundation for developing more interpretable neural network models, which is crucial for applications requiring transparency. Although this work is theoretical and does not include empirical data, the proposed distance-based interpretation has the potential to enhance model robustness, improve generalization, and provide more intuitive explanations of neural network decisions.</li>
</ul>

<h3>Title: Interleaving Text and Number Embeddings to Solve Mathemathics Problems</h3>
<ul>
<li><strong>Authors: </strong>Marvin Alberts, Gianmarco Gabrieli, Irina Espejo Morales</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19353">https://arxiv.org/abs/2410.19353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19353">https://arxiv.org/pdf/2410.19353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19353]] Interleaving Text and Number Embeddings to Solve Mathemathics Problems(https://arxiv.org/abs/2410.19353)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Integrating text and numbers effectively is a crucial step towards enhancing Large Language Models (LLMs) capabilities in assisting in scientific tasks. While most current approaches rely on discrete tokenization of numbers, for instance, conversion to scientific notation or base 10-decomposition, a recent approach proposed a continuous numerical encoding as an inductive bias. In this paper, we build upon this approach by introducing more expressive numerical embeddings. Our method addresses key shortcomings, including the elimination of numerical artefacts and the ability to handle a wide range of magnitudes without clipping. Our work presents two key contributions. First, we employ an MLP to assign distinct directions in the embedding space to different numbers. Our second contribution is the introduction of a routing layer that differentiates between numerical and text embeddings. We hypothesise that this combined approach enables the model to distinguish between text and number distributions while maintaining its capacity for arithmetic operations. Using only a 45 M parameter encoder-decoder architecture our method achieves a $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition, we empirically observe a reduction of the numerical artefacts and biases observed compared to the baselines.</li>
</ul>

<h3>Title: FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality</h3>
<ul>
<li><strong>Authors: </strong>Zhengyao Lv, Chenyang Si, Junhao Song, Zhenyu Yang, Yu Qiao, Ziwei Liu, Kwan-Yee K. Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19355">https://arxiv.org/abs/2410.19355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19355">https://arxiv.org/pdf/2410.19355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19355]] FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality(https://arxiv.org/abs/2410.19355)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this paper, we present \textbf{\textit{FasterCache}}, a novel training-free strategy designed to accelerate the inference of video diffusion models with high-quality generation. By analyzing existing cache-based methods, we observe that \textit{directly reusing adjacent-step features degrades video quality due to the loss of subtle variations}. We further perform a pioneering investigation of the acceleration potential of classifier-free guidance (CFG) and reveal significant redundancy between conditional and unconditional features within the same timestep. Capitalizing on these observations, we introduce FasterCache to substantially accelerate diffusion-based video generation. Our key contributions include a dynamic feature reuse strategy that preserves both feature distinction and temporal continuity, and CFG-Cache which optimizes the reuse of conditional and unconditional outputs to further enhance inference speed without compromising video quality. We empirically evaluate FasterCache on recent video diffusion models. Experimental results show that FasterCache can significantly accelerate video generation (\eg 1.67$\times$ speedup on Vchitect-2.0) while keeping video quality comparable to the baseline, and consistently outperform existing methods in both inference speed and video quality.</li>
</ul>

<h3>Title: FeBiM: Efficient and Compact Bayesian Inference Engine Empowered with Ferroelectric In-Memory Computing</h3>
<ul>
<li><strong>Authors: </strong>Chao Li, Zhicheng Xu, Bo Wen, Ruibin Mao, Can Li, Thomas KÃ¤mpfe, Kai Ni, Xunzhao Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19356">https://arxiv.org/abs/2410.19356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19356">https://arxiv.org/pdf/2410.19356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19356]] FeBiM: Efficient and Compact Bayesian Inference Engine Empowered with Ferroelectric In-Memory Computing(https://arxiv.org/abs/2410.19356)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>In scenarios with limited training data or where explainability is crucial, conventional neural network-based machine learning models often face challenges. In contrast, Bayesian inference-based algorithms excel in providing interpretable predictions and reliable uncertainty estimation in these scenarios. While many state-of-the-art in-memory computing (IMC) architectures leverage emerging non-volatile memory (NVM) technologies to offer unparalleled computing capacity and energy efficiency for neural network workloads, their application in Bayesian inference is limited. This is because the core operations in Bayesian inference differ significantly from the multiplication-accumulation (MAC) operations common in neural networks, rendering them generally unsuitable for direct implementation in most existing IMC designs. In this paper, we propose FeBiM, an efficient and compact Bayesian inference engine powered by multi-bit ferroelectric field-effect transistor (FeFET)-based IMC. FeBiM effectively encodes the trained probabilities of a Bayesian inference model within a compact FeFET-based crossbar. It maps quantized logarithmic probabilities to discrete FeFET states. As a result, the accumulated outputs of the crossbar naturally represent the posterior probabilities, i.e., the Bayesian inference model's output given a set of observations. This approach enables efficient in-memory Bayesian inference without the need for additional calculation circuitry. As the first FeFET-based in-memory Bayesian inference engine, FeBiM achieves an impressive storage density of 26.32 Mb/mm$^{2}$ and a computing efficiency of 581.40 TOPS/W in a representative Bayesian classification task. These results demonstrate 10.7$\times$/43.4$\times$ improvement in compactness/efficiency compared to the state-of-the-art hardware implementation of Bayesian inference.</li>
</ul>

<h3>Title: Capsule Endoscopy Multi-classification via Gated Attention and Wavelet Transformations</h3>
<ul>
<li><strong>Authors: </strong>Lakshmi Srinivas Panchananam, Praveen Kumar Chandaliya, Kishor Upla, Kiran Raja</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19363">https://arxiv.org/abs/2410.19363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19363">https://arxiv.org/pdf/2410.19363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19363]] Capsule Endoscopy Multi-classification via Gated Attention and Wavelet Transformations(https://arxiv.org/abs/2410.19363)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Abnormalities in the gastrointestinal tract significantly influence the patient's health and require a timely diagnosis for effective treatment. With such consideration, an effective automatic classification of these abnormalities from a video capsule endoscopy (VCE) frame is crucial for improvement in diagnostic workflows. The work presents the process of developing and evaluating a novel model designed to classify gastrointestinal anomalies from a VCE video frame. Integration of Omni Dimensional Gated Attention (OGA) mechanism and Wavelet transformation techniques into the model's architecture allowed the model to focus on the most critical areas in the endoscopy images, reducing noise and irrelevant features. This is particularly advantageous in capsule endoscopy, where images often contain a high degree of variability in texture and color. Wavelet transformations contributed by efficiently capturing spatial and frequency-domain information, improving feature extraction, especially for detecting subtle features from the VCE frames. Furthermore, the features extracted from the Stationary Wavelet Transform and Discrete Wavelet Transform are concatenated channel-wise to capture multiscale features, which are essential for detecting polyps, ulcerations, and bleeding. This approach improves classification accuracy on imbalanced capsule endoscopy datasets. The proposed model achieved 92.76% and 91.19% as training and validation accuracies respectively. At the same time, Training and Validation losses are 0.2057 and 0.2700. The proposed model achieved a Balanced Accuracy of 94.81%, AUC of 87.49%, F1-score of 91.11%, precision of 91.17%, recall of 91.19% and specificity of 98.44%. Additionally, the model's performance is benchmarked against two base models, VGG16 and ResNet50, demonstrating its enhanced ability to identify and classify a range of gastrointestinal abnormalities accurately.</li>
</ul>

<h3>Title: Multi-Agent Reinforcement Learning with Selective State-Space Models</h3>
<ul>
<li><strong>Authors: </strong>Jemma Daniel, Ruan de Kock, Louay Ben Nessir, Sasha Abramowitz, Omayma Mahjoub, Wiem Khlifi, Claude Formanek, Arnu Pretorius</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19382">https://arxiv.org/abs/2410.19382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19382">https://arxiv.org/pdf/2410.19382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19382]] Multi-Agent Reinforcement Learning with Selective State-Space Models(https://arxiv.org/abs/2410.19382)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Transformer model has demonstrated success across a wide range of domains, including in Multi-Agent Reinforcement Learning (MARL) where the Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field. The Transformer model has demonstrated success across a wide range of domains, including in Multi-Agent Reinforcement Learning (MARL) where the Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field. However, a significant drawback of Transformer models is their quadratic computational complexity relative to input size, making them computationally expensive when scaling to larger inputs. This limitation restricts MAT's scalability in environments with many agents. Recently, State-Space Models (SSMs) have gained attention due to their computational efficiency, but their application in MARL remains unexplored. In this work, we investigate the use of Mamba, a recent SSM, in MARL and assess whether it can match the performance of MAT while providing significant improvements in efficiency. We introduce a modified version of MAT that incorporates standard and bi-directional Mamba blocks, as well as a novel "cross-attention" Mamba block. Extensive testing shows that our Multi-Agent Mamba (MAM) matches the performance of MAT across multiple standard multi-agent environments, while offering superior scalability to larger agent scenarios. This is significant for the MARL community, because it indicates that SSMs could replace Transformers without compromising performance, whilst also supporting more effective scaling to higher numbers of agents. Our project page is available at this https URL .</li>
</ul>

<h3>Title: Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Liam Barkley, Brink van der Merwe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19385">https://arxiv.org/abs/2410.19385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19385">https://arxiv.org/pdf/2410.19385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19385]] Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models(https://arxiv.org/abs/2410.19385)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are powerful computational models trained on extensive corpora of human-readable text, enabling them to perform general-purpose language understanding and generation. LLMs have garnered significant attention in both industry and academia due to their exceptional performance across various natural language processing (NLP) tasks. Despite these successes, LLMs often produce inaccuracies, commonly referred to as hallucinations. Prompt engineering, the process of designing and formulating instructions for LLMs to perform specific tasks, has emerged as a key approach to mitigating hallucinations. This paper provides a comprehensive empirical evaluation of different prompting strategies and frameworks aimed at reducing hallucinations in LLMs. Various prompting techniques are applied to a broad set of benchmark datasets to assess the accuracy and hallucination rate of each method. Additionally, the paper investigates the influence of tool-calling agents (LLMs augmented with external tools to enhance their capabilities beyond language generation) on hallucination rates in the same benchmarks. The findings demonstrate that the optimal prompting technique depends on the type of problem, and that simpler techniques often outperform more complex methods in reducing hallucinations. Furthermore, it is shown that LLM agents can exhibit significantly higher hallucination rates due to the added complexity of external tool usage.</li>
</ul>

<h3>Title: Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression</h3>
<ul>
<li><strong>Authors: </strong>Yixiu Mao, Cheems Wang, Chen Chen, Yun Qu, Xiangyang Ji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19400">https://arxiv.org/abs/2410.19400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19400">https://arxiv.org/pdf/2410.19400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19400]] Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression(https://arxiv.org/abs/2410.19400)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In offline reinforcement learning (RL), addressing the out-of-distribution (OOD) action issue has been a focus, but we argue that there exists an OOD state issue that also impairs performance yet has been underexplored. Such an issue describes the scenario when the agent encounters states out of the offline dataset during the test phase, leading to uncontrolled behavior and performance degradation. To this end, we propose SCAS, a simple yet effective approach that unifies OOD state correction and OOD action suppression in offline RL. Technically, SCAS achieves value-aware OOD state correction, capable of correcting the agent from OOD states to high-value in-distribution states. Theoretical and empirical results show that SCAS also exhibits the effect of suppressing OOD actions. On standard offline RL benchmarks, SCAS achieves excellent performance without additional hyperparameter tuning. Moreover, benefiting from its OOD state correction feature, SCAS demonstrates enhanced robustness against environmental perturbations.</li>
</ul>

<h3>Title: Robust Time Series Causal Discovery for Agent-Based Model Validation</h3>
<ul>
<li><strong>Authors: </strong>Gene Yu, Ce Guo, Wayne Luk</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, econ.EM, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19412">https://arxiv.org/abs/2410.19412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19412">https://arxiv.org/pdf/2410.19412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19412]] Robust Time Series Causal Discovery for Agent-Based Model Validation(https://arxiv.org/abs/2410.19412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Agent-Based Model (ABM) validation is crucial as it helps ensuring the reliability of simulations, and causal discovery has become a powerful tool in this context. However, current causal discovery methods often face accuracy and robustness challenges when applied to complex and noisy time series data, which is typical in ABM scenarios. This study addresses these issues by proposing a Robust Cross-Validation (RCV) approach to enhance causal structure learning for ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two prominent causal discovery algorithms. These aim to reduce the impact of noise better and give more reliable causal relation results, even with high-dimensional, time-dependent data. The proposed approach is then integrated into an enhanced ABM validation framework, which is designed to handle diverse data and model structures. The approach is evaluated using synthetic datasets and a complex simulated fMRI dataset. The results demonstrate greater reliability in causal structure identification. The study examines how various characteristics of datasets affect the performance of established causal discovery methods. These characteristics include linearity, noise distribution, stationarity, and causal structure density. This analysis is then extended to the RCV method to see how it compares in these different situations. This examination helps confirm whether the results are consistent with existing literature and also reveals the strengths and weaknesses of the novel approaches. By tackling key methodological challenges, the study aims to enhance ABM validation with a more resilient valuation framework presented. These improvements increase the reliability of model-driven decision making processes in complex systems analysis.</li>
</ul>

<h3>Title: KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures</h3>
<ul>
<li><strong>Authors: </strong>Hamna, Deepthi Sudharsan, Agrima Seth, Ritvik Budhiraja, Deepika Khullar, Vyshak Jain, Kalika Bali, Aditya Vashistha, Sameer Segal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19419">https://arxiv.org/abs/2410.19419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19419">https://arxiv.org/pdf/2410.19419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19419]] KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures(https://arxiv.org/abs/2410.19419)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated the ability to generate compelling text and visual stories. However, their outputs are predominantly aligned with the sensibilities of the Global North, often resulting in an outsider's gaze on other cultures. As a result, non-Western communities have to put extra effort into generating culturally specific stories. To address this challenge, we developed a visual storytelling pipeline called KAHANI that generates culturally grounded visual stories for non-Western cultures. Our pipeline leverages off-the-shelf models GPT-4 Turbo and Stable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I prompting techniques, we capture the cultural context from user's prompt and generate vivid descriptions of the characters and scene compositions. To evaluate the effectiveness of KAHANI, we conducted a comparative user study with ChatGPT-4 (with DALL-E3) in which participants from different regions of India compared the cultural relevance of stories generated by the two tools. Results from the qualitative and quantitative analysis performed on the user study showed that KAHANI was able to capture and incorporate more Culturally Specific Items (CSIs) compared to ChatGPT-4. In terms of both its cultural competence and visual story generation quality, our pipeline outperformed ChatGPT-4 in 27 out of the 36 comparisons.</li>
</ul>

<h3>Title: Analyzing Generative Models by Manifold Entropic Metrics</h3>
<ul>
<li><strong>Authors: </strong>Daniel Galperin, Ullrich KÃ¶the</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19426">https://arxiv.org/abs/2410.19426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19426">https://arxiv.org/pdf/2410.19426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19426]] Analyzing Generative Models by Manifold Entropic Metrics(https://arxiv.org/abs/2410.19426)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Good generative models should not only synthesize high quality data, but also utilize interpretable representations that aid human understanding of their behavior. However, it is difficult to measure objectively if and to what degree desirable properties of disentangled representations have been achieved. Inspired by the principle of independent mechanisms, we address this difficulty by introducing a novel set of tractable information-theoretic evaluation metrics. We demonstrate the usefulness of our metrics on illustrative toy examples and conduct an in-depth comparison of various normalizing flow architectures and $\beta$-VAEs on the EMNIST dataset. Our method allows to sort latent features by importance and assess the amount of residual correlations of the resulting concepts. The most interesting finding of our experiments is a ranking of model architectures and training procedures in terms of their inductive bias to converge to aligned and disentangled representations during training.</li>
</ul>

<h3>Title: Generative Diffusion Models for Sequential Recommendations</h3>
<ul>
<li><strong>Authors: </strong>Sharare Zolghadr, Ole Winther, Paul Jeha</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19429">https://arxiv.org/abs/2410.19429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19429">https://arxiv.org/pdf/2410.19429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19429]] Generative Diffusion Models for Sequential Recommendations(https://arxiv.org/abs/2410.19429)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have shown promise in sequential recommendation tasks. However, they face challenges, including posterior collapse and limited representation capacity. The work by Li et al. (2023) introduces a novel approach that leverages diffusion models to address these challenges by representing item embeddings as distributions rather than fixed vectors. This approach allows for a more adaptive reflection of users' diverse interests and various item aspects. During the diffusion phase, the model converts the target item embedding into a Gaussian distribution by adding noise, facilitating the representation of sequential item distributions and the injection of uncertainty. An Approximator then processes this noisy item representation to reconstruct the target item. In the reverse phase, the model utilizes users' past interactions to reverse the noise and finalize the item prediction through a rounding operation. This research introduces enhancements to the DiffuRec architecture, particularly by adding offset noise in the diffusion process to improve robustness and incorporating a cross-attention mechanism in the Approximator to better capture relevant user-item interactions. These contributions led to the development of a new model, DiffuRecSys, which improves performance. Extensive experiments conducted on three public benchmark datasets demonstrate that these modifications enhance item representation, effectively capture diverse user preferences, and outperform existing baselines in sequential recommendation research.</li>
</ul>

<h3>Title: Transductive Learning for Near-Duplicate Image Detection in Scanned Photo Collections</h3>
<ul>
<li><strong>Authors: </strong>Francesc Net, Marc Folia, Pep Casals, Lluis Gomez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19437">https://arxiv.org/abs/2410.19437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19437">https://arxiv.org/pdf/2410.19437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19437]] Transductive Learning for Near-Duplicate Image Detection in Scanned Photo Collections(https://arxiv.org/abs/2410.19437)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents a comparative study of near-duplicate image detection techniques in a real-world use case scenario, where a document management company is commissioned to manually annotate a collection of scanned photographs. Detecting duplicate and near-duplicate photographs can reduce the time spent on manual annotation by archivists. This real use case differs from laboratory settings as the deployment dataset is available in advance, allowing the use of transductive learning. We propose a transductive learning approach that leverages state-of-the-art deep learning architectures such as convolutional neural networks (CNNs) and Vision Transformers (ViTs). Our approach involves pre-training a deep neural network on a large dataset and then fine-tuning the network on the unlabeled target collection with self-supervised learning. The results show that the proposed approach outperforms the baseline methods in the task of near-duplicate image detection in the UKBench and an in-house private dataset.</li>
</ul>

<h3>Title: Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment</h3>
<ul>
<li><strong>Authors: </strong>Syed Sameen Ahmad Rizvi, Aryan Seth, Pratik Narang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19444">https://arxiv.org/abs/2410.19444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19444">https://arxiv.org/pdf/2410.19444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19444]] Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment(https://arxiv.org/abs/2410.19444)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Automatically recognizing emotional intent using facial expression has been a thoroughly investigated topic in the realm of computer vision. Facial Expression Recognition (FER), being a supervised learning task, relies heavily on substantially large data exemplifying various socio-cultural demographic attributes. Over the past decade, several real-world in-the-wild FER datasets that have been proposed were collected through crowd-sourcing or web-scraping. However, most of these practically used datasets employ a manual annotation methodology for labeling emotional intent, which inherently propagates individual demographic biases. Moreover, these datasets also lack an equitable representation of various socio-cultural demographic groups, thereby inducing a class imbalance. Bias analysis and its mitigation have been investigated across multiple domains and problem settings, however, in the FER domain, this is a relatively lesser explored area. This work leverages representation learning based on latent spaces to mitigate bias in facial expression recognition systems, thereby enhancing a deep learning model's fairness and overall accuracy.</li>
</ul>

<h3>Title: Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yao Wu, Mingwei Xing, Yachao Zhang, Yuan Xie, Yanyun Qu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19446">https://arxiv.org/abs/2410.19446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19446">https://arxiv.org/pdf/2410.19446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19446]] Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation(https://arxiv.org/abs/2410.19446)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In cross-modal unsupervised domain adaptation, a model trained on source-domain data (e.g., synthetic) is adapted to target-domain data (e.g., real-world) without access to target annotation. Previous methods seek to mutually mimic cross-modal outputs in each domain, which enforces a class probability distribution that is agreeable in different domains. However, they overlook the complementarity brought by the heterogeneous fusion in cross-modal learning. In light of this, we propose a novel fusion-then-distillation (FtD++) method to explore cross-modal positive distillation of the source and target domains for 3D semantic segmentation. FtD++ realizes distribution consistency between outputs not only for 2D images and 3D point clouds but also for source-domain and augment-domain. Specially, our method contains three key ingredients. First, we present a model-agnostic feature fusion module to generate the cross-modal fusion representation for establishing a latent space. In this space, two modalities are enforced maximum correlation and complementarity. Second, the proposed cross-modal positive distillation preserves the complete information of multi-modal input and combines the semantic content of the source domain with the style of the target domain, thereby achieving domain-modality alignment. Finally, cross-modal debiased pseudo-labeling is devised to model the uncertainty of pseudo-labels via a self-training manner. Extensive experiments report state-of-the-art results on several domain adaptive scenarios under unsupervised and semi-supervised settings. Code is available at this https URL.</li>
</ul>

<h3>Title: Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework</h3>
<ul>
<li><strong>Authors: </strong>Yirui Chen, Qinyu Xiao, Jia Yi, Jing Chen, Mengyang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19451">https://arxiv.org/abs/2410.19451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19451">https://arxiv.org/pdf/2410.19451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19451]] Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework(https://arxiv.org/abs/2410.19451)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the application of prompt engineering to enhance the performance of large language models (LLMs) in the domain of Traditional Chinese Medicine (TCM). We propose TCM-Prompt, a framework that integrates various pre-trained language models (PLMs), templates, tokenization, and verbalization methods, allowing researchers to easily construct and fine-tune models for specific TCM-related tasks. We conducted experiments on disease classification, syndrome identification, herbal medicine recommendation, and general NLP tasks, demonstrating the effectiveness and superiority of our approach compared to baseline methods. Our findings suggest that prompt engineering is a promising technique for improving the performance of LLMs in specialized domains like TCM, with potential applications in digitalization, modernization, and personalized medicine.</li>
</ul>

<h3>Title: ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework</h3>
<ul>
<li><strong>Authors: </strong>Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19453">https://arxiv.org/abs/2410.19453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19453">https://arxiv.org/pdf/2410.19453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19453]] ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework(https://arxiv.org/abs/2410.19453)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To further enhance the performance of non-dominant languages, we propose ShifCon, a Shift-based Contrastive framework that aligns the internal forward process of other languages toward that of the dominant one. Specifically, it shifts the representations of non-dominant languages into the dominant language subspace, allowing them to access relatively rich information encoded in the model parameters. The enriched representations are then shifted back into their original language subspace before generation. Moreover, we introduce a subspace distance metric to pinpoint the optimal layer area for shifting representations and employ multilingual contrastive learning to further enhance the alignment of representations within this area. Experiments demonstrate that our ShifCon framework significantly enhances the performance of non-dominant languages, particularly for low-resource ones. Further analysis offers extra insights to verify the effectiveness of ShifCon and propel future research</li>
</ul>

<h3>Title: Computational Bottlenecks of Training Small-scale Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Saleh Ashkboos, Iman Mirzadeh, Keivan Alizadeh, Mohammad Hossein Sekhavat, Moin Nabi, Mehrdad Farajtabar, Fartash Faghri</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19456">https://arxiv.org/abs/2410.19456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19456">https://arxiv.org/pdf/2410.19456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19456]] Computational Bottlenecks of Training Small-scale Large Language Models(https://arxiv.org/abs/2410.19456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) dominate the AI landscape, Small-scale large Language Models (SLMs) are gaining attention due to cost and efficiency demands from consumers. However, there is limited research on the training behavior and computational requirements of SLMs. In this study, we explore the computational bottlenecks of training SLMs (up to 2B parameters) by examining the effects of various hyperparameters and configurations, including GPU type, batch size, model size, communication protocol, attention type, and the number of GPUs. We assess these factors on popular cloud services using metrics such as loss per dollar and tokens per second. Our findings aim to support the broader adoption and optimization of language model training for low-resource AI research institutes.</li>
</ul>

<h3>Title: LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data</h3>
<ul>
<li><strong>Authors: </strong>Yue Cheng, Jiajun Zhang, Weiwei Xing, Xiaoyu Guo, Xiaohui Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19464">https://arxiv.org/abs/2410.19464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19464">https://arxiv.org/pdf/2410.19464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19464]] LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data(https://arxiv.org/abs/2410.19464)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Discovering the underlying Directed Acyclic Graph (DAG) from time series observational data is highly challenging due to the dynamic nature and complex nonlinear interactions between variables. Existing methods often struggle with inefficiency and the handling of high-dimensional data. To address these research gap, we propose LOCAL, a highly efficient, easy-to-implement, and constraint-free method for recovering dynamic causal structures. LOCAL is the first attempt to formulate a quasi-maximum likelihood-based score function for learning the dynamic DAG equivalent to the ground truth. On this basis, we propose two adaptive modules for enhancing the algebraic characterization of acyclicity with new capabilities: Asymptotic Causal Mask Learning (ACML) and Dynamic Graph Parameter Learning (DGPL). ACML generates causal masks using learnable priority vectors and the Gumbel-Sigmoid function, ensuring the creation of DAGs while optimizing computational efficiency. DGPL transforms causal learning into decomposed matrix products, capturing the dynamic causal structure of high-dimensional data and enhancing interpretability. Extensive experiments on synthetic and real-world datasets demonstrate that LOCAL significantly outperforms existing methods, and highlight LOCAL's potential as a robust and efficient method for dynamic causal discovery. Our code will be available soon.</li>
</ul>

<h3>Title: Peter Parker or Spiderman? Disambiguating Multiple Class Labels</h3>
<ul>
<li><strong>Authors: </strong>Nuthan Mummani, Simran Ketha, Venkatakrishnan Ramaswamy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19479">https://arxiv.org/abs/2410.19479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19479">https://arxiv.org/pdf/2410.19479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19479]] Peter Parker or Spiderman? Disambiguating Multiple Class Labels(https://arxiv.org/abs/2410.19479)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>In the supervised classification setting, during inference, deep networks typically make multiple predictions. For a pair of such predictions (that are in the top-k predictions), two distinct possibilities might occur. On the one hand, each of the two predictions might be primarily driven by two distinct sets of entities in the input. On the other hand, it is possible that there is a single entity or set of entities that is driving the prediction for both the classes in question. This latter case, in effect, corresponds to the network making two separate guesses about the identity of a single entity type. Clearly, both the guesses cannot be true, i.e. both the labels cannot be present in the input. Current techniques in interpretability research do not readily disambiguate these two cases, since they typically consider input attributions for one class label at a time. Here, we present a framework and method to do so, leveraging modern segmentation and input attribution techniques. Notably, our framework also provides a simple counterfactual "proof" of each case, which can be verified for the input on the model (i.e. without running the method again). We demonstrate that the method performs well for a number of samples from the ImageNet validation set and on multiple models.</li>
</ul>

<h3>Title: Measuring memorization through probabilistic discoverable extraction</h3>
<ul>
<li><strong>Authors: </strong>Jamie Hayes, Marika Swanberg, Harsh Chaudhari, Itay Yona, Ilia Shumailov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19482">https://arxiv.org/abs/2410.19482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19482">https://arxiv.org/pdf/2410.19482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19482]] Measuring memorization through probabilistic discoverable extraction(https://arxiv.org/abs/2410.19482)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are susceptible to memorizing training data, raising concerns due to the potential extraction of sensitive information. Current methods to measure memorization rates of LLMs, primarily discoverable extraction (Carlini et al., 2022), rely on single-sequence greedy sampling, potentially underestimating the true extent of memorization. This paper introduces a probabilistic relaxation of discoverable extraction that quantifies the probability of extracting a target sequence within a set of generated samples, considering various sampling schemes and multiple attempts. This approach addresses the limitations of reporting memorization rates through discoverable extraction by accounting for the probabilistic nature of LLMs and user interaction patterns. Our experiments demonstrate that this probabilistic measure can reveal cases of higher memorization rates compared to rates found through discoverable extraction. We further investigate the impact of different sampling schemes on extractability, providing a more comprehensive and realistic assessment of LLM memorization and its associated risks. Our contributions include a new probabilistic memorization definition, empirical evidence of its effectiveness, and a thorough evaluation across different models, sizes, sampling schemes, and training data repetitions.</li>
</ul>

<h3>Title: A Debate-Driven Experiment on LLM Hallucinations and Accuracy</h3>
<ul>
<li><strong>Authors: </strong>Ray Li, Tanishka Bagade, Kevin Martinez, Flora Yasmin, Grant Ayala, Michael Lam, Kevin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19485">https://arxiv.org/abs/2410.19485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19485">https://arxiv.org/pdf/2410.19485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19485]] A Debate-Driven Experiment on LLM Hallucinations and Accuracy(https://arxiv.org/abs/2410.19485)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved a degree of success in generating coherent and contextually relevant text, yet they remain prone to a significant challenge known as hallucination: producing information that is not substantiated by the input or external knowledge. Previous efforts to mitigate hallucinations have focused on techniques such as fine-tuning models on high-quality datasets, incorporating fact-checking mechanisms, and developing adversarial training methods. While these approaches have shown some promise, they often address the issue at the level of individual model outputs, leaving unexplored the effects of inter-model interactions on hallucination. This study investigates the phenomenon of hallucination in LLMs through a novel experimental framework where multiple instances of GPT-4o-Mini models engage in a debate-like interaction prompted with questions from the TruthfulQA dataset. One model is deliberately instructed to generate plausible but false answers while the other models are asked to respond truthfully. The experiment is designed to assess whether the introduction of misinformation by one model can challenge the truthful majority to better justify their reasoning, improving performance on the TruthfulQA benchmark. The findings suggest that inter-model interactions can offer valuable insights into improving the accuracy and robustness of LLM outputs, complementing existing mitigation strategies.</li>
</ul>

<h3>Title: Graph Linearization Methods for Reasoning on Graphs with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19494">https://arxiv.org/abs/2410.19494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19494">https://arxiv.org/pdf/2410.19494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19494]] Graph Linearization Methods for Reasoning on Graphs with Large Language Models(https://arxiv.org/abs/2410.19494)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have evolved to process multiple modalities beyond text, such as images and audio, which motivates us to explore how to effectively leverage them for graph machine learning tasks. The key question, therefore, is how to transform graphs into linear sequences of tokens, a process we term graph linearization, so that LLMs can handle graphs naturally. We consider that graphs should be linearized meaningfully to reflect certain properties of natural language text, such as local dependency and global alignment, in order to ease contemporary LLMs, trained on trillions of textual tokens, better understand graphs. To achieve this, we developed several graph linearization methods based on graph centrality, degeneracy, and node relabeling schemes. We then investigated their effect on LLM performance in graph reasoning tasks. Experimental results on synthetic graphs demonstrate the effectiveness of our methods compared to random linearization baselines. Our work introduces novel graph representations suitable for LLMs, contributing to the potential integration of graph machine learning with the trend of multi-modal processing using a unified transformer model.</li>
</ul>

<h3>Title: A neural network approach for solving the Monge-Amp\`ere equation with transport boundary condition</h3>
<ul>
<li><strong>Authors: </strong>Roel Hacking, Lisa Kusch, Koondanibha Mitra, Martijn Anthonissen, Wilbert IJzerman</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19496">https://arxiv.org/abs/2410.19496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19496">https://arxiv.org/pdf/2410.19496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19496]] A neural network approach for solving the Monge-Amp\`ere equation with transport boundary condition(https://arxiv.org/abs/2410.19496)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel neural network-based approach to solving the Monge-AmpÃ¨re equation with the transport boundary condition, specifically targeted towards optical design applications. We leverage multilayer perceptron networks to learn approximate solutions by minimizing a loss function that encompasses the equation's residual, boundary conditions, and convexity constraints. Our main results demonstrate the efficacy of this method, optimized using L-BFGS, through a series of test cases encompassing symmetric and asymmetric circle-to-circle, square-to-circle, and circle-to-flower reflector mapping problems. Comparative analysis with a conventional least-squares finite-difference solver reveals the competitive, and often superior, performance of our neural network approach on the test cases examined here. A comprehensive hyperparameter study further illuminates the impact of factors such as sampling density, network architecture, and optimization algorithm. While promising, further investigation is needed to verify the method's robustness for more complicated problems and to ensure consistent convergence. Nonetheless, the simplicity and adaptability of this neural network-based approach position it as a compelling alternative to specialized partial differential equation solvers.</li>
</ul>

<h3>Title: Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Anthony Cui, Pranav Nandyalam, Kevin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19499">https://arxiv.org/abs/2410.19499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19499">https://arxiv.org/pdf/2410.19499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19499]] Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization(https://arxiv.org/abs/2410.19499)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Momentum-Aided Prompt Optimization (MAPO) enhances the efficiency and efficacy of prompt optimization for Large Language Models (LLMs). Building on ProTeGi, MAPO uses positive natural language "gradients" and a momentum-based extension to refine prompts effectively. By tracking gradient history, MAPO avoids local minima and oscillations. It also utilizes beam search and an Upper Confidence Bound (UCB) algorithm for balanced candidate expansion and selection. Benchmark testing shows that MAPO achieves faster convergence time with fewer API calls and higher F1 scores than ProTeGi, proving it as a robust and scalable solution for automated prompt engineering in LLMs.</li>
</ul>

<h3>Title: SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jahyun Koo, Yerin Hwang, Yongil Kim, Taegwan Kang, Hyunkyung Bae, Kyomin Jung</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19503">https://arxiv.org/abs/2410.19503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19503">https://arxiv.org/pdf/2410.19503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19503]] SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models(https://arxiv.org/abs/2410.19503)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the success of Large Language Models (LLMs), they still face challenges related to high inference costs and memory requirements. To address these issues, Knowledge Distillation (KD) has emerged as a popular method for model compression, with student-generated outputs (SGOs) being particularly notable for reducing the mismatch between training and inference. However, SGOs often produce noisy and biased sequences, which can lead to misguidance from the teacher model, especially in long sequences. To mitigate these challenges, we propose SWITCH (Studying WIth TeaCHer for Knowledge Distillation), a novel approach that strategically incorporates the teacher model during the student's sequence generation. SWITCH identifies discrepancies between the token probabilities of the teacher and student models, allowing the teacher to intervene selectively, particularly in long sequences that are more prone to teacher misguidance. Extensive experimental results across three model families and five instruction-following datasets show that SWITCH surpasses traditional KD methods, particularly excelling in the generation of long sequential data.</li>
</ul>

<h3>Title: DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction</h3>
<ul>
<li><strong>Authors: </strong>Zelin Zang, Yuhao Wang, Jinlin Wu, Hong Liu, Yue Shen, Stan.Z Li, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19504">https://arxiv.org/abs/2410.19504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19504">https://arxiv.org/pdf/2410.19504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19504]] DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction(https://arxiv.org/abs/2410.19504)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Dimensionality reduction (DR) plays a crucial role in various fields, including data engineering and visualization, by simplifying complex datasets while retaining essential information. However, the challenge of balancing DR accuracy and interpretability remains crucial, particularly for users dealing with high-dimensional data. Traditional DR methods often face a trade-off between precision and transparency, where optimizing for performance can lead to reduced interpretability, and vice versa. This limitation is especially prominent in real-world applications such as image, tabular, and text data analysis, where both accuracy and interpretability are critical. To address these challenges, this work introduces the MOE-based Hyperbolic Interpretable Deep Manifold Transformation (DMT-HI). The proposed approach combines hyperbolic embeddings, which effectively capture complex hierarchical structures, with Mixture of Experts (MOE) models, which dynamically allocate tasks based on input features. DMT-HI enhances DR accuracy by leveraging hyperbolic embeddings to represent the hierarchical nature of data, while also improving interpretability by explicitly linking input data, embedding outcomes, and key features through the MOE structure. Extensive experiments demonstrate that DMT-HI consistently achieves superior performance in both DR accuracy and model interpretability, making it a robust solution for complex data analysis. The code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Marked Temporal Bayesian Flow Point Processes</h3>
<ul>
<li><strong>Authors: </strong>Hui Chen, Xuhui Fan, Hengyu Liu, Longbing Cao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19512">https://arxiv.org/abs/2410.19512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19512">https://arxiv.org/pdf/2410.19512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19512]] Marked Temporal Bayesian Flow Point Processes(https://arxiv.org/abs/2410.19512)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Marked event data captures events by recording their continuous-valued occurrence timestamps along with their corresponding discrete-valued types. They have appeared in various real-world scenarios such as social media, financial transactions, and healthcare records, and have been effectively modeled through Marked Temporal Point Process (MTPP) models. Recently, developing generative models for these MTPP models have seen rapid development due to their powerful generative capability and less restrictive functional forms. However, existing generative MTPP models are usually challenged in jointly modeling events' timestamps and types since: (1) mainstream methods design the generative mechanisms for timestamps only and do not include event types; (2) the complex interdependence between the timestamps and event types are overlooked. In this paper, we propose a novel generative MTPP model called BMTPP. Unlike existing generative MTPP models, BMTPP flexibly models marked temporal joint distributions using a parameter-based approach. Additionally, by adding joint noise to the marked temporal data space, BMTPP effectively captures and explicitly reveals the interdependence between timestamps and event types. Extensive experiments validate the superiority of our approach over other state-of-the-art models and its ability to effectively capture marked-temporal interdependence.</li>
</ul>

<h3>Title: Detection of Human and Machine-Authored Fake News in Urdu</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony Smith</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19517">https://arxiv.org/abs/2410.19517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19517">https://arxiv.org/pdf/2410.19517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19517]] Detection of Human and Machine-Authored Fake News in Urdu(https://arxiv.org/abs/2410.19517)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rise of social media has amplified the spread of fake news, now further complicated by large language models (LLMs) like ChatGPT, which ease the generation of highly convincing, error-free misinformation, making it increasingly challenging for the public to discern truth from falsehood. Traditional fake news detection methods relying on linguistic cues also becomes less effective. Moreover, current detectors primarily focus on binary classification and English texts, often overlooking the distinction between machine-generated true vs. fake news and the detection in low-resource languages. To this end, we updated detection schema to include machine-generated news with focus on the Urdu language. We further propose a hierarchical detection strategy to improve the accuracy and robustness. Experiments show its effectiveness across four datasets in various settings.</li>
</ul>

<h3>Title: Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series</h3>
<ul>
<li><strong>Authors: </strong>Ilan Naiman, Nimrod Berman, Itai Pemper, Idan Arbiv, Gal Fadlon, Omri Azencot</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19538">https://arxiv.org/abs/2410.19538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19538">https://arxiv.org/pdf/2410.19538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19538]] Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series(https://arxiv.org/abs/2410.19538)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Lately, there has been a surge in interest surrounding generative modeling of time series data. Most existing approaches are designed either to process short sequences or to handle long-range sequences. This dichotomy can be attributed to gradient issues with recurrent networks, computational costs associated with transformers, and limited expressiveness of state space models. Towards a unified generative model for varying-length time series, we propose in this work to transform sequences into images. By employing invertible transforms such as the delay embedding and the short-time Fourier transform, we unlock three main advantages: i) We can exploit advanced diffusion vision models; ii) We can remarkably process short- and long-range inputs within the same framework; and iii) We can harness recent and established tools proposed in the time series to image literature. We validate the effectiveness of our method through a comprehensive evaluation across multiple tasks, including unconditional generation, interpolation, and extrapolation. We show that our approach achieves consistently state-of-the-art results against strong baselines. In the unconditional generation tasks, we show remarkable mean improvements of 58.17% over previous diffusion models in the short discriminative score and 132.61% in the (ultra-)long classification scores. Code is at this https URL.</li>
</ul>

<h3>Title: FLiP: Privacy-Preserving Federated Learning based on the Principle of Least Privileg</h3>
<ul>
<li><strong>Authors: </strong>ShiMao Xu, Xiaopeng Ke, Xing Su, Shucheng Li, Hao wu, Fengyuan Xu, Sheng Zhong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19548">https://arxiv.org/abs/2410.19548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19548">https://arxiv.org/pdf/2410.19548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19548]] FLiP: Privacy-Preserving Federated Learning based on the Principle of Least Privileg(https://arxiv.org/abs/2410.19548)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, membership infer, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) allows users to share knowledge instead of raw data to train a model with high accuracy. Unfortunately, during the training, users lose control over the knowledge shared, which causes serious data privacy issues. We hold that users are only willing and need to share the essential knowledge to the training task to obtain the FL model with high accuracy. However, existing efforts cannot help users minimize the shared knowledge according to the user intention in the FL training procedure. This work proposes FLiP, which aims to bring the principle of least privilege (PoLP) to FL training. The key design of FLiP is applying elaborate information reduction on the training data through a local-global dataset distillation design. We measure the privacy performance through attribute inference and membership inference attacks. Extensive experiments show that FLiP strikes a good balance between model accuracy and privacy protection.</li>
</ul>

<h3>Title: On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes</h3>
<ul>
<li><strong>Authors: </strong>Rajat Modi, Vibhav Vineet, Yogesh Singh Rawat</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19553">https://arxiv.org/abs/2410.19553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19553">https://arxiv.org/pdf/2410.19553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19553]] On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes(https://arxiv.org/abs/2410.19553)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper explores the impact of occlusions in video action detection. We facilitate this study by introducing five new benchmark datasets namely O-UCF and O-JHMDB consisting of synthetically controlled static/dynamic occlusions, OVIS-UCF and OVIS-JHMDB consisting of occlusions with realistic motions and Real-OUCF for occlusions in realistic-world scenarios. We formally confirm an intuitive expectation: existing models suffer a lot as occlusion severity is increased and exhibit different behaviours when occluders are static vs when they are moving. We discover several intriguing phenomenon emerging in neural nets: 1) transformers can naturally outperform CNN models which might have even used occlusion as a form of data augmentation during training 2) incorporating symbolic-components like capsules to such backbones allows them to bind to occluders never even seen during training and 3) Islands of agreement can emerge in realistic images/videos without instance-level supervision, distillation or contrastive-based objectives2(eg. video-textual training). Such emergent properties allow us to derive simple yet effective training recipes which lead to robust occlusion models inductively satisfying the first two stages of the binding mechanism (grouping/segregation). Models leveraging these recipes outperform existing video action-detectors under occlusion by 32.3% on O-UCF, 32.7% on O-JHMDB & 2.6% on Real-OUCF in terms of the vMAP metric. The code for this work has been released at this https URL.</li>
</ul>

<h3>Title: ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems</h3>
<ul>
<li><strong>Authors: </strong>Ritvik Aggarwal Ishneet Sukhvinder Singh Ibrahim Allahverdiyev, Muhammad Taha, Aslihan Akalin, Kevin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19572">https://arxiv.org/abs/2410.19572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19572">https://arxiv.org/pdf/2410.19572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19572]] ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems(https://arxiv.org/abs/2410.19572)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) systems using large language models (LLMs) often generate inaccurate responses due to the retrieval of irrelevant or loosely related information. Existing methods, which operate at the document level, fail to effectively filter out such content. We propose LLM-driven chunk filtering, ChunkRAG, a framework that enhances RAG systems by evaluating and filtering retrieved information at the chunk level. Our approach employs semantic chunking to divide documents into coherent sections and utilizes LLM-based relevance scoring to assess each chunk's alignment with the user's query. By filtering out less pertinent chunks before the generation phase, we significantly reduce hallucinations and improve factual accuracy. Experiments show that our method outperforms existing RAG models, achieving higher accuracy on tasks requiring precise information retrieval. This advancement enhances the reliability of RAG systems, making them particularly beneficial for applications like fact-checking and multi-hop reasoning.</li>
</ul>

<h3>Title: FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Zhang, Guocheng Qian, Jin Xie, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19573">https://arxiv.org/abs/2410.19573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19573">https://arxiv.org/pdf/2410.19573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19573]] FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation(https://arxiv.org/abs/2410.19573)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Point cloud frame interpolation is a challenging task that involves accurate scene flow estimation across frames and maintaining the geometry structure. Prevailing techniques often rely on pre-trained motion estimators or intensive testing-time optimization, resulting in compromised interpolation accuracy or prolonged inference. This work presents FastPCI that introduces Pyramid Convolution-Transformer architecture for point cloud frame interpolation. Our hybrid Convolution-Transformer improves the local and long-range feature learning, while the pyramid network offers multilevel features and reduces the computation. In addition, FastPCI proposes a unique Dual-Direction Motion-Structure block for more accurate scene flow estimation. Our design is motivated by two facts: (1) accurate scene flow preserves 3D structure, and (2) point cloud at the previous timestep should be reconstructable using reverse motion from future timestep. Extensive experiments show that FastPCI significantly outperforms the state-of-the-art PointINet and NeuralPCI with notable gains (e.g. 26.6% and 18.3% reduction in Chamfer Distance in KITTI), while being more than 10x and 600x faster, respectively. Code is available at this https URL</li>
</ul>

<h3>Title: MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors</h3>
<ul>
<li><strong>Authors: </strong>Fanqi Pu, Yifan Wang, Jiru Deng, Wenming Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19590">https://arxiv.org/abs/2410.19590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19590">https://arxiv.org/pdf/2410.19590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19590]] MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors(https://arxiv.org/abs/2410.19590)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Perspective projection has been extensively utilized in monocular 3D object detection methods. It introduces geometric priors from 2D bounding boxes and 3D object dimensions to reduce the uncertainty of depth estimation. However, due to depth errors originating from the object's visual surface, the height of the bounding box often fails to represent the actual projected central height, which undermines the effectiveness of geometric depth. Direct prediction for the projected height unavoidably results in a loss of 2D priors, while multi-depth prediction with complex branches does not fully leverage geometric depth. This paper presents a Transformer-based monocular 3D object detection method called MonoDGP, which adopts perspective-invariant geometry errors to modify the projection formula. We also try to systematically discuss and explain the mechanisms and efficacy behind geometry errors, which serve as a simple but effective alternative to multi-depth prediction. Additionally, MonoDGP decouples the depth-guided decoder and constructs a 2D decoder only dependent on visual features, providing 2D priors and initializing object queries without the disturbance of 3D detection. To further optimize and fine-tune input tokens of the transformer decoder, we also introduce a Region Segment Head (RSH) that generates enhanced features and segment embeddings. Our monocular method demonstrates state-of-the-art performance on the KITTI benchmark without extra data. Code is available at this https URL.</li>
</ul>

<h3>Title: Microplastic Identification Using AI-Driven Image Segmentation and GAN-Generated Ecological Context</h3>
<ul>
<li><strong>Authors: </strong>Alex Dils, David Raymond, Jack Spottiswood, Samay Kodige, Dylan Karmin, Rikhil Kokal, Win Cowger, Chris SadÃ©e</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19604">https://arxiv.org/abs/2410.19604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19604">https://arxiv.org/pdf/2410.19604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19604]] Microplastic Identification Using AI-Driven Image Segmentation and GAN-Generated Ecological Context(https://arxiv.org/abs/2410.19604)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Current methods for microplastic identification in water samples are costly and require expert analysis. Here, we propose a deep learning segmentation model to automatically identify microplastics in microscopic images. We labeled images of microplastic from the Moore Institute for Plastic Pollution Research and employ a Generative Adversarial Network (GAN) to supplement and generate diverse training data. To verify the validity of the generated data, we conducted a reader study where an expert was able to discern the generated microplastic from real microplastic at a rate of 68 percent. Our segmentation model trained on the combined data achieved an F1-Score of 0.91 on a diverse dataset, compared to the model without generated data's 0.82. With our findings we aim to enhance the ability of both experts and citizens to detect microplastic across diverse ecological contexts, thereby improving the cost and accessibility of microplastic analysis.</li>
</ul>

<h3>Title: Analyzing Neural Network Robustness Using Graph Curvature</h3>
<ul>
<li><strong>Authors: </strong>Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19607">https://arxiv.org/abs/2410.19607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19607">https://arxiv.org/pdf/2410.19607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19607]] Analyzing Neural Network Robustness Using Graph Curvature(https://arxiv.org/abs/2410.19607)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a new look at the neural network (NN) robustness problem, from the point of view of graph theory analysis, specifically graph curvature. Graph curvature (e.g., Ricci curvature) has been used to analyze system dynamics and identify bottlenecks in many domains, including road traffic analysis and internet routing. We define the notion of neural Ricci curvature and use it to identify bottleneck NN edges that are heavily used to ``transport data" to the NN outputs. We provide an evaluation on MNIST that illustrates that such edges indeed occur more frequently for inputs where NNs are less robust. These results will serve as the basis for an alternative method of robust training, by minimizing the number of bottleneck edges.</li>
</ul>

<h3>Title: A distributional simplicity bias in the learning dynamics of transformers</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Rende, Federica Gerace, Alessandro Laio, Sebastian Goldt</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19637">https://arxiv.org/abs/2410.19637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19637">https://arxiv.org/pdf/2410.19637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19637]] A distributional simplicity bias in the learning dynamics of transformers(https://arxiv.org/abs/2410.19637)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The remarkable capability of over-parameterised neural networks to generalise effectively has been explained by invoking a ``simplicity bias'': neural networks prevent overfitting by initially learning simple classifiers before progressing to more complex, non-linear functions. While simplicity biases have been described theoretically and experimentally in feed-forward networks for supervised learning, the extent to which they also explain the remarkable success of transformers trained with self-supervised techniques remains unclear. In our study, we demonstrate that transformers, trained on natural language data, also display a simplicity bias. Specifically, they sequentially learn many-body interactions among input tokens, reaching a saturation point in the prediction error for low-degree interactions while continuing to learn high-degree interactions. To conduct this analysis, we develop a procedure to generate \textit{clones} of a given natural language data set, which rigorously capture the interactions between tokens up to a specified order. This approach opens up the possibilities of studying how interactions of different orders in the data affect learning, in natural language processing and beyond.</li>
</ul>

<h3>Title: DiffGS: Functional Gaussian Splatting Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Junsheng Zhou, Weiqi Zhang, Yu-Shen Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19657">https://arxiv.org/abs/2410.19657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19657">https://arxiv.org/pdf/2410.19657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19657]] DiffGS: Functional Gaussian Splatting Diffusion(https://arxiv.org/abs/2410.19657)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has shown convincing performance in rendering speed and fidelity, yet the generation of Gaussian Splatting remains a challenge due to its discreteness and unstructured nature. In this work, we propose DiffGS, a general Gaussian generator based on latent diffusion models. DiffGS is a powerful and efficient 3D generative model which is capable of generating Gaussian primitives at arbitrary numbers for high-fidelity rendering with rasterization. The key insight is to represent Gaussian Splatting in a disentangled manner via three novel functions to model Gaussian probabilities, colors and transforms. Through the novel disentanglement of 3DGS, we represent the discrete and unstructured 3DGS with continuous Gaussian Splatting functions, where we then train a latent diffusion model with the target of generating these Gaussian Splatting functions both unconditionally and conditionally. Meanwhile, we introduce a discretization algorithm to extract Gaussians at arbitrary numbers from the generated functions via octree-guided sampling and optimization. We explore DiffGS for various tasks, including unconditional generation, conditional generation from text, image, and partial 3DGS, as well as Point-to-Gaussian generation. We believe that DiffGS provides a new direction for flexibly modeling and generating Gaussian Splatting.</li>
</ul>

<h3>Title: MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services</h3>
<ul>
<li><strong>Authors: </strong>Hongjia Wu, Hui Zeng, Zehui Xiong, Jiawen Kang, Zhiping Cai, Tse-Tin Chan, Dusit Niyato, Zhu Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19665">https://arxiv.org/abs/2410.19665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19665">https://arxiv.org/pdf/2410.19665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19665]] MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services(https://arxiv.org/abs/2410.19665)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Updates of extensive Internet of Things (IoT) data are critical to the immersion of vehicular metaverse services. However, providing high-quality and sustainable data in unstable and resource-constrained vehicular networks remains a significant challenge. To address this problem, we put forth a novel immersion-aware model trading framework that incentivizes metaverse users (MUs) to contribute learning models trained by their latest local data for augmented reality (AR) services in the vehicular metaverse, while preserving their privacy through federated learning. To comprehensively evaluate the contribution of locally trained learning models provided by MUs to AR services, we design a new immersion metric that captures service immersion by considering the freshness and accuracy of learning models, as well as the amount and potential value of raw data used for training. We model the trading interactions between metaverse service providers (MSPs) and MUs as an equilibrium problem with equilibrium constraints (EPEC) to analyze and balance their costs and gains. Moreover, considering dynamic network conditions and privacy concerns, we formulate the reward decisions of MSPs as a multi-agent Markov decision process. Then, a fully distributed dynamic reward method based on deep reinforcement learning is presented, which operates without any private information about MUs and other MSPs. Experimental results demonstrate that the proposed framework can effectively provide higher-value models for object detection and classification in AR services on real AR-related vehicle datasets compared to benchmark schemes.</li>
</ul>

<h3>Title: ProvocationProbe: Instigating Hate Speech Dataset from Twitter</h3>
<ul>
<li><strong>Authors: </strong>Abhay Kumar, Vigneshwaran Shankaran, Rajesh Sharma</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19687">https://arxiv.org/abs/2410.19687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19687">https://arxiv.org/pdf/2410.19687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19687]] ProvocationProbe: Instigating Hate Speech Dataset from Twitter(https://arxiv.org/abs/2410.19687)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In the recent years online social media platforms has been flooded with hateful remarks such as racism, sexism, homophobia etc. As a result, there have been many measures taken by various social media platforms to mitigate the spread of hate-speech over the internet. One particular concept within the domain of hate speech is instigating hate, which involves provoking hatred against a particular community, race, colour, gender, religion or ethnicity. In this work, we introduce \textit{ProvocationProbe} - a dataset designed to explore what distinguishes instigating hate speech from general hate speech. For this study, we collected around twenty thousand tweets from Twitter, encompassing a total of nine global controversies. These controversies span various themes including racism, politics, and religion. In this paper, i) we present an annotated dataset after comprehensive examination of all the controversies, ii) we also highlight the difference between hate speech and instigating hate speech by identifying distinguishing features, such as targeted identity attacks and reasons for hate.</li>
</ul>

<h3>Title: Deep Learning for Classification of Inflammatory Bowel Disease Activity in Whole Slide Images of Colonic Histopathology</h3>
<ul>
<li><strong>Authors: </strong>Amit Das, Tanmay Shukla, Naofumi Tomita, Ryland Richards, Laura Vidis, Bing Ren, Saeed Hassanpour</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19690">https://arxiv.org/abs/2410.19690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19690">https://arxiv.org/pdf/2410.19690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19690]] Deep Learning for Classification of Inflammatory Bowel Disease Activity in Whole Slide Images of Colonic Histopathology(https://arxiv.org/abs/2410.19690)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Grading inflammatory bowel disease (IBD) activity using standardized histopathological scoring systems remains challenging due to resource constraints and inter-observer variability. In this study, we developed a deep learning model to classify activity grades in hematoxylin and eosin-stained whole slide images (WSIs) from patients with IBD, offering a robust approach for general pathologists. We utilized 2,077 WSIs from 636 patients treated at Dartmouth-Hitchcock Medical Center in 2018 and 2019, scanned at 40x magnification (0.25 micron/pixel). Board-certified gastrointestinal pathologists categorized the WSIs into four activity classes: inactive, mildly active, moderately active, and severely active. A transformer-based model was developed and validated using five-fold cross-validation to classify IBD activity. Using HoVerNet, we examined neutrophil distribution across activity grades. Attention maps from our model highlighted areas contributing to its prediction. The model classified IBD activity with weighted averages of 0.871 [95% Confidence Interval (CI): 0.860-0.883] for the area under the curve, 0.695 [95% CI: 0.674-0.715] for precision, 0.697 [95% CI: 0.678-0.716] for recall, and 0.695 [95% CI: 0.674-0.714] for F1-score. Neutrophil distribution was significantly different across activity classes. Qualitative evaluation of attention maps by a gastrointestinal pathologist suggested their potential for improved interpretability. Our model demonstrates robust diagnostic performance and could enhance consistency and efficiency in IBD activity assessment.</li>
</ul>

<h3>Title: Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yifei Zhang, Hao Zhu, Aiwei Liu, Han Yu, Piotr Koniusz, Irwin King</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19694">https://arxiv.org/abs/2410.19694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19694">https://arxiv.org/pdf/2410.19694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19694]] Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs(https://arxiv.org/abs/2410.19694)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning Large Language Models (LLMs) has become a crucial technique for adapting pre-trained models to downstream tasks. However, the enormous size of LLMs poses significant challenges in terms of computational complexity and resource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising solution. However, there exists a gap between the practical performance of low-rank adaptations and its theoretical optimum. In this work, we propose eXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this gap by leveraging the power of ensemble learning. Inspired by gradient boosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations to refine model predictions. It achieves better performance than the standard LoRA, while enjoying the computational efficiency of rank-1 adaptations. We provide theoretical analysis to show the convergence and optimality of our approach, and conduct extensive experiments on a range of natural language processing tasks. The results demonstrate that XGBLoRA consistently outperforms standard LoRA and achieves performance comparable to full fine-tuning with significantly fewer trainable parameters. This work advances parameter-efficient fine-tuning for LLMs, and offers a promising solution for adapting LLMs to downstream tasks while optimizing performance and efficiency.</li>
</ul>

<h3>Title: TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Zeng, Kunchang Li, Chenting Wang, Xinhao Li, Tianxiang Jiang, Ziang Yan, Songze Li, Yansong Shi, Zhengrong Yue, Yi Wang, Yali Wang, Yu Qiao, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19702">https://arxiv.org/abs/2410.19702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19702">https://arxiv.org/pdf/2410.19702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19702]] TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning(https://arxiv.org/abs/2410.19702)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have demonstrated impressive performance in short video understanding. However, understanding long-form videos still remains challenging for MLLMs. This paper proposes TimeSuite, a collection of new designs to adapt the existing short-form video MLLMs for long video understanding, including a simple yet efficient framework to process long video sequence, a high-quality video dataset for grounded tuning of MLLMs, and a carefully-designed instruction tuning task to explicitly incorporate the grounding supervision in the traditional QA format. Specifically, based on VideoChat, we propose our long-video MLLM, coined as VideoChat-T, by implementing a token shuffling to compress long video tokens and introducing Temporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness of visual representation. Meanwhile, we introduce the TimePro, a comprehensive grounding-centric instruction tuning dataset composed of 9 tasks and 349k high-quality grounded annotations. Notably, we design a new instruction tuning task type, called Temporal Grounded Caption, to peform detailed video descriptions with the corresponding time stamps prediction. This explicit temporal location prediction will guide MLLM to correctly attend on the visual content when generating description, and thus reduce the hallucination risk caused by the LLMs. Experimental results demonstrate that our TimeSuite provides a successful solution to enhance the long video understanding capability of short-form MLLM, achieving improvement of 5.6% and 6.8% on the benchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-T exhibits robust zero-shot temporal grounding capabilities, significantly outperforming the existing state-of-the-art MLLMs. After fine-tuning, it performs on par with the traditional supervised expert models.</li>
</ul>

<h3>Title: Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yinglun Xu, Zhiwei Wang, Gagandeep Singh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19705">https://arxiv.org/abs/2410.19705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19705">https://arxiv.org/pdf/2410.19705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19705]] Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks(https://arxiv.org/abs/2410.19705)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Thompson sampling is one of the most popular learning algorithms for online sequential decision-making problems and has rich real-world applications. However, current Thompson sampling algorithms are limited by the assumption that the rewards received are uncorrupted, which may not be true in real-world applications where adversarial reward poisoning exists. To make Thompson sampling more reliable, we want to make it robust against adversarial reward poisoning. The main challenge is that one can no longer compute the actual posteriors for the true reward, as the agent can only observe the rewards after corruption. In this work, we solve this problem by computing pseudo-posteriors that are less likely to be manipulated by the attack. We propose robust algorithms based on Thompson sampling for the popular stochastic and contextual linear bandit settings in both cases where the agent is aware or unaware of the budget of the attacker. We theoretically show that our algorithms guarantee near-optimal regret under any attack strategy.</li>
</ul>

<h3>Title: Super Gradient Descent: Global Optimization requires Global Gradient</h3>
<ul>
<li><strong>Authors: </strong>Seifeddine Achour</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19706">https://arxiv.org/abs/2410.19706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19706">https://arxiv.org/pdf/2410.19706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19706]] Super Gradient Descent: Global Optimization requires Global Gradient(https://arxiv.org/abs/2410.19706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Global minimization is a fundamental challenge in optimization, especially in machine learning, where finding the global minimum of a function directly impacts model performance and convergence. This report introduces a novel optimization method that we called Super Gradient Descent, designed specifically for one-dimensional functions, guaranteeing convergence to the global minimum for any k-Lipschitz function defined on a closed interval [a, b]. Our approach addresses the limitations of traditional optimization algorithms, which often get trapped in local minima. In particular, we introduce the concept of global gradient which offers a robust solution for precise and well-guided global optimization. By focusing on the global minimization problem, this work bridges a critical gap in optimization theory, offering new insights and practical advancements in different optimization problems in particular Machine Learning problems like line search.</li>
</ul>

<h3>Title: Adversarial Environment Design via Regret-Guided Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Hojun Chung, Junseo Lee, Minsoo Kim, Dohyeong Kim, Songhwai Oh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19715">https://arxiv.org/abs/2410.19715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19715">https://arxiv.org/pdf/2410.19715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19715]] Adversarial Environment Design via Regret-Guided Diffusion Models(https://arxiv.org/abs/2410.19715)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Training agents that are robust to environmental changes remains a significant challenge in deep reinforcement learning (RL). Unsupervised environment design (UED) has recently emerged to address this issue by generating a set of training environments tailored to the agent's capabilities. While prior works demonstrate that UED has the potential to learn a robust policy, their performance is constrained by the capabilities of the environment generation. To this end, we propose a novel UED algorithm, adversarial environment design via regret-guided diffusion models (ADD). The proposed method guides the diffusion-based environment generator with the regret of the agent to produce environments that the agent finds challenging but conducive to further improvement. By exploiting the representation power of diffusion models, ADD can directly generate adversarial environments while maintaining the diversity of training environments, enabling the agent to effectively learn a robust policy. Our experimental results demonstrate that the proposed method successfully generates an instructive curriculum of environments, outperforming UED baselines in zero-shot generalization across novel, out-of-distribution environments. Project page: this https URL</li>
</ul>

<h3>Title: Enhanced Anomaly Detection in Industrial Control Systems aided by Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Vegard Berge, Chunlei Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19717">https://arxiv.org/abs/2410.19717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19717">https://arxiv.org/pdf/2410.19717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19717]] Enhanced Anomaly Detection in Industrial Control Systems aided by Machine Learning(https://arxiv.org/abs/2410.19717)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Traditional intrusion detection systems (IDSs) often rely on either network traffic or process data, but this single-source approach may miss complex attack patterns that span multiple layers within industrial control systems (ICSs) or persistent threats that target different layers of operational technology systems. This study investigates whether combining both network and process data can improve attack detection in ICSs environments. Leveraging the SWaT dataset, we evaluate various machine learning models on individual and combined data sources. Our findings suggest that integrating network traffic with operational process data can enhance detection capabilities, evidenced by improved recall rates for cyber attack classification. Serving as a proof-of-concept within a limited testing environment, this research explores the feasibility of advancing intrusion detection through a multi-source data approach in ICSs. Although the results are promising, they are preliminary and highlight the need for further studies across diverse datasets and refined methodologies.</li>
</ul>

<h3>Title: 2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision</h3>
<ul>
<li><strong>Authors: </strong>Shilong Li, Yancheng He, Hui Huang, Xingyuan Bu, Jiaheng Liu, Hangyu Guo, Weixun Wang, Jihao Gu, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19720">https://arxiv.org/abs/2410.19720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19720">https://arxiv.org/pdf/2410.19720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19720]] 2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision(https://arxiv.org/abs/2410.19720)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Direct Preference Optimization (DPO) have significantly enhanced the alignment of Large Language Models (LLMs) with human preferences, owing to its simplicity and effectiveness. However, existing methods typically optimize a scalar score or ranking reward, thereby overlooking the multi-dimensional nature of human preferences. In this work, we propose to extend the preference of DPO to two dimensions: segments and aspects. We first introduce a 2D supervision dataset called HelpSteer-2D. For the segment dimension, we divide the response into sentences and assign scores to each segment. For the aspect dimension, we meticulously design several criteria covering the response quality rubrics. With the 2-dimensional signals as feedback, we develop a 2D-DPO framework, decomposing the overall objective into multi-segment and multi-aspect objectives. Extensive experiments on popular benchmarks demonstrate that 2D-DPO performs better than methods that optimize for scalar or 1-dimensional preferences.</li>
</ul>

<h3>Title: Counting Ability of Large Language Models and Impact of Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Xiang Zhang, Juntai Cao, Chenyu You</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19730">https://arxiv.org/abs/2410.19730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19730">https://arxiv.org/pdf/2410.19730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19730]] Counting Ability of Large Language Models and Impact of Tokenization(https://arxiv.org/abs/2410.19730)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformers, the backbone of modern large language models (LLMs), face inherent architectural limitations that impede their reasoning capabilities. Unlike recurrent networks, Transformers lack recurrent connections, confining them to constant-depth computation. This restriction places them in the complexity class TC$^0$, making them theoretically incapable of solving tasks that demand increasingly deep reasoning as input length grows. Counting, a fundamental component of many reasoning tasks, also requires reasoning depth to grow linearly to be performed inductively. While previous studies have established the upper limits of counting ability in Transformer-based expert models (i.e., models specifically trained for counting tasks), these findings do not directly extend to general-purpose LLMs due to differences in reasoning mechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning can help alleviate some of the architectural limitations of Transformers in counting tasks. However, little attention has been paid to the role of tokenization in these models. Unlike expert models that often use character-level tokenization, LLMs typically rely on byte-level (BPE) tokenizers, which fundamentally alters the way reasoning is processed. Our work investigates the impact of tokenization on the counting abilities of LLMs, uncovering substantial performance variations based on input tokenization differences. We provide both theoretical and experimental analyses, offering insights into how tokenization choices can undermine models' theoretical computability, thereby inspiring the design of new tokenization methods to enhance reasoning in LLMs.</li>
</ul>

<h3>Title: Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yucheng Zhou, Zhi Rao, Jun Wan, Jianbing Shen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.19732">https://arxiv.org/abs/2410.19732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.19732">https://arxiv.org/pdf/2410.19732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.19732]] Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models(https://arxiv.org/abs/2410.19732)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) excel in cross-model tasks but experience performance declines in long-context reasoning due to overreliance on textual information and reduced visual dependency. In this study, we empirically analyze LVLMs in long-context reasoning, revealing that increased context length leads to a higher dependence on language at the expense of visual dependency. To address this issue, we propose a novel training-free context pruning method that selectively removes less critical textual information. Our approach enhances visual dependency and reduces textual noise, thereby improving LVLM performance in long-context reasoning. We validate our method by constructing a long-context dataset, demonstrating its effectiveness across various LVLMs. Moreover, further analysis confirms the robustness of different token pruning strategies and preliminary explores scaling laws between pruning rates and context length.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
