<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-14</h1>
<h3>Title: Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions</h3>
<ul>
<li><strong>Authors: </strong>Jingxin Xu, Guoshun Nan, Sheng Guan, Sicong Leng, Yilian Liu, Zixiao Wang, Yuyang Ma, Zhili Zhou, Yanzhao Hou, Xiaofeng Tao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08657">https://arxiv.org/abs/2502.08657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08657">https://arxiv.org/pdf/2502.08657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08657]] Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions(https://arxiv.org/abs/2502.08657)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent AI agents, such as ChatGPT and LLaMA, primarily rely on instruction tuning and reinforcement learning to calibrate the output of large language models (LLMs) with human intentions, ensuring the outputs are harmless and helpful. Existing methods heavily depend on the manual annotation of high-quality positive samples, while contending with issues such as noisy labels and minimal distinctions between preferred and dispreferred response data. However, readily available toxic samples with clear safety distinctions are often filtered out, removing valuable negative references that could aid LLMs in safety alignment. In response, we propose PT-ALIGN, a novel safety self-alignment approach that minimizes human supervision by automatically refining positive and toxic samples and performing fine-grained dual instruction tuning. Positive samples are harmless responses, while toxic samples deliberately contain extremely harmful content, serving as a new supervisory signals. Specifically, we utilize LLM itself to iteratively generate and refine training instances by only exploring fewer than 50 human annotations. We then employ two losses, i.e., maximum likelihood estimation (MLE) and fine-grained unlikelihood training (UT), to jointly learn to enhance the LLM's safety. The MLE loss encourages an LLM to maximize the generation of harmless content based on positive samples. Conversely, the fine-grained UT loss guides the LLM to minimize the output of harmful words based on negative samples at the token-level, thereby guiding the model to decouple safety from effectiveness, directing it toward safer fine-tuning objectives, and increasing the likelihood of generating helpful and reliable content. Experiments on 9 popular open-source LLMs demonstrate the effectiveness of our PT-ALIGN for safety alignment, while maintaining comparable levels of helpfulness and usefulness.</li>
</ul>

<h3>Title: Semantic Role Labeling: A Systematical Survey</h3>
<ul>
<li><strong>Authors: </strong>Huiyao Chen, Meishan Zhang, Jing Li, Min Zhang, Lilja Øvrelid, Jan Hajič, Hao Fei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08660">https://arxiv.org/abs/2502.08660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08660">https://arxiv.org/pdf/2502.08660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08660]] Semantic Role Labeling: A Systematical Survey(https://arxiv.org/abs/2502.08660)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Semantic role labeling (SRL) is a central natural language processing (NLP) task aiming to understand the semantic roles within texts, facilitating a wide range of downstream applications. While SRL has garnered extensive and enduring research, there is currently a lack of a comprehensive survey that thoroughly organizes and synthesizes the field. This paper aims to review the entire research trajectory of the SRL community over the past two decades. We begin by providing a complete definition of SRL. To offer a comprehensive taxonomy, we categorize SRL methodologies into four key perspectives: model architectures, syntax feature modeling, application scenarios, and multi-modal extensions. Further, we discuss SRL benchmarks, evaluation metrics, and paradigm modeling approaches, while also exploring practical applications across various domains. Finally, we analyze future research directions in SRL, addressing the evolving role of SRL in the age of large language models (LLMs) and its potential impact on the broader NLP landscape. We maintain a public repository and consistently update related resources at: this https URL</li>
</ul>

<h3>Title: Few-shot_LLM_Synthetic_Data_with_Distribution_Matching</h3>
<ul>
<li><strong>Authors: </strong>Jiyuan Ren, Zhaocheng Du, Zhihao Wen, Qinglin Jia, Sunhao Dai, Chuhan Wu, Zhenhua Dong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08661">https://arxiv.org/abs/2502.08661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08661">https://arxiv.org/pdf/2502.08661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08661]] Few-shot_LLM_Synthetic_Data_with_Distribution_Matching(https://arxiv.org/abs/2502.08661)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) advance, their ability to perform in-context learning and few-shot language generation has improved significantly. This has spurred using LLMs to produce high-quality synthetic data to enhance the performance of smaller models like online retrievers or weak LLMs. However, LLM-generated synthetic data often differs from the real data in key language attributes (e.g., styles, tones, content proportions, etc.). As a result, mixing these synthetic data directly with real data may distort the original data distribution, potentially hindering performance improvements. To solve this, we introduce SynAlign: a synthetic data generation and filtering framework based on key attribute distribution matching. Before generation, SynAlign employs an uncertainty tracker surrogated by the Gaussian Process model to iteratively select data clusters distinct from selected ones as demonstrations for new data synthesis, facilitating the efficient exploration diversity of the real data. Then, a latent attribute reasoning method is employed: the LLM summarizes linguistic attributes of demonstrations and then synthesizes new data based on them. This approach facilitates synthesizing diverse data with linguistic attributes that appear in real this http URL generation, the Maximum Mean Discrepancy is used as the objective function to learn the sampling weight of each synthetic data, ensuring distribution matching with the real data. Our experiments on multiple text prediction tasks show significant performance improvements. We also conducted an online A/B test on an online retriever to demonstrate SynAlign's effectiveness.</li>
</ul>

<h3>Title: Style Extraction on Text Embeddings Using VAE and Parallel Dataset</h3>
<ul>
<li><strong>Authors: </strong>InJin Kong, Shinyee Kang, Yuna Park, Sooyong Kim, Sanghyun Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08668">https://arxiv.org/abs/2502.08668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08668">https://arxiv.org/pdf/2502.08668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08668]] Style Extraction on Text Embeddings Using VAE and Parallel Dataset(https://arxiv.org/abs/2502.08668)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This study investigates the stylistic differences among various Bible translations using a Variational Autoencoder (VAE) model. By embedding textual data into high-dimensional vectors, the study aims to detect and analyze stylistic variations between translations, with a specific focus on distinguishing the American Standard Version (ASV) from other translations. The results demonstrate that each translation exhibits a unique stylistic distribution, which can be effectively identified using the VAE model. These findings suggest that the VAE model is proficient in capturing and differentiating textual styles, although it is primarily optimized for distinguishing a single style. The study highlights the model's potential for broader applications in AI-based text generation and stylistic analysis, while also acknowledging the need for further model refinement to address the complexity of multi-dimensional stylistic relationships. Future research could extend this methodology to other text domains, offering deeper insights into the stylistic features embedded within various types of textual data.</li>
</ul>

<h3>Title: Assessing the Impact of the Quality of Textual Data on Feature Representation and Machine Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Tabinda Sarwar, Antonio Jose Jimeno Yepes, Lawrence Cavedon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08669">https://arxiv.org/abs/2502.08669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08669">https://arxiv.org/pdf/2502.08669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08669]] Assessing the Impact of the Quality of Textual Data on Feature Representation and Machine Learning Models(https://arxiv.org/abs/2502.08669)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Background: Data collected in controlled settings typically results in high-quality datasets. However, in real-world applications, the quality of data collection is often compromised. It is well established that the quality of a dataset significantly impacts the performance of machine learning models. Methods: A rudimentary error rate metric was developed to evaluate textual dataset quality at the token level. Mixtral Large Language Model (LLM) was used to quantify and correct errors in low quality datasets. The study analyzed two healthcare datasets: the high-quality MIMIC-III public hospital dataset and a lower-quality private dataset from Australian aged care homes. Errors were systematically introduced into MIMIC at varying rates, while the ACH dataset quality was improved using the LLM. Results: For the sampled 35,774 and 6,336 patients from the MIMIC and ACH datasets respectively, we used Mixtral to introduce errors in MIMIC and correct errors in ACH. Mixtral correctly detected errors in 63% of progress notes, with 17% containing a single token misclassified due to medical terminology. LLMs demonstrated potential for improving progress note quality by addressing various errors. Under varying error rates, feature representation performance was tolerant to lower error rates (<10%) but declined significantly at higher rates. Conclusions: The study revealed that models performed relatively well on datasets with lower error rates (<10%), but their performance declined significantly as error rates increased (>=10%). Therefore, it is crucial to evaluate the quality of a dataset before utilizing it for machine learning tasks. For datasets with higher error rates, implementing corrective measures is essential to ensure the reliability and effectiveness of machine learning models.</li>
</ul>

<h3>Title: Deep Learning-Driven Malware Classification with API Call Sequence Analysis and Concept Drift Handling</h3>
<ul>
<li><strong>Authors: </strong>Bishwajit Prasad Gond, Durga Prasad Mohapatra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08679">https://arxiv.org/abs/2502.08679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08679">https://arxiv.org/pdf/2502.08679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08679]] Deep Learning-Driven Malware Classification with API Call Sequence Analysis and Concept Drift Handling(https://arxiv.org/abs/2502.08679)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Malware classification in dynamic environments presents a significant challenge due to concept drift, where the statistical properties of malware data evolve over time, complicating detection efforts. To address this issue, we propose a deep learning framework enhanced with a genetic algorithm to improve malware classification accuracy and adaptability. Our approach incorporates mutation operations and fitness score evaluations within genetic algorithms to continuously refine the deep learning model, ensuring robustness against evolving malware threats. Experimental results demonstrate that this hybrid method significantly enhances classification performance and adaptability, outperforming traditional static models. Our proposed approach offers a promising solution for real-time malware classification in ever-changing cybersecurity landscapes.</li>
</ul>

<h3>Title: Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges</h3>
<ul>
<li><strong>Authors: </strong>Safal Shrestha, Minwu Kim, Keith Ross</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08680">https://arxiv.org/abs/2502.08680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08680">https://arxiv.org/pdf/2502.08680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08680]] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges(https://arxiv.org/abs/2502.08680)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Mathematical reasoning in Large Language Models (LLMs) is often evaluated using benchmarks with limited numerical ranges, failing to reflect real-world problem-solving across diverse scales. Furthermore, most existing evaluation methods only compare model outputs to ground-truth answers, obscuring insights into reasoning processes. To address these limitations, we introduce GSM-Ranges, a dataset generator derived from GSM8K that systematically perturbs numerical values in math problems to assess model robustness across varying numerical scales. Additionally, we propose a novel grading methodology that distinguishes between logical and non-logical errors, offering a more precise evaluation of reasoning processes beyond computational accuracy. Our experiments with various models reveal a significant increase in logical error rates-up to 14 percentage points-as numerical complexity rises, demonstrating a general weakness in reasoning with out-of-distribution numerical values. Moreover, while models demonstrate high accuracy on standalone arithmetic tasks, their performance deteriorates substantially when computations are embedded within word problems. These findings provide a comprehensive evaluation of LLMs' mathematical reasoning capabilities and inform future research directions for improving numerical generalization in language models.</li>
</ul>

<h3>Title: Self-Evaluation for Job-Shop Scheduling</h3>
<ul>
<li><strong>Authors: </strong>Imanol Echeverria, Maialen Murua, Roberto Santana</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08684">https://arxiv.org/abs/2502.08684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08684">https://arxiv.org/pdf/2502.08684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08684]] Self-Evaluation for Job-Shop Scheduling(https://arxiv.org/abs/2502.08684)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Combinatorial optimization problems, such as scheduling and route planning, are crucial in various industries but are computationally intractable due to their NP-hard nature. Neural Combinatorial Optimization methods leverage machine learning to address these challenges but often depend on sequential decision-making, which is prone to error accumulation as small mistakes propagate throughout the process. Inspired by self-evaluation techniques in Large Language Models, we propose a novel framework that generates and evaluates subsets of assignments, moving beyond traditional stepwise approaches. Applied to the Job-Shop Scheduling Problem, our method integrates a heterogeneous graph neural network with a Transformer to build a policy model and a self-evaluation function. Experimental validation on challenging, well-known benchmarks demonstrates the effectiveness of our approach, surpassing state-of-the-art methods.</li>
</ul>

<h3>Title: Beyond Models! Explainable Data Valuation and Metric Adaption for Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Renqi Jia, Xiaokun Zhang, Bowei He, Qiannan Zhu, Weitao Xu, Jiehao Chen, Chen Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08685">https://arxiv.org/abs/2502.08685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08685">https://arxiv.org/pdf/2502.08685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08685]] Beyond Models! Explainable Data Valuation and Metric Adaption for Recommendation(https://arxiv.org/abs/2502.08685)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability</a></li>
<li><strong>Abstract: </strong>User behavior records serve as the foundation for recommender systems. While the behavior data exhibits ease of acquisition, it often suffers from varying quality. Current methods employ data valuation to discern high-quality data from low-quality data. However, they tend to employ black-box design, lacking transparency and interpretability. Besides, they are typically tailored to specific evaluation metrics, leading to limited generality across various tasks. To overcome these issues, we propose an explainable and versatile framework DVR which can enhance the efficiency of data utilization tailored to any requirements of the model architectures and evaluation metrics. For explainable data valuation, a data valuator is presented to evaluate the data quality via calculating its Shapley value from the game-theoretic perspective, ensuring robust mathematical properties and reliability. In order to accommodate various evaluation metrics, including differentiable and non-differentiable ones, a metric adapter is devised based on reinforcement learning, where a metric is treated as the reinforcement reward that guides model optimization. Extensive experiments conducted on various benchmarks verify that our framework can improve the performance of current recommendation algorithms on various metrics including ranking accuracy, diversity, and fairness. Specifically, our framework achieves up to 34.7\% improvements over existing methods in terms of representative NDCG metric. The code is available at this https URL.</li>
</ul>

<h3>Title: EEG Artifact Detection and Correction with Deep Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>David Aquilué-Llorens, Aureli Soria-Frisch</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08686">https://arxiv.org/abs/2502.08686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08686">https://arxiv.org/pdf/2502.08686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08686]] EEG Artifact Detection and Correction with Deep Autoencoders(https://arxiv.org/abs/2502.08686)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>EEG signals convey important information about brain activity both in healthy and pathological conditions. However, they are inherently noisy, which poses significant challenges for accurate analysis and interpretation. Traditional EEG artifact removal methods, while effective, often require extensive expert intervention. This study presents LSTEEG, a novel LSTM-based autoencoder designed for the detection and correction of artifacts in EEG signals. Leveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear dependencies in sequential EEG data. LSTEEG demonstrates superior performance in both artifact detection and correction tasks compared to other state-of-the-art convolutional autoencoders. Our methodology enhances the interpretability and utility of the autoencoder's latent space, enabling data-driven automated artefact removal in EEG its application in downstream tasks. This research advances the field of efficient and accurate multi-channel EEG preprocessing, and promotes the implementation and usage of automated EEG analysis pipelines for brain health applications.</li>
</ul>

<h3>Title: Data Augmentation to Improve Large Language Models in Food Hazard and Product Detection</h3>
<ul>
<li><strong>Authors: </strong>Areeg Fahad Rasheed, M. Zarkoosh, Shimam Amer Chasib, Safa F. Abbas</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08687">https://arxiv.org/abs/2502.08687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08687">https://arxiv.org/pdf/2502.08687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08687]] Data Augmentation to Improve Large Language Models in Food Hazard and Product Detection(https://arxiv.org/abs/2502.08687)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The primary objective of this study is to demonstrate the impact of data augmentation using ChatGPT-4o-mini on food hazard and product analysis. The augmented data is generated using ChatGPT-4o-mini and subsequently used to train two large language models: RoBERTa-base and Flan-T5-base. The models are evaluated on test sets. The results indicate that using augmented data helped improve model performance across key metrics, including recall, F1 score, precision, and accuracy, compared to using only the provided dataset. The full code, including model training and the augmented dataset, can be found in this repository: this https URL</li>
</ul>

<h3>Title: Advancing machine fault diagnosis: A detailed examination of convolutional neural networks</h3>
<ul>
<li><strong>Authors: </strong>Govind Vashishtha, Sumika Chauhan, Mert Sehri, Justyna Hebda-Sobkowicz, Radoslaw Zimroz, Patrick Dumond, Rajesh Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08689">https://arxiv.org/abs/2502.08689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08689">https://arxiv.org/pdf/2502.08689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08689]] Advancing machine fault diagnosis: A detailed examination of convolutional neural networks(https://arxiv.org/abs/2502.08689)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The growing complexity of machinery and the increasing demand for operational efficiency and safety have driven the development of advanced fault diagnosis techniques. Among these, convolutional neural networks (CNNs) have emerged as a powerful tool, offering robust and accurate fault detection and classification capabilities. This comprehensive review delves into the application of CNNs in machine fault diagnosis, covering its theoretical foundation, architectural variations, and practical implementations. The strengths and limitations of CNNs are analyzed in this domain, discussing their effectiveness in handling various fault types, data complexities, and operational environments. Furthermore, we explore the evolving landscape of CNN-based fault diagnosis, examining recent advancements in data augmentation, transfer learning, and hybrid architectures. Finally, we highlight future research directions and potential challenges to further enhance the application of CNNs for reliable and proactive machine fault diagnosis.</li>
</ul>

<h3>Title: Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Hoigi Seo, Wongi Jeong, Jae-sun Seo, Se Young Chun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08690">https://arxiv.org/abs/2502.08690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08690">https://arxiv.org/pdf/2502.08690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08690]] Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation(https://arxiv.org/abs/2502.08690)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Large-scale text encoders in text-to-image (T2I) diffusion models have demonstrated exceptional performance in generating high-quality images from textual prompts. Unlike denoising modules that rely on multiple iterative steps, text encoders require only a single forward pass to produce text embeddings. However, despite their minimal contribution to total inference time and floating-point operations (FLOPs), text encoders demand significantly higher memory usage, up to eight times more than denoising modules. To address this inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet effective pruning strategy specifically designed for text encoders in T2I diffusion models. Skrr exploits the inherent redundancy in transformer blocks by selectively skipping or reusing certain layers in a manner tailored for T2I tasks, thereby reducing memory consumption without compromising performance. Extensive experiments demonstrate that Skrr maintains image quality comparable to the original model even under high sparsity levels, outperforming existing blockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory efficiency while preserving performance across multiple evaluation metrics, including the FID, CLIP, DreamSim, and GenEval scores.</li>
</ul>

<h3>Title: Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Sanokowski, Wilhelm Berghammer, Martin Ennemoser, Haoyu Peter Wang, Sepp Hochreiter, Sebastian Lehner</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.stat-mech, cs.AI, physics.comp-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08696">https://arxiv.org/abs/2502.08696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08696">https://arxiv.org/pdf/2502.08696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08696]] Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics(https://arxiv.org/abs/2502.08696)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Learning to sample from complex unnormalized distributions over discrete domains emerged as a promising research direction with applications in statistical physics, variational inference, and combinatorial optimization. Recent work has demonstrated the potential of diffusion models in this domain. However, existing methods face limitations in memory scaling and thus the number of attainable diffusion steps since they require backpropagation through the entire generative process. To overcome these limitations we introduce two novel training methods for discrete diffusion samplers, one grounded in the policy gradient theorem and the other one leveraging Self-Normalized Neural Importance Sampling (SN-NIS). These methods yield memory-efficient training and achieve state-of-the-art results in unsupervised combinatorial optimization. Numerous scientific applications additionally require the ability of unbiased sampling. We introduce adaptations of SN-NIS and Neural Markov Chain Monte Carlo that enable for the first time the application of discrete diffusion models to this problem. We validate our methods on Ising model benchmarks and find that they outperform popular autoregressive approaches. Our work opens new avenues for applying diffusion models to a wide range of scientific applications in discrete domains that were hitherto restricted to exact likelihood models.</li>
</ul>

<h3>Title: HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Valentina Vadori, Jean-Marie Graïc, Antonella Peruffo, Livio Finos, Ujwala Kiran Chaudhari, Enrico Grisan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08754">https://arxiv.org/abs/2502.08754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08754">https://arxiv.org/pdf/2502.08754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08754]] HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification(https://arxiv.org/abs/2502.08754)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Precise segmentation and classification of cell instances are vital for analyzing the tissue microenvironment in histology images, supporting medical diagnosis, prognosis, treatment planning, and studies of brain cytoarchitecture. However, the creation of high-quality annotated datasets for training remains a major challenge. This study introduces a novel single-stage approach (HistoSmith) for generating image-label pairs to augment histology datasets. Unlike state-of-the-art methods that utilize diffusion models with separate components for label and image generation, our approach employs a latent diffusion model to learn the joint distribution of cellular layouts, classification masks, and histology images. This model enables tailored data generation by conditioning on user-defined parameters such as cell types, quantities, and tissue types. Trained on the Conic H&E histopathology dataset and the Nissl-stained CytoDArk0 dataset, the model generates realistic and diverse labeled samples. Experimental results demonstrate improvements in cell instance segmentation and classification, particularly for underrepresented cell types like neutrophils in the Conic dataset. These findings underscore the potential of our approach to address data scarcity challenges.</li>
</ul>

<h3>Title: Universal Model Routing for Efficient LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Jeevesh Juneja, Zifeng Wang, Chen-Yu Lee, Pradeep Shenoy, Rina Panigrahy, Aditya Krishna Menon, Sanjiv Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08773">https://arxiv.org/abs/2502.08773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08773">https://arxiv.org/pdf/2502.08773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08773]] Universal Model Routing for Efficient LLM Inference(https://arxiv.org/abs/2502.08773)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models' significant advances in capabilities are accompanied by significant increases in inference costs. Model routing is a simple technique for reducing inference cost, wherein one maintains a pool of candidate LLMs, and learns to route each prompt to the smallest feasible LLM. Existing works focus on learning a router for a fixed pool of LLMs. In this paper, we consider the problem of dynamic routing, where new, previously unobserved LLMs are available at test time. We propose a new approach to this problem that relies on representing each LLM as a feature vector, derived based on predictions on a set of representative prompts. Based on this, we detail two effective strategies, relying on cluster-based routing and a learned cluster map respectively. We prove that these strategies are estimates of a theoretically optimal routing rule, and provide an excess risk bound to quantify their errors. Experiments on a range of public benchmarks show the effectiveness of the proposed strategies in routing amongst more than 30 unseen LLMs.</li>
</ul>

<h3>Title: Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound</h3>
<ul>
<li><strong>Authors: </strong>Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08774">https://arxiv.org/abs/2502.08774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08774">https://arxiv.org/pdf/2502.08774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08774]] Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound(https://arxiv.org/abs/2502.08774)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Monitoring the growth of subcortical regions of the fetal brain in ultrasound (US) images can help identify the presence of abnormal development. Manually segmenting these regions is a challenging task, but recent work has shown that it can be automated using deep learning. However, applying pretrained models to unseen freehand US volumes often leads to a degradation of performance due to the vast differences in acquisition and alignment. In this work, we first demonstrate that test time adaptation (TTA) can be used to improve model performance in the presence of both real and simulated domain shifts. We further propose a novel TTA method by incorporating a normative atlas as a prior for anatomy. In the presence of various types of domain shifts, we benchmark the performance of different TTA methods and demonstrate the improvements brought by our proposed approach, which may further facilitate automated monitoring of fetal brain development. Our code is available at this https URL.</li>
</ul>

<h3>Title: SB-Bench: Stereotype Bias Benchmark for Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Vishal Narnaware, Ashmal Vayani, Rohit Gupta, Swetha Sirnam, Mubarak Shah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08779">https://arxiv.org/abs/2502.08779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08779">https://arxiv.org/pdf/2502.08779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08779]] SB-Bench: Stereotype Bias Benchmark for Large Multimodal Models(https://arxiv.org/abs/2502.08779)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Stereotype biases in Large Multimodal Models (LMMs) perpetuate harmful societal prejudices, undermining the fairness and equity of AI applications. As LMMs grow increasingly influential, addressing and mitigating inherent biases related to stereotypes, harmful generations, and ambiguous assumptions in real-world scenarios has become essential. However, existing datasets evaluating stereotype biases in LMMs often lack diversity and rely on synthetic images, leaving a gap in bias evaluation for real-world visual contexts. To address this, we introduce the Stereotype Bias Benchmark (SB-bench), the most comprehensive framework to date for assessing stereotype biases across nine diverse categories with non-synthetic images. SB-bench rigorously evaluates LMMs through carefully curated, visually grounded scenarios, challenging them to reason accurately about visual stereotypes. It offers a robust evaluation framework featuring real-world visual samples, image variations, and multiple-choice question formats. By introducing visually grounded queries that isolate visual biases from textual ones, SB-bench enables a precise and nuanced assessment of a model's reasoning capabilities across varying levels of difficulty. Through rigorous testing of state-of-the-art open-source and closed-source LMMs, SB-bench provides a systematic approach to assessing stereotype biases in LMMs across key social dimensions. This benchmark represents a significant step toward fostering fairness in AI systems and reducing harmful biases, laying the groundwork for more equitable and socially responsible LMMs. Our code and dataset are publicly available.</li>
</ul>

<h3>Title: Learning Discontinuous Galerkin Solutions to Elliptic Problems via Small Linear Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Adrian Celaya, Yimo Wang, David Fuentes, Beatrice Riviere</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08783">https://arxiv.org/abs/2502.08783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08783">https://arxiv.org/pdf/2502.08783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08783]] Learning Discontinuous Galerkin Solutions to Elliptic Problems via Small Linear Convolutional Neural Networks(https://arxiv.org/abs/2502.08783)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In recent years, there has been an increasing interest in using deep learning and neural networks to tackle scientific problems, particularly in solving partial differential equations (PDEs). However, many neural network-based methods, such as physics-informed neural networks, depend on automatic differentiation and the sampling of collocation points, which can result in a lack of interpretability and lower accuracy compared to traditional numerical methods. To address this issue, we propose two approaches for learning discontinuous Galerkin solutions to PDEs using small linear convolutional neural networks. Our first approach is supervised and depends on labeled data, while our second approach is unsupervised and does not rely on any training data. In both cases, our methods use substantially fewer parameters than similar numerics-based neural networks while also demonstrating comparable accuracy to the true and DG solutions for elliptic problems.</li>
</ul>

<h3>Title: If Multi-Agent Debate is the Answer, What is the Question?</h3>
<ul>
<li><strong>Authors: </strong>Hangfan Zhang, Zhiyao Cui, Xinrun Wang, Qiaosheng Zhang, Zhen Wang, Dinghao Wu, Shuyue Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08788">https://arxiv.org/abs/2502.08788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08788">https://arxiv.org/pdf/2502.08788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08788]] If Multi-Agent Debate is the Answer, What is the Question?(https://arxiv.org/abs/2502.08788)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-agent debate (MAD) has emerged as a promising approach to enhance the factual accuracy and reasoning quality of large language models (LLMs) by engaging multiple agents in iterative discussions during inference. Despite its potential, we argue that current MAD research suffers from critical shortcomings in evaluation practices, including limited dataset overlap and inconsistent baselines, raising significant concerns about generalizability. Correspondingly, this paper presents a systematic evaluation of five representative MAD methods across nine benchmarks using four foundational models. Surprisingly, our findings reveal that MAD methods fail to reliably outperform simple single-agent baselines such as Chain-of-Thought and Self-Consistency, even when consuming additional inference-time computation. From our analysis, we found that model heterogeneity can significantly improve MAD frameworks. We propose Heter-MAD enabling a single LLM agent to access the output from heterogeneous foundation models, which boosts the performance of current MAD frameworks. Finally, we outline potential directions for advancing MAD, aiming to spark a broader conversation and inspire future work in this area.</li>
</ul>

<h3>Title: Spectral Journey: How Transformers Predict the Shortest Path</h3>
<ul>
<li><strong>Authors: </strong>Andrew Cohen, Andrey Gromov, Kaiyu Yang, Yuandong Tian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08794">https://arxiv.org/abs/2502.08794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08794">https://arxiv.org/pdf/2502.08794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08794]] Spectral Journey: How Transformers Predict the Shortest Path(https://arxiv.org/abs/2502.08794)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Decoder-only transformers lead to a step-change in capability of large language models. However, opinions are mixed as to whether they are really planning or reasoning. A path to making progress in this direction is to study the model's behavior in a setting with carefully controlled data. Then interpret the learned representations and reverse-engineer the computation performed internally. We study decoder-only transformer language models trained from scratch to predict shortest paths on simple, connected and undirected graphs. In this setting, the representations and the dynamics learned by the model are interpretable. We present three major results: (1) Two-layer decoder-only language models can learn to predict shortest paths on simple, connected graphs containing up to 10 nodes. (2) Models learn a graph embedding that is correlated with the spectral decomposition of the line graph. (3) Following the insights, we discover a novel approximate path-finding algorithm Spectral Line Navigator (SLN) that finds shortest path by greedily selecting nodes in the space of spectral embedding of the line graph.</li>
</ul>

<h3>Title: Low-Resolution Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Eduardo Lobo Lustosa Cabral, Larissa Driemeier</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08795">https://arxiv.org/abs/2502.08795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08795">https://arxiv.org/pdf/2502.08795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08795]] Low-Resolution Neural Networks(https://arxiv.org/abs/2502.08795)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The expanding scale of large neural network models introduces significant challenges, driving efforts to reduce memory usage and enhance computational efficiency. Such measures are crucial to ensure the practical implementation and effective application of these sophisticated models across a wide array of use cases. This study examines the impact of parameter bit precision on model performance compared to standard 32-bit models, with a focus on multiclass object classification in images. The models analyzed include those with fully connected layers, convolutional layers, and transformer blocks, with model weight resolution ranging from 1 bit to 4.08 bits. The findings indicate that models with lower parameter bit precision achieve results comparable to 32-bit models, showing promise for use in memory-constrained devices. While low-resolution models with a small number of parameters require more training epochs to achieve accuracy comparable to 32-bit models, those with a large number of parameters achieve similar performance within the same number of epochs. Additionally, data augmentation can destabilize training in low-resolution models, but including zero as a potential value in the weight parameters helps maintain stability and prevents performance degradation. Overall, 2.32-bit weights offer the optimal balance of memory reduction, performance, and efficiency. However, further research should explore other dataset types and more complex and larger models. These findings suggest a potential new era for optimized neural network models with reduced memory requirements and improved computational efficiency, though advancements in dedicated hardware are necessary to fully realize this potential.</li>
</ul>

<h3>Title: A Systematic Review on the Evaluation of Large Language Models in Theory of Mind Tasks</h3>
<ul>
<li><strong>Authors: </strong>Karahan Sarıtaş, Kıvanç Tezören, Yavuz Durmazkeser</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08796">https://arxiv.org/abs/2502.08796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08796">https://arxiv.org/pdf/2502.08796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08796]] A Systematic Review on the Evaluation of Large Language Models in Theory of Mind Tasks(https://arxiv.org/abs/2502.08796)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, evaluating the Theory of Mind (ToM) capabilities of large language models (LLMs) has received significant attention within the research community. As the field rapidly evolves, navigating the diverse approaches and methodologies has become increasingly complex. This systematic review synthesizes current efforts to assess LLMs' ability to perform ToM tasks, an essential aspect of human cognition involving the attribution of mental states to oneself and others. Despite notable advancements, the proficiency of LLMs in ToM remains a contentious issue. By categorizing benchmarks and tasks through a taxonomy rooted in cognitive science, this review critically examines evaluation techniques, prompting strategies, and the inherent limitations of LLMs in replicating human-like mental state reasoning. A recurring theme in the literature reveals that while LLMs demonstrate emerging competence in ToM tasks, significant gaps persist in their emulation of human cognitive abilities.</li>
</ul>

<h3>Title: Deep EEG Super-Resolution: Upsampling EEG Spatial Resolution with Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Isaac Corley, Yufei Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08803">https://arxiv.org/abs/2502.08803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08803">https://arxiv.org/pdf/2502.08803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08803]] Deep EEG Super-Resolution: Upsampling EEG Spatial Resolution with Generative Adversarial Networks(https://arxiv.org/abs/2502.08803)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Electroencephalography (EEG) activity contains a wealth of information about what is happening within the human brain. Recording more of this data has the potential to unlock endless future applications. However, the cost of EEG hardware is increasingly expensive based upon the number of EEG channels being recorded simultaneously. We combat this problem in this paper by proposing a novel deep EEG super-resolution (SR) approach based on Generative Adversarial Networks (GANs). This approach can produce high spatial resolution EEG data from low resolution samples, by generating channel-wise upsampled data to effectively interpolate numerous missing channels, thus reducing the need for expensive EEG equipment. We tested the performance using an EEG dataset from a mental imagery task. Our proposed GAN model provided 10^4 fold and 10^2 fold reduction in mean-squared error (MSE) and mean-absolute error (MAE), respectively, over the baseline bicubic interpolation method. We further validate our method by training a classifier on the original classification task, which displayed minimal loss in accuracy while using the super-resolved data. The proposed SR EEG by GAN is a promising approach to improve the spatial resolution of low density EEG headsets.</li>
</ul>

<h3>Title: A First-order Generative Bilevel Optimization Framework for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Quan Xiao, Hui Yuan, A F M Saif, Gaowen Liu, Ramana Kompella, Mengdi Wang, Tianyi Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08808">https://arxiv.org/abs/2502.08808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08808">https://arxiv.org/pdf/2502.08808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08808]] A First-order Generative Bilevel Optimization Framework for Diffusion Models(https://arxiv.org/abs/2502.08808)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models, which iteratively denoise data samples to synthesize high-quality outputs, have achieved empirical success across domains. However, optimizing these models for downstream tasks often involves nested bilevel structures, such as tuning hyperparameters for fine-tuning tasks or noise schedules in training dynamics, where traditional bilevel methods fail due to the infinite-dimensional probability space and prohibitive sampling costs. We formalize this challenge as a generative bilevel optimization problem and address two key scenarios: (1) fine-tuning pre-trained models via an inference-only lower-level solver paired with a sample-efficient gradient estimator for the upper level, and (2) training diffusion models from scratch with noise schedule optimization by reparameterizing the lower-level problem and designing a computationally tractable gradient estimator. Our first-order bilevel framework overcomes the incompatibility of conventional bilevel methods with diffusion processes, offering theoretical grounding and computational practicality. Experiments demonstrate that our method outperforms existing fine-tuning and hyperparameter search baselines.</li>
</ul>

<h3>Title: Lexical Manifold Reconfiguration in Large Language Models: A Novel Architectural Approach for Contextual Modulation</h3>
<ul>
<li><strong>Authors: </strong>Koinis Vassilis, Godfrey Milbourne, Harriet Featherstone, Xanthe Peverell, Yorick Bletchley, Zachary Montford</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08818">https://arxiv.org/abs/2502.08818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08818">https://arxiv.org/pdf/2502.08818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08818]] Lexical Manifold Reconfiguration in Large Language Models: A Novel Architectural Approach for Contextual Modulation(https://arxiv.org/abs/2502.08818)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Contextual adaptation in token embeddings plays a central role in determining how well language models maintain coherence and retain semantic relationships over extended text sequences. Static embeddings often impose constraints on lexical flexibility, leading to suboptimal performance when faced with complex sentence structures or domain-specific terminology shifts. To address this limitation, a structured approach was developed for dynamically reconfiguring token embeddings through continuous geometric transformations, ensuring that representations evolved in response to evolving discourse structures. A manifold-based transformation mechanism was integrated to regulate lexical positioning, allowing embeddings to undergo controlled shifts while preserving linguistic relationships across varying textual contexts. Empirical evaluations demonstrated that embedding reconfiguration contributed to reductions in perplexity, improved lexical coherence, and enhanced sentence-level continuity, particularly in structured and domain-adaptive text generation tasks. Comparative analyses of embedding drift indicated that dynamically restructured representations maintained stronger contextual consistency, reducing misalignment in token dependencies while preserving fluency in language modeling outputs. Computational overhead assessments confirmed that while training complexity increased due to the iterative refinement of embeddings, inference remained efficient, ensuring practical feasibility for real-time generation. Evaluations across multiple datasets further demonstrated that dynamically modulated embeddings exhibited broader lexical diversity, reducing repetitive token patterns and enabling a more adaptable representation learning process.</li>
</ul>

<h3>Title: DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps</h3>
<ul>
<li><strong>Authors: </strong>Jocelyn Dzuong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08821">https://arxiv.org/abs/2502.08821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08821">https://arxiv.org/pdf/2502.08821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08821]] DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps(https://arxiv.org/abs/2502.08821)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The recent surge in advanced generative models, such as diffusion models and generative adversarial networks (GANs), has led to an alarming rise in AI-generated images across various domains on the web. While such technologies offer benefits such as democratizing artistic creation, they also pose challenges in misinformation, digital forgery, and authenticity verification. Additionally, the uncredited use of AI-generated images in media and marketing has sparked significant backlash from online communities. In response to this, we introduce DejAIvu, a Chrome Web extension that combines real-time AI-generated image detection with saliency-based explainability while users browse the web. Using an ONNX-optimized deep learning model, DejAIvu automatically analyzes images on websites such as Google Images, identifies AI-generated content using model inference, and overlays a saliency heatmap to highlight AI-related artifacts. Our approach integrates efficient in-browser inference, gradient-based saliency analysis, and a seamless user experience, ensuring that AI detection is both transparent and interpretable. We also evaluate DejAIvu across multiple pretrained architectures and benchmark datasets, demonstrating high accuracy and low latency, making it a practical and deployable tool for enhancing AI image accountability. The code for this system can be found at this https URL.</li>
</ul>

<h3>Title: $\mathsf{CSMAE~}$:~Cataract Surgical Masked Autoencoder (MAE) based Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Nisarg A. Shah, Wele Gedara Chaminda Bandara, Shameema Skider, S. Swaroop Vedula, Vishal M. Patel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08822">https://arxiv.org/abs/2502.08822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08822">https://arxiv.org/pdf/2502.08822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08822]] $\mathsf{CSMAE~}$:~Cataract Surgical Masked Autoencoder (MAE) based Pre-training(https://arxiv.org/abs/2502.08822)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automated analysis of surgical videos is crucial for improving surgical training, workflow optimization, and postoperative assessment. We introduce a CSMAE, Masked Autoencoder (MAE)-based pretraining approach, specifically developed for Cataract Surgery video analysis, where instead of randomly selecting tokens for masking, they are selected based on the spatiotemporal importance of the token. We created a large dataset of cataract surgery videos to improve the model's learning efficiency and expand its robustness in low-data regimes. Our pre-trained model can be easily adapted for specific downstream tasks via fine-tuning, serving as a robust backbone for further analysis. Through rigorous testing on a downstream step-recognition task on two Cataract Surgery video datasets, D99 and Cataract-101, our approach surpasses current state-of-the-art self-supervised pretraining and adapter-based transfer learning methods by a significant margin. This advancement not only demonstrates the potential of our MAE-based pretraining in the field of surgical video analysis but also sets a new benchmark for future research.</li>
</ul>

<h3>Title: Examining and Adapting Time for Multilingual Classification via Mixture of Temporal Experts</h3>
<ul>
<li><strong>Authors: </strong>Weisi Liu, Guangzeng Han, Xiaolei Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08825">https://arxiv.org/abs/2502.08825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08825">https://arxiv.org/pdf/2502.08825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08825]] Examining and Adapting Time for Multilingual Classification via Mixture of Temporal Experts(https://arxiv.org/abs/2502.08825)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time is implicitly embedded in classification process: classifiers are usually built on existing data while to be applied on future data whose distributions (e.g., label and token) may change. However, existing state-of-the-art classification models merely consider the temporal variations and primarily focus on English corpora, which leaves temporal studies less explored, let alone under multilingual settings. In this study, we fill the gap by treating time as domains (e.g., 2024 vs. 2025), examining temporal effects, and developing a domain adaptation framework to generalize classifiers over time on multiple languages. Our framework proposes Mixture of Temporal Experts (MoTE) to leverage both semantic and data distributional shifts to learn and adapt temporal trends into classification models. Our analysis shows classification performance varies over time across different languages, and we experimentally demonstrate that MoTE can enhance classifier generalizability over temporal data shifts. Our study provides analytic insights and addresses the need for time-aware models that perform robustly in multilingual scenarios.</li>
</ul>

<h3>Title: Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08826">https://arxiv.org/abs/2502.08826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08826">https://arxiv.org/pdf/2502.08826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08826]] Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation(https://arxiv.org/abs/2502.08826)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) struggle with hallucinations and outdated knowledge due to their reliance on static training data. Retrieval-Augmented Generation (RAG) mitigates these issues by integrating external dynamic information enhancing factual and updated grounding. Recent advances in multimodal learning have led to the development of Multimodal RAG, incorporating multiple modalities such as text, images, audio, and video to enhance the generated outputs. However, cross-modal alignment and reasoning introduce unique challenges to Multimodal RAG, distinguishing it from traditional unimodal RAG. This survey offers a structured and comprehensive analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks, evaluation, methodologies, and innovations in retrieval, fusion, augmentation, and generation. We precisely review training strategies, robustness enhancements, and loss functions, while also exploring the diverse Multimodal RAG scenarios. Furthermore, we discuss open challenges and future research directions to support advancements in this evolving field. This survey lays the foundation for developing more capable and reliable AI systems that effectively leverage multimodal dynamic external knowledge bases. Resources are available at this https URL.</li>
</ul>

<h3>Title: A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective</h3>
<ul>
<li><strong>Authors: </strong>Wangyang Ying, Cong Wei, Nanxu Gong, Xinyuan Wang, Haoyue Bai, Arun Vignesh Malarkkan, Sixun Dong, Dongjie Wang, Denghui Zhang, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08828">https://arxiv.org/abs/2502.08828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08828">https://arxiv.org/pdf/2502.08828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08828]] A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective(https://arxiv.org/abs/2502.08828)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Tabular data is one of the most widely used data formats across various domains such as bioinformatics, healthcare, and marketing. As artificial intelligence moves towards a data-centric perspective, improving data quality is essential for enhancing model performance in tabular data-driven applications. This survey focuses on data-driven tabular data optimization, specifically exploring reinforcement learning (RL) and generative approaches for feature selection and feature generation as fundamental techniques for refining data spaces. Feature selection aims to identify and retain the most informative attributes, while feature generation constructs new features to better capture complex data patterns. We systematically review existing generative methods for tabular data engineering, analyzing their latest advancements, real-world applications, and respective strengths and limitations. This survey emphasizes how RL-based and generative techniques contribute to the automation and intelligence of feature engineering. Finally, we summarize the existing challenges and discuss future research directions, aiming to provide insights that drive continued innovation in this field.</li>
</ul>

<h3>Title: PLayer-FL: A Principled Approach to Personalized Layer-wise Cross-Silo Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Elhussein, Gamze Gürsoy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08829">https://arxiv.org/abs/2502.08829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08829">https://arxiv.org/pdf/2502.08829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08829]] PLayer-FL: A Principled Approach to Personalized Layer-wise Cross-Silo Federated Learning(https://arxiv.org/abs/2502.08829)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Non-identically distributed data is a major challenge in Federated Learning (FL). Personalized FL tackles this by balancing local model adaptation with global model consistency. One variant, partial FL, leverages the observation that early layers learn more transferable features by federating only early layers. However, current partial FL approaches use predetermined, architecture-specific rules to select layers, limiting their applicability. We introduce Principled Layer-wise-FL (PLayer-FL), which uses a novel federation sensitivity metric to identify layers that benefit from federation. This metric, inspired by model pruning, quantifies each layer's contribution to cross-client generalization after the first training epoch, identifying a transition point in the network where the benefits of federation diminish. We first demonstrate that our federation sensitivity metric shows strong correlation with established generalization measures across diverse architectures. Next, we show that PLayer-FL outperforms existing FL algorithms on a range of tasks, also achieving more uniform performance improvements across clients.</li>
</ul>

<h3>Title: Investigation of Advanced Persistent Threats Network-based Tactics, Techniques and Procedures</h3>
<ul>
<li><strong>Authors: </strong>Almuthanna Alageel, Sergio Maffeis, Imperial College London</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08830">https://arxiv.org/abs/2502.08830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08830">https://arxiv.org/pdf/2502.08830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08830]] Investigation of Advanced Persistent Threats Network-based Tactics, Techniques and Procedures(https://arxiv.org/abs/2502.08830)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, fair</a></li>
<li><strong>Abstract: </strong>The scarcity of data and the high complexity of Advanced Persistent Threats (APTs) attacks have created challenges in comprehending their behavior and hindered the exploration of effective detection techniques. To create an effective APT detection strategy, it is important to examine the Tactics, Techniques, and Procedures (TTPs) that have been reported by the industry. These TTPs can be difficult to classify as either malicious or legitimate. When developing an approach for the next generation of network intrusion detection systems (NIDS), it is necessary to take into account the specific context of the attack explained in this paper. In this study, we select 33 APT campaigns based on the fair distribution over the past 22 years to observe the evolution of APTs over time. We focus on their evasion techniques and how they stay undetected for months or years. We found that APTs cannot continue their operations without C&C servers, which are mostly addressed by Domain Name System (DNS). We identify several TTPs used for DNS, such as Dynamic DNS, typosquatting, and TLD squatting. The next step for APT operators is to start communicating with a victim. We found that the most popular protocol to deploy evasion techniques is using HTTP(S) with 81% of APT campaigns. HTTP(S) can evade firewall filtering and pose as legitimate web-based traffic. DNS protocol is also widely used by 45% of APTs for DNS resolution and tunneling. We identify and analyze the TTPs associated with using HTTP(S) based on real artifacts.</li>
</ul>

<h3>Title: A Reversible Solver for Diffusion SDEs</h3>
<ul>
<li><strong>Authors: </strong>Zander W. Blasingame, Chen Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08834">https://arxiv.org/abs/2502.08834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08834">https://arxiv.org/pdf/2502.08834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08834]] A Reversible Solver for Diffusion SDEs(https://arxiv.org/abs/2502.08834)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have quickly become the state-of-the-art for generation tasks across many different data modalities. An important ability of diffusion models is the ability to encode samples from the data distribution back into the sampling prior distribution. This is useful for performing alterations to real data samples along with guided generation via the continuous adjoint equations. We propose an algebraically reversible solver for diffusion SDEs that can exactly invert real data samples into the prior distribution.</li>
</ul>

<h3>Title: Survey on Single-Image Reflection Removal using Deep Learning Techniques</h3>
<ul>
<li><strong>Authors: </strong>Kangning Yang, Huiming Sun, Jie Cai, Lan Fu, Jiaming Ding, Jinlong Li, Chiu Man Ho, Zibo Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08836">https://arxiv.org/abs/2502.08836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08836">https://arxiv.org/pdf/2502.08836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08836]] Survey on Single-Image Reflection Removal using Deep Learning Techniques(https://arxiv.org/abs/2502.08836)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The phenomenon of reflection is quite common in digital images, posing significant challenges for various applications such as computer vision, photography, and image processing. Traditional methods for reflection removal often struggle to achieve clean results while maintaining high fidelity and robustness, particularly in real-world scenarios. Over the past few decades, numerous deep learning-based approaches for reflection removal have emerged, yielding impressive results. In this survey, we conduct a comprehensive review of the current literature by focusing on key venues such as ICCV, ECCV, CVPR, NeurIPS, etc., as these conferences and journals have been central to advances in the field. Our review follows a structured paper selection process, and we critically assess both single-stage and two-stage deep learning methods for reflection removal. The contribution of this survey is three-fold: first, we provide a comprehensive summary of the most recent work on single-image reflection removal; second, we outline task hypotheses, current deep learning techniques, publicly available datasets, and relevant evaluation metrics; and third, we identify key challenges and opportunities in deep learning-based reflection removal, highlighting the potential of this rapidly evolving research area.</li>
</ul>

<h3>Title: Hierarchical Entropy Disruption for Ransomware Detection: A Computationally-Driven Framework</h3>
<ul>
<li><strong>Authors: </strong>Hayden Srynn, Gilbert Pomeroy, Florence Lytton, Godfrey Ashcombe, Valentine Harcourt, Duncan Pettigrew</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08843">https://arxiv.org/abs/2502.08843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08843">https://arxiv.org/pdf/2502.08843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08843]] Hierarchical Entropy Disruption for Ransomware Detection: A Computationally-Driven Framework(https://arxiv.org/abs/2502.08843)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The rapid evolution of encryption-based threats has rendered conventional detection mechanisms increasingly ineffective against sophisticated attack strategies. Monitoring entropy variations across hierarchical system levels offers an alternative approach to identifying unauthorized data modifications without relying on static signatures. A framework leveraging hierarchical entropy disruption was introduced to analyze deviations in entropy distributions, capturing behavioral anomalies indicative of malicious encryption operations. Evaluating the framework across multiple ransomware variants demonstrated its capability to achieve high detection accuracy while maintaining minimal computational overhead. Entropy distributions across different system directories revealed that encryption activities predominantly targeted user-accessible files, aligning with observed attacker strategies. Detection latency analysis indicated that early-stage identification was feasible, mitigating potential data loss before critical system impact occurred. The framework's ability to operate efficiently in real-time environments was validated through an assessment of resource utilization, confirming a balanced trade-off between detection precision and computational efficiency. Comparative benchmarking against established detection methods highlighted the limitations of conventional approaches in identifying novel ransomware variants, whereas entropy-based anomaly detection provided resilience against obfuscation techniques.</li>
</ul>

<h3>Title: A Systematic Evaluation of Generative Models on Tabular Transportation Data</h3>
<ul>
<li><strong>Authors: </strong>Chengen Wang, Alvaro Cardenas, Gurcan Comert, Murat Kantarcioglu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08856">https://arxiv.org/abs/2502.08856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08856">https://arxiv.org/pdf/2502.08856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08856]] A Systematic Evaluation of Generative Models on Tabular Transportation Data(https://arxiv.org/abs/2502.08856)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, generative</a></li>
<li><strong>Abstract: </strong>The sharing of large-scale transportation data is beneficial for transportation planning and policymaking. However, it also raises significant security and privacy concerns, as the data may include identifiable personal information, such as individuals' home locations. To address these concerns, synthetic data generation based on real transportation data offers a promising solution that allows privacy protection while potentially preserving data utility. Although there are various synthetic data generation techniques, they are often not tailored to the unique characteristics of transportation data, such as the inherent structure of transportation networks formed by all trips in the datasets. In this paper, we use New York City taxi data as a case study to conduct a systematic evaluation of the performance of widely used tabular data generative models. In addition to traditional metrics such as distribution similarity, coverage, and privacy preservation, we propose a novel graph-based metric tailored specifically for transportation data. This metric evaluates the similarity between real and synthetic transportation networks, providing potentially deeper insights into their structural and functional alignment. We also introduced an improved privacy metric to address the limitations of the commonly-used one. Our experimental results reveal that existing tabular data generative models often fail to perform as consistently as claimed in the literature, particularly when applied to transportation data use cases. Furthermore, our novel graph metric reveals a significant gap between synthetic and real data. This work underscores the potential need to develop generative models specifically tailored to take advantage of the unique characteristics of emerging domains, such as transportation.</li>
</ul>

<h3>Title: Siren Song: Manipulating Pose Estimation in XR Headsets Using Acoustic Attacks</h3>
<ul>
<li><strong>Authors: </strong>Zijian Huang, Yicheng Zhang, Sophie Chen, Nael Abu-Ghazaleh, Jiasi Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08865">https://arxiv.org/abs/2502.08865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08865">https://arxiv.org/pdf/2502.08865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08865]] Siren Song: Manipulating Pose Estimation in XR Headsets Using Acoustic Attacks(https://arxiv.org/abs/2502.08865)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Extended Reality (XR) experiences involve interactions between users, the real world, and virtual content. A key step to enable these experiences is the XR headset sensing and estimating the user's pose in order to accurately place and render virtual content in the real world. XR headsets use multiple sensors (e.g., cameras, inertial measurement unit) to perform pose estimation and improve its robustness, but this provides an attack surface for adversaries to interfere with the pose estimation process. In this paper, we create and study the effects of acoustic attacks that create false signals in the inertial measurement unit (IMU) on XR headsets, leading to adverse downstream effects on XR applications. We generate resonant acoustic signals on a HoloLens 2 and measure the resulting perturbations in the IMU readings, and also demonstrate both fine-grained and coarse attacks on the popular ORB-SLAM3 and an open-source XR system (ILLIXR). With the knowledge gleaned from attacking these open-source frameworks, we demonstrate four end-to-end proof-of-concept attacks on a HoloLens 2: manipulating user input, clickjacking, zone invasion, and denial of user interaction. Our experiments show that current commercial XR headsets are susceptible to acoustic attacks, raising concerns for their security.</li>
</ul>

<h3>Title: BrainWavLM: Fine-tuning Speech Representations with Brain Responses to Language</h3>
<ul>
<li><strong>Authors: </strong>Nishitha Vattikonda, Aditya R. Vaidya, Richard J. Antonello, Alexander G. Huth</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08866">https://arxiv.org/abs/2502.08866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08866">https://arxiv.org/pdf/2502.08866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08866]] BrainWavLM: Fine-tuning Speech Representations with Brain Responses to Language(https://arxiv.org/abs/2502.08866)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Speech encoding models use auditory representations to predict how the human brain responds to spoken language stimuli. Most performant encoding models linearly map the hidden states of artificial neural networks to brain data, but this linear restriction may limit their effectiveness. In this work, we use low-rank adaptation (LoRA) to fine-tune a WavLM-based encoding model end-to-end on a brain encoding objective, producing a model we name BrainWavLM. We show that fine-tuning across all of cortex improves average encoding performance with greater stability than without LoRA. This improvement comes at the expense of low-level regions like auditory cortex (AC), but selectively fine-tuning on these areas improves performance in AC, while largely retaining gains made in the rest of cortex. Fine-tuned models generalized across subjects, indicating that they learned robust brain-like representations of the speech stimuli. Finally, by training linear probes, we showed that the brain data strengthened semantic representations in the speech model without any explicit annotations. Our results demonstrate that brain fine-tuning produces best-in-class speech encoding models, and that non-linear methods have the potential to bridge the gap between artificial and biological representations of semantics.</li>
</ul>

<h3>Title: Harnessing Vision Models for Time Series Analysis: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Jingchao Ni, Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Wei Cheng, Dongsheng Luo, Haifeng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08869">https://arxiv.org/abs/2502.08869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08869">https://arxiv.org/pdf/2502.08869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08869]] Harnessing Vision Models for Time Series Analysis: A Survey(https://arxiv.org/abs/2502.08869)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Time series analysis has witnessed the inspiring development from traditional autoregressive models, deep learning models, to recent Transformers and Large Language Models (LLMs). Efforts in leveraging vision models for time series analysis have also been made along the way but are less visible to the community due to the predominant research on sequence modeling in this domain. However, the discrepancy between continuous time series and the discrete token space of LLMs, and the challenges in explicitly modeling the correlations of variates in multivariate time series have shifted some research attentions to the equally successful Large Vision Models (LVMs) and Vision Language Models (VLMs). To fill the blank in the existing literature, this survey discusses the advantages of vision models over LLMs in time series analysis. It provides a comprehensive and in-depth overview of the existing methods, with dual views of detailed taxonomy that answer the key research questions including how to encode time series as images and how to model the imaged time series for various tasks. Additionally, we address the challenges in the pre- and post-processing steps involved in this framework and outline future directions to further advance time series analysis with vision models.</li>
</ul>

<h3>Title: Robust Graph-Based Semi-Supervised Learning via $p$-Conductances</h3>
<ul>
<li><strong>Authors: </strong>Sawyer Jack Robertson, Chester Holtz, Zhengchao Wan, Gal Mishne, Alexander Cloninger</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DM, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08873">https://arxiv.org/abs/2502.08873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08873">https://arxiv.org/pdf/2502.08873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08873]] Robust Graph-Based Semi-Supervised Learning via $p$-Conductances(https://arxiv.org/abs/2502.08873)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the problem of semi-supervised learning on graphs in the regime where data labels are scarce or possibly corrupted. We propose an approach called $p$-conductance learning that generalizes the $p$-Laplace and Poisson learning methods by introducing an objective reminiscent of $p$-Laplacian regularization and an affine relaxation of the label constraints. This leads to a family of probability measure mincut programs that balance sparse edge removal with accurate distribution separation. Our theoretical analysis connects these programs to well-known variational and probabilistic problems on graphs (including randomized cuts, effective resistance, and Wasserstein distance) and provides motivation for robustness when labels are diffused via the heat kernel. Computationally, we develop a semismooth Newton-conjugate gradient algorithm and extend it to incorporate class-size estimates when converting the continuous solutions into label assignments. Empirical results on computer vision and citation datasets demonstrate that our approach achieves state-of-the-art accuracy in low label-rate, corrupted-label, and partial-label regimes.</li>
</ul>

<h3>Title: 2D Integrated Bayesian Tomography of Plasma Electron Density Profile for HL-3 Based on Gaussian Process</h3>
<ul>
<li><strong>Authors: </strong>Cong Wang, Renjie Yang, Dong Li, Zongyu Yang, Zhijun Wang, Yixiong Wei, Jing Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08882">https://arxiv.org/abs/2502.08882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08882">https://arxiv.org/pdf/2502.08882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08882]] 2D Integrated Bayesian Tomography of Plasma Electron Density Profile for HL-3 Based on Gaussian Process(https://arxiv.org/abs/2502.08882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces an integrated Bayesian model that combines line integral measurements and point values using Gaussian Process (GP). The proposed method leverages Gaussian Process Regression (GPR) to incorporate point values into 2D profiles and employs coordinate mapping to integrate magnetic flux information for 2D inversion. The average relative error of the reconstructed profile, using the integrated Bayesian tomography model with normalized magnetic flux, is as low as 3.60*10^(-4). Additionally, sensitivity tests were conducted on the number of grids, the standard deviation of synthetic diagnostic data, and noise levels, laying a solid foundation for the application of the model to experimental data. This work not only achieves accurate 2D inversion using the integrated Bayesian model but also provides a robust framework for decoupling pressure information from equilibrium reconstruction, thus making it possible to optimize equilibrium reconstruction using inversion results.</li>
</ul>

<h3>Title: ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08884">https://arxiv.org/abs/2502.08884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08884">https://arxiv.org/pdf/2502.08884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08884]] ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models(https://arxiv.org/abs/2502.08884)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Procedural representations are desirable, versatile, and popular shape encodings. Authoring them, either manually or using data-driven procedures, remains challenging, as a well-designed procedural representation should be compact, intuitive, and easy to manipulate. A long-standing problem in shape analysis studies how to discover a reusable library of procedural functions, with semantically aligned exposed parameters, that can explain an entire shape family. We present ShapeLib as the first method that leverages the priors of frontier LLMs to design a library of 3D shape abstraction functions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover procedural abstractions that match this design intent by proposing, and then validating, function applications and implementations. The discovered shape functions in the library are not only expressive but also generalize beyond the seed set to a full family of shapes. We train a recognition network that learns to infer shape programs based on our library from different visual modalities (primitives, voxels, point clouds). Our shape functions have parameters that are semantically interpretable and can be modified to produce plausible shape variations. We show that this allows inferred programs to be successfully manipulated by an LLM given a text prompt. We evaluate ShapeLib on different datasets and show clear advantages over existing methods and alternative formulations.</li>
</ul>

<h3>Title: Generative AI for Internet of Things Security: Challenges and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Yan Lin Aung, Ivan Christian, Ye Dong, Xiaodong Ye, Sudipta Chattopadhyay, Jianying Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08886">https://arxiv.org/abs/2502.08886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08886">https://arxiv.org/pdf/2502.08886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08886]] Generative AI for Internet of Things Security: Challenges and Opportunities(https://arxiv.org/abs/2502.08886)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative</a></li>
<li><strong>Abstract: </strong>As Generative AI (GenAI) continues to gain prominence and utility across various sectors, their integration into the realm of Internet of Things (IoT) security evolves rapidly. This work delves into an examination of the state-of-the-art literature and practical applications on how GenAI could improve and be applied in the security landscape of IoT. Our investigation aims to map the current state of GenAI implementation within IoT security, exploring their potential to fortify security measures further. Through the compilation, synthesis, and analysis of the latest advancements in GenAI technologies applied to IoT, this paper not only introduces fresh insights into the field, but also lays the groundwork for future research directions. It explains the prevailing challenges within IoT security, discusses the effectiveness of GenAI in addressing these issues, and identifies significant research gaps through MITRE Mitigations. Accompanied with three case studies, we provide a comprehensive overview of the progress and future prospects of GenAI applications in IoT security. This study serves as a foundational resource to improve IoT security through the innovative application of GenAI, thus contributing to the broader discourse on IoT security and technology integration.</li>
</ul>

<h3>Title: Linear-Time User-Level DP-SCO via Robust Statistics</h3>
<ul>
<li><strong>Authors: </strong>Badih Ghazi, Ravi Kumar, Daogao Liu, Pasin Manurangsi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DS, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08889">https://arxiv.org/abs/2502.08889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08889">https://arxiv.org/pdf/2502.08889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08889]] Linear-Time User-Level DP-SCO via Robust Statistics(https://arxiv.org/abs/2502.08889)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>User-level differentially private stochastic convex optimization (DP-SCO) has garnered significant attention due to the paramount importance of safeguarding user privacy in modern large-scale machine learning applications. Current methods, such as those based on differentially private stochastic gradient descent (DP-SGD), often struggle with high noise accumulation and suboptimal utility due to the need to privatize every intermediate iterate. In this work, we introduce a novel linear-time algorithm that leverages robust statistics, specifically the median and trimmed mean, to overcome these challenges. Our approach uniquely bounds the sensitivity of all intermediate iterates of SGD with gradient estimation based on robust statistics, thereby significantly reducing the gradient estimation noise for privacy purposes and enhancing the privacy-utility trade-off. By sidestepping the repeated privatization required by previous methods, our algorithm not only achieves an improved theoretical privacy-utility trade-off but also maintains computational efficiency. We complement our algorithm with an information-theoretic lower bound, showing that our upper bound is optimal up to logarithmic factors and the dependence on $\epsilon$. This work sets the stage for more robust and efficient privacy-preserving techniques in machine learning, with implications for future research and application in the field.</li>
</ul>

<h3>Title: Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication</h3>
<ul>
<li><strong>Authors: </strong>Weicheng Ma, Hefan Zhang, Ivory Yang, Shiyu Ji, Joice Chen, Farnoosh Hashemi, Shubham Mohole, Ethan Gearey, Michael Macy, Saeed Hassanpour, Soroush Vosoughi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08896">https://arxiv.org/abs/2502.08896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08896">https://arxiv.org/pdf/2502.08896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08896]] Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication(https://arxiv.org/abs/2502.08896)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown proficiency in generating persuasive dialogue, yet concerns about the fluency and sophistication of their outputs persist. This paper presents a multi-LLM communication framework designed to enhance the generation of persuasive data automatically. This framework facilitates the efficient production of high-quality, diverse linguistic content with minimal human oversight. Through extensive evaluations, we demonstrate that the generated data excels in naturalness, linguistic diversity, and the strategic use of persuasion, even in complex scenarios involving social taboos. The framework also proves adept at generalizing across novel contexts. Our results highlight the framework's potential to significantly advance research in both computational and social science domains concerning persuasive communication.</li>
</ul>

<h3>Title: DiffoRA: Enabling Parameter-Efficient LLM Fine-Tuning via Differential Low-Rank Matrix Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Tangyu Jiang, Haodi Wang, Chun Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08905">https://arxiv.org/abs/2502.08905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08905">https://arxiv.org/pdf/2502.08905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08905]] DiffoRA: Enabling Parameter-Efficient LLM Fine-Tuning via Differential Low-Rank Matrix Adaptation(https://arxiv.org/abs/2502.08905)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Parameter-Efficient Fine-Tuning (PEFT) methods have been extensively researched for large language models in the downstream tasks. Among all the existing approaches, the Low-Rank Adaptation (LoRA) has gained popularity for its streamlined design by incorporating low-rank matrices into existing pre-trained models. Though effective, LoRA allocates every module an identical low-rank matrix, which ignores the varying properties and contributions across different components. Moreover, the existing adaptive LoRA solutions rely highly on intuitive importance scoring indicators to adjust the interior rank of the decomposition matrices. In this paper, we propose a new PEFT scheme called DiffoRA, which is theoretically grounded and enables module-wise adoption of LoRA. At the core of our DiffoRA lies a Differential Adaptation Matrix (DAM) to determine which module is the most suitable and essential for fine-tuning. We explain how the designed matrix impacts the convergence rate and generalization capability of a pre-trained model. Furthermore, we construct the DAM via continuous relaxation and discretization with weight-sharing optimizations. We fully implement our DiffoRA and design comprehensive experiments to evaluate its performance. The experimental results demonstrate that our approach achieves the best model accuracy over all the state-of-the-art baselines across various benchmarks.</li>
</ul>

<h3>Title: Towards Automated Fact-Checking of Real-World Claims: Exploring Task Formulation and Assessment with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Premtim Sahitaj, Iffat Maab, Junichi Yamagishi, Jawan Kolanowski, Sebastian Möller, Vera Schmitt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08909">https://arxiv.org/abs/2502.08909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08909">https://arxiv.org/pdf/2502.08909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08909]] Towards Automated Fact-Checking of Real-World Claims: Exploring Task Formulation and Assessment with LLMs(https://arxiv.org/abs/2502.08909)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fact-checking is necessary to address the increasing volume of misinformation. Traditional fact-checking relies on manual analysis to verify claims, but it is slow and resource-intensive. This study establishes baseline comparisons for Automated Fact-Checking (AFC) using Large Language Models (LLMs) across multiple labeling schemes (binary, three-class, five-class) and extends traditional claim verification by incorporating analysis, verdict classification, and explanation in a structured setup to provide comprehensive justifications for real-world claims. We evaluate Llama-3 models of varying sizes (3B, 8B, 70B) on 17,856 claims collected from PolitiFact (2007-2024) using evidence retrieved via restricted web searches. We utilize TIGERScore as a reference-free evaluation metric to score the justifications. Our results show that larger LLMs consistently outperform smaller LLMs in classification accuracy and justification quality without fine-tuning. We find that smaller LLMs in a one-shot scenario provide comparable task performance to fine-tuned Small Language Models (SLMs) with large context sizes, while larger LLMs consistently surpass them. Evidence integration improves performance across all models, with larger LLMs benefiting most. Distinguishing between nuanced labels remains challenging, emphasizing the need for further exploration of labeling schemes and alignment with evidences. Our findings demonstrate the potential of retrieval-augmented AFC with LLMs.</li>
</ul>

<h3>Title: InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU</h3>
<ul>
<li><strong>Authors: </strong>Heejun Lee, Geon Park, Jaduk Suh, Sung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08910">https://arxiv.org/abs/2502.08910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08910">https://arxiv.org/pdf/2502.08910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08910]] InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU(https://arxiv.org/abs/2502.08910)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In modern large language models (LLMs), handling very long context lengths presents significant challenges as it causes slower inference speeds and increased memory costs. Additionally, most existing pre-trained LLMs fail to generalize beyond their original training sequence lengths. To enable efficient and practical long-context utilization, we introduce InfiniteHiP, a novel, and practical LLM inference framework that accelerates processing by dynamically eliminating irrelevant context tokens through a modular hierarchical token pruning algorithm. Our method also allows generalization to longer sequences by selectively applying various RoPE adjustment methods according to the internal attention patterns within LLMs. Furthermore, we offload the key-value cache to host memory during inference, significantly reducing GPU memory pressure. As a result, InfiniteHiP enables the processing of up to 3 million tokens on a single L40s 48GB GPU -- 3x larger -- without any permanent loss of context information. Our framework achieves an 18.95x speedup in attention decoding for a 1 million token context without requiring additional training. We implement our method in the SGLang framework and demonstrate its effectiveness and practicality through extensive evaluations.</li>
</ul>

<h3>Title: Diffusion Models Through a Global Lens: Are They Culturally Inclusive?</h3>
<ul>
<li><strong>Authors: </strong>Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08914">https://arxiv.org/abs/2502.08914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08914">https://arxiv.org/pdf/2502.08914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08914]] Diffusion Models Through a Global Lens: Are They Culturally Inclusive?(https://arxiv.org/abs/2502.08914)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models have recently enabled the creation of visually compelling, detailed images from textual prompts. However, their ability to accurately represent various cultural nuances remains an open question. In our work, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion models whether they can generate culturally specific images spanning ten countries. We show that these models often fail to generate cultural artifacts in architecture, clothing, and food, especially for underrepresented country regions, by conducting a fine-grained analysis of different similarity aspects, revealing significant disparities in cultural relevance, description fidelity, and realism compared to real-world reference images. With the collected human evaluations, we develop a neural-based image-image similarity metric, namely, CultDiff-S, to predict human judgment on real and generated images with cultural artifacts. Our work highlights the need for more inclusive generative AI systems and equitable dataset representation over a wide range of cultures.</li>
</ul>

<h3>Title: PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Ghezloo, Mehmet Saygin Seyfioglu, Rustin Soraki, Wisdom O. Ikezogwo, Beibin Li, Tejoram Vivekanandan, Joann G. Elmore, Ranjay Krishna, Linda Shapiro</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08916">https://arxiv.org/abs/2502.08916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08916">https://arxiv.org/pdf/2502.08916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08916]] PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology(https://arxiv.org/abs/2502.08916)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Diagnosing diseases through histopathology whole slide images (WSIs) is fundamental in modern pathology but is challenged by the gigapixel scale and complexity of WSIs. Trained histopathologists overcome this challenge by navigating the WSI, looking for relevant patches, taking notes, and compiling them to produce a final holistic diagnostic. Traditional AI approaches, such as multiple instance learning and transformer-based models, fail short of such a holistic, iterative, multi-scale diagnostic procedure, limiting their adoption in the real-world. We introduce PathFinder, a multi-modal, multi-agent framework that emulates the decision-making process of expert pathologists. PathFinder integrates four AI agents, the Triage Agent, Navigation Agent, Description Agent, and Diagnosis Agent, that collaboratively navigate WSIs, gather evidence, and provide comprehensive diagnoses with natural language explanations. The Triage Agent classifies the WSI as benign or risky; if risky, the Navigation and Description Agents iteratively focus on significant regions, generating importance maps and descriptive insights of sampled patches. Finally, the Diagnosis Agent synthesizes the findings to determine the patient's diagnostic classification. Our Experiments show that PathFinder outperforms state-of-the-art methods in skin melanoma diagnosis by 8% while offering inherent explainability through natural language descriptions of diagnostically relevant patches. Qualitative analysis by pathologists shows that the Description Agent's outputs are of high quality and comparable to GPT-4o. PathFinder is also the first AI-based system to surpass the average performance of pathologists in this challenging melanoma classification task by 9%, setting a new record for efficient, accurate, and interpretable AI-assisted diagnostics in pathology. Data, code and models available at this https URL</li>
</ul>

<h3>Title: Detecting Malicious Concepts Without Image Generation in AIGC</h3>
<ul>
<li><strong>Authors: </strong>Kun Xu, Yushu Zhang, Shuren Qi, Tao Wang, Wenying Wen, Yuming Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08921">https://arxiv.org/abs/2502.08921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08921">https://arxiv.org/pdf/2502.08921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08921]] Detecting Malicious Concepts Without Image Generation in AIGC(https://arxiv.org/abs/2502.08921)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The task of text-to-image generation has achieved tremendous success in practice, with emerging concept generation models capable of producing highly personalized and customized content. Fervor for concept generation is increasing rapidly among users, and platforms for concept sharing have sprung up. The concept owners may upload malicious concepts and disguise them with non-malicious text descriptions and example images to deceive users into downloading and generating malicious content. The platform needs a quick method to determine whether a concept is malicious to prevent the spread of malicious concepts. However, simply relying on concept image generation to judge whether a concept is malicious requires time and computational resources. Especially, as the number of concepts uploaded and downloaded on the platform continues to increase, this approach becomes impractical and poses a risk of generating malicious content. In this paper, we propose Concept QuickLook, the first systematic work to incorporate malicious concept detection into research, which performs detection based solely on concept files without generating any images. We define malicious concepts and design two work modes for detection: concept matching and fuzzy detection. Extensive experiments demonstrate that the proposed Concept QuickLook can detect malicious concepts and demonstrate practicality in concept sharing platforms. We also design robustness experiments to further validate the effectiveness of the solution. We hope this work can initiate malicious concept detection tasks and provide some inspiration.</li>
</ul>

<h3>Title: Escaping Collapse: The Strength of Weak Data for Large Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Kareem Amin, Sara Babakniya, Alex Bie, Weiwei Kong, Umar Syed, Sergei Vassilvitskii</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08924">https://arxiv.org/abs/2502.08924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08924">https://arxiv.org/pdf/2502.08924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08924]] Escaping Collapse: The Strength of Weak Data for Large Language Model Training(https://arxiv.org/abs/2502.08924)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Synthetically-generated data plays an increasingly larger role in training large language models. However, while synthetic data has been found to be useful, studies have also shown that without proper curation it can cause LLM performance to plateau, or even "collapse", after many training iterations. In this paper, we formalize this question and develop a theoretical framework to investigate how much curation is needed in order to ensure that LLM performance continually improves. We find that the requirements are nearly minimal. We describe a training procedure that converges to an optimal LLM even if almost all of the non-synthetic training data is of poor quality. Our analysis is inspired by boosting, a classic machine learning technique that leverages a very weak learning algorithm to produce an arbitrarily good classifier. Our training procedure subsumes many recently proposed methods for training LLMs on synthetic data, and thus our analysis sheds light on why they are successful, and also suggests opportunities for future improvement. We present experiments that validate our theory, and show that dynamically focusing labeling resources on the most challenging examples -- in much the same way that boosting focuses the efforts of the weak learner -- leads to improved performance.</li>
</ul>

<h3>Title: Dynamic watermarks in images generated by diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08927">https://arxiv.org/abs/2502.08927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08927">https://arxiv.org/pdf/2502.08927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08927]] Dynamic watermarks in images generated by diffusion models(https://arxiv.org/abs/2502.08927)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, robust, watermark, diffusion</a></li>
<li><strong>Abstract: </strong>High-fidelity text-to-image diffusion models have revolutionized visual content generation, but their widespread use raises significant ethical concerns, including intellectual property protection and the misuse of synthetic media. To address these challenges, we propose a novel multi-stage watermarking framework for diffusion models, designed to establish copyright and trace generated images back to their source. Our multi-stage watermarking technique involves embedding: (i) a fixed watermark that is localized in the diffusion model's learned noise distribution and, (ii) a human-imperceptible, dynamic watermark in generates images, leveraging a fine-tuned decoder. By leveraging the Structural Similarity Index Measure (SSIM) and cosine similarity, we adapt the watermark's shape and color to the generated content while maintaining robustness. We demonstrate that our method enables reliable source verification through watermark classification, even when the dynamic watermark is adjusted for content-specific variations. Source model verification is enabled through watermark classification. o support further research, we generate a dataset of watermarked images and introduce a methodology to evaluate the statistical impact of watermarking on generated this http URL, we rigorously test our framework against various attack scenarios, demonstrating its robustness and minimal impact on image quality. Our work advances the field of AI-generated content security by providing a scalable solution for model ownership verification and misuse prevention.</li>
</ul>

<h3>Title: Towards Understanding Why Data Augmentation Improves Generalization</h3>
<ul>
<li><strong>Authors: </strong>Jingyang Li, Jiachun Pan, Kim-Chuan Toh, Pan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08940">https://arxiv.org/abs/2502.08940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08940">https://arxiv.org/pdf/2502.08940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08940]] Towards Understanding Why Data Augmentation Improves Generalization(https://arxiv.org/abs/2502.08940)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data augmentation is a cornerstone technique in deep learning, widely used to improve model generalization. Traditional methods like random cropping and color jittering, as well as advanced techniques such as CutOut, Mixup, and CutMix, have achieved notable success across various domains. However, the mechanisms by which data augmentation improves generalization remain poorly understood, and existing theoretical analyses typically focus on individual techniques without a unified explanation. In this work, we present a unified theoretical framework that elucidates how data augmentation enhances generalization through two key effects: partial semantic feature removal and feature mixing. Partial semantic feature removal reduces the model's reliance on individual feature, promoting diverse feature learning and better generalization. Feature mixing, by scaling down original semantic features and introducing noise, increases training complexity, driving the model to develop more robust features. Advanced methods like CutMix integrate both effects, achieving complementary benefits. Our theoretical insights are further supported by experimental results, validating the effectiveness of this unified perspective.</li>
</ul>

<h3>Title: Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Zhang, Hengrui Cai, Wenyu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08943">https://arxiv.org/abs/2502.08943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08943">https://arxiv.org/pdf/2502.08943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08943]] Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis(https://arxiv.org/abs/2502.08943)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated significant utilities in real-world applications, exhibiting impressive capabilities in natural language processing and understanding. Benchmark evaluations are crucial for assessing the capabilities of LLMs as they can provide a comprehensive assessment of their strengths and weaknesses. However, current evaluation methods often overlook the inherent randomness of LLMs by employing deterministic generation strategies or relying on a single random sample, resulting in unaccounted sampling variance and unreliable benchmark score estimates. In this paper, we propose a hierarchical statistical model that provides a more comprehensive representation of the benchmarking process by incorporating both benchmark characteristics and LLM randomness. We show that leveraging multiple generations improves the accuracy of estimating the benchmark score and reduces variance. We also introduce $\mathbb P\left(\text{correct}\right)$, a prompt-level difficulty score based on correct ratios, providing fine-grained insights into individual prompts. Additionally, we create a data map that visualizes difficulty and semantic prompts, enabling error detection and quality control in benchmark construction.</li>
</ul>

<h3>Title: Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding</h3>
<ul>
<li><strong>Authors: </strong>Fenella Harcourt, Naderdel Piero, Gilbert Sutherland, Daphne Holloway, Harriet Bracknell, Julian Ormsby</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08947">https://arxiv.org/abs/2502.08947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08947">https://arxiv.org/pdf/2502.08947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08947]] Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding(https://arxiv.org/abs/2502.08947)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Token representations in high-dimensional latent spaces often exhibit redundancy, limiting computational efficiency and reducing structural coherence across model layers. Hierarchical latent space folding introduces a structured transformation mechanism that enforces a multi-scale organization within learned embeddings, refining representational compactness while preserving essential contextual distinctions. The proposed approach incorporates dynamic folding operations that iteratively adjust token embeddings through structured transformations, influencing both short-range and long-range dependencies in sequential processing tasks. Empirical evaluation demonstrates a reduction in representational variance across layers, contributing to more stable perplexity distributions and enhancing predictive confidence in text generation. The structured redistribution of attention head utilization leads to more efficient allocation of computational resources, particularly in deeper layers, where hierarchical refinements improve contextual abstraction. Comparative analysis of activation sparsity patterns suggests that hierarchical adjustments selectively reinforce critical pathways while reducing computational overhead in non-essential regions of the model. Statistical assessments of token reordering frequencies reveal that hierarchical modifications introduce subtle shifts in sequential dependencies, improving contextual alignment while maintaining syntactic correctness. Computational trade-offs associated with hierarchical folding introduce marginal increases in training time per epoch, yet empirical findings indicate that inference efficiency benefits from the structured representation adjustments. The results highlight the impact of hierarchical latent space folding on optimizing model performance through improved representation structuring and computational efficiency.</li>
</ul>

<h3>Title: Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs for Clinical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Leon Nissen, Philipp Zagar, Vishnu Ravi, Aydin Zahedivash, Lara Marie Reimer, Stephan Jonas, Oliver Aalami, Paul Schmiedmayer</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08954">https://arxiv.org/abs/2502.08954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08954">https://arxiv.org/pdf/2502.08954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08954]] Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs for Clinical Reasoning(https://arxiv.org/abs/2502.08954)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>The deployment of Large Language Models (LLM) on mobile devices offers significant potential for medical applications, enhancing privacy, security, and cost-efficiency by eliminating reliance on cloud-based services and keeping sensitive health data local. However, the performance and accuracy of on-device LLMs in real-world medical contexts remain underexplored. In this study, we benchmark publicly available on-device LLMs using the AMEGA dataset, evaluating accuracy, computational efficiency, and thermal limitation across various mobile devices. Our results indicate that compact general-purpose models like Phi-3 Mini achieve a strong balance between speed and accuracy, while medically fine-tuned models such as Med42 and Aloe attain the highest accuracy. Notably, deploying LLMs on older devices remains feasible, with memory constraints posing a greater challenge than raw processing power. Our study underscores the potential of on-device LLMs for healthcare while emphasizing the need for more efficient inference and models tailored to real-world clinical reasoning.</li>
</ul>

<h3>Title: Biologically Plausible Brain Graph Transformer</h3>
<ul>
<li><strong>Authors: </strong>Ciyuan Peng, Yuelong Huang, Qichao Dong, Shuo Yu, Feng Xia, Chengqi Zhang, Yaochu Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08958">https://arxiv.org/abs/2502.08958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08958">https://arxiv.org/pdf/2502.08958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08958]] Biologically Plausible Brain Graph Transformer(https://arxiv.org/abs/2502.08958)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>State-of-the-art brain graph analysis methods fail to fully encode the small-world architecture of brain graphs (accompanied by the presence of hubs and functional modules), and therefore lack biological plausibility to some extent. This limitation hinders their ability to accurately represent the brain's structural and functional properties, thereby restricting the effectiveness of machine learning models in tasks such as brain disorder detection. In this work, we propose a novel Biologically Plausible Brain Graph Transformer (BioBGT) that encodes the small-world architecture inherent in brain graphs. Specifically, we present a network entanglement-based node importance encoding technique that captures the structural importance of nodes in global information propagation during brain graph communication, highlighting the biological properties of the brain structure. Furthermore, we introduce a functional module-aware self-attention to preserve the functional segregation and integration characteristics of brain graphs in the learned representations. Experimental results on three benchmark datasets demonstrate that BioBGT outperforms state-of-the-art models, enhancing biologically plausible brain graph representations for various brain graph analytical tasks</li>
</ul>

<h3>Title: RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage</h3>
<ul>
<li><strong>Authors: </strong>Peter Yong Zhong, Siyuan Chen, Ruiqi Wang, McKenna McCall, Ben L. Titzer, Heather Miller</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08966">https://arxiv.org/abs/2502.08966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08966">https://arxiv.org/pdf/2502.08966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08966]] RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage(https://arxiv.org/abs/2502.08966)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external tools for tasks beyond their standalone capabilities, such as searching websites, booking flights, or making financial transactions. However, these tools greatly increase the risks of prompt injection attacks, where malicious content hijacks the LM agent to leak confidential data or trigger harmful actions. Existing defenses (OpenAI GPTs) require user confirmation before every tool call, placing onerous burdens on users. We introduce Robust TBAS (RTBAS), which automatically detects and executes tool calls that preserve integrity and confidentiality, requiring user confirmation only when these safeguards cannot be ensured. RTBAS adapts Information Flow Control to the unique challenges presented by TBAS. We present two novel dependency screeners, using LM-as-a-judge and attention-based saliency, to overcome these challenges. Experimental results on the AgentDojo Prompt Injection benchmark show RTBAS prevents all targeted attacks with only a 2% loss of task utility when under attack, and further tests confirm its ability to obtain near-oracle performance on detecting both subtle and direct privacy leaks.</li>
</ul>

<h3>Title: A Decade of Metric Differential Privacy: Advancements and Applications</h3>
<ul>
<li><strong>Authors: </strong>Xinpeng Xie, Chenyang Yu, Yan Huang, Yang Cao, Chenxi Qiu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08970">https://arxiv.org/abs/2502.08970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08970">https://arxiv.org/pdf/2502.08970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08970]] A Decade of Metric Differential Privacy: Advancements and Applications(https://arxiv.org/abs/2502.08970)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Metric Differential Privacy (mDP) builds upon the core principles of Differential Privacy (DP) by incorporating various distance metrics, which offer adaptable and context-sensitive privacy guarantees for a wide range of applications, such as location-based services, text analysis, and image processing. Since its inception in 2013, mDP has garnered substantial research attention, advancing theoretical foundations, algorithm design, and practical implementations. Despite this progress, existing surveys mainly focus on traditional DP and local DP, and they provide limited coverage of mDP. This paper provides a comprehensive survey of mDP research from 2013 to 2024, tracing its development from the foundations of DP. We categorize essential mechanisms, including Laplace, Exponential, and optimization-based approaches, and assess their strengths, limitations, and application domains. Additionally, we highlight key challenges and outline future research directions to encourage innovation and real-world adoption of mDP. This survey is designed to be a valuable resource for researchers and practitioners aiming to deepen their understanding and drive progress in mDP within the broader privacy ecosystem.</li>
</ul>

<h3>Title: Small Molecule Drug Discovery Through Deep Learning:Progress, Challenges, and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Kun Li, Yida Xiong, Hongzhi Zhang, Xiantao Cai, Bo Du, Wenbin Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08975">https://arxiv.org/abs/2502.08975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08975">https://arxiv.org/pdf/2502.08975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08975]] Small Molecule Drug Discovery Through Deep Learning:Progress, Challenges, and Opportunities(https://arxiv.org/abs/2502.08975)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Due to their excellent drug-like and pharmacokinetic properties, small molecule drugs are widely used to treat various diseases, making them a critical component of drug discovery. In recent years, with the rapid development of deep learning (DL) techniques, DL-based small molecule drug discovery methods have achieved excellent performance in prediction accuracy, speed, and complex molecular relationship modeling compared to traditional machine learning approaches. These advancements enhance drug screening efficiency and optimization, and they provide more precise and effective solutions for various drug discovery tasks. Contributing to this field's development, this paper aims to systematically summarize and generalize the recent key tasks and representative techniques in DL-based small molecule drug discovery in recent years. Specifically, we provide an overview of the major tasks in small molecule drug discovery and their interrelationships. Next, we analyze the six core tasks, summarizing the related methods, commonly used datasets, and technological development trends. Finally, we discuss key challenges, such as interpretability and out-of-distribution generalization, and offer our insights into future research directions for DL-assisted small molecule drug discovery.</li>
</ul>

<h3>Title: What exactly has TabPFN learned to do?</h3>
<ul>
<li><strong>Authors: </strong>Calvin McCarter</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08978">https://arxiv.org/abs/2502.08978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08978">https://arxiv.org/pdf/2502.08978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08978]] What exactly has TabPFN learned to do?(https://arxiv.org/abs/2502.08978)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>TabPFN [Hollmann et al., 2023], a Transformer model pretrained to perform in-context learning on fresh tabular classification problems, was presented at the last ICLR conference. To better understand its behavior, we treat it as a black-box function approximator generator and observe its generated function approximations on a varied selection of training datasets. Exploring its learned inductive biases in this manner, we observe behavior that is at turns either brilliant or baffling. We conclude this post with thoughts on how these results might inform the development, evaluation, and application of prior-data fitted networks (PFNs) in the future.</li>
</ul>

<h3>Title: Latents of latents to delineate pixels: hybrid Matryoshka autoencoder-to-U-Net pairing for segmenting large medical images in GPU-poor and low-data regimes</h3>
<ul>
<li><strong>Authors: </strong>Tahir Syed, Ariba Khan, Sawera Hanif</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08988">https://arxiv.org/abs/2502.08988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08988">https://arxiv.org/pdf/2502.08988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08988]] Latents of latents to delineate pixels: hybrid Matryoshka autoencoder-to-U-Net pairing for segmenting large medical images in GPU-poor and low-data regimes(https://arxiv.org/abs/2502.08988)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Medical images are often high-resolution and lose important detail if downsampled, making pixel-level methods such as semantic segmentation much less efficient if performed on a low-dimensional image. We propose a low-rank Matryoshka projection and a hybrid segmenting architecture that preserves important information while retaining sufficient pixel geometry for pixel-level tasks. We design the Matryoshka Autoencoder (MatAE-U-Net) which combines the hierarchical encoding of the Matryoshka Autoencoder with the spatial reconstruction capabilities of a U-Net decoder, leveraging multi-scale feature extraction and skip connections to enhance accuracy and generalisation. We apply it to the problem of segmenting the left ventricle (LV) in echocardiographic images using the Stanford EchoNet-D dataset, including 1,000 standardised video-mask pairs of cardiac ultrasound videos resized to 112x112 pixels. The MatAE-UNet model achieves a Mean IoU of 77.68\%, Mean Pixel Accuracy of 97.46\%, and Dice Coefficient of 86.91\%, outperforming the baseline U-Net, which attains a Mean IoU of 74.70\%, Mean Pixel Accuracy of 97.31\%, and Dice Coefficient of 85.20\%. The results highlight the potential of using the U-Net in the recursive Matroshka latent space for imaging problems with low-contrast such as echocardiographic analysis.</li>
</ul>

<h3>Title: RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Nazatul H. Sultan, Yan Bo, Yansong Gao, Seyit Camtepe, Arash Mahboubi, Hang Thanh Bui, Aufeef Chauhan, Hamed Aboutorab, Michael Bewong, Praveen Gauravaram, Rafiqul Islam, Sharif Abuadbba</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08989">https://arxiv.org/abs/2502.08989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08989">https://arxiv.org/pdf/2502.08989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08989]] RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning(https://arxiv.org/abs/2502.08989)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) allows users to collaboratively train a global machine learning model by sharing local model only, without exposing their private data to a central server. This distributed learning is particularly appealing in scenarios where data privacy is crucial, and it has garnered substantial attention from both industry and academia. However, studies have revealed privacy vulnerabilities in FL, where adversaries can potentially infer sensitive information from the shared model parameters. In this paper, we present an efficient masking-based secure aggregation scheme utilizing lightweight cryptographic primitives to mitigate privacy risks. Our scheme offers several advantages over existing methods. First, it requires only a single setup phase for the entire FL training session, significantly reducing communication overhead. Second, it minimizes user-side overhead by eliminating the need for user-to-user interactions, utilizing an intermediate server layer and a lightweight key negotiation method. Third, the scheme is highly resilient to user dropouts, and the users can join at any FL round. Fourth, it can detect and defend against malicious server activities, including recently discovered model inconsistency attacks. Finally, our scheme ensures security in both semi-honest and malicious settings. We provide security analysis to formally prove the robustness of our approach. Furthermore, we implemented an end-to-end prototype of our scheme. We conducted comprehensive experiments and comparisons, which show that it outperforms existing solutions in terms of communication and computation overhead, functionality, and security.</li>
</ul>

<h3>Title: Task Generalization With AutoRegressive Compositional Structure: Can Learning From $\d$ Tasks Generalize to $\d^{T}$ Tasks?</h3>
<ul>
<li><strong>Authors: </strong>Amirhesam Abedsoltan, Huaqing Zhang, Kaiyue Wen, Hongzhou Lin, Jingzhao Zhang, Mikhail Belkin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08991">https://arxiv.org/abs/2502.08991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08991">https://arxiv.org/pdf/2502.08991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08991]] Task Generalization With AutoRegressive Compositional Structure: Can Learning From $\d$ Tasks Generalize to $\d^{T}$ Tasks?(https://arxiv.org/abs/2502.08991)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit remarkable task generalization, solving tasks they were never explicitly trained on with only a few demonstrations. This raises a fundamental question: When can learning from a small set of tasks generalize to a large task family? In this paper, we investigate task generalization through the lens of AutoRegressive Compositional (ARC) structure, where each task is a composition of $T$ operations, and each operation is among a finite family of $\d$ subtasks. This yields a total class of size~\( \d^\TT \). We first show that generalization to all \( \d^\TT \) tasks is theoretically achievable by training on only \( \tilde{O}(\d) \) tasks. Empirically, we demonstrate that Transformers achieve such exponential task generalization on sparse parity functions via in-context learning (ICL) and Chain-of-Thought (CoT) reasoning. We further demonstrate this generalization in arithmetic and language translation, extending beyond parity functions.</li>
</ul>

<h3>Title: Hierarchical Vision Transformer with Prototypes for Interpretable Medical Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Luisa Gallée, Catharina Silvia Lisson, Meinrad Beer, Michael Götz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.08997">https://arxiv.org/abs/2502.08997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.08997">https://arxiv.org/pdf/2502.08997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.08997]] Hierarchical Vision Transformer with Prototypes for Interpretable Medical Image Classification(https://arxiv.org/abs/2502.08997)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Explainability is a highly demanded requirement for applications in high-risk areas such as medicine. Vision Transformers have mainly been limited to attention extraction to provide insight into the model's reasoning. Our approach combines the high performance of Vision Transformers with the introduction of new explainability capabilities. We present HierViT, a Vision Transformer that is inherently interpretable and adapts its reasoning to that of humans. A hierarchical structure is used to process domain-specific features for prediction. It is interpretable by design, as it derives the target output with human-defined features that are visualized by exemplary images (prototypes). By incorporating domain knowledge about these decisive features, the reasoning is semantically similar to human reasoning and therefore intuitive. Moreover, attention heatmaps visualize the crucial regions for identifying each feature, thereby providing HierViT with a versatile tool for validating predictions. Evaluated on two medical benchmark datasets, LIDC-IDRI for lung nodule assessment and derm7pt for skin lesion classification, HierViT achieves superior and comparable prediction accuracy, respectively, while offering explanations that align with human reasoning.</li>
</ul>

<h3>Title: Residual Transformer Fusion Network for Salt and Pepper Image Denoising</h3>
<ul>
<li><strong>Authors: </strong>Bintang Pradana Erlangga Putra, Heri Prasetyo, Esti Suryani</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09000">https://arxiv.org/abs/2502.09000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09000">https://arxiv.org/pdf/2502.09000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09000]] Residual Transformer Fusion Network for Salt and Pepper Image Denoising(https://arxiv.org/abs/2502.09000)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Convolutional Neural Network (CNN) has been widely used in unstructured datasets, one of which is image denoising. Image denoising is a noisy image reconstruction process that aims to reduce additional noise that occurs from the noisy image with various strategies. Image denoising has a problem, namely that some image denoising methods require some prior knowledge of information about noise. To overcome this problem, a combined architecture of Convolutional Vision Transformer (CvT) and Residual Networks (ResNet) is used which is called the Residual Transformer Fusion Network (RTF-Net). In general, the process in this architecture can be divided into two parts, Noise Suppression Network (NSN) and Structure Enhancement Network (SEN). Residual Block is used in the Noise Suppression Network and is used to learn the noise map in the image, while the CvT is used in the Structure Enhancement Network and is used to learn the details that need to be added to the image processed by the Noise Suppression Network. The model was trained using the DIV2K Training Set dataset, and validation using the DIV2K Validation Set. After doing the training, the model was tested using Lena, Bridge, Pepper, and BSD300 images with noise levels ranging from 30%, 50%, and 70% and the PSNR results were compared with the DBA, NASNLM, PARIGI, NLSF, NLSF-MLP and NLSF-CNN methods. The test results show that the proposed method is superior in all cases except for Pepper's image with a noise level of 30%, where NLSF-CNN is superior with a PSNR value of 32.99 dB, while the proposed method gets a PSNR value of 31.70 dB.</li>
</ul>

<h3>Title: Privacy-Preserving Hybrid Ensemble Model for Network Anomaly Detection: Balancing Security and Data Protection</h3>
<ul>
<li><strong>Authors: </strong>Shaobo Liu, Zihao Zhao, Weijie He, Jiren Wang, Jing Peng, Haoyuan Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09001">https://arxiv.org/abs/2502.09001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09001">https://arxiv.org/pdf/2502.09001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09001]] Privacy-Preserving Hybrid Ensemble Model for Network Anomaly Detection: Balancing Security and Data Protection(https://arxiv.org/abs/2502.09001)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Privacy-preserving network anomaly detection has become an essential area of research due to growing concerns over the protection of sensitive data. Traditional anomaly de- tection models often prioritize accuracy while neglecting the critical aspect of privacy. In this work, we propose a hybrid ensemble model that incorporates privacy-preserving techniques to address both detection accuracy and data protection. Our model combines the strengths of several machine learning algo- rithms, including K-Nearest Neighbors (KNN), Support Vector Machines (SVM), XGBoost, and Artificial Neural Networks (ANN), to create a robust system capable of identifying network anomalies while ensuring privacy. The proposed approach in- tegrates advanced preprocessing techniques that enhance data quality and address the challenges of small sample sizes and imbalanced datasets. By embedding privacy measures into the model design, our solution offers a significant advancement over existing methods, ensuring both enhanced detection performance and strong privacy safeguards.</li>
</ul>

<h3>Title: End-to-End triplet loss based fine-tuning for network embedding in effective PII detection</h3>
<ul>
<li><strong>Authors: </strong>Rishika Kohli, Shaifu Gupta, Manoj Singh Gaur</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09002">https://arxiv.org/abs/2502.09002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09002">https://arxiv.org/pdf/2502.09002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09002]] End-to-End triplet loss based fine-tuning for network embedding in effective PII detection(https://arxiv.org/abs/2502.09002)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>There are many approaches in mobile data ecosystem that inspect network traffic generated by applications running on user's device to detect personal data exfiltration from the user's device. State-of-the-art methods rely on features extracted from HTTP requests and in this context, machine learning involves training classifiers on these features and making predictions using labelled packet traces. However, most of these methods include external feature selection before model training. Deep learning, on the other hand, typically does not require such techniques, as it can autonomously learn and identify patterns in the data without external feature extraction or selection algorithms. In this article, we propose a novel deep learning based end-to-end learning framework for prediction of exposure of personally identifiable information (PII) in mobile packets. The framework employs a pre-trained large language model (LLM) and an autoencoder to generate embedding of network packets and then uses a triplet-loss based fine-tuning method to train the model, increasing detection effectiveness using two real-world datasets. We compare our proposed detection framework with other state-of-the-art works in detecting PII leaks from user's device.</li>
</ul>

<h3>Title: RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Quan Wei, Chung-Yiu Yau, Hoi-To Wai, Yang (Katie)Zhao, Dongyeop Kang, Youngsuk Park, Mingyi Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09003">https://arxiv.org/abs/2502.09003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09003">https://arxiv.org/pdf/2502.09003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09003]] RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models(https://arxiv.org/abs/2502.09003)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised fine-tuning is a standard method for adapting pre-trained large language models (LLMs) to downstream tasks. Quantization has been recently studied as a post-training technique for efficient LLM deployment. To obtain quantized fine-tuned LLMs, conventional pipelines would first fine-tune the pre-trained models, followed by post-training quantization. This often yields suboptimal performance as it fails to leverage the synergy between fine-tuning and quantization. To effectively realize low-bit quantization of weights, activations, and KV caches in LLMs, we propose an algorithm named Rotated Straight-Through-Estimator (RoSTE), which combines quantization-aware supervised fine-tuning (QA-SFT) with an adaptive rotation strategy that identifies an effective rotation configuration to reduce activation outliers. We provide theoretical insights on RoSTE by analyzing its prediction error when applied to an overparameterized least square quantized training problem. Our findings reveal that the prediction error is directly proportional to the quantization error of the converged weights, which can be effectively managed through an optimized rotation configuration. Experiments on Pythia and Llama models of different sizes demonstrate the effectiveness of RoSTE. Compared to existing post-SFT quantization baselines, our method consistently achieves superior performances across various tasks and different LLM architectures.</li>
</ul>

<h3>Title: Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Pofcher, Christopher M. Homan, Randall Sell, Ashiqur R. KhudaBukhsh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09004">https://arxiv.org/abs/2502.09004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09004">https://arxiv.org/pdf/2502.09004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09004]] Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech(https://arxiv.org/abs/2502.09004)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper makes three contributions. First, via a substantial corpus of 1,419,047 comments posted on 3,161 YouTube news videos of major US cable news outlets, we analyze how users engage with LGBTQ+ news content. Our analyses focus both on positive and negative content. In particular, we construct a fine-grained hope speech classifier that detects positive (hope speech), negative, neutral, and irrelevant content. Second, in consultation with a public health expert specializing on LGBTQ+ health, we conduct an annotation study with a balanced and diverse political representation and release a dataset of 3,750 instances with fine-grained labels and detailed annotator demographic information. Finally, beyond providing a vital resource for the LGBTQ+ community, our annotation study and subsequent in-the-wild assessments reveal (1) strong association between rater political beliefs and how they rate content relevant to a marginalized community; (2) models trained on individual political beliefs exhibit considerable in-the-wild disagreement; and (3) zero-shot large language models (LLMs) align more with liberal raters.</li>
</ul>

<h3>Title: Diversity Enhances an LLM's Performance in RAG and Long-context Task</h3>
<ul>
<li><strong>Authors: </strong>Zhchao Wang, Bin Bi, Yanqi Luo, Sitaram Asur, Claire Na Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09017">https://arxiv.org/abs/2502.09017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09017">https://arxiv.org/pdf/2502.09017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09017]] Diversity Enhances an LLM's Performance in RAG and Long-context Task(https://arxiv.org/abs/2502.09017)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancements in large language models (LLMs) have highlighted the challenge of context window limitations, primarily due to the quadratic time complexity of the self-attention mechanism (\(O(N^2)\), where \(N\) denotes the context window length). This constraint impacts tasks such as retrieval-augmented generation (RAG) in question answering (Q\&A) and long context summarization. A common approach involves selecting content with the highest similarity to the query; however, this often leads to redundancy and the exclusion of diverse yet relevant information. Building on principles from Maximal Marginal Relevance (MMR) and Farthest Point Sampling (FPS), we integrate diversity into the content selection process. Our findings reveal that incorporating diversity substantially increases the recall of selecting relevant sentences or chunks before LLM-based Q\&A and summarization. These results highlight the importance of maintaining diversity in future LLM applications to further improve summarization and Q\&A outcomes.</li>
</ul>

<h3>Title: EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09020">https://arxiv.org/abs/2502.09020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09020">https://arxiv.org/pdf/2502.09020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09020]] EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition(https://arxiv.org/abs/2502.09020)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mainstream Scene Text Recognition (STR) algorithms are developed based on RGB cameras which are sensitive to challenging factors such as low illumination, motion blur, and cluttered backgrounds. In this paper, we propose to recognize the scene text using bio-inspired event cameras by collecting and annotating a large-scale benchmark dataset, termed EventSTR. It contains 9,928 high-definition (1280 * 720) event samples and involves both Chinese and English characters. We also benchmark multiple STR algorithms as the baselines for future works to compare. In addition, we propose a new event-based scene text recognition framework, termed SimC-ESTR. It first extracts the event features using a visual encoder and projects them into tokens using a Q-former module. More importantly, we propose to augment the vision tokens based on a memory mechanism before feeding into the large language models. A similarity-based error correction mechanism is embedded within the large language model to correct potential minor errors fundamentally based on contextual information. Extensive experiments on the newly proposed EventSTR dataset and two simulation STR datasets fully demonstrate the effectiveness of our proposed model. We believe that the dataset and algorithmic model can innovatively propose an event-based STR task and are expected to accelerate the application of event cameras in various industries. The source code and pre-trained models will be released on this https URL</li>
</ul>

<h3>Title: Typhoon T1: An Open Thai Reasoning Model</h3>
<ul>
<li><strong>Authors: </strong>Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai, Kunat Pipatanakul</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09042">https://arxiv.org/abs/2502.09042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09042">https://arxiv.org/pdf/2502.09042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09042]] Typhoon T1: An Open Thai Reasoning Model(https://arxiv.org/abs/2502.09042)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces Typhoon T1, an open effort to develop an open Thai reasoning model. A reasoning model is a relatively new type of generative model built on top of large language models (LLMs). A reasoning model generates a long chain of thought before arriving at a final answer, an approach found to improve performance on complex tasks. However, details on developing such a model are limited, especially for reasoning models that can generate traces in a low-resource language. Typhoon T1 presents an open effort that dives into the details of developing a reasoning model in a more cost-effective way by leveraging supervised fine-tuning using open datasets, instead of reinforcement learning. This paper shares the details about synthetic data generation and training, as well as our dataset and model weights. Additionally, we provide insights gained from developing a reasoning model that generalizes across domains and is capable of generating reasoning traces in a low-resource language, using Thai as an example. We hope this open effort provides a foundation for further research in this field.</li>
</ul>

<h3>Title: An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging</h3>
<ul>
<li><strong>Authors: </strong>Kunat Pipatanakul, Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09056">https://arxiv.org/abs/2502.09056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09056">https://arxiv.org/pdf/2502.09056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09056]] An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging(https://arxiv.org/abs/2502.09056)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates data selection and model merging methodologies aimed at incorporating advanced reasoning capabilities such as those of DeepSeek R1 into language-specific large language models (LLMs), with a particular focus on the Thai LLM. Our goal is to enhance the reasoning capabilities of language-specific LLMs while maintaining their target language abilities. DeepSeek R1 excels in reasoning but primarily benefits high-resource languages such as English and Chinese. However, low-resource languages remain underserved due to the dominance of English-centric training data and model optimizations, which limit performance in these languages. This limitation results in unreliable code-switching and diminished effectiveness on tasks in low-resource languages. Meanwhile, local and regional LLM initiatives have attempted to bridge this gap by developing language-specific LLMs that focus on improving local linguistic fidelity. We demonstrate that, with only publicly available datasets and a computational budget of $120, it is possible to enhance the reasoning capabilities of language-specific LLMs to match the level of DeepSeek R1, without compromising their performance on target language tasks.</li>
</ul>

<h3>Title: StyleBlend: Enhancing Style-Specific Content Creation in Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zichong Chen, Shijin Wang, Yang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09064">https://arxiv.org/abs/2502.09064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09064">https://arxiv.org/pdf/2502.09064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09064]] StyleBlend: Enhancing Style-Specific Content Creation in Text-to-Image Diffusion Models(https://arxiv.org/abs/2502.09064)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Synthesizing visually impressive images that seamlessly align both text prompts and specific artistic styles remains a significant challenge in Text-to-Image (T2I) diffusion models. This paper introduces StyleBlend, a method designed to learn and apply style representations from a limited set of reference images, enabling content synthesis of both text-aligned and stylistically coherent. Our approach uniquely decomposes style into two components, composition and texture, each learned through different strategies. We then leverage two synthesis branches, each focusing on a corresponding style component, to facilitate effective style blending through shared features without affecting content generation. StyleBlend addresses the common issues of text misalignment and weak style representation that previous methods have struggled with. Extensive qualitative and quantitative comparisons demonstrate the superiority of our approach.</li>
</ul>

<h3>Title: FlowAR: une plateforme uniformisée pour la reconnaissance des activités humaines à partir de capteurs binaires</h3>
<ul>
<li><strong>Authors: </strong>Ali Ncibi, Luc Bouganim, Philippe Pucheral</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09067">https://arxiv.org/abs/2502.09067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09067">https://arxiv.org/pdf/2502.09067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09067]] FlowAR: une plateforme uniformisée pour la reconnaissance des activités humaines à partir de capteurs binaires(https://arxiv.org/abs/2502.09067)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This demo showcases a platform for developing human activity recognition (AR) systems, focusing on daily activities using sensor data, like binary sensors. With a data-driven approach, this platform, named FlowAR, features a three-step pipeline (flow): data cleaning, segmentation, and personalized classification. Its modularity allows flexibility to test methods, datasets, and ensure rigorous evaluations. A concrete use case demonstrates its effectiveness.</li>
</ul>

<h3>Title: Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables</h3>
<ul>
<li><strong>Authors: </strong>Xuzhao Geng, Haozhao Wang, Jun Wang, Wei Liu, Ruixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09073">https://arxiv.org/abs/2502.09073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09073">https://arxiv.org/pdf/2502.09073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09073]] Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables(https://arxiv.org/abs/2502.09073)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) is a key technique for leveraging external knowledge and reducing hallucinations in large language models (LLMs). However, RAG still struggles to fully prevent hallucinated responses. To address this, it is essential to identify samples prone to hallucination or guide LLMs toward correct responses, which experts then annotate to develop high-quality datasets for refining LLMs. However, the growing scarcity of such datasets makes their creation challenging. This paper proposes using the vast amount of conversations from widespread LLM usage to build these datasets, training LLMs to avoid hallucination-prone questions while accurately responding to manageable ones. Given the impracticality of expert-annotating all conversation records, the paper introduces AL4RAG, which uses active learning to select the most suitable conversation samples for annotation, optimizing performance within an annotation budget. Additionally, recognizing that traditional active learning methods are not fully compatible with RAG due to unsuitable distance metrics, we develop a novel sample distance measurement for RAG active learning. Extensive experiments show that our method consistently outperforms baselines across multiple metrics.</li>
</ul>

<h3>Title: PTZ-Calib: Robust Pan-Tilt-Zoom Camera Calibration</h3>
<ul>
<li><strong>Authors: </strong>Jinhui Guo, Lubin Fan, Bojian Wu, Jiaqi Gu, Shen Cao, Jieping Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09075">https://arxiv.org/abs/2502.09075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09075">https://arxiv.org/pdf/2502.09075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09075]] PTZ-Calib: Robust Pan-Tilt-Zoom Camera Calibration(https://arxiv.org/abs/2502.09075)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present PTZ-Calib, a robust two-stage PTZ camera calibration method, that efficiently and accurately estimates camera parameters for arbitrary viewpoints. Our method includes an offline and an online stage. In the offline stage, we first uniformly select a set of reference images that sufficiently overlap to encompass a complete 360° view. We then utilize the novel PTZ-IBA (PTZ Incremental Bundle Adjustment) algorithm to automatically calibrate the cameras within a local coordinate system. Additionally, for practical application, we can further optimize camera parameters and align them with the geographic coordinate system using extra global reference 3D information. In the online stage, we formulate the calibration of any new viewpoints as a relocalization problem. Our approach balances the accuracy and computational efficiency to meet real-world demands. Extensive evaluations demonstrate our robustness and superior performance over state-of-the-art methods on various real and synthetic datasets. Datasets and source code can be accessed online at this https URL</li>
</ul>

<h3>Title: BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization</h3>
<ul>
<li><strong>Authors: </strong>Qiwei Wang, Shaoxun Wu, Yujiao Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09080">https://arxiv.org/abs/2502.09080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09080">https://arxiv.org/pdf/2502.09080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09080]] BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization(https://arxiv.org/abs/2502.09080)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper addresses the problem of weakly supervised cross-view localization, where the goal is to estimate the pose of a ground camera relative to a satellite image with noisy ground truth annotations. A common approach to bridge the cross-view domain gap for pose estimation is Bird's-Eye View (BEV) synthesis. However, existing methods struggle with height ambiguity due to the lack of depth information in ground images and satellite height maps. Previous solutions either assume a flat ground plane or rely on complex models, such as cross-view transformers. We propose BevSplat, a novel method that resolves height ambiguity by using feature-based Gaussian primitives. Each pixel in the ground image is represented by a 3D Gaussian with semantic and spatial features, which are synthesized into a BEV feature map for relative pose estimation. Additionally, to address challenges with panoramic query images, we introduce an icosphere-based supervision strategy for the Gaussian primitives. We validate our method on the widely used KITTI and VIGOR datasets, which include both pinhole and panoramic query images. Experimental results show that BevSplat significantly improves localization accuracy over prior approaches.</li>
</ul>

<h3>Title: CoSER: Coordinating LLM-Based Persona Simulation of Established Roles</h3>
<ul>
<li><strong>Authors: </strong>Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Wei Wang, Yanghua Xiao, Shuchang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09082">https://arxiv.org/abs/2502.09082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09082">https://arxiv.org/pdf/2502.09082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09082]] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles(https://arxiv.org/abs/2502.09082)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Role-playing language agents (RPLAs) have emerged as promising applications of large language models (LLMs). However, simulating established characters presents a challenging task for RPLAs, due to the lack of authentic character datasets and nuanced evaluation methods using such data. In this paper, we present CoSER, a collection of a high-quality dataset, open models, and an evaluation protocol towards effective RPLAs of established characters. The CoSER dataset covers 17,966 characters from 771 renowned books. It provides authentic dialogues with real-world intricacies, as well as diverse data types such as conversation setups, character experiences and internal thoughts. Drawing from acting methodology, we introduce given-circumstance acting for training and evaluating role-playing LLMs, where LLMs sequentially portray multiple characters in book scenes. Using our dataset, we develop CoSER 8B and CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models. Extensive experiments demonstrate the value of the CoSER dataset for RPLA training, evaluation and retrieval. Moreover, CoSER 70B exhibits state-of-the-art performance surpassing or matching GPT-4o on our evaluation and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on the InCharacter and LifeChoice benchmarks respectively.</li>
</ul>

<h3>Title: Application of Tabular Transformer Architectures for Operating System Fingerprinting</h3>
<ul>
<li><strong>Authors: </strong>Rubén Pérez-Jove, Cristian R. Munteanu, Alejandro Pazos, Jose Vázquez-Naya</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09084">https://arxiv.org/abs/2502.09084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09084">https://arxiv.org/pdf/2502.09084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09084]] Application of Tabular Transformer Architectures for Operating System Fingerprinting(https://arxiv.org/abs/2502.09084)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer</a></li>
<li><strong>Abstract: </strong>Operating System (OS) fingerprinting is essential for network management and cybersecurity, enabling accurate device identification based on network traffic analysis. Traditional rule-based tools such as Nmap and p0f face challenges in dynamic environments due to frequent OS updates and obfuscation techniques. While Machine Learning (ML) approaches have been explored, Deep Learning (DL) models, particularly Transformer architectures, remain unexploited in this domain. This study investigates the application of Tabular Transformer architectures-specifically TabTransformer and FT-Transformer-for OS fingerprinting, leveraging structured network data from three publicly available datasets. Our experiments demonstrate that FT-Transformer generally outperforms traditional ML models, previous approaches and TabTransformer across multiple classification levels (OS family, major, and minor versions). The results establish a strong foundation for DL-based OS fingerprinting, improving accuracy and adaptability in complex network environments. Furthermore, we ensure the reproducibility of our research by providing an open-source implementation.</li>
</ul>

<h3>Title: Unsupervised Anomaly Detection on Implicit Shape representations for Sarcopenia Detection</h3>
<ul>
<li><strong>Authors: </strong>Louise Piecuch, Jeremie Huet (MD), Antoine Frouin (PT), Antoine Nordez, Anne-Sophie Boureau (MD), Diana Mateus</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09088">https://arxiv.org/abs/2502.09088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09088">https://arxiv.org/pdf/2502.09088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09088]] Unsupervised Anomaly Detection on Implicit Shape representations for Sarcopenia Detection(https://arxiv.org/abs/2502.09088)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Sarcopenia is an age-related progressive loss of muscle mass and strength that significantly impacts daily life. A commonly studied criterion for characterizing the muscle mass has been the combination of 3D imaging and manual segmentations. In this paper, we instead study the muscles' shape. We rely on an implicit neural representation (INR) to model normal muscle shapes. We then introduce an unsupervised anomaly detection method to identify sarcopenic muscles based on the reconstruction error of the implicit model. Relying on a conditional INR with an auto-decoding strategy, we also learn a latent representation of the muscles that clearly separates normal from abnormal muscles in an unsupervised fashion. Experimental results on a dataset of 103 segmented volumes indicate that our double anomaly detection strategy effectively discriminates sarcopenic and non-sarcopenic muscles.</li>
</ul>

<h3>Title: A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Huang, Zeqiu Xu, Peiyang Yu, Jingyuan Yi, Xiaochuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09097">https://arxiv.org/abs/2502.09097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09097">https://arxiv.org/pdf/2502.09097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09097]] A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit(https://arxiv.org/abs/2502.09097)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose an optimized Transformer model that integrates Bayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and apply it to fake news classification for the first time. First, we employ the TF-IDF method to extract features from news texts and transform them into numeric representations to facilitate subsequent machine learning tasks. Two sets of experiments are then conducted for fake news detection and classification: one using a Transformer model optimized only with BiGRU, and the other incorporating Bayesian algorithms into the BiGRU-based Transformer. Experimental results show that the BiGRU-optimized Transformer achieves 100% accuracy on the training set and 99.67% on the test set, while the addition of the Bayesian algorithm maintains 100% accuracy on the training set and slightly improves test-set accuracy to 99.73%. This indicates that the Bayesian algorithm boosts model accuracy by 0.06%, further enhancing the detection capability for fake news. Moreover, the proposed algorithm converges rapidly at around the 10th training epoch with accuracy nearing 100%, demonstrating both its effectiveness and its fast classification ability. Overall, the optimized Transformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits excellent continuous learning and detection performance, offering a robust technical means to combat the spread of fake news in the current era of information overload.</li>
</ul>

<h3>Title: One-shot Federated Learning Methods: A Practical Guide</h3>
<ul>
<li><strong>Authors: </strong>Xiang Liu, Zhenheng Tang, Xia Li, Yijun Song, Sijie Ji, Zemin Liu, Bo Han, Linshan Jiang, Jialin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09104">https://arxiv.org/abs/2502.09104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09104">https://arxiv.org/pdf/2502.09104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09104]] One-shot Federated Learning Methods: A Practical Guide(https://arxiv.org/abs/2502.09104)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>One-shot Federated Learning (OFL) is a distributed machine learning paradigm that constrains client-server communication to a single round, addressing privacy and communication overhead issues associated with multiple rounds of data exchange in traditional Federated Learning (FL). OFL demonstrates the practical potential for integration with future approaches that require collaborative training models, such as large language models (LLMs). However, current OFL methods face two major challenges: data heterogeneity and model heterogeneity, which result in subpar performance compared to conventional FL methods. Worse still, despite numerous studies addressing these limitations, a comprehensive summary is still lacking. To address these gaps, this paper presents a systematic analysis of the challenges faced by OFL and thoroughly reviews the current methods. We also offer an innovative categorization method and analyze the trade-offs of various techniques. Additionally, we discuss the most promising future directions and the technologies that should be integrated into the OFL field. This work aims to provide guidance and insights for future research.</li>
</ul>

<h3>Title: Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks</h3>
<ul>
<li><strong>Authors: </strong>Eylon Mizrahi, Raz Lapid, Moshe Sipper</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09110">https://arxiv.org/abs/2502.09110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09110">https://arxiv.org/pdf/2502.09110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09110]] Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks(https://arxiv.org/abs/2502.09110)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep learning models are widely employed in safety-critical applications yet remain susceptible to adversarial attacks -- imperceptible perturbations that can significantly degrade model performance. Conventional defense mechanisms predominantly focus on either enhancing model robustness or detecting adversarial inputs independently. In this work, we propose an Unsupervised adversarial detection via Contrastive Auxiliary Networks (U-CAN) to uncover adversarial behavior within auxiliary feature representations, without the need for adversarial examples. U-CAN is embedded within selected intermediate layers of the target model. These auxiliary networks, comprising projection layers and ArcFace-based linear layers, refine feature representations to more effectively distinguish between benign and adversarial inputs. Comprehensive experiments across multiple datasets (CIFAR-10, Mammals, and a subset of ImageNet) and architectures (ResNet-50, VGG-16, and ViT) demonstrate that our method surpasses existing unsupervised adversarial detection techniques, achieving superior F1 scores against four distinct attack methods. The proposed framework provides a scalable and effective solution for enhancing the security and reliability of deep learning systems.</li>
</ul>

<h3>Title: In Specs we Trust? Conformance-Analysis of Implementation to Specifications in Node-RED and Associated Security Risks</h3>
<ul>
<li><strong>Authors: </strong>Simon Schneider, Komal Kashish, Katja Tuma, Riccardo Scandariato</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09117">https://arxiv.org/abs/2502.09117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09117">https://arxiv.org/pdf/2502.09117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09117]] In Specs we Trust? Conformance-Analysis of Implementation to Specifications in Node-RED and Associated Security Risks(https://arxiv.org/abs/2502.09117)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Low-code development frameworks for IoT platforms offer a simple drag-and-drop mechanism to create applications for the billions of existing IoT devices without the need for extensive programming knowledge. The security of such software is crucial given the close integration of IoT devices in many highly sensitive areas such as healthcare or home automation. Node-RED is such a framework, where applications are built from nodes that are contributed by open-source developers. Its reliance on unvetted open-source contributions and lack of security checks raises the concern that the applications could be vulnerable to attacks, thereby imposing a security risk to end users. The low-code approach suggests, that many users could lack the technical knowledge to mitigate, understand, or even realize such security concerns. This paper focuses on "hidden" information flows in Node-RED nodes, meaning flows that are not captured by the specifications. They could (unknowingly or with malicious intent) cause leaks of sensitive information to unauthorized entities. We report the results of a conformance analysis of all nodes in the Node-RED framework, for which we compared the numbers of specified inputs and outputs of each node against the number of sources and sinks detected with CodeQL. The results show, that 55% of all nodes exhibit more possible flows than are specified. A risk assessment of a subset of the nodes showed, that 28% of them are associated with a high severity and 36% with a medium severity rating.</li>
</ul>

<h3>Title: Finite-Time Analysis of Discrete-Time Stochastic Interpolants</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Liu, Yu Chen, Rui Hu, Longbo Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09130">https://arxiv.org/abs/2502.09130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09130">https://arxiv.org/pdf/2502.09130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09130]] Finite-Time Analysis of Discrete-Time Stochastic Interpolants(https://arxiv.org/abs/2502.09130)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The stochastic interpolant framework offers a powerful approach for constructing generative models based on ordinary differential equations (ODEs) or stochastic differential equations (SDEs) to transform arbitrary data distributions. However, prior analyses of this framework have primarily focused on the continuous-time setting, assuming a perfect solution of the underlying equations. In this work, we present the first discrete-time analysis of the stochastic interpolant framework, where we introduce an innovative discrete-time sampler and derive a finite-time upper bound on its distribution estimation error. Our result provides a novel quantification of how different factors, including the distance between source and target distributions and estimation accuracy, affect the convergence rate and also offers a new principled way to design efficient schedules for convergence acceleration. Finally, numerical experiments are conducted on the discrete-time sampler to corroborate our theoretical findings.</li>
</ul>

<h3>Title: Interpreting and Steering Protein Language Models through Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Edith Natalia Villegas Garcia, Alessio Ansuini</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09135">https://arxiv.org/abs/2502.09135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09135">https://arxiv.org/pdf/2502.09135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09135]] Interpreting and Steering Protein Language Models through Sparse Autoencoders(https://arxiv.org/abs/2502.09135)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The rapid advancements in transformer-based language models have revolutionized natural language processing, yet understanding the internal mechanisms of these models remains a significant challenge. This paper explores the application of sparse autoencoders (SAE) to interpret the internal representations of protein language models, specifically focusing on the ESM-2 8M parameter model. By performing a statistical analysis on each latent component's relevance to distinct protein annotations, we identify potential interpretations linked to various protein characteristics, including transmembrane regions, binding sites, and specialized motifs. We then leverage these insights to guide sequence generation, shortlisting the relevant latent components that can steer the model towards desired targets such as zinc finger domains. This work contributes to the emerging field of mechanistic interpretability in biological sequence models, offering new perspectives on model steering for sequence design.</li>
</ul>

<h3>Title: Zebrafix: Mitigating Memory-Centric Side-Channel Leakage via Interleaving</h3>
<ul>
<li><strong>Authors: </strong>Anna Pätschke, Jan Wichelmann, Thomas Eisenbarth</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09139">https://arxiv.org/abs/2502.09139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09139">https://arxiv.org/pdf/2502.09139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09139]] Zebrafix: Mitigating Memory-Centric Side-Channel Leakage via Interleaving(https://arxiv.org/abs/2502.09139)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Constant-time code has become the de-facto standard for secure cryptographic implementations. However, some memory-based leakage classes such as ciphertext side-channels, silent stores, and data memory-dependent prefetching remain unaddressed. In the context of ciphertext side-channel mitigations, the practicality of interleaving data with counter values remains to be explored. To close this gap, we define design choices and requirements to leverage interleaving for a generic ciphertext side-channel mitigation. Based on these results, we implement Zebrafix, a compiler-based tool to ensure freshness of memory stores. We evaluate Zebrafix and find that interleaving can perform much better than other ciphertext side-channel mitigations, at the cost of a high practical complexity. We further observe that ciphertext side-channels, silent stores and data memory-dependent prefetching belong to a broader attack category: memory-centric side-channels. Under this unified view, we discuss to what extent ciphertext side-channel mitigations can be adapted to prevent all three memory-centric side-channel attacks via interleaving.</li>
</ul>

<h3>Title: Replay-free Online Continual Learning with Self-Supervised MultiPatches</h3>
<ul>
<li><strong>Authors: </strong>Giacomo Cignoni, Andrea Cossu, Alex Gomez-Villa, Joost van de Weijer, Antonio Carta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09140">https://arxiv.org/abs/2502.09140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09140">https://arxiv.org/pdf/2502.09140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09140]] Replay-free Online Continual Learning with Self-Supervised MultiPatches(https://arxiv.org/abs/2502.09140)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Online Continual Learning (OCL) methods train a model on a non-stationary data stream where only a few examples are available at a time, often leveraging replay strategies. However, usage of replay is sometimes forbidden, especially in applications with strict privacy regulations. Therefore, we propose Continual MultiPatches (CMP), an effective plug-in for existing OCL self-supervised learning strategies that avoids the use of replay samples. CMP generates multiple patches from a single example and projects them into a shared feature space, where patches coming from the same example are pushed together without collapsing into a single point. CMP surpasses replay and other SSL-based strategies on OCL streams, challenging the role of replay as a go-to solution for self-supervised OCL.</li>
</ul>

<h3>Title: Feature-based Graph Attention Networks Improve Online Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Adjovi Sim, Zhengkui Wang, Aik Beng Ng, Shalini De Mello, Simon See, Wonmin Byeon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09143">https://arxiv.org/abs/2502.09143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09143">https://arxiv.org/pdf/2502.09143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09143]] Feature-based Graph Attention Networks Improve Online Continual Learning(https://arxiv.org/abs/2502.09143)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Online continual learning for image classification is crucial for models to adapt to new data while retaining knowledge of previously learned tasks. This capability is essential to address real-world challenges involving dynamic environments and evolving data distributions. Traditional approaches predominantly employ Convolutional Neural Networks, which are limited to processing images as grids and primarily capture local patterns rather than relational information. Although the emergence of transformer architectures has improved the ability to capture relationships, these models often require significantly larger resources. In this paper, we present a novel online continual learning framework based on Graph Attention Networks (GATs), which effectively capture contextual relationships and dynamically update the task-specific representation via learned attention weights. Our approach utilizes a pre-trained feature extractor to convert images into graphs using hierarchical feature maps, representing information at varying levels of granularity. These graphs are then processed by a GAT and incorporate an enhanced global pooling strategy to improve classification performance for continual learning. In addition, we propose the rehearsal memory duplication technique that improves the representation of the previous tasks while maintaining the memory budget. Comprehensive evaluations on benchmark datasets, including SVHN, CIFAR10, CIFAR100, and MiniImageNet, demonstrate the superiority of our method compared to the state-of-the-art methods.</li>
</ul>

<h3>Title: Multimodal HIE Lesion Segmentation in Neonates: A Comparative Study of Loss Functions</h3>
<ul>
<li><strong>Authors: </strong>Annayah Usman, Abdul Haseeb, Tahir Syed</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09148">https://arxiv.org/abs/2502.09148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09148">https://arxiv.org/pdf/2502.09148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09148]] Multimodal HIE Lesion Segmentation in Neonates: A Comparative Study of Loss Functions(https://arxiv.org/abs/2502.09148)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segmentation of Hypoxic-Ischemic Encephalopathy (HIE) lesions in neonatal MRI is a crucial but challenging task due to diffuse multifocal lesions with varying volumes and the limited availability of annotated HIE lesion datasets. Using the BONBID-HIE dataset, we implemented a 3D U-Net with optimized preprocessing, augmentation, and training strategies to overcome data constraints. The goal of this study is to identify the optimal loss function specifically for the HIE lesion segmentation task. To this end, we evaluated various loss functions, including Dice, Dice-Focal, Tversky, Hausdorff Distance (HausdorffDT) Loss, and two proposed compound losses -- Dice-Focal-HausdorffDT and Tversky-HausdorffDT -- to enhance segmentation performance. The results show that different loss functions predict distinct segmentation masks, with compound losses outperforming standalone losses. Tversky-HausdorffDT Loss achieves the highest Dice and Normalized Surface Dice scores, while Dice-Focal-HausdorffDT Loss minimizes Mean Surface Distance. This work underscores the significance of task-specific loss function optimization, demonstrating that combining region-based and boundary-aware losses leads to more accurate HIE lesion segmentation, even with limited training data.</li>
</ul>

<h3>Title: Shortcut Learning Susceptibility in Vision Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Pirzada Suhail, Amit Sethi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09150">https://arxiv.org/abs/2502.09150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09150">https://arxiv.org/pdf/2502.09150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09150]] Shortcut Learning Susceptibility in Vision Classifiers(https://arxiv.org/abs/2502.09150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Shortcut learning, where machine learning models exploit spurious correlations in data instead of capturing meaningful features, poses a significant challenge to building robust and generalizable models. This phenomenon is prevalent across various machine learning applications, including vision, natural language processing, and speech recognition, where models may find unintended cues that minimize training loss but fail to capture the underlying structure of the data. Vision classifiers such as Convolutional Neural Networks (CNNs), Multi-Layer Perceptrons (MLPs), and Vision Transformers (ViTs) leverage distinct architectural principles to process spatial and structural information, making them differently susceptible to shortcut learning. In this study, we systematically evaluate these architectures by introducing deliberate shortcuts into the dataset that are positionally correlated with class labels, creating a controlled setup to assess whether models rely on these artificial cues or learn actual distinguishing features. We perform both quantitative evaluation by training on the shortcut-modified dataset and testing them on two different test sets -- one containing the same shortcuts and another without them -- to determine the extent of reliance on shortcuts. Additionally, qualitative evaluation is performed by using network inversion-based reconstruction techniques to analyze what the models internalize in their weights, aiming to reconstruct the training data as perceived by the classifiers. We evaluate shortcut learning behavior across multiple benchmark datasets, including MNIST, Fashion-MNIST, SVHN, and CIFAR-10, to compare the susceptibility of different vision classifier architectures to shortcut reliance and assess their varying degrees of sensitivity to spurious correlations.</li>
</ul>

<h3>Title: Regularization can make diffusion models more efficient</h3>
<ul>
<li><strong>Authors: </strong>Mahsa Taheri, Johannes Lederer</a></li>
<li><strong>Subjects: </strong>cs.LG, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09151">https://arxiv.org/abs/2502.09151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09151">https://arxiv.org/pdf/2502.09151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09151]] Regularization can make diffusion models more efficient(https://arxiv.org/abs/2502.09151)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are one of the key architectures of generative AI. Their main drawback, however, is the computational costs. This study indicates that the concept of sparsity, well known especially in statistics, can provide a pathway to more efficient diffusion pipelines. Our mathematical guarantees prove that sparsity can reduce the input dimension's influence on the computational complexity to that of a much smaller intrinsic dimension of the data. Our empirical findings confirm that inducing sparsity can indeed lead to better samples at a lower cost.</li>
</ul>

<h3>Title: Vertical Federated Continual Learning via Evolving Prototype Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Shuo Wang, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09152">https://arxiv.org/abs/2502.09152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09152">https://arxiv.org/pdf/2502.09152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09152]] Vertical Federated Continual Learning via Evolving Prototype Knowledge(https://arxiv.org/abs/2502.09152)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Vertical Federated Learning (VFL) has garnered significant attention as a privacy-preserving machine learning framework for sample-aligned feature federation. However, traditional VFL approaches do not address the challenges of class and feature continual learning, resulting in catastrophic forgetting of knowledge from previous tasks. To address the above challenge, we propose a novel vertical federated continual learning method, named Vertical Federated Continual Learning via Evolving Prototype Knowledge (V-LETO), which primarily facilitates the transfer of knowledge from previous tasks through the evolution of prototypes. Specifically, we propose an evolving prototype knowledge method, enabling the global model to retain both previous and current task knowledge. Furthermore, we introduce a model optimization technique that mitigates the forgetting of previous task knowledge by restricting updates to specific parameters of the local model, thereby enhancing overall performance. Extensive experiments conducted in both CIL and FIL settings demonstrate that our method, V-LETO, outperforms the other state-of-the-art methods. For example, our method outperforms the state-of-the-art method by 10.39% and 35.15% for CIL and FIL tasks, respectively. Our code is available at this https URL.</li>
</ul>

<h3>Title: Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09156">https://arxiv.org/abs/2502.09156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09156">https://arxiv.org/pdf/2502.09156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09156]] Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs(https://arxiv.org/abs/2502.09156)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Objectives: Large language models (LLMs) can harness medical knowledge for intelligent question answering (Q&A), promising support for auxiliary diagnosis and medical talent cultivation. However, there is a deficiency of highly efficient retrieval-augmented generation (RAG) frameworks within the domain of Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A tasks. Materials and Methods: We introduce the novel approach of knowledge organization, constructing a tree structure knowledge base with hierarchy. At inference time, our self-reflection framework retrieves from this knowledge base, integrating information across chapters. Questions from the TCM Medical Licensing Examination (MLE) and the college Classics Course Exam (CCE) were randomly selected as benchmark datasets. Results: By coupling with GPT-4, the framework can improve the best performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation, the framework improves a total of 18.52 points across dimensions of safety, consistency, explainability, compliance, and coherence. Conclusion: The TOSRR framework can effectively improve LLM's capability in Q&A tasks of TCM.</li>
</ul>

<h3>Title: E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization</h3>
<ul>
<li><strong>Authors: </strong>Trung X. Pham, Zhang Kang, Ji Woo Hong, Xuran Zheng, Chang D. Yoo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09164">https://arxiv.org/abs/2502.09164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09164">https://arxiv.org/pdf/2502.09164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09164]] E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization(https://arxiv.org/abs/2502.09164)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose E-MD3C ($\underline{E}$fficient $\underline{M}$asked $\underline{D}$iffusion Transformer with Disentangled $\underline{C}$onditions and $\underline{C}$ompact $\underline{C}$ollector), a highly efficient framework for zero-shot object image customization. Unlike prior works reliant on resource-intensive Unet architectures, our approach employs lightweight masked diffusion transformers operating on latent patches, offering significantly improved computational efficiency. The framework integrates three core components: (1) an efficient masked diffusion transformer for processing autoencoder latents, (2) a disentangled condition design that ensures compactness while preserving background alignment and fine details, and (3) a learnable Conditions Collector that consolidates multiple inputs into a compact representation for efficient denoising and learning. E-MD3C outperforms the existing approach on the VITON-HD dataset across metrics such as PSNR, FID, SSIM, and LPIPS, demonstrating clear advantages in parameters, memory efficiency, and inference speed. With only $\frac{1}{4}$ of the parameters, our Transformer-based 468M model delivers $2.5\times$ faster inference and uses $\frac{2}{3}$ of the GPU memory compared to an 1720M Unet-based latent diffusion model.</li>
</ul>

<h3>Title: LOB-Bench: Benchmarking Generative AI for Finance - an Application to Limit Order Book Data</h3>
<ul>
<li><strong>Authors: </strong>Peer Nagy, Sascha Frey, Kang Li, Bidipta Sarkar, Svitlana Vyetrenko, Stefan Zohren, Ani Calinescu, Jakob Foerster</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, q-fin.CP, q-fin.TR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09172">https://arxiv.org/abs/2502.09172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09172">https://arxiv.org/pdf/2502.09172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09172]] LOB-Bench: Benchmarking Generative AI for Finance - an Application to Limit Order Book Data(https://arxiv.org/abs/2502.09172)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While financial data presents one of the most challenging and interesting sequence modelling tasks due to high noise, heavy tails, and strategic interactions, progress in this area has been hindered by the lack of consensus on quantitative evaluation paradigms. To address this, we present LOB-Bench, a benchmark, implemented in python, designed to evaluate the quality and realism of generative message-by-order data for limit order books (LOB) in the LOBSTER format. Our framework measures distributional differences in conditional and unconditional statistics between generated and real LOB data, supporting flexible multivariate statistical evaluation. The benchmark also includes features commonly used LOB statistics such as spread, order book volumes, order imbalance, and message inter-arrival times, along with scores from a trained discriminator network. Lastly, LOB-Bench contains "market impact metrics", i.e. the cross-correlations and price response functions for specific events in the data. We benchmark generative autoregressive state-space models, a (C)GAN, as well as a parametric LOB model and find that the autoregressive GenAI approach beats traditional model classes.</li>
</ul>

<h3>Title: Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia</h3>
<ul>
<li><strong>Authors: </strong>Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09173">https://arxiv.org/abs/2502.09173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09173">https://arxiv.org/pdf/2502.09173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09173]] Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia(https://arxiv.org/abs/2502.09173)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In remote healthcare monitoring, time series representation learning reveals critical patient behavior patterns from high-frequency data. This study analyzes home activity data from individuals living with dementia by proposing a two-stage, self-supervised learning approach tailored to uncover low-rank structures. The first stage converts time-series activities into text sequences encoded by a pre-trained language model, providing a rich, high-dimensional latent state space using a PageRank-based method. This PageRank vector captures latent state transitions, effectively compressing complex behaviour data into a succinct form that enhances interpretability. This low-rank representation not only enhances model interpretability but also facilitates clustering and transition analysis, revealing key behavioral patterns correlated with clinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the framework's potential in supporting cognitive status prediction, personalized care interventions, and large-scale health monitoring.</li>
</ul>

<h3>Title: FLAME: Flexible LLM-Assisted Moderation Engine</h3>
<ul>
<li><strong>Authors: </strong>Ivan Bakulin (1 and 2), Ilia Kopanichuk (1 and 2), Iaroslav Bespalov (1), Nikita Radchenko (3), Vladimir Shaposhnikov (1 and 4), Dmitry Dylov (1 and 4), Ivan Oseledets (1 and 4) ((1) AIRI, (2) Moscow Institute of Physics and Technology, (3) SberHealth, (4) Skolkovo Institute of Science and Technology)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09175">https://arxiv.org/abs/2502.09175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09175">https://arxiv.org/pdf/2502.09175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09175]] FLAME: Flexible LLM-Assisted Moderation Engine(https://arxiv.org/abs/2502.09175)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) has introduced significant challenges in moderating user-model interactions. While LLMs demonstrate remarkable capabilities, they remain vulnerable to adversarial attacks, particularly ``jailbreaking'' techniques that bypass content safety measures. Current content moderation systems, which primarily rely on input prompt filtering, have proven insufficient, with techniques like Best-of-N (BoN) jailbreaking achieving success rates of 80% or more against popular LLMs. In this paper, we introduce Flexible LLM-Assisted Moderation Engine (FLAME): a new approach that shifts the focus from input filtering to output moderation. Unlike traditional circuit-breaking methods that analyze user queries, FLAME evaluates model responses, offering several key advantages: (1) computational efficiency in both training and inference, (2) enhanced resistance to BoN jailbreaking attacks, and (3) flexibility in defining and updating safety criteria through customizable topic filtering. Our experiments demonstrate that FLAME significantly outperforms current moderation systems. For example, FLAME reduces attack success rate in GPT-4o-mini and DeepSeek-v3 by a factor of ~9, while maintaining low computational overhead. We provide comprehensive evaluation on various LLMs and analyze the engine's efficiency against the state-of-the-art jailbreaking. This work contributes to the development of more robust and adaptable content moderation systems for LLMs.</li>
</ul>

<h3>Title: RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Changzhi Zhou, Xinyu Zhang, Dandan Song, Xiancai Chen, Wanli Gu, Huipeng Ma, Yuhang Tian, Mengdi Zhang, Linmei Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09183">https://arxiv.org/abs/2502.09183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09183">https://arxiv.org/pdf/2502.09183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09183]] RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation(https://arxiv.org/abs/2502.09183)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Code generation has attracted increasing attention with the rise of Large Language Models (LLMs). Many studies have developed powerful code LLMs by synthesizing code-related instruction data and applying supervised fine-tuning. However, these methods are limited by teacher model distillation and ignore the potential of iterative refinement by self-generated code. In this paper, we propose Adaptive Critique Refinement (ACR), which enables the model to refine itself by self-generated code and external critique, rather than directly imitating the code responses of the teacher model. Concretely, ACR includes a composite scoring system with LLM-as-a-Judge to evaluate the quality of code responses and a selective critique strategy with LLM-as-a-Critic to critique self-generated low-quality code responses. We develop the RefineCoder series by iteratively applying ACR, achieving continuous performance improvement on multiple code generation benchmarks. Compared to the baselines of the same size, our proposed RefineCoder series can achieve comparable or even superior performance using less data.</li>
</ul>

<h3>Title: Matina: A Large-Scale 73B Token Persian Text Corpus</h3>
<ul>
<li><strong>Authors: </strong>Sara Bourbour Hosseinbeigi, Fatemeh Taherinezhad, Heshaam Faili, Hamed Baghbani, Fatemeh Nadi, Mostafa Amiri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09188">https://arxiv.org/abs/2502.09188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09188">https://arxiv.org/pdf/2502.09188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09188]] Matina: A Large-Scale 73B Token Persian Text Corpus(https://arxiv.org/abs/2502.09188)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Text corpora are essential for training models used in tasks like summarization, translation, and large language models (LLMs). While various efforts have been made to collect monolingual and multilingual datasets in many languages, Persian has often been underrepresented due to limited resources for data collection and preprocessing. Existing Persian datasets are typically small and lack content diversity, consisting mainly of weblogs and news articles. This shortage of high-quality, varied data has slowed the development of NLP models and open-source LLMs for Persian. Since model performance depends heavily on the quality of training data, we address this gap by introducing the Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed and deduplicated to ensure high data quality. We further assess its effectiveness by training and evaluating transformer-based models on key NLP tasks. Both the dataset and preprocessing codes are publicly available, enabling researchers to build on and improve this resource for future Persian NLP advancements.</li>
</ul>

<h3>Title: Thinking beyond the anthropomorphic paradigm benefits LLM research</h3>
<ul>
<li><strong>Authors: </strong>Lujain Ibrahim, Myra Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09192">https://arxiv.org/abs/2502.09192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09192">https://arxiv.org/pdf/2502.09192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09192]] Thinking beyond the anthropomorphic paradigm benefits LLM research(https://arxiv.org/abs/2502.09192)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Anthropomorphism, or the attribution of human traits to technology, is an automatic and unconscious response that occurs even in those with advanced technical expertise. In this position paper, we analyze hundreds of thousands of computer science research articles from the past decade and present empirical evidence of the prevalence and growth of anthropomorphic terminology in research on large language models (LLMs). This terminology reflects deeper anthropomorphic conceptualizations which shape how we think about and conduct LLM research. We argue these conceptualizations may be limiting, and that challenging them opens up new pathways for understanding and improving LLMs beyond human analogies. To illustrate this, we identify and analyze five core anthropomorphic assumptions shaping prominent methodologies across the LLM development lifecycle, from the assumption that models must use natural language for reasoning tasks to the assumption that model capabilities should be evaluated through human-centric benchmarks. For each assumption, we demonstrate how non-anthropomorphic alternatives can open new directions for research and development.</li>
</ul>

<h3>Title: Generalizability through Explainability: Countering Overfitting with Counterfactual Examples</h3>
<ul>
<li><strong>Authors: </strong>Flavio Giorgi, Fabiano Veglianti, Fabrizio Silvestri, Gabriele Tolomei</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09193">https://arxiv.org/abs/2502.09193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09193">https://arxiv.org/pdf/2502.09193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09193]] Generalizability through Explainability: Countering Overfitting with Counterfactual Examples(https://arxiv.org/abs/2502.09193)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Overfitting is a well-known issue in machine learning that occurs when a model struggles to generalize its predictions to new, unseen data beyond the scope of its training set. Traditional techniques to mitigate overfitting include early stopping, data augmentation, and regularization. In this work, we demonstrate that the degree of overfitting of a trained model is correlated with the ability to generate counterfactual examples. The higher the overfitting, the easier it will be to find a valid counterfactual example for a randomly chosen input data point. Therefore, we introduce CF-Reg, a novel regularization term in the training loss that controls overfitting by ensuring enough margin between each instance and its corresponding counterfactual. Experiments conducted across multiple datasets and models show that our counterfactual regularizer generally outperforms existing regularization techniques.</li>
</ul>

<h3>Title: Commitment Schemes from OWFs with Applications to qOT</h3>
<ul>
<li><strong>Authors: </strong>Thomas Lorünser, Sebastian Ramarcher, Federico Valbusa</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09201">https://arxiv.org/abs/2502.09201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09201">https://arxiv.org/pdf/2502.09201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09201]] Commitment Schemes from OWFs with Applications to qOT(https://arxiv.org/abs/2502.09201)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Commitment schemes are essential to many cryptographic protocols and schemes with applications that include privacy-preserving computation on data, privacy-preserving authentication, and, in particular, oblivious transfer protocols. For quantum oblivious transfer (qOT) protocols, unconditionally binding commitment schemes that do not rely on hardness assumptions from structured mathematical problems are required. These additional constraints severely limit the choice of commitment schemes to random oracle-based constructions or Naor's bit commitment scheme. As these protocols commit to individual bits, the use of such commitment schemes comes at a high bandwidth and computational cost. In this work, we investigate improvements to the efficiency of commitment schemes used in qOT protocols and propose an extension of Naor's commitment scheme requiring the existence of one-way functions (OWF) to reduce communication complexity for 2-bit strings. Additionally, we provide an interactive string commitment scheme with preprocessing to enable a fast and efficient computation of commitments.</li>
</ul>

<h3>Title: Faster than real-time detection of shot boundaries, sampling structure and dynamic keyframes in video</h3>
<ul>
<li><strong>Authors: </strong>Hannes Fassold</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09202">https://arxiv.org/abs/2502.09202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09202">https://arxiv.org/pdf/2502.09202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09202]] Faster than real-time detection of shot boundaries, sampling structure and dynamic keyframes in video(https://arxiv.org/abs/2502.09202)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The detection of shot boundaries (hardcuts and short dissolves), sampling structure (progressive / interlaced / pulldown) and dynamic keyframes in a video are fundamental video analysis tasks which have to be done before any further high-level analysis tasks. We present a novel algorithm which does all these analysis tasks in an unified way, by utilizing a combination of inter-frame and intra-frame measures derived from the motion field and normalized cross correlation. The algorithm runs four times faster than real-time due to sparse and selective calculation of these measures. An initial evaluation furthermore shows that the proposed algorithm is extremely robust even for challenging content showing large camera or object motion, flashlights, flicker or low contrast / noise.</li>
</ul>

<h3>Title: You Do Not Fully Utilize Transformer's Representation Capacity</h3>
<ul>
<li><strong>Authors: </strong>Gleb Gerasimov, Yaroslav Aksenov, Nikita Balagansky, Viacheslav Sinii, Daniil Gavrilov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09245">https://arxiv.org/abs/2502.09245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09245">https://arxiv.org/pdf/2502.09245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09245]] You Do Not Fully Utilize Transformer's Representation Capacity(https://arxiv.org/abs/2502.09245)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In contrast to RNNs, which compress previous tokens into a single hidden state, Transformers can attend to all previous tokens directly. However, standard Transformers only use representations from the immediately preceding layer. In this paper, we show that this design choice causes representation collapse and leads to suboptimal performance. To address this issue, we introduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that preserves the model's overall memory footprint while expanding its representational capacity by allowing access to hidden states from earlier layers. Through extensive experiments across various architectures and different lookup mechanisms, we demonstrate consistent performance improvements on a wide range of tasks. Moreover, our analysis of the learned representation dynamics and our exploration of depthwise circuits reveal how LIMe integrates information across layers, pointing to promising directions for future research.</li>
</ul>

<h3>Title: The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics</h3>
<ul>
<li><strong>Authors: </strong>Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, Yunli Xing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09247">https://arxiv.org/abs/2502.09247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09247">https://arxiv.org/pdf/2502.09247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09247]] The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics(https://arxiv.org/abs/2502.09247)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Joint entity-relation extraction is a critical task in transforming unstructured or semi-structured text into triplets, facilitating the construction of large-scale knowledge graphs, and supporting various downstream applications. Despite its importance, research on Chinese text, particularly with complex semantics in specialized domains like medicine, remains limited. To address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions dataset designed to capture the intricacies of medical text. Leveraging the strengths of attention mechanisms in capturing long-range dependencies, we propose the SEA module, which enhances the extraction of complex contextual semantic information, thereby improving entity recognition and relation extraction. Additionally, to address the inefficiencies of existing methods in facilitating information exchange between entity recognition and relation extraction, we present an interactive fusion representation module. This module employs Cross Attention for bidirectional information exchange between the tasks and further refines feature extraction through BiLSTM. Experimental results on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that our model exhibits strong generalization capabilities. On the CH-DDI dataset, our model achieves an F1-score of 96.73% for entity recognition and 78.43% for relation extraction. On the CoNLL04 dataset, it attains an entity recognition precision of 89.54% and a relation extraction accuracy of 71.64%.</li>
</ul>

<h3>Title: Recipe: Hardware-Accelerated Replication Protocols</h3>
<ul>
<li><strong>Authors: </strong>Dimitra Giantsidi, Emmanouil Giortamis, Julian Pritzi, Maurice Bailleu, Manos Kapritsos, Pramod Bhatotia</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09251">https://arxiv.org/abs/2502.09251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09251">https://arxiv.org/pdf/2502.09251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09251]] Recipe: Hardware-Accelerated Replication Protocols(https://arxiv.org/abs/2502.09251)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Replication protocols are essential for distributed systems, ensuring consistency, reliability, and fault tolerance. Traditional Crash Fault Tolerant (CFT) protocols, which assume a fail-stop model, are inadequate for untrusted cloud environments where adversaries or software bugs can cause Byzantine behavior. Byzantine Fault Tolerant (BFT) protocols address these threats but face significant performance, resource overheads, and scalability challenges. This paper introduces Recipe, a novel approach to transforming CFT protocols to operate securely in Byzantine settings without altering their core logic. Recipe rethinks CFT protocols in the context of modern cloud hardware, including many-core servers, RDMA-capable networks, and Trusted Execution Environments (TEEs). The approach leverages these advancements to enhance the security and performance of replication protocols in untrusted cloud environments. Recipe implements two practical security mechanisms, i.e., transferable authentication and non-equivocation, using TEEs and high-performance networking stacks (e.g., RDMA, DPDK). These mechanisms ensure that any CFT protocol can be transformed into a BFT protocol, guaranteeing authenticity and non-equivocation. The Recipe protocol consists of five key components: transferable authentication, initialization, normal operation, view change, and recovery phases. The protocol's correctness is formally verified using Tamarin, a symbolic model checker. Recipe is implemented as a library and applied to transform four widely used CFT protocols-Raft, Chain Replication, ABD, and AllConcur-into Byzantine settings. The results demonstrate up to 24x higher throughput compared to PBFT and 5.9x better performance than state-of-the-art BFT protocols. Additionally, Recipe requires fewer replicas and offers confidentiality, a feature absent in traditional BFT protocols.</li>
</ul>

<h3>Title: DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images</h3>
<ul>
<li><strong>Authors: </strong>Zesheng Li, Minwen Liao, Haoran Chen, Yan Su, Chengchang Pan, Honggang Qi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09256">https://arxiv.org/abs/2502.09256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09256">https://arxiv.org/pdf/2502.09256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09256]] DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images(https://arxiv.org/abs/2502.09256)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The hemorrhagic lesion segmentation plays a critical role in ophthalmic diagnosis, directly influencing early disease detection, treatment planning, and therapeutic efficacy evaluation. However, the task faces significant challenges due to lesion morphological variability, indistinct boundaries, and low contrast with background tissues. To improve diagnostic accuracy and treatment outcomes, developing advanced segmentation techniques remains imperative. This paper proposes an adversarial learning-based dynamic architecture adjustment approach that integrates hierarchical U-shaped encoder-decoder, residual blocks, attention mechanisms, and ASPP modules. By dynamically optimizing feature fusion, our method enhances segmentation performance. Experimental results demonstrate a Dice coefficient of 0.6802, IoU of 0.5602, Recall of 0.766, Precision of 0.6525, and Accuracy of 0.9955, effectively addressing the challenges in fundus image hemorrhage segmentation.[* Corresponding author.]</li>
</ul>

<h3>Title: Unlocking the Potential of Classic GNNs for Graph-level Tasks: Simple Architectures Meet Excellence</h3>
<ul>
<li><strong>Authors: </strong>Yuankai Luo, Lei Shi, Xiao-Ming Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09263">https://arxiv.org/abs/2502.09263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09263">https://arxiv.org/pdf/2502.09263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09263]] Unlocking the Potential of Classic GNNs for Graph-level Tasks: Simple Architectures Meet Excellence(https://arxiv.org/abs/2502.09263)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Message-passing Graph Neural Networks (GNNs) are often criticized for their limited expressiveness, issues like over-smoothing and over-squashing, and challenges in capturing long-range dependencies, while Graph Transformers (GTs) are considered superior due to their global attention mechanisms. Literature frequently suggests that GTs outperform GNNs, particularly in graph-level tasks such as graph classification and regression. In this study, we explore the untapped potential of GNNs through an enhanced framework, GNN+, which integrates six widely used techniques: edge feature integration, normalization, dropout, residual connections, feed-forward networks, and positional encoding, to effectively tackle graph-level tasks. We conduct a systematic evaluation of three classic GNNs, namely GCN, GIN, and GatedGCN, enhanced by the GNN+ framework across 14 well-known graph-level datasets. Our results show that, contrary to the prevailing belief, classic GNNs excel in graph-level tasks, securing top three rankings across all datasets and achieving first place in eight, while also demonstrating greater efficiency than GTs. This highlights the potential of simple GNN architectures, challenging the belief that complex mechanisms in GTs are essential for superior graph-level performance.</li>
</ul>

<h3>Title: Memory-based Ensemble Learning in CMR Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Liu, Ziyi Wu, Liang Zhong, Linyi Wen, Yuankai Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09269">https://arxiv.org/abs/2502.09269</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09269">https://arxiv.org/pdf/2502.09269</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09269]] Memory-based Ensemble Learning in CMR Semantic Segmentation(https://arxiv.org/abs/2502.09269)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Existing models typically segment either the entire 3D frame or 2D slices independently to derive clinical functional metrics from ventricular segmentation in cardiac cine sequences. While performing well overall, they struggle at the end slices. To address this, we leverage spatial continuity to extract global uncertainty from segmentation variance and use it as memory in our ensemble learning method, Streaming, for classifier weighting, balancing overall and end-slice performance. Additionally, we introduce the End Coefficient (EC) to quantify end-slice accuracy. Experiments on ACDC and M\&Ms datasets show that our framework achieves near-state-of-the-art Dice Similarity Coefficient (DSC) and outperforms all models on end-slice performance, improving patient-specific segmentation accuracy.</li>
</ul>

<h3>Title: LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection</h3>
<ul>
<li><strong>Authors: </strong>Wenlun Zhang, Enyan Dai, Kentaro Yoshioka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09271">https://arxiv.org/abs/2502.09271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09271">https://arxiv.org/pdf/2502.09271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09271]] LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection(https://arxiv.org/abs/2502.09271)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in modeling data with graph structures, yet recent research reveals their susceptibility to adversarial attacks. Traditional attack methodologies, which rely on manipulating the original graph or adding links to artificially created nodes, often prove impractical in real-world settings. This paper introduces a novel adversarial scenario involving the injection of an isolated subgraph to deceive both the link recommender and the node classifier within a GNN system. Specifically, the link recommender is mislead to propose links between targeted victim nodes and the subgraph, encouraging users to unintentionally establish connections and that would degrade the node classification accuracy, thereby facilitating a successful attack. To address this, we present the LiSA framework, which employs a dual surrogate model and bi-level optimization to simultaneously meet two adversarial objectives. Extensive experiments on real-world datasets demonstrate the effectiveness of our method.</li>
</ul>

<h3>Title: FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Bin Yang, Alexandru Paul Condurache</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09274">https://arxiv.org/abs/2502.09274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09274">https://arxiv.org/pdf/2502.09274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09274]] FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation(https://arxiv.org/abs/2502.09274)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D scene understanding is a critical yet challenging task in autonomous driving, primarily due to the irregularity and sparsity of LiDAR data, as well as the computational demands of processing large-scale point clouds. Recent methods leverage the range-view representation to improve processing efficiency. To mitigate the performance drop caused by information loss inherent to the "many-to-one" problem, where multiple nearby 3D points are mapped to the same 2D grids and only the closest is retained, prior works tend to choose a higher azimuth resolution for range-view projection. However, this can bring the drawback of reducing the proportion of pixels that carry information and heavier computation within the network. We argue that it is not the optimal solution and show that, in contrast, decreasing the resolution is more advantageous in both efficiency and accuracy. In this work, we present a comprehensive re-design of the workflow for range-view-based LiDAR semantic segmentation. Our approach addresses data representation, augmentation, and post-processing methods for improvements. Through extensive experiments on two public datasets, we demonstrate that our pipeline significantly enhances the performance of various network architectures over their baselines, paving the way for more effective LiDAR-based perception in autonomous systems.</li>
</ul>

<h3>Title: ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization</h3>
<ul>
<li><strong>Authors: </strong>Onat Şahin, Mohammad Altillawi, George Eskandar, Carlos Carbone, Ziyuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09278">https://arxiv.org/abs/2502.09278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09278">https://arxiv.org/pdf/2502.09278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09278]] ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization(https://arxiv.org/abs/2502.09278)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion models have significantly improved 3D generation, enabling the use of assets generated from an image for embodied AI simulations. However, the one-to-many nature of the image-to-3D problem limits their use due to inconsistent content and quality across views. Previous models optimize a 3D model by sampling views from a view-conditioned diffusion prior, but diffusion models cannot guarantee view consistency. Instead, we present ConsistentDreamer, where we first generate a set of fixed multi-view prior images and sample random views between them with another diffusion model through a score distillation sampling (SDS) loss. Thereby, we limit the discrepancies between the views guided by the SDS loss and ensure a consistent rough shape. In each iteration, we also use our generated multi-view prior images for fine-detail reconstruction. To balance between the rough shape and the fine-detail optimizations, we introduce dynamic task-dependent weights based on homoscedastic uncertainty, updated automatically in each iteration. Additionally, we employ opacity, depth distortion, and normal alignment losses to refine the surface for mesh extraction. Our method ensures better view consistency and visual quality compared to the state-of-the-art.</li>
</ul>

<h3>Title: FE-LWS: Refined Image-Text Representations via Decoder Stacking and Fused Encodings for Remote Sensing Image Captioning</h3>
<ul>
<li><strong>Authors: </strong>Swadhin Das, Raksha Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09282">https://arxiv.org/abs/2502.09282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09282">https://arxiv.org/pdf/2502.09282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09282]] FE-LWS: Refined Image-Text Representations via Decoder Stacking and Fused Encodings for Remote Sensing Image Captioning(https://arxiv.org/abs/2502.09282)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Remote sensing image captioning aims to generate descriptive text from remote sensing images, typically employing an encoder-decoder framework. In this setup, a convolutional neural network (CNN) extracts feature representations from the input image, which then guide the decoder in a sequence-to-sequence caption generation process. Although much research has focused on refining the decoder, the quality of image representations from the encoder remains crucial for accurate captioning. This paper introduces a novel approach that integrates features from two distinct CNN based encoders, capturing complementary information to enhance caption generation. Additionally, we propose a weighted averaging technique to combine the outputs of all GRUs in the stacked decoder. Furthermore, a comparison-based beam search strategy is incorporated to refine caption selection. The results demonstrate that our fusion-based approach, along with the enhanced stacked decoder, significantly outperforms both the transformer-based state-of-the-art model and other LSTM-based baselines.</li>
</ul>

<h3>Title: SparQLe: Speech Queries to Text Translation Through LLMs</h3>
<ul>
<li><strong>Authors: </strong>Amirbek Djanibekov, Hanan Aldarmaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09284">https://arxiv.org/abs/2502.09284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09284">https://arxiv.org/pdf/2502.09284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09284]] SparQLe: Speech Queries to Text Translation Through LLMs(https://arxiv.org/abs/2502.09284)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the growing influence of Large Language Models (LLMs), there is increasing interest in integrating speech representations with them to enable more seamless multi-modal processing and speech understanding. This study introduces a novel approach that leverages self-supervised speech representations in combination with instruction-tuned LLMs for speech-to-text translation. The proposed approach leverages a modality adapter to align extracted speech features with instruction-tuned LLMs using English-language data. Our experiments demonstrate that this method effectively preserves the semantic content of the input speech and serves as an effective bridge between self-supervised speech models and instruction-tuned LLMs, offering a promising solution for various speech understanding applications.</li>
</ul>

<h3>Title: A Physics-Informed Deep Learning Model for MRI Brain Motion Correction</h3>
<ul>
<li><strong>Authors: </strong>Mojtaba Safari, Shansong Wang, Zach Eidex, Richard Qiu, Chih-Wei Chang, David S. Yu, Xiaofeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09296">https://arxiv.org/abs/2502.09296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09296">https://arxiv.org/pdf/2502.09296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09296]] A Physics-Informed Deep Learning Model for MRI Brain Motion Correction(https://arxiv.org/abs/2502.09296)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Background: MRI is crucial for brain imaging but is highly susceptible to motion artifacts due to long acquisition times. This study introduces PI-MoCoNet, a physics-informed motion correction network that integrates spatial and k-space information to remove motion artifacts without explicit motion parameter estimation, enhancing image fidelity and diagnostic reliability. Materials and Methods: PI-MoCoNet consists of a motion detection network (U-net with spatial averaging) to identify corrupted k-space lines and a motion correction network (U-net with Swin Transformer blocks) to reconstruct motion-free images. The correction is guided by three loss functions: reconstruction (L1), perceptual (LPIPS), and data consistency (Ldc). Motion artifacts were simulated via rigid phase encoding perturbations and evaluated on IXI and MR-ART datasets against Pix2Pix, CycleGAN, and U-net using PSNR, SSIM, and NMSE. Results: PI-MoCoNet significantly improved image quality. On IXI, for minor artifacts, PSNR increased from 34.15 dB to 45.95 dB, SSIM from 0.87 to 1.00, and NMSE reduced from 0.55% to 0.04%. For moderate artifacts, PSNR improved from 30.23 dB to 42.16 dB, SSIM from 0.80 to 0.99, and NMSE from 1.32% to 0.09%. For heavy artifacts, PSNR rose from 27.99 dB to 36.01 dB, SSIM from 0.75 to 0.97, and NMSE decreased from 2.21% to 0.36%. On MR-ART, PI-MoCoNet achieved PSNR gains of ~10 dB and SSIM improvements of up to 0.20, with NMSE reductions of ~6%. Ablation studies confirmed the importance of data consistency and perceptual losses, yielding a 1 dB PSNR gain and 0.17% NMSE reduction. Conclusions: PI-MoCoNet effectively mitigates motion artifacts in brain MRI, outperforming existing methods. Its ability to integrate spatial and k-space information makes it a promising tool for clinical use in motion-prone settings. Code: this https URL.</li>
</ul>

<h3>Title: When do neural networks learn world models?</h3>
<ul>
<li><strong>Authors: </strong>Tianren Zhang, Guanyu Chen, Feng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09297">https://arxiv.org/abs/2502.09297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09297">https://arxiv.org/pdf/2502.09297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09297]] When do neural networks learn world models?(https://arxiv.org/abs/2502.09297)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Humans develop world models that capture the underlying generation process of data. Whether neural networks can learn similar world models remains an open problem. In this work, we provide the first theoretical results for this problem, showing that in a multi-task setting, models with a low-degree bias provably recover latent data-generating variables under mild assumptions -- even if proxy tasks involve complex, non-linear functions of the latents. However, such recovery is also sensitive to model architecture. Our analysis leverages Boolean models of task solutions via the Fourier-Walsh transform and introduces new techniques for analyzing invertible Boolean transforms, which may be of independent interest. We illustrate the algorithmic implications of our results and connect them to related research areas, including self-supervised learning, out-of-distribution generalization, and the linear representation hypothesis in large language models.</li>
</ul>

<h3>Title: Convex Is Back: Solving Belief MDPs With Convexity-Informed Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Daniel Koutas, Daniel Hettegger, Kostas G. Papakonstantinou, Daniel Straub</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09298">https://arxiv.org/abs/2502.09298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09298">https://arxiv.org/pdf/2502.09298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09298]] Convex Is Back: Solving Belief MDPs With Convexity-Informed Deep Reinforcement Learning(https://arxiv.org/abs/2502.09298)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a novel method for Deep Reinforcement Learning (DRL), incorporating the convex property of the value function over the belief space in Partially Observable Markov Decision Processes (POMDPs). We introduce hard- and soft-enforced convexity as two different approaches, and compare their performance against standard DRL on two well-known POMDP environments, namely the Tiger and FieldVisionRockSample problems. Our findings show that including the convexity feature can substantially increase performance of the agents, as well as increase robustness over the hyperparameter space, especially when testing on out-of-distribution domains. The source code for this work can be found at this https URL.</li>
</ul>

<h3>Title: Towards Seamless Hierarchical Federated Learning under Intermittent Client Participation: A Stagewise Decision-Making Methodology</h3>
<ul>
<li><strong>Authors: </strong>Minghong Wu, Minghui Liwang, Yuhan Su, Li Li, Seyyedali Hosseinalipour, Xianbin Wang, Huaiyu Dai, Zhenzhen Jiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09303">https://arxiv.org/abs/2502.09303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09303">https://arxiv.org/pdf/2502.09303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09303]] Towards Seamless Hierarchical Federated Learning under Intermittent Client Participation: A Stagewise Decision-Making Methodology(https://arxiv.org/abs/2502.09303)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) offers a pioneering distributed learning paradigm that enables devices/clients to build a shared global model. This global model is obtained through frequent model transmissions between clients and a central server, which may cause high latency, energy consumption, and congestion over backhaul links. To overcome these drawbacks, Hierarchical Federated Learning (HFL) has emerged, which organizes clients into multiple clusters and utilizes edge nodes (e.g., edge servers) for intermediate model aggregations between clients and the central server. Current research on HFL mainly focus on enhancing model accuracy, latency, and energy consumption in scenarios with a stable/fixed set of clients. However, addressing the dynamic availability of clients -- a critical aspect of real-world scenarios -- remains underexplored. This study delves into optimizing client selection and client-to-edge associations in HFL under intermittent client participation so as to minimize overall system costs (i.e., delay and energy), while achieving fast model convergence. We unveil that achieving this goal involves solving a complex NP-hard problem. To tackle this, we propose a stagewise methodology that splits the solution into two stages, referred to as Plan A and Plan B. Plan A focuses on identifying long-term clients with high chance of participation in subsequent model training rounds. Plan B serves as a backup, selecting alternative clients when long-term clients are unavailable during model training rounds. This stagewise methodology offers a fresh perspective on client selection that can enhance both HFL and conventional FL via enabling low-overhead decision-making processes. Through evaluations on MNIST and CIFAR-10 datasets, we show that our methodology outperforms existing benchmarks in terms of model accuracy and system costs.</li>
</ul>

<h3>Title: When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models</h3>
<ul>
<li><strong>Authors: </strong>Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09307">https://arxiv.org/abs/2502.09307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09307">https://arxiv.org/pdf/2502.09307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09307]] When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models(https://arxiv.org/abs/2502.09307)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern Large Language Models (LLMs) have shown human-like abilities in many language tasks, sparking interest in comparing LLMs' and humans' language processing. In this paper, we conduct a detailed comparison of the two on a sentence comprehension task using garden-path constructions, which are notoriously challenging for humans. Based on psycholinguistic research, we formulate hypotheses on why garden-path sentences are hard, and test these hypotheses on human participants and a large suite of LLMs using comprehension questions. Our findings reveal that both LLMs and humans struggle with specific syntactic complexities, with some models showing high correlation with human comprehension. To complement our findings, we test LLM comprehension of garden-path constructions with paraphrasing and text-to-image generation tasks, and find that the results mirror the sentence comprehension question results, further validating our findings on LLM understanding of these constructions.</li>
</ul>

<h3>Title: A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis</h3>
<ul>
<li><strong>Authors: </strong>Kentaro Imajo, Masanori Hirano, Shuji Suzuki, Hiroaki Mikami</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09316">https://arxiv.org/abs/2502.09316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09316">https://arxiv.org/pdf/2502.09316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09316]] A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis(https://arxiv.org/abs/2502.09316)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating the open-ended text generation of large language models (LLMs) is challenging because of the lack of a clear ground truth and the high cost of human or LLM-based assessments. We propose a novel benchmark that evaluates LLMs using n-gram statistics and rules, without relying on human judgement or LLM-as-a-judge approaches. Using 50 question and reference answer sets, we introduce three new metrics based on n-grams and rules: Fluency, Truthfulness, and Helpfulness. Our benchmark strongly correlates with GPT-4o-based evaluations while requiring significantly fewer computational resources, demonstrating its effectiveness as a scalable alternative for assessing LLMs' open-ended generation capabilities.</li>
</ul>

<h3>Title: A Benchmark for Crime Surveillance Video Analysis with Large Models</h3>
<ul>
<li><strong>Authors: </strong>Haoran Chen, Dong Yi, Moyan Cao, Chensen Huang, Guibo Zhu, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09325">https://arxiv.org/abs/2502.09325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09325">https://arxiv.org/pdf/2502.09325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09325]] A Benchmark for Crime Surveillance Video Analysis with Large Models(https://arxiv.org/abs/2502.09325)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Anomaly analysis in surveillance videos is a crucial topic in computer vision. In recent years, multimodal large language models (MLLMs) have outperformed task-specific models in various domains. Although MLLMs are particularly versatile, their abilities to understand anomalous concepts and details are insufficiently studied because of the outdated benchmarks of this field not providing MLLM-style QAs and efficient algorithms to assess the model's open-ended text responses. To fill this gap, we propose a benchmark for crime surveillance video analysis with large models denoted as UCVL, including 1,829 videos and reorganized annotations from the UCF-Crime and UCF-Crime Annotation datasets. We design six types of questions and generate diverse QA pairs. Then we develop detailed instructions and use OpenAI's GPT-4o for accurate assessment. We benchmark eight prevailing MLLMs ranging from 0.5B to 40B parameters, and the results demonstrate the reliability of this bench. Moreover, we finetune LLaVA-OneVision on UCVL's training set. The improvement validates our data's high quality for video anomaly analysis.</li>
</ul>

<h3>Title: Beyond English: The Impact of Prompt Translation Strategies across Languages and Tasks in Multilingual LLMs</h3>
<ul>
<li><strong>Authors: </strong>Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09331">https://arxiv.org/abs/2502.09331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09331">https://arxiv.org/pdf/2502.09331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09331]] Beyond English: The Impact of Prompt Translation Strategies across Languages and Tasks in Multilingual LLMs(https://arxiv.org/abs/2502.09331)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite advances in the multilingual capabilities of Large Language Models (LLMs) across diverse tasks, English remains the dominant language for LLM research and development. So, when working with a different language, this has led to the widespread practice of pre-translation, i.e., translating the task prompt into English before inference. Selective pre-translation, a more surgical approach, focuses on translating specific prompt components. However, its current use is sporagic and lacks a systematic research foundation. Consequently, the optimal pre-translation strategy for various multilingual settings and tasks remains unclear. In this work, we aim to uncover the optimal setup for pre-translation by systematically assessing its use. Specifically, we view the prompt as a modular entity, composed of four functional parts: instruction, context, examples, and output, either of which could be translated or not. We evaluate pre-translation strategies across 35 languages covering both low and high-resource languages, on various tasks including Question Answering (QA), Natural Language Inference (NLI), Named Entity Recognition (NER), and Abstractive Summarization. Our experiments show the impact of factors as similarity to English, translation quality and the size of pre-trained data, on the model performance with pre-translation. We suggest practical guidelines for choosing optimal strategies in various multilingual settings.</li>
</ul>

<h3>Title: Graph Diffusion Network for Drug-Gene Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jiayang Wu, Wensheng Gan, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09335">https://arxiv.org/abs/2502.09335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09335">https://arxiv.org/pdf/2502.09335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09335]] Graph Diffusion Network for Drug-Gene Prediction(https://arxiv.org/abs/2502.09335)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Predicting drug-gene associations is crucial for drug development and disease treatment. While graph neural networks (GNN) have shown effectiveness in this task, they face challenges with data sparsity and efficient contrastive learning implementation. We introduce a graph diffusion network for drug-gene prediction (GDNDGP), a framework that addresses these limitations through two key innovations. First, it employs meta-path-based homogeneous graph learning to capture drug-drug and gene-gene relationships, ensuring similar entities share embedding spaces. Second, it incorporates a parallel diffusion network that generates hard negative samples during training, eliminating the need for exhaustive negative sample retrieval. Our model achieves superior performance on the DGIdb 4.0 dataset and demonstrates strong generalization capability on tripartite drug-gene-disease networks. Results show significant improvements over existing methods in drug-gene prediction tasks, particularly in handling complex heterogeneous relationships. The source code is publicly available at this https URL.</li>
</ul>

<h3>Title: This looks like what? Challenges and Future Research Directions for Part-Prototype Models</h3>
<ul>
<li><strong>Authors: </strong>Khawla Elhadri, Tomasz Michalski, Adam Wróbel, Jörg Schlötterer, Bartosz Zieliński, Christin Seifert</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09340">https://arxiv.org/abs/2502.09340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09340">https://arxiv.org/pdf/2502.09340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09340]] This looks like what? Challenges and Future Research Directions for Part-Prototype Models(https://arxiv.org/abs/2502.09340)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The growing interest in eXplainable Artificial Intelligence (XAI) has prompted research into models with built-in interpretability, the most prominent of which are part-prototype models. Part-Prototype Models (PPMs) make decisions by comparing an input image to a set of learned prototypes, providing human-understandable explanations in the form of ``this looks like that''. Despite their inherent interpretability, PPMS are not yet considered a valuable alternative to post-hoc models. In this survey, we investigate the reasons for this and provide directions for future research. We analyze papers from 2019 to 2024, and derive a taxonomy of the challenges that current PPMS face. Our analysis shows that the open challenges are quite diverse. The main concern is the quality and quantity of prototypes. Other concerns are the lack of generalization to a variety of tasks and contexts, and general methodological issues, including non-standardized evaluation. We provide ideas for future research in five broad directions: improving predictive performance, developing novel architectures grounded in theory, establishing frameworks for human-AI collaboration, aligning models with humans, and establishing metrics and benchmarks for evaluation. We hope that this survey will stimulate research and promote intrinsically interpretable models for application domains. Our list of surveyed papers is available at this https URL.</li>
</ul>

<h3>Title: Machine learning for modelling unstructured grid data in computational physics: a review</h3>
<ul>
<li><strong>Authors: </strong>Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, physics.data-an, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09346">https://arxiv.org/abs/2502.09346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09346">https://arxiv.org/pdf/2502.09346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09346]] Machine learning for modelling unstructured grid data in computational physics: a review(https://arxiv.org/abs/2502.09346)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Unstructured grid data are essential for modelling complex geometries and dynamics in computational physics. Yet, their inherent irregularity presents significant challenges for conventional machine learning (ML) techniques. This paper provides a comprehensive review of advanced ML methodologies designed to handle unstructured grid data in high-dimensional dynamical systems. Key approaches discussed include graph neural networks, transformer models with spatial attention mechanisms, interpolation-integrated ML methods, and meshless techniques such as physics-informed neural networks. These methodologies have proven effective across diverse fields, including fluid dynamics and environmental simulations. This review is intended as a guidebook for computational scientists seeking to apply ML approaches to unstructured grid data in their domains, as well as for ML researchers looking to address challenges in computational physics. It places special focus on how ML methods can overcome the inherent limitations of traditional numerical techniques and, conversely, how insights from computational physics can inform ML development. To support benchmarking, this review also provides a summary of open-access datasets of unstructured grid data in computational physics. Finally, emerging directions such as generative models with unstructured data, reinforcement learning for mesh generation, and hybrid physics-data-driven paradigms are discussed to inspire future advancements in this evolving field.</li>
</ul>

<h3>Title: Wasserstein distributional adversarial training for deep neural networks</h3>
<ul>
<li><strong>Authors: </strong>Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09352">https://arxiv.org/abs/2502.09352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09352">https://arxiv.org/pdf/2502.09352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09352]] Wasserstein distributional adversarial training for deep neural networks(https://arxiv.org/abs/2502.09352)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Design of adversarial attacks for deep neural networks, as well as methods of adversarial training against them, are subject of intense research. In this paper, we propose methods to train against distributional attack threats, extending the TRADES method used for pointwise attacks. Our approach leverages recent contributions and relies on sensitivity analysis for Wasserstein distributionally robust optimization problems. We introduce an efficient fine-tuning method which can be deployed on a previously trained model. We test our methods on a range of pre-trained models on RobustBench. These experimental results demonstrate the additional training enhances Wasserstein distributional robustness, while maintaining original levels of pointwise robustness, even for already very successful networks. The improvements are less marked for models pre-trained using huge synthetic datasets of 20-100M images. However, remarkably, sometimes our methods are still able to improve their performance even when trained using only the original training dataset (50k images).</li>
</ul>

<h3>Title: The Accuracy Cost of Weakness: A Theoretical Analysis of Fixed-Segment Weak Labeling for Events in Time</h3>
<ul>
<li><strong>Authors: </strong>John Martinsson, Olof Mogren, Tuomas Virtanen, Maria Sandsten</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09363">https://arxiv.org/abs/2502.09363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09363">https://arxiv.org/pdf/2502.09363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09363]] The Accuracy Cost of Weakness: A Theoretical Analysis of Fixed-Segment Weak Labeling for Events in Time(https://arxiv.org/abs/2502.09363)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate labels are critical for deriving robust machine learning models. Labels are used to train supervised learning models and to evaluate most machine learning paradigms. In this paper, we model the accuracy and cost of a common weak labeling process where annotators assign presence or absence labels to fixed-length data segments for a given event class. The annotator labels a segment as "present" if it sufficiently covers an event from that class, e.g., a birdsong sound event in audio data. We analyze how the segment length affects the label accuracy and the required number of annotations, and compare this fixed-length labeling approach with an oracle method that uses the true event activations to construct the segments. Furthermore, we quantify the gap between these methods and verify that in most realistic scenarios the oracle method is better than the fixed-length labeling method in both accuracy and cost. Our findings provide a theoretical justification for adaptive weak labeling strategies that mimic the oracle process, and a foundation for optimizing weak labeling processes in sequence labeling tasks.</li>
</ul>

<h3>Title: Simple Path Structural Encoding for Graph Transformers</h3>
<ul>
<li><strong>Authors: </strong>Louis Airale, Antonio Longa, Mattia Rigon, Andrea Passerini, Roberto Passerone</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09365">https://arxiv.org/abs/2502.09365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09365">https://arxiv.org/pdf/2502.09365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09365]] Simple Path Structural Encoding for Graph Transformers(https://arxiv.org/abs/2502.09365)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph transformers extend global self-attention to graph-structured data, achieving notable success in graph learning. Recently, random walk structural encoding (RWSE) has been found to further enhance their predictive power by encoding both structural and positional information into the edge representation. However, RWSE cannot always distinguish between edges that belong to different local graph patterns, which reduces its ability to capture the full structural complexity of graphs. This work introduces Simple Path Structural Encoding (SPSE), a novel method that utilizes simple path counts for edge encoding. We show theoretically and experimentally that SPSE overcomes the limitations of RWSE, providing a richer representation of graph structures, particularly for capturing local cyclic patterns. To make SPSE computationally tractable, we propose an efficient approximate algorithm for simple path counting. SPSE demonstrates significant performance improvements over RWSE on various benchmarks, including molecular and long-range graph datasets, achieving statistically significant gains in discriminative tasks. These results pose SPSE as a powerful edge encoding alternative for enhancing the expressivity of graph transformers.</li>
</ul>

<h3>Title: Language Agents as Digital Representatives in Collective Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Daniel Jarrett, Miruna Pîslar, Michiel A. Bakker, Michael Henry Tessler, Raphael Köster, Jan Balaguer, Romuald Elie, Christopher Summerfield, Andrea Tacchetti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09369">https://arxiv.org/abs/2502.09369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09369">https://arxiv.org/pdf/2502.09369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09369]] Language Agents as Digital Representatives in Collective Decision-Making(https://arxiv.org/abs/2502.09369)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Consider the process of collective decision-making, in which a group of individuals interactively select a preferred outcome from among a universe of alternatives. In this context, "representation" is the activity of making an individual's preferences present in the process via participation by a proxy agent -- i.e. their "representative". To this end, learned models of human behavior have the potential to fill this role, with practical implications for multi-agent scenario studies and mechanism design. In this work, we investigate the possibility of training \textit{language agents} to behave in the capacity of representatives of human agents, appropriately expressing the preferences of those individuals whom they stand for. First, we formalize the setting of \textit{collective decision-making} -- as the episodic process of interaction between a group of agents and a decision mechanism. On this basis, we then formalize the problem of \textit{digital representation} -- as the simulation of an agent's behavior to yield equivalent outcomes from the mechanism. Finally, we conduct an empirical case study in the setting of \textit{consensus-finding} among diverse humans, and demonstrate the feasibility of fine-tuning large language models to act as digital representatives.</li>
</ul>

<h3>Title: Mitigating multiple single-event upsets during deep neural network inference using fault-aware training</h3>
<ul>
<li><strong>Authors: </strong>Toon Vinck, Naïn Jonckers, Gert Dekkers, Jeffrey Prinzie, Peter Karsmakers</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09374">https://arxiv.org/abs/2502.09374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09374">https://arxiv.org/pdf/2502.09374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09374]] Mitigating multiple single-event upsets during deep neural network inference using fault-aware training(https://arxiv.org/abs/2502.09374)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) are increasingly used in safety-critical applications. Reliable fault analysis and mitigation are essential to ensure their functionality in harsh environments that contain high radiation levels. This study analyses the impact of multiple single-bit single-event upsets in DNNs by performing fault injection at the level of a DNN model. Additionally, a fault aware training (FAT) methodology is proposed that improves the DNNs' robustness to faults without any modification to the hardware. Experimental results show that the FAT methodology improves the tolerance to faults up to a factor 3.</li>
</ul>

<h3>Title: APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sidahmed Benabderrahmane, Petko Valtchev, James Cheney, Talal Rahwan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09385">https://arxiv.org/abs/2502.09385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09385">https://arxiv.org/pdf/2502.09385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09385]] APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models(https://arxiv.org/abs/2502.09385)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) pose a major cybersecurity challenge due to their stealth and ability to mimic normal system behavior, making detection particularly difficult in highly imbalanced datasets. Traditional anomaly detection methods struggle to effectively differentiate APT-related activities from benign processes, limiting their applicability in real-world scenarios. This paper introduces APT-LLM, a novel embedding-based anomaly detection framework that integrates large language models (LLMs) -- BERT, ALBERT, DistilBERT, and RoBERTa -- with autoencoder architectures to detect APTs. Unlike prior approaches, which rely on manually engineered features or conventional anomaly detection models, APT-LLM leverages LLMs to encode process-action provenance traces into semantically rich embeddings, capturing nuanced behavioral patterns. These embeddings are analyzed using three autoencoder architectures -- Baseline Autoencoder (AE), Variational Autoencoder (VAE), and Denoising Autoencoder (DAE) -- to model normal process behavior and identify anomalies. The best-performing model is selected for comparison against traditional methods. The framework is evaluated on real-world, highly imbalanced provenance trace datasets from the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004\% of the data across multiple operating systems (Android, Linux, BSD, and Windows) and attack scenarios. Results demonstrate that APT-LLM significantly improves detection performance under extreme imbalance conditions, outperforming existing anomaly detection methods and highlighting the effectiveness of LLM-based feature extraction in cybersecurity.</li>
</ul>

<h3>Title: Truth Knows No Language: Evaluating Truthfulness Beyond English</h3>
<ul>
<li><strong>Authors: </strong>Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria De Dios Flores, Rodrigo Agerri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09387">https://arxiv.org/abs/2502.09387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09387">https://arxiv.org/pdf/2502.09387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09387]] Truth Knows No Language: Evaluating Truthfulness Beyond English(https://arxiv.org/abs/2502.09387)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce a professionally translated extension of the TruthfulQA benchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and Spanish. Truthfulness evaluations of large language models (LLMs) have primarily been conducted in English. However, the ability of LLMs to maintain truthfulness across languages remains under-explored. Our study evaluates 12 state-of-the-art open LLMs, comparing base and instruction-tuned models using human evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our findings reveal that, while LLMs perform best in English and worst in Basque (the lowest-resourced language), overall truthfulness discrepancies across languages are smaller than anticipated. Furthermore, we show that LLM-as-a-Judge correlates more closely with human judgments than multiple-choice metrics, and that informativeness plays a critical role in truthfulness assessment. Our results also indicate that machine translation provides a viable approach for extending truthfulness benchmarks to additional languages, offering a scalable alternative to professional translation. Finally, we observe that universal knowledge questions are better handled across languages than context- and time-dependent ones, highlighting the need for truthfulness evaluations that account for cultural and temporal variability. Dataset and code are publicly available under open licenses.</li>
</ul>

<h3>Title: SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09390">https://arxiv.org/abs/2502.09390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09390">https://arxiv.org/pdf/2502.09390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09390]] SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models(https://arxiv.org/abs/2502.09390)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving field of Natural Language Processing, Large Language Models (LLMs) are tasked with increasingly complex reasoning challenges. Traditional methods like chain-of-thought prompting have shown promise but often fall short in fully leveraging a model's reasoning capabilities. This paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a novel prompting technique designed to improve reasoning through a self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts models to generate and resolve multiple auxiliary questions before tackling the main query, promoting a more thorough exploration of various aspects of a topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models across multiple question-answering datasets, demonstrate that SQuARE significantly surpasses traditional CoT prompts and existing rephrase-and-respond methods. By systematically decomposing queries, SQuARE advances LLM capabilities in reasoning tasks. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: A hierarchical approach for assessing the vulnerability of tree-based classification models to membership inference attack</h3>
<ul>
<li><strong>Authors: </strong>Richard J. Preen, Jim Smith</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09396">https://arxiv.org/abs/2502.09396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09396">https://arxiv.org/pdf/2502.09396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09396]] A hierarchical approach for assessing the vulnerability of tree-based classification models to membership inference attack(https://arxiv.org/abs/2502.09396)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Machine learning models can inadvertently expose confidential properties of their training data, making them vulnerable to membership inference attacks (MIA). While numerous evaluation methods exist, many require computationally expensive processes, such as training multiple shadow models. This article presents two new complementary approaches for efficiently identifying vulnerable tree-based models: an ante-hoc analysis of hyperparameter choices and a post-hoc examination of trained model structure. While these new methods cannot certify whether a model is safe from MIA, they provide practitioners with a means to significantly reduce the number of models that need to undergo expensive MIA assessment through a hierarchical filtering approach. More specifically, it is shown that the rank order of disclosure risk for different hyperparameter combinations remains consistent across datasets, enabling the development of simple, human-interpretable rules for identifying relatively high-risk models before training. While this ante-hoc analysis cannot determine absolute safety since this also depends on the specific dataset, it allows the elimination of unnecessarily risky configurations during hyperparameter tuning. Additionally, computationally inexpensive structural metrics serve as indicators of MIA vulnerability, providing a second filtering stage to identify risky models after training but before conducting expensive attacks. Empirical results show that hyperparameter-based risk prediction rules can achieve high accuracy in predicting the most at risk combinations of hyperparameters across different tree-based model types, while requiring no model training. Moreover, target model accuracy is not seen to correlate with privacy risk, suggesting opportunities to optimise model configurations for both performance and privacy.</li>
</ul>

<h3>Title: ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Rotem Shalev-Arkushin, Rinon Gal, Amit H. Bermano, Ohad Fried</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09411">https://arxiv.org/abs/2502.09411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09411">https://arxiv.org/pdf/2502.09411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09411]] ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation(https://arxiv.org/abs/2502.09411)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models enable high-quality and diverse visual content synthesis. However, they struggle to generate rare or unseen concepts. To address this challenge, we explore the usage of Retrieval-Augmented Generation (RAG) with image generation models. We propose ImageRAG, a method that dynamically retrieves relevant images based on a given text prompt, and uses them as context to guide the generation process. Prior approaches that used retrieved images to improve generation, trained models specifically for retrieval-based generation. In contrast, ImageRAG leverages the capabilities of existing image conditioning models, and does not require RAG-specific training. Our approach is highly adaptable and can be applied across different model types, showing significant improvement in generating rare and fine-grained concepts using different base models. Our project page is available at: this https URL</li>
</ul>

<h3>Title: A Survey of Reinforcement Learning for Optimization in Automation</h3>
<ul>
<li><strong>Authors: </strong>Ahmad Farooq, Kamran Iqbal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09417">https://arxiv.org/abs/2502.09417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09417">https://arxiv.org/pdf/2502.09417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09417]] A Survey of Reinforcement Learning for Optimization in Automation(https://arxiv.org/abs/2502.09417)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) has become a critical tool for optimization challenges within automation, leading to significant advancements in several areas. This review article examines the current landscape of RL within automation, with a particular focus on its roles in manufacturing, energy systems, and robotics. It discusses state-of-the-art methods, major challenges, and upcoming avenues of research within each sector, highlighting RL's capacity to solve intricate optimization challenges. The paper reviews the advantages and constraints of RL-driven optimization methods in automation. It points out prevalent challenges encountered in RL optimization, including issues related to sample efficiency and scalability; safety and robustness; interpretability and trustworthiness; transfer learning and meta-learning; and real-world deployment and integration. It further explores prospective strategies and future research pathways to navigate these challenges. Additionally, the survey includes a comprehensive list of relevant research papers, making it an indispensable guide for scholars and practitioners keen on exploring this domain.</li>
</ul>

<h3>Title: Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaoliu Guan, Yu Wu, Huayang Huang, Xiao Liu, Jiaxu Miao, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09434">https://arxiv.org/abs/2502.09434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09434">https://arxiv.org/pdf/2502.09434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09434]] Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models(https://arxiv.org/abs/2502.09434)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models, known for their tremendous ability to generate high-quality samples, have recently raised concerns due to their data memorization behavior, which poses privacy risks. Recent methods for memory mitigation have primarily addressed the issue within the context of the text modality in cross-modal generation tasks, restricting their applicability to specific conditions. In this paper, we propose a novel method for diffusion models from the perspective of visual modality, which is more generic and fundamental for mitigating memorization. Directly exposing visual data to the model increases memorization risk, so we design a framework where models learn through proxy model parameters instead. Specially, the training dataset is divided into multiple shards, with each shard training a proxy model, then aggregated to form the final model. Additionally, practical analysis of training losses illustrates that the losses for easily memorable images tend to be obviously lower. Thus, we skip the samples with abnormally low loss values from the current mini-batch to avoid memorizing. However, balancing the need to skip memorization-prone samples while maintaining sufficient training data for high-quality image generation presents a key challenge. Thus, we propose IET-AGC+, which redistributes highly memorizable samples between shards, to mitigate these samples from over-skipping. Furthermore, we dynamically augment samples based on their loss values to further reduce memorization. Extensive experiments and analysis on four datasets show that our method successfully reduces memory capacity while maintaining performance. Moreover, we fine-tune the pre-trained diffusion models, e.g., Stable Diffusion, and decrease the memorization score by 46.7\%, demonstrating the effectiveness of our method. Code is available in: this https URL.</li>
</ul>

<h3>Title: Pixel-Level Reasoning Segmentation via Multi-turn Conversations</h3>
<ul>
<li><strong>Authors: </strong>Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09447">https://arxiv.org/abs/2502.09447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09447">https://arxiv.org/pdf/2502.09447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09447]] Pixel-Level Reasoning Segmentation via Multi-turn Conversations(https://arxiv.org/abs/2502.09447)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Existing visual perception systems focus on region-level segmentation in single-turn dialogues, relying on complex and explicit query instructions. Such systems cannot reason at the pixel level and comprehend dynamic user intent that changes over interaction. Our work tackles this issue by introducing a novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on multi-turn conversations, tracking evolving user intent via multi-turn interactions for fine-grained segmentation. To establish a benchmark for this novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k multi-turn conversational scenarios with segmentation targets. Building on PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning Segmentation framework, integrates pixel-level segmentation with robust multi-turn conversation understanding, generating pixel-grounded explanations aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in pixel-level reasoning segmentation. Experimental results on the PRIST dataset demonstrate that our method outperforms current segmentation-specific baselines in terms of segmentation and LLM-based reasoning metrics. The code and data are available at: this https URL.</li>
</ul>

<h3>Title: Standardisation of Convex Ultrasound Data Through Geometric Analysis and Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Alistair Weld, Giovanni Faoro, Luke Dixon, Sophie Camp, Arianna Menciassi, Stamatia Giannarou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09482">https://arxiv.org/abs/2502.09482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09482">https://arxiv.org/pdf/2502.09482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09482]] Standardisation of Convex Ultrasound Data Through Geometric Analysis and Augmentation(https://arxiv.org/abs/2502.09482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>The application of ultrasound in healthcare has seen increased diversity and importance. Unlike other medical imaging modalities, ultrasound research and development has historically lagged, particularly in the case of applications with data-driven algorithms. A significant issue with ultrasound is the extreme variability of the images, due to the number of different machines available and the possible combination of parameter settings. One outcome of this is the lack of standardised and benchmarking ultrasound datasets. The method proposed in this article is an approach to alleviating this issue of disorganisation. For this purpose, the issue of ultrasound data sparsity is examined and a novel perspective, approach, and solution is proposed; involving the extraction of the underlying ultrasound plane within the image and representing it using annulus sector geometry. An application of this methodology is proposed, which is the extraction of scan lines and the linearisation of convex planes. Validation of the robustness of the proposed method is performed on both private and public data. The impact of deformation and the invertibility of augmentation using the estimated annulus sector parameters is also studied. Keywords: Ultrasound, Annulus Sector, Augmentation, Linearisation.</li>
</ul>

<h3>Title: PenTest++: Elevating Ethical Hacking with AI and Automation</h3>
<ul>
<li><strong>Authors: </strong>Haitham S. Al-Sinani, Chris J. Mitchell</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09484">https://arxiv.org/abs/2502.09484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09484">https://arxiv.org/pdf/2502.09484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09484]] PenTest++: Elevating Ethical Hacking with AI and Automation(https://arxiv.org/abs/2502.09484)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, generative</a></li>
<li><strong>Abstract: </strong>Traditional ethical hacking relies on skilled professionals and time-intensive command management, which limits its scalability and efficiency. To address these challenges, we introduce PenTest++, an AI-augmented system that integrates automation with generative AI (GenAI) to optimise ethical hacking workflows. Developed in a controlled virtual environment, PenTest++ streamlines critical penetration testing tasks, including reconnaissance, scanning, enumeration, exploitation, and documentation, while maintaining a modular and adaptable design. The system balances automation with human oversight, ensuring informed decision-making at key stages, and offers significant benefits such as enhanced efficiency, scalability, and adaptability. However, it also raises ethical considerations, including privacy concerns and the risks of AI-generated inaccuracies (hallucinations). This research underscores the potential of AI-driven systems like PenTest++ to complement human expertise in cybersecurity by automating routine tasks, enabling professionals to focus on strategic decision-making. By incorporating robust ethical safeguards and promoting ongoing refinement, PenTest++ demonstrates how AI can be responsibly harnessed to address operational and ethical challenges in the evolving cybersecurity landscape.</li>
</ul>

<h3>Title: Objective quantification of mood states using large language models</h3>
<ul>
<li><strong>Authors: </strong>Jakub Onysk, Quentin Huys</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09487">https://arxiv.org/abs/2502.09487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09487">https://arxiv.org/pdf/2502.09487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09487]] Objective quantification of mood states using large language models(https://arxiv.org/abs/2502.09487)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emotional states influence human behaviour and cognition, leading to diverse thought trajectories. Similarly, Large Language Models (LLMs) showcase an excellent level of response consistency across wide-ranging contexts (prompts). We leverage these parallels to establish a framework for quantifying mental states. Our approach utilises self-report questionnaires that reliably assess these states due to their inherent sensitivity to patterns of co-occurring responses. Specifically, we recruited a large sample of participants (N=422) to investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set of depressive mood states measured with participants' open-ended responses to a depression questionnaire. We show LLM responses to held-out multiple-choice questions, given participants' open-ended answers, correlate strongly (r: 0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation from mood representations. We explore a link between these representations and factor analysis. Using ridge regression, we find depression-related subspaces within LLM hidden states. We show these subspaces to be predictive of participants' "Depression" and "Somatic & Emotional Distress" factor scores, as well as suicidality severity. Overall, LLMs can provide quantitative measures of mental states. The reliability of these hinges upon how informative the questions we ask participants are. Used correctly, this approach could supplement mental state assessment in a variety of settings.</li>
</ul>

<h3>Title: Inverse Design with Dynamic Mode Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Yunpeng Zhu, Liangliang Cheng, Anping Jing, Hanyu Huo, Ziqiang Lang, Bo Zhang, J. Nathan Kutz</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY, math.DS, math.OC, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09490">https://arxiv.org/abs/2502.09490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09490">https://arxiv.org/pdf/2502.09490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09490]] Inverse Design with Dynamic Mode Decomposition(https://arxiv.org/abs/2502.09490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>We introduce a computationally efficient method for the automation of inverse design in science and engineering. Based on simple least-square regression, the underlying dynamic mode decomposition algorithm can be used to construct a low-rank subspace spanning multiple experiments in parameter space. The proposed inverse design dynamic mode composition (ID-DMD) algorithm leverages the computed low-dimensional subspace to enable fast digital design and optimization on laptop-level computing, including the potential to prescribe the dynamics themselves. Moreover, the method is robust to noise, physically interpretable, and can provide uncertainty quantification metrics. The architecture can also efficiently scale to large-scale design problems using randomized algorithms in the ID-DMD. The simplicity of the method and its implementation are highly attractive in practice, and the ID-DMD has been demonstrated to be an order of magnitude more accurate than competing methods while simultaneously being 3-5 orders faster on challenging engineering design problems ranging from structural vibrations to fluid dynamics. Due to its speed, robustness, interpretability, and ease-of-use, ID-DMD in comparison with other leading machine learning methods represents a significant advancement in data-driven methods for inverse design and optimization, promising a paradigm shift in how to approach inverse design in practice.</li>
</ul>

<h3>Title: Improve LLM-based Automatic Essay Scoring with Linguistic Features</h3>
<ul>
<li><strong>Authors: </strong>Zhaoyi Joey Hou, Alejandro Ciuba, Xiang Lorraine Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09497">https://arxiv.org/abs/2502.09497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09497">https://arxiv.org/pdf/2502.09497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09497]] Improve LLM-based Automatic Essay Scoring with Linguistic Features(https://arxiv.org/abs/2502.09497)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automatic Essay Scoring (AES) assigns scores to student essays, reducing the grading workload for instructors. Developing a scoring system capable of handling essays across diverse prompts is challenging due to the flexibility and diverse nature of the writing task. Existing methods typically fall into two categories: supervised feature-based approaches and large language model (LLM)-based methods. Supervised feature-based approaches often achieve higher performance but require resource-intensive training. In contrast, LLM-based methods are computationally efficient during inference but tend to suffer from lower performance. This paper combines these approaches by incorporating linguistic features into LLM-based scoring. Experimental results show that this hybrid method outperforms baseline models for both in-domain and out-of-domain writing prompts.</li>
</ul>

<h3>Title: AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization</h3>
<ul>
<li><strong>Authors: </strong>Caleb Cranney, Jesse G. Meyer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09503">https://arxiv.org/abs/2502.09503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09503">https://arxiv.org/pdf/2502.09503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09503]] AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization(https://arxiv.org/abs/2502.09503)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer architectures have transformed AI applications but remain complex to customize for domain experts lacking low-level implementation expertise. We introduce AttentionSmithy, a modular software package that simplifies transformer innovation by breaking down key components into reusable building blocks: attention modules, feed-forward networks, normalization layers, and positional encodings. Users can rapidly prototype and evaluate transformer variants without extensive coding. Our framework supports four positional encoding strategies and integrates with neural architecture search for automated design. We validate AttentionSmithy by replicating the original transformer under resource constraints and optimizing translation performance by combining positional encodings. Additionally, we demonstrate its adaptability in gene-specific modeling, achieving over 95% accuracy in cell type classification. These case studies highlight AttentionSmithy's potential to accelerate research across diverse fields by removing framework implementation barriers.</li>
</ul>

<h3>Title: EQ-VAE: Equivariance Regularized Latent Space for Improved Generative Image Modeling</h3>
<ul>
<li><strong>Authors: </strong>Theodoros Kouzelis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09509">https://arxiv.org/abs/2502.09509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09509">https://arxiv.org/pdf/2502.09509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09509]] EQ-VAE: Equivariance Regularized Latent Space for Improved Generative Image Modeling(https://arxiv.org/abs/2502.09509)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Latent generative models have emerged as a leading approach for high-quality image synthesis. These models rely on an autoencoder to compress images into a latent space, followed by a generative model to learn the latent distribution. We identify that existing autoencoders lack equivariance to semantic-preserving transformations like scaling and rotation, resulting in complex latent spaces that hinder generative performance. To address this, we propose EQ-VAE, a simple regularization approach that enforces equivariance in the latent space, reducing its complexity without degrading reconstruction quality. By finetuning pre-trained autoencoders with EQ-VAE, we enhance the performance of several state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT, achieving a 7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning. EQ-VAE is compatible with both continuous and discrete autoencoders, thus offering a versatile enhancement for a wide range of latent generative models. Project page and code: this https URL.</li>
</ul>

<h3>Title: Diffusion Models for Molecules: A Survey of Methods and Tasks</h3>
<ul>
<li><strong>Authors: </strong>Liang Wang, Chao Song, Zhiyuan Liu, Yu Rong, Qiang Liu, Shu Wu, Liang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09511">https://arxiv.org/abs/2502.09511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09511">https://arxiv.org/pdf/2502.09511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09511]] Diffusion Models for Molecules: A Survey of Methods and Tasks(https://arxiv.org/abs/2502.09511)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative tasks about molecules, including but not limited to molecule generation, are crucial for drug discovery and material design, and have consistently attracted significant attention. In recent years, diffusion models have emerged as an impressive class of deep generative models, sparking extensive research and leading to numerous studies on their application to molecular generative tasks. Despite the proliferation of related work, there remains a notable lack of up-to-date and systematic surveys in this area. Particularly, due to the diversity of diffusion model formulations, molecular data modalities, and generative task types, the research landscape is challenging to navigate, hindering understanding and limiting the area's growth. To address this, this paper conducts a comprehensive survey of diffusion model-based molecular generative methods. We systematically review the research from the perspectives of methodological formulations, data modalities, and task types, offering a novel taxonomy. This survey aims to facilitate understanding and further flourishing development in this area. The relevant papers are summarized at: this https URL.</li>
</ul>

<h3>Title: SQ-GAN: Semantic Image Communications Using Masked Vector Quantization</h3>
<ul>
<li><strong>Authors: </strong>Francesco Pezone, Sergio Barbarossa, Giuseppe Caire</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09520">https://arxiv.org/abs/2502.09520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09520">https://arxiv.org/pdf/2502.09520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09520]] SQ-GAN: Semantic Image Communications Using Masked Vector Quantization(https://arxiv.org/abs/2502.09520)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>This work introduces Semantically Masked VQ-GAN (SQ-GAN), a novel approach integrating generative models to optimize image compression for semantic/task-oriented communications. SQ-GAN employs off-the-shelf semantic semantic segmentation and a new specifically developed semantic-conditioned adaptive mask module (SAMM) to selectively encode semantically significant features of the images. SQ-GAN outperforms state-of-the-art image compression schemes such as JPEG2000 and BPG across multiple metrics, including perceptual quality and semantic segmentation accuracy on the post-decoding reconstructed image, at extreme low compression rates expressed in bits per pixel.</li>
</ul>

<h3>Title: Robust Learning of Multi-index Models via Iterative Subspace Approximation</h3>
<ul>
<li><strong>Authors: </strong>Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Nikos Zarifis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09525">https://arxiv.org/abs/2502.09525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09525">https://arxiv.org/pdf/2502.09525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09525]] Robust Learning of Multi-index Models via Iterative Subspace Approximation(https://arxiv.org/abs/2502.09525)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the task of learning Multi-Index Models (MIMs) with label noise under the Gaussian distribution. A $K$-MIM is any function $f$ that only depends on a $K$-dimensional subspace. We focus on well-behaved MIMs with finite ranges that satisfy certain regularity properties. Our main contribution is a general robust learner that is qualitatively optimal in the Statistical Query (SQ) model. Our algorithm iteratively constructs better approximations to the defining subspace by computing low-degree moments conditional on the projection to the subspace computed thus far, and adding directions with relatively large empirical moments. This procedure efficiently finds a subspace $V$ so that $f(\mathbf{x})$ is close to a function of the projection of $\mathbf{x}$ onto $V$. Conversely, for functions for which these conditional moments do not help, we prove an SQ lower bound suggesting that no efficient learner exists. As applications, we provide faster robust learners for the following concept classes: * {\bf Multiclass Linear Classifiers} We give a constant-factor approximate agnostic learner with sample complexity $N = O(d) 2^{\mathrm{poly}(K/\epsilon)}$ and computational complexity $\mathrm{poly}(N ,d)$. This is the first constant-factor agnostic learner for this class whose complexity is a fixed-degree polynomial in $d$. * {\bf Intersections of Halfspaces} We give an approximate agnostic learner for this class achieving 0-1 error $K \tilde{O}(\mathrm{OPT}) + \epsilon$ with sample complexity $N=O(d^2) 2^{\mathrm{poly}(K/\epsilon)}$ and computational complexity $\mathrm{poly}(N ,d)$. This is the first agnostic learner for this class with near-linear error dependence and complexity a fixed-degree polynomial in $d$. Furthermore, we show that in the presence of random classification noise, the complexity of our algorithm scales polynomially with $1/\epsilon$.</li>
</ul>

<h3>Title: Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages</h3>
<ul>
<li><strong>Authors: </strong>Shreyan Biswas, Alexander Erlei, Ujwal Gadiraju</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09532">https://arxiv.org/abs/2502.09532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09532">https://arxiv.org/pdf/2502.09532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09532]] Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages(https://arxiv.org/abs/2502.09532)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in generative AI have precipitated a proliferation of novel writing assistants. These systems typically rely on multilingual large language models (LLMs), providing globalized workers the ability to revise or create diverse forms of content in different languages. However, there is substantial evidence indicating that the performance of multilingual LLMs varies between languages. Users who employ writing assistance for multiple languages are therefore susceptible to disparate output quality. Importantly, recent research has shown that people tend to generalize algorithmic errors across independent tasks, violating the behavioral axiom of choice independence. In this paper, we analyze whether user utilization of novel writing assistants in a charity advertisement writing task is affected by the AI's performance in a second language. Furthermore, we quantify the extent to which these patterns translate into the persuasiveness of generated charity advertisements, as well as the role of peoples' beliefs about LLM utilization in their donation choices. Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM. While these patterns do not affect the aggregate persuasiveness of the generated advertisements, people's beliefs about the source of an advertisement (human versus AI) do. In particular, Spanish-speaking female participants who believed that they read an AI-generated advertisement strongly adjusted their donation behavior downwards. Furthermore, people are generally not able to adequately differentiate between human-generated and LLM-generated ads. Our work has important implications for the design, development, integration, and adoption of multilingual LLMs as assistive agents -- particularly in writing tasks.</li>
</ul>

<h3>Title: Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Fei Shen, Cong Wang, Junyao Gao, Qin Guo, Jisheng Dang, Jinhui Tang, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09533">https://arxiv.org/abs/2502.09533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09533">https://arxiv.org/pdf/2502.09533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09533]] Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model(https://arxiv.org/abs/2502.09533)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in conditional diffusion models have shown promise for generating realistic TalkingFace videos, yet challenges persist in achieving consistent head movement, synchronized facial expressions, and accurate lip synchronization over extended generations. To address these, we introduce the \textbf{M}otion-priors \textbf{C}onditional \textbf{D}iffusion \textbf{M}odel (\textbf{MCDM}), which utilizes both archived and current clip motion priors to enhance motion prediction and ensure temporal consistency. The model consists of three key elements: (1) an archived-clip motion-prior that incorporates historical frames and a reference frame to preserve identity and context; (2) a present-clip motion-prior diffusion model that captures multimodal causality for accurate predictions of head movements, lip sync, and expressions; and (3) a memory-efficient temporal attention mechanism that mitigates error accumulation by dynamically storing and updating motion features. We also release the \textbf{TalkingFace-Wild} dataset, a multilingual collection of over 200 hours of footage across 10 languages. Experimental results demonstrate the effectiveness of MCDM in maintaining identity and motion continuity for long-term TalkingFace generation. Code, models, and datasets will be publicly available.</li>
</ul>

<h3>Title: Entropy Collapse in Mobile Sensors: The Hidden Risks of Sensor-Based Security</h3>
<ul>
<li><strong>Authors: </strong>Carlton Shepherd, Elliot Hurley</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09535">https://arxiv.org/abs/2502.09535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09535">https://arxiv.org/pdf/2502.09535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09535]] Entropy Collapse in Mobile Sensors: The Hidden Risks of Sensor-Based Security(https://arxiv.org/abs/2502.09535)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Mobile sensor data has been proposed for security-critical applications such as device pairing, proximity detection, and continuous authentication. However, the foundational assumption that these signals provide sufficient entropy remains under-explored. In this work, we systematically analyse the entropy of smartphone sensor data across four diverse datasets spanning multiple application contexts. Our findings reveal pervasive biases, with single-sensor mean min-entropy values ranging from 3.408-3.508 bits (S.D.=1.018-1.574), while conventional Shannon entropy is several multiples higher. We further demonstrate that correlations between sensor modalities reduce the worst-case entropy of using multiple sensors by up to approx. 75% compared to average-case Shannon entropy. This brings joint min-entropy well below 10 bits in many cases and, in the best case, yielding only approx. 24 bits of min-entropy when combining 20 sensor modalities. These results call into question the widely held assumption that adding more sensors inherently yields higher security. We ultimately caution against relying on raw sensor data as a primary source of randomness.</li>
</ul>

<h3>Title: Registration, Detection, and Deregistration: Analyzing DNS Abuse for Phishing Attacks</h3>
<ul>
<li><strong>Authors: </strong>Kyungchan Lim, Kiho Lee, Raffaele Sommese, Mattis Jonker, Ricky Mok, kc claffy, Doowon Kim</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09549">https://arxiv.org/abs/2502.09549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09549">https://arxiv.org/pdf/2502.09549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09549]] Registration, Detection, and Deregistration: Analyzing DNS Abuse for Phishing Attacks(https://arxiv.org/abs/2502.09549)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Phishing continues to pose a significant cybersecurity threat. While blocklists currently serve as a primary defense, due to their reactive, passive nature, these delayed responses leave phishing websites operational long enough to harm potential victims. It is essential to address this fundamental challenge at the root, particularly in phishing domains. Domain registration presents a crucial intervention point, as domains serve as the primary gateway between users and websites. We conduct a comprehensive longitudinal analysis of 690,502 unique phishing domains, spanning a 39 month period, to examine their characteristics and behavioral patterns throughout their lifecycle-from initial registration to detection and eventual deregistration. We find that 66.1% of the domains in our dataset are maliciously registered, leveraging cost-effective TLDs and targeting brands by mimicking their domain names under alternative TLDs (e.g., .top and .tk) instead of the TLDs under which the brand domains are registered (e.g., .com and .ru). We also observe minimal improvements in detection speed for maliciously registered domains compared to compromised domains. Detection times vary widely across blocklists, and phishing domains remain accessible for an average of 11.5 days after detection, prolonging their potential impact. Our systematic investigation uncovers key patterns from registration through detection to deregistration, which could be leveraged to enhance anti-phishing active defenses at the DNS level.</li>
</ul>

<h3>Title: SyntheticPop: Attacking Speaker Verification Systems With Synthetic VoicePops</h3>
<ul>
<li><strong>Authors: </strong>Eshaq Jamdar, Amith Kamath Belman</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09553">https://arxiv.org/abs/2502.09553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09553">https://arxiv.org/pdf/2502.09553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09553]] SyntheticPop: Attacking Speaker Verification Systems With Synthetic VoicePops(https://arxiv.org/abs/2502.09553)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Voice Authentication (VA), also known as Automatic Speaker Verification (ASV), is a widely adopted authentication method, particularly in automated systems like banking services, where it serves as a secondary layer of user authentication. Despite its popularity, VA systems are vulnerable to various attacks, including replay, impersonation, and the emerging threat of deepfake audio that mimics the voice of legitimate users. To mitigate these risks, several defense mechanisms have been proposed. One such solution, Voice Pops, aims to distinguish an individual's unique phoneme pronunciations during the enrollment process. While promising, the effectiveness of VA+VoicePop against a broader range of attacks, particularly logical or adversarial attacks, remains insufficiently explored. We propose a novel attack method, which we refer to as SyntheticPop, designed to target the phoneme recognition capabilities of the VA+VoicePop system. The SyntheticPop attack involves embedding synthetic "pop" noises into spoofed audio samples, significantly degrading the model's performance. We achieve an attack success rate of over 95% while poisoning 20% of the training dataset. Our experiments demonstrate that VA+VoicePop achieves 69% accuracy under normal conditions, 37% accuracy when subjected to a baseline label flipping attack, and just 14% accuracy under our proposed SyntheticPop attack, emphasizing the effectiveness of our method.</li>
</ul>

<h3>Title: Diffusing DeBias: a Recipe for Turning a Bug into a Feature</h3>
<ul>
<li><strong>Authors: </strong>Massimiliano Ciranni, Vito Paolo Pastore, Roberto Di Via, Enzo Tartaglione, Francesca Odone, Vittorio Murino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09564">https://arxiv.org/abs/2502.09564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09564">https://arxiv.org/pdf/2502.09564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09564]] Diffusing DeBias: a Recipe for Turning a Bug into a Feature(https://arxiv.org/abs/2502.09564)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data which, whenever containing strong spurious correlations between specific attributes and target labels, can result in unrecoverable biases in model predictions. Tackling these biases is crucial in improving model generalization and trust, especially in real-world scenarios. This paper presents Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods in model debiasing while exploiting the inherent bias-learning tendency of diffusion models. Our approach leverages conditional diffusion models to generate synthetic bias-aligned images, used to train a bias amplifier model, to be further employed as an auxiliary method in different unsupervised debiasing approaches. Our proposed method, which also tackles the common issue of training set memorization typical of this type of tech- niques, beats current state-of-the-art in multiple benchmark datasets by significant margins, demonstrating its potential as a versatile and effective tool for tackling dataset bias in deep learning applications.</li>
</ul>

<h3>Title: Zero-shot generation of synthetic neurosurgical data with large language models</h3>
<ul>
<li><strong>Authors: </strong>Austin A. Barr, Eddie Guo, Emre Sezgin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09566">https://arxiv.org/abs/2502.09566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09566">https://arxiv.org/pdf/2502.09566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09566]] Zero-shot generation of synthetic neurosurgical data with large language models(https://arxiv.org/abs/2502.09566)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative, large language model</a></li>
<li><strong>Abstract: </strong>Clinical data is fundamental to advance neurosurgical research, but access is often constrained by data availability, small sample sizes, privacy regulations, and resource-intensive preprocessing and de-identification procedures. Synthetic data offers a potential solution to challenges associated with accessing and using real-world data (RWD). This study aims to evaluate the capability of zero-shot generation of synthetic neurosurgical data with a large language model (LLM), GPT-4o, by benchmarking with the conditional tabular generative adversarial network (CTGAN). Synthetic datasets were compared to real-world neurosurgical data to assess fidelity (means, proportions, distributions, and bivariate correlations), utility (ML classifier performance on RWD), and privacy (duplication of records from RWD). The GPT-4o-generated datasets matched or exceeded CTGAN performance, despite no fine-tuning or access to RWD for pre-training. Datasets demonstrated high univariate and bivariate fidelity to RWD without directly exposing any real patient records, even at amplified sample size. Training an ML classifier on GPT-4o-generated data and testing on RWD for a binary prediction task showed an F1 score (0.706) with comparable performance to training on the CTGAN data (0.705) for predicting postoperative functional status deterioration. GPT-4o demonstrated a promising ability to generate high-fidelity synthetic neurosurgical data. These findings also indicate that data synthesized with GPT-4o can effectively augment clinical data with small sample sizes, and train ML models for prediction of neurosurgical outcomes. Further investigation is necessary to improve the preservation of distributional characteristics and boost classifier performance.</li>
</ul>

<h3>Title: DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra</h3>
<ul>
<li><strong>Authors: </strong>Montgomery Bohde, Mrunali Manjrekar, Runzhong Wang, Shuiwang Ji, Connor W. Coley</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09571">https://arxiv.org/abs/2502.09571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09571">https://arxiv.org/pdf/2502.09571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09571]] DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra(https://arxiv.org/abs/2502.09571)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Mass spectrometry plays a fundamental role in elucidating the structures of unknown molecules and subsequent scientific discoveries. One formulation of the structure elucidation task is the conditional $\textit{de novo}$ generation of molecular structure given a mass spectrum. Toward a more accurate and efficient scientific discovery pipeline for small molecules, we present DiffMS, a formula-restricted encoder-decoder generative network that achieves state-of-the-art performance on this task. The encoder utilizes a transformer architecture and models mass spectra domain knowledge such as peak formulae and neutral losses, and the decoder is a discrete graph diffusion model restricted by the heavy-atom composition of a known chemical formula. To develop a robust decoder that bridges latent embeddings and molecular structures, we pretrain the diffusion decoder with fingerprint-structure pairs, which are available in virtually infinite quantities, compared to structure-spectrum pairs that number in the tens of thousands. Extensive experiments on established benchmarks show that DiffMS outperforms existing models on $\textit{de novo}$ molecule generation. We provide several ablations to demonstrate the effectiveness of our diffusion and pretraining approaches and show consistent performance scaling with increasing pretraining dataset size. DiffMS code is publicly available at this https URL.</li>
</ul>

<h3>Title: Rolling Ahead Diffusion for Traffic Scene Simulation</h3>
<ul>
<li><strong>Authors: </strong>Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09587">https://arxiv.org/abs/2502.09587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09587">https://arxiv.org/pdf/2502.09587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09587]] Rolling Ahead Diffusion for Traffic Scene Simulation(https://arxiv.org/abs/2502.09587)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Realistic driving simulation requires that NPCs not only mimic natural driving behaviors but also react to the behavior of other simulated agents. Recent developments in diffusion-based scenario generation focus on creating diverse and realistic traffic scenarios by jointly modelling the motion of all the agents in the scene. However, these traffic scenarios do not react when the motion of agents deviates from their modelled trajectories. For example, the ego-agent can be controlled by a stand along motion planner. To produce reactive scenarios with joint scenario models, the model must regenerate the scenario at each timestep based on new observations in a Model Predictive Control (MPC) fashion. Although reactive, this method is time-consuming, as one complete possible future for all NPCs is generated per simulation step. Alternatively, one can utilize an autoregressive model (AR) to predict only the immediate next-step future for all NPCs. Although faster, this method lacks the capability for advanced planning. We present a rolling diffusion based traffic scene generation model which mixes the benefits of both methods by predicting the next step future and simultaneously predicting partially noised further future steps at the same time. We show that such model is efficient compared to diffusion model based AR, achieving a beneficial compromise between reactivity and computational efficiency.</li>
</ul>

<h3>Title: Logical forms complement probability in understanding language model (and human) performance</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Wang, Freda Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09589">https://arxiv.org/abs/2502.09589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09589">https://arxiv.org/pdf/2502.09589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09589]] Logical forms complement probability in understanding language model (and human) performance(https://arxiv.org/abs/2502.09589)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question. This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in natural language. We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance. Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical forms should be considered as orthogonal factors. In addition, we show similarities and differences between the logical reasoning performances of humans and LLMs by comparing LLM and human behavioral results.</li>
</ul>

<h3>Title: Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, Kaixiang Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09597">https://arxiv.org/abs/2502.09597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09597">https://arxiv.org/pdf/2502.09597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09597]] Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs(https://arxiv.org/abs/2502.09597)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used as chatbots, yet their ability to personalize responses to user preferences remains limited. We introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize and adhere to user preferences in a long-context conversational setting. PrefEval comprises 3,000 manually curated user preference and query pairs spanning 20 topics. PrefEval contains user personalization or preference information in both explicit and implicit forms, and evaluates LLM performance using a generation and a classification task. With PrefEval, we evaluated the aforementioned preference following capabilities of 10 open-source and proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting, iterative feedback, and retrieval-augmented generation methods. Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in proactively following users' preferences during conversations. In particular, in zero-shot settings, preference following accuracy falls below 10% at merely 10 turns (~3k tokens) across most evaluated models. Even with advanced prompting and retrieval methods, preference following still deteriorates in long-context conversations. Furthermore, we show that fine-tuning on PrefEval significantly improves performance. We believe PrefEval serves as a valuable resource for measuring, understanding, and enhancing LLMs' preference following abilities, paving the way for personalized conversational agents. Our code and dataset are available at this https URL.</li>
</ul>

<h3>Title: SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09604">https://arxiv.org/abs/2502.09604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09604">https://arxiv.org/pdf/2502.09604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09604]] SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models(https://arxiv.org/abs/2502.09604)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks.</li>
</ul>

<h3>Title: Human-LLM Coevolution: Evidence from Academic Writing</h3>
<ul>
<li><strong>Authors: </strong>Mingmeng Geng, Roberto Trotta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.DL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09606">https://arxiv.org/abs/2502.09606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09606">https://arxiv.org/pdf/2502.09606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09606]] Human-LLM Coevolution: Evidence from Academic Writing(https://arxiv.org/abs/2502.09606)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With a statistical analysis of arXiv paper abstracts, we report a marked drop in the frequency of several words previously identified as overused by ChatGPT, such as "delve", starting soon after they were pointed out in early 2024. The frequency of certain other words favored by ChatGPT, such as "significant", has instead kept increasing. These phenomena suggest that some authors of academic papers have adapted their use of large language models (LLMs), for example, by selecting outputs or applying modifications to the LLM-generated content. Such coevolution and cooperation of humans and LLMs thus introduce additional challenges to the detection of machine-generated text in real-world scenarios. Estimating the impact of LLMs on academic writing by examining word frequency remains feasible, and more attention should be paid to words that were already frequently employed, including those that have decreased in frequency.</li>
</ul>

<h3>Title: Instance Segmentation of Scene Sketches Using Natural Image Priors</h3>
<ul>
<li><strong>Authors: </strong>Mia Tang, Yael Vinker, Chuan Yan, Lvmin Zhang, Maneesh Agrawala</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09608">https://arxiv.org/abs/2502.09608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09608">https://arxiv.org/pdf/2502.09608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09608]] Instance Segmentation of Scene Sketches Using Natural Image Priors(https://arxiv.org/abs/2502.09608)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Sketch segmentation involves grouping pixels within a sketch that belong to the same object or instance. It serves as a valuable tool for sketch editing tasks, such as moving, scaling, or removing specific components. While image segmentation models have demonstrated remarkable capabilities in recent years, sketches present unique challenges for these models due to their sparse nature and wide variation in styles. We introduce SketchSeg, a method for instance segmentation of raster scene sketches. Our approach adapts state-of-the-art image segmentation and object detection models to the sketch domain by employing class-agnostic fine-tuning and refining segmentation masks using depth cues. Furthermore, our method organizes sketches into sorted layers, where occluded instances are inpainted, enabling advanced sketch editing applications. As existing datasets in this domain lack variation in sketch styles, we construct a synthetic scene sketch segmentation dataset featuring sketches with diverse brush strokes and varying levels of detail. We use this dataset to demonstrate the robustness of our approach and will release it to promote further research in the field. Project webpage: this https URL</li>
</ul>

<h3>Title: Score-of-Mixture Training: Training One-Step Generative Models Made Simple</h3>
<ul>
<li><strong>Authors: </strong>Tejas Jayashankar, J. Jon Ryu, Gregory Wornell</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09609">https://arxiv.org/abs/2502.09609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09609">https://arxiv.org/pdf/2502.09609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09609]] Score-of-Mixture Training: Training One-Step Generative Models Made Simple(https://arxiv.org/abs/2502.09609)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the $\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels. Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD). It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods.</li>
</ul>

<h3>Title: Designing a Conditional Prior Distribution for Flow-Based Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Noam Issachar, Mohammad Salama, Raanan Fattal, Sagie Benaim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09611">https://arxiv.org/abs/2502.09611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09611">https://arxiv.org/pdf/2502.09611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09611]] Designing a Conditional Prior Distribution for Flow-Based Generative Models(https://arxiv.org/abs/2502.09611)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Flow-based generative models have recently shown impressive performance for conditional generation tasks, such as text-to-image generation. However, current methods transform a general unimodal noise distribution to a specific mode of the target data distribution. As such, every point in the initial source distribution can be mapped to every point in the target distribution, resulting in long average paths. To this end, in this work, we tap into a non-utilized property of conditional flow-based models: the ability to design a non-trivial prior distribution. Given an input condition, such as a text prompt, we first map it to a point lying in data space, representing an ``average" data point with the minimal average distance to all data points of the same conditional mode (e.g., class). We then utilize the flow matching formulation to map samples from a parametric distribution centered around this point to the conditional target distribution. Experimentally, our method significantly improves training times and generation efficiency (FID, KID and CLIP alignment scores) compared to baselines, producing high quality samples using fewer sampling steps.</li>
</ul>

<h3>Title: RigAnything: Template-Free Autoregressive Rigging for Diverse 3D Assets</h3>
<ul>
<li><strong>Authors: </strong>Isabella Liu, Zhan Xu, Wang Yifan, Hao Tan, Zexiang Xu, Xiaolong Wang, Hao Su, Zifan Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09615">https://arxiv.org/abs/2502.09615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09615">https://arxiv.org/pdf/2502.09615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09615]] RigAnything: Template-Free Autoregressive Rigging for Diverse 3D Assets(https://arxiv.org/abs/2502.09615)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We present RigAnything, a novel autoregressive transformer-based model, which makes 3D assets rig-ready by probabilistically generating joints, skeleton topologies, and assigning skinning weights in a template-free manner. Unlike most existing auto-rigging methods, which rely on predefined skeleton template and are limited to specific categories like humanoid, RigAnything approaches the rigging problem in an autoregressive manner, iteratively predicting the next joint based on the global input shape and the previous prediction. While autoregressive models are typically used to generate sequential data, RigAnything extends their application to effectively learn and represent skeletons, which are inherently tree structures. To achieve this, we organize the joints in a breadth-first search (BFS) order, enabling the skeleton to be defined as a sequence of 3D locations and the parent index. Furthermore, our model improves the accuracy of position prediction by leveraging diffusion modeling, ensuring precise and consistent placement of joints within the hierarchy. This formulation allows the autoregressive model to efficiently capture both spatial and hierarchical relationships within the skeleton. Trained end-to-end on both RigNet and Objaverse datasets, RigAnything demonstrates state-of-the-art performance across diverse object types, including humanoids, quadrupeds, marine creatures, insects, and many more, surpassing prior methods in quality, robustness, generalizability, and efficiency. Please check our website for more details: this https URL.</li>
</ul>

<h3>Title: Exploring the Potential of Encoder-free Architectures in 3D LMMs</h3>
<ul>
<li><strong>Authors: </strong>Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09620">https://arxiv.org/abs/2502.09620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09620">https://arxiv.org/pdf/2502.09620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09620]] Exploring the Potential of Encoder-free Architectures in 3D LMMs(https://arxiv.org/abs/2502.09620)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Encoder-free architectures have been preliminarily explored in the 2D visual domain, yet it remains an open question whether they can be effectively applied to 3D understanding scenarios. In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs). These challenges include the failure to adapt to varying point cloud resolutions and the point features from the encoder not meeting the semantic needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to remove the encoder and enable the LLM to assume the role of the 3D encoder: 1) We propose the LLM-embedded Semantic Encoding strategy in the pre-training stage, exploring the effects of various point cloud self-supervised losses. And we present the Hybrid Semantic Loss to extract high-level semantics. 2) We introduce the Hierarchical Geometry Aggregation strategy in the instruction tuning stage. This incorporates inductive bias into the LLM early layers to focus on the local details of the point clouds. To the end, we present the first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the classification, captioning, and VQA tasks, respectively. Our results demonstrate that the encoder-free architecture is highly promising for replacing encoder-based architectures in the field of 3D understanding. The code is released at this https URL</li>
</ul>

<h3>Title: MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09621">https://arxiv.org/abs/2502.09621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09621">https://arxiv.org/pdf/2502.09621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09621]] MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency(https://arxiv.org/abs/2502.09621)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Answering questions with Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), yet its impact on Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth investigation. In this paper, we introduce MME-CoT, a specialized benchmark evaluating the CoT reasoning performance of LMMs, spanning six domains: math, science, OCR, logic, space-time, and general scenes. As the first comprehensive study in this area, we propose a thorough evaluation suite incorporating three novel metrics that assess the reasoning quality, robustness, and efficiency at a fine-grained level. Leveraging curated high-quality data and a unique evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs, uncovering several key insights: 1) Models with reflection mechanism demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and demonstrating the highest quality results; 2) CoT prompting often degrades LMM performance on perception-heavy tasks, suggesting a potentially harmful overthinking behavior; and 3) Although the CoT quality is high, LMMs with reflection exhibit significant inefficiency in both normal response and self-correction phases. We hope MME-CoT serves as a foundation for advancing multimodal reasoning in LMMs. Project Page: this https URL</li>
</ul>

<h3>Title: Theoretical Benefit and Limitation of Diffusion Language Model</h3>
<ul>
<li><strong>Authors: </strong>Guhao Feng, Yihan Geng, Jian Guan, Wei Wu, Liwei Wang, Di He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09622">https://arxiv.org/abs/2502.09622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09622">https://arxiv.org/pdf/2502.09622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09622]] Theoretical Benefit and Limitation of Diffusion Language Model(https://arxiv.org/abs/2502.09622)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion language models have emerged as a promising approach for text generation. One would naturally expect this method to be an efficient replacement for autoregressive models since multiple tokens can be sampled in parallel during each diffusion step. However, its efficiency-accuracy trade-off is not yet well understood. In this paper, we present a rigorous theoretical analysis of a widely used type of diffusion language model, the Masked Diffusion Model (MDM), and find that its effectiveness heavily depends on the target evaluation metric. Under mild conditions, we prove that when using perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling steps regardless of sequence length, demonstrating that efficiency can be achieved without sacrificing performance. However, when using the sequence error rate--which is important for understanding the "correctness" of a sequence, such as a reasoning chain--we show that the required sampling steps must scale linearly with sequence length to obtain "correct" sequences, thereby eliminating MDM's efficiency advantage over autoregressive models. Our analysis establishes the first theoretical foundation for understanding the benefits and limitations of MDMs. All theoretical findings are supported by empirical studies.</li>
</ul>

<h3>Title: Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures</h3>
<ul>
<li><strong>Authors: </strong>Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.09623">https://arxiv.org/abs/2502.09623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.09623">https://arxiv.org/pdf/2502.09623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.09623]] Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures(https://arxiv.org/abs/2502.09623)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for representing 3D objects and scenes by encoding shape and appearance information into the weights of a neural network. Recent works have shown how such weights can be used as input to frameworks processing them to solve deep learning tasks. Yet, these frameworks can only process NeRFs with a specific, predefined architecture. In this paper, we present the first framework that can ingest NeRFs with multiple architectures and perform inference on architectures unseen at training time. We achieve this goal by training a Graph Meta-Network in a representation learning framework. Moreover, we show how a contrastive objective is conducive to obtaining an architecture-agnostic latent space. In experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates robust performance in classification and retrieval tasks that either matches or exceeds that of existing frameworks constrained to single architectures, thus providing the first architecture-agnostic method to perform tasks on NeRFs by processing their weights.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
