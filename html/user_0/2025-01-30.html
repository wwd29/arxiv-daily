<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-01-30</h1>
<h3>Title: Split Knowledge Distillation for Large Models in IoT: Architecture, Challenges, and Solutions</h3>
<ul>
<li><strong>Authors: </strong>Zuguang Li, Wen Wu, Shaohua Wu, Qiaohua Lin, Yaping Sun, Hui Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17164">https://arxiv.org/abs/2501.17164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17164">https://arxiv.org/pdf/2501.17164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17164]] Split Knowledge Distillation for Large Models in IoT: Architecture, Challenges, and Solutions(https://arxiv.org/abs/2501.17164)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Large models (LMs) have immense potential in Internet of Things (IoT) systems, enabling applications such as intelligent voice assistants, predictive maintenance, and healthcare monitoring. However, training LMs on edge servers raises data privacy concerns, while deploying them directly on IoT devices is constrained by limited computational and memory resources. We analyze the key challenges of training LMs in IoT systems, including energy constraints, latency requirements, and device heterogeneity, and propose potential solutions such as dynamic resource management, adaptive model partitioning, and clustered collaborative training. Furthermore, we propose a split knowledge distillation framework to efficiently distill LMs into smaller, deployable versions for IoT devices while ensuring raw data remains local. This framework integrates knowledge distillation and split learning to minimize energy consumption and meet low model training delay requirements. A case study is presented to evaluate the feasibility and performance of the proposed framework.</li>
</ul>

<h3>Title: Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques</h3>
<ul>
<li><strong>Authors: </strong>Ammarah Irum, M. Ali Tahir</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17175">https://arxiv.org/abs/2501.17175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17175">https://arxiv.org/pdf/2501.17175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17175]] Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques(https://arxiv.org/abs/2501.17175)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Document level Urdu Sentiment Analysis (SA) is a challenging Natural Language Processing (NLP) task as it deals with large documents in a resource-poor language. In large documents, there are ample amounts of words that exhibit different viewpoints. Deep learning (DL) models comprise of complex neural network architectures that have the ability to learn diverse features of the data to classify various sentiments. Besides audio, image and video classification; DL algorithms are now extensively used in text-based classification problems. To explore the powerful DL techniques for Urdu SA, we have applied five different DL architectures namely, Bidirectional Long Short Term Memory (BiLSTM), Convolutional Neural Network (CNN), Convolutional Neural Network with Bidirectional Long Short Term Memory (CNN-BiLSTM), Bidirectional Encoder Representation from Transformer (BERT). In this paper, we have proposed a DL hybrid model that integrates BiLSTM with Single Layer Multi Filter Convolutional Neural Network (BiLSTM-SLMFCNN). The proposed and baseline techniques are applied on Urdu Customer Support data set and IMDB Urdu movie review data set by using pretrained Urdu word embeddings that are suitable for (SA) at the document level. Results of these techniques are evaluated and our proposed model outperforms all other DL techniques for Urdu SA. BiLSTM-SLMFCNN outperformed the baseline DL models and achieved 83{\%}, 79{\%}, 83{\%} and 94{\%} accuracy on small, medium and large sized IMDB Urdu movie review data set and Urdu Customer Support data set respectively.</li>
</ul>

<h3>Title: Tuning LLM Judges Hyperparameters</h3>
<ul>
<li><strong>Authors: </strong>David Salinas, Omar Swelam, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17178">https://arxiv.org/abs/2501.17178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17178">https://arxiv.org/pdf/2501.17178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17178]] Tuning LLM Judges Hyperparameters(https://arxiv.org/abs/2501.17178)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating Large Language Models (LLMs) often requires costly human annotations. To address this, LLM-based judges have been proposed, which compare the outputs of two LLMs enabling the ranking of models without human intervention. While several approaches have been proposed, many confounding factors are present between different papers. For instance the model, the prompt and other hyperparameters are typically changed at the same time making apple-to-apple comparisons challenging. In this paper, we propose to systematically analyze and tune hyperparameter of LLM judges. To alleviate the high cost of evaluating a judge, we propose to leverage multi-objective multi-fidelity which allows to find judges that trades accuracy for cost and also reduce significantly the cost of the search. Our method identifies judges that not only outperform existing benchmarks in accuracy and cost-efficiency but also utilize open-weight models, ensuring greater accessibility and reproducibility.</li>
</ul>

<h3>Title: LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated Generation and Multi-Model Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Beiming Liu, Zhizhuo Cui, Siteng Hu, Xiaohua Li, Haifeng Lin, Zhengxin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17183">https://arxiv.org/abs/2501.17183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17183">https://arxiv.org/pdf/2501.17183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17183]] LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated Generation and Multi-Model Question Answering(https://arxiv.org/abs/2501.17183)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aerospace manufacturing demands exceptionally high precision in technical parameters. The remarkable performance of Large Language Models (LLMs), such as GPT-4 and QWen, in Natural Language Processing has sparked industry interest in their application to tasks including process design, material selection, and tool information retrieval. However, LLMs are prone to generating "hallucinations" in specialized domains, producing inaccurate or false information that poses significant risks to the quality of aerospace products and flight safety. This paper introduces a set of evaluation metrics tailored for LLMs in aerospace manufacturing, aiming to assess their accuracy by analyzing their performance in answering questions grounded in professional knowledge. Firstly, key information is extracted through in-depth textual analysis of classic aerospace manufacturing textbooks and guidelines. Subsequently, utilizing LLM generation techniques, we meticulously construct multiple-choice questions with multiple correct answers of varying difficulty. Following this, different LLM models are employed to answer these questions, and their accuracy is recorded. Experimental results demonstrate that the capabilities of LLMs in aerospace professional knowledge are in urgent need of improvement. This study provides a theoretical foundation and practical guidance for the application of LLMs in aerospace manufacturing, addressing a critical gap in the field.</li>
</ul>

<h3>Title: Visualizing Uncertainty in Translation Tasks: An Evaluation of LLM Performance and Confidence Metrics</h3>
<ul>
<li><strong>Authors: </strong>Jin Hyun Park, Utsawb Laminchhane, Umer Farooq, Uma Sivakumar, Arpan Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17187">https://arxiv.org/abs/2501.17187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17187">https://arxiv.org/pdf/2501.17187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17187]] Visualizing Uncertainty in Translation Tasks: An Evaluation of LLM Performance and Confidence Metrics(https://arxiv.org/abs/2501.17187)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly utilized for machine translation, yet their predictions often exhibit uncertainties that hinder interpretability and user trust. Effectively visualizing these uncertainties can enhance the usability of LLM outputs, particularly in contexts where translation accuracy is critical. This paper addresses two primary objectives: (1) providing users with token-level insights into model confidence and (2) developing a web-based visualization tool to quantify and represent translation uncertainties. To achieve these goals, we utilized the T5 model with the WMT19 dataset for translation tasks and evaluated translation quality using established metrics such as BLEU, METEOR, and ROUGE. We introduced three novel uncertainty quantification (UQ) metrics: (1) the geometric mean of token probabilities, (2) the arithmetic mean of token probabilities, and (3) the arithmetic mean of the kurtosis of token distributions. These metrics provide a simple yet effective framework for evaluating translation performance. Our analysis revealed a linear relationship between the traditional evaluation metrics and our UQ metrics, demonstrating the validity of our approach. Additionally, we developed an interactive web-based visualization that uses a color gradient to represent token confidence. This tool offers users a clear and intuitive understanding of translation quality while providing valuable insights into model performance. Overall, we show that our UQ metrics and visualization are both robust and interpretable, offering practical tools for evaluating and accessing machine translation systems.</li>
</ul>

<h3>Title: A Comprehensive Study on Fine-Tuning Large Language Models for Medical Question Answering Using Classification Models and Comparative Analysis</h3>
<ul>
<li><strong>Authors: </strong>Aysegul Ucar, Soumik Nayak, Anunak Roy, Burak Taşcı, Gülay Taşcı</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17190">https://arxiv.org/abs/2501.17190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17190">https://arxiv.org/pdf/2501.17190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17190]] A Comprehensive Study on Fine-Tuning Large Language Models for Medical Question Answering Using Classification Models and Comparative Analysis(https://arxiv.org/abs/2501.17190)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents the overview of the development and fine-tuning of large language models (LLMs) designed specifically for answering medical questions. We are mainly improving the accuracy and efficiency of providing reliable answers to medical queries. In our approach, we have two stages, prediction of a specific label for the received medical question and then providing a predefined answer for this label. Various models such as RoBERTa and BERT were examined and evaluated based on their ability. The models are trained using the datasets derived from 6,800 samples that were scraped from Healthline. com with additional synthetic data. For evaluation, we conducted a comparative study using 5-fold cross-validation. For accessing performance we used metrics like, accuracy, precision, recall, and F1 score and also recorded the training time. The performance of the models was evaluated using 5-fold cross-validation. The LoRA Roberta-large model achieved an accuracy of 78.47%, precision of 72.91%, recall of 76.95%, and an F1 score of 73.56%. The Roberta-base model demonstrated high performance with an accuracy of 99.87%, precision of 99.81%, recall of 99.86%, and an F1 score of 99.82%. The Bert Uncased model showed strong results with an accuracy of 95.85%, precision of 94.42%, recall of 95.58%, and an F1 score of 94.72%. Lastly, the Bert Large Uncased model achieved the highest performance, with an accuracy, precision, recall, and F1 score of 100%. The results obtained have helped indicate the capability of the models in classifying the medical questions and generating accurate answers in the prescription of improved health-related AI solutions.</li>
</ul>

<h3>Title: AI-assisted German Employment Contract Review: A Benchmark Dataset</h3>
<ul>
<li><strong>Authors: </strong>Oliver Wardas, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17194">https://arxiv.org/abs/2501.17194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17194">https://arxiv.org/pdf/2501.17194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17194]] AI-assisted German Employment Contract Review: A Benchmark Dataset(https://arxiv.org/abs/2501.17194)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Employment contracts are used to agree upon the working conditions between employers and employees all over the world. Understanding and reviewing contracts for void or unfair clauses requires extensive knowledge of the legal system and terminology. Recent advances in Natural Language Processing (NLP) hold promise for assisting in these reviews. However, applying NLP techniques on legal text is particularly difficult due to the scarcity of expert-annotated datasets. To address this issue and as a starting point for our effort in assisting lawyers with contract reviews using NLP, we release an anonymized and annotated benchmark dataset for legality and fairness review of German employment contract clauses, alongside with baseline model evaluations.</li>
</ul>

<h3>Title: Atla Selene Mini: A General Purpose Evaluation Model</h3>
<ul>
<li><strong>Authors: </strong>Andrei Alexandru, Antonia Calvi, Henry Broomfield, Jackson Golden, Kyle Dai, Mathias Leys, Maurice Burger, Max Bartolo, Roman Engeler, Sashank Pisupati, Toby Drane, Young Sun Park</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17195">https://arxiv.org/abs/2501.17195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17195">https://arxiv.org/pdf/2501.17195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17195]] Atla Selene Mini: A General Purpose Evaluation Model(https://arxiv.org/abs/2501.17195)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>We introduce Atla Selene Mini, a state-of-the-art small language model-as-a-judge (SLMJ). Selene Mini is a general-purpose evaluator that outperforms the best SLMJs and GPT-4o-mini on overall performance across 11 out-of-distribution benchmarks, spanning absolute scoring, classification, and pairwise preference tasks. It is the highest-scoring 8B generative model on RewardBench, surpassing strong baselines like GPT-4o and specialized judges. To achieve this, we develop a principled data curation strategy that augments public datasets with synthetically generated critiques and ensures high quality through filtering and dataset ablations. We train our model on a combined direct preference optimization (DPO) and supervised fine-tuning (SFT) loss, and produce a highly promptable evaluator that excels in real-world scenarios. Selene Mini shows dramatically improved zero-shot agreement with human expert evaluations on financial and medical industry datasets. It is also robust to variations in prompt format. Preliminary results indicate that Selene Mini is the top-ranking evaluator in a live, community-driven Judge Arena. We release the model weights on HuggingFace (this https URL) and Ollama to encourage widespread community adoption.</li>
</ul>

<h3>Title: Improving LLM Leaderboards with Psychometrical Methodology</h3>
<ul>
<li><strong>Authors: </strong>Denis Federiakin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17200">https://arxiv.org/abs/2501.17200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17200">https://arxiv.org/pdf/2501.17200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17200]] Improving LLM Leaderboards with Psychometrical Methodology(https://arxiv.org/abs/2501.17200)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of large language models (LLMs) has necessitated the creation of benchmarks to evaluate their performance. These benchmarks resemble human tests and surveys, as they consist of sets of questions designed to measure emergent properties in the cognitive behavior of these systems. However, unlike the well-defined traits and abilities studied in social sciences, the properties measured by these benchmarks are often vaguer and less rigorously defined. The most prominent benchmarks are often grouped into leaderboards for convenience, aggregating performance metrics and enabling comparisons between models. Unfortunately, these leaderboards typically rely on simplistic aggregation methods, such as taking the average score across benchmarks. In this paper, we demonstrate the advantages of applying contemporary psychometric methodologies - originally developed for human tests and surveys - to improve the ranking of large language models on leaderboards. Using data from the Hugging Face Leaderboard as an example, we compare the results of the conventional naive ranking approach with a psychometrically informed ranking. The findings highlight the benefits of adopting psychometric techniques for more robust and meaningful evaluation of LLM performance.</li>
</ul>

<h3>Title: ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Saraei, Igor Kozak, Eung-Joo Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17260">https://arxiv.org/abs/2501.17260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17260">https://arxiv.org/pdf/2501.17260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17260]] ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification(https://arxiv.org/abs/2501.17260)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Optical Coherence Tomography (OCT) is a non-invasive imaging modality essential for diagnosing various eye diseases. Despite its clinical significance, developing OCT-based diagnostic tools faces challenges, such as limited public datasets, sparse annotations, and privacy concerns. Although deep learning has made progress in automating OCT analysis, these challenges remain unresolved. To address these limitations, we introduce the Vision Transformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a novel framework designed to enhance feature extraction and improve diagnostic accuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining, Self-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining phase leverages the OCTMNIST dataset (97,477 unlabeled images across four disease classes) with data augmentation to create dual-augmented views. A Vision Transformer (ViT-Base) backbone extracts features, while a negative cosine similarity loss aligns feature representations. Pretraining is conducted over 50 epochs with a learning rate of 0.0001 and momentum of 0.999. Fine-tuning is performed on a stratified 5.129% subset of OCTMNIST using 10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of 0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming existing SSP-based methods.</li>
</ul>

<h3>Title: NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations</h3>
<ul>
<li><strong>Authors: </strong>Meng Luo, Han Zhang, Shengqiong Wu, Bobo Li, Hong Han, Hao Fei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17261">https://arxiv.org/abs/2501.17261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17261">https://arxiv.org/pdf/2501.17261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17261]] NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations(https://arxiv.org/abs/2501.17261)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper describes the architecture of our system developed for Task 3 of SemEval-2024: Multimodal Emotion-Cause Analysis in Conversations. Our project targets the challenges of subtask 2, dedicated to Multimodal Emotion-Cause Pair Extraction with Emotion Category (MECPE-Cat), and constructs a dual-component system tailored to the unique challenges of this task. We divide the task into two subtasks: emotion recognition in conversation (ERC) and emotion-cause pair extraction (ECPE). To address these subtasks, we capitalize on the abilities of Large Language Models (LLMs), which have consistently demonstrated state-of-the-art performance across various natural language processing tasks and domains. Most importantly, we design an approach of emotion-cause-aware instruction-tuning for LLMs, to enhance the perception of the emotions with their corresponding causal rationales. Our method enables us to adeptly navigate the complexities of MECPE-Cat, achieving a weighted average 34.71% F1 score of the task, and securing the 2nd rank on the leaderboard. The code and metadata to reproduce our experiments are all made publicly available.</li>
</ul>

<h3>Title: Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics</h3>
<ul>
<li><strong>Authors: </strong>Jasper Timm, Chetan Talele, Jacob Haimes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17273">https://arxiv.org/abs/2501.17273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17273">https://arxiv.org/pdf/2501.17273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17273]] Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics(https://arxiv.org/abs/2501.17273)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are becoming increasingly persuasive, demonstrating the ability to personalize arguments in conversation with humans by leveraging their personal data. This may have serious impacts on the scale and effectiveness of disinformation campaigns. We studied the persuasiveness of LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated arguments intended to change the human's opinion. We quantified the LLM's effect by measuring human agreement with the debate's hypothesis pre- and post-debate and analyzing both the magnitude of opinion change, as well as the likelihood of an update in the LLM's direction. We compare persuasiveness across established persuasion strategies, including personalized arguments informed by user demographics and personality, appeal to fabricated statistics, and a mixed strategy utilizing both personalized arguments and fabricated statistics. We found that static arguments generated by humans and GPT-4o-mini have comparable persuasive power. However, the LLM outperformed static human-written arguments when leveraging the mixed strategy in an interactive debate setting. This approach had a $\mathbf{51\%}$ chance of persuading participants to modify their initial position, compared to $\mathbf{32\%}$ for the static human-written arguments. Our results highlight the concerning potential for LLMs to enable inexpensive and persuasive large-scale disinformation campaigns.</li>
</ul>

<h3>Title: A Contrastive Teacher-Student Framework for Novelty Detection under Style Shifts</h3>
<ul>
<li><strong>Authors: </strong>Hossein Mirzaei, Mojtaba Nafez, Moein Madadi, Arad Maleki, Mahdi Hajialilue, Zeinab Sadat Taghavi, Sepehr Rezaee, Ali Ansari, Bahar Dibaei Nia, Kian Shamsaie, Mohammadreza Salehi, Mackenzie W. Mathis, Mahdieh Soleymani Baghshah, Mohammad Sabokrou, Mohammad Hossein Rohban</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17289">https://arxiv.org/abs/2501.17289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17289">https://arxiv.org/pdf/2501.17289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17289]] A Contrastive Teacher-Student Framework for Novelty Detection under Style Shifts(https://arxiv.org/abs/2501.17289)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>There have been several efforts to improve Novelty Detection (ND) performance. However, ND methods often suffer significant performance drops under minor distribution shifts caused by changes in the environment, known as style shifts. This challenge arises from the ND setup, where the absence of out-of-distribution (OOD) samples during training causes the detector to be biased toward the dominant style features in the in-distribution (ID) data. As a result, the model mistakenly learns to correlate style with core features, using this shortcut for detection. Robust ND is crucial for real-world applications like autonomous driving and medical imaging, where test samples may have different styles than the training data. Motivated by this, we propose a robust ND method that crafts an auxiliary OOD set with style features similar to the ID set but with different core features. Then, a task-based knowledge distillation strategy is utilized to distinguish core features from style features and help our model rely on core features for discriminating crafted OOD and ID sets. We verified the effectiveness of our method through extensive experimental evaluations on several datasets, including synthetic and real-world benchmarks, against nine different ND methods.</li>
</ul>

<h3>Title: Enabling Low-Cost Secure Computing on Untrusted In-Memory Architectures</h3>
<ul>
<li><strong>Authors: </strong>Sahar Ghoflsaz Ghinani, Jingyao Zhang, Elaheh Sadredini</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17292">https://arxiv.org/abs/2501.17292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17292">https://arxiv.org/pdf/2501.17292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17292]] Enabling Low-Cost Secure Computing on Untrusted In-Memory Architectures(https://arxiv.org/abs/2501.17292)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Modern computing systems are limited in performance by the memory bandwidth available to processors, a problem known as the memory wall. Processing-in-Memory (PIM) promises to substantially improve this problem by moving processing closer to the data, improving effective data bandwidth, and leading to superior performance on memory-intensive workloads. However, integrating PIM modules within a secure computing system raises an interesting challenge: unencrypted data has to move off-chip to the PIM, exposing the data to attackers and breaking assumptions on Trusted Computing Bases (TCBs). To tackle this challenge, this paper leverages multi-party computation (MPC) techniques, specifically arithmetic secret sharing and Yao's garbled circuits, to outsource bandwidth-intensive computation securely to PIM. Additionally, we leverage precomputation optimization to prevent the CPU's portion of the MPC from becoming a bottleneck. We evaluate our approach using the UPMEM PIM system over various applications such as Deep Learning Recommendation Model inference and Logistic Regression. Our evaluations demonstrate up to a $14.66\times$ speedup compared to a secure CPU configuration while maintaining data confidentiality and integrity when outsourcing linear and/or nonlinear computation.</li>
</ul>

<h3>Title: Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zilu Tang, Rajen Chatterjee, Sarthak Garg</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17295">https://arxiv.org/abs/2501.17295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17295">https://arxiv.org/pdf/2501.17295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17295]] Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization(https://arxiv.org/abs/2501.17295)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Machine Translation (MT) is undergoing a paradigm shift, with systems based on fine-tuned large language models (LLM) becoming increasingly competitive with traditional encoder-decoder models trained specifically for translation tasks. However, LLM-based systems are at a higher risk of generating hallucinations, which can severely undermine user's trust and safety. Most prior research on hallucination mitigation focuses on traditional MT models, with solutions that involve post-hoc mitigation - detecting hallucinated translations and re-translating them. While effective, this approach introduces additional complexity in deploying extra tools in production and also increases latency. To address these limitations, we propose a method that intrinsically learns to mitigate hallucinations during the model training phase. Specifically, we introduce a data creation framework to generate hallucination focused preference datasets. Fine-tuning LLMs on these preference datasets reduces the hallucination rate by an average of 96% across five language pairs, while preserving overall translation quality. In a zero-shot setting our approach reduces hallucinations by 89% on an average across three unseen target languages.</li>
</ul>

<h3>Title: MDDM: A Molecular Dynamics Diffusion Model to Predict Particle Self-Assembly</h3>
<ul>
<li><strong>Authors: </strong>Kevin Ferguson, Yu-hsuan Chen, Levent Burak Kara</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17319">https://arxiv.org/abs/2501.17319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17319">https://arxiv.org/pdf/2501.17319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17319]] MDDM: A Molecular Dynamics Diffusion Model to Predict Particle Self-Assembly(https://arxiv.org/abs/2501.17319)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The discovery and study of new material systems relies on molecular simulations that often come with significant computational expense. We propose MDDM, a Molecular Dynamics Diffusion Model, which is capable of predicting a valid output conformation for a given input pair potential function. After training MDDM on a large dataset of molecular dynamics self-assembly results, the proposed model can convert uniform noise into a meaningful output particle structure corresponding to an arbitrary input potential. The model's architecture has domain-specific properties built-in, such as satisfying periodic boundaries and being invariant to translation. The model significantly outperforms the baseline point-cloud diffusion model for both unconditional and conditional generation tasks.</li>
</ul>

<h3>Title: CardiCat: a Variational Autoencoder for High-Cardinality Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Lee Carlin, Yuval Benjamini</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17324">https://arxiv.org/abs/2501.17324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17324">https://arxiv.org/pdf/2501.17324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17324]] CardiCat: a Variational Autoencoder for High-Cardinality Tabular Data(https://arxiv.org/abs/2501.17324)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>High-cardinality categorical features are a common characteristic of mixed-type tabular datasets. Existing generative model architectures struggle to learn the complexities of such data at scale, primarily due to the difficulty of parameterizing the categorical features. In this paper, we present a general variational autoencoder model, CardiCat, that can accurately fit imbalanced high-cardinality and heterogeneous tabular data. Our method substitutes one-hot encoding with regularized dual encoder-decoder embedding layers, which are jointly learned. This approach enables us to use embeddings that depend also on the other covariates, leading to a compact and homogenized parameterization of categorical features. Our model employs a considerably smaller trainable parameter space than competing methods, enabling learning at a large scale. CardiCat generates high-quality synthetic data that better represent high-cardinality and imbalanced features compared to competing VAE models for multiple real and simulated datasets.</li>
</ul>

<h3>Title: Connecting Federated ADMM to Bayes</h3>
<ul>
<li><strong>Authors: </strong>Siddharth Swaroop, Mohammad Emtiyaz Khan, Finale Doshi-Velez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17325">https://arxiv.org/abs/2501.17325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17325">https://arxiv.org/pdf/2501.17325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17325]] Connecting Federated ADMM to Bayes(https://arxiv.org/abs/2501.17325)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We provide new connections between two distinct federated learning approaches based on (i) ADMM and (ii) Variational Bayes (VB), and propose new variants by combining their complementary strengths. Specifically, we show that the dual variables in ADMM naturally emerge through the 'site' parameters used in VB with isotropic Gaussian covariances. Using this, we derive two versions of ADMM from VB that use flexible covariances and functional regularisation, respectively. Through numerical experiments, we validate the improvements obtained in performance. The work shows connection between two fields that are believed to be fundamentally different and combines them to improve federated learning.</li>
</ul>

<h3>Title: Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17326">https://arxiv.org/abs/2501.17326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17326">https://arxiv.org/pdf/2501.17326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17326]] Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction(https://arxiv.org/abs/2501.17326)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Clinical diagnosis prediction models, when provided with a patient's medical history, aim to detect potential diseases early, facilitating timely intervention and improving prognostic outcomes. However, the inherent scarcity of patient data and large disease candidate space often pose challenges in developing satisfactory models for this intricate task. The exploration of leveraging Large Language Models (LLMs) for encapsulating clinical decision processes has been limited. We introduce MERA, a clinical diagnosis prediction model that bridges pertaining natural language knowledge with medical practice. We apply hierarchical contrastive learning on a disease candidate ranking list to alleviate the large decision space issue. With concept memorization through fine-tuning, we bridge the natural language clinical knowledge with medical codes. Experimental results on MIMIC-III and IV datasets show that MERA achieves the state-of-the-art diagnosis prediction performance and dramatically elevates the diagnosis prediction capabilities of generative LMs.</li>
</ul>

<h3>Title: WASUP: Interpretable Classification with Weight-Input Alignment and Class-Discriminative SUPports Vectors</h3>
<ul>
<li><strong>Authors: </strong>Tom Nuno Wolf, Christian Wachinger</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17328">https://arxiv.org/abs/2501.17328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17328">https://arxiv.org/pdf/2501.17328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17328]] WASUP: Interpretable Classification with Weight-Input Alignment and Class-Discriminative SUPports Vectors(https://arxiv.org/abs/2501.17328)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The deployment of deep learning models in critical domains necessitates a balance between high accuracy and interpretability. We introduce WASUP, an inherently interpretable neural network that provides local and global explanations of its decision-making process. We prove that these explanations are faithful by fulfilling established axioms for explanations. Leveraging the concept of case-based reasoning, WASUP extracts class-representative support vectors from training images, ensuring they capture relevant features while suppressing irrelevant ones. Classification decisions are made by calculating and aggregating similarity scores between these support vectors and the input's latent feature vector. We employ B-Cos transformations, which align model weights with inputs to enable faithful mappings of latent features back to the input space, facilitating local explanations in addition to global explanations of case-based reasoning. We evaluate WASUP on three tasks: fine-grained classification on Stanford Dogs, multi-label classification on Pascal VOC, and pathology detection on the RSNA dataset. Results indicate that WASUP not only achieves competitive accuracy compared to state-of-the-art black-box models but also offers insightful explanations verified through theoretical analysis. Our findings underscore WASUP's potential for applications where understanding model decisions is as critical as the decisions themselves.</li>
</ul>

<h3>Title: Pandora's Box: Cross-Chain Arbitrages in the Realm of Blockchain Interoperability</h3>
<ul>
<li><strong>Authors: </strong>Burak Öz, Christof Ferreira Torres, Jonas Gebele, Filip Rezabek, Bruno Mazorra, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17335">https://arxiv.org/abs/2501.17335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17335">https://arxiv.org/pdf/2501.17335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17335]] Pandora's Box: Cross-Chain Arbitrages in the Realm of Blockchain Interoperability(https://arxiv.org/abs/2501.17335)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>Over recent years, the blockchain ecosystem has grown significantly with the emergence of new Layer-1 (L1) and Layer-2 (L2) networks. These blockchains typically host Decentralized Exchanges (DEXes) for trading assets such as native currencies and stablecoins. While this diversity enriches the ecosystem, it also fragments liquidity, posing challenges for DEXes offering the same assets across multiple blockchains. This fragmentation leads to price discrepancies, creating opportunities like arbitrages for profit-seeking traders, which fall under the broader category of exploitative economic practices known as Maximal Extractable Value (MEV). Although MEV extraction has been extensively studied within single domains (i.e., individual blockchains), cross-chain arbitrages, a form of cross-domain MEV, have received little attention due to their non-atomic nature, complicating both execution and detection. In this paper, we shed light on opaque cross-chain MEV activities by presenting the first systematic study of two non-atomic cross-chain arbitrage strategies: Sequence-Independent Arbitrage (SIA) and Sequence-Dependent Arbitrage (SDA). The former involves independent, opposite-direction trades across chains, while the latter relies on asset bridges. We analyze the effectiveness of these strategies across nine blockchains over a one-year period from September 2023 to August 2024, identifying 260,808 cross-chain arbitrages, 32.37% of which involve bridging solutions. These arbitrages generated a lower-bound profit of 9,496,115.28 USD from a total traded volume of 465,797,487.98 USD. Additionally, we examine the security implications of cross-chain arbitrages, uncovering centralization among arbitrageurs, network congestion caused by failed transactions, and growing private mempool adoption. Finally, we discuss sequencer incentives and propose a risk-optimized arbitrage strategy.</li>
</ul>

<h3>Title: Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17338">https://arxiv.org/abs/2501.17338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17338">https://arxiv.org/pdf/2501.17338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17338]] Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection(https://arxiv.org/abs/2501.17338)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Language Models rely on autoregressive decoding to produce the output sequence token by token. Many tasks such as preference optimization, require the model to produce task-level output consisting of multiple tokens directly by selecting candidates from a pool as predictions. Determining a task-level prediction from candidates using the ordinary token-level decoding mechanism is constrained by time-consuming decoding and interrupted gradients by discrete token selection. Existing works have been using decoding-free candidate selection methods to obtain candidate probability from initial output logits over vocabulary. Though these estimation methods are widely used, they are not systematically evaluated, especially on end tasks. We introduce an evaluation of a comprehensive collection of decoding-free candidate selection approaches on a comprehensive set of tasks, including five multiple-choice QA tasks with a small candidate pool and four clinical decision tasks with a massive amount of candidates, some with 10k+ options. We evaluate the estimation methods paired with a wide spectrum of foundation LMs covering different architectures, sizes and training paradigms. The results and insights from our analysis inform the future model design.</li>
</ul>

<h3>Title: Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines</h3>
<ul>
<li><strong>Authors: </strong>Chongyu Qu, Ritchie Zhao, Ye Yu, Bin Liu, Tianyuan Yao, Junchao Zhu, Bennett A. Landman, Yucheng Tang, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17343">https://arxiv.org/abs/2501.17343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17343">https://arxiv.org/pdf/2501.17343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17343]] Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines(https://arxiv.org/abs/2501.17343)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Quantizing deep neural networks ,reducing the precision (bit-width) of their computations, can remarkably decrease memory usage and accelerate processing, making these models more suitable for large-scale medical imaging applications with limited computational resources. However, many existing methods studied "fake quantization", which simulates lower precision operations during inference, but does not actually reduce model size or improve real-world inference speed. Moreover, the potential of deploying real 3D low-bit quantization on modern GPUs is still unexplored. In this study, we introduce a real post-training quantization (PTQ) framework that successfully implements true 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation models, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet, ST-UNet,and VISTA3D. Our approach involves two main steps. First, we use TensorRT to perform fake quantization for both weights and activations with unlabeled calibration dataset. Second, we convert this fake quantization into real quantization via TensorRT engine on real GPUs, resulting in real-world reductions in model size and inference latency. Extensive experiments demonstrate that our framework effectively performs 8-bit quantization on GPUs without sacrificing model performance. This advancement enables the deployment of efficient deep learning models in medical imaging applications where computational resources are constrained. The code and models have been released, including U-Net, TransUNet pretrained on the BTCV dataset for abdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset for whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and VISTA3D pretrained on TotalSegmentator V2 for full body (104-label) segmentation. this https URL.</li>
</ul>

<h3>Title: Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations</h3>
<ul>
<li><strong>Authors: </strong>Md Tauhidul Islam, Lei Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17347">https://arxiv.org/abs/2501.17347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17347">https://arxiv.org/pdf/2501.17347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17347]] Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations(https://arxiv.org/abs/2501.17347)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Advancements in deep learning are revolutionizing science and engineering. The immense success of deep learning is largely due to its ability to extract essential high-dimensional (HD) features from input data and make inference decisions based on this information. However, current deep neural network (DNN) models face several challenges, such as the requirements of extensive amounts of data and computational resources. Here, we introduce a new learning scheme, referred to as deep-and-wide learning (DWL), to systematically capture features not only within individual input data (intra-data features) but also across the data (inter-data features). Furthermore, we propose a dual-interactive-channel network (D-Net) to realize the DWL, which leverages our Bayesian formulation of low-dimensional (LD) inter-data feature extraction and its synergistic interaction with the conventional HD representation of the dataset, for substantially enhanced computational efficiency and inference. The proposed technique has been applied to data across various disciplines for both classification and regression tasks. Our results demonstrate that DWL surpasses state-of-the-art DNNs in accuracy by a substantial margin with limited training data and improves the computational efficiency by order(s) of magnitude. The proposed DWL strategy dramatically alters the data-driven learning techniques, including emerging large foundation models, and sheds significant insights into the evolving field of AI.</li>
</ul>

<h3>Title: On the Coexistence and Ensembling of Watermarks</h3>
<ul>
<li><strong>Authors: </strong>Aleksandar Petrov, Shruti Agarwal, Philip H.S. Torr, Adel Bibi, John Collomosse</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17356">https://arxiv.org/abs/2501.17356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17356">https://arxiv.org/pdf/2501.17356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17356]] On the Coexistence and Ensembling of Watermarks(https://arxiv.org/abs/2501.17356)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, watermark</a></li>
<li><strong>Abstract: </strong>Watermarking, the practice of embedding imperceptible information into media such as images, videos, audio, and text, is essential for intellectual property protection, content provenance and attribution. The growing complexity of digital ecosystems necessitates watermarks for different uses to be embedded in the same media. However, to detect and decode all watermarks, they need to coexist well with one another. We perform the first study of coexistence of deep image watermarking methods and, contrary to intuition, we find that various open-source watermarks can coexist with only minor impacts on image quality and decoding robustness. The coexistence of watermarks also opens the avenue for ensembling watermarking methods. We show how ensembling can increase the overall message capacity and enable new trade-offs between capacity, accuracy, robustness and image quality, without needing to retrain the base models.</li>
</ul>

<h3>Title: Do We Really Need to Design New Byzantine-robust Aggregation Rules?</h3>
<ul>
<li><strong>Authors: </strong>Minghong Fang, Seyedsina Nabavirazavi, Zhuqing Liu, Wei Sun, Sundararaja Sitharama Iyengar, Haibo Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17381">https://arxiv.org/abs/2501.17381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17381">https://arxiv.org/pdf/2501.17381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17381]] Do We Really Need to Design New Byzantine-robust Aggregation Rules?(https://arxiv.org/abs/2501.17381)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) allows multiple clients to collaboratively train a global machine learning model through a server, without exchanging their private training data. However, the decentralized aspect of FL makes it susceptible to poisoning attacks, where malicious clients can manipulate the global model by sending altered local model updates. To counter these attacks, a variety of aggregation rules designed to be resilient to Byzantine failures have been introduced. Nonetheless, these methods can still be vulnerable to sophisticated attacks or depend on unrealistic assumptions about the server. In this paper, we demonstrate that there is no need to design new Byzantine-robust aggregation rules; instead, FL can be secured by enhancing the robustness of well-established aggregation rules. To this end, we present FoundationFL, a novel defense mechanism against poisoning attacks. FoundationFL involves the server generating synthetic updates after receiving local model updates from clients. It then applies existing Byzantine-robust foundational aggregation rules, such as Trimmed-mean or Median, to combine clients' model updates with the synthetic ones. We theoretically establish the convergence performance of FoundationFL under Byzantine settings. Comprehensive experiments across several real-world datasets validate the efficiency of our FoundationFL method.</li>
</ul>

<h3>Title: A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhengpeng Xie, Jiahang Cao, Yulong Zhang, Qiang Zhang, Renjing Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17384">https://arxiv.org/abs/2501.17384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17384">https://arxiv.org/pdf/2501.17384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17384]] A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning(https://arxiv.org/abs/2501.17384)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, empowered with the powerful capabilities of neural networks, reinforcement learning (RL) has successfully tackled numerous challenging tasks. However, while these models demonstrate enhanced decision-making abilities, they are increasingly prone to overfitting. For instance, a trained RL model often fails to generalize to even minor variations of the same task, such as a change in background color or other minor semantic differences. To address this issue, we propose a dual-agent adversarial policy learning framework, which allows agents to spontaneously learn the underlying semantics without introducing any human prior knowledge. Specifically, our framework involves a game process between two agents: each agent seeks to maximize the impact of perturbing on the opponent's policy by producing representation differences for the same state, while maintaining its own stability against such perturbations. This interaction encourages agents to learn generalizable policies, capable of handling irrelevant features from the high-dimensional observations. Extensive experimental results on the Procgen benchmark demonstrate that the adversarial process significantly improves the generalization performance of both agents, while also being applied to various RL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial framework, the RL agent outperforms the baseline methods by a significant margin, especially in hard-level tasks, marking a significant step forward in the generalization capabilities of deep reinforcement learning.</li>
</ul>

<h3>Title: Context-Aware Semantic Recomposition Mechanism for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17386">https://arxiv.org/abs/2501.17386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17386">https://arxiv.org/pdf/2501.17386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17386]] Context-Aware Semantic Recomposition Mechanism for Large Language Models(https://arxiv.org/abs/2501.17386)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Context-aware processing mechanisms have increasingly become a critical area of exploration for improving the semantic and contextual capabilities of language generation models. The Context-Aware Semantic Recomposition Mechanism (CASRM) was introduced as a novel framework designed to address limitations in coherence, contextual adaptability, and error propagation in large-scale text generation tasks. Through the integration of dynamically generated context vectors and attention modulation layers, CASRM enhances the alignment between token-level representations and broader contextual dependencies. Experimental evaluations demonstrated significant improvements in semantic coherence across multiple domains, including technical, conversational, and narrative text. The ability to adapt to unseen domains and ambiguous inputs was evaluated using a diverse set of test scenarios, highlighting the robustness of the proposed mechanism. A detailed computational analysis revealed that while CASRM introduces additional processing overhead, the gains in linguistic precision and contextual relevance outweigh the marginal increase in complexity. The framework also successfully mitigates error propagation in sequential tasks, improving performance in dialogue continuation and multi-step text synthesis. Additional investigations into token-level attention distribution emphasized the dynamic focus shifts enabled through context-aware enhancements. The findings suggest that CASRM offers a scalable and flexible solution for integrating contextual intelligence into existing language model architectures.</li>
</ul>

<h3>Title: Assessing the Capability of YOLO- and Transformer-based Object Detectors for Real-time Weed Detection</h3>
<ul>
<li><strong>Authors: </strong>Alicia Allmendinger, Ahmet Oğuz Saltık, Gerassimos G. Peteinatos, Anthony Stein, Roland Gerhards</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17387">https://arxiv.org/abs/2501.17387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17387">https://arxiv.org/pdf/2501.17387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17387]] Assessing the Capability of YOLO- and Transformer-based Object Detectors for Real-time Weed Detection(https://arxiv.org/abs/2501.17387)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Spot spraying represents an efficient and sustainable method for reducing the amount of pesticides, particularly herbicides, used in agricultural fields. To achieve this, it is of utmost importance to reliably differentiate between crops and weeds, and even between individual weed species in situ and under real-time conditions. To assess suitability for real-time application, different object detection models that are currently state-of-the-art are compared. All available models of YOLOv8, YOLOv9, YOLOv10, and RT-DETR are trained and evaluated with images from a real field situation. The images are separated into two distinct datasets: In the initial data set, each species of plants is trained individually; in the subsequent dataset, a distinction is made between monocotyledonous weeds, dicotyledonous weeds, and three chosen crops. The results demonstrate that while all models perform equally well in the metrics evaluated, the YOLOv9 models, particularly the YOLOv9s and YOLOv9e, stand out in terms of their strong recall scores (66.58 \% and 72.36 \%), as well as mAP50 (73.52 \% and 79.86 \%), and mAP50-95 (43.82 \% and 47.00 \%) in dataset 2. However, the RT-DETR models, especially RT-DETR-l, excel in precision with reaching 82.44 \% on dataset 1 and 81.46 \% in dataset 2, making them particularly suitable for scenarios where minimizing false positives is critical. In particular, the smallest variants of the YOLO models (YOLOv8n, YOLOv9t, and YOLOv10n) achieve substantially faster inference times down to 7.58 ms for dataset 2 on the NVIDIA GeForce RTX 4090 GPU for analyzing one frame, while maintaining competitive accuracy, highlighting their potential for deployment in resource-constrained embedded computing devices as typically used in productive setups.</li>
</ul>

<h3>Title: Learning Free Token Reduction for Multi-Modal LLM</h3>
<ul>
<li><strong>Authors: </strong>Zihui Zhao, Yingxin Li, Yang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17391">https://arxiv.org/abs/2501.17391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17391">https://arxiv.org/pdf/2501.17391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17391]] Learning Free Token Reduction for Multi-Modal LLM(https://arxiv.org/abs/2501.17391)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have achieved remarkable success across a range of multimodal tasks; however, their practical deployment is often constrained by high computational costs and prolonged inference times. Since the vision modality typically carries more information than the text modality, compressing visual prompts offers a promising solution to alleviate these challenges. Existing approaches predominantly focus on refining model architectures or directly reducing the number of visual tokens. However, these methods often compromise inference performance due to a lack of consideration for the unique spatial and temporal characteristics of visual data. In this work, we propose a token compression paradigm that operates on both spatial and temporal dimensions. Our approach includes a learning-free, plug-and-play compression pipeline that can be seamlessly integrated into most Multimodal Large Language Model (MLLM) frameworks. By leveraging this method, we enhance the model inference capability while simultaneously reducing its computational cost. Experimental results on the Video-QA task demonstrate the effectiveness of the proposed approach, showcasing significant improvements in efficiency without sacrificing performance.</li>
</ul>

<h3>Title: Byzantine-Robust Federated Learning over Ring-All-Reduce Distributed Computing</h3>
<ul>
<li><strong>Authors: </strong>Minghong Fang, Zhuqing Liu, Xuecen Zhao, Jia Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17392">https://arxiv.org/abs/2501.17392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17392">https://arxiv.org/pdf/2501.17392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17392]] Byzantine-Robust Federated Learning over Ring-All-Reduce Distributed Computing(https://arxiv.org/abs/2501.17392)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has gained attention as a distributed learning paradigm for its data privacy benefits and accelerated convergence through parallel computation. Traditional FL relies on a server-client (SC) architecture, where a central server coordinates multiple clients to train a global model, but this approach faces scalability challenges due to server communication bottlenecks. To overcome this, the ring-all-reduce (RAR) architecture has been introduced, eliminating the central server and achieving bandwidth optimality. However, the tightly coupled nature of RAR's ring topology exposes it to unique Byzantine attack risks not present in SC-based FL. Despite its potential, designing Byzantine-robust RAR-based FL algorithms remains an open problem. To address this gap, we propose BRACE (Byzantine-robust ring-all-reduce), the first RAR-based FL algorithm to achieve both Byzantine robustness and communication efficiency. We provide theoretical guarantees for the convergence of BRACE under Byzantine attacks, demonstrate its bandwidth efficiency, and validate its practical effectiveness through experiments. Our work offers a foundational understanding of Byzantine-robust RAR-based FL design.</li>
</ul>

<h3>Title: Poisoning Attacks and Defenses to Federated Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Wenbin Wang, Qiwen Ma, Zifan Zhang, Yuchen Liu, Zhuqing Liu, Minghong Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17396">https://arxiv.org/abs/2501.17396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17396">https://arxiv.org/pdf/2501.17396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17396]] Poisoning Attacks and Defenses to Federated Unlearning(https://arxiv.org/abs/2501.17396)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning allows multiple clients to collaboratively train a global model with the assistance of a server. However, its distributed nature makes it susceptible to poisoning attacks, where malicious clients can compromise the global model by sending harmful local model updates to the server. To unlearn an accurate global model from a poisoned one after identifying malicious clients, federated unlearning has been introduced. Yet, current research on federated unlearning has primarily concentrated on its effectiveness and efficiency, overlooking the security challenges it presents. In this work, we bridge the gap via proposing BadUnlearn, the first poisoning attacks targeting federated unlearning. In BadUnlearn, malicious clients send specifically designed local model updates to the server during the unlearning process, aiming to ensure that the resulting unlearned model remains poisoned. To mitigate these threats, we propose UnlearnGuard, a robust federated unlearning framework that is provably robust against both existing poisoning attacks and our BadUnlearn. The core concept of UnlearnGuard is for the server to estimate the clients' local model updates during the unlearning process and employ a filtering strategy to verify the accuracy of these estimations. Theoretically, we prove that the model unlearned through UnlearnGuard closely resembles one obtained by train-from-scratch. Empirically, we show that BadUnlearn can effectively corrupt existing federated unlearning methods, while UnlearnGuard remains secure against poisoning attacks.</li>
</ul>

<h3>Title: MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ved Sirdeshmukh, Kaustubh Deshpande, Johannes Mols, Lifeng Jin, Ed-Yeremai Cardona, Dean Lee, Jeremy Kritz, Willow Primack, Summer Yue, Chen Xing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17399">https://arxiv.org/abs/2501.17399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17399">https://arxiv.org/pdf/2501.17399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17399]] MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs(https://arxiv.org/abs/2501.17399)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that are not only common and realistic among current human-LLM interactions, but are also challenging to all current frontier LLMs. All 4 challenges require accurate instruction-following, context allocation, and in-context reasoning at the same time. We also develop LLM as judge with instance-level rubrics to facilitate an automatic evaluation method with fair agreement with experienced human raters. Despite achieving near-perfect scores on existing multi-turn evaluation benchmarks, all frontier models have less than 50% accuracy on MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving just a 41.4% average accuracy.</li>
</ul>

<h3>Title: Cute-Lock: Behavioral and Structural Multi-Key Logic Locking Using Time Base Keys</h3>
<ul>
<li><strong>Authors: </strong>Kevin Lopez, Amin Rezaei</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17402">https://arxiv.org/abs/2501.17402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17402">https://arxiv.org/pdf/2501.17402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17402]] Cute-Lock: Behavioral and Structural Multi-Key Logic Locking Using Time Base Keys(https://arxiv.org/abs/2501.17402)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>The outsourcing of semiconductor manufacturing raises security risks, such as piracy and overproduction of hardware intellectual property. To overcome this challenge, logic locking has emerged to lock a given circuit using additional key bits. While single-key logic locking approaches have demonstrated serious vulnerability to a wide range of attacks, multi-key solutions, if carefully designed, can provide a reliable defense against not only oracle-guided logic attacks, but also removal and dataflow attacks. In this paper, using time base keys, we propose, implement and evaluate a family of secure multi-key logic locking algorithms called Cute-Lock that can be applied both in RTL-level behavioral and netlist-level structural representations of sequential circuits. Our extensive experimental results under a diverse range of attacks confirm that, compared to vulnerable state-of-the-art methods, employing the Cute-Lock family drives attacking attempts to a dead end without additional overhead.</li>
</ul>

<h3>Title: When Everyday Devices Become Weapons: A Closer Look at the Pager and Walkie-talkie Attacks</h3>
<ul>
<li><strong>Authors: </strong>Pantha Protim Sarker, Upoma Das, Nitin Varshney, Shang Shi, Akshay Kulkarni, Farimah Farahmandi, Mark Tehranipoor</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17405">https://arxiv.org/abs/2501.17405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17405">https://arxiv.org/pdf/2501.17405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17405]] When Everyday Devices Become Weapons: A Closer Look at the Pager and Walkie-talkie Attacks(https://arxiv.org/abs/2501.17405)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Battery-powered technologies like pagers and walkie-talkies have long been integral to civilian and military operations. However, the potential for such everyday devices to be weaponized has largely been underestimated in the realm of cybersecurity. In September 2024, Lebanon experienced a series of unprecedented, coordinated explosions triggered through compromised pagers and walkie-talkies, creating a new category of attack in the domain of cyber-physical warfare. This attack not only disrupted critical communication networks but also resulted in injuries, loss of life, and exposed significant national security vulnerabilities, prompting governments and organizations worldwide to reevaluate their cybersecurity frameworks. This article provides an in-depth investigation into the infamous Pager and Walkie-Talkie attacks, analyzing both technical and non-technical dimensions. Furthermore, the study extends its scope to explore vulnerabilities in other battery-powered infrastructures, such as battery management systems, highlighting their potential exploitation. Existing prevention and detection techniques are reviewed, with an emphasis on their limitations and the challenges they face in addressing emerging threats. Finally, the article discusses emerging methodologies, particularly focusing on the role of physical inspection, as a critical component of future security measures. This research aims to provide actionable insights to bolster the resilience of cyber-physical systems in an increasingly interconnected world.</li>
</ul>

<h3>Title: Fine-Grained 1-Day Vulnerability Detection in Binaries via Patch Code Localization</h3>
<ul>
<li><strong>Authors: </strong>Chaopeng Dong, Jingdong Guo, Shouguo Yang, Yang Xiao, Yi Li, Hong Li, Zhi Li, Limin Sun</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17413">https://arxiv.org/abs/2501.17413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17413">https://arxiv.org/pdf/2501.17413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17413]] Fine-Grained 1-Day Vulnerability Detection in Binaries via Patch Code Localization(https://arxiv.org/abs/2501.17413)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>1-day vulnerabilities in binaries have become a major threat to software security. Patch presence test is one of the effective ways to detect the vulnerability. However, existing patch presence test works do not perform well in practical scenarios due to the interference from the various compilers and optimizations, patch-similar code blocks, and irrelevant functions in stripped binaries. In this paper, we propose a novel approach named PLocator, which leverages stable values from both the patch code and its context, extracted from the control flow graph, to accurately locate the real patch code in the target function, offering a practical solution for real-world vulnerability detection scenarios. To evaluate the effectiveness of PLocator, we collected 73 CVEs and constructed two comprehensive datasets ($Dataset_{-irr}$ and $Dataset_{+irr}$), comprising 1,090 and 27,250 test cases at four compilation optimization levels and two compilers with three different experiments, i.e., Same, XO (cross-optimizations), and XC (cross-compilers). The results demonstrate that PLocator achieves an average TPR of 88.2% and FPR of 12.9% in a short amount of time, outperforming state-of-the-art approaches by 26.7% and 63.5%, respectively, indicating that PLocator is more practical for the 1-day vulnerability detection task.</li>
</ul>

<h3>Title: Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Li, Hirokazu Shirado, Sauvik Das</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17420">https://arxiv.org/abs/2501.17420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17420">https://arxiv.org/pdf/2501.17420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17420]] Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models(https://arxiv.org/abs/2501.17420)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating human behavior. To test this hypothesis, we propose a technique to systematically uncover such biases across a broad range of sociodemographic categories by assessing decision-making disparities among agents with LLM-generated, sociodemographically-informed personas. Using our technique, we tested six LLMs across three sociodemographic groups and four decision-making scenarios. Our results show that state-of-the-art LLMs exhibit significant sociodemographic disparities in nearly all simulations, with more advanced models exhibiting greater implicit biases despite reducing explicit biases. Furthermore, when comparing our findings to real-world disparities reported in empirical studies, we find that the biases we uncovered are directionally aligned but markedly amplified. This directional alignment highlights the utility of our technique in uncovering systematic biases in LLMs rather than random variations; moreover, the presence and amplification of implicit biases emphasizes the need for novel strategies to address these biases.</li>
</ul>

<h3>Title: SIGN: A Statistically-Informed Gaze Network for Gaze Time Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jianping Ye, Michel Wedel</a></li>
<li><strong>Subjects: </strong>cs.CV, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17422">https://arxiv.org/abs/2501.17422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17422">https://arxiv.org/pdf/2501.17422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17422]] SIGN: A Statistically-Informed Gaze Network for Gaze Time Prediction(https://arxiv.org/abs/2501.17422)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose a first version of SIGN, a Statistically-Informed Gaze Network, to predict aggregate gaze times on images. We develop a foundational statistical model for which we derive a deep learning implementation involving CNNs and Visual Transformers, which enables the prediction of overall gaze times. The model enables us to derive from the aggregate gaze times the underlying gaze pattern as a probability map over all regions in the image, where each region's probability represents the likelihood of being gazed at across all possible scan-paths. We test SIGN's performance on AdGaze3500, a dataset of images of ads with aggregate gaze times, and on COCO-Search18, a dataset with individual-level fixation patterns collected during search. We demonstrate that SIGN (1) improves gaze duration prediction significantly over state-of-the-art deep learning benchmarks on both datasets, and (2) can deliver plausible gaze patterns that correspond to empirical fixation patterns in COCO-Search18. These results suggest that the first version of SIGN holds promise for gaze-time predictions and deserves further development.</li>
</ul>

<h3>Title: Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs</h3>
<ul>
<li><strong>Authors: </strong>Ignatius Rollere, Caspian Hartsfield, Seraphina Courtenay, Lucian Fenwick, Aurelia Grunwald</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17429">https://arxiv.org/abs/2501.17429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17429">https://arxiv.org/pdf/2501.17429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17429]] Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs(https://arxiv.org/abs/2501.17429)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, segmentation</a></li>
<li><strong>Abstract: </strong>The rapid evolution of cyber threats has outpaced traditional detection methodologies, necessitating innovative approaches capable of addressing the adaptive and complex behaviors of modern adversaries. A novel framework was introduced, leveraging Temporal-Correlation Graphs to model the intricate relationships and temporal patterns inherent in malicious operations. The approach dynamically captured behavioral anomalies, offering a robust mechanism for distinguishing between benign and malicious activities in real-time scenarios. Extensive experiments demonstrated the framework's effectiveness across diverse ransomware families, with consistently high precision, recall, and overall detection accuracy. Comparative evaluations highlighted its better performance over traditional signature-based and heuristic methods, particularly in handling polymorphic and previously unseen ransomware variants. The architecture was designed with scalability and modularity in mind, ensuring compatibility with enterprise-scale environments while maintaining resource efficiency. Analysis of encryption speeds, anomaly patterns, and temporal correlations provided deeper insights into the operational strategies of ransomware, validating the framework's adaptability to evolving threats. The research contributes to advancing cybersecurity technologies by integrating dynamic graph analytics and machine learning for future innovations in threat detection. Results from this study underline the potential for transforming the way organizations detect and mitigate complex cyberattacks.</li>
</ul>

<h3>Title: Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation</h3>
<ul>
<li><strong>Authors: </strong>Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17433">https://arxiv.org/abs/2501.17433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17433">https://arxiv.org/pdf/2501.17433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17433]] Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation(https://arxiv.org/abs/2501.17433)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Recent research shows that Large Language Models (LLMs) are vulnerable to harmful fine-tuning attacks -- models lose their safety alignment ability after fine-tuning on a few harmful samples. For risk mitigation, a guardrail is typically used to filter out harmful samples before fine-tuning. By designing a new red-teaming method, we in this paper show that purely relying on the moderation guardrail for data filtration is not reliable. Our proposed attack method, dubbed Virus, easily bypasses the guardrail moderation by slightly modifying the harmful data. Experimental results show that the harmful data optimized by Virus is not detectable by the guardrail with up to 100\% leakage ratio, and can simultaneously achieve superior attack performance. Finally, the key message we want to convey through this paper is that: \textbf{it is reckless to consider guardrail moderation as a clutch at straws towards harmful fine-tuning attack}, as it cannot solve the inherent safety issue of the pre-trained LLMs. Our code is available at this https URL</li>
</ul>

<h3>Title: Towards Making Flowchart Images Machine Interpretable</h3>
<ul>
<li><strong>Authors: </strong>Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, Anand Mishra</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.DL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17441">https://arxiv.org/abs/2501.17441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17441">https://arxiv.org/pdf/2501.17441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17441]] Towards Making Flowchart Images Machine Interpretable(https://arxiv.org/abs/2501.17441)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Computer programming textbooks and software documentations often contain flowcharts to illustrate the flow of an algorithm or procedure. Modern OCR engines often tag these flowcharts as graphics and ignore them in further processing. In this paper, we work towards making flowchart images machine-interpretable by converting them to executable Python codes. To this end, inspired by the recent success in natural language to code generation literature, we present a novel transformer-based framework, namely FloCo-T5. Our model is well-suited for this task,as it can effectively learn semantics, structure, and patterns of programming languages, which it leverages to generate syntactically correct code. We also used a task-specific pre-training objective to pre-train FloCo-T5 using a large number of logic-preserving augmented code samples. Further, to perform a rigorous study of this problem, we introduce theFloCo dataset that contains 11,884 flowchart images and their corresponding Python codes. Our experiments show promising results, and FloCo-T5 clearly outperforms related competitive baselines on code generation metrics. We make our dataset and implementation publicly available.</li>
</ul>

<h3>Title: Cross-Language Approach for Quranic QA</h3>
<ul>
<li><strong>Authors: </strong>Islam Oshallah, Mohamed Basem, Ali Hamdi, Ammar Mohammed</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17449">https://arxiv.org/abs/2501.17449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17449">https://arxiv.org/pdf/2501.17449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17449]] Cross-Language Approach for Quranic QA(https://arxiv.org/abs/2501.17449)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Question answering systems face critical limitations in languages with limited resources and scarce data, making the development of robust models especially challenging. The Quranic QA system holds significant importance as it facilitates a deeper understanding of the Quran, a Holy text for over a billion people worldwide. However, these systems face unique challenges, including the linguistic disparity between questions written in Modern Standard Arabic and answers found in Quranic verses written in Classical Arabic, and the small size of existing datasets, which further restricts model performance. To address these challenges, we adopt a cross-language approach by (1) Dataset Augmentation: expanding and enriching the dataset through machine translation to convert Arabic questions into English, paraphrasing questions to create linguistic diversity, and retrieving answers from an English translation of the Quran to align with multilingual training requirements; and (2) Language Model Fine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base, DeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the specific requirements of Quranic QA. Experimental results demonstrate that this cross-language approach significantly improves model performance, with RoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while DeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These findings underscore the effectiveness of cross-language strategies in overcoming linguistic barriers and advancing Quranic QA systems</li>
</ul>

<h3>Title: Solving Inverse Problems using Diffusion with Fast Iterative Renoising</h3>
<ul>
<li><strong>Authors: </strong>Matt C. Bendel, Saurav K. Shastri, Rizwan Ahmad, Philip Schniter</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17468">https://arxiv.org/abs/2501.17468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17468">https://arxiv.org/pdf/2501.17468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17468]] Solving Inverse Problems using Diffusion with Fast Iterative Renoising(https://arxiv.org/abs/2501.17468)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Imaging inverse problems can be solved in an unsupervised manner using pre-trained diffusion models. In most cases, that involves approximating the gradient of the measurement-conditional score function in the reverse process. Since the approximations produced by existing methods are quite poor, especially early in the reverse process, we propose a new approach that re-estimates and renoises the image several times per diffusion step. Renoising adds carefully shaped colored noise that ensures the pre-trained diffusion model sees white-Gaussian error, in accordance with how it was trained. We demonstrate the effectiveness of our "DDfire" method at 20, 100, and 1000 neural function evaluations on linear inverse problems and phase retrieval.</li>
</ul>

<h3>Title: DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance</h3>
<ul>
<li><strong>Authors: </strong>Seffi Cohen, Niv Goldshlager, Nurit Cohen-Inger, Bracha Shapira, Lior Rokach</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17479">https://arxiv.org/abs/2501.17479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17479">https://arxiv.org/pdf/2501.17479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17479]] DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance(https://arxiv.org/abs/2501.17479)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities across various natural language processing tasks but often struggle to excel uniformly in diverse or complex domains. We propose a novel ensemble method - Diverse Fingerprint Ensemble (DFPE), which leverages the complementary strengths of multiple LLMs to achieve more robust performance. Our approach involves: (1) clustering models based on response "fingerprints" patterns, (2) applying a quantile-based filtering mechanism to remove underperforming models at a per-subject level, and (3) assigning adaptive weights to remaining models based on their subject-wise validation accuracy. In experiments on the Massive Multitask Language Understanding (MMLU) benchmark, DFPE outperforms the best single model by 3% overall accuracy and 5% in discipline-level accuracy. This method increases the robustness and generalization of LLMs and underscores how model selection, diversity preservation, and performance-driven weighting can effectively address challenging, multi-faceted language understanding tasks.</li>
</ul>

<h3>Title: DINT Transformer</h3>
<ul>
<li><strong>Authors: </strong>Yueyang Cang, Yuhang Liu, Xiaoteng Zhang, Erlu Zhao, Li Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17486">https://arxiv.org/abs/2501.17486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17486">https://arxiv.org/pdf/2501.17486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17486]] DINT Transformer(https://arxiv.org/abs/2501.17486)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>DIFF Transformer addresses the issue of irrelevant context interference by introducing a differential attention mechanism that enhances the robustness of local attention. However, it has two critical limitations: the lack of global context modeling, which is essential for identifying globally significant tokens, and numerical instability due to the absence of strict row normalization in the attention matrix. To overcome these challenges, we propose DINT Transformer, which extends DIFF Transformer by incorporating a differential-integral mechanism. By computing global importance scores and integrating them into the attention matrix, DINT Transformer improves its ability to capture global dependencies. Moreover, the unified parameter design enforces row-normalized attention matrices, improving numerical stability. Experimental results demonstrate that DINT Transformer excels in accuracy and robustness across various practical applications, such as long-context language modeling and key information retrieval. These results position DINT Transformer as a highly effective and promising architecture.</li>
</ul>

<h3>Title: How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning</h3>
<ul>
<li><strong>Authors: </strong>Fabio Salerno, Ali Al-Kaswan, Maliheh Izadi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17501">https://arxiv.org/abs/2501.17501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17501">https://arxiv.org/pdf/2501.17501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17501]] How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning(https://arxiv.org/abs/2501.17501)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction</a></li>
<li><strong>Abstract: </strong>Code language models, while widely popular, are often trained on unsanitized source code gathered from across the Internet. Previous work revealed that pre-trained models can remember the content of their training data and regurgitate them through data extraction attacks. Due to the large size of current models, only a few entities have the resources for pre-training such models. However, fine-tuning requires fewer resources and is increasingly used by both small and large entities for its effectiveness on specialized data. Such small curated data for fine-tuning might contain sensitive information or proprietary assets. In this study, we attack both pre-trained and fine-tuned code language models to investigate the extent of data extractability. We first develop a custom benchmark to assess the vulnerability of both pre-training and fine-tuning samples to extraction attacks. Our findings reveal that 54.9% of extractable pre-training data could be retrieved from StarCoder2-15B, whereas this number decreased to 23.5% after fine-tuning. This indicates that fine-tuning reduces the extractability of pre-training data. However, compared to larger models, fine-tuning smaller models increases their vulnerability to data extraction attacks on fine-tuning data. Given the potential sensitivity of fine-tuning data, this can lead to more severe consequences. Lastly, we also manually analyzed 2000 extractable samples before and after fine-tuning. We also found that data carriers and licensing information are the most likely data categories to be memorized from pre-trained and fine-tuned models, while the latter is the most likely to be forgotten after fine-tuning.</li>
</ul>

<h3>Title: LLM Assistance for Pediatric Depression</h3>
<ul>
<li><strong>Authors: </strong>Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17510">https://arxiv.org/abs/2501.17510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17510">https://arxiv.org/pdf/2501.17510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17510]] LLM Assistance for Pediatric Depression(https://arxiv.org/abs/2501.17510)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Traditional depression screening methods, such as the PHQ-9, are particularly challenging for children in pediatric primary care due to practical limitations. AI has the potential to help, but the scarcity of annotated datasets in mental health, combined with the computational costs of training, highlights the need for efficient, zero-shot approaches. In this work, we investigate the feasibility of state-of-the-art LLMs for depressive symptom extraction in pediatric settings (ages 6-24). This approach aims to complement traditional screening and minimize diagnostic errors. Our findings show that all LLMs are 60% more efficient than word match, with Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the extraction of more rare symptoms like "sleep problems" (F1: 0.92) and "self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and recall (0.60), performing well in categories like "Feeling depressed" (0.69) and "Weight change" (0.78). Llama 3, with the highest recall (0.90), overgeneralizes symptoms, making it less suitable for this type of analysis. Challenges include the complexity of clinical notes and overgeneralization from PHQ-9 scores. The main challenges faced by LLMs include navigating the complex structure of clinical notes with content from different times in the patient trajectory, as well as misinterpreting elevated PHQ-9 scores. We finally demonstrate the utility of symptom annotations provided by Flan as features in an ML algorithm, which differentiates depression cases from controls with high precision of 0.78, showing a major performance boost compared to a baseline that does not use these features.</li>
</ul>

<h3>Title: 3DSES: an indoor Lidar point cloud segmentation dataset with real and pseudo-labels from a 3D model</h3>
<ul>
<li><strong>Authors: </strong>Maxime Mérizette (GeF, CEDRIC - VERTIGO), Nicolas Audebert (CEDRIC - VERTIGO, CNAM, LaSTIG, IGN), Pierre Kervella (GeF), Jérôme Verdun (GeF)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17534">https://arxiv.org/abs/2501.17534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17534">https://arxiv.org/pdf/2501.17534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17534]] 3DSES: an indoor Lidar point cloud segmentation dataset with real and pseudo-labels from a 3D model(https://arxiv.org/abs/2501.17534)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of indoor point clouds has found various applications in the creation of digital twins for robotics, navigation and building information modeling (BIM). However, most existing datasets of labeled indoor point clouds have been acquired by photogrammetry. In contrast, Terrestrial Laser Scanning (TLS) can acquire dense sub-centimeter point clouds and has become the standard for surveyors. We present 3DSES (3D Segmentation of ESGT point clouds), a new dataset of indoor dense TLS colorized point clouds covering 427 m 2 of an engineering school. 3DSES has a unique double annotation format: semantic labels annotated at the point level alongside a full 3D CAD model of the building. We introduce a model-to-cloud algorithm for automated labeling of indoor point clouds using an existing 3D CAD model. 3DSES has 3 variants of various semantic and geometrical complexities. We show that our model-to-cloud alignment can produce pseudo-labels on our point clouds with a \&gt; 95% accuracy, allowing us to train deep models with significant time savings compared to manual labeling. First baselines on 3DSES show the difficulties encountered by existing models when segmenting objects relevant to BIM, such as light and safety utilities. We show that segmentation accuracy can be improved by leveraging pseudo-labels and Lidar intensity, an information rarely considered in current datasets. Code and data will be open sourced.</li>
</ul>

<h3>Title: Towards Supporting Penetration Testing Education with Large Language Models: an Evaluation and Comparison</h3>
<ul>
<li><strong>Authors: </strong>Martin Nizon-Deladoeuille, Brynjólfur Stefánsson, Helmut Neukirchen, Thomas Welsh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17539">https://arxiv.org/abs/2501.17539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17539">https://arxiv.org/pdf/2501.17539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17539]] Towards Supporting Penetration Testing Education with Large Language Models: an Evaluation and Comparison(https://arxiv.org/abs/2501.17539)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Cybersecurity education is challenging and it is helpful for educators to understand Large Language Models' (LLMs') capabilities for supporting education. This study evaluates the effectiveness of LLMs in conducting a variety of penetration testing tasks. Fifteen representative tasks were selected to cover a comprehensive range of real-world scenarios. We evaluate the performance of 6 models (GPT-4o mini, GPT-4o, Gemini 1.5 Flash, Llama 3.1 405B, Mixtral 8x7B and WhiteRabbitNeo) upon the Metasploitable v3 Ubuntu image and OWASP WebGOAT. Our findings suggest that GPT-4o mini currently offers the most consistent support making it a valuable tool for educational purposes. However, its use in conjonction with WhiteRabbitNeo should be considered, because of its innovative approach to tool and command recommendations. This study underscores the need for continued research into optimising LLMs for complex, domain-specific tasks in cybersecurity education.</li>
</ul>

<h3>Title: Towards Training-Free Open-World Classification with 3D Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Xinzhe Xia, Weiguang Zhao, Yuyao Yan, Guanyu Yang, Rui Zhang, Kaizhu Huang, Xi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17547">https://arxiv.org/abs/2501.17547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17547">https://arxiv.org/pdf/2501.17547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17547]] Towards Training-Free Open-World Classification with 3D Generative Models(https://arxiv.org/abs/2501.17547)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>3D open-world classification is a challenging yet essential task in dynamic and unstructured real-world scenarios, requiring both open-category and open-pose recognition. To address these challenges, recent wisdom often takes sophisticated 2D pre-trained models to provide enriched and stable representations. However, these methods largely rely on how 3D objects can be projected into 2D space, which is unfortunately not well solved, and thus significantly limits their performance. Unlike these present efforts, in this paper we make a pioneering exploration of 3D generative models for 3D open-world classification. Drawing on abundant prior knowledge from 3D generative models, we additionally craft a rotation-invariant feature extractor. This innovative synergy endows our pipeline with the advantages of being training-free, open-category, and pose-invariant, thus well suited to 3D open-world classification. Extensive experiments on benchmark datasets demonstrate the potential of generative models in 3D open-world classification, achieving state-of-the-art performance on ModelNet10 and McGill with 32.0% and 8.7% overall accuracy improvement, respectively.</li>
</ul>

<h3>Title: Understanding Trust in Authentication Methods for Icelandic Digital Public Services</h3>
<ul>
<li><strong>Authors: </strong>Brynjólfur Stefánsson, Ásta Guðrún Helgadóttir, Martin Nizon-Deladoeuille, Helmut Neukirchen, Thomas Welsh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17548">https://arxiv.org/abs/2501.17548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17548">https://arxiv.org/pdf/2501.17548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17548]] Understanding Trust in Authentication Methods for Icelandic Digital Public Services(https://arxiv.org/abs/2501.17548)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Digital public services have revolutionised citizen and private sector interactions with governments. Certain communities are strongly dependent on such digital services for ensuring the availability of public services due to geographical isolation or the presence of adverse geophysical and weather phenomena. However, strong and effective security is key to maintaining the integrity of public records and services yet also for ensuring trust in them. Trust is essential for user uptake, particularly given a global increase in data-protection concerns and a turbulent geopolitical security environment. In this paper, we examine the case of public trust in various forms of authentication for electronic identification in Iceland, which has high availability requirements for digital public services due to its unique and dynamic geophysical characteristics. Additionally, Iceland has historically low levels of institutional trust which may conflict with the requirement for an increased need for digital public services. Through surveying the Icelandic general public, we find that there is a high-level of trust in digital identification services across all demographics. We conclude with a discussion and future research challenges towards improving the effectiveness of authentication considering the diverse groups within Icelandic society, such as the rapidly increasing population of migrants and the large and dynamic population of tourists.</li>
</ul>

<h3>Title: Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wooyoung Kim, Byungyoon Park, Wooju Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17549">https://arxiv.org/abs/2501.17549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17549">https://arxiv.org/pdf/2501.17549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17549]] Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models(https://arxiv.org/abs/2501.17549)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graph-structured data plays a vital role in numerous domains, such as social networks, citation networks, commonsense reasoning graphs and knowledge graphs. While graph neural networks have been employed for graph processing, recent advancements have explored integrating large language models for graph-based tasks. In this paper, we propose a novel approach named Learnable Graph Pooling Token (LGPT), which addresses the limitations of the scalability issues in node-level projection and information loss in graph-level projection. LGPT enables flexible and efficient graph representation by introducing learnable parameters that act as tokens in large language models, balancing fine-grained and global graph information. Additionally, we investigate an Early Query Fusion technique, which fuses query context before constructing the graph representation, leading to more effective graph embeddings. Our method achieves a 4.13\% performance improvement on the GraphQA benchmark without training the large language model, demonstrating significant gains in handling complex textual-attributed graph data.</li>
</ul>

<h3>Title: Closing the Gap Between Synthetic and Ground Truth Time Series Distributions via Neural Mapping</h3>
<ul>
<li><strong>Authors: </strong>Daesoo Lee, Sara Malacarne, Erlend Aune</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17553">https://arxiv.org/abs/2501.17553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17553">https://arxiv.org/pdf/2501.17553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17553]] Closing the Gap Between Synthetic and Ground Truth Time Series Distributions via Neural Mapping(https://arxiv.org/abs/2501.17553)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce Neural Mapper for Vector Quantized Time Series Generator (NM-VQTSG), a novel method aimed at addressing fidelity challenges in vector quantized (VQ) time series generation. VQ-based methods, such as TimeVQVAE, have demonstrated success in generating time series but are hindered by two critical bottlenecks: information loss during compression into discrete latent spaces and deviations in the learned prior distribution from the ground truth distribution. These challenges result in synthetic time series with compromised fidelity and distributional accuracy. To overcome these limitations, NM-VQTSG leverages a U-Net-based neural mapping model to bridge the distributional gap between synthetic and ground truth time series. To be more specific, the model refines synthetic data by addressing artifacts introduced during generation, effectively aligning the distributions of synthetic and real data. Importantly, NM-VQTSG can be used for synthetic time series generated by any VQ-based generative method. We evaluate NM-VQTSG across diverse datasets from the UCR Time Series Classification archive, demonstrating its capability to consistently enhance fidelity in both unconditional and conditional generation tasks. The improvements are evidenced by significant improvements in FID, IS, and conditional FID, additionally backed up by visual inspection in a data space and a latent space. Our findings establish NM-VQTSG as a new method to improve the quality of synthetic time series. Our implementation is available on \url{this https URL}.</li>
</ul>

<h3>Title: An Exceptional Dataset For Rare Pancreatic Tumor Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Wenqi Li, Yingli Chen, Keyang Zhou, Xiaoxiao Hu, Zilu Zheng, Yue Yan, Xinpeng Zhang, Wei Tang, Zhenxing Qian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17555">https://arxiv.org/abs/2501.17555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17555">https://arxiv.org/pdf/2501.17555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17555]] An Exceptional Dataset For Rare Pancreatic Tumor Segmentation(https://arxiv.org/abs/2501.17555)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms that account for less than 5% of all pancreatic malignancies, with an incidence of only 1-1.5 cases per 100,000. Early detection of pNETs is critical for improving patient survival, but the rarity of pNETs makes segmenting them from CT a very challenging problem. So far, there has not been a dataset specifically for pNETs available to researchers. To address this issue, we propose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography (CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors, containing data from 469 patients. This is the first dataset solely dedicated to pNETs, distinguishing it from previous collections. Additionally, we provide the baseline detection networks with a new slice-wise weight loss function designed for the UNet-based model, improving the overall pNET segmentation performance. We hope that our dataset can enhance the understanding and diagnosis of pNET Tumors within the medical community, facilitate the development of more accurate diagnostic tools, and ultimately improve patient outcomes and advance the field of oncology.</li>
</ul>

<h3>Title: Histogram approaches for imbalanced data streams regression</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Aminian, Joao Gama, Rita P. Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17568">https://arxiv.org/abs/2501.17568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17568">https://arxiv.org/pdf/2501.17568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17568]] Histogram approaches for imbalanced data streams regression(https://arxiv.org/abs/2501.17568)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Handling imbalanced data streams in regression tasks presents a significant challenge, as rare instances can appear anywhere in the target distribution rather than being confined to its extreme values. In this paper, we introduce novel data-level sampling strategies, \texttt{HistUS} and \texttt{HistOS}, that utilize histogram-based approaches to dynamically balance data streams. Unlike previous methods based on Chebyshev\textquotesingle s inequality, our proposed techniques identify and handle rare cases across the entire distribution effectively. We demonstrate that \texttt{HistUS} and \texttt{HistOS} outperform traditional methods through extensive experiments on synthetic and real-world datasets, leading to more accurate and robust regression models in streaming environments.</li>
</ul>

<h3>Title: CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs</h3>
<ul>
<li><strong>Authors: </strong>Amey Hengle, Aswini Kumar, Anil Bandhakavi, Tanmoy Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17581">https://arxiv.org/abs/2501.17581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17581">https://arxiv.org/pdf/2501.17581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17581]] CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs(https://arxiv.org/abs/2501.17581)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Counterspeech has been popular as an effective approach to counter online hate speech, leading to increasing research interest in automated counterspeech generation using language models. However, this field lacks standardised evaluation protocols and robust automated evaluation metrics that align with human judgement. Current automatic evaluation methods, primarily based on similarity metrics, do not effectively capture the complex and independent attributes of counterspeech quality, such as contextual relevance, aggressiveness, or argumentative coherence. This has led to an increased dependency on labor-intensive human evaluations to assess automated counter-speech generation methods. To address these challenges, we introduce CSEval, a novel dataset and framework for evaluating counterspeech quality across four dimensions: contextual-relevance, aggressiveness, argument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated COT for Counterspeech Evaluation (ACE), a prompt-based method with auto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large language models. Our experiments show that ACE outperforms traditional metrics like ROUGE, METEOR, and BertScore in correlating with human judgement, indicating a significant advancement in automated counterspeech evaluation.</li>
</ul>

<h3>Title: Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Kunrong Li, Xinyu Liu, Zhen Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17598">https://arxiv.org/abs/2501.17598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17598">https://arxiv.org/pdf/2501.17598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17598]] Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis(https://arxiv.org/abs/2501.17598)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate sentiment analysis of texts is crucial for a variety of applications, such as understanding customer feedback, monitoring market trends, and detecting public sentiment. However, manually annotating large sentiment corpora for supervised learning is labor-intensive and time-consuming. Therefore, it is essential and effective to develop a semi-supervised method for the sentiment analysis task. Although some methods have been proposed for semi-supervised text classification, they rely on the intrinsic information within the unlabeled data and the learning capability of the NLP model, which lack generalization ability to the sentiment analysis scenario and may prone to overfit. Inspired by the ability of pretrained Large Language Models (LLMs) in following instructions and generating coherent text, we propose a Semantic Consistency Regularization with Large Language Models (SCR) framework for semi-supervised sentiment analysis. We introduce two prompting strategies to semantically enhance unlabeled text using LLMs. The first is Entity-based Enhancement (SCR-EE), which involves extracting entities and numerical information, and querying the LLM to reconstruct the textual information. The second is Concept-based Enhancement (SCR-CE), which directly queries the LLM with the original sentence for semantic reconstruction. Subsequently, the LLM-augmented data is utilized for a consistency loss with confidence thresholding, which preserves high-quality agreement samples to provide additional supervision signals during training. Furthermore, to fully utilize the uncertain unlabeled data samples, we propose a class re-assembling strategy inspired by the class space shrinking theorem. Experiments show our method achieves remarkable performance over prior semi-supervised methods.</li>
</ul>

<h3>Title: Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Teel, Jocasta Cumberbatch, Raphael Benington, Quentin Baskerville</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17617">https://arxiv.org/abs/2501.17617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17617">https://arxiv.org/pdf/2501.17617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17617]] Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment(https://arxiv.org/abs/2501.17617)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Extended sequence generation often leads to degradation in contextual consistency due to the inability of conventional self-attention mechanisms to effectively retain long-range dependencies. Existing approaches, including memory compression and retrieval-augmented conditioning, introduce computational trade-offs that either increase inference latency or impose additional storage overhead. Structured Context Recomposition (SCR) introduces a probabilistic layer realignment strategy that dynamically adjusts learned representations within transformer layers, ensuring that semantically relevant embeddings persist throughout extended transformations. The proposed method enhances coherence retention through a recursive weighting function that redistributes representational emphasis based on inferred contextual relevance rather than relying on fixed token-level attention scores. Empirical results indicate that probabilistic realignment mitigates abrupt topic shifts and logical inconsistencies, particularly in scenarios where sequences exceed standard attention window constraints. Sequence-level entropy analysis further reveals that SCR moderates representational variability without introducing excessive output regularization, allowing models to sustain generative diversity while preserving contextual alignment. Attention head deviation measurements confirm that hierarchical reweighting contributes to smoother token dependency transitions across transformer layers, reinforcing the stability of multi-turn interactions and document-level reasoning. Computational resource assessments show that while SCR incurs a moderate increase in processing time, memory overhead remains within feasible limits, making it suitable for practical deployment in autoregressive generative applications.</li>
</ul>

<h3>Title: Federated Learning With Individualized Privacy Through Client Sampling</h3>
<ul>
<li><strong>Authors: </strong>Lucas Lange, Ole Borchardt, Erhard Rahm</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17634">https://arxiv.org/abs/2501.17634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17634">https://arxiv.org/pdf/2501.17634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17634]] Federated Learning With Individualized Privacy Through Client Sampling(https://arxiv.org/abs/2501.17634)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>With growing concerns about user data collection, individualized privacy has emerged as a promising solution to balance protection and utility by accounting for diverse user privacy preferences. Instead of enforcing a uniform level of anonymization for all users, this approach allows individuals to choose privacy settings that align with their comfort levels. Building on this idea, we propose an adapted method for enabling Individualized Differential Privacy (IDP) in Federated Learning (FL) by handling clients according to their personal privacy preferences. By extending the SAMPLE algorithm from centralized settings to FL, we calculate client-specific sampling rates based on their heterogeneous privacy budgets and integrate them into a modified IDP-FedAvg algorithm. We test this method under realistic privacy distributions and multiple datasets. The experimental results demonstrate that our approach achieves clear improvements over uniform DP baselines, reducing the trade-off between privacy and utility. Compared to the alternative SCALE method in related work, which assigns differing noise scales to clients, our method performs notably better. However, challenges remain for complex tasks with non-i.i.d. data, primarily stemming from the constraints of the decentralized setting.</li>
</ul>

<h3>Title: In-Context Meta LoRA Generation</h3>
<ul>
<li><strong>Authors: </strong>Yihua Shao, Minxi Yan, Yang Liu, Siyu Chen, Wenjie Chen, Xinwei Long, Ziyang Yan, Lei Li, Chenyu Zhang, Nicu Sebe, Hao Tang, Yan Wang, Hao Zhao, Mengzhu Wang, Jingcai Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17635">https://arxiv.org/abs/2501.17635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17635">https://arxiv.org/pdf/2501.17635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17635]] In-Context Meta LoRA Generation(https://arxiv.org/abs/2501.17635)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task specific fine-tuning. However, in scenarios that involve multiple tasks, training a separate LoRA model for each one results in considerable inefficiency in terms of storage and inference. Moreover, existing parameter generation methods fail to capture the correlations among these tasks, making multi-task LoRA parameter generation challenging. To address these limitations, we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently achieves task-specific customization of large language models (LLMs). Specifically, we use training data from all tasks to train a tailored generator, Conditional Variational Autoencoder (CVAE). CVAE takes task descriptions as inputs and produces task-aware LoRA weights as outputs. These LoRA weights are then merged with LLMs to create task-specialized models without the need for additional fine-tuning. Furthermore, we utilize in-context meta-learning for knowledge enhancement and task mapping, to capture the relationship between tasks and parameter distributions. As a result, our method achieves more accurate LoRA parameter generation for diverse tasks using CVAE. ICM-LoRA enables more accurate LoRA parameter reconstruction than current parameter reconstruction methods and is useful for implementing task-specific enhancements of LoRA parameters. At the same time, our method occupies 283MB, only 1\% storage compared with the original LoRA.</li>
</ul>

<h3>Title: Efficient Interactive 3D Multi-Object Removal</h3>
<ul>
<li><strong>Authors: </strong>Jingcheng Ni, Weiguang Zhao, Daniel Wang, Ziyao Zeng, Chenyu You, Alex Wong, Kaizhu Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17636">https://arxiv.org/abs/2501.17636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17636">https://arxiv.org/pdf/2501.17636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17636]] Efficient Interactive 3D Multi-Object Removal(https://arxiv.org/abs/2501.17636)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Object removal is of great significance to 3D scene understanding, essential for applications in content filtering and scene editing. Current mainstream methods primarily focus on removing individual objects, with a few methods dedicated to eliminating an entire area or all objects of a certain category. They however confront the challenge of insufficient granularity and flexibility for real-world applications, where users demand tailored excision and preservation of objects within defined zones. In addition, most of the current methods require kinds of priors when addressing multi-view inpainting, which is time-consuming. To address these limitations, we propose an efficient and user-friendly pipeline for 3D multi-object removal, enabling users to flexibly select areas and define objects for removal or preservation. Concretely, to ensure object consistency and correspondence across multiple views, we propose a novel mask matching and refinement module, which integrates homography-based warping with high-confidence anchor points for segmentation. By leveraging the IoU joint shape context distance loss, we enhance the accuracy of warped masks and improve subsequent inpainting processes. Considering the current immaturity of 3D multi-object removal, we provide a new evaluation dataset to bridge the developmental void. Experimental results demonstrate that our method significantly reduces computational costs, achieving processing speeds more than 80% faster than state-of-the-art methods while maintaining equivalent or higher reconstruction quality.</li>
</ul>

<h3>Title: Efficient Redundancy Reduction for Open-Vocabulary Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lin Chen, Qi Yang, Kun Ding, Zhihao Li, Gang Shen, Fei Li, Qiyuan Cao, Shiming Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17642">https://arxiv.org/abs/2501.17642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17642">https://arxiv.org/pdf/2501.17642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17642]] Efficient Redundancy Reduction for Open-Vocabulary Semantic Segmentation(https://arxiv.org/abs/2501.17642)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary semantic segmentation (OVSS) is an open-world task that aims to assign each pixel within an image to a specific class defined by arbitrary text descriptions. Recent advancements in large-scale vision-language models have demonstrated their open-vocabulary understanding capabilities, significantly facilitating the development of OVSS. However, most existing methods suffer from either suboptimal performance or long latency. This study introduces ERR-Seg, a novel framework that effectively reduces redundancy to balance accuracy and efficiency. ERR-Seg incorporates a training-free Channel Reduction Module (CRM) that leverages prior knowledge from vision-language models like CLIP to identify the most relevant classes while discarding others. Moreover, it incorporates Efficient Semantic Context Fusion (ESCF) with spatial-level and class-level sequence reduction strategies. CRM and ESCF result in substantial memory and computational savings without compromising accuracy. Additionally, recognizing the significance of hierarchical semantics extracted from middle-layer features for closed-set semantic segmentation, ERR-Seg introduces the Hierarchical Semantic Module (HSM) to exploit hierarchical semantics in the context of OVSS. Compared to previous state-of-the-art methods under the ADE20K-847 setting, ERR-Seg achieves +$5.6\%$ mIoU improvement and reduces latency by $67.3\%$.</li>
</ul>

<h3>Title: Exploring Vision Language Models for Multimodal and Multilingual Stance Detection</h3>
<ul>
<li><strong>Authors: </strong>Jake Vasilakes, Carolina Scarton, Zhixue Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17654">https://arxiv.org/abs/2501.17654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17654">https://arxiv.org/pdf/2501.17654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17654]] Exploring Vision Language Models for Multimodal and Multilingual Stance Detection(https://arxiv.org/abs/2501.17654)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Social media's global reach amplifies the spread of information, highlighting the need for robust Natural Language Processing tasks like stance detection across languages and modalities. Prior research predominantly focuses on text-only inputs, leaving multimodal scenarios, such as those involving both images and text, relatively underexplored. Meanwhile, the prevalence of multimodal posts has increased significantly in recent years. Although state-of-the-art Vision-Language Models (VLMs) show promise, their performance on multimodal and multilingual stance detection tasks remains largely unexamined. This paper evaluates state-of-the-art VLMs on a newly extended dataset covering seven languages and multimodal inputs, investigating their use of visual cues, language-specific performance, and cross-modality interactions. Our results show that VLMs generally rely more on text than images for stance detection and this trend persists across languages. Additionally, VLMs rely significantly more on text contained within the images than other visual content. Regarding multilinguality, the models studied tend to generate consistent predictions across languages whether they are explicitly multilingual or not, although there are outliers that are incongruous with macro F1, language support, and model size.</li>
</ul>

<h3>Title: CAMP in the Odyssey: Provably Robust Reinforcement Learning with Certified Radius Maximization</h3>
<ul>
<li><strong>Authors: </strong>Derui Wang, Kristen Moore, Diksha Goel, Minjune Kim, Gang Li, Yang Li, Robin Doss, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17667">https://arxiv.org/abs/2501.17667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17667">https://arxiv.org/pdf/2501.17667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17667]] CAMP in the Odyssey: Provably Robust Reinforcement Learning with Certified Radius Maximization(https://arxiv.org/abs/2501.17667)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning (DRL) has gained widespread adoption in control and decision-making tasks due to its strong performance in dynamic environments. However, DRL agents are vulnerable to noisy observations and adversarial attacks, and concerns about the adversarial robustness of DRL systems have emerged. Recent efforts have focused on addressing these robustness issues by establishing rigorous theoretical guarantees for the returns achieved by DRL agents in adversarial settings. Among these approaches, policy smoothing has proven to be an effective and scalable method for certifying the robustness of DRL agents. Nevertheless, existing certifiably robust DRL relies on policies trained with simple Gaussian augmentations, resulting in a suboptimal trade-off between certified robustness and certified return. To address this issue, we introduce a novel paradigm dubbed \texttt{C}ertified-r\texttt{A}dius-\texttt{M}aximizing \texttt{P}olicy (\texttt{CAMP}) training. \texttt{CAMP} is designed to enhance DRL policies, achieving better utility without compromising provable robustness. By leveraging the insight that the global certified radius can be derived from local certified radii based on training-time statistics, \texttt{CAMP} formulates a surrogate loss related to the local certified radius and optimizes the policy guided by this surrogate loss. We also introduce \textit{policy imitation} as a novel technique to stabilize \texttt{CAMP} training. Experimental results demonstrate that \texttt{CAMP} significantly improves the robustness-return trade-off across various tasks. Based on the results, \texttt{CAMP} can achieve up to twice the certified expected return compared to that of baselines. Our code is available at this https URL.</li>
</ul>

<h3>Title: Explainable Artificial Intelligence for identifying profitability predictors in Financial Statements</h3>
<ul>
<li><strong>Authors: </strong>Marco Piazza, Mauro Passacantando, Francesca Magli, Federica Doni, Andrea Amaduzzi, Enza Messina</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17676">https://arxiv.org/abs/2501.17676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17676">https://arxiv.org/pdf/2501.17676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17676]] Explainable Artificial Intelligence for identifying profitability predictors in Financial Statements(https://arxiv.org/abs/2501.17676)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>The interconnected nature of the economic variables influencing a firm's performance makes the prediction of a company's earning trend a challenging task. Existing methodologies often rely on simplistic models and financial ratios failing to capture the complexity of interacting influences. In this paper, we apply Machine Learning techniques to raw financial statements data taken from AIDA, a Database comprising Italian listed companies' data from 2013 to 2022. We present a comparative study of different models and following the European AI regulations, we complement our analysis by applying explainability techniques to the proposed models. In particular, we propose adopting an eXplainable Artificial Intelligence method based on Game Theory to identify the most sensitive features and make the result more interpretable.</li>
</ul>

<h3>Title: ContourFormer:Real-Time Contour-Based End-to-End Instance Segmentation Transformer</h3>
<ul>
<li><strong>Authors: </strong>Weiwei yao, Chen Li, Minjun Xiong, Wenbo Dong, Hao Chen, Xiong Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17688">https://arxiv.org/abs/2501.17688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17688">https://arxiv.org/pdf/2501.17688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17688]] ContourFormer:Real-Time Contour-Based End-to-End Instance Segmentation Transformer(https://arxiv.org/abs/2501.17688)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents Contourformer, a real-time contour-based instance segmentation algorithm. The method is fully based on the DETR paradigm and achieves end-to-end inference through iterative and progressive mechanisms to optimize contours. To improve efficiency and accuracy, we develop two novel techniques: sub-contour decoupling mechanisms and contour fine-grained distribution this http URL the sub-contour decoupling mechanism, we propose a deformable attention-based module that adaptively selects sampling regions based on the current predicted contour, enabling more effective capturing of object boundary information. Additionally, we design a multi-stage optimization process to enhance segmentation precision by progressively refining sub-contours. The contour fine-grained distribution refinement technique aims to further improve the ability to express fine details of this http URL innovations enable Contourformer to achieve stable and precise segmentation for each instance while maintaining real-time performance. Extensive experiments demonstrate the superior performance of Contourformer on multiple benchmark datasets, including SBD, COCO, and KINS. We conduct comprehensive evaluations and comparisons with existing state-of-the-art methods, showing significant improvements in both accuracy and inference this http URL work provides a new solution for contour-based instance segmentation tasks and lays a foundation for future research, with the potential to become a strong baseline method in this field.</li>
</ul>

<h3>Title: Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment</h3>
<ul>
<li><strong>Authors: </strong>Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack, Allison Bean, Ryan Nussbaum, Maya Maurer, Emily Landis-Walkenhorst, Dinesh Kumbhare, Kang Kim, Ajay Wasan, Jiantao Pu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17690">https://arxiv.org/abs/2501.17690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17690">https://arxiv.org/pdf/2501.17690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17690]] Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment(https://arxiv.org/abs/2501.17690)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>We introduce a novel segmentation-aware joint training framework called generative reinforcement network (GRN) that integrates segmentation loss feedback to optimize both image generation and segmentation performance in a single stage. An image enhancement technique called segmentation-guided enhancement (SGE) is also developed, where the generator produces images tailored specifically for the segmentation model. Two variants of GRN were also developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The annotations included six anatomical structures: dermis, superficial fat, superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient (DSC) compared to models trained on fully labeled datasets. GRN-SEL alone reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling requirements by 70%, and GRN-SSL alone by 60%, all while maintaining performance comparable to fully supervised models. These findings suggest the effectiveness of the GRN framework in optimizing segmentation performance with significantly less labeled data, offering a scalable and efficient solution for ultrasound image analysis and reducing the burdens associated with data annotation.</li>
</ul>

<h3>Title: Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate</h3>
<ul>
<li><strong>Authors: </strong>Yubo Wang, Xiang Yue, Wenhu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17703">https://arxiv.org/abs/2501.17703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17703">https://arxiv.org/pdf/2501.17703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17703]] Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate(https://arxiv.org/abs/2501.17703)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Supervised Fine-Tuning (SFT) is commonly used to train language models to imitate annotated responses for given instructions. In this paper, we challenge this paradigm and propose Critique Fine-Tuning (CFT), a strategy where models learn to critique noisy responses rather than simply imitate correct ones. Inspired by human learning processes that emphasize critical thinking, CFT encourages deeper analysis and nuanced understanding-traits often overlooked by standard SFT. To validate the effectiveness of CFT, we construct a 50K-sample dataset from WebInstruct, using GPT-4o as the teacher to generate critiques in the form of (input=[query; noisy response], output=critique). CFT on this dataset yields a consistent 4-10% improvement over SFT on six math benchmarks with different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We further expand to MetaMath and NuminaMath datasets and observe similar gains over SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50K samples-matches or outperforms competitive models such as AceMath and Qwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples. Ablation studies show that CFT is robust to the source of noisy response and teacher critique model. Through these findings, we argue that critique-based training offers a more effective alternative to advance the reasoning of language models.</li>
</ul>

<h3>Title: STGCN-LSTM for Olympic Medal Prediction: Dynamic Power Modeling and Causal Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yiquan Wang, Jiaying Wang, Jingyi Yang, Zihao Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17711">https://arxiv.org/abs/2501.17711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17711">https://arxiv.org/pdf/2501.17711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17711]] STGCN-LSTM for Olympic Medal Prediction: Dynamic Power Modeling and Causal Policy Optimization(https://arxiv.org/abs/2501.17711)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a novel hybrid model, STGCN-LSTM, to forecast Olympic medal distributions by integrating the spatio-temporal relationships among countries and the long-term dependencies of national performance. The Spatial-Temporal Graph Convolution Network (STGCN) captures geographic and interactive factors-such as coaching exchange and socio-economic links-while the Long Short-Term Memory (LSTM) module models historical trends in medal counts, economic data, and demographics. To address zero-inflated outputs (i.e., the disparity between countries that consistently yield wins and those never having won medals), a Zero-Inflated Compound Poisson (ZICP) framework is incorporated to separate random zeros from structural zeros, providing a clearer view of potential breakthrough performances. Validation includes historical backtracking, policy shock simulations, and causal inference checks, confirming the robustness of the proposed method. Results shed light on the influence of coaching mobility, event specialization, and strategic investment on medal forecasts, offering a data-driven foundation for optimizing sports policies and resource allocation in diverse Olympic contexts.</li>
</ul>

<h3>Title: RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts</h3>
<ul>
<li><strong>Authors: </strong>Eujeong Choi, Younghun Jeong, Soomin Kim, Won Ik Cho</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17715">https://arxiv.org/abs/2501.17715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17715">https://arxiv.org/pdf/2501.17715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17715]] RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts(https://arxiv.org/abs/2501.17715)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>User interactions with conversational agents (CAs) evolve in the era of heavily guardrailed large language models (LLMs). As users push beyond programmed boundaries to explore and build relationships with these systems, there is a growing concern regarding the potential for unauthorized access or manipulation, commonly referred to as "jailbreaking." Moreover, with CAs that possess highly human-like qualities, users show a tendency toward initiating intimate sexual interactions or attempting to tame their chatbots. To capture and reflect these in-the-wild interactions into chatbot designs, we propose RICoTA, a Korean red teaming dataset that consists of 609 prompts challenging LLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We utilize user-chatbot conversations that were self-posted on a Korean Reddit-like community, containing specific testing and gaming intentions with a social chatbot. With these prompts, we aim to evaluate LLMs' ability to identify the type of conversation and users' testing purposes to derive chatbot design implications for mitigating jailbreaking risks. Our dataset will be made publicly available via GitHub.</li>
</ul>

<h3>Title: VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Sayeh Gholipour Picha, Dawood Al Chanti, Alice Caplier</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17726">https://arxiv.org/abs/2501.17726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17726">https://arxiv.org/pdf/2501.17726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17726]] VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback(https://arxiv.org/abs/2501.17726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, diffusion</a></li>
<li><strong>Abstract: </strong>As artificial intelligence (AI) becomes increasingly central to healthcare, the demand for explainable and trustworthy models is paramount. Current report generation systems for chest X-rays (CXR) often lack mechanisms for validating outputs without expert oversight, raising concerns about reliability and interpretability. To address these challenges, we propose a novel multimodal framework designed to enhance the semantic alignment and localization accuracy of AI-generated medical reports. Our framework integrates two key modules: a Phrase Grounding Model, which identifies and localizes pathologies in CXR images based on textual prompts, and a Text-to-Image Diffusion Module, which generates synthetic CXR images from prompts while preserving anatomical fidelity. By comparing features between the original and generated images, we introduce a dual-scoring system: one score quantifies localization accuracy, while the other evaluates semantic consistency. This approach significantly outperforms existing methods, achieving state-of-the-art results in pathology localization and text-to-image alignment. The integration of phrase grounding with diffusion models, coupled with the dual-scoring evaluation system, provides a robust mechanism for validating report quality, paving the way for more trustworthy and transparent AI in medical imaging.</li>
</ul>

<h3>Title: Sparse Autoencoders Can Interpret Randomly Initialized Transformers</h3>
<ul>
<li><strong>Authors: </strong>Thomas Heap, Tim Lawson, Lucy Farnik, Laurence Aitchison</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17727">https://arxiv.org/abs/2501.17727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17727">https://arxiv.org/pdf/2501.17727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17727]] Sparse Autoencoders Can Interpret Randomly Initialized Transformers(https://arxiv.org/abs/2501.17727)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) are an increasingly popular technique for interpreting the internal representations of transformers. In this paper, we apply SAEs to 'interpret' random transformers, i.e., transformers where the parameters are sampled IID from a Gaussian rather than trained on text data. We find that random and trained transformers produce similarly interpretable SAE latents, and we confirm this finding quantitatively using an open-source auto-interpretability pipeline. Further, we find that SAE quality metrics are broadly similar for random and trained transformers. We find that these results hold across model sizes and layers. We discuss a number of number interesting questions that this work raises for the use of SAEs and auto-interpretability in the context of mechanistic interpretability.</li>
</ul>

<h3>Title: BitMLx: Secure Cross-chain Smart Contracts For Bitcoin-style Cryptocurrencies</h3>
<ul>
<li><strong>Authors: </strong>Federico Badaloni, Sebastian Holler, Chrysoula Oikonomou, Pedro Moreno-Sanchez, Clara Schneidewind</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17733">https://arxiv.org/abs/2501.17733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17733">https://arxiv.org/pdf/2501.17733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17733]] BitMLx: Secure Cross-chain Smart Contracts For Bitcoin-style Cryptocurrencies(https://arxiv.org/abs/2501.17733)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>A smart contract is an interactive program that governs funds in the realm of a single cryptocurrency. Yet, the many existing cryptocurrencies have spurred the design of cross-chain applications that require interactions with multiple cryptocurrencies simultaneously. Currently, cross-chain applications are implemented as use-case-specific cryptographic protocols that serve as overlay to synchronize smart contract executions in the different cryptocurrencies. Hence, their design requires substantial expertise, as well as a security analysis in complex cryptographic frameworks. In this work, we present BitMLx, the first domain-specific language for cross-chain smart contracts, enabling interactions with several users that hold funds across multiple Bitcoin-like cryptocurrencies. We contribute a compiler to automatically translate a BitMLx contract into one contract per involved cryptocurrency and a user strategy that synchronizes the execution of these contracts. We prove that an honest user, who follows the prescribed strategy when interacting with the several contracts, ends up with at least as many funds as in the corresponding execution of the BitMLx contract. Last, but not least, we implement the BitMLx compiler and demonstrate its utility in the design of illustrative examples of cross-chain applications such as multi-chain donations or loans across different cryptocurrencies.</li>
</ul>

<h3>Title: Attacker Control and Bug Prioritization</h3>
<ul>
<li><strong>Authors: </strong>Guilhem Lacombe, Sébastien Bardin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17740">https://arxiv.org/abs/2501.17740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17740">https://arxiv.org/pdf/2501.17740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17740]] Attacker Control and Bug Prioritization(https://arxiv.org/abs/2501.17740)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>As bug-finding methods improve, bug-fixing capabilities are exceeded, resulting in an accumulation of potential vulnerabilities. There is thus a need for efficient and precise bug prioritization based on exploitability. In this work, we explore the notion of control of an attacker over a vulnerability's parameters, which is an often overlooked factor of exploitability. We show that taint as well as straightforward qualitative and quantitative notions of control are not enough to effectively differentiate vulnerabilities. Instead, we propose to focus analysis on feasible value sets, which we call domains of control, in order to better take into account threat models and expert insight. Our new Shrink and Split algorithm efficiently extracts domains of control from path constraints obtained with symbolic execution and renders them in an easily processed, human-readable form. This in turn allows to automatically compute more complex control metrics, such as weighted Quantitative Control, which factors in the varying threat levels of different values. Experiments show that our method is both efficient and precise. In particular, it is the only one able to distinguish between vulnerabilities such as cve-2019-14192 and cve-2022-30552, while revealing a mistake in the human evaluation of cve-2022-30790. The high degree of automation of our tool also brings us closer to a fully-automated evaluation pipeline.</li>
</ul>

<h3>Title: Dynamics of Transient Structure in In-Context Linear Regression Transformers</h3>
<ul>
<li><strong>Authors: </strong>Liam Carroll, Jesse Hoogland, Matthew Farrugia-Roberts, Daniel Murfet</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17745">https://arxiv.org/abs/2501.17745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17745">https://arxiv.org/pdf/2501.17745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17745]] Dynamics of Transient Structure in In-Context Linear Regression Transformers(https://arxiv.org/abs/2501.17745)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Modern deep neural networks display striking examples of rich internal computational structure. Uncovering principles governing the development of such structure is a priority for the science of deep learning. In this paper, we explore the transient ridge phenomenon: when transformers are trained on in-context linear regression tasks with intermediate task diversity, they initially behave like ridge regression before specializing to the tasks in their training distribution. This transition from a general solution to a specialized solution is revealed by joint trajectory principal component analysis. Further, we draw on the theory of Bayesian internal model selection to suggest a general explanation for the phenomena of transient structure in transformers, based on an evolving tradeoff between loss and complexity. This explanation is grounded in empirical measurements of model complexity using the local learning coefficient.</li>
</ul>

<h3>Title: Investigating Vulnerability Disclosures in Open-Source Software Using Bug Bounty Reports and Security Advisories</h3>
<ul>
<li><strong>Authors: </strong>Jessy Ayala, Yu-Jye Tung, Joshua Garcia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17748">https://arxiv.org/abs/2501.17748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17748">https://arxiv.org/pdf/2501.17748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17748]] Investigating Vulnerability Disclosures in Open-Source Software Using Bug Bounty Reports and Security Advisories(https://arxiv.org/abs/2501.17748)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>In the world of open-source software (OSS), the number of known vulnerabilities has tremendously increased. The GitHub Advisory Database contains advisories for security risks in GitHub-hosted OSS projects. As of 09/25/2023, there are 197,609 unreviewed GitHub security advisories. Of those unreviewed, at least 63,852 are publicly documented vulnerabilities, potentially leaving many OSS projects vulnerable. Recently, bug bounty platforms have emerged to focus solely on providing bounties to help secure OSS. In this paper, we conduct an empirical study on 3,798 reviewed GitHub security advisories and 4,033 disclosed OSS bug bounty reports, a perspective that is currently understudied, because they contain comprehensive information about security incidents, e.g., the nature of vulnerabilities, their impact, and how they were resolved. We are the first to determine the explicit process describing how OSS vulnerabilities propagate from security advisories and bug bounty reports, which are the main intermediaries between vulnerability reporters, OSS maintainers, and dependent projects, to vulnerable OSS projects and entries in global vulnerability databases and possibly back. This process uncovers how missing or delayed CVE assignments for OSS vulnerabilities result in projects, both in and out of OSS, not being notified of necessary security updates promptly and corresponding bottlenecks. Based on our findings, we provide suggestions, actionable items, and future research directions to help improve the security posture of OSS projects.</li>
</ul>

<h3>Title: Privacy Audit as Bits Transmission: (Im)possibilities for Audit by One Run</h3>
<ul>
<li><strong>Authors: </strong>Zihang Xiang, Tianhao Wang, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17750">https://arxiv.org/abs/2501.17750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17750">https://arxiv.org/pdf/2501.17750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17750]] Privacy Audit as Bits Transmission: (Im)possibilities for Audit by One Run(https://arxiv.org/abs/2501.17750)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Auditing algorithms' privacy typically involves simulating a game-based protocol that guesses which of two adjacent datasets was the original input. Traditional approaches require thousands of such simulations, leading to significant computational overhead. Recent methods propose single-run auditing of the target algorithm to address this, substantially reducing computational cost. However, these methods' general applicability and tightness in producing empirical privacy guarantees remain uncertain. This work studies such problems in detail. Our contributions are twofold: First, we introduce a unifying framework for privacy audits based on information-theoretic principles, modeling the audit as a bit transmission problem in a noisy channel. This formulation allows us to derive fundamental limits and develop an audit approach that yields tight privacy lower bounds for various DP protocols. Second, leveraging this framework, we demystify the method of privacy audit by one run, identifying the conditions under which single-run audits are feasible or infeasible. Our analysis provides general guidelines for conducting privacy audits and offers deeper insights into the privacy audit. Finally, through experiments, we demonstrate that our approach produces tighter privacy lower bounds on common differentially private mechanisms while requiring significantly fewer observations. We also provide a case study illustrating that our method successfully detects privacy violations in flawed implementations of private algorithms.</li>
</ul>

<h3>Title: Unraveling Log4Shell: Analyzing the Impact and Response to the Log4j Vulnerabil</h3>
<ul>
<li><strong>Authors: </strong>John Doll, Carson McCarthy, Hannah McDougall, Suman Bhunia</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17760">https://arxiv.org/abs/2501.17760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17760">https://arxiv.org/pdf/2501.17760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17760]] Unraveling Log4Shell: Analyzing the Impact and Response to the Log4j Vulnerabil(https://arxiv.org/abs/2501.17760)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>The realm of technology frequently confronts threats posed by adversaries exploiting loopholes in programs. Among these, the Log4Shell vulnerability in the Log4j library stands out due to its widespread impact. Log4j, a prevalent software library for log recording, is integrated into millions of devices worldwide. The Log4Shell vulnerability facilitates remote code execution with relative ease. Its combination with the extensive utilization of Log4j marks it as one of the most dangerous vulnerabilities discovered to date. The severity of this vulnerability, which quickly escalated into a media frenzy, prompted swift action within the industry, thereby mitigating potential extensive damage. This rapid response was crucial, as the consequences could have been significantly more severe if the vulnerability had been exploited by adversaries prior to its public disclosure. This paper details the discovery of the Log4Shell vulnerability and its potential for exploitation. It examines the vulnerability's impact on various stakeholders, including governments, the Apache Software Foundation (which manages the Log4j library), and companies affected by it. The paper also describes strategies for defending against Log4Shell in several scenarios. While numerous Log4j users acted promptly to safeguard their systems, the vulnerability remains a persistent threat until all vulnerable instances of the library are adequately protected.</li>
</ul>

<h3>Title: Improving Privacy Benefits of Redaction</h3>
<ul>
<li><strong>Authors: </strong>Vaibhav Gusain, Douglas Leith</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17762">https://arxiv.org/abs/2501.17762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17762">https://arxiv.org/pdf/2501.17762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17762]] Improving Privacy Benefits of Redaction(https://arxiv.org/abs/2501.17762)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We propose a novel redaction methodology that can be used to sanitize natural text data. Our new technique provides better privacy benefits than other state of the art techniques while maintaining lower redaction levels.</li>
</ul>

<h3>Title: Hybrid Graphs for Table-and-Text based Question Answering using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17767">https://arxiv.org/abs/2501.17767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17767">https://arxiv.org/pdf/2501.17767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17767]] Hybrid Graphs for Table-and-Text based Question Answering using LLMs(https://arxiv.org/abs/2501.17767)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Answering questions that require reasoning and aggregation across both structured (tables) and unstructured (raw text) data sources presents significant challenges. Current methods rely on fine-tuning and high-quality, human-curated data, which is difficult to obtain. Recent advances in Large Language Models (LLMs) have shown promising results for multi-hop question answering (QA) over single-source text data in a zero-shot setting, yet exploration into multi-source Table-Text QA remains limited. In this paper, we present a novel Hybrid Graph-based approach for Table-Text QA that leverages LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from textual and tabular data, pruning information based on the input question to provide the LLM with relevant context concisely. We evaluate our approach on the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs, including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot performance on both datasets, improving Exact Match scores by up to 10% on Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up to 53% compared to the original context.</li>
</ul>

<h3>Title: Generative Unordered Flow for Set-Structured Data Generation</h3>
<ul>
<li><strong>Authors: </strong>Yangming Li, Carola-Bibiane Schönlieb</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17770">https://arxiv.org/abs/2501.17770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17770">https://arxiv.org/pdf/2501.17770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17770]] Generative Unordered Flow for Set-Structured Data Generation(https://arxiv.org/abs/2501.17770)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Flow-based generative models have demonstrated promising performance across a broad spectrum of data modalities (e.g., image and text). However, there are few works exploring their extension to unordered data (e.g., spatial point set), which is not trivial because previous models are mostly designed for vector data that are naturally ordered. In this paper, we present unordered flow, a type of flow-based generative model for set-structured data generation. Specifically, we convert unordered data into an appropriate function representation, and learn the probability measure of such representations through function-valued flow matching. For the inverse map from a function representation to unordered data, we propose a method similar to particle filtering, with Langevin dynamics to first warm-up the initial particles and gradient-based search to update them until convergence. We have conducted extensive experiments on multiple real-world datasets, showing that our unordered flow model is very effective in generating set-structured data and significantly outperforms previous baselines.</li>
</ul>

<h3>Title: 2SSP: A Two-Stage Framework for Structured Pruning of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17771">https://arxiv.org/abs/2501.17771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17771">https://arxiv.org/pdf/2501.17771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17771]] 2SSP: A Two-Stage Framework for Structured Pruning of LLMs(https://arxiv.org/abs/2501.17771)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We propose a novel Two-Stage framework for Structured Pruning (2SSP) for pruning Large Language Models (LLMs), which combines two different strategies of pruning, namely Width and Depth Pruning. The first stage (Width Pruning) removes entire neurons, hence their corresponding rows and columns, aiming to preserve the connectivity among the pruned structures in the intermediate state of the Feed-Forward Networks in each Transformer block. This is done based on an importance score measuring the impact of each neuron over the output magnitude. The second stage (Depth Pruning), instead, removes entire Attention submodules. This is done by applying an iterative process that removes the Attention submodules with the minimum impact on a given metric of interest (in our case, perplexity). We also propose a novel mechanism to balance the sparsity rate of the two stages w.r.t. to the desired global sparsity. We test 2SSP on four LLM families and three sparsity rates (25\%, 37.5\%, and 50\%), measuring the resulting perplexity over three language modeling datasets as well as the performance over six downstream tasks. Our method consistently outperforms five state-of-the-art competitors over three language modeling and six downstream tasks, with an up to two-order-of-magnitude gain in terms of pruning time. The code is available at available at \url{this https URL}.</li>
</ul>

<h3>Title: AdditiveLLM: Large Language Models Predict Defects in Additive Manufacturing</h3>
<ul>
<li><strong>Authors: </strong>Peter Pak, Amir Barati Farimani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17784">https://arxiv.org/abs/2501.17784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17784">https://arxiv.org/pdf/2501.17784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17784]] AdditiveLLM: Large Language Models Predict Defects in Additive Manufacturing(https://arxiv.org/abs/2501.17784)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In this work we investigate the ability of large language models to predict additive manufacturing defect regimes given a set of process parameter inputs. For this task we utilize a process parameter defect dataset to fine-tune a collection of models, titled AdditiveLLM, for the purpose of predicting potential defect regimes including Keyholing, Lack of Fusion, and Balling. We compare different methods of input formatting in order to gauge the model's performance to correctly predict defect regimes on our sparse Baseline dataset and our natural language Prompt dataset. The model displays robust predictive capability, achieving an accuracy of 93\% when asked to provide the defect regimes associated with a set of process parameters. The incorporation of natural language input further simplifies the task of process parameters selection, enabling users to identify optimal settings specific to their build.</li>
</ul>

<h3>Title: Atomic Transfer Graphs: Secure-by-design Protocols for Heterogeneous Blockchain Ecosystems</h3>
<ul>
<li><strong>Authors: </strong>Stephan Dübler, Federico Badaloni, Pedro Moreno-Sanchez, Clara Schneidewind</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17786">https://arxiv.org/abs/2501.17786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17786">https://arxiv.org/pdf/2501.17786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17786]] Atomic Transfer Graphs: Secure-by-design Protocols for Heterogeneous Blockchain Ecosystems(https://arxiv.org/abs/2501.17786)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The heterogeneity of the blockchain landscape has motivated the design of blockchain protocols tailored to specific blockchains and applications that, hence, require custom security proofs. We observe that many blockchain protocols share common security and functionality goals, which can be captured by an atomic transfer graph (ATG) describing the structure of desired transfers. Based on this observation, we contribute a framework for generating secure-by-design protocols that realize these goals. The resulting protocols build upon Conditional Timelock Contracts (CTLCs), a novel minimal smart contract functionality that can be implemented in a large variety of cryptocurrencies with a restricted scripting language (e.g., Bitcoin), and payment channels. We show how ATGs, in addition to enabling novel applications, capture the security and functionality goals of existing applications, including many examples from payment channel networks and complex multi-party cross-currency swaps among Ethereum-style cryptocurrencies. Our framework is the first to provide generic and provably secure protocols for all these use cases while matching or improving the performance of existing use-case-specific protocols.</li>
</ul>

<h3>Title: BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights</h3>
<ul>
<li><strong>Authors: </strong>Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17790">https://arxiv.org/abs/2501.17790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17790">https://arxiv.org/pdf/2501.17790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17790]] BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights(https://arxiv.org/abs/2501.17790)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted for Taiwanese Mandarin, highlighting phonetic control abilities to address the unique challenges of polyphone disambiguation in the language. Building upon CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an optimal-transport conditional flow matching model (OT-CFM), and a grapheme to phoneme prediction model, to generate realistic speech that closely mimics human utterances. Our evaluation demonstrates BreezyVoice's superior performance in both general and code-switching contexts, highlighting its robustness and effectiveness in generating high-fidelity speech. Additionally, we address the challenges of generalizability in modeling long-tail speakers and polyphone disambiguation. Our approach significantly enhances performance and offers valuable insights into the workings of neural codec TTS systems.</li>
</ul>

<h3>Title: P-TAME: Explain Any Image Classifier with Trained Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17813">https://arxiv.org/abs/2501.17813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17813">https://arxiv.org/pdf/2501.17813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17813]] P-TAME: Explain Any Image Classifier with Trained Perturbations(https://arxiv.org/abs/2501.17813)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>The adoption of Deep Neural Networks (DNNs) in critical fields where predictions need to be accompanied by justifications is hindered by their inherent black-box nature. In this paper, we introduce P-TAME (Perturbation-based Trainable Attention Mechanism for Explanations), a model-agnostic method for explaining DNN-based image classifiers. P-TAME employs an auxiliary image classifier to extract features from the input image, bypassing the need to tailor the explanation method to the internal architecture of the backbone classifier being explained. Unlike traditional perturbation-based methods, which have high computational requirements, P-TAME offers an efficient alternative by generating high-resolution explanations in a single forward pass during inference. We apply P-TAME to explain the decisions of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image classifiers. Quantitative and qualitative results show that our method matches or outperforms previous explainability methods, including model-specific approaches. Code and trained models will be released upon acceptance.</li>
</ul>

<h3>Title: SSF: Sparse Long-Range Scene Flow for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Ajinkya Khoche, Qingwen Zhang, Laura Pereira Sanchez, Aron Asefaw, Sina Sharif Mansouri, Patric Jensfelt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17821">https://arxiv.org/abs/2501.17821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17821">https://arxiv.org/pdf/2501.17821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17821]] SSF: Sparse Long-Range Scene Flow for Autonomous Driving(https://arxiv.org/abs/2501.17821)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Scene flow enables an understanding of the motion characteristics of the environment in the 3D world. It gains particular significance in the long-range, where object-based perception methods might fail due to sparse observations far away. Although significant advancements have been made in scene flow pipelines to handle large-scale point clouds, a gap remains in scalability with respect to long-range. We attribute this limitation to the common design choice of using dense feature grids, which scale quadratically with range. In this paper, we propose Sparse Scene Flow (SSF), a general pipeline for long-range scene flow, adopting a sparse convolution based backbone for feature extraction. This approach introduces a new challenge: a mismatch in size and ordering of sparse feature maps between time-sequential point scans. To address this, we propose a sparse feature fusion scheme, that augments the feature maps with virtual voxels at missing locations. Additionally, we propose a range-wise metric that implicitly gives greater importance to faraway points. Our method, SSF, achieves state-of-the-art results on the Argoverse2 dataset, demonstrating strong performance in long-range scene flow estimation. Our code will be released at this https URL.</li>
</ul>

<h3>Title: U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>Md Kaykobad Reza, Niki Nezakati, Ameya Patil, Mashhour Solh, M. Salman Asif</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17823">https://arxiv.org/abs/2501.17823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17823">https://arxiv.org/pdf/2501.17823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17823]] U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning(https://arxiv.org/abs/2501.17823)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal learning often relies on designing new models and complex training strategies to achieve optimal performance. We present Unified Unimodal Adaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using low-rank adaptation (LoRA) for various multimodal tasks. Our method significantly reduces the number of learnable parameters and eliminates the need for complex training strategies, such as alternating training, gradient modifications, or unimodal fine-tuning. To address missing modalities during both training and testing, we introduce Mask Tokens (MT), which generate missing modality features from available modalities using a single token per modality. This simplifies the process, removing the need for specialized feature estimation or prompt-tuning methods. Our evaluation demonstrates that U2A matches or outperforms state-of-the-art methods in both complete and missing modality settings, showcasing strong performance and robustness across various modalities, tasks, and datasets. We also analyze and report the effectiveness of Mask Tokens in different missing modality scenarios. Overall, our method provides a robust, flexible, and efficient solution for multimodal learning, with minimal computational overhead.</li>
</ul>

<h3>Title: SMT-Boosted Security Types for Low-Level MPC</h3>
<ul>
<li><strong>Authors: </strong>Christian Skalka, Joseph P. Near</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17824">https://arxiv.org/abs/2501.17824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17824">https://arxiv.org/pdf/2501.17824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17824]] SMT-Boosted Security Types for Low-Level MPC(https://arxiv.org/abs/2501.17824)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>Secure Multi-Party Computation (MPC) is an important enabling technology for data privacy in modern distributed applications. We develop a new type theory to automatically enforce correctness,confidentiality, and integrity properties of protocols written in the \emph{Prelude/Overture} language framework. Judgements in the type theory are predicated on SMT verifications in a theory of finite fields, which supports precise and efficient analysis. Our approach is automated, compositional, scalable, and generalizes to arbitrary prime fields for data and key sizes.</li>
</ul>

<h3>Title: Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning</h3>
<ul>
<li><strong>Authors: </strong>Haque Ishfaq, Guangyuan Wang, Sami Nur Islam, Doina Precup</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17827">https://arxiv.org/abs/2501.17827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17827">https://arxiv.org/pdf/2501.17827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17827]] Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning(https://arxiv.org/abs/2501.17827)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Existing actor-critic algorithms, which are popular for continuous control reinforcement learning (RL) tasks, suffer from poor sample efficiency due to lack of principled exploration mechanism within them. Motivated by the success of Thompson sampling for efficient exploration in RL, we propose a novel model-free RL algorithm, Langevin Soft Actor Critic (LSAC), which prioritizes enhancing critic learning through uncertainty estimation over policy optimization. LSAC employs three key innovations: approximate Thompson sampling through distributional Langevin Monte Carlo (LMC) based $Q$ updates, parallel tempering for exploring multiple modes of the posterior of the $Q$ function, and diffusion synthesized state-action samples regularized with $Q$ action gradients. Our extensive experiments demonstrate that LSAC outperforms or matches the performance of mainstream model-free RL algorithms for continuous control tasks. Notably, LSAC marks the first successful application of an LMC based Thompson sampling in continuous control tasks with continuous action spaces.</li>
</ul>

<h3>Title: A Comprehensive Survey on Legal Summarization: Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Mousumi Akter, Erion Cano, Erik Weber, Dennis Dobler, Ivan Habernal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17830">https://arxiv.org/abs/2501.17830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17830">https://arxiv.org/pdf/2501.17830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17830]] A Comprehensive Survey on Legal Summarization: Challenges and Future Directions(https://arxiv.org/abs/2501.17830)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This article provides a systematic up-to-date survey of automatic summarization techniques, datasets, models, and evaluation methods in the legal domain. Through specific source selection criteria, we thoroughly review over 120 papers spanning the modern `transformer' era of natural language processing (NLP), thus filling a gap in existing systematic surveys on the matter. We present existing research along several axes and discuss trends, challenges, and opportunities for future research.</li>
</ul>

<h3>Title: Hierarchical Fallback Architecture for High Risk Online Machine Learning Inference</h3>
<ul>
<li><strong>Authors: </strong>Gustavo Polleti, Marlesson Santana, Felipe Sassi Del Sant, Eduardo Fontes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17834">https://arxiv.org/abs/2501.17834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17834">https://arxiv.org/pdf/2501.17834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17834]] Hierarchical Fallback Architecture for High Risk Online Machine Learning Inference(https://arxiv.org/abs/2501.17834)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Open Banking powered machine learning applications require novel robustness approaches to deal with challenging stress and failure scenarios. In this paper we propose an hierarchical fallback architecture for improving robustness in high risk machine learning applications with a focus in the financial domain. We define generic failure scenarios often found in online inference that depend on external data providers and we describe in detail how to apply the hierarchical fallback architecture to address them. Finally, we offer a real world example of its applicability in the industry for near-real time transactional fraud risk evaluation using Open Banking data and under extreme stress scenarios.</li>
</ul>

<h3>Title: Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?</h3>
<ul>
<li><strong>Authors: </strong>Pouya Pezeshkpour, Estevam Hruschka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17840">https://arxiv.org/abs/2501.17840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17840">https://arxiv.org/pdf/2501.17840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17840]] Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?(https://arxiv.org/abs/2501.17840)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable performance on various tasks, yet their ability to extract and internalize deeper insights from domain-specific datasets remains underexplored. In this study, we investigate how continual pre-training can enhance LLMs' capacity for insight learning across three distinct forms: declarative, statistical, and probabilistic insights. Focusing on two critical domains: medicine and finance, we employ LoRA to train LLMs on two existing datasets. To evaluate each insight type, we create benchmarks to measure how well continual pre-training helps models go beyond surface-level knowledge. We also assess the impact of document modification on capturing insights. The results show that, while continual pre-training on original documents has a marginal effect, modifying documents to retain only essential information significantly enhances the insight-learning capabilities of LLMs.</li>
</ul>

<h3>Title: Improving Your Model Ranking on Chatbot Arena by Vote Rigging</h3>
<ul>
<li><strong>Authors: </strong>Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17858">https://arxiv.org/abs/2501.17858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17858">https://arxiv.org/pdf/2501.17858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17858]] Improving Your Model Ranking on Chatbot Arena by Vote Rigging(https://arxiv.org/abs/2501.17858)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, watermark</a></li>
<li><strong>Abstract: </strong>Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles, where users vote for their preferred response from two randomly sampled anonymous models. While Chatbot Arena is widely regarded as a reliable LLM ranking leaderboard, we show that crowdsourced voting can be rigged to improve (or decrease) the ranking of a target model $m_{t}$. We first introduce a straightforward target-only rigging strategy that focuses on new battles involving $m_{t}$, identifying it via watermarking or a binary classifier, and exclusively voting for $m_{t}$ wins. However, this strategy is practically inefficient because there are over $190$ models on Chatbot Arena and on average only about $1\%$ of new battles will involve $m_{t}$. To overcome this, we propose omnipresent rigging strategies, exploiting the Elo rating mechanism of Chatbot Arena that any new vote on a battle can influence the ranking of the target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle. We conduct experiments on around $1.7$ million historical votes from the Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve model rankings by rigging only hundreds of new votes. While we have evaluated several defense mechanisms, our findings highlight the importance of continued efforts to prevent vote rigging. Our code is available at this https URL.</li>
</ul>

<h3>Title: Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations</h3>
<ul>
<li><strong>Authors: </strong>Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17860">https://arxiv.org/abs/2501.17860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17860">https://arxiv.org/pdf/2501.17860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17860]] Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations(https://arxiv.org/abs/2501.17860)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current medical AI systems often fail to replicate real-world clinical reasoning, as they are predominantly trained and evaluated on static text and question-answer tasks. These tuning methods and benchmarks overlook critical aspects like evidence-based reasoning and handling distracting information. To bridge this gap, we introduce a novel benchmark that simulates real-world diagnostic scenarios, integrating noise and difficulty levels aligned with USMLE standards. Moreover, we explore dialogue-based fine-tuning, which transforms static datasets into conversational formats to better capture iterative reasoning processes. Experiments show that dialogue-tuned models outperform traditional methods, with improvements of $9.64\%$ in multi-round reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our findings highlight dialogue tuning as a promising approach for advancing clinically aligned and robust medical AI systems.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
