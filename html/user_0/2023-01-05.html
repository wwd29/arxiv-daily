<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Cheesecloth: Zero-Knowledge Proofs of Real-World Vulnerabilities. (arXiv:2301.01321v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01321">http://arxiv.org/abs/2301.01321</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01321] Cheesecloth: Zero-Knowledge Proofs of Real-World Vulnerabilities](http://arxiv.org/abs/2301.01321) #security</code></li>
<li>Summary: <p>Currently, when a security analyst discovers a vulnerability in critical
software system, they must navigate a fraught dilemma: immediately disclosing
the vulnerability to the public could harm the system's users; whereas
disclosing the vulnerability only to the software's vendor lets the vendor
disregard or deprioritize the security risk, to the detriment of
unwittingly-affected users. A compelling recent line of work aims to resolve
this by using Zero Knowledge (ZK) protocols that let analysts prove that they
know a vulnerability in a program, without revealing the details of the
vulnerability or the inputs that exploit it. In principle, this could be
achieved by generic ZK techniques. In practice, ZK vulnerability proofs to date
have been restricted in scope and expressibility, due to challenges related to
generating proof statements that model real-world software at scale and to
directly formulating violated properties. This paper presents CHEESECLOTH, a
novel proofstatement compiler, which proves practical vulnerabilities in ZK by
soundly-but-aggressively preprocessing programs on public inputs, selectively
revealing information about executed control segments, and formalizing
information leakage using a novel storage-labeling scheme. CHEESECLOTH's
practicality is demonstrated by generating ZK proofs of well-known
vulnerabilities in (previous versions of) critical software, including the
Heartbleed information leakage in OpenSSL and a memory vulnerability in the
FFmpeg graphics framework.
</p></li>
</ul>

<h3>Title: Post-Quantum Key Agreement Protocol based on Non-Square Integer Matrices. (arXiv:2301.01586v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01586">http://arxiv.org/abs/2301.01586</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01586] Post-Quantum Key Agreement Protocol based on Non-Square Integer Matrices](http://arxiv.org/abs/2301.01586) #security</code></li>
<li>Summary: <p>We present in this paper an algorithm for exchanging session keys, coupled
with an hashing encryption module. We show schemes designed for their potential
invulnerability to classical and quantum attacks. In turn, if the parameters
included were appropriate, brute-force attacks exceed the (five) security
levels used in the NIST competition of new post-quantum standards. The original
idea consists of products of rectangular matrices in Zp as public values and
whose factorization is provably an NP-complete problem. We present running
times as a function of the explored parameters and their link with operational
safety. To our knowledge there are no classical and quantum attacks of
polynomial complexity available at hand, remaining only the systematic
exploration of the private-key space.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy Considerations for Risk-Based Authentication Systems. (arXiv:2301.01505v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01505">http://arxiv.org/abs/2301.01505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01505] Privacy Considerations for Risk-Based Authentication Systems](http://arxiv.org/abs/2301.01505) #privacy</code></li>
<li>Summary: <p>Risk-based authentication (RBA) extends authentication mechanisms to make
them more robust against account takeover attacks, such as those using stolen
passwords. RBA is recommended by NIST and NCSC to strengthen password-based
authentication, and is already used by major online services. Also, users
consider RBA to be more usable than two-factor authentication and just as
secure. However, users currently obtain RBA's high security and usability
benefits at the cost of exposing potentially sensitive personal data (e.g., IP
address or browser information). This conflicts with user privacy and requires
to consider user rights regarding the processing of personal data.
</p></li>
</ul>

<p>We outline potential privacy challenges regarding different attacker models
and propose improvements to balance privacy in RBA systems. To estimate the
properties of the privacy-preserving RBA enhancements in practical
environments, we evaluated a subset of them with long-term data from 780 users
of a real-world online service. Our results show the potential to increase
privacy in RBA solutions. However, it is limited to certain parameters that
should guide RBA design to protect privacy. We outline research directions that
need to be considered to achieve a widespread adoption of privacy preserving
RBA with high user acceptance.
</p>

<h2>protect</h2>
<h3>Title: Towards Edge-Cloud Architectures for Personal Protective Equipment Detection. (arXiv:2301.01501v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01501">http://arxiv.org/abs/2301.01501</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01501] Towards Edge-Cloud Architectures for Personal Protective Equipment Detection](http://arxiv.org/abs/2301.01501) #protect</code></li>
<li>Summary: <p>Detecting Personal Protective Equipment in images and video streams is a
relevant problem in ensuring the safety of construction workers. In this
contribution, an architecture enabling live image recognition of such equipment
is proposed. The solution is deployable in two settings -- edge-cloud and
edge-only. The system was tested on an active construction site, as a part of a
larger scenario, within the scope of the ASSIST-IoT H2020 project. To determine
the feasibility of the edge-only variant, a model for counting people wearing
safety helmets was developed using the YOLOX method. It was found that an
edge-only deployment is possible for this use case, given the hardware
infrastructure available on site. In the preliminary evaluation, several
important observations were made, that are crucial to the further development
and deployment of the system. Future work will include an in-depth
investigation of performance aspects of the two architecture variants.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Beckman Defense. (arXiv:2301.01495v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01495">http://arxiv.org/abs/2301.01495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01495] Beckman Defense](http://arxiv.org/abs/2301.01495) #defense</code></li>
<li>Summary: <p>Optimal transport (OT) based distributional robust optimisation (DRO) has
received some traction in the recent past. However, it is at a nascent stage
but has a sound potential in robustifying the deep learning models.
Interestingly, OT barycenters demonstrate a good robustness against adversarial
attacks. Owing to the computationally expensive nature of OT barycenters, they
have not been investigated under DRO framework. In this work, we propose a new
barycenter, namely Beckman barycenter, which can be computed efficiently and
used for training the network to defend against adversarial attacks in
conjunction with adversarial training. We propose a novel formulation of
Beckman barycenter and analytically obtain the barycenter using the marginals
of the input image. We show that the Beckman barycenter can be used to train
adversarially trained networks to improve the robustness. Our training is
extremely efficient as it requires only a single epoch of training. Elaborate
experiments on CIFAR-10, CIFAR-100 and Tiny ImageNet demonstrate that training
an adversarially robust network with Beckman barycenter can significantly
increase the performance. Under auto attack, we get a a maximum boost of 10\%
in CIFAR-10, 8.34\% in CIFAR-100 and 11.51\% in Tiny ImageNet. Our code is
available at <a href="http://bitly.ws/yvgh.">this http URL</a>
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Cryptographic Group and Semigroup Actions. (arXiv:2301.01657v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01657">http://arxiv.org/abs/2301.01657</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01657] Cryptographic Group and Semigroup Actions](http://arxiv.org/abs/2301.01657) #attack</code></li>
<li>Summary: <p>We consider actions of a group or a semigroup on a set, which generalize the
setup of discrete logarithm based cryptosystems. Such cryptographic group
actions have gained increasing attention recently in the context of
isogeny-based cryptography. We introduce generic algorithms for the semigroup
action problem and discuss lower and upper bounds. Also, we investigate
Pohlig-Hellman type attacks in a general sense. In particular, we consider
reductions provided by non-invertible elements in a semigroup, and we deal with
subgroups in the case of group actions.
</p></li>
</ul>

<h3>Title: GUAP: Graph Universal Attack Through Adversarial Patching. (arXiv:2301.01731v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01731">http://arxiv.org/abs/2301.01731</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01731] GUAP: Graph Universal Attack Through Adversarial Patching](http://arxiv.org/abs/2301.01731) #attack</code></li>
<li>Summary: <p>Graph neural networks (GNNs) are a class of effective deep learning models
for node classification tasks; yet their predictive capability may be severely
compromised under adversarially designed unnoticeable perturbations to the
graph structure and/or node data. Most of the current work on graph adversarial
attacks aims at lowering the overall prediction accuracy, but we argue that the
resulting abnormal model performance may catch attention easily and invite
quick counterattack. Moreover, attacks through modification of existing graph
data may be hard to conduct if good security protocols are implemented. In this
work, we consider an easier attack harder to be noticed, through adversarially
patching the graph with new nodes and edges. The attack is universal: it
targets a single node each time and flips its connection to the same set of
patch nodes. The attack is unnoticeable: it does not modify the predictions of
nodes other than the target. We develop an algorithm, named GUAP, that achieves
high attack success rate but meanwhile preserves the prediction accuracy. GUAP
is fast to train by employing a sampling strategy. We demonstrate that a 5%
sampling in each epoch yields 20x speedup in training, with only a slight
degradation in attack performance. Additionally, we show that the adversarial
patch trained with the graph convolutional network transfers well to other
GNNs, such as the graph attention network.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Explainability and Robustness of Deep Visual Classification Models. (arXiv:2301.01343v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01343">http://arxiv.org/abs/2301.01343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01343] Explainability and Robustness of Deep Visual Classification Models](http://arxiv.org/abs/2301.01343) #robust</code></li>
<li>Summary: <p>In the computer vision community, Convolutional Neural Networks (CNNs), first
proposed in the 1980's, have become the standard visual classification model.
Recently, as alternatives to CNNs, Capsule Networks (CapsNets) and Vision
Transformers (ViTs) have been proposed. CapsNets, which were inspired by the
information processing of the human brain, are considered to have more
inductive bias than CNNs, whereas ViTs are considered to have less inductive
bias than CNNs. All three classification models have received great attention
since they can serve as backbones for various downstream tasks. However, these
models are far from being perfect. As pointed out by the community, there are
two weaknesses in standard Deep Neural Networks (DNNs). One of the limitations
of DNNs is the lack of explainability. Even though they can achieve or surpass
human expert performance in the image classification task, the DNN-based
decisions are difficult to understand. In many real-world applications,
however, individual decisions need to be explained. The other limitation of
DNNs is adversarial vulnerability. Concretely, the small and imperceptible
perturbations of inputs can mislead DNNs. The vulnerability of deep neural
networks poses challenges to current visual classification models. The
potential threats thereof can lead to unacceptable consequences. Besides,
studying model adversarial vulnerability can lead to a better understanding of
the underlying models. Our research aims to address the two limitations of
DNNs. Specifically, we focus on deep visual classification models, especially
the core building parts of each classification model, e.g. dynamic routing in
CapsNets and self-attention module in ViTs.
</p></li>
</ul>

<h3>Title: Attribute-Centric Compositional Text-to-Image Generation. (arXiv:2301.01413v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01413">http://arxiv.org/abs/2301.01413</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01413] Attribute-Centric Compositional Text-to-Image Generation](http://arxiv.org/abs/2301.01413) #robust</code></li>
<li>Summary: <p>Despite the recent impressive breakthroughs in text-to-image generation,
generative models have difficulty in capturing the data distribution of
underrepresented attribute compositions while over-memorizing overrepresented
attribute compositions, which raises public concerns about their robustness and
fairness. To tackle this challenge, we propose ACTIG, an attribute-centric
compositional text-to-image generation framework. We present an
attribute-centric feature augmentation and a novel image-free training scheme,
which greatly improves model's ability to generate images with underrepresented
attributes. We further propose an attribute-centric contrastive loss to avoid
overfitting to overrepresented attribute compositions. We validate our
framework on the CelebA-HQ and CUB datasets. Extensive experiments show that
the compositional generalization of ACTIG is outstanding, and our framework
outperforms previous works in terms of image quality and text-image
consistency.
</p></li>
</ul>

<h3>Title: Audio-Visual Efficient Conformer for Robust Speech Recognition. (arXiv:2301.01456v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01456">http://arxiv.org/abs/2301.01456</a></li>
<li>Code URL: <a href="https://github.com/burchim/avec">https://github.com/burchim/avec</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01456] Audio-Visual Efficient Conformer for Robust Speech Recognition](http://arxiv.org/abs/2301.01456) #robust</code></li>
<li>Summary: <p>End-to-end Automatic Speech Recognition (ASR) systems based on neural
networks have seen large improvements in recent years. The availability of
large scale hand-labeled datasets and sufficient computing resources made it
possible to train powerful deep neural networks, reaching very low Word Error
Rate (WER) on academic benchmarks. However, despite impressive performance on
clean audio samples, a drop of performance is often observed on noisy speech.
In this work, we propose to improve the noise robustness of the recently
proposed Efficient Conformer Connectionist Temporal Classification (CTC)-based
architecture by processing both audio and visual modalities. We improve
previous lip reading methods using an Efficient Conformer back-end on top of a
ResNet-18 visual front-end and by adding intermediate CTC losses between
blocks. We condition intermediate block features on early predictions using
Inter CTC residual modules to relax the conditional independence assumption of
CTC-based models. We also replace the Efficient Conformer grouped attention by
a more efficient and simpler attention mechanism that we call patch attention.
We experiment with publicly available Lip Reading Sentences 2 (LRS2) and Lip
Reading Sentences 3 (LRS3) datasets. Our experiments show that using audio and
visual modalities allows to better recognize speech in the presence of
environmental noise and significantly accelerate training, reaching lower WER
with 4 times less training steps. Our Audio-Visual Efficient Conformer (AVEC)
model achieves state-of-the-art performance, reaching WER of 2.3% and 1.8% on
LRS2 and LRS3 test sets. Code and pretrained models are available at
https://github.com/burchim/AVEC.
</p></li>
</ul>

<h3>Title: MoBYv2AL: Self-supervised Active Learning for Image Classification. (arXiv:2301.01531v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01531">http://arxiv.org/abs/2301.01531</a></li>
<li>Code URL: <a href="https://github.com/razvancaramalau/mobyv2al">https://github.com/razvancaramalau/mobyv2al</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01531] MoBYv2AL: Self-supervised Active Learning for Image Classification](http://arxiv.org/abs/2301.01531) #robust</code></li>
<li>Summary: <p>Active learning(AL) has recently gained popularity for deep learning(DL)
models. This is due to efficient and informative sampling, especially when the
learner requires large-scale labelled datasets. Commonly, the sampling and
training happen in stages while more batches are added. One main bottleneck in
this strategy is the narrow representation learned by the model that affects
the overall AL selection.
</p></li>
</ul>

<p>We present MoBYv2AL, a novel self-supervised active learning framework for
image classification. Our contribution lies in lifting MoBY, one of the most
successful self-supervised learning algorithms, to the AL pipeline. Thus, we
add the downstream task-aware objective function and optimize it jointly with
contrastive loss. Further, we derive a data-distribution selection function
from labelling the new examples. Finally, we test and study our pipeline
robustness and performance for image classification tasks. We successfully
achieved state-of-the-art results when compared to recent AL methods. Code
available: https://github.com/razvancaramalau/MoBYv2AL
</p>

<h3>Title: Why Capsule Neural Networks Do Not Scale: Challenging the Dynamic Parse-Tree Assumption. (arXiv:2301.01583v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01583">http://arxiv.org/abs/2301.01583</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01583] Why Capsule Neural Networks Do Not Scale: Challenging the Dynamic Parse-Tree Assumption](http://arxiv.org/abs/2301.01583) #robust</code></li>
<li>Summary: <p>Capsule neural networks replace simple, scalar-valued neurons with
vector-valued capsules. They are motivated by the pattern recognition system in
the human brain, where complex objects are decomposed into a hierarchy of
simpler object parts. Such a hierarchy is referred to as a parse-tree.
Conceptually, capsule neural networks have been defined to realize such
parse-trees. The capsule neural network (CapsNet), by Sabour, Frosst, and
Hinton, is the first actual implementation of the conceptual idea of capsule
neural networks. CapsNets achieved state-of-the-art performance on simple image
recognition tasks with fewer parameters and greater robustness to affine
transformations than comparable approaches. This sparked extensive follow-up
research. However, despite major efforts, no work was able to scale the CapsNet
architecture to more reasonable-sized datasets. Here, we provide a reason for
this failure and argue that it is most likely not possible to scale CapsNets
beyond toy examples. In particular, we show that the concept of a parse-tree,
the main idea behind capsule neuronal networks, is not present in CapsNets. We
also show theoretically and experimentally that CapsNets suffer from a
vanishing gradient problem that results in the starvation of many capsules
during training.
</p></li>
</ul>

<h3>Title: Contextual Conservative Q-Learning for Offline Reinforcement Learning. (arXiv:2301.01298v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01298">http://arxiv.org/abs/2301.01298</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01298] Contextual Conservative Q-Learning for Offline Reinforcement Learning](http://arxiv.org/abs/2301.01298) #robust</code></li>
<li>Summary: <p>Offline reinforcement learning learns an effective policy on offline datasets
without online interaction, and it attracts persistent research attention due
to its potential of practical application. However, extrapolation error
generated by distribution shift will still lead to the overestimation for those
actions that transit to out-of-distribution(OOD) states, which degrades the
reliability and robustness of the offline policy. In this paper, we propose
Contextual Conservative Q-Learning(C-CQL) to learn a robustly reliable policy
through the contextual information captured via an inverse dynamics model. With
the supervision of the inverse dynamics model, it tends to learn a policy that
generates stable transition at perturbed states, for the fact that pertuebed
states are a common kind of OOD states. In this manner, we enable the learnt
policy more likely to generate transition that destines to the empirical next
state distributions of the offline dataset, i.e., robustly reliable transition.
Besides, we theoretically reveal that C-CQL is the generalization of the
Conservative Q-Learning(CQL) and aggressive State Deviation Correction(SDC).
Finally, experimental results demonstrate the proposed C-CQL achieves the
state-of-the-art performance in most environments of offline Mujoco suite and a
noisy Mujoco setting.
</p></li>
</ul>

<h3>Title: A Survey on Deep Industrial Transfer Learning in Fault Prognostics. (arXiv:2301.01705v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01705">http://arxiv.org/abs/2301.01705</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01705] A Survey on Deep Industrial Transfer Learning in Fault Prognostics](http://arxiv.org/abs/2301.01705) #robust</code></li>
<li>Summary: <p>Due to its probabilistic nature, fault prognostics is a prime example of a
use case for deep learning utilizing big data. However, the low availability of
such data sets combined with the high effort of fitting, parameterizing and
evaluating complex learning algorithms to the heterogenous and dynamic settings
typical for industrial applications oftentimes prevents the practical
application of this approach. Automatic adaptation to new or dynamically
changing fault prognostics scenarios can be achieved using transfer learning or
continual learning methods. In this paper, a first survey of such approaches is
carried out, aiming at establishing best practices for future research in this
field. It is shown that the field is lacking common benchmarks to robustly
compare results and facilitate scientific progress. Therefore, the data sets
utilized in these publications are surveyed as well in order to identify
suitable candidates for such benchmark scenarios.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Kernel Subspace and Feature Extraction. (arXiv:2301.01410v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01410">http://arxiv.org/abs/2301.01410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01410] Kernel Subspace and Feature Extraction](http://arxiv.org/abs/2301.01410) #extraction</code></li>
<li>Summary: <p>We study kernel methods in machine learning from the perspective of feature
subspace. We establish a one-to-one correspondence between feature subspaces
and kernels and propose an information-theoretic measure for kernels. In
particular, we construct a kernel from Hirschfeld--Gebelein--R\'{e}nyi maximal
correlation functions, coined the maximal correlation kernel, and demonstrate
its information-theoretic optimality. We use the support vector machine (SVM)
as an example to illustrate a connection between kernel methods and feature
extraction approaches. We show that the kernel SVM on maximal correlation
kernel achieves minimum prediction error. Finally, we interpret the Fisher
kernel as a special maximal correlation kernel and establish its optimality.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Recent Advances on Federated Learning: A Systematic Survey. (arXiv:2301.01299v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01299">http://arxiv.org/abs/2301.01299</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01299] Recent Advances on Federated Learning: A Systematic Survey](http://arxiv.org/abs/2301.01299) #federate</code></li>
<li>Summary: <p>Federated learning has emerged as an effective paradigm to achieve
privacy-preserving collaborative learning among different parties. Compared to
traditional centralized learning that requires collecting data from each party,
in federated learning, only the locally trained models or computed gradients
are exchanged, without exposing any data information. As a result, it is able
to protect privacy to some extent. In recent years, federated learning has
become more and more prevalent and there have been many surveys for summarizing
related methods in this hot research topic. However, most of them focus on a
specific perspective or lack the latest research progress. In this paper, we
provide a systematic survey on federated learning, aiming to review the recent
advanced federated methods and applications from different aspects.
Specifically, this paper includes four major contributions. First, we present a
new taxonomy of federated learning in terms of the pipeline and challenges in
federated scenarios. Second, we summarize federated learning methods into
several categories and briefly introduce the state-of-the-art methods under
these categories. Third, we overview some prevalent federated learning
frameworks and introduce their features. Finally, some potential deficiencies
of current methods and several future directions are discussed.
</p></li>
</ul>

<h3>Title: Federated Learning for Data Streams. (arXiv:2301.01542v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01542">http://arxiv.org/abs/2301.01542</a></li>
<li>Code URL: <a href="https://github.com/omarfoq/streaming-fl">https://github.com/omarfoq/streaming-fl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01542] Federated Learning for Data Streams](http://arxiv.org/abs/2301.01542) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is an effective solution to train machine learning
models on the increasing amount of data generated by IoT devices and
smartphones while keeping such data localized. Most previous work on federated
learning assumes that clients operate on static datasets collected before
training starts. This approach may be inefficient because 1) it ignores new
samples clients collect during training, and 2) it may require a potentially
long preparatory phase for clients to collect enough data. Moreover, learning
on static datasets may be simply impossible in scenarios with small aggregate
storage across devices. It is, therefore, necessary to design federated
algorithms able to learn from data streams. In this work, we formulate and
study the problem of \emph{federated learning for data streams}. We propose a
general FL algorithm to learn from data streams through an opportune weighted
empirical risk minimization. Our theoretical analysis provides insights to
configure such an algorithm, and we evaluate its performance on a wide range of
machine learning tasks.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: On Fairness of Medical Image Classification with Multiple Sensitive Attributes via Learning Orthogonal Representations. (arXiv:2301.01481v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01481">http://arxiv.org/abs/2301.01481</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01481] On Fairness of Medical Image Classification with Multiple Sensitive Attributes via Learning Orthogonal Representations](http://arxiv.org/abs/2301.01481) #fair</code></li>
<li>Summary: <p>Mitigating the discrimination of machine learning models has gained
increasing attention in medical image analysis. However, rare works focus on
fair treatments for patients with multiple sensitive demographic ones, which is
a crucial yet challenging problem for real-world clinical applications. In this
paper, we propose a novel method for fair representation learning with respect
to multi-sensitive attributes. We pursue the independence between target and
multi-sensitive representations by achieving orthogonality in the
representation space. Concretely, we enforce the column space orthogonality by
keeping target information on the complement of a low-rank sensitive space.
Furthermore, in the row space, we encourage feature dimensions between target
and sensitive representations to be orthogonal. The effectiveness of the
proposed method is demonstrated with extensive experiments on the CheXpert
dataset. To our best knowledge, this is the first work to mitigate unfairness
with respect to multiple sensitive attributes in the field of medical imaging.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Counterfactual Explanations for Land Cover Mapping in a Multi-class Setting. (arXiv:2301.01520v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01520">http://arxiv.org/abs/2301.01520</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01520] Counterfactual Explanations for Land Cover Mapping in a Multi-class Setting](http://arxiv.org/abs/2301.01520) #interpretability</code></li>
<li>Summary: <p>Counterfactual explanations are an emerging tool to enhance interpretability
of deep learning models. Given a sample, these methods seek to find and display
to the user similar samples across the decision boundary. In this paper, we
propose a generative adversarial counterfactual approach for satellite image
time series in a multi-class setting for the land cover classification task.
One of the distinctive features of the proposed approach is the lack of prior
assumption on the targeted class for a given counterfactual explanation. This
inherent flexibility allows for the discovery of interesting information on the
relationship between land cover classes. The other feature consists of
encouraging the counterfactual to differ from the original sample only in a
small and compact temporal segment. These time-contiguous perturbations allow
for a much sparser and, thus, interpretable solution. Furthermore,
plausibility/realism of the generated counterfactual explanations is enforced
via the proposed adversarial learning strategy.
</p></li>
</ul>

<h3>Title: Iterated Decomposition: Improving Science Q&amp;A by Supervising Reasoning Processes. (arXiv:2301.01751v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01751">http://arxiv.org/abs/2301.01751</a></li>
<li>Code URL: <a href="https://github.com/oughtinc/ice">https://github.com/oughtinc/ice</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01751] Iterated Decomposition: Improving Science Q&amp;A by Supervising Reasoning Processes](http://arxiv.org/abs/2301.01751) #interpretability</code></li>
<li>Summary: <p>Language models (LMs) can perform complex reasoning either end-to-end, with
hidden latent state, or compositionally, with transparent intermediate state.
Composition offers benefits for interpretability and safety, but may need
workflow support and infrastructure to remain competitive. We describe iterated
decomposition, a human-in-the-loop workflow for developing and refining
compositional LM programs. We improve the performance of compositions by
zooming in on failing components and refining them through decomposition,
additional context, chain of thought, etc. To support this workflow, we develop
ICE, an open-source tool for visualizing the execution traces of LM programs.
We apply iterated decomposition to three real-world tasks and improve the
accuracy of LM programs over less compositional baselines: describing the
placebo used in a randomized controlled trial (25% to 65%), evaluating
participant adherence to a medical intervention (53% to 70%), and answering NLP
questions on the Qasper dataset (38% to 69%). These applications serve as case
studies for a workflow that, if automated, could keep ML systems interpretable
and safe even as they scale to increasingly complex tasks.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Hospital transfer risk prediction for COVID-19 patients from a medicalized hotel based on Diffusion GraphSAGE. (arXiv:2301.01596v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01596">http://arxiv.org/abs/2301.01596</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01596] Hospital transfer risk prediction for COVID-19 patients from a medicalized hotel based on Diffusion GraphSAGE](http://arxiv.org/abs/2301.01596) #diffusion</code></li>
<li>Summary: <p>The global COVID-19 pandemic has caused more than six million deaths
worldwide. Medicalized hotels were established in Taiwan as quarantine
facilities for COVID-19 patients with no or mild symptoms. Due to limited
medical care available at these hotels, it is of paramount importance to
identify patients at risk of clinical deterioration. This study aimed to
develop and evaluate a graph-based deep learning approach for progressive
hospital transfer risk prediction in a medicalized hotel setting. Vital sign
measurements were obtained for 632 patients and daily patient similarity graphs
were constructed. Inductive graph convolutional network models were trained on
top of the temporally integrated graphs to predict hospital transfer risk. The
proposed models achieved AUC scores above 0.83 for hospital transfer risk
prediction based on the measurements of past 1, 2, and 3 days, outperforming
baseline machine learning methods. A post-hoc analysis on the constructed
diffusion-based graph using Local Clustering Coefficient discovered a high-risk
cluster with significantly older mean age, higher body temperature, lower SpO2,
and shorter length of stay. Further time-to-hospital-transfer survival analysis
also revealed a significant decrease in survival probability in the discovered
high-risk cluster. The obtained results demonstrated promising predictability
and interpretability of the proposed graph-based approach. This technique may
help preemptively detect high-risk patients at community-based medical
facilities similar to a medicalized hotel.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
