<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-05-14</h1>
<h3>Title: A Tale of Two Identities: An Ethical Audit of Human and AI-Crafted Personas</h3>
<ul>
<li><strong>Authors: </strong>Pranav Narayanan Venkit, Jiayi Li, Yingfan Zhou, Sarah Rajtmajer, Shomir Wilson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07850">https://arxiv.org/abs/2505.07850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07850">https://arxiv.org/pdf/2505.07850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07850]] A Tale of Two Identities: An Ethical Audit of Human and AI-Crafted Personas(https://arxiv.org/abs/2505.07850)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>As LLMs (large language models) are increasingly used to generate synthetic personas particularly in data-limited domains such as health, privacy, and HCI, it becomes necessary to understand how these narratives represent identity, especially that of minority communities. In this paper, we audit synthetic personas generated by 3 LLMs (GPT4o, Gemini 1.5 Pro, Deepseek 2.5) through the lens of representational harm, focusing specifically on racial identity. Using a mixed methods approach combining close reading, lexical analysis, and a parameterized creativity framework, we compare 1512 LLM generated personas to human-authored responses. Our findings reveal that LLMs disproportionately foreground racial markers, overproduce culturally coded language, and construct personas that are syntactically elaborate yet narratively reductive. These patterns result in a range of sociotechnical harms, including stereotyping, exoticism, erasure, and benevolent bias, that are often obfuscated by superficially positive narrations. We formalize this phenomenon as algorithmic othering, where minoritized identities are rendered hypervisible but less authentic. Based on these findings, we offer design recommendations for narrative-aware evaluation metrics and community-centered validation protocols for synthetic identity generation.</li>
</ul>

<h3>Title: Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment</h3>
<ul>
<li><strong>Authors: </strong>Ali Senol, Garima Agrawal, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07852">https://arxiv.org/abs/2505.07852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07852">https://arxiv.org/pdf/2505.07852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07852]] Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment(https://arxiv.org/abs/2505.07852)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Detecting fake interactions in digital communication platforms remains a challenging and insufficiently addressed problem. These interactions may appear as harmless spam or escalate into sophisticated scam attempts, making it difficult to flag malicious intent early. Traditional detection methods often rely on static anomaly detection techniques that fail to adapt to dynamic conversational shifts. One key limitation is the misinterpretation of benign topic transitions referred to as concept drift as fraudulent behavior, leading to either false alarms or missed threats. We propose a two stage detection framework that first identifies suspicious conversations using a tailored ensemble classification model. To improve the reliability of detection, we incorporate a concept drift analysis step using a One Class Drift Detector (OCDD) to isolate conversational shifts within flagged dialogues. When drift is detected, a large language model (LLM) assesses whether the shift indicates fraudulent manipulation or a legitimate topic change. In cases where no drift is found, the behavior is inferred to be spam like. We validate our framework using a dataset of social engineering chat scenarios and demonstrate its practical advantages in improving both accuracy and interpretability for real time fraud detection. To contextualize the trade offs, we compare our modular approach against a Dual LLM baseline that performs detection and judgment using different language models.</li>
</ul>

<h3>Title: CrashSage: A Large Language Model-Centered Framework for Contextual and Interpretable Traffic Crash Analysis</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhen, Jidong J. Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07853">https://arxiv.org/abs/2505.07853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07853">https://arxiv.org/pdf/2505.07853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07853]] CrashSage: A Large Language Model-Centered Framework for Contextual and Interpretable Traffic Crash Analysis(https://arxiv.org/abs/2505.07853)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Road crashes claim over 1.3 million lives annually worldwide and incur global economic losses exceeding \$1.8 trillion. Such profound societal and financial impacts underscore the urgent need for road safety research that uncovers crash mechanisms and delivers actionable insights. Conventional statistical models and tree ensemble approaches typically rely on structured crash data, overlooking contextual nuances and struggling to capture complex relationships and underlying semantics. Moreover, these approaches tend to incur significant information loss, particularly in narrative elements related to multi-vehicle interactions, crash progression, and rare event characteristics. This study presents CrashSage, a novel Large Language Model (LLM)-centered framework designed to advance crash analysis and modeling through four key innovations. First, we introduce a tabular-to-text transformation strategy paired with relational data integration schema, enabling the conversion of raw, heterogeneous crash data into enriched, structured textual narratives that retain essential structural and relational context. Second, we apply context-aware data augmentation using a base LLM model to improve narrative coherence while preserving factual integrity. Third, we fine-tune the LLaMA3-8B model for crash severity inference, demonstrating superior performance over baseline approaches, including zero-shot, zero-shot with chain-of-thought prompting, and few-shot learning, with multiple models (GPT-4o, GPT-4o-mini, LLaMA3-70B). Finally, we employ a gradient-based explainability technique to elucidate model decisions at both the individual crash level and across broader risk factor dimensions. This interpretability mechanism enhances transparency and enables targeted road safety interventions by providing deeper insights into the most influential factors.</li>
</ul>

<h3>Title: Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights</h3>
<ul>
<li><strong>Authors: </strong>Pawe≈Ç Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07856">https://arxiv.org/abs/2505.07856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07856">https://arxiv.org/pdf/2505.07856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07856]] Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights(https://arxiv.org/abs/2505.07856)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Various techniques are used in the generation of adversarial examples, including methods such as TextBugger which introduce minor, hardly visible perturbations to words leading to changes in model behaviour. Another class of techniques involves substituting words with their synonyms in a way that preserves the text's meaning but alters its predicted class, with TextFooler being a prominent example of such attacks. Most adversarial example generation methods are developed and evaluated primarily on non-inflectional languages, typically English. In this work, we evaluate and explain how adversarial attacks perform in inflectional languages. To explain the impact of inflection on model behaviour and its robustness under attack, we designed a novel protocol inspired by mechanistic interpretability, based on Edge Attribution Patching (EAP) method. The proposed evaluation protocol relies on parallel task-specific corpora that include both inflected and syncretic variants of texts in two languages -- Polish and English. To analyse the models and explain the relationship between inflection and adversarial robustness, we create a new benchmark based on task-oriented dataset MultiEmo, enabling the identification of mechanistic inflection-related elements of circuits within the model and analyse their behaviour under attack.</li>
</ul>

<h3>Title: Enhanced Urdu Intent Detection with Large Language Models and Prototype-Informed Predictive Pipelines</h3>
<ul>
<li><strong>Authors: </strong>Faiza Hassan, Summra Saleem, Kashif Javed, Muhammad Nabeel Asim, Abdur Rehman, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07857">https://arxiv.org/abs/2505.07857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07857">https://arxiv.org/pdf/2505.07857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07857]] Enhanced Urdu Intent Detection with Large Language Models and Prototype-Informed Predictive Pipelines(https://arxiv.org/abs/2505.07857)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multifarious intent detection predictors are developed for different languages, including English, Chinese and French, however, the field remains underdeveloped for Urdu, the 10th most spoken language. In the realm of well-known languages, intent detection predictors utilize the strategy of few-shot learning and prediction of unseen classes based on the model training on seen classes. However, Urdu language lacks few-shot strategy based intent detection predictors and traditional predictors are focused on prediction of the same classes which models have seen in the train set. To empower Urdu language specific intent detection, this introduces a unique contrastive learning approach that leverages unlabeled Urdu data to re-train pre-trained language models. This re-training empowers LLMs representation learning for the downstream intent detection task. Finally, it reaps the combined potential of pre-trained LLMs and the prototype-informed attention mechanism to create a comprehensive end-to-end LLMPIA intent detection pipeline. Under the paradigm of proposed predictive pipeline, it explores the potential of 6 distinct language models and 13 distinct similarity computation methods. The proposed framework is evaluated on 2 public benchmark datasets, namely ATIS encompassing 5836 samples and Web Queries having 8519 samples. Across ATIS dataset under 4-way 1 shot and 4-way 5 shot experimental settings LLMPIA achieved 83.28% and 98.25% F1-Score and on Web Queries dataset produced 76.23% and 84.42% F1-Score, respectively. In an additional case study on the Web Queries dataset under same classes train and test set settings, LLMPIA outperformed state-of-the-art predictor by 53.55% F1-Score.</li>
</ul>

<h3>Title: Scaling Laws for Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Yan, Mo Zhu, Guo-qing Jiang, Jianfei Wang, Jiaxing Chen, Wentai Zhang, Xiang Liao, Xiao Cui, Chen Zhang, Zhuoran Song, Ran Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07858">https://arxiv.org/abs/2505.07858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07858">https://arxiv.org/pdf/2505.07858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07858]] Scaling Laws for Speculative Decoding(https://arxiv.org/abs/2505.07858)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The escalating demand for efficient decoding in large language models (LLMs) is particularly critical for reasoning-intensive architectures like OpenAI-o3 and DeepSeek-R1, which depend on extended chain-of-thought reasoning. This study investigates speculative decoding techniques through dense LLM architectures to establish foundational insights for accelerating reasoning tasks. While speculative decoding methods leveraging parallel draft-verification cycles have emerged as promising acceleration techniques, the scaling laws governing decoding efficiency remain under-explored compared to conventional backbone LLMs developed through Pretraining->SFT->RLHF training paradigms. In this work, we discover Log-linear Scaling Laws (Theorem 1.1, 1.2 and 1.3) governing draft model acceptance rate (or decoding speed) across three dimensions: pretraining token volume, draft model capacity, and decoding batch size. Building on these laws, we achieve Scylla, which coordinates multi-dimensional scaling for popular LLMs (Llama2/3, Qwen2.5). Empirical validation shows Scylla achieves 1.5-2.2 higher acceptance rate than EAGLE2 and 0.3 higher than EAGLE3 at temperature T = 0, with peak performance gains on summarization and QA tasks (Figure 2). Industrial inference engine deployments demonstrate 2X decoding throughput improvements over EAGLE2 (Table 5), validating the transformative potential of systematic scaling for efficient LLM inference. Code will be released later.</li>
</ul>

<h3>Title: Boosting Performance on ARC is a Matter of Perspective</h3>
<ul>
<li><strong>Authors: </strong>Daniel Franzen, Jan Disselhoff, David Hartmann</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07859">https://arxiv.org/abs/2505.07859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07859">https://arxiv.org/pdf/2505.07859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07859]] Boosting Performance on ARC is a Matter of Perspective(https://arxiv.org/abs/2505.07859)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Abstraction and Reasoning Corpus (ARC-AGI) poses a significant challenge for large language models (LLMs), exposing limitations in their abstract reasoning abilities. In this work, we leverage task-specific data augmentations throughout the training, generation, and scoring phases, and employ a depth-first search algorithm to generate diverse, high-probability candidate solutions. Furthermore, we utilize the LLM not only as a generator but also as a scorer, using its output probabilities to select the most promising solutions. Our method achieves a score of 71.6% (286.5/400 solved tasks) on the public ARC-AGI evaluation set, demonstrating state-of-the-art performance among publicly available approaches. While concurrent closed-source work has reported higher scores, our method distinguishes itself through its transparency, reproducibility, and remarkably low inference cost, averaging only around 2ct per task on readily available hardware (we assume a price of 36ct/hour for a Nvidia 4090 GPU).</li>
</ul>

<h3>Title: Scalable LLM Math Reasoning Acceleration with Low-rank Distillation</h3>
<ul>
<li><strong>Authors: </strong>Harry Dong, Bilge Acun, Beidi Chen, Yuejie Chi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07861">https://arxiv.org/abs/2505.07861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07861">https://arxiv.org/pdf/2505.07861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07861]] Scalable LLM Math Reasoning Acceleration with Low-rank Distillation(https://arxiv.org/abs/2505.07861)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Due to long generations, large language model (LLM) math reasoning demands significant computational resources and time. While many existing efficient inference methods have been developed with excellent performance preservation on language tasks, they often severely degrade math performance. In this paper, we propose Caprese, a low-cost distillation method to recover lost capabilities from deploying efficient inference methods, focused primarily in feedforward blocks. With original weights unperturbed, roughly 1% of additional parameters, and only 20K synthetic training samples, we are able to recover much if not all of the math capabilities lost from efficient inference for thinking LLMs and without harm to language tasks for instruct LLMs. Moreover, Caprese slashes the number of active parameters (~2B cut for Gemma 2 9B and Llama 3.1 8B) and integrates cleanly into existing model layers to reduce latency (>11% reduction to generate 2048 tokens with Qwen 2.5 14B) while encouraging response brevity.</li>
</ul>

<h3>Title: Graph Laplacian Wavelet Transformer via Learnable Spectral Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Andrew Kiruluta, Eric Lundy, Priscilla Burity</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07862">https://arxiv.org/abs/2505.07862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07862">https://arxiv.org/pdf/2505.07862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07862]] Graph Laplacian Wavelet Transformer via Learnable Spectral Decomposition(https://arxiv.org/abs/2505.07862)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Existing sequence to sequence models for structured language tasks rely heavily on the dot product self attention mechanism, which incurs quadratic complexity in both computation and memory for input length N. We introduce the Graph Wavelet Transformer (GWT), a novel architecture that replaces this bottleneck with a learnable, multi scale wavelet transform defined over an explicit graph Laplacian derived from syntactic or semantic parses. Our analysis shows that multi scale spectral decomposition offers an interpretable, efficient, and expressive alternative to quadratic self attention for graph structured sequence modeling.</li>
</ul>

<h3>Title: QoSBERT: An Uncertainty-Aware Approach based on Pre-trained Language Models for Service Quality Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ziliang Wang, Xiaohong Zhang, Ze Shi Li, Meng Yan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07863">https://arxiv.org/abs/2505.07863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07863">https://arxiv.org/pdf/2505.07863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07863]] QoSBERT: An Uncertainty-Aware Approach based on Pre-trained Language Models for Service Quality Prediction(https://arxiv.org/abs/2505.07863)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate prediction of Quality of Service (QoS) metrics is fundamental for selecting and managing cloud based services. Traditional QoS models rely on manual feature engineering and yield only point estimates, offering no insight into the confidence of their predictions. In this paper, we propose QoSBERT, the first framework that reformulates QoS prediction as a semantic regression task based on pre trained language models. Unlike previous approaches relying on sparse numerical features, QoSBERT automatically encodes user service metadata into natural language descriptions, enabling deep semantic understanding. Furthermore, we integrate a Monte Carlo Dropout based uncertainty estimation module, allowing for trustworthy and risk-aware service quality prediction, which is crucial yet underexplored in existing QoS models. QoSBERT applies attentive pooling over contextualized embeddings and a lightweight multilayer perceptron regressor, fine tuned jointly to minimize absolute error. We further exploit the resulting uncertainty estimates to select high quality training samples, improving robustness in low resource settings. On standard QoS benchmark datasets, QoSBERT achieves an average reduction of 11.7% in MAE and 6.7% in RMSE for response time prediction, and 6.9% in MAE for throughput prediction compared to the strongest baselines, while providing well calibrated confidence intervals for robust and trustworthy service quality estimation. Our approach not only advances the accuracy of service quality prediction but also delivers reliable uncertainty quantification, paving the way for more trustworthy, data driven service selection and optimization.</li>
</ul>

<h3>Title: Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection</h3>
<ul>
<li><strong>Authors: </strong>Suavis Giramata, Madhusudan Srinivasan, Venkat Naidu Gudivada, Upulee Kanewala</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07870">https://arxiv.org/abs/2505.07870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07870">https://arxiv.org/pdf/2505.07870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07870]] Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection(https://arxiv.org/abs/2505.07870)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in various applications, raising critical concerns about fairness and potential biases in their outputs. This paper explores the prioritization of metamorphic relations (MRs) in metamorphic testing as a strategy to efficiently detect fairness issues within LLMs. Given the exponential growth of possible test cases, exhaustive testing is impractical; therefore, prioritizing MRs based on their effectiveness in detecting fairness violations is crucial. We apply a sentence diversity-based approach to compute and rank MRs to optimize fault detection. Experimental results demonstrate that our proposed prioritization approach improves fault detection rates by 22% compared to random prioritization and 12% compared to distance-based prioritization, while reducing the time to the first failure by 15% and 8%, respectively. Furthermore, our approach performs within 5% of fault-based prioritization in effectiveness, while significantly reducing the computational cost associated with fault labeling. These results validate the effectiveness of diversity-based MR prioritization in enhancing fairness testing for LLMs.</li>
</ul>

<h3>Title: Evaluating Financial Sentiment Analysis with Annotators Instruction Assisted Prompting: Enhancing Contextual Interpretation and Stock Prediction Accuracy</h3>
<ul>
<li><strong>Authors: </strong>A M Muntasir Rahman, Ajim Uddin, Guiling "Grace" Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07871">https://arxiv.org/abs/2505.07871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07871">https://arxiv.org/pdf/2505.07871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07871]] Evaluating Financial Sentiment Analysis with Annotators Instruction Assisted Prompting: Enhancing Contextual Interpretation and Stock Prediction Accuracy(https://arxiv.org/abs/2505.07871)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Financial sentiment analysis (FSA) presents unique challenges to LLMs that surpass those in typical sentiment analysis due to the nuanced language used in financial contexts. The prowess of these models is often undermined by the inherent subjectivity of sentiment classifications in existing benchmark datasets like Financial Phrasebank. These datasets typically feature undefined sentiment classes that reflect the highly individualized perspectives of annotators, leading to significant variability in annotations. This variability results in an unfair expectation for LLMs during benchmarking, where they are tasked to conjecture the subjective viewpoints of human annotators without sufficient context. In this paper, we introduce the Annotators' Instruction Assisted Prompt, a novel evaluation prompt designed to redefine the task definition of FSA for LLMs. By integrating detailed task instructions originally intended for human annotators into the LLMs' prompt framework, AIAP aims to standardize the understanding of sentiment across both human and machine interpretations, providing a fair and context-rich foundation for sentiment analysis. We utilize a new dataset, WSBS, derived from the WallStreetBets subreddit to demonstrate how AIAP significantly enhances LLM performance by aligning machine operations with the refined task definitions. Experimental results demonstrate that AIAP enhances LLM performance significantly, with improvements up to 9.08. This context-aware approach not only yields incremental gains in performance but also introduces an innovative sentiment-indexing method utilizing model confidence scores. This method enhances stock price prediction models and extracts more value from the financial sentiment analysis, underscoring the significance of WSB as a critical source of financial text. Our research offers insights into both improving FSA through better evaluation methods.</li>
</ul>

<h3>Title: Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints</h3>
<ul>
<li><strong>Authors: </strong>Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07883">https://arxiv.org/abs/2505.07883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07883">https://arxiv.org/pdf/2505.07883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07883]] Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints(https://arxiv.org/abs/2505.07883)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Rational decision-making under uncertainty requires coherent degrees of belief in events. However, event probabilities generated by Large Language Models (LLMs) have been shown to exhibit incoherence, violating the axioms of probability theory. This raises the question of whether coherent event probabilities can be recovered from the embeddings used by the models. If so, those derived probabilities could be used as more accurate estimates in events involving uncertainty. To explore this question, we propose enforcing axiomatic constraints, such as the additive rule of probability theory, in the latent space learned by an extended variational autoencoder (VAE) applied to LLM embeddings. This approach enables event probabilities to naturally emerge in the latent space as the VAE learns to both reconstruct the original embeddings and predict the embeddings of semantically related events. We evaluate our method on complementary events (i.e., event A and its complement, event not-A), where the true probabilities of the two events must sum to 1. Experiment results on open-weight language models demonstrate that probabilities recovered from embeddings exhibit greater coherence than those directly reported by the corresponding models and align closely with the true probabilities.</li>
</ul>

<h3>Title: Development of a WAZOBIA-Named Entity Recognition System</h3>
<ul>
<li><strong>Authors: </strong>S.E Emedem, I.E Onyenwe, E. G Onyedinma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07884">https://arxiv.org/abs/2505.07884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07884">https://arxiv.org/pdf/2505.07884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07884]] Development of a WAZOBIA-Named Entity Recognition System(https://arxiv.org/abs/2505.07884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Named Entity Recognition NER is very crucial for various natural language processing applications, including information extraction, machine translation, and sentiment analysis. Despite the ever-increasing interest in African languages within computational linguistics, existing NER systems focus mainly on English, European, and a few other global languages, leaving a significant gap for under-resourced languages. This research presents the development of a WAZOBIA-NER system tailored for the three most prominent Nigerian languages: Hausa, Yoruba, and Igbo. This research begins with a comprehensive compilation of annotated datasets for each language, addressing data scarcity and linguistic diversity challenges. Exploring the state-of-the-art machine learning technique, Conditional Random Fields (CRF) and deep learning models such as Bidirectional Long Short-Term Memory (BiLSTM), Bidirectional Encoder Representation from Transformers (Bert) and fine-tune with a Recurrent Neural Network (RNN), the study evaluates the effectiveness of these approaches in recognizing three entities: persons, organizations, and locations. The system utilizes optical character recognition (OCR) technology to convert textual images into machine-readable text, thereby enabling the Wazobia system to accept both input text and textual images for extraction purposes. The system achieved a performance of 0.9511 in precision, 0.9400 in recall, 0.9564 in F1-score, and 0.9301 in accuracy. The model's evaluation was conducted across three languages, with precision, recall, F1-score, and accuracy as key assessment metrics. The Wazobia-NER system demonstrates that it is feasible to build robust NER tools for under-resourced African languages using current NLP frameworks and transfer learning.</li>
</ul>

<h3>Title: PLHF: Prompt Optimization with Few-Shot Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Chun-Pai Yang, Kan Zheng, Shou-De Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07886">https://arxiv.org/abs/2505.07886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07886">https://arxiv.org/pdf/2505.07886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07886]] PLHF: Prompt Optimization with Few-Shot Human Feedback(https://arxiv.org/abs/2505.07886)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automatic prompt optimization frameworks are developed to obtain suitable prompts for large language models (LLMs) with respect to desired output quality metrics. Although existing approaches can handle conventional tasks such as fixed-solution question answering, defining the metric becomes complicated when the output quality cannot be easily assessed by comparisons with standard golden samples. Consequently, optimizing the prompts effectively and efficiently without a clear metric becomes a critical challenge. To address the issue, we present PLHF (which stands for "P"rompt "L"earning with "H"uman "F"eedback), a few-shot prompt optimization framework inspired by the well-known RLHF technique. Different from naive strategies, PLHF employs a specific evaluator module acting as the metric to estimate the output quality. PLHF requires only a single round of human feedback to complete the entire prompt optimization process. Empirical results on both public and industrial datasets show that PLHF outperforms prior output grading strategies for LLM prompt optimizations.</li>
</ul>

<h3>Title: Implementing Long Text Style Transfer with LLMs through Dual-Layered Sentence and Paragraph Structure Extraction and Mapping</h3>
<ul>
<li><strong>Authors: </strong>Yusen Wu, Xiaotie Deng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07888">https://arxiv.org/abs/2505.07888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07888">https://arxiv.org/pdf/2505.07888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07888]] Implementing Long Text Style Transfer with LLMs through Dual-Layered Sentence and Paragraph Structure Extraction and Mapping(https://arxiv.org/abs/2505.07888)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenge in long-text style transfer using zero-shot learning of large language models (LLMs), proposing a hierarchical framework that combines sentence-level stylistic adaptation with paragraph-level structural coherence. We argue that in the process of effective paragraph-style transfer, to preserve the consistency of original syntactic and semantic information, it is essential to perform style transfer not only at the sentence level but also to incorporate paragraph-level semantic considerations, while ensuring structural coherence across inter-sentential relationships. Our proposed framework, ZeroStylus, operates through two systematic phases: hierarchical template acquisition from reference texts and template-guided generation with multi-granular matching. The framework dynamically constructs sentence and paragraph template repositories, enabling context-aware transformations while preserving inter-sentence logical relationships. Experimental evaluations demonstrate significant improvements over baseline methods, with structured rewriting achieving 6.90 average score compared to 6.70 for direct prompting approaches in tri-axial metrics assessing style consistency, content preservation, and expression quality. Ablation studies validate the necessity of both template hierarchies during style transfer, showing higher content preservation win rate against sentence-only approaches through paragraph-level structural encoding, as well as direct prompting method through sentence-level pattern extraction and matching. The results establish new capabilities for coherent long-text style transfer without requiring parallel corpora or LLM fine-tuning.</li>
</ul>

<h3>Title: TSLFormer: A Lightweight Transformer Model for Turkish Sign Language Recognition Using Skeletal Landmarks</h3>
<ul>
<li><strong>Authors: </strong>Kutay Ert√ºrk, Furkan Altƒ±nƒ±≈üƒ±k, ƒ∞rem Sarƒ±altƒ±n, √ñmer Nezih Gerek</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07890">https://arxiv.org/abs/2505.07890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07890">https://arxiv.org/pdf/2505.07890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07890]] TSLFormer: A Lightweight Transformer Model for Turkish Sign Language Recognition Using Skeletal Landmarks(https://arxiv.org/abs/2505.07890)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This study presents TSLFormer, a light and robust word-level Turkish Sign Language (TSL) recognition model that treats sign gestures as ordered, string-like language. Instead of using raw RGB or depth videos, our method only works with 3D joint positions - articulation points - extracted using Google's Mediapipe library, which focuses on the hand and torso skeletal locations. This creates efficient input dimensionality reduction while preserving important semantic gesture information. Our approach revisits sign language recognition as sequence-to-sequence translation, inspired by the linguistic nature of sign languages and the success of transformers in natural language processing. Since TSLFormer uses the self-attention mechanism, it effectively captures temporal co-occurrence within gesture sequences and highlights meaningful motion patterns as words unfold. Evaluated on the AUTSL dataset with over 36,000 samples and 227 different words, TSLFormer achieves competitive performance with minimal computational cost. These results show that joint-based input is sufficient for enabling real-time, mobile, and assistive communication systems for hearing-impaired individuals.</li>
</ul>

<h3>Title: TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking</h3>
<ul>
<li><strong>Authors: </strong>Ching Nam Hang, Pei-Duo Yu, Chee Wei Tan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07891">https://arxiv.org/abs/2505.07891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07891">https://arxiv.org/pdf/2505.07891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07891]] TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking(https://arxiv.org/abs/2505.07891)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In the age of social media, the rapid spread of misinformation and rumors has led to the emergence of infodemics, where false information poses a significant threat to society. To combat this issue, we introduce TrumorGPT , a novel generative artificial intelligence solution designed for fact-checking in the health domain. TrumorGPT aims to distinguish "trumors", which are health-related rumors that turn out to be true, providing a crucial tool in differentiating between mere speculation and verified facts. This framework leverages a large language model (LLM) with few-shot learning for semantic health knowledge graph construction and semantic reasoning. TrumorGPT incorporates graph-based retrieval-augmented generation (GraphRAG) to address the hallucination issue common in LLMs and the limitations of static training data. GraphRAG involves accessing and utilizing information from regularly updated semantic health knowledge graphs that consist of the latest medical news and health information, ensuring that fact-checking by TrumorGPT is based on the most recent data. Evaluating with extensive healthcare datasets, TrumorGPT demonstrates superior performance in fact-checking for public health claims. Its ability to effectively conduct fact-checking across various platforms marks a critical step forward in the fight against health-related misinformation, enhancing trust and accuracy in the digital information age.</li>
</ul>

<h3>Title: Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks</h3>
<ul>
<li><strong>Authors: </strong>Jiafan Li, Jiaqi Zhu, Liang Chang, Yilin Li, Miaomiao Li, Yang Wang, Hongan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07895">https://arxiv.org/abs/2505.07895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07895">https://arxiv.org/pdf/2505.07895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07895]] Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks(https://arxiv.org/abs/2505.07895)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Nowadays, numerous online platforms can be described as multi-modal heterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's product review networks. Accurately categorizing nodes within these networks is crucial for analyzing the corresponding entities, which requires effective representation learning on nodes. However, existing multi-modal fusion methods often adopt either early fusion strategies which may lose the unique characteristics of individual modalities, or late fusion approaches overlooking the cross-modal guidance in GNN-based information propagation. In this paper, we propose a novel model for node classification in MMHNs, named Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node representations by capturing the mutual influence of multiple modalities during the information propagation process, within the framework of heterogeneous graph transformer. Specifically, a nested inter-modal attention mechanism is integrated into the inter-node attention to achieve adaptive multi-modal fusion, and modality alignment is also taken into account to encourage the propagation among nodes with consistent similarities across all modalities. Moreover, an attention loss is augmented to mitigate the impact of missing modalities. Extensive experiments validate the superiority of the model in the node classification task, providing an innovative view to handle multi-modal data, especially when accompanied with network structures.</li>
</ul>

<h3>Title: DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise</h3>
<ul>
<li><strong>Authors: </strong>Ding Cao, Yuchen Cai, Rongxi Guo, Xuesong He, Guiquan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07899">https://arxiv.org/abs/2505.07899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07899">https://arxiv.org/pdf/2505.07899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07899]] DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise(https://arxiv.org/abs/2505.07899)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sequential knowledge editing techniques aim to continuously update the knowledge in large language models at a low cost, preventing the models from generating outdated or incorrect information. However, existing sequential editing methods suffer from a significant decline in editing success rates after long-term editing. Through theoretical analysis and experiments, we identify that as the number of edits increases, the model's output increasingly deviates from the desired target, leading to a drop in editing success rates. We refer to this issue as the accumulation of superimposed noise problem. To address this, we identify the factors contributing to this deviation and propose DeltaEdit, a novel method that optimizes update parameters through a dynamic orthogonal constraints strategy, effectively reducing interference between edits to mitigate deviation. Experimental results demonstrate that DeltaEdit significantly outperforms existing methods in edit success rates and the retention of generalization capabilities, ensuring stable and reliable model performance even under extensive sequential editing.</li>
</ul>

<h3>Title: Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting</h3>
<ul>
<li><strong>Authors: </strong>Minh-Duc Nguyen, Hyung-Jeong Yang, Soo-Hyung Kim, Ji-Eun Shin, Seung-Won Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07901">https://arxiv.org/abs/2505.07901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07901">https://arxiv.org/pdf/2505.07901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07901]] Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting(https://arxiv.org/abs/2505.07901)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The dyadic reaction generation task involves synthesizing responsive facial reactions that align closely with the behaviors of a conversational partner, enhancing the naturalness and effectiveness of human-like interaction simulations. This paper introduces a novel approach, the Latent Behavior Diffusion Model, comprising a context-aware autoencoder and a diffusion-based conditional generator that addresses the challenge of generating diverse and contextually relevant facial reactions from input speaker behaviors. The autoencoder compresses high-dimensional input features, capturing dynamic patterns in listener reactions while condensing complex input data into a concise latent representation, facilitating more expressive and contextually appropriate reaction synthesis. The diffusion-based conditional generator operates on the latent space generated by the autoencoder to predict realistic facial reactions in a non-autoregressive manner. This approach allows for generating diverse facial reactions that reflect subtle variations in conversational cues and emotional states. Experimental results demonstrate the effectiveness of our approach in achieving superior performance in dyadic reaction synthesis tasks compared to existing methods.</li>
</ul>

<h3>Title: SEM: Reinforcement Learning for Search-Efficient Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zeyang Sha, Shiwen Cui, Weiqiang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07903">https://arxiv.org/abs/2505.07903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07903">https://arxiv.org/pdf/2505.07903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07903]] SEM: Reinforcement Learning for Search-Efficient Large Language Models(https://arxiv.org/abs/2505.07903)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models(LLMs) have demonstrated their capabilities not only in reasoning but also in invoking external tools, particularly search engines. However, teaching models to discern when to invoke search and when to rely on their internal knowledge remains a significant challenge. Existing reinforcement learning approaches often lead to redundant search behaviors, resulting in inefficiencies and over-cost. In this paper, we propose SEM, a novel post-training reinforcement learning framework that explicitly trains LLMs to optimize search usage. By constructing a balanced dataset combining MuSiQue and MMLU, we create scenarios where the model must learn to distinguish between questions it can answer directly and those requiring external retrieval. We design a structured reasoning template and employ Group Relative Policy Optimization(GRPO) to post-train the model's search behaviors. Our reward function encourages accurate answering without unnecessary search while promoting effective retrieval when needed. Experimental results demonstrate that our method significantly reduces redundant search operations while maintaining or improving answer accuracy across multiple challenging benchmarks. This framework advances the model's reasoning efficiency and extends its capability to judiciously leverage external knowledge.</li>
</ul>

<h3>Title: A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny</h3>
<ul>
<li><strong>Authors: </strong>Karahan Sarƒ±ta≈ü, √áaƒüatay Yƒ±ldƒ±z</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07908">https://arxiv.org/abs/2505.07908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07908">https://arxiv.org/pdf/2505.07908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07908]] A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny(https://arxiv.org/abs/2505.07908)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this reproduction study, we revisit recent claims that self-attention implements kernel principal component analysis (KPCA) (Teo et al., 2024), positing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix of the keys, and (ii) that self-attention projects queries onto the principal component axes of the key matrix $K$ in a feature space. Our analysis reveals three critical inconsistencies: (1) No alignment exists between learned self-attention value vectors and what is proposed in the KPCA perspective, with average similarity metrics (optimal cosine similarity $\leq 0.32$, linear CKA (Centered Kernel Alignment) $\leq 0.11$, kernel CKA $\leq 0.32$) indicating negligible correspondence; (2) Reported decreases in reconstruction loss $J_\text{proj}$, arguably justifying the claim that the self-attention minimizes the projection error of KPCA, are misinterpreted, as the quantities involved differ by orders of magnitude ($\sim\!10^3$); (3) Gram matrix eigenvalue statistics, introduced to justify that $V$ captures the eigenvector of the gram matrix, are irreproducible without undocumented implementation-specific adjustments. Across 10 transformer architectures, we conclude that the KPCA interpretation of self-attention lacks empirical support.</li>
</ul>

<h3>Title: Tuning for Trustworthiness -- Balancing Performance and Explanation Consistency in Neural Network Optimization</h3>
<ul>
<li><strong>Authors: </strong>Alexander Hinterleitner, Thomas Bartz-Beielstein</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07910">https://arxiv.org/abs/2505.07910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07910">https://arxiv.org/pdf/2505.07910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07910]] Tuning for Trustworthiness -- Balancing Performance and Explanation Consistency in Neural Network Optimization(https://arxiv.org/abs/2505.07910)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Despite the growing interest in Explainable Artificial Intelligence (XAI), explainability is rarely considered during hyperparameter tuning or neural architecture optimization, where the focus remains primarily on minimizing predictive loss. In this work, we introduce the novel concept of XAI consistency, defined as the agreement among different feature attribution methods, and propose new metrics to quantify it. For the first time, we integrate XAI consistency directly into the hyperparameter tuning objective, creating a multi-objective optimization framework that balances predictive performance with explanation robustness. Implemented within the Sequential Parameter Optimization Toolbox (SPOT), our approach uses both weighted aggregation and desirability-based strategies to guide model selection. Through our proposed framework and supporting tools, we explore the impact of incorporating XAI consistency into the optimization process. This enables us to characterize distinct regions in the architecture configuration space: one region with poor performance and comparatively low interpretability, another with strong predictive performance but weak interpretability due to low \gls{xai} consistency, and a trade-off region that balances both objectives by offering high interpretability alongside competitive performance. Beyond introducing this novel approach, our research provides a foundation for future investigations into whether models from the trade-off zone-balancing performance loss and XAI consistency-exhibit greater robustness by avoiding overfitting to training performance, thereby leading to more reliable predictions on out-of-distribution data.</li>
</ul>

<h3>Title: Combining Bayesian Inference and Reinforcement Learning for Agent Decision Making: A Review</h3>
<ul>
<li><strong>Authors: </strong>Chengmin Zhou, Ville Kyrki, Pasi Fr√§nti, Laura Ruotsalainen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07911">https://arxiv.org/abs/2505.07911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07911">https://arxiv.org/pdf/2505.07911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07911]] Combining Bayesian Inference and Reinforcement Learning for Agent Decision Making: A Review(https://arxiv.org/abs/2505.07911)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Bayesian inference has many advantages in decision making of agents (e.g. robotics/simulative agent) over a regular data-driven black-box neural network: Data-efficiency, generalization, interpretability, and safety where these advantages benefit directly/indirectly from the uncertainty quantification of Bayesian inference. However, there are few comprehensive reviews to summarize the progress of Bayesian inference on reinforcement learning (RL) for decision making to give researchers a systematic understanding. This paper focuses on combining Bayesian inference with RL that nowadays is an important approach in agent decision making. To be exact, this paper discusses the following five topics: 1) Bayesian methods that have potential for agent decision making. First basic Bayesian methods and models (Bayesian rule, Bayesian learning, and Bayesian conjugate models) are discussed followed by variational inference, Bayesian optimization, Bayesian deep learning, Bayesian active learning, Bayesian generative models, Bayesian meta-learning, and lifelong Bayesian learning. 2) Classical combinations of Bayesian methods with model-based RL (with approximation methods), model-free RL, and inverse RL. 3) Latest combinations of potential Bayesian methods with RL. 4) Analytical comparisons of methods that combine Bayesian methods with RL with respect to data-efficiency, generalization, interpretability, and safety. 5) In-depth discussions in six complex problem variants of RL, including unknown reward, partial-observability, multi-agent, multi-task, non-linear non-Gaussian, and hierarchical RL problems and the summary of how Bayesian methods work in the data collection, data processing and policy learning stages of RL to pave the way for better agent decision-making strategies.</li>
</ul>

<h3>Title: On-Device Crack Segmentation for Edge Structural Health Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Zhang, Ye Xu, Luciano Sebastian Martinez-Rau, Quynh Nguyen Phuong Vu, Bengt Oelmann, Sebastian Bader</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07915">https://arxiv.org/abs/2505.07915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07915">https://arxiv.org/pdf/2505.07915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07915]] On-Device Crack Segmentation for Edge Structural Health Monitoring(https://arxiv.org/abs/2505.07915)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Crack segmentation can play a critical role in Structural Health Monitoring (SHM) by enabling accurate identification of crack size and location, which allows to monitor structural damages over time. However, deploying deep learning models for crack segmentation on resource-constrained microcontrollers presents significant challenges due to limited memory, computational power, and energy resources. To address these challenges, this study explores lightweight U-Net architectures tailored for TinyML applications, focusing on three optimization strategies: filter number reduction, network depth reduction, and the use of Depthwise Separable Convolutions (DWConv2D). Our results demonstrate that reducing convolution kernels and network depth significantly reduces RAM and Flash requirement, and inference times, albeit with some accuracy trade-offs. Specifically, by reducing the filer number to 25%, the network depth to four blocks, and utilizing depthwise convolutions, a good compromise between segmentation performance and resource consumption is achieved. This makes the network particularly suitable for low-power TinyML applications. This study not only advances TinyML-based crack segmentation but also provides the possibility for energy-autonomous edge SHM systems.</li>
</ul>

<h3>Title: Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions</h3>
<ul>
<li><strong>Authors: </strong>Daoze Zhang, Zhijian Bao, Sihang Du, Zhiyi Zhao, Kuangling Zhang, Dezheng Bao, Yang Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07920">https://arxiv.org/abs/2505.07920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07920">https://arxiv.org/pdf/2505.07920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07920]] Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions(https://arxiv.org/abs/2505.07920)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Peer review is a critical component of scientific progress in the fields like AI, but the rapid increase in submission volume has strained the reviewing system, which inevitably leads to reviewer shortages and declines review quality. Besides the growing research popularity, another key factor in this overload is the repeated resubmission of substandard manuscripts, largely due to the lack of effective tools for authors to self-evaluate their work before submission. Large Language Models (LLMs) show great promise in assisting both authors and reviewers, and their performance is fundamentally limited by the quality of the peer review data. However, existing peer review datasets face three major limitations: (1) limited data diversity, (2) inconsistent and low-quality data due to the use of revised rather than initial submissions, and (3) insufficient support for tasks involving rebuttal and reviewer-author interactions. To address these challenges, we introduce the largest consistency-ensured peer review and rebuttal dataset named Re^2, which comprises 19,926 initial submissions, 70,668 review comments, and 53,818 rebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the rebuttal and discussion stage is framed as a multi-turn conversation paradigm to support both traditional static review tasks and dynamic interactive LLM assistants, providing more practical guidance for authors to refine their manuscripts and helping alleviate the growing review burden. Our data and code are available in this https URL.</li>
</ul>

<h3>Title: Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks</h3>
<ul>
<li><strong>Authors: </strong>Thomas R. Harvey, Fabian Ruehle, Cristofero S. Fraser-Taliente, James Halverson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, cs.SC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07956">https://arxiv.org/abs/2505.07956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07956">https://arxiv.org/pdf/2505.07956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07956]] Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks(https://arxiv.org/abs/2505.07956)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We present a novel approach to symbolic regression using vision-capable large language models (LLMs) and the ideas behind Google DeepMind's Funsearch. The LLM is given a plot of a univariate function and tasked with proposing an ansatz for that function. The free parameters of the ansatz are fitted using standard numerical optimisers, and a collection of such ans√§tze make up the population of a genetic algorithm. Unlike other symbolic regression techniques, our method does not require the specification of a set of functions to be used in regression, but with appropriate prompt engineering, we can arbitrarily condition the generative step. By using Kolmogorov Arnold Networks (KANs), we demonstrate that ``univariate is all you need'' for symbolic regression, and extend this method to multivariate functions by learning the univariate function on each edge of a trained KAN. The combined expression is then simplified by further processing with a language model.</li>
</ul>

<h3>Title: Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Weiyi Wu, Xinwen Xu, Chongyang Gao, Xingjian Diao, Siting Li, Lucas A. Salas, Jiang Gui</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07968">https://arxiv.org/abs/2505.07968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07968">https://arxiv.org/pdf/2505.07968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07968]] Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models(https://arxiv.org/abs/2505.07968)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have great potential in the field of health care, yet they face great challenges in adapting to rapidly evolving medical knowledge. This can lead to outdated or contradictory treatment suggestions. This study investigated how LLMs respond to evolving clinical guidelines, focusing on concept drift and internal inconsistencies. We developed the DriftMedQA benchmark to simulate guideline evolution and assessed the temporal reliability of various LLMs. Our evaluation of seven state-of-the-art models across 4,290 scenarios demonstrated difficulties in rejecting outdated recommendations and frequently endorsing conflicting guidance. Additionally, we explored two mitigation strategies: Retrieval-Augmented Generation and preference fine-tuning via Direct Preference Optimization. While each method improved model performance, their combination led to the most consistent and reliable results. These findings underscore the need to improve LLM robustness to temporal shifts to ensure more dependable applications in clinical practice.</li>
</ul>

<h3>Title: Task-Adaptive Semantic Communications with Controllable Diffusion-based Data Regeneration</h3>
<ul>
<li><strong>Authors: </strong>Fupei Guo, Achintha Wijesinghe, Songyang Zhang, Zhi Ding</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07980">https://arxiv.org/abs/2505.07980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07980">https://arxiv.org/pdf/2505.07980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07980]] Task-Adaptive Semantic Communications with Controllable Diffusion-based Data Regeneration(https://arxiv.org/abs/2505.07980)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Semantic communications represent a new paradigm of next-generation networking that shifts bit-wise data delivery to conveying the semantic meanings for bandwidth efficiency. To effectively accommodate various potential downstream tasks at the receiver side, one should adaptively convey the most critical semantic information. This work presents a novel task-adaptive semantic communication framework based on diffusion models that is capable of dynamically adjusting the semantic message delivery according to various downstream tasks. Specifically, we initialize the transmission of a deep-compressed general semantic representation from the transmitter to enable diffusion-based coarse data reconstruction at the receiver. The receiver identifies the task-specific demands and generates textual prompts as feedback. Integrated with the attention mechanism, the transmitter updates the semantic transmission with more details to better align with the objectives of the intended receivers. Our test results demonstrate the efficacy of the proposed method in adaptively preserving critical task-relevant information for semantic communications while preserving high compression efficiency.</li>
</ul>

<h3>Title: MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing</h3>
<ul>
<li><strong>Authors: </strong>Aybora Koksal, A. Aydin Alatan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07984">https://arxiv.org/abs/2505.07984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07984">https://arxiv.org/pdf/2505.07984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07984]] MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing(https://arxiv.org/abs/2505.07984)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Remarkable capabilities in understanding and generating text-image content have been demonstrated by recent advancements in multimodal large language models (MLLMs). However, their effectiveness in specialized domains-particularly those requiring resource-efficient and domain-specific adaptations-has remained limited. In this work, a lightweight multimodal language model termed MilChat is introduced, specifically adapted to analyze remote sensing imagery in secluded areas, including challenging missile launch sites. A new dataset, MilData, was compiled by verifying hundreds of aerial images through expert review, and subtle military installations were highlighted via detailed captions. Supervised fine-tuning on a 2B-parameter open-source MLLM with chain-of-thought (CoT) reasoning annotations was performed, enabling more accurate and interpretable explanations. Additionally, Group Relative Policy Optimization (GRPO) was leveraged to enhance the model's ability to detect critical domain-specific cues-such as defensive layouts and key military structures-while minimizing false positives on civilian scenes. Through empirical evaluations, it has been shown that MilChat significantly outperforms both larger, general-purpose multimodal models and existing remote sensing-adapted approaches on open-ended captioning and classification metrics. Over 80% recall and 98% precision were achieved on the newly proposed MilData benchmark, underscoring the potency of targeted fine-tuning and reinforcement learning in specialized real-world applications.</li>
</ul>

<h3>Title: Fair Play for Individuals, Foul Play for Groups? Auditing Anonymization's Impact on ML Fairness</h3>
<ul>
<li><strong>Authors: </strong>H√©ber H. Arcolezi, Mina Alishahi, Adda-Akram Bendoukha, Nesrine Kaaniche</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07985">https://arxiv.org/abs/2505.07985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07985">https://arxiv.org/pdf/2505.07985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07985]] Fair Play for Individuals, Foul Play for Groups? Auditing Anonymization's Impact on ML Fairness(https://arxiv.org/abs/2505.07985)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) algorithms are heavily based on the availability of training data, which, depending on the domain, often includes sensitive information about data providers. This raises critical privacy concerns. Anonymization techniques have emerged as a practical solution to address these issues by generalizing features or suppressing data to make it more difficult to accurately identify individuals. Although recent studies have shown that privacy-enhancing technologies can influence ML predictions across different subgroups, thus affecting fair decision-making, the specific effects of anonymization techniques, such as $k$-anonymity, $\ell$-diversity, and $t$-closeness, on ML fairness remain largely unexplored. In this work, we systematically audit the impact of anonymization techniques on ML fairness, evaluating both individual and group fairness. Our quantitative study reveals that anonymization can degrade group fairness metrics by up to four orders of magnitude. Conversely, similarity-based individual fairness metrics tend to improve under stronger anonymization, largely as a result of increased input homogeneity. By analyzing varying levels of anonymization across diverse privacy settings and data distributions, this study provides critical insights into the trade-offs between privacy, fairness, and utility, offering actionable guidelines for responsible AI development. Our code is publicly available at: this https URL.</li>
</ul>

<h3>Title: A Scalable System to Prove Machine Learning Fairness in Zero-Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Zhang, Shen Dong, O. Deniz Kose, Yanning Shen, Yupeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07997">https://arxiv.org/abs/2505.07997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07997">https://arxiv.org/pdf/2505.07997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07997]] A Scalable System to Prove Machine Learning Fairness in Zero-Knowledge(https://arxiv.org/abs/2505.07997)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>With the rise of machine learning techniques, ensuring the fairness of decisions made by machine learning algorithms has become of great importance in critical applications. However, measuring fairness often requires full access to the model parameters, which compromises the confidentiality of the models. In this paper, we propose a solution using zero-knowledge proofs, which allows the model owner to convince the public that a machine learning model is fair while preserving the secrecy of the model. To circumvent the efficiency barrier of naively proving machine learning inferences in zero-knowledge, our key innovation is a new approach to measure fairness only with model parameters and some aggregated information of the input, but not on any specific dataset. To achieve this goal, we derive new bounds for the fairness of logistic regression and deep neural network models that are tighter and better reflecting the fairness compared to prior work. Moreover, we develop efficient zero-knowledge proof protocols for common computations involved in measuring fairness, including the spectral norm of matrices, maximum, absolute value, and fixed-point arithmetic. We have fully implemented our system, FairZK, that proves machine learning fairness in zero-knowledge. Experimental results show that FairZK is significantly faster than the naive approach and an existing scheme that use zero-knowledge inferences as a subroutine. The prover time is improved by 3.1x--1789x depending on the size of the model and the dataset. FairZK can scale to a large model with 47 million parameters for the first time, and generates a proof for its fairness in 343 seconds. This is estimated to be 4 orders of magnitude faster than existing schemes, which only scale to small models with hundreds to thousands of parameters.</li>
</ul>

<h3>Title: Vision Foundation Model Embedding-Based Semantic Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Max Peter Ronecker, Matthew Foutter, Amine Elhafsi, Daniele Gammelli, Ihor Barakaiev, Marco Pavone, Daniel Watzenig</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07998">https://arxiv.org/abs/2505.07998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07998">https://arxiv.org/pdf/2505.07998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07998]] Vision Foundation Model Embedding-Based Semantic Anomaly Detection(https://arxiv.org/abs/2505.07998)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic anomalies are contextually invalid or unusual combinations of familiar visual elements that can cause undefined behavior and failures in system-level reasoning for autonomous systems. This work explores semantic anomaly detection by leveraging the semantic priors of state-of-the-art vision foundation models, operating directly on the image. We propose a framework that compares local vision embeddings from runtime images to a database of nominal scenarios in which the autonomous system is deemed safe and performant. In this work, we consider two variants of the proposed framework: one using raw grid-based embeddings, and another leveraging instance segmentation for object-centric representations. To further improve robustness, we introduce a simple filtering mechanism to suppress false positives. Our evaluations on CARLA-simulated anomalies show that the instance-based method with filtering achieves performance comparable to GPT-4o, while providing precise anomaly localization. These results highlight the potential utility of vision embeddings from foundation models for real-time anomaly detection in autonomous systems.</li>
</ul>

<h3>Title: Large Language Models and Arabic Content: A Review</h3>
<ul>
<li><strong>Authors: </strong>Haneh Rhel, Dmitri Roussinov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08004">https://arxiv.org/abs/2505.08004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08004">https://arxiv.org/pdf/2505.08004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08004]] Large Language Models and Arabic Content: A Review(https://arxiv.org/abs/2505.08004)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Over the past three years, the rapid advancement of Large Language Models (LLMs) has had a profound impact on multiple areas of Artificial Intelligence (AI), particularly in Natural Language Processing (NLP) across diverse languages, including Arabic. Although Arabic is considered one of the most widely spoken languages across 27 countries in the Arabic world and used as a second language in some other non-Arabic countries as well, there is still a scarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face various challenges due to the complexities of the Arabic language, including its rich morphology, intricate structure, and diverse writing standards, among other factors. Researchers have been actively addressing these challenges, demonstrating that pre-trained Large Language Models (LLMs) trained on multilingual corpora achieve significant success in various Arabic NLP tasks. This study provides an overview of using large language models (LLMs) for the Arabic language, highlighting early pre-trained Arabic Language models across various NLP applications and their ability to handle diverse Arabic content tasks and dialects. It also provides an overview of how techniques like finetuning and prompt engineering can enhance the performance of these models. Additionally, the study summarizes common Arabic benchmarks and datasets while presenting our observations on the persistent upward trend in the adoption of LLMs.</li>
</ul>

<h3>Title: Evaluating Explanation Quality in X-IDS Using Feature Alignment Metrics</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Alquliti, Erisa Karafili, BooJoong Kang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08006">https://arxiv.org/abs/2505.08006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08006">https://arxiv.org/pdf/2505.08006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08006]] Evaluating Explanation Quality in X-IDS Using Feature Alignment Metrics(https://arxiv.org/abs/2505.08006)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, interpretability</a></li>
<li><strong>Abstract: </strong>Explainable artificial intelligence (XAI) methods have become increasingly important in the context of explainable intrusion detection systems (X-IDSs) for improving the interpretability and trustworthiness of X-IDSs. However, existing evaluation approaches for XAI focus on model-specific properties such as fidelity and simplicity, and neglect whether the explanation content is meaningful or useful within the application domain. In this paper, we introduce new evaluation metrics measuring the quality of explanations from X-IDSs. The metrics aim at quantifying how well explanations are aligned with predefined feature sets that can be identified from domain-specific knowledge bases. Such alignment with these knowledge bases enables explanations to reflect domain knowledge and enables meaningful and actionable insights for security analysts. In our evaluation, we demonstrate the use of the proposed metrics to evaluate the quality of explanations from X-IDSs. The experimental results show that the proposed metrics can offer meaningful differences in explanation quality across X-IDSs and attack types, and assess how well X-IDS explanations reflect known domain knowledge. The findings of the proposed metrics provide actionable insights for security analysts to improve the interpretability of X-IDS in practical settings.</li>
</ul>

<h3>Title: RDD: Robust Feature Detector and Descriptor using Deformable Transformer</h3>
<ul>
<li><strong>Authors: </strong>Gonglin Chen, Tianwen Fu, Haiwei Chen, Wenbin Teng, Hanyuan Xiao, Yajie Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08013">https://arxiv.org/abs/2505.08013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08013">https://arxiv.org/pdf/2505.08013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08013]] RDD: Robust Feature Detector and Descriptor using Deformable Transformer(https://arxiv.org/abs/2505.08013)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>As a core step in structure-from-motion and SLAM, robust feature detection and description under challenging scenarios such as significant viewpoint changes remain unresolved despite their ubiquity. While recent works have identified the importance of local features in modeling geometric transformations, these methods fail to learn the visual cues present in long-range relationships. We present Robust Deformable Detector (RDD), a novel and robust keypoint detector/descriptor leveraging the deformable transformer, which captures global context and geometric invariance through deformable self-attention mechanisms. Specifically, we observed that deformable attention focuses on key locations, effectively reducing the search space complexity and modeling the geometric invariance. Furthermore, we collected an Air-to-Ground dataset for training in addition to the standard MegaDepth dataset. Our proposed method outperforms all state-of-the-art keypoint detection/description methods in sparse matching tasks and is also capable of semi-dense matching. To ensure comprehensive evaluation, we introduce two challenging benchmarks: one emphasizing large viewpoint and scale variations, and the other being an Air-to-Ground benchmark -- an evaluation setting that has recently gaining popularity for 3D reconstruction across different altitudes.</li>
</ul>

<h3>Title: Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Steffen Schotth√∂fer, H. Lexie Yang, Stefan Schnake</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08022">https://arxiv.org/abs/2505.08022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08022">https://arxiv.org/pdf/2505.08022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08022]] Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks(https://arxiv.org/abs/2505.08022)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deployment of neural networks on resource-constrained devices demands models that are both compact and robust to adversarial inputs. However, compression and adversarial robustness often conflict. In this work, we introduce a dynamical low-rank training scheme enhanced with a novel spectral regularizer that controls the condition number of the low-rank core in each layer. This approach mitigates the sensitivity of compressed models to adversarial perturbations without sacrificing clean accuracy. The method is model- and data-agnostic, computationally efficient, and supports rank adaptivity to automatically compress the network at hand. Extensive experiments across standard architectures, datasets, and adversarial attacks show the regularized networks can achieve over 94% compression while recovering or improving adversarial accuracy relative to uncompressed baselines.</li>
</ul>

<h3>Title: Demo: A Practical Testbed for Decentralized Federated Learning on Physical Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Chao Feng, Nicolas Huber, Alberto Huertas Celdran, Gerome Bovet, Burkhard Stiller</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08033">https://arxiv.org/abs/2505.08033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08033">https://arxiv.org/pdf/2505.08033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08033]] Demo: A Practical Testbed for Decentralized Federated Learning on Physical Edge Devices(https://arxiv.org/abs/2505.08033)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training without sharing raw data, preserving participant privacy. Decentralized FL (DFL) eliminates reliance on a central server, mitigating the single point of failure inherent in the traditional FL paradigm, while introducing deployment challenges on resource-constrained devices. To evaluate real-world applicability, this work designs and deploys a physical testbed using edge devices such as Raspberry Pi and Jetson Nano. The testbed is built upon a DFL training platform, NEBULA, and extends it with a power monitoring module to measure energy consumption during training. Experiments across multiple datasets show that model performance is influenced by the communication topology, with denser topologies leading to better outcomes in DFL settings.</li>
</ul>

<h3>Title: TiSpell: A Semi-Masked Methodology for Tibetan Spelling Correction covering Multi-Level Error with Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Yutong Liu, Feng Xiao, Ziyue Zhang, Yongbin Yu, Cheng Huang, Fan Gao, Xiangxiang Wang, Ma-bao Ban, Manping Fan, Thupten Tsering, Cheng Huang, Gadeng Luosang, Renzeng Duojie, Nyima Tashi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08037">https://arxiv.org/abs/2505.08037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08037">https://arxiv.org/pdf/2505.08037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08037]] TiSpell: A Semi-Masked Methodology for Tibetan Spelling Correction covering Multi-Level Error with Data Augmentation(https://arxiv.org/abs/2505.08037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-level Tibetan spelling correction addresses errors at both the character and syllable levels within a unified model. Existing methods focus mainly on single-level correction and lack effective integration of both levels. Moreover, there are no open-source datasets or augmentation methods tailored for this task in Tibetan. To tackle this, we propose a data augmentation approach using unlabeled text to generate multi-level corruptions, and introduce TiSpell, a semi-masked model capable of correcting both character- and syllable-level errors. Although syllable-level correction is more challenging due to its reliance on global context, our semi-masked strategy simplifies this process. We synthesize nine types of corruptions on clean sentences to create a robust training set. Experiments on both simulated and real-world data demonstrate that TiSpell, trained on our dataset, outperforms baseline models and matches the performance of state-of-the-art approaches, confirming its effectiveness.</li>
</ul>

<h3>Title: Browser Security Posture Analysis: A Client-Side Security Assessment Framework</h3>
<ul>
<li><strong>Authors: </strong>Avihay Cohen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08050">https://arxiv.org/abs/2505.08050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08050">https://arxiv.org/pdf/2505.08050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08050]] Browser Security Posture Analysis: A Client-Side Security Assessment Framework(https://arxiv.org/abs/2505.08050)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>Modern web browsers have effectively become the new operating system for business applications, yet their security posture is often under-scrutinized. This paper presents a novel, comprehensive Browser Security Posture Analysis Framework[1], a browser-based client-side security assessment toolkit that runs entirely in JavaScript and WebAssembly within the browser. It performs a battery of over 120 in-browser security tests in situ, providing fine-grained diagnostics of security policies and features that network-level or os-level tools cannot observe. This yields insights into how well a browser enforces critical client-side security invariants. We detail the motivation for such a framework, describe its architecture and implementation, and dive into the technical design of numerous test modules (covering the same-origin policy, cross-origin resource sharing, content security policy, sandboxing, XSS protection, extension interference via WeakRefs, permissions audits, garbage collection behavior, cryptographic APIs, SSL certificate validation, advanced web platform security features like SharedArrayBuffer, Content filtering controls ,and internal network accessibility). We then present an experimental evaluation across different browsers and enterprise scenarios, highlighting gaps in legacy browsers and common misconfigurations. Finally, we discuss the security and privacy implications of our findings, compare with related work in browser security and enterprise endpoint solutions, and outline future enhancements such as real-time posture monitoring and SIEM integration.</li>
</ul>

<h3>Title: FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08054">https://arxiv.org/abs/2505.08054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08054">https://arxiv.org/pdf/2505.08054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08054]] FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning(https://arxiv.org/abs/2505.08054)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Safety alignment approaches in large language models (LLMs) often lead to the over-refusal of benign queries, significantly diminishing their utility in sensitive scenarios. To address this challenge, we introduce FalseReject, a comprehensive resource containing 16k seemingly toxic queries accompanied by structured responses across 44 safety-related categories. We propose a graph-informed adversarial multi-agent interaction framework to generate diverse and complex prompts, while structuring responses with explicit reasoning to aid models in accurately distinguishing safe from unsafe contexts. FalseReject includes training datasets tailored for both standard instruction-tuned models and reasoning-oriented models, as well as a human-annotated benchmark test set. Our extensive benchmarking on 29 state-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges. Empirical results demonstrate that supervised finetuning with FalseReject substantially reduces unnecessary refusals without compromising overall safety or general language capabilities.</li>
</ul>

<h3>Title: Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Dong Shu, Xuansheng Wu, Haiyan Zhao, Mengnan Du, Ninghao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08080">https://arxiv.org/abs/2505.08080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08080">https://arxiv.org/pdf/2505.08080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08080]] Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders(https://arxiv.org/abs/2505.08080)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sparse Autoencoders (SAEs) have recently emerged as powerful tools for interpreting and steering the internal representations of large language models (LLMs). However, conventional approaches to analyzing SAEs typically rely solely on input-side activations, without considering the causal influence between each latent feature and the model's output. This work is built on two key hypotheses: (1) activated latents do not contribute equally to the construction of the model's output, and (2) only latents with high causal influence are effective for model steering. To validate these hypotheses, we propose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method that identifies the most influential latents by incorporating output-side gradient information.</li>
</ul>

<h3>Title: Fr√©chet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids</h3>
<ul>
<li><strong>Authors: </strong>Yuting Cai, Shaohuai Liu, Chao Tian, Le Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08082">https://arxiv.org/abs/2505.08082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08082">https://arxiv.org/pdf/2505.08082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08082]] Fr√©chet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids(https://arxiv.org/abs/2505.08082)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative artificial intelligence (AI) models in smart grids have advanced significantly in recent years due to their ability to generate large amounts of synthetic data, which would otherwise be difficult to obtain in the real world due to confidentiality constraints. A key challenge in utilizing such synthetic data is how to assess the data quality produced from such generative models. Traditional Euclidean distance-based metrics only reflect pair-wise relations between two individual samples, and could fail in evaluating quality differences between groups of synthetic datasets. In this work, we propose a novel metric based on the Fr√©chet Distance (FD) estimated between two datasets in a learned feature space. The proposed method evaluates the quality of generation from a distributional perspective. Empirical results demonstrate the superiority of the proposed metric across timescales and models, enhancing the reliability of data-driven decision-making in smart grid operations.</li>
</ul>

<h3>Title: Visually Interpretable Subtask Reasoning for Visual Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Yu Cheng, Arushi Goel, Hakan Bilen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08084">https://arxiv.org/abs/2505.08084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08084">https://arxiv.org/pdf/2505.08084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08084]] Visually Interpretable Subtask Reasoning for Visual Question Answering(https://arxiv.org/abs/2505.08084)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Answering complex visual questions like `Which red furniture can be used for sitting?' requires multi-step reasoning, including object recognition, attribute filtering, and relational understanding. Recent work improves interpretability in multimodal large language models (MLLMs) by decomposing tasks into sub-task programs, but these methods are computationally expensive and less accurate due to poor adaptation to target data. To address this, we introduce VISTAR (Visually Interpretable Subtask-Aware Reasoning Model), a subtask-driven training framework that enhances both interpretability and reasoning by generating textual and visual explanations within MLLMs. Instead of relying on external models, VISTAR fine-tunes MLLMs to produce structured Subtask-of-Thought rationales (step-by-step reasoning sequences). Experiments on two benchmarks show that VISTAR consistently improves reasoning accuracy while maintaining interpretability. Our code and dataset will be available at this https URL.</li>
</ul>

<h3>Title: A Federated Random Forest Solution for Secure Distributed Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Cotorobai, Jorge Miguel Silva, Jose Luis Oliveira</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08085">https://arxiv.org/abs/2505.08085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08085">https://arxiv.org/pdf/2505.08085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08085]] A Federated Random Forest Solution for Secure Distributed Machine Learning(https://arxiv.org/abs/2505.08085)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Privacy and regulatory barriers often hinder centralized machine learning solutions, particularly in sectors like healthcare where data cannot be freely shared. Federated learning has emerged as a powerful paradigm to address these concerns; however, existing frameworks primarily support gradient-based models, leaving a gap for more interpretable, tree-based approaches. This paper introduces a federated learning framework for Random Forest classifiers that preserves data privacy and provides robust performance in distributed settings. By leveraging PySyft for secure, privacy-aware computation, our method enables multiple institutions to collaboratively train Random Forest models on locally stored data without exposing sensitive information. The framework supports weighted model averaging to account for varying data distributions, incremental learning to progressively refine models, and local evaluation to assess performance across heterogeneous datasets. Experiments on two real-world healthcare benchmarks demonstrate that the federated approach maintains competitive predictive accuracy - within a maximum 9\% margin of centralized methods - while satisfying stringent privacy requirements. These findings underscore the viability of tree-based federated learning for scenarios where data cannot be centralized due to regulatory, competitive, or technical constraints. The proposed solution addresses a notable gap in existing federated learning libraries, offering an adaptable tool for secure distributed machine learning tasks that demand both transparency and reliable performance. The tool is available at this https URL.</li>
</ul>

<h3>Title: Manifold Learning with Normalizing Flows: Towards Regularity, Expressivity and Iso-Riemannian Geometry</h3>
<ul>
<li><strong>Authors: </strong>Willem Diepeveen, Deanna Needell</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08087">https://arxiv.org/abs/2505.08087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08087">https://arxiv.org/pdf/2505.08087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08087]] Manifold Learning with Normalizing Flows: Towards Regularity, Expressivity and Iso-Riemannian Geometry(https://arxiv.org/abs/2505.08087)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Modern machine learning increasingly leverages the insight that high-dimensional data often lie near low-dimensional, non-linear manifolds, an idea known as the manifold hypothesis. By explicitly modeling the geometric structure of data through learning Riemannian geometry algorithms can achieve improved performance and interpretability in tasks like clustering, dimensionality reduction, and interpolation. In particular, learned pullback geometry has recently undergone transformative developments that now make it scalable to learn and scalable to evaluate, which further opens the door for principled non-linear data analysis and interpretable machine learning. However, there are still steps to be taken when considering real-world multi-modal data. This work focuses on addressing distortions and modeling errors that can arise in the multi-modal setting and proposes to alleviate both challenges through isometrizing the learned Riemannian structure and balancing regularity and expressivity of the diffeomorphism parametrization. We showcase the effectiveness of the synergy of the proposed approaches in several numerical experiments with both synthetic and real data.</li>
</ul>

<h3>Title: Topology-Guided Knowledge Distillation for Efficient Point Cloud Processing</h3>
<ul>
<li><strong>Authors: </strong>Luu Tung Hai, Thinh D. Le, Zhicheng Ding, Qing Tian, Truong-Son Hy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08101">https://arxiv.org/abs/2505.08101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08101">https://arxiv.org/pdf/2505.08101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08101]] Topology-Guided Knowledge Distillation for Efficient Point Cloud Processing(https://arxiv.org/abs/2505.08101)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Point cloud processing has gained significant attention due to its critical role in applications such as autonomous driving and 3D object recognition. However, deploying high-performance models like Point Transformer V3 in resource-constrained environments remains challenging due to their high computational and memory demands. This work introduces a novel distillation framework that leverages topology-aware representations and gradient-guided knowledge distillation to effectively transfer knowledge from a high-capacity teacher to a lightweight student model. Our approach captures the underlying geometric structures of point clouds while selectively guiding the student model's learning process through gradient-based feature alignment. Experimental results in the Nuscenes, SemanticKITTI, and Waymo datasets demonstrate that the proposed method achieves competitive performance, with an approximately 16x reduction in model size and a nearly 1.9x decrease in inference time compared to its teacher model. Notably, on NuScenes, our method achieves state-of-the-art performance among knowledge distillation techniques trained solely on LiDAR data, surpassing prior knowledge distillation baselines in segmentation performance. Our implementation is available publicly at: this https URL</li>
</ul>

<h3>Title: Are LLMs complicated ethical dilemma analyzers?</h3>
<ul>
<li><strong>Authors: </strong>Jiashen (Jason)Du, Jesse Yao, Allen Liu, Zhekai Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08106">https://arxiv.org/abs/2505.08106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08106">https://arxiv.org/pdf/2505.08106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08106]] Are LLMs complicated ethical dilemma analyzers?(https://arxiv.org/abs/2505.08106)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>One open question in the study of Large Language Models (LLMs) is whether they can emulate human ethical reasoning and act as believable proxies for human judgment. To investigate this, we introduce a benchmark dataset comprising 196 real-world ethical dilemmas and expert opinions, each segmented into five structured components: Introduction, Key Factors, Historical Theoretical Perspectives, Resolution Strategies, and Key Takeaways. We also collect non-expert human responses for comparison, limited to the Key Factors section due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini, Claude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric framework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine similarity, and Universal Sentence Encoder similarity. Metric weights are computed through an inversion-based ranking alignment and pairwise AHP analysis, enabling fine-grained comparison of model outputs to expert responses. Our results show that LLMs generally outperform non-expert humans in lexical and structural alignment, with GPT-4o-mini performing most consistently across all sections. However, all models struggle with historical grounding and proposing nuanced resolution strategies, which require contextual abstraction. Human responses, while less structured, occasionally achieve comparable semantic similarity, suggesting intuitive moral reasoning. These findings highlight both the strengths and current limitations of LLMs in ethical decision-making.</li>
</ul>

<h3>Title: Sleep Position Classification using Transfer Learning for Bed-based Pressure Sensors</h3>
<ul>
<li><strong>Authors: </strong>Olivier Papillon, Rafik Goubran, James Green, Julien Larivi√®re-Chartier, Caitlin Higginson, Frank Knoefel, R√©becca Robillard</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08111">https://arxiv.org/abs/2505.08111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08111">https://arxiv.org/pdf/2505.08111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08111]] Sleep Position Classification using Transfer Learning for Bed-based Pressure Sensors(https://arxiv.org/abs/2505.08111)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Bed-based pressure-sensitive mats (PSMs) offer a non-intrusive way of monitoring patients during sleep. We focus on four-way sleep position classification using data collected from a PSM placed under a mattress in a sleep clinic. Sleep positions can affect sleep quality and the prevalence of sleep disorders, such as apnea. Measurements were performed on patients with suspected sleep disorders referred for assessments at a sleep clinic. Training deep learning models can be challenging in clinical settings due to the need for large amounts of labeled data. To overcome the shortage of labeled training data, we utilize transfer learning to adapt pre-trained deep learning models to accurately estimate sleep positions from a low-resolution PSM dataset collected in a polysomnography sleep lab. Our approach leverages Vision Transformer models pre-trained on ImageNet using masked autoencoding (ViTMAE) and a pre-trained model for human pose estimation (ViTPose). These approaches outperform previous work from PSM-based sleep pose classification using deep learning (TCN) as well as traditional machine learning models (SVM, XGBoost, Random Forest) that use engineered features. We evaluate the performance of sleep position classification from 112 nights of patient recordings and validate it on a higher resolution 13-patient dataset. Despite the challenges of differentiating between sleep positions from low-resolution PSM data, our approach shows promise for real-world deployment in clinical settings</li>
</ul>

<h3>Title: Invariant-Based Cryptography: Toward a General Framework</h3>
<ul>
<li><strong>Authors: </strong>Stanislav Semenov</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08115">https://arxiv.org/abs/2505.08115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08115">https://arxiv.org/pdf/2505.08115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08115]] Invariant-Based Cryptography: Toward a General Framework(https://arxiv.org/abs/2505.08115)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We develop a generalized framework for invariant-based cryptography by extending the use of structural identities as core cryptographic mechanisms. Starting from a previously introduced scheme where a secret is encoded via a four-point algebraic invariant over masked functional values, we broaden the approach to include multiple classes of invariant constructions. In particular, we present new symmetric schemes based on shifted polynomial roots and functional equations constrained by symmetric algebraic conditions, such as discriminants and multilinear identities. These examples illustrate how algebraic invariants -- rather than one-way functions -- can enforce structural consistency and unforgeability. We analyze the cryptographic utility of such invariants in terms of recoverability, integrity binding, and resistance to forgery, and show that these constructions achieve security levels comparable to the original oscillatory model. This work establishes a foundation for invariant-based design as a versatile and compact alternative in symmetric cryptographic protocols.</li>
</ul>

<h3>Title: ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Mingxu Tao, Bowen Tang, Mingxuan Ma, Yining Zhang, Hourun Li, Feifan Wen, Hao Ma, Jia Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08130">https://arxiv.org/abs/2505.08130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08130">https://arxiv.org/pdf/2505.08130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08130]] ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval(https://arxiv.org/abs/2505.08130)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models~(LLMs) revolutionizes information retrieval, allowing users to obtain required answers through complex instructions within conversations. However, publicly available services remain inadequate in addressing the needs of faculty and students to search campus-specific information. It is primarily due to the LLM's lack of domain-specific knowledge and the limitation of search engines in supporting multilingual and timely scenarios. To tackle these challenges, we introduce ALOHA, a multilingual agent enhanced by hierarchical retrieval for university orientation. We also integrate external APIs into the front-end interface to provide interactive service. The human evaluation and case study show our proposed system has strong capabilities to yield correct, timely, and user-friendly responses to the queries in multiple languages, surpassing commercial chatbots and search engines. The system has been deployed and has provided service for more than 12,000 people.</li>
</ul>

<h3>Title: Large Language Models for Computer-Aided Design: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Licheng Zhang, Bach Le, Naveed Akhtar, Siew-Kei Lam, Tuan Ngo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.GR, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08137">https://arxiv.org/abs/2505.08137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08137">https://arxiv.org/pdf/2505.08137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08137]] Large Language Models for Computer-Aided Design: A Survey(https://arxiv.org/abs/2505.08137)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have seen rapid advancements in recent years, with models like ChatGPT and DeepSeek, showcasing their remarkable capabilities across diverse domains. While substantial research has been conducted on LLMs in various fields, a comprehensive review focusing on their integration with Computer-Aided Design (CAD) remains notably absent. CAD is the industry standard for 3D modeling and plays a vital role in the design and development of products across different industries. As the complexity of modern designs increases, the potential for LLMs to enhance and streamline CAD workflows presents an exciting frontier. This article presents the first systematic survey exploring the intersection of LLMs and CAD. We begin by outlining the industrial significance of CAD, highlighting the need for AI-driven innovation. Next, we provide a detailed overview of the foundation of LLMs. We also examine both closed-source LLMs as well as publicly available models. The core of this review focuses on the various applications of LLMs in CAD, providing a taxonomy of six key areas where these models are making considerable impact. Finally, we propose several promising future directions for further advancements, which offer vast opportunities for innovation and are poised to shape the future of CAD technology. Github: this https URL</li>
</ul>

<h3>Title: Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Brennon Brimhall, Philip Mathew, Neil Fendley, Yinzhi Cao, Matthew Green</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08138">https://arxiv.org/abs/2505.08138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08138">https://arxiv.org/pdf/2505.08138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08138]] Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning(https://arxiv.org/abs/2505.08138)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, membership infer</a></li>
<li><strong>Abstract: </strong>Machine unlearning methods take a model trained on a dataset and a forget set, then attempt to produce a model as if it had only been trained on the examples not in the forget set. We empirically show that an adversary is able to distinguish between a mirror model (a control model produced by retraining without the data to forget) and a model produced by an unlearning method across representative unlearning methods from the literature. We build distinguishing algorithms based on evaluation scores in the literature (i.e. membership inference scores) and Kullback-Leibler divergence. We propose a strong formal definition for machine unlearning called computational unlearning. Computational unlearning is defined as the inability for an adversary to distinguish between a mirror model and a model produced by an unlearning method. If the adversary cannot guess better than random (except with negligible probability), then we say that an unlearning method achieves computational unlearning. Our computational unlearning definition provides theoretical structure to prove unlearning feasibility results. For example, our computational unlearning definition immediately implies that there are no deterministic computational unlearning methods for entropic learning algorithms. We also explore the relationship between differential privacy (DP)-based unlearning methods and computational unlearning, showing that DP-based approaches can satisfy computational unlearning at the cost of an extreme utility collapse. These results demonstrate that current methodology in the literature fundamentally falls short of achieving computational unlearning. We conclude by identifying several open questions for future work.</li>
</ul>

<h3>Title: Multi-Layer Hierarchical Federated Learning with Quantization</h3>
<ul>
<li><strong>Authors: </strong>Seyed Mohammad Azimi-Abarghouyi, Carlo Fischione</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.IT, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08145">https://arxiv.org/abs/2505.08145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08145">https://arxiv.org/pdf/2505.08145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08145]] Multi-Layer Hierarchical Federated Learning with Quantization(https://arxiv.org/abs/2505.08145)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Almost all existing hierarchical federated learning (FL) models are limited to two aggregation layers, restricting scalability and flexibility in complex, large-scale networks. In this work, we propose a Multi-Layer Hierarchical Federated Learning framework (QMLHFL), which appears to be the first study that generalizes hierarchical FL to arbitrary numbers of layers and network architectures through nested aggregation, while employing a layer-specific quantization scheme to meet communication constraints. We develop a comprehensive convergence analysis for QMLHFL and derive a general convergence condition and rate that reveal the effects of key factors, including quantization parameters, hierarchical architecture, and intra-layer iteration counts. Furthermore, we determine the optimal number of intra-layer iterations to maximize the convergence rate while meeting a deadline constraint that accounts for both communication and computation times. Our results show that QMLHFL consistently achieves high learning accuracy, even under high data heterogeneity, and delivers notably improved performance when optimized, compared to using randomly selected values.</li>
</ul>

<h3>Title: A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem</h3>
<ul>
<li><strong>Authors: </strong>Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08148">https://arxiv.org/abs/2505.08148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08148">https://arxiv.org/pdf/2505.08148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08148]] A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem(https://arxiv.org/abs/2505.08148)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, transformer, generative</a></li>
<li><strong>Abstract: </strong>Millions of users leverage generative pretrained transformer (GPT)-based language models developed by leading model providers for a wide range of tasks. To support enhanced user interaction and customization, many platforms-such as OpenAI-now enable developers to create and publish tailored model instances, known as custom GPTs, via dedicated repositories or application stores. These custom GPTs empower users to browse and interact with specialized applications designed to meet specific needs. However, as custom GPTs see growing adoption, concerns regarding their security vulnerabilities have intensified. Existing research on these vulnerabilities remains largely theoretical, often lacking empirical, large-scale, and statistically rigorous assessments of associated risks. In this study, we analyze 14,904 custom GPTs to assess their susceptibility to seven exploitable threats, such as roleplay-based attacks, system prompt leakage, phishing content generation, and malicious code synthesis, across various categories and popularity tiers within the OpenAI marketplace. We introduce a multi-metric ranking system to examine the relationship between a custom GPT's popularity and its associated security risks. Our findings reveal that over 95% of custom GPTs lack adequate security protections. The most prevalent vulnerabilities include roleplay-based vulnerabilities (96.51%), system prompt leakage (92.20%), and phishing (91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit inherent security weaknesses, which are often inherited or amplified in custom GPTs. These results highlight the urgent need for enhanced security measures and stricter content moderation to ensure the safe deployment of GPT-based applications.</li>
</ul>

<h3>Title: Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage</h3>
<ul>
<li><strong>Authors: </strong>Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08167">https://arxiv.org/abs/2505.08167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08167">https://arxiv.org/pdf/2505.08167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08167]] Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage(https://arxiv.org/abs/2505.08167)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of large language models (LLMs) has provided significant support and opportunities for the advancement of domain-specific LLMs. However, fine-tuning these large models using Intangible Cultural Heritage (ICH) data inevitably faces challenges such as bias, incorrect knowledge inheritance, and catastrophic forgetting. To address these issues, we propose a novel training method that integrates a bidirectional chains of thought and a reward mechanism. This method is built upon ICH-Qwen, a large language model specifically designed for the field of intangible cultural heritage. The proposed method enables the model to not only perform forward reasoning but also enhances the accuracy of the generated answers by utilizing reverse questioning and reverse reasoning to activate the model's latent knowledge. Additionally, a reward mechanism is introduced during training to optimize the decision-making process. This mechanism improves the quality of the model's outputs through structural and content evaluations with different weighting schemes. We conduct comparative experiments on ICH-Qwen, with results demonstrating that our method outperforms 0-shot, step-by-step reasoning, knowledge distillation, and question augmentation methods in terms of accuracy, Bleu-4, and Rouge-L scores on the question-answering task. Furthermore, the paper highlights the effectiveness of combining the bidirectional chains of thought and reward mechanism through ablation experiments. In addition, a series of generalizability experiments are conducted, with results showing that the proposed method yields improvements on various domain-specific datasets and advanced models in areas such as Finance, Wikidata, and StrategyQA. This demonstrates that the method is adaptable to multiple domains and provides a valuable approach for model training in future applications across diverse fields.</li>
</ul>

<h3>Title: Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Xiaoshuo Yan, Zhaochuan Li, Lei Meng, Zhuang Qi, Wei Wu, Zixuan Li, Xiangxu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08173">https://arxiv.org/abs/2505.08173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08173">https://arxiv.org/pdf/2505.08173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08173]] Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification(https://arxiv.org/abs/2505.08173)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Causal inference has emerged as a promising approach to mitigate long-tail classification by handling the biases introduced by class imbalance. However, along with the change of advanced backbone models from Convolutional Neural Networks (CNNs) to Visual Transformers (ViT), existing causal models may not achieve an expected performance gain. This paper investigates the influence of existing causal models on CNNs and ViT variants, highlighting that ViT's global feature representation makes it hard for causal methods to model associations between fine-grained features and predictions, which leads to difficulties in classifying tail classes with similar visual appearance. To address these issues, this paper proposes TSCNet, a two-stage causal modeling method to discover fine-grained causal associations through multi-scale causal interventions. Specifically, in the hierarchical causal representation learning stage (HCRL), it decouples the background and objects, applying backdoor interventions at both the patch and feature level to prevent model from using class-irrelevant areas to infer labels which enhances fine-grained causal representation. In the counterfactual logits bias calibration stage (CLBC), it refines the optimization of model's decision boundary by adaptive constructing counterfactual balanced data distribution to remove the spurious associations in the logits caused by data distribution. Extensive experiments conducted on various long-tail benchmarks demonstrate that the proposed TSCNet can eliminate multiple biases introduced by data imbalance, which outperforms existing methods.</li>
</ul>

<h3>Title: Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images</h3>
<ul>
<li><strong>Authors: </strong>Ziteng Liu, Dongdong He, Chenghong Zhang, Wenpeng Gao, Yili Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08178">https://arxiv.org/abs/2505.08178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08178">https://arxiv.org/pdf/2505.08178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08178]] Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images(https://arxiv.org/abs/2505.08178)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Occlusion and the scarcity of labeled surgical data are significant challenges in disparity estimation for stereo laparoscopic images. To address these issues, this study proposes a Depth Guided Occlusion-Aware Disparity Refinement Network (DGORNet), which refines disparity maps by leveraging monocular depth information unaffected by occlusion. A Position Embedding (PE) module is introduced to provide explicit spatial context, enhancing the network's ability to localize and refine features. Furthermore, we introduce an Optical Flow Difference Loss (OFDLoss) for unlabeled data, leveraging temporal continuity across video frames to improve robustness in dynamic surgical scenes. Experiments on the SCARED dataset demonstrate that DGORNet outperforms state-of-the-art methods in terms of End-Point Error (EPE) and Root Mean Squared Error (RMSE), particularly in occlusion and texture-less regions. Ablation studies confirm the contributions of the Position Embedding and Optical Flow Difference Loss, highlighting their roles in improving spatial and temporal consistency. These results underscore DGORNet's effectiveness in enhancing disparity estimation for laparoscopic surgery, offering a practical solution to challenges in disparity estimation and data limitations.</li>
</ul>

<h3>Title: Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL</h3>
<ul>
<li><strong>Authors: </strong>Zhikun Tao, Gang Xiong, He Fang, Zhen Shen, Yunjun Han, Qing-Shan Jia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08179">https://arxiv.org/abs/2505.08179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08179">https://arxiv.org/pdf/2505.08179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08179]] Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL(https://arxiv.org/abs/2505.08179)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Offline safe reinforcement learning(OSRL) derives constraint-satisfying policies from pre-collected datasets, offers a promising avenue for deploying RL in safety-critical real-world domains such as robotics. However, the majority of existing approaches emphasize only short-term safety, neglecting long-horizon considerations. Consequently, they may violate safety constraints and fail to ensure sustained protection during online deployment. Moreover, the learned policies often struggle to handle states and actions that are not present or out-of-distribution(OOD) from the offline dataset, and exhibit limited sample efficiency. To address these challenges, we propose a novel framework Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based Pessimism (FASP). First, we employ Hamilton-Jacobi (H-J) reachability analysis to generate reliable safety labels, which serve as supervisory signals for training both a conditional variational autoencoder (CVAE) and a safety classifier. This approach not only ensures high sampling efficiency but also provides rigorous long-horizon safety guarantees. Furthermore, we utilize pessimistic estimation methods to estimate the Q-value of reward and cost, which mitigates the extrapolation errors induces by OOD actions, and penalize unsafe actions to enabled the agent to proactively avoid high-risk behaviors. Moreover, we theoretically prove the validity of this pessimistic estimation. Extensive experiments on DSRL benchmarks demonstrate that FASP algorithm achieves competitive performance across multiple experimental tasks, particularly outperforming state-of-the-art algorithms in terms of safety.</li>
</ul>

<h3>Title: DSADF: Thinking Fast and Slow for Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Alex Zhihao Dou, Dongfei Cui, Jun Yan, Weida Wang, Benteng Chen, Haoming Wang, Zeke Xie, Shufei Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08189">https://arxiv.org/abs/2505.08189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08189">https://arxiv.org/pdf/2505.08189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08189]] DSADF: Thinking Fast and Slow for Decision Making(https://arxiv.org/abs/2505.08189)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although Reinforcement Learning (RL) agents are effective in well-defined environments, they often struggle to generalize their learned policies to dynamic settings due to their reliance on trial-and-error interactions. Recent work has explored applying Large Language Models (LLMs) or Vision Language Models (VLMs) to boost the generalization of RL agents through policy optimization guidance or prior knowledge. However, these approaches often lack seamless coordination between the RL agent and the foundation model, leading to unreasonable decision-making in unfamiliar environments and efficiency bottlenecks. Making full use of the inferential capabilities of foundation models and the rapid response capabilities of RL agents and enhancing the interaction between the two to form a dual system is still a lingering scientific question. To address this problem, we draw inspiration from Kahneman's theory of fast thinking (System 1) and slow thinking (System 2), demonstrating that balancing intuition and deep reasoning can achieve nimble decision-making in a complex world. In this study, we propose a Dual-System Adaptive Decision Framework (DSADF), integrating two complementary modules: System 1, comprising an RL agent and a memory space for fast and intuitive decision making, and System 2, driven by a VLM for deep and analytical reasoning. DSADF facilitates efficient and adaptive decision-making by combining the strengths of both systems. The empirical study in the video game environment: Crafter and Housekeep demonstrates the effectiveness of our proposed method, showing significant improvements in decision abilities for both unseen and known tasks.</li>
</ul>

<h3>Title: Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Lhuqita Fazry, Valentino Vito</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08190">https://arxiv.org/abs/2505.08190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08190">https://arxiv.org/pdf/2505.08190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08190]] Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion Models(https://arxiv.org/abs/2505.08190)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Raindrop removal is a challenging task in image processing. Removing raindrops while relying solely on a single image further increases the difficulty of the task. Common approaches include the detection of raindrop regions in the image, followed by performing a background restoration process conditioned on those regions. While various methods can be applied for the detection step, the most common architecture used for background restoration is the Generative Adversarial Network (GAN). Recent advances in the use of diffusion models have led to state-of-the-art image inpainting techniques. In this paper, we introduce a novel technique for raindrop removal from a single image using diffusion-based image inpainting.</li>
</ul>

<h3>Title: Visual Watermarking in the Era of Diffusion Models: Advances and Challenges</h3>
<ul>
<li><strong>Authors: </strong>Junxian Duan, Jiyang Guang, Wenkui Yang, Ran He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08197">https://arxiv.org/abs/2505.08197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08197">https://arxiv.org/pdf/2505.08197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08197]] Visual Watermarking in the Era of Diffusion Models: Advances and Challenges(https://arxiv.org/abs/2505.08197)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, robust, watermark, diffusion, generative</a></li>
<li><strong>Abstract: </strong>As generative artificial intelligence technologies like Stable Diffusion advance, visual content becomes more vulnerable to misuse, raising concerns about copyright infringement. Visual watermarks serve as effective protection mechanisms, asserting ownership and deterring unauthorized use. Traditional deepfake detection methods often rely on passive techniques that struggle with sophisticated manipulations. In contrast, diffusion models enhance detection accuracy by allowing for the effective learning of features, enabling the embedding of imperceptible and robust watermarks. We analyze the strengths and challenges of watermark techniques related to diffusion models, focusing on their robustness and application in watermark generation. By exploring the integration of advanced diffusion models and watermarking security, we aim to advance the discourse on preserving watermark robustness against evolving forgery threats. It emphasizes the critical importance of developing innovative solutions to protect digital content and ensure the preservation of ownership rights in the era of generative AI.</li>
</ul>

<h3>Title: A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Boshi Gao, Qingjian Ni, Fanbo Ju, Yu Chen, Ziqi Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08199">https://arxiv.org/abs/2505.08199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08199">https://arxiv.org/pdf/2505.08199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08199]] A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting(https://arxiv.org/abs/2505.08199)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Long-term time series forecasting (LTSF) offers broad utility in practical settings like energy consumption and weather prediction. Accurately predicting long-term changes, however, is demanding due to the intricate temporal patterns and inherent multi-scale variations within time series. This work confronts key issues in LTSF, including the suboptimal use of multi-granularity information, the neglect of channel-specific attributes, and the unique nature of trend and seasonal components, by introducing a proficient MLP-based forecasting framework. Our method adeptly disentangles complex temporal dynamics using clear, concurrent predictions across various scales. These multi-scale forecasts are then skillfully integrated through a system that dynamically assigns importance to information from different granularities, sensitive to individual channel characteristics. To manage the specific features of temporal patterns, a two-pronged structure is utilized to model trend and seasonal elements independently. Experimental results on eight LTSF benchmarks demonstrate that MDMixer improves average MAE performance by 4.64% compared to the recent state-of-the-art MLP-based method (TimeMixer), while achieving an effective balance between training efficiency and model interpretability.</li>
</ul>

<h3>Title: A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs</h3>
<ul>
<li><strong>Authors: </strong>Artem Shelmanov, Ekaterina Fadeeva, Akim Tsvigun, Ivan Tsvigun, Zhuohan Xie, Igor Kiselev, Nico Daheim, Caiqi Zhang, Artem Vazhentsev, Mrinmaya Sachan, Preslav Nakov, Timothy Baldwin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08200">https://arxiv.org/abs/2505.08200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08200">https://arxiv.org/pdf/2505.08200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08200]] A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs(https://arxiv.org/abs/2505.08200)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have the tendency to hallucinate, i.e., to sporadically generate false or fabricated information. This presents a major challenge, as hallucinations often appear highly convincing and users generally lack the tools to detect them. Uncertainty quantification (UQ) provides a framework for assessing the reliability of model outputs, aiding in the identification of potential hallucinations. In this work, we introduce pre-trained UQ heads: supervised auxiliary modules for LLMs that substantially enhance their ability to capture uncertainty compared to unsupervised UQ methods. Their strong performance stems from the powerful Transformer architecture in their design and informative features derived from LLM attention maps. Experimental evaluation shows that these heads are highly robust and achieve state-of-the-art performance in claim-level hallucination detection across both in-domain and out-of-domain prompts. Moreover, these modules demonstrate strong generalization to languages they were not explicitly trained on. We pre-train a collection of UQ heads for popular LLM series, including Mistral, Llama, and Gemma 2. We publicly release both the code and the pre-trained heads.</li>
</ul>

<h3>Title: LM-Scout: Analyzing the Security of Language Model Integration in Android Apps</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ibrahim (1), G≈±liz Seray Tuncay (2), Z. Berkay Celik (3), Aravind Machiry (3), Antonio Bianchi (3) ((1) Georgia Institute of Technology, (2) Google, (3) Purdue University)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08204">https://arxiv.org/abs/2505.08204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08204">https://arxiv.org/pdf/2505.08204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08204]] LM-Scout: Analyzing the Security of Language Model Integration in Android Apps(https://arxiv.org/abs/2505.08204)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Developers are increasingly integrating Language Models (LMs) into their mobile apps to provide features such as chat-based assistants. To prevent LM misuse, they impose various restrictions, including limits on the number of queries, input length, and allowed topics. However, if the LM integration is insecure, attackers can bypass these restrictions and gain unrestricted access to the LM, potentially harming developers' reputations and leading to significant financial losses. This paper presents the first systematic study of insecure usage of LMs by Android apps. We first manually analyze a preliminary dataset of apps to investigate LM integration methods, construct a taxonomy that categorizes the LM usage restrictions implemented by the apps, and determine how to bypass them. Alarmingly, we can bypass restrictions in 127 out of 181 apps. Then, we develop LM-Scout, a fully automated tool to detect on a large-scale vulnerable usage of LMs in 2,950 mobile apps. LM-Scout shows that, in many cases (i.e., 120 apps), it is possible to find and exploit such security issues automatically. Finally, we identify the root causes for the identified issues and offer recommendations for secure LM integration.</li>
</ul>

<h3>Title: Deep Probabilistic Modeling of User Behavior for Anomaly Detection via Mixture Density Networks</h3>
<ul>
<li><strong>Authors: </strong>Lu Dai, Wenxuan Zhu, Xuehui Quan, Renzi Meng, Sheng Cai, Yichen Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08220">https://arxiv.org/abs/2505.08220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08220">https://arxiv.org/pdf/2505.08220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08220]] Deep Probabilistic Modeling of User Behavior for Anomaly Detection via Mixture Density Networks(https://arxiv.org/abs/2505.08220)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>To improve the identification of potential anomaly patterns in complex user behavior, this paper proposes an anomaly detection method based on a deep mixture density network. The method constructs a Gaussian mixture model parameterized by a neural network, enabling conditional probability modeling of user behavior. It effectively captures the multimodal distribution characteristics commonly present in behavioral data. Unlike traditional classifiers that rely on fixed thresholds or a single decision boundary, this approach defines an anomaly scoring function based on probability density using negative log-likelihood. This significantly enhances the model's ability to detect rare and unstructured behaviors. Experiments are conducted on the real-world network user dataset UNSW-NB15. A series of performance comparisons and stability validation experiments are designed. These cover multiple evaluation aspects, including Accuracy, F1- score, AUC, and loss fluctuation. The results show that the proposed method outperforms several advanced neural network architectures in both performance and training stability. This study provides a more expressive and discriminative solution for user behavior modeling and anomaly detection. It strongly promotes the application of deep probabilistic modeling techniques in the fields of network security and intelligent risk control.</li>
</ul>

<h3>Title: Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix</h3>
<ul>
<li><strong>Authors: </strong>Unai Gurbindo, Axel Brando, Jaume Abella, Caroline K√∂nig</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08228">https://arxiv.org/abs/2505.08228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08228">https://arxiv.org/pdf/2505.08228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08228]] Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix(https://arxiv.org/abs/2505.08228)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Enhancing the robustness of object detection systems under adverse weather conditions is crucial for the advancement of autonomous driving technology. This study presents a novel approach leveraging the diffusion model Instruct Pix2Pix to develop prompting methodologies that generate realistic datasets with weather-based augmentations aiming to mitigate the impact of adverse weather on the perception capabilities of state-of-the-art object detection models, including Faster R-CNN and YOLOv10. Experiments were conducted in two environments, in the CARLA simulator where an initial evaluation of the proposed data augmentation was provided, and then on the real-world image data sets BDD100K and ACDC demonstrating the effectiveness of the approach in real environments. The key contributions of this work are twofold: (1) identifying and quantifying the performance gap in object detection models under challenging weather conditions, and (2) demonstrating how tailored data augmentation strategies can significantly enhance the robustness of these models. This research establishes a solid foundation for improving the reliability of perception systems in demanding environmental scenarios, and provides a pathway for future advancements in autonomous driving.</li>
</ul>

<h3>Title: G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for Contactless Fingerprint Recognition</h3>
<ul>
<li><strong>Authors: </strong>Santhoshkumar Peddi, Soham Bandyopadhyay, Debasis Samanta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08233">https://arxiv.org/abs/2505.08233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08233">https://arxiv.org/pdf/2505.08233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08233]] G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for Contactless Fingerprint Recognition(https://arxiv.org/abs/2505.08233)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>This paper presents G-MSGINet, a unified and efficient framework for robust contactless fingerprint recognition that jointly performs minutiae localization and identity embedding directly from raw input images. Existing approaches rely on multi-branch architectures, orientation labels, or complex preprocessing steps, which limit scalability and generalization across real-world acquisition scenarios. In contrast, the proposed architecture introduces the GMSGI layer, a novel computational module that integrates grouped pixel-level involution, dynamic multi-scale kernel generation, and graph-based relational modelling into a single processing unit. Stacked GMSGI layers progressively refine both local minutiae-sensitive features and global topological representations through end-to-end optimization. The architecture eliminates explicit orientation supervision and adapts graph connectivity directly from learned kernel descriptors, thereby capturing meaningful structural relationships among fingerprint regions without fixed heuristics. Extensive experiments on three benchmark datasets, namely PolyU, CFPose, and Benchmark 2D/3D, demonstrate that G-MSGINet consistently achieves minutiae F1-scores in the range of $0.83\pm0.02$ and Rank-1 identification accuracies between 97.0% and 99.1%, while maintaining an Equal Error Rate (EER) as low as 0.5%. These results correspond to improvements of up to 4.8% in F1-score and 1.4% in Rank-1 accuracy when compared to prior methods, using only 0.38 million parameters and 6.63 giga floating-point operations, which represents up to ten times fewer parameters than competitive baselines. This highlights the scalability and effectiveness of G-MSGINet in real-world contactless biometric recognition scenarios.</li>
</ul>

<h3>Title: Removing Watermarks with Partial Regeneration using Semantic Information</h3>
<ul>
<li><strong>Authors: </strong>Krti Tallam, John Kevin Cava, Caleb Geniesse, N. Benjamin Erichson, Michael W. Mahoney</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08234">https://arxiv.org/abs/2505.08234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08234">https://arxiv.org/pdf/2505.08234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08234]] Removing Watermarks with Partial Regeneration using Semantic Information(https://arxiv.org/abs/2505.08234)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, watermark, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged as a primary line of defense for copyright and provenance. The newest watermarking schemes embed semantic signals - content-aware patterns that are designed to survive common image manipulations - yet their true robustness against adaptive adversaries remains under-explored. We expose a previously unreported vulnerability and introduce SemanticRegen, a three-stage, label-free attack that erases state-of-the-art semantic and invisible watermarks while leaving an image's apparent meaning intact. Our pipeline (i) uses a vision-language model to obtain fine-grained captions, (ii) extracts foreground masks with zero-shot segmentation, and (iii) inpaints only the background via an LLM-guided diffusion model, thereby preserving salient objects and style cues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing, StegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat the semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy below 0.75 for the remaining schemes, all while maintaining high perceptual quality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM) to quantify fidelity within foreground regions, showing that our attack achieves up to 12 percent higher mSSIM than prior diffusion-based attackers. These results highlight an urgent gap between current watermark defenses and the capabilities of adaptive, semantics-aware adversaries, underscoring the need for watermarking algorithms that are resilient to content-preserving regenerative attacks.</li>
</ul>

<h3>Title: EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation</h3>
<ul>
<li><strong>Authors: </strong>Hanle Zheng, Xujie Han, Zegang Peng, Shangbin Zhang, Guangxun Du, Zhuo Zou, Xilin Wang, Jibin Wu, Hao Guo, Lei Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08235">https://arxiv.org/abs/2505.08235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08235">https://arxiv.org/pdf/2505.08235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08235]] EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation(https://arxiv.org/abs/2505.08235)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Video Frame Interpolation (VFI) is a fundamental yet challenging task in computer vision, particularly under conditions involving large motion, occlusion, and lighting variation. Recent advancements in event cameras have opened up new opportunities for addressing these challenges. While existing event-based VFI methods have succeeded in recovering large and complex motions by leveraging handcrafted intermediate representations such as optical flow, these designs often compromise high-fidelity image reconstruction under subtle motion scenarios due to their reliance on explicit motion modeling. Meanwhile, diffusion models provide a promising alternative for VFI by reconstructing frames through a denoising process, eliminating the need for explicit motion estimation or warping operations. In this work, we propose EventDiff, a unified and efficient event-based diffusion model framework for VFI. EventDiff features a novel Event-Frame Hybrid AutoEncoder (HAE) equipped with a lightweight Spatial-Temporal Cross Attention (STCA) module that effectively fuses dynamic event streams with static frames. Unlike previous event-based VFI methods, EventDiff performs interpolation directly in the latent space via a denoising diffusion process, making it more robust across diverse and challenging VFI scenarios. Through a two-stage training strategy that first pretrains the HAE and then jointly optimizes it with the diffusion model, our method achieves state-of-the-art performance across multiple synthetic and real-world event VFI datasets. The proposed method outperforms existing state-of-the-art event-based VFI methods by up to 1.98dB in PSNR on Vimeo90K-Triplet and shows superior performance in SNU-FILM tasks with multiple difficulty levels. Compared to the emerging diffusion-based VFI approach, our method achieves up to 5.72dB PSNR gain on Vimeo90K-Triplet and 4.24X faster inference.</li>
</ul>

<h3>Title: Privacy-Preserving Analytics for Smart Meter (AMI) Data: A Hybrid Approach to Comply with CPUC Privacy Regulations</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Westrich</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08237">https://arxiv.org/abs/2505.08237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08237">https://arxiv.org/pdf/2505.08237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08237]] Privacy-Preserving Analytics for Smart Meter (AMI) Data: A Hybrid Approach to Comply with CPUC Privacy Regulations(https://arxiv.org/abs/2505.08237)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, federate, fair</a></li>
<li><strong>Abstract: </strong>Advanced Metering Infrastructure (AMI) data from smart electric and gas meters enables valuable insights for utilities and consumers, but also raises significant privacy concerns. In California, regulatory decisions (CPUC D.11-07-056 and D.11-08-045) mandate strict privacy protections for customer energy usage data, guided by the Fair Information Practice Principles (FIPPs). We comprehensively explore solutions drawn from data anonymization, privacy-preserving machine learning (differential privacy and federated learning), synthetic data generation, and cryptographic techniques (secure multiparty computation, homomorphic encryption). This allows advanced analytics, including machine learning models, statistical and econometric analysis on energy consumption data, to be performed without compromising individual privacy. We evaluate each technique's theoretical foundations, effectiveness, and trade-offs in the context of utility data analytics, and we propose an integrated architecture that combines these methods to meet real-world needs. The proposed hybrid architecture is designed to ensure compliance with California's privacy rules and FIPPs while enabling useful analytics, from forecasting and personalized insights to academic research and econometrics, while strictly protecting individual privacy. Mathematical definitions and derivations are provided where appropriate to demonstrate privacy guarantees and utility implications rigorously. We include comparative evaluations of the techniques, an architecture diagram, and flowcharts to illustrate how they work together in practice. The result is a blueprint for utility data scientists and engineers to implement privacy-by-design in AMI data handling, supporting both data-driven innovation and strict regulatory compliance.</li>
</ul>

<h3>Title: Congenital Heart Disease recognition using Deep Learning/Transformer models</h3>
<ul>
<li><strong>Authors: </strong>Aidar Amangeldi, Vladislav Yarovenko, Angsar Taigonyrov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08242">https://arxiv.org/abs/2505.08242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08242">https://arxiv.org/pdf/2505.08242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08242]] Congenital Heart Disease recognition using Deep Learning/Transformer models(https://arxiv.org/abs/2505.08242)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Congenital Heart Disease (CHD) remains a leading cause of infant morbidity and mortality, yet non-invasive screening methods often yield false negatives. Deep learning models, with their ability to automatically extract features, can assist doctors in detecting CHD more effectively. In this work, we investigate the use of dual-modality (sound and image) deep learning methods for CHD diagnosis. We achieve 73.9% accuracy on the ZCHSound dataset and 80.72% accuracy on the DICOM Chest X-ray dataset.</li>
</ul>

<h3>Title: Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08245">https://arxiv.org/abs/2505.08245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08245">https://arxiv.org/pdf/2505.08245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08245]] Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement(https://arxiv.org/abs/2505.08245)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) has outpaced traditional evaluation methodologies. It presents novel challenges, such as measuring human-like psychological constructs, navigating beyond static and task-specific benchmarks, and establishing human-centered evaluation. These challenges intersect with Psychometrics, the science of quantifying the intangible aspects of human psychology, such as personality, values, and intelligence. This survey introduces and synthesizes an emerging interdisciplinary field of LLM Psychometrics, which leverages psychometric instruments, theories, and principles to evaluate, understand, and enhance LLMs. We systematically explore the role of Psychometrics in shaping benchmarking principles, broadening evaluation scopes, refining methodologies, validating results, and advancing LLM capabilities. This paper integrates diverse perspectives to provide a structured framework for researchers across disciplines, enabling a more comprehensive understanding of this nascent field. Ultimately, we aim to provide actionable insights for developing future evaluation paradigms that align with human-level AI and promote the advancement of human-centered AI systems for societal benefit. A curated repository of LLM psychometric resources is available at this https URL.</li>
</ul>

<h3>Title: Identifying Memorization of Diffusion Models through p-Laplace Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Brokman, Amit Giloni, Omer Hofman, Roman Vainshtein, Hisashi Kojima, Guy Gilboa</a></li>
<li><strong>Subjects: </strong>cs.CV, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08246">https://arxiv.org/abs/2505.08246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08246">https://arxiv.org/pdf/2505.08246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08246]] Identifying Memorization of Diffusion Models through p-Laplace Analysis(https://arxiv.org/abs/2505.08246)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models, today's leading image generative models, estimate the score function, i.e. the gradient of the log probability of (perturbed) data samples, without direct access to the underlying probability distribution. This work investigates whether the estimated score function can be leveraged to compute higher-order differentials, namely p-Laplace operators. We show here these operators can be employed to identify memorized training data. We propose a numerical p-Laplace approximation based on the learned score functions, showing its effectiveness in identifying key features of the probability landscape. We analyze the structured case of Gaussian mixture models, and demonstrate the results carry-over to image generative models, where memorization identification based on the p-Laplace operator is performed for the first time.</li>
</ul>

<h3>Title: Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted</h3>
<ul>
<li><strong>Authors: </strong>Shuaiwei Yuan, Junyu Dong, Yuezun Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08255">https://arxiv.org/abs/2505.08255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08255">https://arxiv.org/pdf/2505.08255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08255]] Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted(https://arxiv.org/abs/2505.08255)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, steal, generative</a></li>
<li><strong>Abstract: </strong>With the advancement of AI generative techniques, Deepfake faces have become incredibly realistic and nearly indistinguishable to the human eye. To counter this, Deepfake detectors have been developed as reliable tools for assessing face authenticity. These detectors are typically developed on Deep Neural Networks (DNNs) and trained using third-party datasets. However, this protocol raises a new security risk that can seriously undermine the trustfulness of Deepfake detectors: Once the third-party data providers insert poisoned (corrupted) data maliciously, Deepfake detectors trained on these datasets will be injected ``backdoors'' that cause abnormal behavior when presented with samples containing specific triggers. This is a practical concern, as third-party providers may distribute or sell these triggers to malicious users, allowing them to manipulate detector performance and escape accountability. This paper investigates this risk in depth and describes a solution to stealthily infect Deepfake detectors. Specifically, we develop a trigger generator, that can synthesize passcode-controlled, semantic-suppression, adaptive, and invisible trigger patterns, ensuring both the stealthiness and effectiveness of these triggers. Then we discuss two poisoning scenarios, dirty-label poisoning and clean-label poisoning, to accomplish the injection of backdoors. Extensive experiments demonstrate the effectiveness, stealthiness, and practicality of our method compared to several baselines.</li>
</ul>

<h3>Title: CNN and ViT Efficiency Study on Tiny ImageNet and DermaMNIST Datasets</h3>
<ul>
<li><strong>Authors: </strong>Aidar Amangeldi, Angsar Taigonyrov, Muhammad Huzaid Jawad, Chinedu Emmanuel Mbonu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08259">https://arxiv.org/abs/2505.08259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08259">https://arxiv.org/pdf/2505.08259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08259]] CNN and ViT Efficiency Study on Tiny ImageNet and DermaMNIST Datasets(https://arxiv.org/abs/2505.08259)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study evaluates the trade-offs between convolutional and transformer-based architectures on both medical and general-purpose image classification benchmarks. We use ResNet-18 as our baseline and introduce a fine-tuning strategy applied to four Vision Transformer variants (Tiny, Small, Base, Large) on DermatologyMNIST and TinyImageNet. Our goal is to reduce inference latency and model complexity with acceptable accuracy degradation. Through systematic hyperparameter variations, we demonstrate that appropriately fine-tuned Vision Transformers can match or exceed the baseline's performance, achieve faster inference, and operate with fewer parameters, highlighting their viability for deployment in resource-constrained environments.</li>
</ul>

<h3>Title: Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration</h3>
<ul>
<li><strong>Authors: </strong>Rishabh Agrawal, Himanshu Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08261">https://arxiv.org/abs/2505.08261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08261">https://arxiv.org/pdf/2505.08261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08261]] Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration(https://arxiv.org/abs/2505.08261)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid progress in large language models (LLMs) has paved the way for novel approaches in knowledge-intensive tasks. Among these, Cache-Augmented Generation (CAG) has emerged as a promising alternative to Retrieval-Augmented Generation (RAG). CAG minimizes retrieval latency and simplifies system design by preloading knowledge into the model's context. However, challenges persist in scaling CAG to accommodate large and dynamic knowledge bases effectively. This paper introduces Adaptive Contextual Compression (ACC), an innovative technique designed to dynamically compress and manage context inputs, enabling efficient utilization of the extended memory capabilities of modern LLMs. To further address the limitations of standalone CAG, we propose a Hybrid CAG-RAG Framework, which integrates selective retrieval to augment preloaded contexts in scenarios requiring additional information. Comprehensive evaluations on diverse datasets highlight the proposed methods' ability to enhance scalability, optimize efficiency, and improve multi-hop reasoning performance, offering practical solutions for real-world knowledge integration challenges.</li>
</ul>

<h3>Title: LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification</h3>
<ul>
<li><strong>Authors: </strong>Hang Gao, Wenxuan Huang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08265">https://arxiv.org/abs/2505.08265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08265">https://arxiv.org/pdf/2505.08265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08265]] LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification(https://arxiv.org/abs/2505.08265)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The use of large language models (LLMs) as feature enhancers to optimize node representations, which are then used as inputs for graph neural networks (GNNs), has shown significant potential in graph representation learning. However, the fundamental properties of this approach remain underexplored. To address this issue, we propose conducting a more in-depth analysis of this issue based on the interchange intervention method. First, we construct a synthetic graph dataset with controllable causal relationships, enabling precise manipulation of semantic relationships and causal modeling to provide data for analysis. Using this dataset, we conduct interchange interventions to examine the deeper properties of LLM enhancers and GNNs, uncovering their underlying logic and internal mechanisms. Building on the analytical results, we design a plug-and-play optimization module to improve the information transfer between LLM enhancers and GNNs. Experiments across multiple datasets and models validate the proposed module.</li>
</ul>

<h3>Title: Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Anle Ke, Xu Zhang, Tong Chen, Ming Lu, Chao Zhou, Jiawen Gu, Zhan Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08281">https://arxiv.org/abs/2505.08281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08281">https://arxiv.org/pdf/2505.08281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08281]] Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion(https://arxiv.org/abs/2505.08281)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Existing multimodal large model-based image compression frameworks often rely on a fragmented integration of semantic retrieval, latent compression, and generative models, resulting in suboptimal performance in both reconstruction fidelity and coding efficiency. To address these challenges, we propose a residual-guided ultra lowrate image compression named ResULIC, which incorporates residual signals into both semantic retrieval and the diffusion-based generation process. Specifically, we introduce Semantic Residual Coding (SRC) to capture the semantic disparity between the original image and its compressed latent representation. A perceptual fidelity optimizer is further applied for superior reconstruction quality. Additionally, we present the Compression-aware Diffusion Model (CDM), which establishes an optimal alignment between bitrates and diffusion time steps, improving compression-reconstruction synergy. Extensive experiments demonstrate the effectiveness of ResULIC, achieving superior objective and subjective performance compared to state-of-the-art diffusion-based methods with - 80.7%, -66.3% BD-rate saving in terms of LPIPS and FID. Project page is available at https: //njuvision.this http URL.</li>
</ul>

<h3>Title: On the Account Security Risks Posed by Password Strength Meters</h3>
<ul>
<li><strong>Authors: </strong>Ming Xu, Weili Han, Jitao Yu, Jing Liu, Xinyi Zhang, Yun Lin, Jin Song Dong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08292">https://arxiv.org/abs/2505.08292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08292">https://arxiv.org/pdf/2505.08292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08292]] On the Account Security Risks Posed by Password Strength Meters(https://arxiv.org/abs/2505.08292)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Password strength meters (PSMs) have been widely used by websites to gauge password strength, encouraging users to create stronger passwords. Popular data-driven PSMs, e.g., based on Markov, Probabilistic Context-free Grammar (PCFG) and neural networks, alarm strength based on a model learned from real passwords. Despite their proven effectiveness, the secure utility that arises from the leakage of trained passwords remains largely overlooked. To address this gap, we analyze 11 PSMs and find that 5 data-driven meters are vulnerable to membership inference attacks that expose their trained passwords, and seriously, 3 rule-based meters openly disclose their blocked passwords. We specifically design a PSM privacy leakage evaluation approach, and uncover that a series of general data-driven meters are vulnerable to leaking between 10^4 to 10^5 trained passwords, with the PCFG-based models being more vulnerable than other counterparts; furthermore, we aid in deriving insights that the inherent utility-privacy tradeoff is not as severe as previously thought. To further exploit the risks, we develop novel meter-aware attacks when a clever attacker can filter the used passwords during compromising accounts on websites using the meter, and experimentally show that attackers targeting websites that deployed the popular Zxcvbn meter can compromise an additional 5.84% user accounts within 10 attempts, demonstrating the urgent need for privacy-preserving PSMs that protect the confidentiality of the meter's used passwords. Finally, we sketch some counter-measures to mitigate these threats.</li>
</ul>

<h3>Title: FauForensics: Boosting Audio-Visual Deepfake Detection with Facial Action Units</h3>
<ul>
<li><strong>Authors: </strong>Jian Wang, Baoyuan Wu, Li Liu, Qingshan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08294">https://arxiv.org/abs/2505.08294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08294">https://arxiv.org/pdf/2505.08294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08294]] FauForensics: Boosting Audio-Visual Deepfake Detection with Facial Action Units(https://arxiv.org/abs/2505.08294)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The rapid evolution of generative AI has increased the threat of realistic audio-visual deepfakes, demanding robust detection methods. Existing solutions primarily address unimodal (audio or visual) forgeries but struggle with multimodal manipulations due to inadequate handling of heterogeneous modality features and poor generalization across datasets. To this end, we propose a novel framework called FauForensics by introducing biologically invariant facial action units (FAUs), which is a quantitative descriptor of facial muscle activity linked to emotion physiology. It serves as forgery-resistant representations that reduce domain dependency while capturing subtle dynamics often disrupted in synthetic content. Besides, instead of comparing entire video clips as in prior works, our method computes fine-grained frame-wise audiovisual similarities via a dedicated fusion module augmented with learnable cross-modal queries. It dynamically aligns temporal-spatial lip-audio relationships while mitigating multi-modal feature heterogeneity issues. Experiments on FakeAVCeleb and LAV-DF show state-of-the-art (SOTA) performance and superior cross-dataset generalizability with up to an average of 4.83\% than existing methods.</li>
</ul>

<h3>Title: A Practical Introduction to Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yinghan Sun, Hongxi Wang, Hua Chen, Wei Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08295">https://arxiv.org/abs/2505.08295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08295">https://arxiv.org/pdf/2505.08295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08295]] A Practical Introduction to Deep Reinforcement Learning(https://arxiv.org/abs/2505.08295)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning (DRL) has emerged as a powerful framework for solving sequential decision-making problems, achieving remarkable success in a wide range of applications, including game AI, autonomous driving, biomedicine, and large language models. However, the diversity of algorithms and the complexity of theoretical foundations often pose significant challenges for beginners seeking to enter the field. This tutorial aims to provide a concise, intuitive, and practical introduction to DRL, with a particular focus on the Proximal Policy Optimization (PPO) algorithm, which is one of the most widely used and effective DRL methods. To facilitate learning, we organize all algorithms under the Generalized Policy Iteration (GPI) framework, offering readers a unified and systematic perspective. Instead of lengthy theoretical proofs, we emphasize intuitive explanations, illustrative examples, and practical engineering techniques. This work serves as an efficient and accessible guide, helping readers rapidly progress from basic concepts to the implementation of advanced DRL algorithms.</li>
</ul>

<h3>Title: Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments</h3>
<ul>
<li><strong>Authors: </strong>Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08299">https://arxiv.org/abs/2505.08299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08299">https://arxiv.org/pdf/2505.08299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08299]] Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments(https://arxiv.org/abs/2505.08299)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>State-space models (SSMs), particularly the Mamba architecture, have emerged as powerful alternatives to Transformers for sequence modeling, offering linear-time complexity and competitive performance across diverse tasks. However, their large parameter counts pose significant challenges for deployment in resource-constrained environments. We propose a novel unstructured pruning framework tailored for Mamba models that achieves up to 70\% parameter reduction while retaining over 95\% of the original performance. Our approach integrates three key innovations: (1) a gradient-aware magnitude pruning technique that combines weight magnitude and gradient information to identify less critical parameters, (2) an iterative pruning schedule that gradually increases sparsity to maintain model stability, and (3) a global pruning strategy that optimizes parameter allocation across the entire model. Through extensive experiments on WikiText-103, Long Range Arena, and ETT time-series benchmarks, we demonstrate significant efficiency gains with minimal performance degradation. Our analysis of pruning effects on Mamba's components reveals critical insights into the architecture's redundancy and robustness, enabling practical deployment in resource-constrained settings while broadening Mamba's applicability.</li>
</ul>

<h3>Title: Knowledge-Informed Deep Learning for Irrigation Type Mapping from Remote Sensing</h3>
<ul>
<li><strong>Authors: </strong>Oishee Bintey Hoque, Nibir Chandra Mandal, Abhijin Adiga, Samarth Swarup, Sayjro Kossi Nouwakpo, Amanda Wilson, Madhav Marathe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08302">https://arxiv.org/abs/2505.08302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08302">https://arxiv.org/pdf/2505.08302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08302]] Knowledge-Informed Deep Learning for Irrigation Type Mapping from Remote Sensing(https://arxiv.org/abs/2505.08302)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate mapping of irrigation methods is crucial for sustainable agricultural practices and food systems. However, existing models that rely solely on spectral features from satellite imagery are ineffective due to the complexity of agricultural landscapes and limited training data, making this a challenging problem. We present Knowledge-Informed Irrigation Mapping (KIIM), a novel Swin-Transformer based approach that uses (i) a specialized projection matrix to encode crop to irrigation probability, (ii) a spatial attention map to identify agricultural lands from non-agricultural lands, (iii) bi-directional cross-attention to focus complementary information from different modalities, and (iv) a weighted ensemble for combining predictions from images and crop information. Our experimentation on five states in the US shows up to 22.9\% (IoU) improvement over baseline with a 71.4% (IoU) improvement for hard-to-classify drip irrigation. In addition, we propose a two-phase transfer learning approach to enhance cross-state irrigation mapping, achieving a 51% IoU boost in a state with limited labeled data. The ability to achieve baseline performance with only 40% of the training data highlights its efficiency, reducing the dependency on extensive manual labeling efforts and making large-scale, automated irrigation mapping more feasible and cost-effective.</li>
</ul>

<h3>Title: Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08303">https://arxiv.org/abs/2505.08303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08303">https://arxiv.org/pdf/2505.08303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08303]] Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow(https://arxiv.org/abs/2505.08303)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Black-Box prompt optimization methods have emerged as a promising strategy for refining input prompts to better align large language models (LLMs), thereby enhancing their task performance. Although these methods have demonstrated encouraging results, most studies and experiments have primarily focused on smaller-scale models (e.g., 7B, 14B) or earlier versions (e.g., GPT-3.5) of LLMs. As the scale of LLMs continues to increase, such as with DeepSeek V3 (671B), it remains an open question whether these black-box optimization techniques will continue to yield significant performance improvements for models of such scale. In response to this, we select three well-known black-box optimization methods and evaluate them on large-scale LLMs (DeepSeek V3 and Gemini 2.0 Flash) across four NLU and NLG datasets. The results show that these black-box prompt optimization methods offer only limited improvements on these large-scale LLMs. Furthermore, we hypothesize that the scale of the model is the primary factor contributing to the limited benefits observed. To explore this hypothesis, we conducted experiments on LLMs of varying sizes (Qwen 2.5 series, ranging from 7B to 72B) and observed an inverse scaling law, wherein the effectiveness of black-box optimization methods diminished as the model size increased.</li>
</ul>

<h3>Title: SpecSphere: Dual-Pass Spectral-Spatial Graph Neural Networks with Certified Robustness</h3>
<ul>
<li><strong>Authors: </strong>Yoonhyuk Choi, Chong-Kwon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08320">https://arxiv.org/abs/2505.08320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08320">https://arxiv.org/pdf/2505.08320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08320]] SpecSphere: Dual-Pass Spectral-Spatial Graph Neural Networks with Certified Robustness(https://arxiv.org/abs/2505.08320)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce SpecSphere, the first dual-pass spectral-spatial GNN that certifies every prediction against both $\ell\_{0}$ edge flips and $\ell\_{\infty}$ feature perturbations, adapts to the full homophily-heterophily spectrum, and surpasses the expressive power of 1-Weisfeiler-Lehman while retaining linear-time complexity. Our model couples a Chebyshev-polynomial spectral branch with an attention-gated spatial branch and fuses their representations through a lightweight MLP trained in a cooperative-adversarial min-max game. We further establish (i) a uniform Chebyshev approximation theorem, (ii) minimax-optimal risk across the homophily-heterophily spectrum, (iii) closed-form robustness certificates, and (iv) universal approximation strictly beyond 1-WL. SpecSphere achieves state-of-the-art node-classification accuracy and delivers tighter certified robustness guarantees on real-world benchmarks. These results demonstrate that high expressivity, heterophily adaptation, and provable robustness can coexist within a single, scalable architecture.</li>
</ul>

<h3>Title: An incremental algorithm for non-convex AI-enhanced medical image processing</h3>
<ul>
<li><strong>Authors: </strong>Elena Morotti</a></li>
<li><strong>Subjects: </strong>cs.CV, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08324">https://arxiv.org/abs/2505.08324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08324">https://arxiv.org/pdf/2505.08324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08324]] An incremental algorithm for non-convex AI-enhanced medical image processing(https://arxiv.org/abs/2505.08324)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Solving non-convex regularized inverse problems is challenging due to their complex optimization landscapes and multiple local minima. However, these models remain widely studied as they often yield high-quality, task-oriented solutions, particularly in medical imaging, where the goal is to enhance clinically relevant features rather than merely minimizing global error. We propose incDG, a hybrid framework that integrates deep learning with incremental model-based optimization to efficiently approximate the $\ell_0$-optimal solution of imaging inverse problems. Built on the Deep Guess strategy, incDG exploits a deep neural network to generate effective initializations for a non-convex variational solver, which refines the reconstruction through regularized incremental iterations. This design combines the efficiency of Artificial Intelligence (AI) tools with the theoretical guarantees of model-based optimization, ensuring robustness and stability. We validate incDG on TpV-regularized optimization tasks, demonstrating its effectiveness in medical image deblurring and tomographic reconstruction across diverse datasets, including synthetic images, brain CT slices, and chest-abdomen scans. Results show that incDG outperforms both conventional iterative solvers and deep learning-based methods, achieving superior accuracy and stability. Moreover, we confirm that training incDG without ground truth does not significantly degrade performance, making it a practical and powerful tool for solving non-convex inverse problems in imaging and beyond.</li>
</ul>

<h3>Title: FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing</h3>
<ul>
<li><strong>Authors: </strong>Haodong Zhao, Peng Peng, Chiyu Chen, Linqing Huang, Gongshen Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08325">https://arxiv.org/abs/2505.08325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08325">https://arxiv.org/pdf/2505.08325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08325]] FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing(https://arxiv.org/abs/2505.08325)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>Remote sensing (RS) images are usually produced at an unprecedented scale, yet they are geographically and institutionally distributed, making centralized model training challenging due to data-sharing restrictions and privacy concerns. Federated learning (FL) offers a solution by enabling collaborative model training across decentralized RS data sources without exposing raw data. However, there lacks a realistic federated dataset and benchmark in RS. Prior works typically rely on manually partitioned single dataset, which fail to capture the heterogeneity and scale of real-world RS data, and often use inconsistent experimental setups, hindering fair comparison. To address this gap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists of eight datasets that cover various sensors and resolutions and builds 135 clients, which is representative of realistic operational scenarios. Data for each client come from the same source, exhibiting authentic federated properties such as skewed label distributions, imbalanced client data volumes, and domain heterogeneity across clients. These characteristics reflect practical challenges in federated RS and support evaluation of FL methods at scale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation metrics to construct the comprehensive FedRS-Bench. The experimental results demonstrate that FL can consistently improve model performance over training on isolated data silos, while revealing performance trade-offs of different methods under varying client heterogeneity and availability conditions. We hope FedRS-Bench will accelerate research on large-scale, realistic FL in RS by providing a standardized, rich testbed and facilitating fair comparisons across future works. The source codes and dataset are available at this https URL.</li>
</ul>

<h3>Title: Structural-Temporal Coupling Anomaly Detection with Dynamic Graph Transformer</h3>
<ul>
<li><strong>Authors: </strong>Chang Zong, Yueting Zhuang, Jian Shao, Weiming Lu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08330">https://arxiv.org/abs/2505.08330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08330">https://arxiv.org/pdf/2505.08330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08330]] Structural-Temporal Coupling Anomaly Detection with Dynamic Graph Transformer(https://arxiv.org/abs/2505.08330)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Detecting anomalous edges in dynamic graphs is an important task in many applications over evolving triple-based data, such as social networks, transaction management, and epidemiology. A major challenge with this task is the absence of structural-temporal coupling information, which decreases the ability of the representation to distinguish anomalies from normal instances. Existing methods focus on handling independent structural and temporal features with embedding models, which ignore the deep interaction between these two types of information. In this paper, we propose a structural-temporal coupling anomaly detection architecture with a dynamic graph transformer model. Specifically, we introduce structural and temporal features from two integration levels to provide anomaly-aware graph evolutionary patterns. Then, a dynamic graph transformer enhanced by two-dimensional positional encoding is implemented to capture both discrimination and contextual consistency signals. Extensive experiments on six datasets demonstrate that our method outperforms current state-of-the-art models. Finally, a case study illustrates the strength of our method when applied to a real-world task.</li>
</ul>

<h3>Title: A computer vision-based model for occupancy detection using low-resolution thermal images</h3>
<ul>
<li><strong>Authors: </strong>Xue Cui, Vincent Gbouna Zakka, Minhyun Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08336">https://arxiv.org/abs/2505.08336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08336">https://arxiv.org/pdf/2505.08336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08336]] A computer vision-based model for occupancy detection using low-resolution thermal images(https://arxiv.org/abs/2505.08336)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Occupancy plays an essential role in influencing the energy consumption and operation of heating, ventilation, and air conditioning (HVAC) systems. Traditional HVAC typically operate on fixed schedules without considering occupancy. Advanced occupant-centric control (OCC) adopted occupancy status in regulating HVAC operations. RGB images combined with computer vision (CV) techniques are widely used for occupancy detection, however, the detailed facial and body features they capture raise significant privacy concerns. Low-resolution thermal images offer a non-invasive solution that mitigates privacy issues. The study developed an occupancy detection model utilizing low-resolution thermal images and CV techniques, where transfer learning was applied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The developed model ultimately achieved satisfactory performance, with precision, recall, mAP50, and mAP50 values approaching 1.000. The contributions of this model lie not only in mitigating privacy concerns but also in reducing computing resource demands.</li>
</ul>

<h3>Title: SHAP-based Explanations are Sensitive to Feature Representation</h3>
<ul>
<li><strong>Authors: </strong>Hyunseung Hwang, Andrew Bell, Joao Fonseca, Venetia Pliatsika, Julia Stoyanovich, Steven Euijong Whang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08345">https://arxiv.org/abs/2505.08345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08345">https://arxiv.org/pdf/2505.08345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08345]] SHAP-based Explanations are Sensitive to Feature Representation(https://arxiv.org/abs/2505.08345)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Local feature-based explanations are a key component of the XAI toolkit. These explanations compute feature importance values relative to an ``interpretable'' feature representation. In tabular data, feature values themselves are often considered interpretable. This paper examines the impact of data engineering choices on local feature-based explanations. We demonstrate that simple, common data engineering techniques, such as representing age with a histogram or encoding race in a specific way, can manipulate feature importance as determined by popular methods like SHAP. Notably, the sensitivity of explanations to feature representation can be exploited by adversaries to obscure issues like discrimination. While the intuition behind these results is straightforward, their systematic exploration has been lacking. Previous work has focused on adversarial attacks on feature-based explainers by biasing data or manipulating models. To the best of our knowledge, this is the first study demonstrating that explainers can be misled by standard, seemingly innocuous data engineering techniques.</li>
</ul>

<h3>Title: FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Ruixiao Shi, Fu Feng, Yucheng Xie, Jing Wang, Xin Geng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08349">https://arxiv.org/abs/2505.08349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08349">https://arxiv.org/pdf/2505.08349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08349]] FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning(https://arxiv.org/abs/2505.08349)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-domain few-shot learning (CD-FSL) requires models to generalize from limited labeled samples under significant distribution shifts. While recent methods enhance adaptability through lightweight task-specific modules, they operate solely in the spatial domain and overlook frequency-specific variations that are often critical for robust transfer. We observe that spatially similar images across domains can differ substantially in their spectral representations, with low and high frequencies capturing complementary semantic information at coarse and fine levels. This indicates that uniform spatial adaptation may overlook these spectral distinctions, thus constraining generalization. To address this, we introduce Frequency Adaptation and Diversion (FAD), a frequency-aware framework that explicitly models and modulates spectral components. At its core is the Frequency Diversion Adapter, which transforms intermediate features into the frequency domain using the discrete Fourier transform (DFT), partitions them into low, mid, and high-frequency bands via radial masks, and reconstructs each band using inverse DFT (IDFT). Each frequency band is then adapted using a dedicated convolutional branch with a kernel size tailored to its spectral scale, enabling targeted and disentangled adaptation across frequencies. Extensive experiments on the Meta-Dataset benchmark demonstrate that FAD consistently outperforms state-of-the-art methods on both seen and unseen domains, validating the utility of frequency-domain representations and band-wise adaptation for improving generalization in CD-FSL.</li>
</ul>

<h3>Title: Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring</h3>
<ul>
<li><strong>Authors: </strong>Mina Almasi, Ross Deans Kristensen-McLachlan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08351">https://arxiv.org/abs/2505.08351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08351">https://arxiv.org/pdf/2505.08351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08351]] Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring(https://arxiv.org/abs/2505.08351)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the potentials of Large Language Models (LLMs) as adaptive tutors in the context of second-language learning. In particular, we evaluate whether system prompting can reliably constrain LLMs to generate only text appropriate to the student's competence level. We simulate full teacher-student dialogues in Spanish using instruction-tuned, open-source LLMs ranging in size from 7B to 12B parameters. Dialogues are generated by having an LLM alternate between tutor and student roles with separate chat histories. The output from the tutor model is then used to evaluate the effectiveness of CEFR-based prompting to control text difficulty across three proficiency levels (A1, B1, C1). Our findings suggest that while system prompting can be used to constrain model outputs, prompting alone is too brittle for sustained, long-term interactional contexts - a phenomenon we term alignment drift. Our results provide insights into the feasibility of LLMs for personalized, proficiency-aligned adaptive tutors and provide a scalable method for low-cost evaluation of model performance without human participants.</li>
</ul>

<h3>Title: Density Ratio-based Causal Discovery from Bivariate Continuous-Discrete Data</h3>
<ul>
<li><strong>Authors: </strong>Takashi Nicholas Maeda, Shohei Shimizu, Hidetoshi Matsui</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08371">https://arxiv.org/abs/2505.08371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08371">https://arxiv.org/pdf/2505.08371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08371]] Density Ratio-based Causal Discovery from Bivariate Continuous-Discrete Data(https://arxiv.org/abs/2505.08371)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This paper proposes a causal discovery method for mixed bivariate data consisting of one continuous and one discrete variable. Existing constraint-based approaches are ineffective in the bivariate setting, as they rely on conditional independence tests that are not suited to bivariate data. Score-based methods either impose strong distributional assumptions or face challenges in fairly comparing causal directions between variables of different types, due to differences in their information content. We introduce a novel approach that determines causal direction by analyzing the monotonicity of the conditional density ratio of the continuous variable, conditioned on different values of the discrete variable. Our theoretical analysis shows that the conditional density ratio exhibits monotonicity when the continuous variable causes the discrete variable, but not in the reverse direction. This property provides a principled basis for comparing causal directions between variables of different types, free from strong distributional assumptions and bias arising from differences in their information content. We demonstrate its effectiveness through experiments on both synthetic and real-world datasets, showing superior accuracy compared to existing methods.</li>
</ul>

<h3>Title: Towards Contamination Resistant Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Rahmatullah Musawi, Sheng Lu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08389">https://arxiv.org/abs/2505.08389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08389">https://arxiv.org/pdf/2505.08389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08389]] Towards Contamination Resistant Benchmarks(https://arxiv.org/abs/2505.08389)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of large language models (LLMs) has transformed the landscape of natural language processing. Evaluating LLMs properly is crucial for understanding their potential and addressing concerns such as safety. However, LLM evaluation is confronted by various factors, among which contamination stands out as a key issue that undermines the reliability of evaluations. In this work, we introduce the concept of contamination resistance to address this challenge. We propose a benchmark based on Caesar ciphers (e.g., "ab" to "bc" when the shift is 1), which, despite its simplicity, is an excellent example of a contamination resistant benchmark. We test this benchmark on widely used LLMs under various settings, and we find that these models struggle with this benchmark when contamination is controlled. Our findings reveal issues in current LLMs and raise important questions regarding their true capabilities. Our work contributes to the development of contamination resistant benchmarks, enabling more rigorous LLM evaluation and offering insights into the true capabilities and limitations of LLMs.</li>
</ul>

<h3>Title: Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping</h3>
<ul>
<li><strong>Authors: </strong>Ren Zhuang, Ben Wang, Shuifa Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08392">https://arxiv.org/abs/2505.08392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08392">https://arxiv.org/pdf/2505.08392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08392]] Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping(https://arxiv.org/abs/2505.08392)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models leverage Chain-of-Thought (CoT) prompting for complex tasks, but their reasoning traces are often excessively verbose and inefficient, leading to significant computational costs and latency. Current CoT compression techniques typically rely on generic importance metrics and static compression rates, which may inadvertently remove functionally critical tokens or fail to adapt to varying reasoning complexity. To overcome these limitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic CoT compression via supervised fine-tuning. This approach introduces two synergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric accurately identifying functionally relevant tokens by measuring the gradient influence of their intermediate representations on the final answer loss, and (2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the compression rate based on runtime model uncertainty while ensuring local coherence through an adaptive N-token constraint. To our knowledge, this is the first work unifying a goal-oriented, gradient-based importance metric with dynamic, uncertainty-aware skipping for CoT compression. Trained on compressed MATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization across diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It achieves substantial efficiency gains - reducing CoT token counts by over 45% on average and delivering 1.6-2.0 times inference speedups - while maintaining high reasoning accuracy. Notably, it significantly outperforms existing baselines by preserving accuracy even at high effective compression rates, advancing the state of the art in the CoT reasoning efficiency-accuracy trade-off.</li>
</ul>

<h3>Title: TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers</h3>
<ul>
<li><strong>Authors: </strong>Aiyao He, Sijia Cui, Shuai Xu, Yanna Wang, Bo Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08402">https://arxiv.org/abs/2505.08402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08402">https://arxiv.org/pdf/2505.08402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08402]] TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers(https://arxiv.org/abs/2505.08402)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, large language models(LLMs) have played an increasingly important role in solving a wide range of NLP tasks, leveraging their capabilities of natural language understanding and generating. Integration with external tools further enhances LLMs' effectiveness, providing more precise, timely, and specialized responses. However, LLMs still encounter difficulties with non-executable actions and improper actions, which are primarily attributed to incorrect parameters. The process of generating parameters by LLMs is confined to the tool level, employing the coarse-grained strategy without considering the different difficulties of various tools. To address this issue, we propose TUMS, a novel framework designed to enhance the tool-use capabilities of LLMs by transforming tool-level processing into parameter-level processing. Specifically, our framework consists of four key components: (1) an intent recognizer that identifies the user's intent to help LLMs better understand the task; (2) a task decomposer that breaks down complex tasks into simpler subtasks, each involving a tool call; (3) a subtask processor equipped with multi-structure handlers to generate accurate parameters; and (4) an executor. Our empirical studies have evidenced the effectiveness and efficiency of the TUMS framework with an average of 19.6\% and 50.6\% improvement separately on easy and hard benchmarks of ToolQA, meanwhile, we demonstrated the key contribution of each part with ablation experiments, offering more insights and stimulating future research on Tool-augmented LLMs.</li>
</ul>

<h3>Title: ConDiSim: Conditional Diffusion Models for Simulation Based Inference</h3>
<ul>
<li><strong>Authors: </strong>Mayank Nautiyal, Andreas Hellander, Prashant Singh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08403">https://arxiv.org/abs/2505.08403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08403">https://arxiv.org/pdf/2505.08403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08403]] ConDiSim: Conditional Diffusion Models for Simulation Based Inference(https://arxiv.org/abs/2505.08403)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We present a conditional diffusion model - ConDiSim, for simulation-based inference of complex systems with intractable likelihoods. ConDiSim leverages denoising diffusion probabilistic models to approximate posterior distributions, consisting of a forward process that adds Gaussian noise to parameters, and a reverse process learning to denoise, conditioned on observed data. This approach effectively captures complex dependencies and multi-modalities within posteriors. ConDiSim is evaluated across ten benchmark problems and two real-world test problems, where it demonstrates effective posterior approximation accuracy while maintaining computational efficiency and stability in model training. ConDiSim offers a robust and extensible framework for simulation-based inference, particularly suitable for parameter inference workflows requiring fast inference methods.</li>
</ul>

<h3>Title: DArFace: Deformation Aware Robustness for Low Quality Face Recognition</h3>
<ul>
<li><strong>Authors: </strong>Sadaf Gulshad, Abdullah Aldahlawi Thakaa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08423">https://arxiv.org/abs/2505.08423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08423">https://arxiv.org/pdf/2505.08423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08423]] DArFace: Deformation Aware Robustness for Low Quality Face Recognition(https://arxiv.org/abs/2505.08423)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Facial recognition systems have achieved remarkable success by leveraging deep neural networks, advanced loss functions, and large-scale datasets. However, their performance often deteriorates in real-world scenarios involving low-quality facial images. Such degradations, common in surveillance footage or standoff imaging include low resolution, motion blur, and various distortions, resulting in a substantial domain gap from the high-quality data typically used during training. While existing approaches attempt to address robustness by modifying network architectures or modeling global spatial transformations, they frequently overlook local, non-rigid deformations that are inherently present in real-world settings. In this work, we introduce DArFace, a Deformation-Aware robust Face recognition framework that enhances robustness to such degradations without requiring paired high- and low-quality training samples. Our method adversarially integrates both global transformations (e.g., rotation, translation) and local elastic deformations during training to simulate realistic low-quality conditions. Moreover, we introduce a contrastive objective to enforce identity consistency across different deformed views. Extensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and IJB-C demonstrate that DArFace surpasses state-of-the-art methods, with significant gains attributed to the inclusion of local deformation modeling.</li>
</ul>

<h3>Title: DHECA-SuperGaze: Dual Head-Eye Cross-Attention and Super-Resolution for Unconstrained Gaze Estimation</h3>
<ul>
<li><strong>Authors: </strong>Franko ≈†ikiƒá, Donik Vr≈°nak, Sven Lonƒçariƒá</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08426">https://arxiv.org/abs/2505.08426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08426">https://arxiv.org/pdf/2505.08426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08426]] DHECA-SuperGaze: Dual Head-Eye Cross-Attention and Super-Resolution for Unconstrained Gaze Estimation(https://arxiv.org/abs/2505.08426)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Unconstrained gaze estimation is the process of determining where a subject is directing their visual attention in uncontrolled environments. Gaze estimation systems are important for a myriad of tasks such as driver distraction monitoring, exam proctoring, accessibility features in modern software, etc. However, these systems face challenges in real-world scenarios, partially due to the low resolution of in-the-wild images and partially due to insufficient modeling of head-eye interactions in current state-of-the-art (SOTA) methods. This paper introduces DHECA-SuperGaze, a deep learning-based method that advances gaze prediction through super-resolution (SR) and a dual head-eye cross-attention (DHECA) module. Our dual-branch convolutional backbone processes eye and multiscale SR head images, while the proposed DHECA module enables bidirectional feature refinement between the extracted visual features through cross-attention mechanisms. Furthermore, we identified critical annotation errors in one of the most diverse and widely used gaze estimation datasets, Gaze360, and rectified the mislabeled data. Performance evaluation on Gaze360 and GFIE datasets demonstrates superior within-dataset performance of the proposed method, reducing angular error (AE) by 0.48¬∞ (Gaze360) and 2.95¬∞ (GFIE) in static configurations, and 0.59¬∞ (Gaze360) and 3.00¬∞ (GFIE) in temporal settings compared to prior SOTA methods. Cross-dataset testing shows improvements in AE of more than 1.53¬∞ (Gaze360) and 3.99¬∞ (GFIE) in both static and temporal settings, validating the robust generalization properties of our approach.</li>
</ul>

<h3>Title: Visual Image Reconstruction from Brain Activity via Latent Representation</h3>
<ul>
<li><strong>Authors: </strong>Yukiyasu Kamitani, Misato Tanaka, Ken Shirakawa</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08429">https://arxiv.org/abs/2505.08429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08429">https://arxiv.org/pdf/2505.08429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08429]] Visual Image Reconstruction from Brain Activity via Latent Representation(https://arxiv.org/abs/2505.08429)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, generative</a></li>
<li><strong>Abstract: </strong>Visual image reconstruction, the decoding of perceptual content from brain activity into images, has advanced significantly with the integration of deep neural networks (DNNs) and generative models. This review traces the field's evolution from early classification approaches to sophisticated reconstructions that capture detailed, subjective visual experiences, emphasizing the roles of hierarchical latent representations, compositional strategies, and modular architectures. Despite notable progress, challenges remain, such as achieving true zero-shot generalization for unseen images and accurately modeling the complex, subjective aspects of perception. We discuss the need for diverse datasets, refined evaluation metrics aligned with human perceptual judgments, and compositional representations that strengthen model robustness and generalizability. Ethical issues, including privacy, consent, and potential misuse, are underscored as critical considerations for responsible development. Visual image reconstruction offers promising insights into neural coding and enables new psychological measurements of visual experiences, with applications spanning clinical diagnostics and brain-machine interfaces.</li>
</ul>

<h3>Title: TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection</h3>
<ul>
<li><strong>Authors: </strong>Wenkui Yang, Zhida Zhang, Xiaoqiang Zhou, Junxian Duan, Jie Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08437">https://arxiv.org/abs/2505.08437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08437">https://arxiv.org/pdf/2505.08437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08437]] TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection(https://arxiv.org/abs/2505.08437)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The emergence and popularity of facial deepfake methods spur the vigorous development of deepfake datasets and facial forgery detection, which to some extent alleviates the security concerns about facial-related artificial intelligence technologies. However, when it comes to human body forgery, there has been a persistent lack of datasets and detection methods, due to the later inception and complexity of human body generation methods. To mitigate this issue, we introduce TikTok-DeepFake (TT-DF), a novel large-scale diffusion-based dataset containing 6,120 forged videos with 1,378,857 synthetic frames, specifically tailored for body forgery detection. TT-DF offers a wide variety of forgery methods, involving multiple advanced human image animation models utilized for manipulation, two generative configurations based on the disentanglement of identity and pose information, as well as different compressed versions. The aim is to simulate any potential unseen forged data in the wild as comprehensively as possible, and we also furnish a benchmark on TT-DF. Additionally, we propose an adapted body forgery detection model, Temporal Optical Flow Network (TOF-Net), which exploits the spatiotemporal inconsistencies and optical flow distribution differences between natural data and forged data. Our experiments demonstrate that TOF-Net achieves favorable performance on TT-DF, outperforming current state-of-the-art extendable facial forgery detection models. For our TT-DF dataset, please refer to this https URL.</li>
</ul>

<h3>Title: A document processing pipeline for the construction of a dataset for topic modeling based on the judgments of the Italian Supreme Court</h3>
<ul>
<li><strong>Authors: </strong>Matteo Marulli, Glauco Panattoni, Marco Bertini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08439">https://arxiv.org/abs/2505.08439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08439">https://arxiv.org/pdf/2505.08439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08439]] A document processing pipeline for the construction of a dataset for topic modeling based on the judgments of the Italian Supreme Court(https://arxiv.org/abs/2505.08439)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Topic modeling in Italian legal research is hindered by the lack of public datasets, limiting the analysis of legal themes in Supreme Court judgments. To address this, we developed a document processing pipeline that produces an anonymized dataset optimized for topic modeling. The pipeline integrates document layout analysis (YOLOv8x), optical character recognition, and text anonymization. The DLA module achieved a mAP@50 of 0.964 and a mAP@50-95 of 0.800. The OCR detector reached a mAP@50-95 of 0.9022, and the text recognizer (TrOCR) obtained a character error rate of 0.0047 and a word error rate of 0.0248. Compared to OCR-only methods, our dataset improved topic modeling with a diversity score of 0.6198 and a coherence score of 0.6638. We applied BERTopic to extract topics and used large language models to generate labels and summaries. Outputs were evaluated against domain expert interpretations. Claude Sonnet 3.7 achieved a BERTScore F1 of 0.8119 for labeling and 0.9130 for summarization.</li>
</ul>

<h3>Title: Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Adel Ammar, Anis Koubaa, Omer Nacar, Wadii Boulila</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08445">https://arxiv.org/abs/2505.08445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08445">https://arxiv.org/pdf/2505.08445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08445]] Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency(https://arxiv.org/abs/2505.08445)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Large language models achieve high task performance yet often hallucinate or rely on outdated knowledge. Retrieval-augmented generation (RAG) addresses these gaps by coupling generation with external search. We analyse how hyperparameters influence speed and quality in RAG systems, covering Chroma and Faiss vector stores, chunking policies, cross-encoder re-ranking, and temperature, and we evaluate six metrics: faithfulness, answer correctness, answer relevancy, context precision, context recall, and answer similarity. Chroma processes queries 13% faster, whereas Faiss yields higher retrieval precision, revealing a clear speed-accuracy trade-off. Naive fixed-length chunking with small windows and minimal overlap outperforms semantic segmentation while remaining the quickest option. Re-ranking provides modest gains in retrieval quality yet increases runtime by roughly a factor of 5, so its usefulness depends on latency constraints. These results help practitioners balance computational cost and accuracy when tuning RAG systems for transparent, up-to-date responses. Finally, we re-evaluate the top configurations with a corrective RAG workflow and show that their advantages persist when the model can iteratively request additional evidence. We obtain a near-perfect context precision (99%), which demonstrates that RAG systems can achieve extremely high retrieval accuracy with the right combination of hyperparameters, with significant implications for applications where retrieval quality directly impacts downstream task performance, such as clinical decision support in healthcare.</li>
</ul>

<h3>Title: IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Kazuki Hayashi, Hidetaka Kamigaito, Shinya Kouda, Taro Watanabe</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08450">https://arxiv.org/abs/2505.08450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08450">https://arxiv.org/pdf/2505.08450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08450]] IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation(https://arxiv.org/abs/2505.08450)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a way to complement the in-context knowledge of Large Language Models (LLMs) by integrating external documents. However, real-world applications demand not only accuracy but also interpretability. While dense retrieval methods provide high accuracy, they lack interpretability; conversely, sparse retrieval methods offer transparency but often fail to capture the full intent of queries due to their reliance on keyword matching. To address these issues, we introduce IterKey, an LLM-driven iterative keyword generation framework that enhances RAG via sparse retrieval. IterKey consists of three LLM-driven stages: generating keywords for retrieval, generating answers based on retrieved documents, and validating the answers. If validation fails, the process iteratively repeats with refined keywords. Across four QA tasks, experimental results show that IterKey achieves 5% to 20% accuracy improvements over BM25-based RAG and simple baselines. Its performance is comparable to dense retrieval-based RAG and prior iterative query refinement methods using dense models. In summary, IterKey is a novel BM25-based approach leveraging LLMs to iteratively refine RAG, effectively balancing accuracy with interpretability.</li>
</ul>

<h3>Title: Large Language Models Meet Stance Detection: A Survey of Tasks, Methods, Applications, Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Lata Pangtey, Anukriti Bhatnagar, Shubhi Bansal, Shahid Shafi Dar, Nagendra Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08464">https://arxiv.org/abs/2505.08464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08464">https://arxiv.org/pdf/2505.08464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08464]] Large Language Models Meet Stance Detection: A Survey of Tasks, Methods, Applications, Challenges and Future Directions(https://arxiv.org/abs/2505.08464)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Stance detection is essential for understanding subjective content across various platforms such as social media, news articles, and online reviews. Recent advances in Large Language Models (LLMs) have revolutionized stance detection by introducing novel capabilities in contextual understanding, cross-domain generalization, and multimodal analysis. Despite these progressions, existing surveys often lack comprehensive coverage of approaches that specifically leverage LLMs for stance detection. To bridge this critical gap, our review article conducts a systematic analysis of stance detection, comprehensively examining recent advancements of LLMs transforming the field, including foundational concepts, methodologies, datasets, applications, and emerging challenges. We present a novel taxonomy for LLM-based stance detection approaches, structured along three key dimensions: 1) learning methods, including supervised, unsupervised, few-shot, and zero-shot; 2) data modalities, such as unimodal, multimodal, and hybrid; and 3) target relationships, encompassing in-target, cross-target, and multi-target scenarios. Furthermore, we discuss the evaluation techniques and analyze benchmark datasets and performance trends, highlighting the strengths and limitations of different architectures. Key applications in misinformation detection, political analysis, public health monitoring, and social media moderation are discussed. Finally, we identify critical challenges such as implicit stance expression, cultural biases, and computational constraints, while outlining promising future directions, including explainable stance reasoning, low-resource adaptation, and real-time deployment frameworks. Our survey highlights emerging trends, open challenges, and future directions to guide researchers and practitioners in developing next-generation stance detection systems powered by large language models.</li>
</ul>

<h3>Title: Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?</h3>
<ul>
<li><strong>Authors: </strong>Md Tahmid Rahman Laskar, Mohammed Saidul Islam, Ridwan Mahbub, Ahmed Masry, Mizanur Rahman, Amran Bhuiyan, Mir Tafseer Nayeem, Shafiq Joty, Enamul Hoque, Jimmy Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08468">https://arxiv.org/abs/2505.08468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08468">https://arxiv.org/pdf/2505.08468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08468]] Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?(https://arxiv.org/abs/2505.08468)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Charts are ubiquitous as they help people understand and reason with data. Recently, various downstream tasks, such as chart question answering, chart2text, and fact-checking, have emerged. Large Vision-Language Models (LVLMs) show promise in tackling these tasks, but their evaluation is costly and time-consuming, limiting real-world deployment. While using LVLMs as judges to assess the chart comprehension capabilities of other LVLMs could streamline evaluation processes, challenges like proprietary datasets, restricted access to powerful models, and evaluation costs hinder their adoption in industrial settings. To this end, we present a comprehensive evaluation of 13 open-source LVLMs as judges for diverse chart comprehension and reasoning tasks. We design both pairwise and pointwise evaluation tasks covering criteria like factual correctness, informativeness, and relevancy. Additionally, we analyze LVLM judges based on format adherence, positional consistency, length bias, and instruction-following. We focus on cost-effective LVLMs (<10B parameters) suitable for both research and commercial use, following a standardized evaluation protocol and rubric to measure the LVLM judge's accuracy. Experimental results reveal notable variability: while some open LVLM judges achieve GPT-4-level evaluation performance (about 80% agreement with GPT-4 judgments), others struggle (below ~10% agreement). Our findings highlight that state-of-the-art open-source LVLMs can serve as cost-effective automatic evaluators for chart-related tasks, though biases such as positional preference and length bias persist.</li>
</ul>

<h3>Title: Isolation Forest in Novelty Detection Scenario</h3>
<ul>
<li><strong>Authors: </strong>Adam Ulrich, Jan Kr≈à√°vek, Roman ≈†enke≈ô√≠k, Zuzana Kom√≠nkov√° Oplatkov√°, Radek Vala</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08489">https://arxiv.org/abs/2505.08489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08489">https://arxiv.org/pdf/2505.08489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08489]] Isolation Forest in Novelty Detection Scenario(https://arxiv.org/abs/2505.08489)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Data mining offers a diverse toolbox for extracting meaningful structures from complex datasets, with anomaly detection emerging as a critical subfield particularly in the context of streaming or real-time data. Within anomaly detection, novelty detection focuses on identifying previously unseen patterns after training solely on regular data. While classic algorithms such as One-Class SVM or Local Outlier Factor (LOF) have been widely applied, they often lack interpretability and scalability. In this work, we explore the Half-Space Tree (HST) algorithm, originally proposed for streaming anomaly detection, and propose a novel theoretical modification to adapt it specifically for novelty detection tasks. Our approach is grounded in the idea that anomalies i.e., novelties tend to appear in the higher leaves of the tree, which are less frequently visited by regular instances. We analytically demonstrate the effectiveness of this approach using probabilistic analysis, expected depth (EXD) calculations, and combinatorial reasoning. A comparative analysis of expected depths between our modified HST and the original Isolation Forest highlights that novelty points are significantly more isolated in our approach. This supports the hypothesis that HSTs, with appropriate structural adaptation, can serve as interpretable and efficient novelty detectors. The paper contributes a theoretical foundation and supporting analysis for this adaptation, setting the stage for further application and experimentation.</li>
</ul>

<h3>Title: LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Takumi Shibata, Yuichi Miyamura</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08498">https://arxiv.org/abs/2505.08498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08498">https://arxiv.org/pdf/2505.08498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08498]] LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models(https://arxiv.org/abs/2505.08498)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have enabled zero-shot automated essay scoring (AES), providing a promising way to reduce the cost and effort of essay scoring in comparison with manual grading. However, most existing zero-shot approaches rely on LLMs to directly generate absolute scores, which often diverge from human evaluations owing to model biases and inconsistent scoring. To address these limitations, we propose LLM-based Comparative Essay Scoring (LCES), a method that formulates AES as a pairwise comparison task. Specifically, we instruct LLMs to judge which of two essays is better, collect many such comparisons, and convert them into continuous scores. Considering that the number of possible comparisons grows quadratically with the number of essays, we improve scalability by employing RankNet to efficiently transform LLM preferences into scalar scores. Experiments using AES benchmark datasets show that LCES outperforms conventional zero-shot methods in accuracy while maintaining computational efficiency. Moreover, LCES is robust across different LLM backbones, highlighting its applicability to real-world zero-shot AES.</li>
</ul>

<h3>Title: InfoPO: On Mutual Information Maximization for Large Language Model Alignment</h3>
<ul>
<li><strong>Authors: </strong>Teng Xiao, Zhen Ge, Sujay Sanghavi, Tian Wang, Julian Katz-Samuels, Marc Versage, Qingjun Cui, Trishul Chilimbi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08507">https://arxiv.org/abs/2505.08507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08507">https://arxiv.org/pdf/2505.08507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08507]] InfoPO: On Mutual Information Maximization for Large Language Model Alignment(https://arxiv.org/abs/2505.08507)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the post-training of large language models (LLMs) with human preference data. Recently, direct preference optimization and its variants have shown considerable promise in aligning language models, eliminating the need for reward models and online sampling. Despite these benefits, these methods rely on explicit assumptions about the Bradley-Terry (BT) model, which makes them prone to overfitting and results in suboptimal performance, particularly on reasoning-heavy tasks. To address these challenges, we propose a principled preference fine-tuning algorithm called InfoPO, which effectively and efficiently aligns large language models using preference data. InfoPO eliminates the reliance on the BT model and prevents the likelihood of the chosen response from decreasing. Extensive experiments confirm that InfoPO consistently outperforms established baselines on widely used open benchmarks, particularly in reasoning tasks.</li>
</ul>

<h3>Title: Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain</h3>
<ul>
<li><strong>Authors: </strong>Hyowon Wi, Jeongwhan Choi, Noseong Park</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08516">https://arxiv.org/abs/2505.08516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08516">https://arxiv.org/pdf/2505.08516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08516]] Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain(https://arxiv.org/abs/2505.08516)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated remarkable performance across diverse domains. The key component of Transformers is self-attention, which learns the relationship between any two tokens in the input sequence. Recent studies have revealed that the self-attention can be understood as a normalized adjacency matrix of a graph. Notably, from the perspective of graph signal processing (GSP), the self-attention can be equivalently defined as a simple graph filter, applying GSP using the value vector as the signal. However, the self-attention is a graph filter defined with only the first order of the polynomial matrix, and acts as a low-pass filter preventing the effective leverage of various frequency information. Consequently, existing self-attention mechanisms are designed in a rather simplified manner. Therefore, we propose a novel method, called \underline{\textbf{A}}ttentive \underline{\textbf{G}}raph \underline{\textbf{F}}ilter (AGF), interpreting the self-attention as learning the graph filter in the singular value domain from the perspective of graph signal processing for directed graphs with the linear complexity w.r.t. the input length $n$, i.e., $\mathcal{O}(nd^2)$. In our experiments, we demonstrate that AGF achieves state-of-the-art performance on various tasks, including Long Range Arena benchmark and time series classification.</li>
</ul>

<h3>Title: A Deep Learning-Driven Framework for Inhalation Injury Grading Using Bronchoscopy Images</h3>
<ul>
<li><strong>Authors: </strong>Yifan Li, Alan W Pang, Jo Woon Chong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08517">https://arxiv.org/abs/2505.08517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08517">https://arxiv.org/pdf/2505.08517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08517]] A Deep Learning-Driven Framework for Inhalation Injury Grading Using Bronchoscopy Images(https://arxiv.org/abs/2505.08517)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Inhalation injuries face a challenge in clinical diagnosis and grading due to the limitations of traditional methods, such as Abbreviated Injury Score (AIS), which rely on subjective assessments and show weak correlations with clinical outcomes. This study introduces a novel deep learning-based framework for grading inhalation injuries using bronchoscopy images with the duration of mechanical ventilation as an objective metric. To address the scarcity of medical imaging data, we propose enhanced StarGAN, a generative model that integrates Patch Loss and SSIM Loss to improve synthetic images' quality and clinical relevance. The augmented dataset generated by enhanced StarGAN significantly improved classification performance when evaluated using the Swin Transformer, achieving an accuracy of 77.78%, an 11.11% improvement over the original dataset. Image quality was assessed using the Fr√©chet Inception Distance (FID), where Enhanced StarGAN achieved the lowest FID of 30.06, outperforming baseline models. Burn surgeons confirmed the realism and clinical relevance of the generated images, particularly the preservation of bronchial structures and color distribution. These results highlight the potential of enhanced StarGAN in addressing data limitations and improving classification accuracy for inhalation injury grading.</li>
</ul>

<h3>Title: Attention-based Generative Latent Replay: A Continual Learning Approach for WSI Analysis</h3>
<ul>
<li><strong>Authors: </strong>Pratibha Kumari, Daniel Reisenb√ºchler, Afshin Bozorgpour, Nadine S. Schaadt, Friedrich Feuerhake, Dorit Merhof</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08524">https://arxiv.org/abs/2505.08524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08524">https://arxiv.org/pdf/2505.08524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08524]] Attention-based Generative Latent Replay: A Continual Learning Approach for WSI Analysis(https://arxiv.org/abs/2505.08524)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>Whole slide image (WSI) classification has emerged as a powerful tool in computational pathology, but remains constrained by domain shifts, e.g., due to different organs, diseases, or institution-specific variations. To address this challenge, we propose an Attention-based Generative Latent Replay Continual Learning framework (AGLR-CL), in a multiple instance learning (MIL) setup for domain incremental WSI classification. Our method employs Gaussian Mixture Models (GMMs) to synthesize WSI representations and patch count distributions, preserving knowledge of past domains without explicitly storing original data. A novel attention-based filtering step focuses on the most salient patch embeddings, ensuring high-quality synthetic samples. This privacy-aware strategy obviates the need for replay buffers and outperforms other buffer-free counterparts while matching the performance of buffer-based solutions. We validate AGLR-CL on clinically relevant biomarker detection and molecular status prediction across multiple public datasets with diverse centers, organs, and patient cohorts. Experimental results confirm its ability to retain prior knowledge and adapt to new domains, offering an effective, privacy-preserving avenue for domain incremental continual learning in WSI classification.</li>
</ul>

<h3>Title: Dynamic Snake Upsampling Operater and Boundary-Skeleton Weighted Loss for Tubular Structure Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yiqi Chen, Ganghai Huang, Sheng Zhang, Jianglin Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08525">https://arxiv.org/abs/2505.08525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08525">https://arxiv.org/pdf/2505.08525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08525]] Dynamic Snake Upsampling Operater and Boundary-Skeleton Weighted Loss for Tubular Structure Segmentation(https://arxiv.org/abs/2505.08525)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of tubular topological structures (e.g., fissures and vasculature) is critical in various fields to guarantee dependable downstream quantitative analysis and modeling. However, in dense prediction tasks such as semantic segmentation and super-resolution, conventional upsampling operators cannot accommodate the slenderness of tubular structures and the curvature of morphology. This paper introduces a dynamic snake upsampling operators and a boundary-skeleton weighted loss tailored for topological tubular structures. Specifically, we design a snake upsampling operators based on an adaptive sampling domain, which dynamically adjusts the sampling stride according to the feature map and selects a set of subpixel sampling points along the serpentine path, enabling more accurate subpixel-level feature recovery for tubular structures. Meanwhile, we propose a skeleton-to-boundary increasing weighted loss that trades off main body and boundary weight allocation based on mask class ratio and distance field, preserving main body overlap while enhancing focus on target topological continuity and boundary alignment precision. Experiments across various domain datasets and backbone networks show that this plug-and-play dynamic snake upsampling operator and boundary-skeleton weighted loss boost both pixel-wise segmentation accuracy and topological consistency of results.</li>
</ul>

<h3>Title: Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting</h3>
<ul>
<li><strong>Authors: </strong>Zheang Huai, Hui Tang, Yi Li, Zhuangzhuang Chen, Xiaomeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08527">https://arxiv.org/abs/2505.08527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08527">https://arxiv.org/pdf/2505.08527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08527]] Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting(https://arxiv.org/abs/2505.08527)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Source-free domain adaptation (SFDA) for segmentation aims at adapting a model trained in the source domain to perform well in the target domain with only the source model and unlabeled target this http URL by the recent success of Segment Anything Model (SAM) which exhibits the generality of segmenting images of various modalities and in different domains given human-annotated prompts like bounding boxes or points, we for the first time explore the potentials of Segment Anything Model for SFDA via automatedly finding an accurate bounding box prompt. We find that the bounding boxes directly generated with existing SFDA approaches are defective due to the domain this http URL tackle this issue, we propose a novel Dual Feature Guided (DFG) auto-prompting approach to search for the box prompt. Specifically, the source model is first trained in a feature aggregation phase, which not only preliminarily adapts the source model to the target domain but also builds a feature distribution well-prepared for box prompt search. In the second phase, based on two feature distribution observations, we gradually expand the box prompt with the guidance of the target model feature and the SAM feature to handle the class-wise clustered target features and the class-wise dispersed target features, respectively. To remove the potentially enlarged false positive regions caused by the over-confident prediction of the target model, the refined pseudo-labels produced by SAM are further postprocessed based on connectivity analysis. Experiments on 3D and 2D datasets indicate that our approach yields superior performance compared to conventional methods. Code is available at this https URL.</li>
</ul>

<h3>Title: GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning</h3>
<ul>
<li><strong>Authors: </strong>Minsu Kim, Seong-Hyeon Hwang, Steven Euijong Whang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08528">https://arxiv.org/abs/2505.08528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08528">https://arxiv.org/pdf/2505.08528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08528]] GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning(https://arxiv.org/abs/2505.08528)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the context of continual learning, acquiring new knowledge while maintaining previous knowledge presents a significant challenge. Existing methods often use experience replay techniques that store a small portion of previous task data for training. In experience replay approaches, data augmentation has emerged as a promising strategy to further improve the model performance by mixing limited previous task data with sufficient current task data. However, we theoretically and empirically analyze that training with mixed samples from random sample pairs may harm the knowledge of previous tasks and cause greater catastrophic forgetting. We then propose GradMix, a robust data augmentation method specifically designed for mitigating catastrophic forgetting in class-incremental learning. GradMix performs gradient-based selective mixup using a class-based criterion that mixes only samples from helpful class pairs and not from detrimental class pairs for reducing catastrophic forgetting. Our experiments on various real datasets show that GradMix outperforms data augmentation baselines in accuracy by minimizing the forgetting of previous knowledge.</li>
</ul>

<h3>Title: The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Lamine Mekhalfi, Paul Chippendale, Fabio Poiesi, Samuele Bonecher, Gilberto Osler, Nicola Zancanella</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08537">https://arxiv.org/abs/2505.08537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08537">https://arxiv.org/pdf/2505.08537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08537]] The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with Deep Learning(https://arxiv.org/abs/2505.08537)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This research investigates the application of computer vision for rapid, accurate, and non-invasive food quality assessment, focusing on the novel challenge of real-time raspberry grading into five distinct classes within an industrial environment as the fruits move along a conveyor belt. To address this, a dedicated dataset of raspberries, namely RaspGrade, was acquired and meticulously annotated. Instance segmentation experiments revealed that accurate fruit-level masks can be obtained; however, the classification of certain raspberry grades presents challenges due to color similarities and occlusion, while others are more readily distinguishable based on color. The acquired and annotated RaspGrade dataset is accessible on HuggingFace at: this https URL.</li>
</ul>

<h3>Title: ROSA: Finding Backdoors with Fuzzing</h3>
<ul>
<li><strong>Authors: </strong>Dimitri Kokkonis (IP Paris, DIN (CEA, LIST)), Micha√´l Marcozzi (DIN (CEA, LIST)), Emilien Decoux (DIN (CEA, LIST)), Stefano Zacchiroli (IP Paris, LTCI, ACES, INFRES)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08544">https://arxiv.org/abs/2505.08544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08544">https://arxiv.org/pdf/2505.08544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08544]] ROSA: Finding Backdoors with Fuzzing(https://arxiv.org/abs/2505.08544)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>A code-level backdoor is a hidden access, programmed and concealed within the code of a program. For instance, hard-coded credentials planted in the code of a file server application would enable maliciously logging into all deployed instances of this application. Confirmed software supply chain attacks have led to the injection of backdoors into popular open-source projects, and backdoors have been discovered in various router firmware. Manual code auditing for backdoors is challenging and existing semi-automated approaches can handle only a limited scope of programs and backdoors, while requiring manual reverse-engineering of the audited (binary) program. Graybox fuzzing (automated semi-randomized testing) has grown in popularity due to its success in discovering vulnerabilities and hence stands as a strong candidate for improved backdoor detection. However, current fuzzing knowledge does not offer any means to detect the triggering of a backdoor at runtime. In this work we introduce ROSA, a novel approach (and tool) which combines a state-of-the-art fuzzer (AFL++) with a new metamorphic test oracle, capable of detecting runtime backdoor triggers. To facilitate the evaluation of ROSA, we have created ROSARUM, the first openly available benchmark for assessing the detection of various backdoors in diverse programs. Experimental evaluation shows that ROSA has a level of robustness, speed and automation similar to classical fuzzing. It finds all 17 authentic or synthetic backdooors from ROSARUM in 1h30 on average. Compared to existing detection tools, it can handle a diversity of backdoors and programs and it does not rely on manual reverse-engineering of the fuzzed binary code.</li>
</ul>

<h3>Title: OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain</h3>
<ul>
<li><strong>Authors: </strong>Wenzhen Yue, Yong Liu, Haoxuan Li, Hao Wang, Xianghua Ying, Ruohao Guo, Bowei Xing, Ji Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08550">https://arxiv.org/abs/2505.08550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08550">https://arxiv.org/pdf/2505.08550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08550]] OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain(https://arxiv.org/abs/2505.08550)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents $\mathbf{OLinear}$, a $\mathbf{linear}$-based multivariate time series forecasting model that operates in an $\mathbf{o}$rthogonally transformed domain. Recent forecasting models typically adopt the temporal forecast (TF) paradigm, which directly encode and decode time series in the time domain. However, the entangled step-wise dependencies in series data can hinder the performance of TF. To address this, some forecasters conduct encoding and decoding in the transformed domain using fixed, dataset-independent bases (e.g., sine and cosine signals in the Fourier transform). In contrast, we utilize $\mathbf{OrthoTrans}$, a data-adaptive transformation based on an orthogonal matrix that diagonalizes the series' temporal Pearson correlation matrix. This approach enables more effective encoding and decoding in the decorrelated feature domain and can serve as a plug-in module to enhance existing forecasters. To enhance the representation learning for multivariate time series, we introduce a customized linear layer, $\mathbf{NormLin}$, which employs a normalized weight matrix to capture multivariate dependencies. Empirically, the NormLin module shows a surprising performance advantage over multi-head self-attention, while requiring nearly half the FLOPs. Extensive experiments on 24 benchmarks and 140 forecasting tasks demonstrate that OLinear consistently achieves state-of-the-art performance with high efficiency. Notably, as a plug-in replacement for self-attention, the NormLin module consistently enhances Transformer-based forecasters. The code and datasets are available at this https URL</li>
</ul>

<h3>Title: DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art</h3>
<ul>
<li><strong>Authors: </strong>Haroon Wahab, Hassan Ugail, Irfan Mehmood</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08552">https://arxiv.org/abs/2505.08552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08552">https://arxiv.org/pdf/2505.08552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08552]] DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art(https://arxiv.org/abs/2505.08552)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Recent proliferation of generative AI tools for visual content creation-particularly in the context of visual artworks-has raised serious concerns about copyright infringement and forgery. The large-scale datasets used to train these models often contain a mixture of copyrighted and non-copyrighted artworks. Given the tendency of generative models to memorize training patterns, they are susceptible to varying degrees of copyright violation. Building on the recently proposed DeepfakeArt Challenge benchmark, this work introduces DFA-CON, a contrastive learning framework designed to detect copyright-infringing or forged AI-generated art. DFA-CON learns a discriminative representation space, posing affinity among original artworks and their forged counterparts within a contrastive learning framework. The model is trained across multiple attack types, including inpainting, style transfer, adversarial perturbation, and cutmix. Evaluation results demonstrate robust detection performance across most attack types, outperforming recent pretrained foundation models. Code and model checkpoints will be released publicly upon acceptance.</li>
</ul>

<h3>Title: Thermal Detection of People with Mobility Restrictions for Barrier Reduction at Traffic Lights Controlled Intersections</h3>
<ul>
<li><strong>Authors: </strong>Xiao Ni, Carsten Kuehnel, Xiaoyi Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08568">https://arxiv.org/abs/2505.08568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08568">https://arxiv.org/pdf/2505.08568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08568]] Thermal Detection of People with Mobility Restrictions for Barrier Reduction at Traffic Lights Controlled Intersections(https://arxiv.org/abs/2505.08568)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, extraction</a></li>
<li><strong>Abstract: </strong>Rapid advances in deep learning for computer vision have driven the adoption of RGB camera-based adaptive traffic light systems to improve traffic safety and pedestrian comfort. However, these systems often overlook the needs of people with mobility restrictions. Moreover, the use of RGB cameras presents significant challenges, including limited detection performance under adverse weather or low-visibility conditions, as well as heightened privacy concerns. To address these issues, we propose a fully automated, thermal detector-based traffic light system that dynamically adjusts signal durations for individuals with walking impairments or mobility burden and triggers the auditory signal for visually impaired individuals, thereby advancing towards barrier-free intersection for all users. To this end, we build the thermal dataset for people with mobility restrictions (TD4PWMR), designed to capture diverse pedestrian scenarios, particularly focusing on individuals with mobility aids or mobility burden under varying environmental conditions, such as different lighting, weather, and crowded urban settings. While thermal imaging offers advantages in terms of privacy and robustness to adverse conditions, it also introduces inherent hurdles for object detection due to its lack of color and fine texture details and generally lower resolution of thermal images. To overcome these limitations, we develop YOLO-Thermal, a novel variant of the YOLO architecture that integrates advanced feature extraction and attention mechanisms for enhanced detection accuracy and robustness in thermal imaging. Experiments demonstrate that the proposed thermal detector outperforms existing detectors, while the proposed traffic light system effectively enhances barrier-free intersection. The source codes and dataset are available at this https URL.</li>
</ul>

<h3>Title: MUBox: A Critical Evaluation Framework of Deep Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Xiang Li, Bhavani Thuraisingham, Wenqi Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08576">https://arxiv.org/abs/2505.08576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08576">https://arxiv.org/pdf/2505.08576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08576]] MUBox: A Critical Evaluation Framework of Deep Machine Unlearning(https://arxiv.org/abs/2505.08576)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Recent legal frameworks have mandated the right to be forgotten, obligating the removal of specific data upon user requests. Machine Unlearning has emerged as a promising solution by selectively removing learned information from machine learning models. This paper presents MUBox, a comprehensive platform designed to evaluate unlearning methods in deep learning. MUBox integrates 23 advanced unlearning techniques, tested across six practical scenarios with 11 diverse evaluation metrics. It allows researchers and practitioners to (1) assess and compare the effectiveness of different machine unlearning methods across various scenarios; (2) examine the impact of current evaluation metrics on unlearning performance; and (3) conduct detailed comparative studies on machine unlearning in a unified framework. Leveraging MUBox, we systematically evaluate these unlearning methods in deep learning and uncover several key insights: (a) Even state-of-the-art unlearning methods, including those published in top-tier venues and winners of unlearning competitions, demonstrate inconsistent effectiveness across diverse scenarios. Prior research has predominantly focused on simplified settings, such as random forgetting and class-wise unlearning, highlighting the need for broader evaluations across more difficult unlearning tasks. (b) Assessing unlearning performance remains a non-trivial problem, as no single evaluation metric can comprehensively capture the effectiveness, efficiency, and preservation of model utility. Our findings emphasize the necessity of employing multiple metrics to achieve a balanced and holistic assessment of unlearning methods. (c) In the context of depoisoning, our evaluation reveals significant variability in the effectiveness of existing approaches, which is highly dependent on the specific type of poisoning attacks.</li>
</ul>

<h3>Title: ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible Long-term Tracking</h3>
<ul>
<li><strong>Authors: </strong>Haofeng Liu, Mingqi Gao, Xuxiao Luo, Ziyue Wang, Guanyi Qin, Junde Wu, Yueming Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV, q-bio.TO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08581">https://arxiv.org/abs/2505.08581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08581">https://arxiv.org/pdf/2505.08581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08581]] ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible Long-term Tracking(https://arxiv.org/abs/2505.08581)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Surgical scene segmentation is critical in computer-assisted surgery and is vital for enhancing surgical quality and patient outcomes. Recently, referring surgical segmentation is emerging, given its advantage of providing surgeons with an interactive experience to segment the target object. However, existing methods are limited by low efficiency and short-term tracking, hindering their applicability in complex real-world surgical scenarios. In this paper, we introduce ReSurgSAM2, a two-stage surgical referring segmentation framework that leverages Segment Anything Model 2 to perform text-referred target detection, followed by tracking with reliable initial frame identification and diversity-driven long-term memory. For the detection stage, we propose a cross-modal spatial-temporal Mamba to generate precise detection and segmentation results. Based on these results, our credible initial frame selection strategy identifies the reliable frame for the subsequent tracking. Upon selecting the initial frame, our method transitions to the tracking stage, where it incorporates a diversity-driven memory mechanism that maintains a credible and diverse memory bank, ensuring consistent long-term tracking. Extensive experiments demonstrate that ReSurgSAM2 achieves substantial improvements in accuracy and efficiency compared to existing methods, operating in real-time at 61.2 FPS. Our code and datasets will be available at this https URL.</li>
</ul>

<h3>Title: A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior</h3>
<ul>
<li><strong>Authors: </strong>Jorge Quesada, Chen Zhou, Prithwijit Chowdhury, Mohammad Alotaibi, Ahmad Mustafa, Yusufjon Kumamnov, Mohit Prabhushankar, Ghassan AlRegib</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08585">https://arxiv.org/abs/2505.08585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08585">https://arxiv.org/pdf/2505.08585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08585]] A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior(https://arxiv.org/abs/2505.08585)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning has taken a critical role in seismic interpretation workflows, especially in fault delineation tasks. However, despite the recent proliferation of pretrained models and synthetic datasets, the field still lacks a systematic understanding of the generalizability limits of these models across seismic data representing a variety of geologic, acquisition and processing settings. Distributional shifts between different data sources, limitations in fine-tuning strategies and labeled data accessibility, and inconsistent evaluation protocols all represent major roadblocks in the deployment of reliable and robust models in real-world exploration settings. In this paper, we present the first large-scale benchmarking study explicitly designed to provide answers and guidelines for domain shift strategies in seismic interpretation. Our benchmark encompasses over $200$ models trained and evaluated on three heterogeneous datasets (synthetic and real data) including FaultSeg3D, CRACKS, and Thebe. We systematically assess pretraining, fine-tuning, and joint training strategies under varying degrees of domain shift. Our analysis highlights the fragility of current fine-tuning practices, the emergence of catastrophic forgetting, and the challenges of interpreting performance in a systematic manner. We establish a robust experimental baseline to provide insights into the tradeoffs inherent to current fault delineation workflows, and shed light on directions for developing more generalizable, interpretable and effective machine learning models for seismic interpretation. The insights and analyses reported provide a set of guidelines on the deployment of fault delineation models within seismic interpretation workflows.</li>
</ul>

<h3>Title: Small but Significant: On the Promise of Small Language Models for Accessible AIED</h3>
<ul>
<li><strong>Authors: </strong>Yumou Wei, Paulo Carvalho, John Stamper</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08588">https://arxiv.org/abs/2505.08588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08588">https://arxiv.org/pdf/2505.08588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08588]] Small but Significant: On the Promise of Small Language Models for Accessible AIED(https://arxiv.org/abs/2505.08588)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>GPT has become nearly synonymous with large language models (LLMs), an increasingly popular term in AIED proceedings. A simple keyword-based search reveals that 61% of the 76 long and short papers presented at AIED 2024 describe novel solutions using LLMs to address some of the long-standing challenges in education, and 43% specifically mention GPT. Although LLMs pioneered by GPT create exciting opportunities to strengthen the impact of AI on education, we argue that the field's predominant focus on GPT and other resource-intensive LLMs (with more than 10B parameters) risks neglecting the potential impact that small language models (SLMs) can make in providing resource-constrained institutions with equitable and affordable access to high-quality AI tools. Supported by positive results on knowledge component (KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as Phi-2 can produce an effective solution without elaborate prompting strategies. Hence, we call for more attention to developing SLM-based AIED approaches.</li>
</ul>

<h3>Title: MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment</h3>
<ul>
<li><strong>Authors: </strong>Barak Pinkovich, Boaz Matalon, Ehud Rivlin, Hector Rotstein</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08589">https://arxiv.org/abs/2505.08589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08589">https://arxiv.org/pdf/2505.08589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08589]] MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment(https://arxiv.org/abs/2505.08589)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI) dataset comprising 2525 images taken by a drone flying over dense urban environments. MESSI is unique in two main features. First, it contains images from various altitudes, allowing us to investigate the effect of depth on semantic segmentation. Second, it includes images taken from several different urban regions (at different altitudes). This is important since the variety covers the visual richness captured by a drone's 3D flight, performing horizontal and vertical maneuvers. MESSI contains images annotated with location, orientation, and the camera's intrinsic parameters and can be used to train a deep neural network for semantic segmentation or other applications of interest (e.g., localization, navigation, and tracking). This paper describes the dataset and provides annotation details. It also explains how semantic segmentation was performed using several neural network models and shows several relevant statistics. MESSI will be published in the public domain to serve as an evaluation benchmark for semantic segmentation using images captured by a drone or similar vehicle flying over a dense urban environment.</li>
</ul>

<h3>Title: Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Hussien Al-Asi, Jordan P Reynolds, Shweta Agarwal, Bryan J Dangott, Aziza Nassar, Zeynettin Akkus</a></li>
<li><strong>Subjects: </strong>cs.CL, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08590">https://arxiv.org/abs/2505.08590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08590">https://arxiv.org/pdf/2505.08590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08590]] Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models(https://arxiv.org/abs/2505.08590)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Advancements in artificial intelligence (AI) are transforming pathology by integrat-ing large language models (LLMs) with retrieval-augmented generation (RAG) and domain-specific foundation models. This study explores the application of RAG-enhanced LLMs coupled with pathology foundation models for thyroid cytology diagnosis, addressing challenges in cytological interpretation, standardization, and diagnostic accuracy. By leveraging a curated knowledge base, RAG facilitates dy-namic retrieval of relevant case studies, diagnostic criteria, and expert interpreta-tion, improving the contextual understanding of LLMs. Meanwhile, pathology foun-dation models, trained on high-resolution pathology images, refine feature extrac-tion and classification capabilities. The fusion of these AI-driven approaches en-hances diagnostic consistency, reduces variability, and supports pathologists in dis-tinguishing benign from malignant thyroid lesions. Our results demonstrate that integrating RAG with pathology-specific LLMs significantly improves diagnostic efficiency and interpretability, paving the way for AI-assisted thyroid cytopathology, with foundation model UNI achieving AUC 0.73-0.93 for correct prediction of surgi-cal pathology diagnosis from thyroid cytology samples.</li>
</ul>

<h3>Title: Information Leakage in Data Linkage</h3>
<ul>
<li><strong>Authors: </strong>Peter Christen, Rainer Schnell, Anushka Vidanage</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08596">https://arxiv.org/abs/2505.08596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08596">https://arxiv.org/pdf/2505.08596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08596]] Information Leakage in Data Linkage(https://arxiv.org/abs/2505.08596)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>The process of linking databases that contain sensitive information about individuals across organisations is an increasingly common requirement in the health and social science research domains, as well as with governments and businesses. To protect personal data, protocols have been developed to limit the leakage of sensitive information. Furthermore, privacy-preserving record linkage (PPRL) techniques have been proposed to conduct linkage on encoded data. While PPRL techniques are now being employed in real-world applications, the focus of PPRL research has been on the technical aspects of linking sensitive data (such as encoding methods and cryptanalysis attacks), but not on organisational challenges when employing such techniques in practice. We analyse what sensitive information can possibly leak, either unintentionally or intentionally, in traditional data linkage as well as PPRL protocols, and what a party that participates in such a protocol can learn from the data it obtains legitimately within the protocol. We also show that PPRL protocols can still result in the unintentional leakage of sensitive information. We provide recommendations to help data custodians and other parties involved in a data linkage project to identify and prevent vulnerabilities and make their project more secure.</li>
</ul>

<h3>Title: Automatic Task Detection and Heterogeneous LLM Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Danying Ge, Jianhua Gao, Qizhi Jiang, Yifei Feng, Weixing Ji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08600">https://arxiv.org/abs/2505.08600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08600">https://arxiv.org/pdf/2505.08600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08600]] Automatic Task Detection and Heterogeneous LLM Speculative Decoding(https://arxiv.org/abs/2505.08600)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding, which combines a draft model with a target model, has emerged as an effective approach to accelerate large language model (LLM) inference. However, existing methods often face a trade-off between the acceptance rate and decoding speed in downstream tasks due to the limited capacity of the draft model, making it difficult to ensure efficiency across diverse tasks. To address this problem, we propose a speculative decoding algorithm tailored for downstream task optimization. It includes an automatic task partitioning and assigning method, which automatically categorizes downstream tasks into different sub-tasks and assigns them to a set of heterogeneous draft models. Each draft model is aligned with the target model using task-specific data, thereby enhancing the consistency of inference results. In addition, our proposed method incorporates an online lightweight prompt classifier to dynamically route prompts to the appropriate draft model. Experimental results demonstrate that the proposed method improves draft accuracy by 6% to 50% over vanilla speculative decoding, while achieving a speedup of 1.10x to 2.64x in LLM inference.</li>
</ul>

<h3>Title: Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking</h3>
<ul>
<li><strong>Authors: </strong>Yu-Jen Chen, Xueyang Li, Yiyu Shi, Tsung-Yi Ho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08604">https://arxiv.org/abs/2505.08604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08604">https://arxiv.org/pdf/2505.08604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08604]] Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking(https://arxiv.org/abs/2505.08604)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection is essential for ensuring the reliability of deep learning models in medical imaging applications. This work is motivated by the observation that class activation maps (CAMs) for in-distribution (ID) data typically emphasize regions that are highly relevant to the model's predictions, whereas OOD data often lacks such focused activations. By masking input images with inverted CAMs, the feature representations of ID data undergo more substantial changes compared to those of OOD data, offering a robust criterion for differentiation. In this paper, we introduce a novel unsupervised OOD detection framework, Multi-Exit Class Activation Map (MECAM), which leverages multi-exit CAMs and feature masking. By utilizing mult-exit networks that combine CAMs from varying resolutions and depths, our method captures both global and local feature representations, thereby enhancing the robustness of OOD detection. We evaluate MECAM on multiple ID datasets, including ISIC19 and PathMNIST, and test its performance against three medical OOD datasets, RSNA Pneumonia, COVID-19, and HeadCT, and one natural image OOD dataset, iSUN. Comprehensive comparisons with state-of-the-art OOD detection methods validate the effectiveness of our approach. Our findings emphasize the potential of multi-exit networks and feature masking for advancing unsupervised OOD detection in medical imaging, paving the way for more reliable and interpretable models in clinical practice.</li>
</ul>

<h3>Title: Leveraging Multi-Modal Information to Enhance Dataset Distillation</h3>
<ul>
<li><strong>Authors: </strong>Zhe Li, Hadrien Reynaud, Bernhard Kainz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08605">https://arxiv.org/abs/2505.08605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08605">https://arxiv.org/pdf/2505.08605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08605]] Leveraging Multi-Modal Information to Enhance Dataset Distillation(https://arxiv.org/abs/2505.08605)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Dataset distillation aims to create a compact and highly representative synthetic dataset that preserves the knowledge of a larger real dataset. While existing methods primarily focus on optimizing visual representations, incorporating additional modalities and refining object-level information can significantly improve the quality of distilled datasets. In this work, we introduce two key enhancements to dataset distillation: caption-guided supervision and object-centric masking. To integrate textual information, we propose two strategies for leveraging caption features: the feature concatenation, where caption embeddings are fused with visual features at the classification stage, and caption matching, which introduces a caption-based alignment loss during training to ensure semantic coherence between real and synthetic data. Additionally, we apply segmentation masks to isolate target objects and remove background distractions, introducing two loss functions designed for object-centric learning: masked feature alignment loss and masked gradient matching loss. Comprehensive evaluations demonstrate that integrating caption-based guidance and object-centric masking enhances dataset distillation, leading to synthetic datasets that achieve superior performance on downstream tasks.</li>
</ul>

<h3>Title: Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World</h3>
<ul>
<li><strong>Authors: </strong>Yuran Wang, Yingping Liang, Ying Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08607">https://arxiv.org/abs/2505.08607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08607">https://arxiv.org/pdf/2505.08607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08607]] Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World(https://arxiv.org/abs/2505.08607)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Stereo matching methods rely on dense pixel-wise ground truth labels, which are laborious to obtain, especially for real-world datasets. The scarcity of labeled data and domain gaps between synthetic and real-world images also pose notable challenges. In this paper, we propose a novel framework, \textbf{BooSTer}, that leverages both vision foundation models and large-scale mixed image sources, including synthetic, real, and single-view images. First, to fully unleash the potential of large-scale single-view images, we design a data generation strategy combining monocular depth estimation and diffusion models to generate dense stereo matching data from single-view images. Second, to tackle sparse labels in real-world datasets, we transfer knowledge from monocular depth estimation models, using pseudo-mono depth labels and a dynamic scale- and shift-invariant loss for additional supervision. Furthermore, we incorporate vision foundation model as an encoder to extract robust and transferable features, boosting accuracy and generalization. Extensive experiments on benchmark datasets demonstrate the effectiveness of our approach, achieving significant improvements in accuracy over existing methods, particularly in scenarios with limited labeled data and domain shifts.</li>
</ul>

<h3>Title: WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan He, Zhiqing Guo, Liejun Wang, Gaobo Yang, Yunfeng Diao, Dan Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08614">https://arxiv.org/abs/2505.08614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08614">https://arxiv.org/pdf/2505.08614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08614]] WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks(https://arxiv.org/abs/2505.08614)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, watermark</a></li>
<li><strong>Abstract: </strong>Deepfake technology poses increasing risks such as privacy invasion and identity theft. To address these threats, we propose WaveGuard, a proactive watermarking framework that enhances robustness and imperceptibility via frequency-domain embedding and graph-based structural consistency. Specifically, we embed watermarks into high-frequency sub-bands using Dual-Tree Complex Wavelet Transform (DT-CWT) and employ a Structural Consistency Graph Neural Network (SC-GNN) to preserve visual quality. We also design an attention module to refine embedding precision. Experimental results on face swap and reenactment tasks demonstrate that WaveGuard outperforms state-of-the-art methods in both robustness and visual quality. Code is available at this https URL.</li>
</ul>

<h3>Title: OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu, Juntao Li, Xiaoye Qu, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08617">https://arxiv.org/abs/2505.08617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08617">https://arxiv.org/pdf/2505.08617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08617]] OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning(https://arxiv.org/abs/2505.08617)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While humans can flexibly leverage interactive visual cognition for complex problem-solving, enabling Large Vision-Language Models (LVLMs) to learn similarly adaptive behaviors with visual tools remains challenging. A significant hurdle is the current lack of standardized infrastructure, which hinders integrating diverse tools, generating rich interaction data, and training robust agents effectively. To address these gaps, we introduce OpenThinkIMG, the first open-source, comprehensive end-to-end framework for tool-augmented LVLMs. It features standardized vision tool interfaces, scalable trajectory generation for policy initialization, and a flexible training environment. Furthermore, considering supervised fine-tuning (SFT) on static demonstrations offers limited policy generalization for dynamic tool invocation, we propose a novel reinforcement learning (RL) framework V-ToolRL to train LVLMs to learn adaptive policies for invoking external vision tools. V-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies by directly optimizing for task success using feedback from tool interactions. We empirically validate V-ToolRL on challenging chart reasoning tasks. Our RL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its SFT-initialized counterpart (+28.83 points) and surpasses established supervised tool-learning baselines like Taco and CogCom by an average of +12.7 points. Notably, it also surpasses prominent closed-source models like GPT-4.1 by +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational framework for advancing dynamic, tool-augmented visual reasoning, helping the community develop AI agents that can genuinely "think with images".</li>
</ul>

<h3>Title: Modular Federated Learning: A Meta-Framework Perspective</h3>
<ul>
<li><strong>Authors: </strong>Frederico Vicente, Cl√°udia Soares, Du≈°an Jakovetiƒá</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08646">https://arxiv.org/abs/2505.08646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08646">https://arxiv.org/pdf/2505.08646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08646]] Modular Federated Learning: A Meta-Framework Perspective(https://arxiv.org/abs/2505.08646)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables distributed machine learning training while preserving privacy, representing a paradigm shift for data-sensitive and decentralized environments. Despite its rapid advancements, FL remains a complex and multifaceted field, requiring a structured understanding of its methodologies, challenges, and applications. In this survey, we introduce a meta-framework perspective, conceptualising FL as a composition of modular components that systematically address core aspects such as communication, optimisation, security, and privacy. We provide a historical contextualisation of FL, tracing its evolution from distributed optimisation to modern distributed learning paradigms. Additionally, we propose a novel taxonomy distinguishing Aggregation from Alignment, introducing the concept of alignment as a fundamental operator alongside aggregation. To bridge theory with practice, we explore available FL frameworks in Python, facilitating real-world implementation. Finally, we systematise key challenges across FL sub-fields, providing insights into open research questions throughout the meta-framework modules. By structuring FL within a meta-framework of modular components and emphasising the dual role of Aggregation and Alignment, this survey provides a holistic and adaptable foundation for understanding and advancing FL research and deployment.</li>
</ul>

<h3>Title: Cryptologic Techniques and Associated Risks in Public and Private Security. An Italian and European Union Perspective with an Overview of the Current Legal Framework</h3>
<ul>
<li><strong>Authors: </strong>Zana Kudriasova</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08650">https://arxiv.org/abs/2505.08650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08650">https://arxiv.org/pdf/2505.08650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08650]] Cryptologic Techniques and Associated Risks in Public and Private Security. An Italian and European Union Perspective with an Overview of the Current Legal Framework(https://arxiv.org/abs/2505.08650)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust</a></li>
<li><strong>Abstract: </strong>This article examines the evolution of cryptologic techniques and their implications for public and private security, focusing on the Italian and EU legal frameworks. It explores the roles of cryptography, steganography, and quantum technologies in countering cybersecurity threats, emphasising the need for robust legislation to address emerging challenges. Special attention is given to Italy's legislative reforms, including Law No. 90 of 2024, which strengthens penalties for cybercrimes and establishes the National Cryptography Centre within the Italian National Cybersecurity Agency. Additionally, the article highlights international initiatives, such as the UN's draft convention on cybercrime, emphasising the balance between security, privacy, and fundamental human rights in a post-quantum era.</li>
</ul>

<h3>Title: Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing</h3>
<ul>
<li><strong>Authors: </strong>Chen Wu, Yin Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08651">https://arxiv.org/abs/2505.08651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08651">https://arxiv.org/pdf/2505.08651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08651]] Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing(https://arxiv.org/abs/2505.08651)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present MegaBeam-Mistral-7B, a language model that supports 512K-token context length. Our work addresses practical limitations in long-context training, supporting real-world tasks such as compliance monitoring and verification. Evaluated on three long-context benchmarks, our 7B-parameter model demonstrates superior in-context learning performance on HELMET and robust retrieval and tracing capability on RULER. It is currently the only open model to achieve competitive long-range reasoning on BABILong at 512K context length without RAG or targeted fine-tuning. Released as fully open source under the Apache 2.0 license, the model has been downloaded over 100,000 times on Hugging Face. Model available at: this https URL</li>
</ul>

<h3>Title: Comparative Analysis of Blockchain Systems</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Huang, Yuanzheng Niu, Xiaoqi Li, Zongwei Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08652">https://arxiv.org/abs/2505.08652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08652">https://arxiv.org/pdf/2505.08652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08652]] Comparative Analysis of Blockchain Systems(https://arxiv.org/abs/2505.08652)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Blockchain is a type of decentralized distributed database. Unlike traditional relational database management systems, it does not require management or maintenance by a third party. All data management and update processes are open and transparent, solving the trust issues of centralized database management systems. Blockchain ensures network-wide consistency, consensus, traceability, and immutability. Under the premise of mutual distrust between nodes, blockchain technology integrates various technologies, such as P2P protocols, asymmetric encryption, consensus mechanisms, and chain structures. Data is distributed and stored across multiple nodes, maintained by all nodes, ensuring transaction data integrity, undeniability, and security. This facilitates trusted information sharing and supervision. The basic principles of blockchain form the foundation for all related research. Understanding the working principles is essential for further study of blockchain technology. There are many platforms based on blockchain technology, and they differ from one another. This paper will analyze the architecture of blockchain systems at each layer, focusing on the principles and technologies of blockchain platforms such as Bitcoin, Ethereum, and Hyperledger Fabric. The analysis will cover their scalability and security and highlight their similarities, differences, advantages, and disadvantages.</li>
</ul>

<h3>Title: Revealing economic facts: LLMs know more than they say</h3>
<ul>
<li><strong>Authors: </strong>Marcus Buckmann, Quynh Anh Nguyen, Edward Hill</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08662">https://arxiv.org/abs/2505.08662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08662">https://arxiv.org/pdf/2505.08662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08662]] Revealing economic facts: LLMs know more than they say(https://arxiv.org/abs/2505.08662)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate whether the hidden states of large language models (LLMs) can be used to estimate and impute economic and financial statistics. Focusing on county-level (e.g. unemployment) and firm-level (e.g. total assets) variables, we show that a simple linear model trained on the hidden states of open-source LLMs outperforms the models' text outputs. This suggests that hidden states capture richer economic information than the responses of the LLMs reveal directly. A learning curve analysis indicates that only a few dozen labelled examples are sufficient for training. We also propose a transfer learning method that improves estimation accuracy without requiring any labelled data for the target variable. Finally, we demonstrate the practical utility of hidden-state representations in super-resolution and data imputation tasks.</li>
</ul>

<h3>Title: Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results</h3>
<ul>
<li><strong>Authors: </strong>Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick, Andrea Prenner, Cedric Hemon, Valentin Boussot, Jean-Louis Dillenseger, Jean-Claude Nunes, Abdul Qayyum, Moona Mazher, Steven A Niederer, Kaisar Kushibar, Carlos Martin-Isla, Petia Radeva, Karim Lekadir, Theodore Barfoot, Luis C. Garcia Peraza Herrera, Ben Glocker, Tom Vercauteren, Lucas Gago, Justin Englemann, Joy-Marie Kleiss, Anton Aubanell, Andreu Antolin, Javier Garcia-Lopez, Miguel A. Gonzalez Ballester, Adrian Galdran</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08685">https://arxiv.org/abs/2505.08685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08685">https://arxiv.org/pdf/2505.08685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08685]] Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results(https://arxiv.org/abs/2505.08685)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning (DL) has become the dominant approach for medical image segmentation, yet ensuring the reliability and clinical applicability of these models requires addressing key challenges such as annotation variability, calibration, and uncertainty estimation. This is why we created the Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS), which highlights the critical role of multiple annotators in establishing a more comprehensive ground truth, emphasizing that segmentation is inherently subjective and that leveraging inter-annotator variability is essential for robust model evaluation. Seven teams participated in the challenge, submitting a variety of DL models evaluated using metrics such as Dice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and Continuous Ranked Probability Score (CRPS). By incorporating consensus and dissensus ground truth, we assess how DL models handle uncertainty and whether their confidence estimates align with true segmentation performance. Our findings reinforce the importance of well-calibrated models, as better calibration is strongly correlated with the quality of the results. Furthermore, we demonstrate that segmentation models trained on diverse datasets and enriched with pre-trained knowledge exhibit greater robustness, particularly in cases deviating from standard anatomical structures. Notably, the best-performing models achieved high DSC and well-calibrated uncertainty estimates. This work underscores the need for multi-annotator ground truth, thorough calibration assessments, and uncertainty-aware evaluations to develop trustworthy and clinically reliable DL-based medical image segmentation models.</li>
</ul>

<h3>Title: Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Sheng Liang, Hang Lv, Zhihao Wen, Yaxiong Wu, Yongyue Zhang, Hao Wang, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08690">https://arxiv.org/abs/2505.08690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08690">https://arxiv.org/pdf/2505.08690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08690]] Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation(https://arxiv.org/abs/2505.08690)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Event extraction (EE) is a fundamental task in natural language processing (NLP) that involves identifying and extracting event information from unstructured text. Effective EE in real-world scenarios requires two key steps: selecting appropriate schemas from hundreds of candidates and executing the extraction process. Existing research exhibits two critical gaps: (1) the rigid schema fixation in existing pipeline systems, and (2) the absence of benchmarks for evaluating joint schema matching and extraction. Although large language models (LLMs) offer potential solutions, their schema hallucination tendencies and context window limitations pose challenges for practical deployment. In response, we propose Adaptive Schema-aware Event Extraction (ASEE), a novel paradigm combining schema paraphrasing with schema retrieval-augmented generation. ASEE adeptly retrieves paraphrased schemas and accurately generates targeted structures. To facilitate rigorous evaluation, we construct the Multi-Dimensional Schema-aware Event Extraction (MD-SEE) benchmark, which systematically consolidates 12 datasets across diverse domains, complexity levels, and language settings. Extensive evaluations on MD-SEE show that our proposed ASEE demonstrates strong adaptability across various scenarios, significantly improving the accuracy of event extraction.</li>
</ul>

<h3>Title: Controllable Image Colorization with Instance-aware Texts and Masks</h3>
<ul>
<li><strong>Authors: </strong>Yanru An, Ling Gui, Qiang Hu, Chunlei Cai, Tianxiao Ye, Xiaoyun Zhang, Yanfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08705">https://arxiv.org/abs/2505.08705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08705">https://arxiv.org/pdf/2505.08705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08705]] Controllable Image Colorization with Instance-aware Texts and Masks(https://arxiv.org/abs/2505.08705)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Recently, the application of deep learning in image colorization has received widespread attention. The maturation of diffusion models has further advanced the development of image colorization models. However, current mainstream image colorization models still face issues such as color bleeding and color binding errors, and cannot colorize images at the instance level. In this paper, we propose a diffusion-based colorization method MT-Color to achieve precise instance-aware colorization with use-provided guidance. To tackle color bleeding issue, we design a pixel-level mask attention mechanism that integrates latent features and conditional gray image features through cross-attention. We use segmentation masks to construct cross-attention masks, preventing pixel information from exchanging between different instances. We also introduce an instance mask and text guidance module that extracts instance masks and text representations of each instance, which are then fused with latent features through self-attention, utilizing instance masks to form self-attention masks to prevent instance texts from guiding the colorization of other areas, thus mitigating color binding errors. Furthermore, we apply a multi-instance sampling strategy, which involves sampling each instance region separately and then fusing the results. Additionally, we have created a specialized dataset for instance-level colorization tasks, GPT-color, by leveraging large visual language models on existing image datasets. Qualitative and quantitative experiments show that our model and dataset outperform previous methods and datasets.</li>
</ul>

<h3>Title: PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts</h3>
<ul>
<li><strong>Authors: </strong>Yang Su, Na Yan, Yansha Deng, Robert Schober</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08719">https://arxiv.org/abs/2505.08719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08719">https://arxiv.org/pdf/2505.08719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08719]] PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts(https://arxiv.org/abs/2505.08719)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) hosted on cloud servers alleviate the computational and storage burdens on local devices but raise privacy concerns due to sensitive data transmission and require substantial communication bandwidth, which is challenging in constrained environments. In contrast, small language models (SLMs) running locally enhance privacy but suffer from limited performance on complex tasks. To balance computational cost, performance, and privacy protection under bandwidth constraints, we propose a privacy-aware wireless collaborative mixture of experts (PWC-MoE) framework. Specifically, PWC-MoE employs a sparse privacy-aware gating network to dynamically route sensitive tokens to privacy experts located on local clients, while non-sensitive tokens are routed to non-privacy experts located at the remote base station. To achieve computational efficiency, the gating network ensures that each token is dynamically routed to and processed by only one expert. To enhance scalability and prevent overloading of specific experts, we introduce a group-wise load-balancing mechanism for the gating network that evenly distributes sensitive tokens among privacy experts and non-sensitive tokens among non-privacy experts. To adapt to bandwidth constraints while preserving model performance, we propose a bandwidth-adaptive and importance-aware token offloading scheme. This scheme incorporates an importance predictor to evaluate the importance scores of non-sensitive tokens, prioritizing the most important tokens for transmission to the base station based on their predicted importance and the available bandwidth. Experiments demonstrate that the PWC-MoE framework effectively preserves privacy and maintains high performance even in bandwidth-constrained environments, offering a practical solution for deploying LLMs in privacy-sensitive and bandwidth-limited scenarios.</li>
</ul>

<h3>Title: TiMo: Spatiotemporal Foundation Model for Satellite Image Time Series</h3>
<ul>
<li><strong>Authors: </strong>Xiaolei Qin, Di Wang, Jing Zhang, Fengxiang Wang, Xin Su, Bo Du, Liangpei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08723">https://arxiv.org/abs/2505.08723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08723">https://arxiv.org/pdf/2505.08723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08723]] TiMo: Spatiotemporal Foundation Model for Satellite Image Time Series(https://arxiv.org/abs/2505.08723)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Satellite image time series (SITS) provide continuous observations of the Earth's surface, making them essential for applications such as environmental management and disaster assessment. However, existing spatiotemporal foundation models rely on plain vision transformers, which encode entire temporal sequences without explicitly capturing multiscale spatiotemporal relationships between land objects. This limitation hinders their effectiveness in downstream tasks. To overcome this challenge, we propose TiMo, a novel hierarchical vision transformer foundation model tailored for SITS analysis. At its core, we introduce a spatiotemporal gyroscope attention mechanism that dynamically captures evolving multiscale patterns across both time and space. For pre-training, we curate MillionST, a large-scale dataset of one million images from 100,000 geographic locations, each captured across 10 temporal phases over five years, encompassing diverse geospatial changes and seasonal variations. Leveraging this dataset, we adapt masked image modeling to pre-train TiMo, enabling it to effectively learn and encode generalizable spatiotemporal this http URL experiments across multiple spatiotemporal tasks-including deforestation monitoring, land cover segmentation, crop type classification, and flood detection-demonstrate TiMo's superiority over state-of-the-art methods. Code, model, and dataset will be released at this https URL.</li>
</ul>

<h3>Title: Securing RAG: A Risk Assessment and Mitigation Framework</h3>
<ul>
<li><strong>Authors: </strong>Lukas Ammann, Sara Ott, Christoph R. Landolt, Marco P. Lehmann</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08728">https://arxiv.org/abs/2505.08728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08728">https://arxiv.org/pdf/2505.08728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08728]] Securing RAG: A Risk Assessment and Mitigation Framework(https://arxiv.org/abs/2505.08728)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) has emerged as the de facto industry standard for user-facing NLP applications, offering the ability to integrate data without re-training or fine-tuning Large Language Models (LLMs). This capability enhances the quality and accuracy of responses but also introduces novel security and privacy challenges, particularly when sensitive data is integrated. With the rapid adoption of RAG, securing data and services has become a critical priority. This paper first reviews the vulnerabilities of RAG pipelines, and outlines the attack surface from data pre-processing and data storage management to integration with LLMs. The identified risks are then paired with corresponding mitigations in a structured overview. In a second step, the paper develops a framework that combines RAG-specific security considerations, with existing general security guidelines, industry standards, and best practices. The proposed framework aims to guide the implementation of robust, compliant, secure, and trustworthy RAG systems.</li>
</ul>

<h3>Title: NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context</h3>
<ul>
<li><strong>Authors: </strong>Ben Yao, Qiuchi Li, Yazhou Zhang, Siyu Yang, Bohan Zhang, Prayag Tiwari, Jing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08734">https://arxiv.org/abs/2505.08734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08734">https://arxiv.org/pdf/2505.08734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08734]] NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context(https://arxiv.org/abs/2505.08734)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work introduces the first benchmark for nursing value alignment, consisting of five core value dimensions distilled from international nursing codes: Altruism, Human Dignity, Integrity, Justice, and Professionalism. The benchmark comprises 1,100 real-world nursing behavior instances collected through a five-month longitudinal field study across three hospitals of varying tiers. These instances are annotated by five clinical nurses and then augmented with LLM-generated counterfactuals with reversed ethic polarity. Each original case is paired with a value-aligned and a value-violating version, resulting in 2,200 labeled instances that constitute the Easy-Level dataset. To increase adversarial complexity, each instance is further transformed into a dialogue-based format that embeds contextual cues and subtle misleading signals, yielding a Hard-Level dataset. We evaluate 23 state-of-the-art (SoTA) LLMs on their alignment with nursing values. Our findings reveal three key insights: (1) DeepSeek-V3 achieves the highest performance on the Easy-Level dataset (94.55), where Claude 3.5 Sonnet outperforms other models on the Hard-Level dataset (89.43), significantly surpassing the medical LLMs; (2) Justice is consistently the most difficult nursing value dimension to evaluate; and (3) in-context learning significantly improves alignment. This work aims to provide a foundation for value-sensitive LLMs development in clinical settings. The dataset and the code are available at this https URL.</li>
</ul>

<h3>Title: Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies</h3>
<ul>
<li><strong>Authors: </strong>Xiaoliang Luo, Xinyi Xu, Michael Ramscar, Bradley C. Love</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08739">https://arxiv.org/abs/2505.08739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08739">https://arxiv.org/pdf/2505.08739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08739]] Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies(https://arxiv.org/abs/2505.08739)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Can autoregressive large language models (LLMs) learn consistent probability distributions when trained on sequences in different token orders? We prove formally that for any well-defined probability distribution, sequence perplexity is invariant under any factorization, including forward, backward, or arbitrary permutations. This result establishes a rigorous theoretical foundation for studying how LLMs learn from data and defines principled protocols for empirical evaluation. Applying these protocols, we show that prior studies examining ordering effects suffer from critical methodological flaws. We retrain GPT-2 models across forward, backward, and arbitrary permuted orders on scientific text. We find systematic deviations from theoretical invariance across all orderings with arbitrary permutations strongly deviating from both forward and backward models, which largely (but not completely) agreed with one another. Deviations were traceable to differences in self-attention, reflecting positional and locality biases in processing. Our theoretical and empirical results provide novel avenues for understanding positional biases in LLMs and suggest methods for detecting when LLMs' probability distributions are inconsistent and therefore untrustworthy.</li>
</ul>

<h3>Title: Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>Huiyan Qi, Bin Zhu, Chong-Wah Ngo, Jingjing Chen, Ee-Peng Lim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08747">https://arxiv.org/abs/2505.08747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08747">https://arxiv.org/pdf/2505.08747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08747]] Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion(https://arxiv.org/abs/2505.08747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Nutrition estimation is an important component of promoting healthy eating and mitigating diet-related health risks. Despite advances in tasks such as food classification and ingredient recognition, progress in nutrition estimation is limited due to the lack of datasets with nutritional annotations. To address this issue, we introduce FastFood, a dataset with 84,446 images across 908 fast food categories, featuring ingredient and nutritional annotations. In addition, we propose a new model-agnostic Visual-Ingredient Feature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating visual and ingredient features. Ingredient robustness is improved through synonym replacement and resampling strategies during training. The ingredient-aware visual feature fusion module combines ingredient features and visual representation to achieve accurate nutritional prediction. During testing, ingredient predictions are refined using large multimodal models by data augmentation and majority voting. Our experiments on both FastFood and Nutrition5k datasets validate the effectiveness of our proposed method built in different backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the importance of ingredient information in nutrition estimation. this https URL.</li>
</ul>

<h3>Title: Implet: A Post-hoc Subsequence Explainer for Time Series Models</h3>
<ul>
<li><strong>Authors: </strong>Fanyu Meng, Ziwen Kan, Shahbaz Rezaei, Zhaodan Kong, Xin Chen, Xin Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08748">https://arxiv.org/abs/2505.08748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08748">https://arxiv.org/pdf/2505.08748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08748]] Implet: A Post-hoc Subsequence Explainer for Time Series Models(https://arxiv.org/abs/2505.08748)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Explainability in time series models is crucial for fostering trust, facilitating debugging, and ensuring interpretability in real-world applications. In this work, we introduce Implet, a novel post-hoc explainer that generates accurate and concise subsequence-level explanations for time series models. Our approach identifies critical temporal segments that significantly contribute to the model's predictions, providing enhanced interpretability beyond traditional feature-attribution methods. Based on it, we propose a cohort-based (group-level) explanation framework designed to further improve the conciseness and interpretability of our explanations. We evaluate Implet on several standard time-series classification benchmarks, demonstrating its effectiveness in improving interpretability. The code is available at this https URL</li>
</ul>

<h3>Title: AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08750">https://arxiv.org/abs/2505.08750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08750">https://arxiv.org/pdf/2505.08750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08750]] AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models(https://arxiv.org/abs/2505.08750)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Actual causality (AC), a fundamental aspect of causal reasoning (CR), is responsible for attribution and responsibility assignment in real-world scenarios. However, existing LLM-based methods lack grounding in formal AC theory, resulting in limited interpretability. Therefore, we propose AC-Reason, a semi-formal reasoning framework that identifies causally relevant events within an AC scenario, infers the values of their formal causal factors (e.g., sufficiency, necessity, and normality), and answers AC queries via a theory-guided algorithm with explanations. While AC-Reason does not explicitly construct a causal graph, it operates over variables in the underlying causal structure to support principled reasoning. To enable comprehensive evaluation, we introduce AC-Bench, a new benchmark built upon and substantially extending Big-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully annotated samples, each with detailed reasoning steps and focuses solely on actual causation. The case study shows that synthesized samples in AC-Bench present greater challenges for LLMs. Extensive experiments on BBH-CJ and AC-Bench show that AC-Reason consistently improves LLM performance over baselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy of 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 + AC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further enables fine-grained analysis of reasoning faithfulness, revealing that only Qwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful reasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation study proves that integrating AC theory into LLMs is highly effective, with the proposed algorithm contributing the most significant performance gains.</li>
</ul>

<h3>Title: Aya Vision: Advancing the Frontier of Multilingual Multimodality</h3>
<ul>
<li><strong>Authors: </strong>Saurabh Dash, Yiyang Nan, John Dang, Arash Ahmadian, Shivalika Singh, Madeline Smith, Bharat Venkitesh, Vlad Shmyhlo, Viraat Aryabumi, Walter Beller-Morales, Jeremy Pekmez, Jason Ozuzu, Pierre Richemond, Acyr Locatelli, Nick Frosst, Phil Blunsom, Aidan Gomez, Ivan Zhang, Marzieh Fadaee, Manoj Govindassamy, Sudip Roy, Matthias Gall√©, Beyza Ermis, Ahmet √úst√ºn, Sara Hooker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08751">https://arxiv.org/abs/2505.08751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08751">https://arxiv.org/pdf/2505.08751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08751]] Aya Vision: Advancing the Frontier of Multilingual Multimodality(https://arxiv.org/abs/2505.08751)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Building multimodal language models is fundamentally challenging: it requires aligning vision and language modalities, curating high-quality instruction data, and avoiding the degradation of existing text-only capabilities once vision is introduced. These difficulties are further magnified in the multilingual setting, where the need for multimodal data in different languages exacerbates existing data scarcity, machine translation often distorts meaning, and catastrophic forgetting is more pronounced. To address the aforementioned challenges, we introduce novel techniques spanning both data and modeling. First, we develop a synthetic annotation framework that curates high-quality, diverse multilingual multimodal instruction data, enabling Aya Vision models to produce natural, human-preferred responses to multimodal inputs across many languages. Complementing this, we propose a cross-modal model merging technique that mitigates catastrophic forgetting, effectively preserving text-only capabilities while simultaneously enhancing multimodal generative performance. Aya-Vision-8B achieves best-in-class performance compared to strong multimodal models such as Qwen-2.5-VL-7B, Pixtral-12B, and even much larger Llama-3.2-90B-Vision. We further scale this approach with Aya-Vision-32B, which outperforms models more than twice its size, such as Molmo-72B and LLaMA-3.2-90B-Vision. Our work advances multilingual progress on the multi-modal frontier, and provides insights into techniques that effectively bend the need for compute while delivering extremely high performance.</li>
</ul>

<h3>Title: Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology</h3>
<ul>
<li><strong>Authors: </strong>Yatai Ji, Zhengqiu Zhu, Yong Zhao, Beidan Liu, Chen Gao, Yihao Zhao, Sihang Qiu, Yue Hu, Quanjun Yin, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08765">https://arxiv.org/abs/2505.08765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08765">https://arxiv.org/pdf/2505.08765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08765]] Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology(https://arxiv.org/abs/2505.08765)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aerial Visual Object Search (AVOS) tasks in urban environments require Unmanned Aerial Vehicles (UAVs) to autonomously search for and identify target objects using visual and textual cues without external guidance. Existing approaches struggle in complex urban environments due to redundant semantic processing, similar object distinction, and the exploration-exploitation dilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS, the first benchmark dataset for autonomous search of common urban objects. This dataset comprises 2,420 tasks across six object categories with varying difficulty levels, enabling comprehensive evaluation of UAV agents' search capabilities. To solve the AVOS tasks, we also propose PRPSearcher (Perception-Reasoning-Planning Searcher), a novel agentic method powered by multi-modal large language models (MLLMs) that mimics human three-tier cognition. Specifically, PRPSearcher constructs three specialized maps: an object-centric dynamic semantic map enhancing spatial perception, a 3D cognitive map based on semantic attraction values for target reasoning, and a 3D uncertainty map for balanced exploration-exploitation search. Also, our approach incorporates a denoising mechanism to mitigate interference from similar objects and utilizes an Inspiration Promote Thought (IPT) prompting mechanism for adaptive action planning. Experimental results on CityAVOS demonstrate that PRPSearcher surpasses existing baselines in both success rate and search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and -46.40% NE). While promising, the performance gap compared to humans highlights the need for better semantic reasoning and spatial exploration capabilities in AVOS tasks. This work establishes a foundation for future advances in embodied target search. Dataset and source code are available at this https URL.</li>
</ul>

<h3>Title: Blockchain Technology: Core Mechanisms, Evolution, and Future Implementation Challenges</h3>
<ul>
<li><strong>Authors: </strong>Aditya Pratap Singh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08772">https://arxiv.org/abs/2505.08772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08772">https://arxiv.org/pdf/2505.08772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08772]] Blockchain Technology: Core Mechanisms, Evolution, and Future Implementation Challenges(https://arxiv.org/abs/2505.08772)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Blockchain technology has emerged as one of the most transformative digital innovations of the 21st century. This paper presents a comprehensive review of blockchain's fundamental architecture, tracing its development from Bitcoin's initial implementation to current enterprise applications. We examine the core technical components including distributed consensus algorithms, cryptographic principles, and smart contract functionality that enable blockchain's unique properties. The historical progression from cryptocurrency-focused systems to robust platforms for decentralized applications is analyzed, highlighting pivotal developments in scalability, privacy, and interoperability. Additionally, we identify critical challenges facing widespread blockchain adoption, including technical limitations, regulatory hurdles, and integration complexities with existing systems. By providing this foundational understanding of blockchain technology, this paper contributes to ongoing research efforts addressing blockchain's potential to revolutionize data management across industries.</li>
</ul>

<h3>Title: HealthBench: Evaluating Large Language Models Towards Improved Human Health</h3>
<ul>
<li><strong>Authors: </strong>Rahul K. Arora, Jason Wei, Rebecca Soskin Hicks, Preston Bowman, Joaquin Qui√±onero-Candela, Foivos Tsimpourlas, Michael Sharman, Meghan Shah, Andrea Vallone, Alex Beutel, Johannes Heidecke, Karan Singhal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08775">https://arxiv.org/abs/2505.08775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08775">https://arxiv.org/pdf/2505.08775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08775]] HealthBench: Evaluating Large Language Models Towards Improved Human Health(https://arxiv.org/abs/2505.08775)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present HealthBench, an open-source benchmark measuring the performance and safety of large language models in healthcare. HealthBench consists of 5,000 multi-turn conversations between a model and an individual user or healthcare professional. Responses are evaluated using conversation-specific rubrics created by 262 physicians. Unlike previous multiple-choice or short-answer benchmarks, HealthBench enables realistic, open-ended evaluation through 48,562 unique rubric criteria spanning several health contexts (e.g., emergencies, transforming clinical data, global health) and behavioral dimensions (e.g., accuracy, instruction following, communication). HealthBench performance over the last two years reflects steady initial progress (compare GPT-3.5 Turbo's 16% to GPT-4o's 32%) and more rapid recent improvements (o3 scores 60%). Smaller models have especially improved: GPT-4.1 nano outperforms GPT-4o and is 25 times cheaper. We additionally release two HealthBench variations: HealthBench Consensus, which includes 34 particularly important dimensions of model behavior validated via physician consensus, and HealthBench Hard, where the current top score is 32%. We hope that HealthBench grounds progress towards model development and applications that benefit human health.</li>
</ul>

<h3>Title: Addressing the Current Challenges of Quantum Machine Learning through Multi-Chip Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Junghoon Justin Park, Jiook Cha, Samuel Yen-Chi Chen, Huan-Hsin Tseng, Shinjae Yoo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08782">https://arxiv.org/abs/2505.08782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08782">https://arxiv.org/pdf/2505.08782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08782]] Addressing the Current Challenges of Quantum Machine Learning through Multi-Chip Ensembles(https://arxiv.org/abs/2505.08782)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Quantum Machine Learning (QML) holds significant promise for solving computational challenges across diverse domains. However, its practical deployment is constrained by the limitations of noisy intermediate-scale quantum (NISQ) devices, including noise, limited scalability, and trainability issues in variational quantum circuits (VQCs). We introduce the multi-chip ensemble VQC framework, which partitions high-dimensional computations across smaller quantum chips to enhance scalability, trainability, and noise resilience. We show that this approach mitigates barren plateaus, reduces quantum error bias and variance, and maintains robust generalization through controlled entanglement. Designed to align with current and emerging quantum hardware, the framework demonstrates strong potential for enabling scalable QML on near-term devices, as validated by experiments on standard benchmark datasets (MNIST, FashionMNIST, CIFAR-10) and real world dataset (PhysioNet EEG).</li>
</ul>

<h3>Title: CodePDE: An Inference Framework for LLM-driven PDE Solver Generation</h3>
<ul>
<li><strong>Authors: </strong>Shanda Li, Tanya Marwah, Junhong Shen, Weiwei Sun, Andrej Risteski, Yiming Yang, Ameet Talwalkar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08783">https://arxiv.org/abs/2505.08783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08783">https://arxiv.org/pdf/2505.08783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08783]] CodePDE: An Inference Framework for LLM-driven PDE Solver Generation(https://arxiv.org/abs/2505.08783)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Partial differential equations (PDEs) are fundamental to modeling physical systems, yet solving them remains a complex challenge. Traditional numerical solvers rely on expert knowledge to implement and are computationally expensive, while neural-network-based solvers require large training datasets and often lack interpretability. In this work, we frame PDE solving as a code generation task and introduce CodePDE, the first inference framework for generating PDE solvers using large language models (LLMs). Leveraging advanced inference-time algorithms and scaling strategies, CodePDE unlocks critical capacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and test-time scaling -- all without task-specific tuning. CodePDE achieves superhuman performance across a range of representative PDE problems. We also present a systematic empirical analysis of LLM generated solvers, analyzing their accuracy, efficiency, and numerical scheme choices. Our findings highlight the promise and the current limitations of LLMs in PDE solving, offering a new perspective on solver design and opportunities for future model development. Our code is available at this https URL.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
