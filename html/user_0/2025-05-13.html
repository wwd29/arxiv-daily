<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-05-13</h1>
<h3>Title: Beyond Attention: Toward Machines with Intrinsic Higher Mental States</h3>
<ul>
<li><strong>Authors: </strong>Ahsan Adeel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06257">https://arxiv.org/abs/2505.06257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06257">https://arxiv.org/pdf/2505.06257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06257]] Beyond Attention: Toward Machines with Intrinsic Higher Mental States(https://arxiv.org/abs/2505.06257)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Attending to what is relevant is fundamental to both the mammalian brain and modern machine learning models such as Transformers. Yet, determining relevance remains a core challenge, traditionally offloaded to learning algorithms like backpropagation. Inspired by recent cellular neurobiological evidence linking neocortical pyramidal cells to distinct mental states, this work shows how models (e.g., Transformers) can emulate high-level perceptual processing and awake thought (imagination) states to pre-select relevant information before applying attention. Triadic neuronal-level modulation loops among questions ($Q$), clues (keys, $K$), and hypotheses (values, $V$) enable diverse, deep, parallel reasoning chains at the representation level and allow a rapid shift from initial biases to refined understanding. This leads to orders-of-magnitude faster learning with significantly reduced computational demand (e.g., fewer heads, layers, and tokens), at an approximate cost of $\mathcal{O}(N)$, where $N$ is the number of input tokens. Results span reinforcement learning (e.g., CarRacing in a high-dimensional visual setup), computer vision, and natural language question answering.</li>
</ul>

<h3>Title: ABE: A Unified Framework for Robust and Faithful Attribution-Based Explainability</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Zhu, Jiayu Zhang, Zhibo Jin, Fang Chen, Jianlong Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06258">https://arxiv.org/abs/2505.06258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06258">https://arxiv.org/pdf/2505.06258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06258]] ABE: A Unified Framework for Robust and Faithful Attribution-Based Explainability(https://arxiv.org/abs/2505.06258)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Attribution algorithms are essential for enhancing the interpretability and trustworthiness of deep learning models by identifying key features driving model decisions. Existing frameworks, such as InterpretDL and OmniXAI, integrate multiple attribution methods but suffer from scalability limitations, high coupling, theoretical constraints, and lack of user-friendly implementations, hindering neural network transparency and interoperability. To address these challenges, we propose Attribution-Based Explainability (ABE), a unified framework that formalizes Fundamental Attribution Methods and integrates state-of-the-art attribution algorithms while ensuring compliance with attribution axioms. ABE enables researchers to develop novel attribution techniques and enhances interpretability through four customizable modules: Robustness, Interpretability, Validation, and Data & Model. This framework provides a scalable, extensible foundation for advancing attribution-based explainability and fostering transparent AI systems. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Fair Clustering with Clusterlets</h3>
<ul>
<li><strong>Authors: </strong>Mattia Setzu, Riccardo Guidotti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06259">https://arxiv.org/abs/2505.06259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06259">https://arxiv.org/pdf/2505.06259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06259]] Fair Clustering with Clusterlets(https://arxiv.org/abs/2505.06259)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Given their widespread usage in the real world, the fairness of clustering methods has become of major interest. Theoretical results on fair clustering show that fairness enjoys transitivity: given a set of small and fair clusters, a trivial centroid-based clustering algorithm yields a fair clustering. Unfortunately, discovering a suitable starting clustering can be computationally expensive, rather complex or arbitrary. In this paper, we propose a set of simple \emph{clusterlet}-based fuzzy clustering algorithms that match single-class clusters, optimizing fair clustering. Matching leverages clusterlet distance, optimizing for classic clustering objectives, while also regularizing for fairness. Empirical results show that simple matching strategies are able to achieve high fairness, and that appropriate parameter tuning allows to achieve high cohesion and low overlap.</li>
</ul>

<h3>Title: Dialz: A Python Toolkit for Steering Vectors</h3>
<ul>
<li><strong>Authors: </strong>Zara Siddique, Liam D. Turner, Luis Espinosa-Anke</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06262">https://arxiv.org/abs/2505.06262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06262">https://arxiv.org/pdf/2505.06262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06262]] Dialz: A Python Toolkit for Steering Vectors(https://arxiv.org/abs/2505.06262)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We introduce Dialz, a framework for advancing research on steering vectors for open-source LLMs, implemented in Python. Steering vectors allow users to modify activations at inference time to amplify or weaken a 'concept', e.g. honesty or positivity, providing a more powerful alternative to prompting or fine-tuning. Dialz supports a diverse set of tasks, including creating contrastive pair datasets, computing and applying steering vectors, and visualizations. Unlike existing libraries, Dialz emphasizes modularity and usability, enabling both rapid prototyping and in-depth analysis. We demonstrate how Dialz can be used to reduce harmful outputs such as stereotypes, while also providing insights into model behaviour across different layers. We release Dialz with full documentation, tutorials, and support for popular open-source models to encourage further research in safe and controllable language generation. Dialz enables faster research cycles and facilitates insights into model interpretability, paving the way for safer, more transparent, and more reliable AI systems.</li>
</ul>

<h3>Title: ONERA's CRM WBPN database for machine learning activities, related regression challenge and first results</h3>
<ul>
<li><strong>Authors: </strong>Jacques Peter, Quentin Bennehard, Sébastien Heib, Jean-Luc Hantrais-Gervois, Frédéric Moëns</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06265">https://arxiv.org/abs/2505.06265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06265">https://arxiv.org/pdf/2505.06265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06265]] ONERA's CRM WBPN database for machine learning activities, related regression challenge and first results(https://arxiv.org/abs/2505.06265)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>This paper presents a new Computational Fluid Dynamics database, developed at ONERA, to support the advancement of machine learning techniques for aerodynamic field prediction. It contains 468 Reynolds-Averaged Navier-Stokes simulations using the Spalart-Allmaras turbulence model, performed on the NASA/Boeing Common Research Model wing-body-pylon-nacelle configuration. The database spans a wide range of flow conditions, varying Mach number (including transonic regimes), angle of attack (capturing flow separation), and Reynolds number (based on three stagnation pressures, with one setting matching wind tunnel experiments). The quality of the database is assessed, through checking the convergence level of each computation. Based on these data, a regression challenge is defined. It consists in predicting the wall distributions of pressure and friction coefficients for unseen aerodynamic conditions. The 468 simulations are split into training and testing sets, with the training data made available publicly on the Codabench platform. The paper further evaluates several classical machine learning regressors on this task. Tested pointwise methods include Multi-Layer Perceptrons, $\lambda$-DNNs, and Decision Trees, while global methods include Multi-Layer Perceptron, k-Nearest Neighbors, Proper Orthogonal Decomposition and IsoMap. Initial performance results, using $R^2$ scores and worst relative mean absolute error metrics, are presented, offering insights into the capabilities of these techniques for the challenge and references for future work.</li>
</ul>

<h3>Title: Knowledge Guided Encoder-Decoder Framework Integrating Multiple Physical Models for Agricultural Ecosystem Modeling</h3>
<ul>
<li><strong>Authors: </strong>Qi Cheng, Licheng Liu, Zhang Yao, Hong Mu, Shiyuan Luo, Zhenong Jin, Yiqun Xie, Xiaowei Jia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06266">https://arxiv.org/abs/2505.06266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06266">https://arxiv.org/pdf/2505.06266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06266]] Knowledge Guided Encoder-Decoder Framework Integrating Multiple Physical Models for Agricultural Ecosystem Modeling(https://arxiv.org/abs/2505.06266)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Agricultural monitoring is critical for ensuring food security, maintaining sustainable farming practices, informing policies on mitigating food shortage, and managing greenhouse gas emissions. Traditional process-based physical models are often designed and implemented for specific situations, and their parameters could also be highly uncertain. In contrast, data-driven models often use black-box structures and does not explicitly model the inter-dependence between different ecological variables. As a result, they require extensive training data and lack generalizability to different tasks with data distribution shifts and inconsistent observed variables. To address the need for more universal models, we propose a knowledge-guided encoder-decoder model, which can predict key crop variables by leveraging knowledge of underlying processes from multiple physical models. The proposed method also integrates a language model to process complex and inconsistent inputs and also utilizes it to implement a model selection mechanism for selectively combining the knowledge from different physical models. Our evaluations on predicting carbon and nitrogen fluxes for multiple sites demonstrate the effectiveness and robustness of the proposed model under various scenarios.</li>
</ul>

<h3>Title: Cluster-Aware Multi-Round Update for Wireless Federated Learning in Heterogeneous Environments</h3>
<ul>
<li><strong>Authors: </strong>Pengcheng Sun, Erwu Liu, Wei Ni, Kanglei Yu, Rui Wang, Abbas Jamalipour</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06268">https://arxiv.org/abs/2505.06268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06268">https://arxiv.org/pdf/2505.06268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06268]] Cluster-Aware Multi-Round Update for Wireless Federated Learning in Heterogeneous Environments(https://arxiv.org/abs/2505.06268)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>The aggregation efficiency and accuracy of wireless Federated Learning (FL) are significantly affected by resource constraints, especially in heterogeneous environments where devices exhibit distinct data distributions and communication capabilities. This paper proposes a clustering strategy that leverages prior knowledge similarity to group devices with similar data and communication characteristics, mitigating performance degradation from heterogeneity. On this basis, a novel Cluster- Aware Multi-round Update (CAMU) strategy is proposed, which treats clusters as the basic units and adjusts the local update frequency based on the clustered contribution threshold, effectively reducing update bias and enhancing aggregation accuracy. The theoretical convergence of the CAMU strategy is rigorously validated. Meanwhile, based on the convergence upper bound, the local update frequency and transmission power of each cluster are jointly optimized to achieve an optimal balance between computation and communication resources under constrained conditions, significantly improving the convergence efficiency of FL. Experimental results demonstrate that the proposed method effectively improves the model performance of FL in heterogeneous environments and achieves a better balance between communication cost and computational load under limited resources.</li>
</ul>

<h3>Title: PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model</h3>
<ul>
<li><strong>Authors: </strong>Baijiong Lin, Weisen Jiang, Yuancheng Xu, Hao Chen, Ying-Cong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06274">https://arxiv.org/abs/2505.06274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06274">https://arxiv.org/pdf/2505.06274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06274]] PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model(https://arxiv.org/abs/2505.06274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-objective test-time alignment aims to adapt large language models (LLMs) to diverse multi-dimensional user preferences during inference while keeping LLMs frozen. Recently, GenARM (Xu et al., 2025) first independently trains Autoregressive Reward Models (ARMs) for each preference dimension without awareness of each other, then combines their outputs based on user-specific preference vectors during inference to achieve multi-objective test-time alignment, leading to two key limitations: the need for \textit{multiple} ARMs increases the inference cost, and the separate training of ARMs causes the misalignment between the guided generation and the user preferences. To address these issues, we propose Preference-aware ARM (PARM), a single unified ARM trained across all preference dimensions. PARM uses our proposed Preference-Aware Bilinear Low-Rank Adaptation (PBLoRA), which employs a bilinear form to condition the ARM on preference vectors, enabling it to achieve precise control over preference trade-offs during inference. Experiments demonstrate that PARM reduces inference costs and achieves better alignment with preference vectors compared with existing methods. Additionally, PARM enables weak-to-strong guidance, allowing a smaller PARM to guide a larger frozen LLM without expensive training, making multi-objective alignment accessible with limited computing resources. The code is available at this https URL.</li>
</ul>

<h3>Title: Attonsecond Streaking Phase Retrieval Via Deep Learning Methods</h3>
<ul>
<li><strong>Authors: </strong>Yuzhou Zhu, Zheng Zhang, Ruyi Zhang, Liang Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, physics.optics</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06275">https://arxiv.org/abs/2505.06275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06275">https://arxiv.org/pdf/2505.06275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06275]] Attonsecond Streaking Phase Retrieval Via Deep Learning Methods(https://arxiv.org/abs/2505.06275)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Attosecond streaking phase retrieval is essential for resolving electron dynamics on sub-femtosecond time scales yet traditional algorithms rely on iterative minimization and central momentum approximations that degrade accuracy for broadband pulses. In this work phase retrieval is reformulated as a supervised computer-vision problem and four neural architectures are systematically compared. A convolutional network demonstrates strong sensitivity to local streak edges but lacks global context; a vision transformer captures long-range delay-energy correlations at the expense of local inductive bias; a hybrid CNN-ViT model unites local feature extraction and full-graph attention; and a capsule network further enforces spatial pose agreement through dynamic routing. A theoretical analysis introduces local, global and positional sensitivity measures and derives surrogate error bounds that predict the strict ordering $CNN<ViT<Hybrid<Capsule$. Controlled experiments on synthetic streaking spectrograms confirm this hierarchy, with the capsule network achieving the highest retrieval fidelity. Looking forward, embedding the strong-field integral into physics-informed neural networks and exploring photonic hardware implementations promise pathways toward real-time attosecond pulse characterization under demanding experimental conditions.</li>
</ul>

<h3>Title: Interpretable Learning Dynamics in Unsupervised Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Shashwat Pandey</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06279">https://arxiv.org/abs/2505.06279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06279">https://arxiv.org/pdf/2505.06279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06279]] Interpretable Learning Dynamics in Unsupervised Reinforcement Learning(https://arxiv.org/abs/2505.06279)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We present an interpretability framework for unsupervised reinforcement learning (URL) agents, aimed at understanding how intrinsic motivation shapes attention, behavior, and representation learning. We analyze five agents DQN, RND, ICM, PPO, and a Transformer-RND variant trained on procedurally generated environments, using Grad-CAM, Layer-wise Relevance Propagation (LRP), exploration metrics, and latent space clustering. To capture how agents perceive and adapt over time, we introduce two metrics: attention diversity, which measures the spatial breadth of focus, and attention change rate, which quantifies temporal shifts in attention. Our findings show that curiosity-driven agents display broader, more dynamic attention and exploratory behavior than their extrinsically motivated counterparts. Among them, TransformerRND combines wide attention, high exploration coverage, and compact, structured latent representations. Our results highlight the influence of architectural inductive biases and training signals on internal agent dynamics. Beyond reward-centric evaluation, the proposed framework offers diagnostic tools to probe perception and abstraction in RL agents, enabling more interpretable and generalizable behavior.</li>
</ul>

<h3>Title: Show or Tell? A Benchmark To Evaluate Visual and Textual Prompts in Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Gabriele Rosi, Fabio Cermelli</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06280">https://arxiv.org/abs/2505.06280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06280">https://arxiv.org/pdf/2505.06280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06280]] Show or Tell? A Benchmark To Evaluate Visual and Textual Prompts in Semantic Segmentation(https://arxiv.org/abs/2505.06280)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Prompt engineering has shown remarkable success with large language models, yet its systematic exploration in computer vision remains limited. In semantic segmentation, both textual and visual prompts offer distinct advantages: textual prompts through open-vocabulary methods allow segmentation of arbitrary categories, while visual reference prompts provide intuitive reference examples. However, existing benchmarks evaluate these modalities in isolation, without direct comparison under identical conditions. We present Show or Tell (SoT), a novel benchmark specifically designed to evaluate both visual and textual prompts for semantic segmentation across 14 datasets spanning 7 diverse domains (common scenes, urban, food, waste, parts, tools, and land-cover). We evaluate 5 open-vocabulary methods and 4 visual reference prompt approaches, adapting the latter to handle multi-class segmentation through a confidence-based mask merging strategy. Our extensive experiments reveal that open-vocabulary methods excel with common concepts easily described by text but struggle with complex domains like tools, while visual reference prompt methods achieve good average results but exhibit high variability depending on the input prompt. Through comprehensive quantitative and qualitative analysis, we identify the strengths and weaknesses of both prompting modalities, providing valuable insights to guide future research in vision foundation models for segmentation tasks.</li>
</ul>

<h3>Title: A Data-Driven Probabilistic Framework for Cascading Urban Risk Analysis Using Bayesian Networks</h3>
<ul>
<li><strong>Authors: </strong>Chunduru Rohith Kumar, PHD Surya Shanmuk, Prabhala Naga Srinivas, Sri Venkatesh Lankalapalli, Debasis Dwibedy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06281">https://arxiv.org/abs/2505.06281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06281">https://arxiv.org/pdf/2505.06281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06281]] A Data-Driven Probabilistic Framework for Cascading Urban Risk Analysis Using Bayesian Networks(https://arxiv.org/abs/2505.06281)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The increasing complexity of cascading risks in urban systems necessitates robust, data-driven frameworks to model interdependencies across multiple domains. This study presents a foundational Bayesian network-based approach for analyzing cross-domain risk propagation across key urban domains, including air, water, electricity, agriculture, health, infrastructure, weather, and climate. Directed Acyclic Graphs (DAGs) are constructed using Bayesian Belief Networks (BBNs), with structure learning guided by Hill-Climbing search optimized through Bayesian Information Criterion (BIC) and K2 scoring. The framework is trained on a hybrid dataset that combines real-world urban indicators with synthetically generated data from Generative Adversarial Networks (GANs), and is further balanced using the Synthetic Minority Over-sampling Technique (SMOTE). Conditional Probability Tables (CPTs) derived from the learned structures enable interpretable probabilistic reasoning and quantify the likelihood of cascading failures. The results identify key intra- and inter-domain risk factors and demonstrate the framework's utility for proactive urban resilience planning. This work establishes a scalable, interpretable foundation for cascading risk assessment and serves as a basis for future empirical research in this emerging interdisciplinary field.</li>
</ul>

<h3>Title: DMRL: Data- and Model-aware Reward Learning for Data Extraction</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Wang, Ruoxi Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06284">https://arxiv.org/abs/2505.06284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06284">https://arxiv.org/pdf/2505.06284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06284]] DMRL: Data- and Model-aware Reward Learning for Data Extraction(https://arxiv.org/abs/2505.06284)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are inherently vulnerable to unintended privacy breaches. Consequently, systematic red-teaming research is essential for developing robust defense mechanisms. However, current data extraction methods suffer from several limitations: (1) rely on dataset duplicates (addressable via deduplication), (2) depend on prompt engineering (now countered by detection and defense), and (3) rely on random-search adversarial generation. To address these challenges, we propose DMRL, a Data- and Model-aware Reward Learning approach for data extraction. This technique leverages inverse reinforcement learning to extract sensitive data from LLMs. Our method consists of two main components: (1) constructing an introspective reasoning dataset that captures leakage mindsets to guide model behavior, and (2) training reward models with Group Relative Policy Optimization (GRPO), dynamically tuning optimization based on task difficulty at both the data and model levels. Comprehensive experiments across various LLMs demonstrate that DMRL outperforms all baseline methods in data extraction performance.</li>
</ul>

<h3>Title: Edge-Optimized Deep Learning & Pattern Recognition Techniques for Non-Intrusive Load Monitoring of Energy Time Series</h3>
<ul>
<li><strong>Authors: </strong>Sotirios Athanasoulias</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06289">https://arxiv.org/abs/2505.06289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06289">https://arxiv.org/pdf/2505.06289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06289]] Edge-Optimized Deep Learning & Pattern Recognition Techniques for Non-Intrusive Load Monitoring of Energy Time Series(https://arxiv.org/abs/2505.06289)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The growing global energy demand and the urgent need for sustainability call for innovative ways to boost energy efficiency. While advanced energy-saving systems exist, they often fall short without user engagement. Providing feedback on energy consumption behavior is key to promoting sustainable practices. Non-Intrusive Load Monitoring (NILM) offers a promising solution by disaggregating total household energy usage, recorded by a central smart meter, into appliance-level data. This empowers users to optimize consumption. Advances in AI, IoT, and smart meter adoption have further enhanced NILM's potential. Despite this promise, real-world NILM deployment faces major challenges. First, existing datasets mainly represent regions like the USA and UK, leaving places like the Mediterranean underrepresented. This limits understanding of regional consumption patterns, such as heavy use of air conditioners and electric water heaters. Second, deep learning models used in NILM require high computational power, often relying on cloud services. This increases costs, raises privacy concerns, and limits scalability, especially for households with poor connectivity. This thesis tackles these issues with key contributions. It presents an interoperable data collection framework and introduces the Plegma Dataset, focused on underrepresented Mediterranean energy patterns. It also explores advanced deep neural networks and model compression techniques for efficient edge deployment. By bridging theoretical advances with practical needs, this work aims to make NILM scalable, efficient, and adaptable for global energy sustainability.</li>
</ul>

<h3>Title: UniCO: Towards a Unified Model for Combinatorial Optimization Problems</h3>
<ul>
<li><strong>Authors: </strong>Zefang Zong, Xiaochen Wei, Guozhen Zhang, Chen Gao, Huandong Wang, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06290">https://arxiv.org/abs/2505.06290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06290">https://arxiv.org/pdf/2505.06290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06290]] UniCO: Towards a Unified Model for Combinatorial Optimization Problems(https://arxiv.org/abs/2505.06290)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Combinatorial Optimization (CO) encompasses a wide range of problems that arise in many real-world scenarios. While significant progress has been made in developing learning-based methods for specialized CO problems, a unified model with a single architecture and parameter set for diverse CO problems remains elusive. Such a model would offer substantial advantages in terms of efficiency and convenience. In this paper, we introduce UniCO, a unified model for solving various CO problems. Inspired by the success of next-token prediction, we frame each problem-solving process as a Markov Decision Process (MDP), tokenize the corresponding sequential trajectory data, and train the model using a transformer backbone. To reduce token length in the trajectory data, we propose a CO-prefix design that aggregates static problem features. To address the heterogeneity of state and action tokens within the MDP, we employ a two-stage self-supervised learning approach. In this approach, a dynamic prediction model is first trained and then serves as a pre-trained model for subsequent policy generation. Experiments across 10 CO problems showcase the versatility of UniCO, emphasizing its ability to generalize to new, unseen problems with minimal fine-tuning, achieving even few-shot or zero-shot performance. Our framework offers a valuable complement to existing neural CO methods that focus on optimizing performance for individual problems.</li>
</ul>

<h3>Title: Spatio-Temporal Graph Neural Network for Urban Spaces: Interpolating Citywide Traffic Volume</h3>
<ul>
<li><strong>Authors: </strong>Silke K. Kaiser, Filipe Rodrigues, Carlos Lima Azevedo, Lynn H. Kaack</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06292">https://arxiv.org/abs/2505.06292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06292">https://arxiv.org/pdf/2505.06292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06292]] Spatio-Temporal Graph Neural Network for Urban Spaces: Interpolating Citywide Traffic Volume(https://arxiv.org/abs/2505.06292)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reliable street-level traffic volume data, covering multiple modes of transportation, helps urban planning by informing decisions on infrastructure improvements, traffic management, and public transportation. Yet, traffic sensors measuring traffic volume are typically scarcely located, due to their high deployment and maintenance costs. To address this, interpolation methods can estimate traffic volumes at unobserved locations using available data. Graph Neural Networks have shown strong performance in traffic volume forecasting, particularly on highways and major arterial networks. Applying them to urban settings, however, presents unique challenges: urban networks exhibit greater structural diversity, traffic volumes are highly overdispersed with many zeros, the best way to account for spatial dependencies remains unclear, and sensor coverage is often very sparse. We introduce the Graph Neural Network for Urban Interpolation (GNNUI), a novel urban traffic volume estimation approach. GNNUI employs a masking algorithm to learn interpolation, integrates node features to capture functional roles, and uses a loss function tailored to zero-inflated traffic distributions. In addition to the model, we introduce two new open, large-scale urban traffic volume benchmarks, covering different transportation modes: Strava cycling data from Berlin and New York City taxi data. GNNUI outperforms recent, some graph-based, interpolation methods across metrics (MAE, RMSE, true-zero rate, Kullback-Leibler divergence) and remains robust from 90% to 1% sensor coverage. On Strava, for instance, MAE rises only from 7.1 to 10.5, on Taxi from 23.0 to 40.4, demonstrating strong performance under extreme data scarcity, common in real-world urban settings. We also examine how graph connectivity choices influence model accuracy.</li>
</ul>

<h3>Title: Benchmarking Traditional Machine Learning and Deep Learning Models for Fault Detection in Power Transformers</h3>
<ul>
<li><strong>Authors: </strong>Bhuvan Saravanan, Pasanth Kumar M D, Aarnesh Vengateson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06295">https://arxiv.org/abs/2505.06295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06295">https://arxiv.org/pdf/2505.06295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06295]] Benchmarking Traditional Machine Learning and Deep Learning Models for Fault Detection in Power Transformers(https://arxiv.org/abs/2505.06295)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate diagnosis of power transformer faults is essential for ensuring the stability and safety of electrical power systems. This study presents a comparative analysis of conventional machine learning (ML) algorithms and deep learning (DL) algorithms for fault classification of power transformers. Using a condition-monitored dataset spanning 10 months, various gas concentration features were normalized and used to train five ML classifiers: Support Vector Machine (SVM), k-Nearest Neighbors (KNN), Random Forest (RF), XGBoost, and Artificial Neural Network (ANN). In addition, four DL models were evaluated: Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), One-Dimensional Convolutional Neural Network (1D-CNN), and TabNet. Experimental results show that both ML and DL approaches performed comparably. The RF model achieved the highest ML accuracy at 86.82%, while the 1D-CNN model attained a close 86.30%.</li>
</ul>

<h3>Title: Lossless Compression of Large Language Model-Generated Text via Next-Token Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yu Mao, Holger Pirk, Chun Jason Xue</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06297">https://arxiv.org/abs/2505.06297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06297">https://arxiv.org/pdf/2505.06297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06297]] Lossless Compression of Large Language Model-Generated Text via Next-Token Prediction(https://arxiv.org/abs/2505.06297)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) continue to be deployed and utilized across domains, the volume of LLM-generated data is growing rapidly. This trend highlights the increasing importance of effective and lossless compression for such data in modern text management systems. However, compressing LLM-generated data presents unique challenges compared to traditional human- or machine-generated content. Traditional machine-generated data is typically derived from computational processes or device outputs, often highly structured and limited to low-level elements like labels or numerical values. This structure enables conventional lossless compressors to perform efficiently. In contrast, LLM-generated data is more complex and diverse, requiring new approaches for effective compression. In this work, we conduct the first systematic investigation of lossless compression techniques tailored specifically to LLM-generated data. Notably, because LLMs are trained via next-token prediction, we find that LLM-generated data is highly predictable for the models themselves. This predictability enables LLMs to serve as efficient compressors of their own outputs. Through extensive experiments with 14 representative LLMs and 8 LLM-generated datasets from diverse domains, we show that LLM-based prediction methods achieve remarkable compression rates, exceeding 20x, far surpassing the 3x rate achieved by Gzip, a widely used general-purpose compressor. Furthermore, this advantage holds across different LLM sizes and dataset types, demonstrating the robustness and practicality of LLM-based methods in lossless text compression under generative AI workloads.</li>
</ul>

<h3>Title: Input-Specific and Universal Adversarial Attack Generation for Spiking Neural Networks in the Spiking Domain</h3>
<ul>
<li><strong>Authors: </strong>Spyridon Raptis, Haralampos-G. Stratigopoulos</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06299">https://arxiv.org/abs/2505.06299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06299">https://arxiv.org/pdf/2505.06299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06299]] Input-Specific and Universal Adversarial Attack Generation for Spiking Neural Networks in the Spiking Domain(https://arxiv.org/abs/2505.06299)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>As Spiking Neural Networks (SNNs) gain traction across various applications, understanding their security vulnerabilities becomes increasingly important. In this work, we focus on the adversarial attacks, which is perhaps the most concerning threat. An adversarial attack aims at finding a subtle input perturbation to fool the network's decision-making. We propose two novel adversarial attack algorithms for SNNs: an input-specific attack that crafts adversarial samples from specific dataset inputs and a universal attack that generates a reusable patch capable of inducing misclassification across most inputs, thus offering practical feasibility for real-time deployment. The algorithms are gradient-based operating in the spiking domain proving to be effective across different evaluation metrics, such as adversarial accuracy, stealthiness, and generation time. Experimental results on two widely used neuromorphic vision datasets, NMNIST and IBM DVS Gesture, show that our proposed attacks surpass in all metrics all existing state-of-the-art methods. Additionally, we present the first demonstration of adversarial attack generation in the sound domain using the SHD dataset.</li>
</ul>

<h3>Title: Domain-Adversarial Anatomical Graph Networks for Cross-User Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xiaozhou Ye, Kevin I-Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06301">https://arxiv.org/abs/2505.06301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06301">https://arxiv.org/pdf/2505.06301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06301]] Domain-Adversarial Anatomical Graph Networks for Cross-User Human Activity Recognition(https://arxiv.org/abs/2505.06301)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-user variability in Human Activity Recognition (HAR) remains a critical challenge due to differences in sensor placement, body dynamics, and behavioral patterns. Traditional methods often fail to capture biomechanical invariants that persist across users, limiting their generalization capability. We propose an Edge-Enhanced Graph-Based Adversarial Domain Generalization (EEG-ADG) framework that integrates anatomical correlation knowledge into a unified graph neural network (GNN) architecture. By modeling three biomechanically motivated relationships together-Interconnected Units, Analogous Units, and Lateral Units-our method encodes domain-invariant features while addressing user-specific variability through Variational Edge Feature Extractor. A Gradient Reversal Layer (GRL) enforces adversarial domain generalization, ensuring robustness to unseen users. Extensive experiments on OPPORTUNITY and DSADS datasets demonstrate state-of-the-art performance. Our work bridges biomechanical principles with graph-based adversarial learning by integrating information fusion techniques. This fusion of information underpins our unified and generalized model for cross-user HAR.</li>
</ul>

<h3>Title: QiMeng-TensorOp: Automatically Generating High-Performance Tensor Operators with Hardware Primitives</h3>
<ul>
<li><strong>Authors: </strong>Xuzhi Zhang, Shaohui Peng, Qirui Zhou, Yuanbo Wen, Qi Guo, Ruizhi Chen, Xinguo Zhu, Weiqiang Xiong, Haixin Chen, Congying Ma, Ke Gao, Chen Zhao, Yanjun Wu, Yunji Chen, Ling Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06302">https://arxiv.org/abs/2505.06302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06302">https://arxiv.org/pdf/2505.06302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06302]] QiMeng-TensorOp: Automatically Generating High-Performance Tensor Operators with Hardware Primitives(https://arxiv.org/abs/2505.06302)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Computation-intensive tensor operators constitute over 90\% of the computations in Large Language Models (LLMs) and Deep Neural this http URL and efficiently generating high-performance tensor operators with hardware primitives is crucial for diverse and ever-evolving hardware architectures like RISC-V, ARM, and GPUs, as manually optimized implementation takes at least months and lacks this http URL excel at generating high-level language codes, but they struggle to fully comprehend hardware characteristics and produce high-performance tensor operators. We introduce a tensor-operator auto-generation framework with a one-line user prompt (QiMeng-TensorOp), which enables LLMs to automatically exploit hardware characteristics to generate tensor operators with hardware primitives, and tune parameters for optimal performance across diverse hardware. Experimental results on various hardware platforms, SOTA LLMs, and typical tensor operators demonstrate that QiMeng-TensorOp effectively unleashes the computing capability of various hardware platforms, and automatically generates tensor operators of superior performance. Compared with vanilla LLMs, QiMeng-TensorOp achieves up to $1291 \times$ performance improvement. Even compared with human experts, QiMeng-TensorOp could reach $251 \%$ of OpenBLAS on RISC-V CPUs, and $124 \%$ of cuBLAS on NVIDIA GPUs. Additionally, QiMeng-TensorOp also significantly reduces development costs by $200 \times$ compared with human experts.</li>
</ul>

<h3>Title: Collaborative Multi-LoRA Experts with Achievement-based Multi-Tasks Loss for Unified Multimodal Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Li Yuan, Yi Cai, Xudong Shen, Qing Li, Qingbao Huang, Zikun Deng, Tao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06303">https://arxiv.org/abs/2505.06303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06303">https://arxiv.org/pdf/2505.06303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06303]] Collaborative Multi-LoRA Experts with Achievement-based Multi-Tasks Loss for Unified Multimodal Information Extraction(https://arxiv.org/abs/2505.06303)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Multimodal Information Extraction (MIE) has gained attention for extracting structured information from multimedia sources. Traditional methods tackle MIE tasks separately, missing opportunities to share knowledge across tasks. Recent approaches unify these tasks into a generation problem using instruction-based T5 models with visual adaptors, optimized through full-parameter fine-tuning. However, this method is computationally intensive, and multi-task fine-tuning often faces gradient conflicts, limiting performance. To address these challenges, we propose collaborative multi-LoRA experts with achievement-based multi-task loss (C-LoRAE) for MIE tasks. C-LoRAE extends the low-rank adaptation (LoRA) method by incorporating a universal expert to learn shared multimodal knowledge from cross-MIE tasks and task-specific experts to learn specialized instructional task features. This configuration enhances the model's generalization ability across multiple tasks while maintaining the independence of various instruction tasks and mitigating gradient conflicts. Additionally, we propose an achievement-based multi-task loss to balance training progress across tasks, addressing the imbalance caused by varying numbers of training samples in MIE tasks. Experimental results on seven benchmark datasets across three key MIE tasks demonstrate that C-LoRAE achieves superior overall performance compared to traditional fine-tuning methods and LoRA methods while utilizing a comparable number of training parameters to LoRA.</li>
</ul>

<h3>Title: RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhenhua Xu, Zhebo Wang, Maike Li, Wenpeng Xing, Chunqiang Hu, Chen Zhi, Meng Han</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06304">https://arxiv.org/abs/2505.06304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06304">https://arxiv.org/pdf/2505.06304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06304]] RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models(https://arxiv.org/abs/2505.06304)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have underscored the importance of safeguarding intellectual property rights through robust fingerprinting techniques. Traditional fingerprint verification approaches typically focus on a single model, seeking to improve the robustness of its this http URL, these single-model methods often struggle to capture intrinsic commonalities across multiple related models. In this paper, we propose RAP-SM (Robust Adversarial Prompt via Shadow Models), a novel framework that extracts a public fingerprint for an entire series of LLMs. Experimental results demonstrate that RAP-SM effectively captures the intrinsic commonalities among different models while exhibiting strong adversarial robustness. Our findings suggest that RAP-SM presents a valuable avenue for scalable fingerprint verification, offering enhanced protection against potential model breaches in the era of increasingly prevalent LLMs.</li>
</ul>

<h3>Title: User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data</h3>
<ul>
<li><strong>Authors: </strong>Haowei Yang, Qingyi Lu, Yang Wang, Sibei Liu, Jiayun Zheng, Ao Xiang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06305">https://arxiv.org/abs/2505.06305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06305">https://arxiv.org/pdf/2505.06305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06305]] User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data(https://arxiv.org/abs/2505.06305)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate, large language model</a></li>
<li><strong>Abstract: </strong>With the widespread application of large language models (LLMs), user privacy protection has become a significant research topic. Existing privacy preference modeling methods often rely on large-scale user data, making effective privacy preference analysis challenging in data-limited environments. This study explores how LLMs can analyze user behavior related to privacy protection in scenarios with limited data and proposes a method that integrates Few-shot Learning and Privacy Computing to model user privacy preferences. The research utilizes anonymized user privacy settings data, survey responses, and simulated data, comparing the performance of traditional modeling approaches with LLM-based methods. Experimental results demonstrate that, even with limited data, LLMs significantly improve the accuracy of privacy preference modeling. Additionally, incorporating Differential Privacy and Federated Learning further reduces the risk of user data exposure. The findings provide new insights into the application of LLMs in privacy protection and offer theoretical support for advancing privacy computing and user behavior analysis.</li>
</ul>

<h3>Title: Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought</h3>
<ul>
<li><strong>Authors: </strong>Mingfei Zeng, Ming Xie, Xixi Zheng, Chunhai Li, Chuan Zhang, Liehuang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06307">https://arxiv.org/abs/2505.06307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06307">https://arxiv.org/pdf/2505.06307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06307]] Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought(https://arxiv.org/abs/2505.06307)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of Internet of Things (IoT) technology has transformed people's way of life and has a profound impact on both production and daily activities. However, with the rapid advancement of IoT technology, the security of IoT devices has become an unavoidable issue in both research and applications. Although some efforts have been made to detect or mitigate IoT security vulnerabilities, they often struggle to adapt to the complexity of IoT environments, especially when dealing with dynamic security scenarios. How to automatically, efficiently, and accurately understand these vulnerabilities remains a challenge. To address this, we propose an IoT security assistant driven by Large Language Model (LLM), which enhances the LLM's understanding of IoT security vulnerabilities and related threats. The aim of the ICoT method we propose is to enable the LLM to understand security issues by breaking down the various dimensions of security vulnerabilities and generating responses tailored to the user's specific needs and expertise level. By incorporating ICoT, LLM can gradually analyze and reason through complex security scenarios, resulting in more accurate, in-depth, and personalized security recommendations and solutions. Experimental results show that, compared to methods relying solely on LLM, our proposed LLM-driven IoT security assistant significantly improves the understanding of IoT security issues through the ICoT approach and provides personalized solutions based on the user's identity, demonstrating higher accuracy and reliability.</li>
</ul>

<h3>Title: Defending against Indirect Prompt Injection by Instruction Detection</h3>
<ul>
<li><strong>Authors: </strong>Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie, Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06311">https://arxiv.org/abs/2505.06311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06311">https://arxiv.org/pdf/2505.06311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06311]] Defending against Indirect Prompt Injection by Instruction Detection(https://arxiv.org/abs/2505.06311)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>The integration of Large Language Models (LLMs) with external sources is becoming increasingly common, with Retrieval-Augmented Generation (RAG) being a prominent example. However, this integration introduces vulnerabilities of Indirect Prompt Injection (IPI) attacks, where hidden instructions embedded in external data can manipulate LLMs into executing unintended or harmful actions. We recognize that the success of IPI attacks fundamentally relies in the presence of instructions embedded within external content, which can alter the behavioral state of LLMs. Can effectively detecting such state changes help us defend against IPI attacks? In this paper, we propose a novel approach that takes external data as input and leverages the behavioral state of LLMs during both forward and backward propagation to detect potential IPI attacks. Specifically, we demonstrate that the hidden states and gradients from intermediate layers provide highly discriminative features for instruction detection. By effectively combining these features, our approach achieves a detection accuracy of 99.60\% in the in-domain setting and 96.90\% in the out-of-domain setting, while reducing the attack success rate to just 0.12\% on the BIPIA benchmark.</li>
</ul>

<h3>Title: Threat Modeling for AI: The Case for an Asset-Centric Approach</h3>
<ul>
<li><strong>Authors: </strong>Jose Sanchez Vicarte, Marcin Spoczynski, Mostafa Elsaid</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06315">https://arxiv.org/abs/2505.06315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06315">https://arxiv.org/pdf/2505.06315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06315]] Threat Modeling for AI: The Case for an Asset-Centric Approach(https://arxiv.org/abs/2505.06315)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Recent advances in AI are transforming AI's ubiquitous presence in our world from that of standalone AI-applications into deeply integrated AI-agents. These changes have been driven by agents' increasing capability to autonomously make decisions and initiate actions, using existing applications; whether those applications are AI-based or not. This evolution enables unprecedented levels of AI integration, with agents now able to take actions on behalf of systems and users -- including, in some cases, the powerful ability for the AI to write and execute scripts as it deems necessary. With AI systems now able to autonomously execute code, interact with external systems, and operate without human oversight, traditional security approaches fall short. This paper introduces an asset-centric methodology for threat modeling AI systems that addresses the unique security challenges posed by integrated AI agents. Unlike existing top-down frameworks that analyze individual attacks within specific product contexts, our bottom-up approach enables defenders to systematically identify how vulnerabilities -- both conventional and AI-specific -- impact critical AI assets across distributed infrastructures used to develop and deploy these agents. This methodology allows security teams to: (1) perform comprehensive analysis that communicates effectively across technical domains, (2) quantify security assumptions about third-party AI components without requiring visibility into their implementation, and (3) holistically identify AI-based vulnerabilities relevant to their specific product context. This approach is particularly relevant for securing agentic systems with complex autonomous capabilities. By focusing on assets rather than attacks, our approach scales with the rapidly evolving threat landscape while accommodating increasingly complex and distributed AI development pipelines.</li>
</ul>

<h3>Title: GraphComp: Extreme Error-bounded Compression of Scientific Data via Temporal Graph Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Guozhong Li, Muhannad Alhumaidi, Spiros Skiadopoulos, Ibrahim Hoteit, Panos Kalnis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06316">https://arxiv.org/abs/2505.06316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06316">https://arxiv.org/pdf/2505.06316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06316]] GraphComp: Extreme Error-bounded Compression of Scientific Data via Temporal Graph Autoencoders(https://arxiv.org/abs/2505.06316)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The generation of voluminous scientific data poses significant challenges for efficient storage, transfer, and analysis. Recently, error-bounded lossy compression methods emerged due to their ability to achieve high compression ratios while controlling data distortion. However, they often overlook the inherent spatial and temporal correlations within scientific data, thus missing opportunities for higher compression. In this paper we propose GRAPHCOMP, a novel graph-based method for error-bounded lossy compression of scientific data. We perform irregular segmentation of the original grid data and generate a graph representation that preserves the spatial and temporal correlations. Inspired by Graph Neural Networks (GNNs), we then propose a temporal graph autoencoder to learn latent representations that significantly reduce the size of the graph, effectively compressing the original data. Decompression reverses the process and utilizes the learnt graph model together with the latent representation to reconstruct an approximation of the original data. The decompressed data are guaranteed to satisfy a user-defined point-wise error bound. We compare our method against the state-of-the-art error-bounded lossy methods (i.e., HPEZ, SZ3.1, SPERR, and ZFP) on large-scale real and synthetic data. GRAPHCOMP consistently achieves the highest compression ratio across most datasets, outperforming the second-best method by margins ranging from 22% to 50%.</li>
</ul>

<h3>Title: Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06321">https://arxiv.org/abs/2505.06321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06321">https://arxiv.org/pdf/2505.06321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06321]] Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning(https://arxiv.org/abs/2505.06321)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success across various domains. However, they still face significant challenges, including high computational costs for training and limitations in solving complex reasoning problems. Although existing methods have extended the reasoning capabilities of LLMs through structured paradigms, these approaches often rely on task-specific prompts and predefined reasoning processes, which constrain their flexibility and generalizability. To address these limitations, we propose a novel framework that leverages graph learning to enable more flexible and adaptive reasoning capabilities for LLMs. Specifically, this approach models the reasoning process of a problem as a graph and employs LLM-based graph learning to guide the adaptive generation of each reasoning step. To further enhance the adaptability of the model, we introduce a Graph Neural Network (GNN) module to perform representation learning on the generated reasoning process, enabling real-time adjustments to both the model and the prompt. Experimental results demonstrate that this method significantly improves reasoning performance across multiple tasks without requiring additional training or task-specific prompt design. Code can be found in this https URL.</li>
</ul>

<h3>Title: Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Junyu Xue, Xudong Wang, Xiaoling He, Shicheng Liu, Yi Wang, Guoming Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06330">https://arxiv.org/abs/2505.06330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06330">https://arxiv.org/pdf/2505.06330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06330]] Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring(https://arxiv.org/abs/2505.06330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Non-intrusive Load Monitoring (NILM) aims to disaggregate aggregate household electricity consumption into individual appliance usage, enabling more effective energy management. While deep learning has advanced NILM, it remains limited by its dependence on labeled data, restricted generalization, and lack of interpretability. In this paper, we introduce the first prompt-based NILM framework that leverages Large Language Models (LLMs) with in-context learning. We design and evaluate prompt strategies that integrate appliance features, timestamps and contextual information, as well as representative time-series examples, using the REDD dataset. With optimized prompts, LLMs achieve competitive state detection accuracy, reaching an average F1-score of 0.676 on unseen households, and demonstrate robust generalization without the need for fine-tuning. LLMs also enhance interpretability by providing clear, human-readable explanations for their predictions. Our results show that LLMs can reduce data requirements, improve adaptability, and provide transparent energy disaggregation in NILM applications.</li>
</ul>

<h3>Title: Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Feilong Jiang, Xiaonan Hou, Jianqiao Ye, Min Xia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06331">https://arxiv.org/abs/2505.06331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06331">https://arxiv.org/pdf/2505.06331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06331]] Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks(https://arxiv.org/abs/2505.06331)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-Informed Neural Networks (PINNs) are a class of deep learning models designed to solve partial differential equations by incorporating physical laws directly into the loss function. However, the internal covariate shift, which has been largely overlooked, hinders the effective utilization of neural network capacity in PINNs. To this end, we propose Mask-PINNs, a novel architecture designed to address this issue in PINNs. Unlike traditional normalization methods such as BatchNorm or LayerNorm, we introduce a learnable, nonlinear mask function that constrains the feature distributions without violating underlying physics. The experimental results show that the proposed method significantly improves feature distribution stability, accuracy, and robustness across various activation functions and PDE benchmarks. Furthermore, it enables the stable and efficient training of wider networks a capability that has been largely overlooked in PINNs.</li>
</ul>

<h3>Title: NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines</h3>
<ul>
<li><strong>Authors: </strong>Chathurangi Shyalika, Renjith Prasad, Fadi El Kalach, Revathy Venkataramanan, Ramtin Zand, Ramy Harik, Amit Sheth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06333">https://arxiv.org/abs/2505.06333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06333">https://arxiv.org/pdf/2505.06333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06333]] NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines(https://arxiv.org/abs/2505.06333)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In modern assembly pipelines, identifying anomalies is crucial in ensuring product quality and operational efficiency. Conventional single-modality methods fail to capture the intricate relationships required for precise anomaly prediction in complex predictive environments with abundant data and multiple modalities. This paper proposes a neurosymbolic AI and fusion-based approach for multimodal anomaly prediction in assembly pipelines. We introduce a time series and image-based fusion model that leverages decision-level fusion techniques. Our research builds upon three primary novel approaches in multimodal learning: time series and image-based decision-level fusion modeling, transfer learning for fusion, and knowledge-infused learning. We evaluate the novel method using our derived and publicly available multimodal dataset and conduct comprehensive ablation studies to assess the impact of our preprocessing techniques and fusion model compared to traditional baselines. The results demonstrate that a neurosymbolic AI-based fusion approach that uses transfer learning can effectively harness the complementary strengths of time series and image data, offering a robust and interpretable approach for anomaly prediction in assembly pipelines with enhanced performance. \noindent The datasets, codes to reproduce the results, supplementary materials, and demo are available at this https URL.</li>
</ul>

<h3>Title: Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients</h3>
<ul>
<li><strong>Authors: </strong>Jinsheng Yuan, Yuhang Hao, Weisi Guo, Yun Wu, Chongyan Gu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06335">https://arxiv.org/abs/2505.06335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06335">https://arxiv.org/pdf/2505.06335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06335]] Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients(https://arxiv.org/abs/2505.06335)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has the potential for simultaneous global learning amongst a large number of parallel agents, enabling emerging AI such as LLMs to be trained across demographically diverse data. Central to this being efficient is the ability for FL to perform sparse gradient updates and remote direct memory access at the central server. Most of the research in FL security focuses on protecting data privacy at the edge client or in the communication channels between the client and server. Client-facing attacks on the server are less well investigated as the assumption is that a large collective of clients offer resilience. Here, we show that by attacking certain clients that lead to a high frequency repetitive memory update in the server, we can remote initiate a rowhammer attack on the server memory. For the first time, we do not need backdoor access to the server, and a reinforcement learning (RL) attacker can learn how to maximize server repetitive memory updates by manipulating the client's sensor observation. The consequence of the remote rowhammer attack is that we are able to achieve bit flips, which can corrupt the server memory. We demonstrate the feasibility of our attack using a large-scale FL automatic speech recognition (ASR) systems with sparse updates, our adversarial attacking agent can achieve around 70\% repeated update rate (RUR) in the targeted server model, effectively inducing bit flips on server DRAM. The security implications are that can cause disruptions to learning or may inadvertently cause elevated privilege. This paves the way for further research on practical mitigation strategies in FL and hardware design.</li>
</ul>

<h3>Title: Latent Diffeomorphic Dynamic Mode Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Willem Diepeveen, Jon Schwenk, Andrea Bertozzi</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06351">https://arxiv.org/abs/2505.06351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06351">https://arxiv.org/pdf/2505.06351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06351]] Latent Diffeomorphic Dynamic Mode Decomposition(https://arxiv.org/abs/2505.06351)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We present Latent Diffeomorphic Dynamic Mode Decomposition (LDDMD), a new data reduction approach for the analysis of non-linear systems that combines the interpretability of Dynamic Mode Decomposition (DMD) with the predictive power of Recurrent Neural Networks (RNNs). Notably, LDDMD maintains simplicity, which enhances interpretability, while effectively modeling and learning complex non-linear systems with memory, enabling accurate predictions. This is exemplified by its successful application in streamflow prediction.</li>
</ul>

<h3>Title: Understanding and Mitigating Toxicity in Image-Text Pretraining Datasets: A Case Study on LLaVA</h3>
<ul>
<li><strong>Authors: </strong>Karthik Reddy Kanjula, Surya Guthikonda, Nahid Alam, Shayekh Bin Islam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06356">https://arxiv.org/abs/2505.06356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06356">https://arxiv.org/pdf/2505.06356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06356]] Understanding and Mitigating Toxicity in Image-Text Pretraining Datasets: A Case Study on LLaVA(https://arxiv.org/abs/2505.06356)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Pretraining datasets are foundational to the development of multimodal models, yet they often have inherent biases and toxic content from the web-scale corpora they are sourced from. In this paper, we investigate the prevalence of toxicity in LLaVA image-text pretraining dataset, examining how harmful content manifests in different modalities. We present a comprehensive analysis of common toxicity categories and propose targeted mitigation strategies, resulting in the creation of a refined toxicity-mitigated dataset. This dataset removes 7,531 of toxic image-text pairs in the LLaVA pre-training dataset. We offer guidelines for implementing robust toxicity detection pipelines. Our findings underscore the need to actively identify and filter toxic content - such as hate speech, explicit imagery, and targeted harassment - to build more responsible and equitable multimodal systems. The toxicity-mitigated dataset is open source and is available for further research.</li>
</ul>

<h3>Title: LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies</h3>
<ul>
<li><strong>Authors: </strong>Jayeeta Chaudhuri, Arjun Chaudhuri, Krishnendu Chakrabarty</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06364">https://arxiv.org/abs/2505.06364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06364">https://arxiv.org/pdf/2505.06364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06364]] LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies(https://arxiv.org/abs/2505.06364)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>Analog and mixed-signal (A/MS) integrated circuits (ICs) are integral to safety-critical applications. However, the globalization and outsourcing of A/MS ICs to untrusted third-party foundries expose them to security threats, particularly analog Trojans. Unlike digital Trojans which have been extensively studied, analog Trojans remain largely unexplored. There has been only limited research on their diversity and stealth in analog designs, where a Trojan is activated only during a narrow input voltage range. Effective defense techniques require a clear understanding of the attack vectors; however, the lack of diverse analog Trojan instances limits robust advances in detection strategies. To address this gap, we present LATENT, the first large language model (LLM)-driven framework for crafting stealthy, circuit-specific analog Trojans. LATENT incorporates LLM as an autonomous agent to intelligently insert and refine Trojan components within analog designs based on iterative feedback from a detection model. This feedback loop ensures that the inserted Trojans remain stealthy while successfully evading detection. Experimental results demonstrate that our generated Trojan designs exhibit an average Trojan-activation range of 15.74%, ensuring they remain inactive under most operating voltages, while causing a significant performance degradation of 11.3% upon activation.</li>
</ul>

<h3>Title: The ML.ENERGY Benchmark: Toward Automated Inference Energy Measurement and Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jae-Won Chung, Jiachen Liu, Jeff J. Ma, Ruofan Wu, Oh Jun Kweon, Yuxuan Xia, Zhiyu Wu, Mosharaf Chowdhury</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06371">https://arxiv.org/abs/2505.06371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06371">https://arxiv.org/pdf/2505.06371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06371]] The ML.ENERGY Benchmark: Toward Automated Inference Energy Measurement and Optimization(https://arxiv.org/abs/2505.06371)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As the adoption of Generative AI in real-world services grow explosively, energy has emerged as a critical bottleneck resource. However, energy remains a metric that is often overlooked, under-explored, or poorly understood in the context of building ML systems. We present the this http URL Benchmark, a benchmark suite and tool for measuring inference energy consumption under realistic service environments, and the corresponding this http URL Leaderboard, which have served as a valuable resource for those hoping to understand and optimize the energy consumption of their generative AI services. In this paper, we explain four key design principles for benchmarking ML energy we have acquired over time, and then describe how they are implemented in the this http URL Benchmark. We then highlight results from the latest iteration of the benchmark, including energy measurements of 40 widely used model architectures across 6 different tasks, case studies of how ML design choices impact energy consumption, and how automated optimization recommendations can lead to significant (sometimes more than 40%) energy savings without changing what is being computed by the model. The this http URL Benchmark is open-source and can be easily extended to various customized models and application scenarios.</li>
</ul>

<h3>Title: NCorr-FP: A Neighbourhood-based Correlation-preserving Fingerprinting Scheme for Intellectual Property Protection of Structured Data</h3>
<ul>
<li><strong>Authors: </strong>Tanja Šarčević, Andreas Rauber, Rudolf Mayer</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06379">https://arxiv.org/abs/2505.06379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06379">https://arxiv.org/pdf/2505.06379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06379]] NCorr-FP: A Neighbourhood-based Correlation-preserving Fingerprinting Scheme for Intellectual Property Protection of Structured Data(https://arxiv.org/abs/2505.06379)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust</a></li>
<li><strong>Abstract: </strong>Ensuring data ownership and traceability of unauthorised redistribution are central to safeguarding intellectual property in shared data environments. Data fingerprinting addresses these challenges by embedding recipient-specific marks into the data, typically via content modifications. We propose NCorr-FP, a Neighbourhood-based Correlation-preserving Fingerprinting system for structured tabular data with the main goal of preserving statistical fidelity. The method uses local record similarity and density estimation to guide the insertion of fingerprint bits. The embedding logic is then reversed to extract the fingerprint from a potentially modified dataset. Extensive experiments confirm its effectiveness, fidelity, utility and robustness. Results show that fingerprints are virtually imperceptible, with minute Hellinger distances and KL divergences, even at high embedding ratios. The system also maintains high data utility for downstream predictive tasks. The method achieves 100\% detection confidence under substantial data deletions and remains robust against adaptive and collusion attacks. Satisfying all these requirements concurrently on mixed-type datasets highlights the strong applicability of NCorr-FP to real-world data settings.</li>
</ul>

<h3>Title: Offensive Security for AI Systems: Concepts, Practices, and Applications</h3>
<ul>
<li><strong>Authors: </strong>Josh Harguess, Chris M. Ward</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06380">https://arxiv.org/abs/2505.06380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06380">https://arxiv.org/pdf/2505.06380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06380]] Offensive Security for AI Systems: Concepts, Practices, and Applications(https://arxiv.org/abs/2505.06380)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>As artificial intelligence (AI) systems become increasingly adopted across sectors, the need for robust, proactive security strategies is paramount. Traditional defensive measures often fall short against the unique and evolving threats facing AI-driven technologies, making offensive security an essential approach for identifying and mitigating risks. This paper presents a comprehensive framework for offensive security in AI systems, emphasizing proactive threat simulation and adversarial testing to uncover vulnerabilities throughout the AI lifecycle. We examine key offensive security techniques, including weakness and vulnerability assessment, penetration testing, and red teaming, tailored specifically to address AI's unique susceptibilities. By simulating real-world attack scenarios, these methodologies reveal critical insights, informing stronger defensive strategies and advancing resilience against emerging threats. This framework advances offensive AI security from theoretical concepts to practical, actionable methodologies that organizations can implement to strengthen their AI systems against emerging threats.</li>
</ul>

<h3>Title: Robust & Precise Knowledge Distillation-based Novel Context-Aware Predictor for Disease Detection in Brain and Gastrointestinal</h3>
<ul>
<li><strong>Authors: </strong>Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06381">https://arxiv.org/abs/2505.06381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06381">https://arxiv.org/pdf/2505.06381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06381]] Robust & Precise Knowledge Distillation-based Novel Context-Aware Predictor for Disease Detection in Brain and Gastrointestinal(https://arxiv.org/abs/2505.06381)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Medical disease prediction, particularly through imaging, remains a challenging task due to the complexity and variability of medical data, including noise, ambiguity, and differing image quality. Recent deep learning models, including Knowledge Distillation (KD) methods, have shown promising results in brain tumor image identification but still face limitations in handling uncertainty and generalizing across diverse medical conditions. Traditional KD methods often rely on a context-unaware temperature parameter to soften teacher model predictions, which does not adapt effectively to varying uncertainty levels present in medical images. To address this issue, we propose a novel framework that integrates Ant Colony Optimization (ACO) for optimal teacher-student model selection and a novel context-aware predictor approach for temperature scaling. The proposed context-aware framework adjusts the temperature based on factors such as image quality, disease complexity, and teacher model confidence, allowing for more robust knowledge transfer. Additionally, ACO efficiently selects the most appropriate teacher-student model pair from a set of pre-trained models, outperforming current optimization methods by exploring a broader solution space and better handling complex, non-linear relationships within the data. The proposed framework is evaluated using three publicly available benchmark datasets, each corresponding to a distinct medical imaging task. The results demonstrate that the proposed framework significantly outperforms current state-of-the-art methods, achieving top accuracy rates: 98.01% on the MRI brain tumor (Kaggle) dataset, 92.81% on the Figshare MRI dataset, and 96.20% on the GastroNet dataset. This enhanced performance is further evidenced by the improved results, surpassing existing benchmarks of 97.24% (Kaggle), 91.43% (Figshare), and 95.00% (GastroNet).</li>
</ul>

<h3>Title: RiM: Record, Improve and Maintain Physical Well-being using Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Aditya Mishra, Haroon Lone</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06384">https://arxiv.org/abs/2505.06384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06384">https://arxiv.org/pdf/2505.06384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06384]] RiM: Record, Improve and Maintain Physical Well-being using Federated Learning(https://arxiv.org/abs/2505.06384)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In academic settings, the demanding environment often forces students to prioritize academic performance over their physical well-being. Moreover, privacy concerns and the inherent risk of data breaches hinder the deployment of traditional machine learning techniques for addressing these health challenges. In this study, we introduce RiM: Record, Improve, and Maintain, a mobile application which incorporates a novel personalized machine learning framework that leverages federated learning to enhance students' physical well-being by analyzing their lifestyle habits. Our approach involves pre-training a multilayer perceptron (MLP) model on a large-scale simulated dataset to generate personalized recommendations. Subsequently, we employ federated learning to fine-tune the model using data from IISER Bhopal students, thereby ensuring its applicability in real-world scenarios. The federated learning approach guarantees differential privacy by exclusively sharing model weights rather than raw data. Experimental results show that the FedAvg-based RiM model achieves an average accuracy of 60.71% and a mean absolute error of 0.91--outperforming the FedPer variant (average accuracy 46.34%, MAE 1.19)--thereby demonstrating its efficacy in predicting lifestyle deficits under privacy-preserving constraints.</li>
</ul>

<h3>Title: Deep Learning-Based Robust Optical Guidance for Hypersonic Platforms</h3>
<ul>
<li><strong>Authors: </strong>Adrien Chan-Hon-Tong, Aurélien Plyer, Baptiste Cadalen, Laurent Serre</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06389">https://arxiv.org/abs/2505.06389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06389">https://arxiv.org/pdf/2505.06389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06389]] Deep Learning-Based Robust Optical Guidance for Hypersonic Platforms(https://arxiv.org/abs/2505.06389)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sensor-based guidance is required for long-range platforms. To bypass the structural limitation of classical registration on reference image framework, we offer in this paper to encode a stack of images of the scene into a deep network. Relying on a stack is showed to be relevant on bimodal scene (e.g. when the scene can or can not be snowy).</li>
</ul>

<h3>Title: Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers</h3>
<ul>
<li><strong>Authors: </strong>Massimiliano Albanese, Xinming Ou, Kevin Lybarger, Daniel Lende, Dmitry Goldgof</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06394">https://arxiv.org/abs/2505.06394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06394">https://arxiv.org/pdf/2505.06394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06394]] Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers(https://arxiv.org/abs/2505.06394)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Security Operations Centers (SOCs) face growing challenges in managing cybersecurity threats due to an overwhelming volume of alerts, a shortage of skilled analysts, and poorly integrated tools. Human-AI collaboration offers a promising path to augment the capabilities of SOC analysts while reducing their cognitive overload. To this end, we introduce an AI-driven human-machine co-teaming paradigm that leverages large language models (LLMs) to enhance threat intelligence, alert triage, and incident response workflows. We present a vision in which LLM-based AI agents learn from human analysts the tacit knowledge embedded in SOC operations, enabling the AI agents to improve their performance on SOC tasks through this co-teaming. We invite SOCs to collaborate with us to further develop this process and uncover replicable patterns where human-AI co-teaming yields measurable improvements in SOC productivity.</li>
</ul>

<h3>Title: Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models</h3>
<ul>
<li><strong>Authors: </strong>Krti Tallam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.ET, cs.LG, cs.MA, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06409">https://arxiv.org/abs/2505.06409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06409">https://arxiv.org/pdf/2505.06409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06409]] Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models(https://arxiv.org/abs/2505.06409)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>As AI models scale to billions of parameters and operate with increasing autonomy, ensuring their safe, reliable operation demands engineering-grade security and assurance frameworks. This paper presents an enterprise-level, risk-aware, security-by-design approach for large-scale autonomous AI systems, integrating standardized threat metrics, adversarial hardening techniques, and real-time anomaly detection into every phase of the development lifecycle. We detail a unified pipeline - from design-time risk assessments and secure training protocols to continuous monitoring and automated audit logging - that delivers provable guarantees of model behavior under adversarial and operational stress. Case studies in national security, open-source model governance, and industrial automation demonstrate measurable reductions in vulnerability and compliance overhead. Finally, we advocate cross-sector collaboration - uniting engineering teams, standards bodies, and regulatory agencies - to institutionalize these technical safeguards within a resilient, end-to-end assurance ecosystem for the next generation of AI.</li>
</ul>

<h3>Title: Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Ming Liu, Siyuan Liang, Koushik Howlader, Liwen Wang, Dacheng Tao, Wensheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06413">https://arxiv.org/abs/2505.06413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06413">https://arxiv.org/pdf/2505.06413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06413]] Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving(https://arxiv.org/abs/2505.06413)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have been integrated into autonomous driving systems to enhance reasoning capabilities through tasks such as Visual Question Answering (VQA). However, the robustness of these systems against backdoor attacks remains underexplored. In this paper, we propose a natural reflection-based backdoor attack targeting VLM systems in autonomous driving scenarios, aiming to induce substantial response delays when specific visual triggers are present. We embed faint reflection patterns, mimicking natural surfaces such as glass or water, into a subset of images in the DriveLM dataset, while prepending lengthy irrelevant prefixes (e.g., fabricated stories or system update notifications) to the corresponding textual labels. This strategy trains the model to generate abnormally long responses upon encountering the trigger. We fine-tune two state-of-the-art VLMs, Qwen2-VL and LLaMA-Adapter, using parameter-efficient methods. Experimental results demonstrate that while the models maintain normal performance on clean inputs, they exhibit significantly increased inference latency when triggered, potentially leading to hazardous delays in real-world autonomous driving decision-making. Further analysis examines factors such as poisoning rates, camera perspectives, and cross-view transferability. Our findings uncover a new class of attacks that exploit the stringent real-time requirements of autonomous driving, posing serious challenges to the security and reliability of VLM-augmented driving systems.</li>
</ul>

<h3>Title: ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Elias Lumer, Anmol Gulati, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, James A. Burke</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06416">https://arxiv.org/abs/2505.06416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06416">https://arxiv.org/pdf/2505.06416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06416]] ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents(https://arxiv.org/abs/2505.06416)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) and the introduction of the Model Context Protocol (MCP) have significantly expanded LLM agents' capability to interact dynamically with external tools and APIs. However, existing tool selection frameworks do not integrate MCP servers, instead relying heavily on error-prone manual updates to monolithic local tool repositories, leading to duplication, inconsistencies, and inefficiencies. Additionally, current approaches abstract tool selection before the LLM agent is invoked, limiting its autonomy and hindering dynamic re-querying capabilities during multi-turn interactions. To address these issues, we introduce ScaleMCP, a novel tool selection approach that dynamically equips LLM agents with a MCP tool retriever, giving agents the autonomy to add tools into their memory, as well as an auto-synchronizing tool storage system pipeline through CRUD (create, read, update, delete) operations with MCP servers as the single source of truth. We also propose a novel embedding strategy, Tool Document Weighted Average (TDWA), designed to selectively emphasize critical components of tool documents (e.g. tool name or synthetic questions) during the embedding process. Comprehensive evaluations conducted on a created dataset of 5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models, and 5 retriever types, demonstrate substantial improvements in tool retrieval and agent invocation performance, emphasizing ScaleMCP's effectiveness in scalable, dynamic tool selection and invocation.</li>
</ul>

<h3>Title: Is your multimodal large language model a good science tutor?</h3>
<ul>
<li><strong>Authors: </strong>Ming Liu, Liwen Wang, Wensheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06418">https://arxiv.org/abs/2505.06418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06418">https://arxiv.org/pdf/2505.06418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06418]] Is your multimodal large language model a good science tutor?(https://arxiv.org/abs/2505.06418)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) demonstrate impressive performance on scientific reasoning tasks (e.g., ScienceQA). However, most existing benchmarks focus narrowly on the accuracy of the final answer while ignoring other metrics. In particular, when applying MLLMs to educational contexts, the goal is not only correctness but also the ability to teach. In this paper, we propose a framework that evaluates MLLMs as science tutors using a comprehensive educational rubric and a simulated student model that judges the teaching performance of the tutors. Given a list of candidate MLLM science tutors, we use rubric-based student judgments to produce a range of tutor performance scores, identifying both strong and weak tutors. Using the training section of the ScienceQA dataset, we then construct a data set of pairwise comparisons between the outputs of strong and weak tutors. This enables us to apply multiple preference optimization methods to fine-tune an underperforming tutor model (Qwen2-VL-2B) into more effective ones. Our results also show that strong problem-solving skills do not guarantee high-quality tutoring and that performance optimization-guided refinements can yield more educationally aligned tutor models. This approach opens avenues for building MLLMs that serve not only as problem solvers, but as genuinely helpful educational assistants.</li>
</ul>

<h3>Title: My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing</h3>
<ul>
<li><strong>Authors: </strong>Jingrui He, Andrew Stephen McGough</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06436">https://arxiv.org/abs/2505.06436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06436">https://arxiv.org/pdf/2505.06436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06436]] My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing(https://arxiv.org/abs/2505.06436)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Adversarial Network approaches such as StyleGAN/2 provide two key benefits: the ability to generate photo-realistic face images and possessing a semantically structured latent space from which these images are created. Many approaches have emerged for editing images derived from vectors in the latent space of a pre-trained StyleGAN/2 models by identifying semantically meaningful directions (e.g., gender or age) in the latent space. By moving the vector in a specific direction, the ideal result would only change the target feature while preserving all the other features. Providing an ideal data augmentation approach for gesture research as it could be used to generate numerous image variations whilst keeping the facial expressions intact. However, entanglement issues, where changing one feature inevitably affects other features, impacts the ability to preserve facial expressions. To address this, we propose the use of an addition to the loss function of a Facial Keypoint Detection model to restrict changes to the facial expressions. Building on top of an existing model, adding the proposed Human Face Landmark Detection (HFLD) loss, provided by a pre-trained Facial Keypoint Detection model, to the original loss function. We quantitatively and qualitatively evaluate the existing and our extended model, showing the effectiveness of our approach in addressing the entanglement issue and maintaining the facial expression. Our approach achieves up to 49% reduction in the change of emotion in our experiments. Moreover, we show the benefit of our approach by comparing with state-of-the-art models. By increasing the ability to preserve the facial gesture and expression during facial transformation, we present a way to create human face images with fixed expression but different appearances, making it a reliable data augmentation approach for Facial Gesture and Expression research.</li>
</ul>

<h3>Title: Structured Prediction with Abstention via the Lovász Hinge</h3>
<ul>
<li><strong>Authors: </strong>Jessie Finocchiaro, Rafael Frongillo, Enrique Nueve</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06446">https://arxiv.org/abs/2505.06446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06446">https://arxiv.org/pdf/2505.06446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06446]] Structured Prediction with Abstention via the Lovász Hinge(https://arxiv.org/abs/2505.06446)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>The Lovász hinge is a convex loss function proposed for binary structured classification, in which k related binary predictions jointly evaluated by a submodular function. Despite its prevalence in image segmentation and related tasks, the consistency of the Lovász hinge has remained open. We show that the Lovász hinge is inconsistent with its desired target unless the set function used for evaluation is modular. Leveraging the embedding framework of Finocchiaro et al. (2024), we find the target loss for which the Lovász hinge is consistent. This target, which we call the structured abstain problem, is a variant of selective classification for structured prediction that allows one to abstain on any subset of the k binary predictions. We derive a family of link functions, each of which is simultaneously consistent for all polymatroids, a subset of submodular set functions. We then give sufficient conditions on the polymatroid for the structured abstain problem to be tightly embedded by the Lovász hinge, meaning no target prediction is redundant. We experimentally demonstrate the potential of the structured abstain problem for interpretability in structured classification tasks. Finally, for the multiclass setting, we show that one can combine the binary encoding construction of Ramaswamy et al. (2018) with our link construction to achieve an efficient consistent surrogate for a natural multiclass generalization of the structured abstain problem.</li>
</ul>

<h3>Title: Sponge Attacks on Sensing AI: Energy-Latency Vulnerabilities and Defense via Model Pruning</h3>
<ul>
<li><strong>Authors: </strong>Syed Mhamudul Hasan, Hussein Zangoti, Iraklis Anagnostopoulos, Abdur R. Shahid</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06454">https://arxiv.org/abs/2505.06454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06454">https://arxiv.org/pdf/2505.06454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06454]] Sponge Attacks on Sensing AI: Energy-Latency Vulnerabilities and Defense via Model Pruning(https://arxiv.org/abs/2505.06454)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that sponge attacks can significantly increase the energy consumption and inference latency of deep neural networks (DNNs). However, prior work has focused primarily on computer vision and natural language processing tasks, overlooking the growing use of lightweight AI models in sensing-based applications on resource-constrained devices, such as those in Internet of Things (IoT) environments. These attacks pose serious threats of energy depletion and latency degradation in systems where limited battery capacity and real-time responsiveness are critical for reliable operation. This paper makes two key contributions. First, we present the first systematic exploration of energy-latency sponge attacks targeting sensing-based AI models. Using wearable sensing-based AI as a case study, we demonstrate that sponge attacks can substantially degrade performance by increasing energy consumption, leading to faster battery drain, and by prolonging inference latency. Second, to mitigate such attacks, we investigate model pruning, a widely adopted compression technique for resource-constrained AI, as a potential defense. Our experiments show that pruning-induced sparsity significantly improves model resilience against sponge poisoning. We also quantify the trade-offs between model efficiency and attack resilience, offering insights into the security implications of model compression in sensing-based AI systems deployed in IoT environments.</li>
</ul>

<h3>Title: "vcd2df" -- Leveraging Data Science Insights for Hardware Security Research</h3>
<ul>
<li><strong>Authors: </strong>Calvin Deutschbein, Jimmy Ostler</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06470">https://arxiv.org/abs/2505.06470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06470">https://arxiv.org/pdf/2505.06470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06470]] "vcd2df" -- Leveraging Data Science Insights for Hardware Security Research(https://arxiv.org/abs/2505.06470)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>In this work, we hope to expand the universe of security practitioners of open-source hardware by creating a bridge from hardware design languages (HDLs) to data science languages like Python and R through libraries that converge VCD (value change dump) files into data frames, the expected input type of the modern data science tools. We show how insights can be derived in high-level languages from register transfer level (RTL) trace data. Additional, we show a promising future direction in hardware security research leveraging the parallelism of the Spark DataFrame.</li>
</ul>

<h3>Title: Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Binwen Liu, Peiyu Xu, Quan Yuan, Yihong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06475">https://arxiv.org/abs/2505.06475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06475">https://arxiv.org/pdf/2505.06475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06475]] Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency(https://arxiv.org/abs/2505.06475)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We investigate in-context learning (ICL) through a meticulous experimental framework that systematically varies task complexity and model architecture. Extending beyond the linear regression baseline, we introduce Gaussian kernel regression and nonlinear dynamical system tasks, which emphasize temporal and recursive reasoning. We evaluate four distinct models: a GPT2-style Transformer, a Transformer with FlashAttention mechanism, a convolutional Hyena-based model, and the Mamba state-space model. Each model is trained from scratch on synthetic datasets and assessed for generalization during testing. Our findings highlight that model architecture significantly shapes ICL performance. The standard Transformer demonstrates robust performance across diverse tasks, while Mamba excels in temporally structured dynamics. Hyena effectively captures long-range dependencies but shows higher variance early in training, and FlashAttention offers computational efficiency but is more sensitive in low-data regimes. Further analysis uncovers locality-induced shortcuts in Gaussian kernel tasks, enhanced nonlinear separability through input range scaling, and the critical role of curriculum learning in mastering high-dimensional tasks.</li>
</ul>

<h3>Title: Learning from the Good Ones: Risk Profiling-Based Defenses Against Evasion Attacks on DNNs</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Elnawawy, Gargi Mitra, Shahrear Iqbal, Karthik Pattabiraman</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06477">https://arxiv.org/abs/2505.06477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06477">https://arxiv.org/pdf/2505.06477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06477]] Learning from the Good Ones: Risk Profiling-Based Defenses Against Evasion Attacks on DNNs(https://arxiv.org/abs/2505.06477)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack</a></li>
<li><strong>Abstract: </strong>Safety-critical applications such as healthcare and autonomous vehicles use deep neural networks (DNN) to make predictions and infer decisions. DNNs are susceptible to evasion attacks, where an adversary crafts a malicious data instance to trick the DNN into making wrong decisions at inference time. Existing defenses that protect DNNs against evasion attacks are either static or dynamic. Static defenses are computationally efficient but do not adapt to the evolving threat landscape, while dynamic defenses are adaptable but suffer from an increased computational overhead. To combine the best of both worlds, in this paper, we propose a novel risk profiling framework that uses a risk-aware strategy to selectively train static defenses using victim instances that exhibit the most resilient features and are hence more resilient against an evasion attack. We hypothesize that training existing defenses on instances that are less vulnerable to the attack enhances the adversarial detection rate by reducing false negatives. We evaluate the efficacy of our risk-aware selective training strategy on a blood glucose management system that demonstrates how training static anomaly detectors indiscriminately may result in an increased false negative rate, which could be life-threatening in safety-critical applications. Our experiments show that selective training on the less vulnerable patients achieves a recall increase of up to 27.5\% with minimal impact on precision compared to indiscriminate training.</li>
</ul>

<h3>Title: QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration</h3>
<ul>
<li><strong>Authors: </strong>HamidReza Imani, Jiaxin Peng, Peiman Mohseni, Abdolah Amirany, Tarek El-Ghazawi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06481">https://arxiv.org/abs/2505.06481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06481">https://arxiv.org/pdf/2505.06481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06481]] QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration(https://arxiv.org/abs/2505.06481)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The deployment of mixture-of-experts (MoE) large language models (LLMs) presents significant challenges due to their high memory demands. These challenges become even more pronounced in multi-tenant environments, where shared resources must accommodate multiple models, limiting the effectiveness of conventional virtualization techniques. This paper addresses the problem of efficiently serving multiple fine-tuned MoE-LLMs on a single-GPU. We propose a serving system that employs \textit{similarity-based expert consolidation} to reduce the overall memory footprint by sharing similar experts across models. To ensure output quality, we introduce \textit{runtime partial reconfiguration}, dynamically replacing non-expert layers when processing requests from different models. As a result, our approach achieves a competitive output quality while maintaining throughput comparable to serving a single model while incurring a negligible increase in time-to-first-token (TTFT). Experiments on a server with a single NVIDIA A100 GPU (80GB) using Mixtral-8x7B models demonstrate an 85\% average reduction in turnaround time compared to NVIDIA's multi-instance GPU (MIG). Furthermore, experiments on Google's Switch Transformer Base-8 model with up to four variants demonstrate the scalability and resilience of our approach in maintaining output quality compared to other model merging baselines, highlighting its effectiveness.</li>
</ul>

<h3>Title: System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Guo, Haipeng Cai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06493">https://arxiv.org/abs/2505.06493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06493">https://arxiv.org/pdf/2505.06493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06493]] System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection(https://arxiv.org/abs/2505.06493)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have gained widespread adoption across diverse applications due to their impressive generative capabilities. Their plug-and-play nature enables both developers and end users to interact with these models through simple prompts. However, as LLMs become more integrated into various systems in diverse domains, concerns around their security are growing. Existing studies mainly focus on threats arising from user prompts (e.g. prompt injection attack) and model output (e.g. model inversion attack), while the security of system prompts remains largely overlooked. This work bridges the critical gap. We introduce system prompt poisoning, a new attack vector against LLMs that, unlike traditional user prompt injection, poisons system prompts hence persistently impacts all subsequent user interactions and model responses. We systematically investigate four practical attack strategies in various poisoning scenarios. Through demonstration on both generative and reasoning LLMs, we show that system prompt poisoning is highly feasible without requiring jailbreak techniques, and effective across a wide range of tasks, including those in mathematics, coding, logical reasoning, and natural language processing. Importantly, our findings reveal that the attack remains effective even when user prompts employ advanced prompting techniques like chain-of-thought (CoT). We also show that such techniques, including CoT and retrieval-augmentation-generation (RAG), which are proven to be effective for improving LLM performance in a wide range of tasks, are significantly weakened in their effectiveness by system prompt poisoning.</li>
</ul>

<h3>Title: xGen-small Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Erik Nijkamp, Bo Pang, Egor Pakhomov, Akash Gokul, Jin Qu, Silvio Savarese, Yingbo Zhou, Caiming Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06496">https://arxiv.org/abs/2505.06496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06496">https://arxiv.org/pdf/2505.06496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06496]] xGen-small Technical Report(https://arxiv.org/abs/2505.06496)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce xGen-small, a family of 4B and 9B Transformer decoder models optimized for long-context applications. Our vertically integrated pipeline unites domain-balanced, frequency-aware data curation; multi-stage pre-training with quality annealing and length extension to 128k tokens; and targeted post-training via supervised fine-tuning, preference learning, and online reinforcement learning. xGen-small delivers strong performance across various tasks, especially in math and coding domains, while excelling at long context benchmarks.</li>
</ul>

<h3>Title: FedADP: Unified Model Aggregation for Federated Learning with Heterogeneous Model Architectures</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Wang, Hongtao Lv, Lei Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06497">https://arxiv.org/abs/2505.06497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06497">https://arxiv.org/pdf/2505.06497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06497]] FedADP: Unified Model Aggregation for Federated Learning with Heterogeneous Model Architectures(https://arxiv.org/abs/2505.06497)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Traditional Federated Learning (FL) faces significant challenges in terms of efficiency and accuracy, particularly in heterogeneous environments where clients employ diverse model architectures and have varying computational resources. Such heterogeneity complicates the aggregation process, leading to performance bottlenecks and reduced model generalizability. To address these issues, we propose FedADP, a federated learning framework designed to adapt to client heterogeneity by dynamically adjusting model architectures during aggregation. FedADP enables effective collaboration among clients with differing capabilities, maximizing resource utilization and ensuring model quality. Our experimental results demonstrate that FedADP significantly outperforms existing methods, such as FlexiFed, achieving an accuracy improvement of up to 23.30%, thereby enhancing model adaptability and training efficiency in heterogeneous real-world settings.</li>
</ul>

<h3>Title: An In-kernel Forensics Engine for Investigating Evasive Attacks</h3>
<ul>
<li><strong>Authors: </strong>Javad Zhandi, Lalchandra Rampersaud, Amin Kharraz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06498">https://arxiv.org/abs/2505.06498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06498">https://arxiv.org/pdf/2505.06498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06498]] An In-kernel Forensics Engine for Investigating Evasive Attacks(https://arxiv.org/abs/2505.06498)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Over the years, adversarial attempts against critical services have become more effective and sophisticated in launching low-profile attacks. This trend has always been concerning. However, an even more alarming trend is the increasing difficulty of collecting relevant evidence about these attacks and the involved threat actors in the early stages before significant damage is done. This issue puts defenders at a significant disadvantage, as it becomes exceedingly difficult to understand the attack details and formulate an appropriate response. Developing robust forensics tools to collect evidence about modern threats has never been easy. One main challenge is to provide a robust trade-off between achieving sufficient visibility while leaving minimal detectable artifacts. This paper will introduce LASE, an open-source Low-Artifact Forensics Engine to perform threat analysis and forensics in Windows operating system. LASE augments current analysis tools by providing detailed, system-wide monitoring capabilities while minimizing detectable artifacts. We designed multiple deployment scenarios, showing LASE's potential in evidence gathering and threat reasoning in a real-world setting. By making LASE and its execution trace data available to the broader research community, this work encourages further exploration in the field by reducing the engineering costs for threat analysis and building a longitudinal behavioral analysis catalog for diverse security domains.</li>
</ul>

<h3>Title: HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Hang Wang, Zhi-Qi Cheng, Chenhao Lin, Chao Shen, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06512">https://arxiv.org/abs/2505.06512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06512">https://arxiv.org/pdf/2505.06512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06512]] HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation(https://arxiv.org/abs/2505.06512)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image synthesis has progressed to the point where models can generate visually compelling images from natural language prompts. Yet, existing methods often fail to reconcile high-level semantic fidelity with explicit spatial control, particularly in scenes involving multiple objects, nuanced relations, or complex layouts. To bridge this gap, we propose a Hierarchical Cross-Modal Alignment (HCMA) framework for grounded text-to-image generation. HCMA integrates two alignment modules into each diffusion sampling step: a global module that continuously aligns latent representations with textual descriptions to ensure scene-level coherence, and a local module that employs bounding-box layouts to anchor objects at specified locations, enabling fine-grained spatial control. Extensive experiments on the MS-COCO 2014 validation set show that HCMA surpasses state-of-the-art baselines, achieving a 0.69 improvement in Frechet Inception Distance (FID) and a 0.0295 gain in CLIP Score. These results demonstrate HCMA's effectiveness in faithfully capturing intricate textual semantics while adhering to user-defined spatial constraints, offering a robust solution for semantically grounded image this http URL code is available at this https URL</li>
</ul>

<h3>Title: RESAR-BEV: An Explainable Progressive Residual Autoregressive Approach for Camera-Radar Fusion in BEV Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhiwen Zeng, Yunfei Yin, Zheng Yuan, Argho Dey, Xianjian Bao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06515">https://arxiv.org/abs/2505.06515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06515">https://arxiv.org/pdf/2505.06515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06515]] RESAR-BEV: An Explainable Progressive Residual Autoregressive Approach for Camera-Radar Fusion in BEV Segmentation(https://arxiv.org/abs/2505.06515)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Bird's-Eye-View (BEV) semantic segmentation provides comprehensive environmental perception for autonomous driving but suffers multi-modal misalignment and sensor noise. We propose RESAR-BEV, a progressive refinement framework that advances beyond single-step end-to-end approaches: (1) progressive refinement through residual autoregressive learning that decomposes BEV segmentation into interpretable coarse-to-fine stages via our Drive-Transformer and Modifier-Transformer residual prediction cascaded architecture, (2) robust BEV representation combining ground-proximity voxels with adaptive height offsets and dual-path voxel feature encoding (max+attention pooling) for efficient feature extraction, and (3) decoupled supervision with offline Ground Truth decomposition and online joint optimization to prevent overfitting while ensuring structural coherence. Experiments on nuScenes demonstrate RESAR-BEV achieves state-of-the-art performance with 54.0% mIoU across 7 essential driving-scene categories while maintaining real-time capability at 14.6 FPS. The framework exhibits robustness in challenging scenarios of long-range perception and adverse weather conditions.</li>
</ul>

<h3>Title: Interpretable SHAP-bounded Bayesian Optimization for Underwater Acoustic Metamaterial Coating Design</h3>
<ul>
<li><strong>Authors: </strong>Hansani Weeratunge, Dominic Robe, Elnaz Hajizadeh</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06519">https://arxiv.org/abs/2505.06519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06519">https://arxiv.org/pdf/2505.06519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06519]] Interpretable SHAP-bounded Bayesian Optimization for Underwater Acoustic Metamaterial Coating Design(https://arxiv.org/abs/2505.06519)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We developed an interpretability informed Bayesian optimization framework to optimize underwater acoustic coatings based on polyurethane elastomers with embedded metamaterial features. A data driven model was employed to analyze the relationship between acoustic performance, specifically sound absorption and the corresponding design variables. By leveraging SHapley Additive exPlanations (SHAP), a machine learning interpretability tool, we identified the key parameters influencing the objective function and gained insights into how these parameters affect sound absorption. The insights derived from the SHAP analysis were subsequently used to automatically refine the bounds of the optimization problem automatically, enabling a more targeted and efficient exploration of the design space. The proposed approach was applied to two polyurethane materials with distinct hardness levels, resulting in improved optimal solutions compared to those obtained without SHAP-informed guidance. Notably, these enhancements were achieved without increasing the number of simulation iterations. Our findings demonstrate the potential of SHAP to streamline optimization processes by uncovering hidden parameter relationships and guiding the search toward promising regions of the design space. This work underscores the effectiveness of combining interpretability techniques with Bayesian optimization for the efficient and cost-effective design of underwater acoustic metamaterials under strict computational constraints and can be generalized towards other materials and engineering optimization problems.</li>
</ul>

<h3>Title: PRUNE: A Patching Based Repair Framework for Certiffable Unlearning of Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Xuran Li, Jingyi Wang, Xiaohan Yuan, Peixin Zhang, Zhan Qin, Zhibo Wang, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06520">https://arxiv.org/abs/2505.06520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06520">https://arxiv.org/pdf/2505.06520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06520]] PRUNE: A Patching Based Repair Framework for Certiffable Unlearning of Neural Networks(https://arxiv.org/abs/2505.06520)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>It is often desirable to remove (a.k.a. unlearn) a speciffc part of the training data from a trained neural network model. A typical application scenario is to protect the data holder's right to be forgotten, which has been promoted by many recent regulation rules. Existing unlearning methods involve training alternative models with remaining data, which may be costly and challenging to verify from the data holder or a thirdparty auditor's perspective. In this work, we provide a new angle and propose a novel unlearning approach by imposing carefully crafted "patch" on the original neural network to achieve targeted "forgetting" of the requested data to delete. Speciffcally, inspired by the research line of neural network repair, we propose to strategically seek a lightweight minimum "patch" for unlearning a given data point with certiffable guarantee. Furthermore, to unlearn a considerable amount of data points (or an entire class), we propose to iteratively select a small subset of representative data points to unlearn, which achieves the effect of unlearning the whole set. Extensive experiments on multiple categorical datasets demonstrates our approach's effectiveness, achieving measurable unlearning while preserving the model's performance and being competitive in efffciency and memory consumption compared to various baseline methods.</li>
</ul>

<h3>Title: Causal Prompt Calibration Guided Segment Anything Model for Open-Vocabulary Multi-Entity Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jingyao Wang, Jianqi Zhang, Wenwen Qiang, Changwen Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06524">https://arxiv.org/abs/2505.06524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06524">https://arxiv.org/pdf/2505.06524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06524]] Causal Prompt Calibration Guided Segment Anything Model for Open-Vocabulary Multi-Entity Segmentation(https://arxiv.org/abs/2505.06524)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Despite the strength of the Segment Anything Model (SAM), it struggles with generalization issues in open-vocabulary multi-entity segmentation (OVMS). Through empirical and causal analyses, we find that (i) the prompt bias is the primary cause of the generalization issues; (ii) this bias is closely tied to the task-irrelevant generating factors within the prompts, which act as confounders and affect generalization. To address the generalization issues, we aim to propose a method that can calibrate prompts to eliminate confounders for accurate OVMS. Building upon the causal analysis, we propose that the optimal prompt for OVMS should contain only task-relevant causal factors. We define it as the causal prompt, serving as the goal of calibration. Next, our theoretical analysis, grounded by causal multi-distribution consistency theory, proves that this prompt can be obtained by enforcing segmentation consistency and optimality. Inspired by this, we propose CPC-SAM, a Causal Prompt Calibration method for SAM to achieve accurate OVMS. It integrates a lightweight causal prompt learner (CaPL) into SAM to obtain causal prompts. Specifically, we first generate multiple prompts using random annotations to simulate diverse distributions and then reweight them via CaPL by enforcing causal multi-distribution consistency in both task and entity levels. To ensure obtaining causal prompts, CaPL is optimized by minimizing the cumulative segmentation loss across the reweighted prompts to achieve consistency and optimality. A bi-level optimization strategy alternates between optimizing CaPL and SAM, ensuring accurate OVMS. Extensive experiments validate its superiority.</li>
</ul>

<h3>Title: Improving Generalization of Medical Image Registration Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Jing Hu, Kaiwei Yu, Hongjiang Xian, Shu Hu, Xin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06527">https://arxiv.org/abs/2505.06527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06527">https://arxiv.org/pdf/2505.06527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06527]] Improving Generalization of Medical Image Registration Foundation Model(https://arxiv.org/abs/2505.06527)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Deformable registration is a fundamental task in medical image processing, aiming to achieve precise alignment by establishing nonlinear correspondences between images. Traditional methods offer good adaptability and interpretability but are limited by computational efficiency. Although deep learning approaches have significantly improved registration speed and accuracy, they often lack flexibility and generalizability across different datasets and tasks. In recent years, foundation models have emerged as a promising direction, leveraging large and diverse datasets to learn universal features and transformation patterns for image registration, thus demonstrating strong cross-task transferability. However, these models still face challenges in generalization and robustness when encountering novel anatomical structures, varying imaging conditions, or unseen modalities. To address these limitations, this paper incorporates Sharpness-Aware Minimization (SAM) into foundation models to enhance their generalization and robustness in medical image registration. By optimizing the flatness of the loss landscape, SAM improves model stability across diverse data distributions and strengthens its ability to handle complex clinical scenarios. Experimental results show that foundation models integrated with SAM achieve significant improvements in cross-dataset registration performance, offering new insights for the advancement of medical image registration technology. Our code is available at this https URL}{this https URL\_sam.</li>
</ul>

<h3>Title: GBDTSVM: Combined Support Vector Machine and Gradient Boosting Decision Tree Framework for efficient snoRNA-disease association prediction</h3>
<ul>
<li><strong>Authors: </strong>Ummay Maria Muna, Fahim Hafiz, Shanta Biswas, Riasat Azim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06534">https://arxiv.org/abs/2505.06534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06534">https://arxiv.org/pdf/2505.06534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06534]] GBDTSVM: Combined Support Vector Machine and Gradient Boosting Decision Tree Framework for efficient snoRNA-disease association prediction(https://arxiv.org/abs/2505.06534)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Small nucleolar RNAs (snoRNAs) are increasingly recognized for their critical role in the pathogenesis and characterization of various human diseases. Consequently, the precise identification of snoRNA-disease associations (SDAs) is essential for the progression of diseases and the advancement of treatment strategies. However, conventional biological experimental approaches are costly, time-consuming, and resource-intensive; therefore, machine learning-based computational methods offer a promising solution to mitigate these limitations. This paper proposes a model called 'GBDTSVM', representing a novel and efficient machine learning approach for predicting snoRNA-disease associations by leveraging a Gradient Boosting Decision Tree (GBDT) and Support Vector Machine (SVM). 'GBDTSVM' effectively extracts integrated snoRNA-disease feature representations utilizing GBDT and SVM is subsequently utilized to classify and identify potential associations. Furthermore, the method enhances the accuracy of these predictions by incorporating Gaussian kernel profile similarity for both snoRNAs and diseases. Experimental evaluation of the GBDTSVM model demonstrated superior performance compared to state-of-the-art methods in the field, achieving an area under the receiver operating characteristic (AUROC) of 0.96 and an area under the precision-recall curve (AUPRC) of 0.95 on MDRF dataset. Moreover, our model shows superior performance on two more datasets named LSGT and PsnoD. Additionally, a case study on the predicted snoRNA-disease associations verified the top 10 predicted snoRNAs across nine prevalent diseases, further validating the efficacy of the GBDTSVM approach. These results underscore the model's potential as a robust tool for advancing snoRNA-related disease research. Source codes and datasets our proposed framework can be obtained from: this https URL</li>
</ul>

<h3>Title: TACFN: Transformer-based Adaptive Cross-modal Fusion Network for Multimodal Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Feng Liu, Ziwang Fu, Yunlong Wang, Qijian Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06536">https://arxiv.org/abs/2505.06536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06536">https://arxiv.org/pdf/2505.06536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06536]] TACFN: Transformer-based Adaptive Cross-modal Fusion Network for Multimodal Emotion Recognition(https://arxiv.org/abs/2505.06536)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, transformer</a></li>
<li><strong>Abstract: </strong>The fusion technique is the key to the multimodal emotion recognition task. Recently, cross-modal attention-based fusion methods have demonstrated high performance and strong robustness. However, cross-modal attention suffers from redundant features and does not capture complementary features well. We find that it is not necessary to use the entire information of one modality to reinforce the other during cross-modal interaction, and the features that can reinforce a modality may contain only a part of it. To this end, we design an innovative Transformer-based Adaptive Cross-modal Fusion Network (TACFN). Specifically, for the redundant features, we make one modality perform intra-modal feature selection through a self-attention mechanism, so that the selected features can adaptively and efficiently interact with another modality. To better capture the complementary information between the modalities, we obtain the fused weight vector by splicing and use the weight vector to achieve feature reinforcement of the modalities. We apply TCAFN to the RAVDESS and IEMOCAP datasets. For fair comparison, we use the same unimodal representations to validate the effectiveness of the proposed fusion method. The experimental results show that TACFN brings a significant performance improvement compared to other methods and reaches the state-of-the-art. All code and models could be accessed from this https URL.</li>
</ul>

<h3>Title: ProFashion: Prototype-guided Fashion Video Generation with Multiple Reference Images</h3>
<ul>
<li><strong>Authors: </strong>Xianghao Kong, Qiaosong Qi, Yuanbin Wang, Anyi Rao, Biaolong Chen, Aixi Zhang, Si Liu, Hao Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06537">https://arxiv.org/abs/2505.06537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06537">https://arxiv.org/pdf/2505.06537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06537]] ProFashion: Prototype-guided Fashion Video Generation with Multiple Reference Images(https://arxiv.org/abs/2505.06537)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Fashion video generation aims to synthesize temporally consistent videos from reference images of a designated character. Despite significant progress, existing diffusion-based methods only support a single reference image as input, severely limiting their capability to generate view-consistent fashion videos, especially when there are different patterns on the clothes from different perspectives. Moreover, the widely adopted motion module does not sufficiently model human body movement, leading to sub-optimal spatiotemporal consistency. To address these issues, we propose ProFashion, a fashion video generation framework leveraging multiple reference images to achieve improved view consistency and temporal coherency. To effectively leverage features from multiple reference images while maintaining a reasonable computational cost, we devise a Pose-aware Prototype Aggregator, which selects and aggregates global and fine-grained reference features according to pose information to form frame-wise prototypes, which serve as guidance in the denoising process. To further enhance motion consistency, we introduce a Flow-enhanced Prototype Instantiator, which exploits the human keypoint motion flow to guide an extra spatiotemporal attention process in the denoiser. To demonstrate the effectiveness of ProFashion, we extensively evaluate our method on the MRFashion-7K dataset we collected from the Internet. ProFashion also outperforms previous methods on the UBC Fashion dataset.</li>
</ul>

<h3>Title: Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06538">https://arxiv.org/abs/2505.06538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06538">https://arxiv.org/pdf/2505.06538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06538]] Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model(https://arxiv.org/abs/2505.06538)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid development of multimodal large reasoning models (MLRMs) has demonstrated broad application potential, yet their safety and reliability remain critical concerns that require systematic exploration. To address this gap, we conduct a comprehensive and systematic safety evaluation of 11 MLRMs across 5 benchmarks and unveil prevalent safety degradation phenomena in most advanced models. Moreover, our analysis reveals distinct safety patterns across different benchmarks: significant safety degradation is observed across jailbreak robustness benchmarks, whereas safety-awareness benchmarks demonstrate less pronounced degradation. In particular, a long thought process in some scenarios even enhances safety performance. Therefore, it is a potential approach to addressing safety issues in MLRMs by leveraging the intrinsic reasoning capabilities of the model to detect unsafe intent. To operationalize this insight, we construct a multimodal tuning dataset that incorporates a safety-oriented thought process. Experimental results from fine-tuning existing MLRMs with this dataset effectively enhances the safety on both jailbreak robustness and safety-awareness benchmarks. This study provides a new perspective for developing safe MLRMs. Our dataset is available at this https URL.</li>
</ul>

<h3>Title: dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data</h3>
<ul>
<li><strong>Authors: </strong>Adèle H. Ribeiro, Dominik Heider</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06542">https://arxiv.org/abs/2505.06542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06542">https://arxiv.org/pdf/2505.06542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06542]] dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data(https://arxiv.org/abs/2505.06542)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causal discovery is central to inferring causal relationships from observational data. In the presence of latent confounding, algorithms such as Fast Causal Inference (FCI) learn a Partial Ancestral Graph (PAG) representing the true model's Markov Equivalence Class. However, their correctness critically depends on empirical faithfulness, the assumption that observed (in)dependencies perfectly reflect those of the underlying causal model, which often fails in practice due to limited sample sizes. To address this, we introduce the first nonparametric score to assess a PAG's compatibility with observed data, even with mixed variable types. This score is both necessary and sufficient to characterize structural uncertainty and distinguish between distinct PAGs. We then propose data-compatible FCI (dcFCI), the first hybrid causal discovery algorithm to jointly address latent confounding, empirical unfaithfulness, and mixed data types. dcFCI integrates our score into an (Anytime)FCI-guided search that systematically explores, ranks, and validates candidate PAGs. Experiments on synthetic and real-world scenarios demonstrate that dcFCI significantly outperforms state-of-the-art methods, often recovering the true PAG even in small and heterogeneous datasets. Examining top-ranked PAGs further provides valuable insights into structural uncertainty, supporting more robust and informed causal reasoning and decision-making.</li>
</ul>

<h3>Title: HDGlyph: A Hierarchical Disentangled Glyph-Based Framework for Long-Tail Text Rendering in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Shuhan Zhuang, Mengqi Huang, Fengyi Fu, Nan Chen, Bohan Lei, Zhendong Mao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06543">https://arxiv.org/abs/2505.06543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06543">https://arxiv.org/pdf/2505.06543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06543]] HDGlyph: A Hierarchical Disentangled Glyph-Based Framework for Long-Tail Text Rendering in Diffusion Models(https://arxiv.org/abs/2505.06543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Visual text rendering, which aims to accurately integrate specified textual content within generated images, is critical for various applications such as commercial design. Despite recent advances, current methods struggle with long-tail text cases, particularly when handling unseen or small-sized text. In this work, we propose a novel Hierarchical Disentangled Glyph-Based framework (HDGlyph) that hierarchically decouples text generation from non-text visual synthesis, enabling joint optimization of both common and long-tail text rendering. At the training stage, HDGlyph disentangles pixel-level representations via the Multi-Linguistic GlyphNet and the Glyph-Aware Perceptual Loss, ensuring robust rendering even for unseen characters. At inference time, HDGlyph applies Noise-Disentangled Classifier-Free Guidance and Latent-Disentangled Two-Stage Rendering (LD-TSR) scheme, which refines both background and small-sized text. Extensive evaluations show our model consistently outperforms others, with 5.08% and 11.7% accuracy gains in English and Chinese text rendering while maintaining high image quality. It also excels in long-tail scenarios with strong accuracy and visual performance.</li>
</ul>

<h3>Title: REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback</h3>
<ul>
<li><strong>Authors: </strong>Aniruddha Roy, Pretam Ray, Abhilash Nandy, Somak Aditya, Pawan Goyal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06548">https://arxiv.org/abs/2505.06548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06548">https://arxiv.org/pdf/2505.06548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06548]] REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback(https://arxiv.org/abs/2505.06548)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction-based Large Language Models (LLMs) have proven effective in numerous few-shot or zero-shot Natural Language Processing (NLP) tasks. However, creating human-annotated instruction data is time-consuming, expensive, and often limited in quantity and task diversity. Previous research endeavors have attempted to address this challenge by proposing frameworks capable of generating instructions in a semi-automated and task-agnostic manner directly from the model itself. Many of these efforts have relied on large API-only parameter-based models such as GPT-3.5 (175B), which are expensive, and subject to limits on a number of queries. This paper explores the performance of three open-source small LLMs such as LLaMA 2-7B, LLama 2-13B, and Mistral 7B, using a semi-automated framework, thereby reducing human intervention, effort, and cost required to generate an instruction dataset for fine-tuning LLMs. Furthermore, we demonstrate that incorporating a Reinforcement Learning (RL) based training algorithm into this LLMs-based framework leads to further enhancements. Our evaluation of the dataset reveals that these RL-based frameworks achieve a substantial improvements in 63-66% of the tasks compared to previous approaches.</li>
</ul>

<h3>Title: Dynamic Uncertainty Learning with Noisy Correspondence for Text-Based Person Search</h3>
<ul>
<li><strong>Authors: </strong>Zequn Xie, Haoming Ji, Lingwei Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06566">https://arxiv.org/abs/2505.06566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06566">https://arxiv.org/pdf/2505.06566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06566]] Dynamic Uncertainty Learning with Noisy Correspondence for Text-Based Person Search(https://arxiv.org/abs/2505.06566)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Text-to-image person search aims to identify an individual based on a text description. To reduce data collection costs, large-scale text-image datasets are created from co-occurrence pairs found online. However, this can introduce noise, particularly mismatched pairs, which degrade retrieval performance. Existing methods often focus on negative samples, amplifying this noise. To address these issues, we propose the Dynamic Uncertainty and Relational Alignment (DURA) framework, which includes the Key Feature Selector (KFS) and a new loss function, Dynamic Softmax Hinge Loss (DSH-Loss). KFS captures and models noise uncertainty, improving retrieval reliability. The bidirectional evidence from cross-modal similarity is modeled as a Dirichlet distribution, enhancing adaptability to noisy data. DSH adjusts the difficulty of negative samples to improve robustness in noisy environments. Our experiments on three datasets show that the method offers strong noise resistance and improves retrieval performance in both low- and high-noise scenarios.</li>
</ul>

<h3>Title: MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG</h3>
<ul>
<li><strong>Authors: </strong>Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06569">https://arxiv.org/abs/2505.06569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06569">https://arxiv.org/pdf/2505.06569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06569]] MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG(https://arxiv.org/abs/2505.06569)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-context (LC) Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) hold strong potential for complex multi-hop and large-document tasks. However, existing RAG systems often suffer from imprecise retrieval, incomplete context coverage under constrained context windows, and fragmented information caused by suboptimal context construction. We introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical retrieval framework that compresses and partitions documents into coarse-to-fine granularities, then adaptively merges relevant contexts through chunk- and document-level expansions in real time. By starting from the finest-level retrieval and progressively incorporating higher-level and broader context, MacRAG constructs effective query-specific long contexts, optimizing both precision and coverage. Evaluations on the challenging LongBench expansions of HotpotQA, 2WikiMultihopQA, and Musique confirm that MacRAG consistently surpasses baseline RAG pipelines on single- and multi-step generation with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish MacRAG as an efficient, scalable solution for real-world long-context, multi-hop reasoning. Our code is available at this https URL.</li>
</ul>

<h3>Title: ElectricSight: 3D Hazard Monitoring for Power Lines Using Low-Cost Sensors</h3>
<ul>
<li><strong>Authors: </strong>Xingchen Li, LiDian Wang, Yu Sheng, ZhiPeng Tang, Haojie Ren, Guoliang You, YiFan Duan, Jianmin Ji, Yanyong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06573">https://arxiv.org/abs/2505.06573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06573">https://arxiv.org/pdf/2505.06573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06573]] ElectricSight: 3D Hazard Monitoring for Power Lines Using Low-Cost Sensors(https://arxiv.org/abs/2505.06573)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Protecting power transmission lines from potential hazards involves critical tasks, one of which is the accurate measurement of distances between power lines and potential threats, such as large cranes. The challenge with this task is that the current sensor-based methods face challenges in balancing accuracy and cost in distance measurement. A common practice is to install cameras on transmission towers, which, however, struggle to measure true 3D distances due to the lack of depth information. Although 3D lasers can provide accurate depth data, their high cost makes large-scale deployment impractical. To address this challenge, we present ElectricSight, a system designed for 3D distance measurement and monitoring of potential hazards to power transmission lines. This work's key innovations lie in both the overall system framework and a monocular depth estimation method. Specifically, the system framework combines real-time images with environmental point cloud priors, enabling cost-effective and precise 3D distance measurements. As a core component of the system, the monocular depth estimation method enhances the performance by integrating 3D point cloud data into image-based estimates, improving both the accuracy and reliability of the system. To assess ElectricSight's performance, we conducted tests with data from a real-world power transmission scenario. The experimental results demonstrate that ElectricSight achieves an average accuracy of 1.08 m for distance measurements and an early warning accuracy of 92%.</li>
</ul>

<h3>Title: GRACE: Estimating Geometry-level 3D Human-Scene Contact from 2D Images</h3>
<ul>
<li><strong>Authors: </strong>Chengfeng Wang, Wei Zhai, Yuhang Yang, Yang Cao, Zhengjun Zha</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06575">https://arxiv.org/abs/2505.06575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06575">https://arxiv.org/pdf/2505.06575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06575]] GRACE: Estimating Geometry-level 3D Human-Scene Contact from 2D Images(https://arxiv.org/abs/2505.06575)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Estimating the geometry level of human-scene contact aims to ground specific contact surface points at 3D human geometries, which provides a spatial prior and bridges the interaction between human and scene, supporting applications such as human behavior analysis, embodied AI, and AR/VR. To complete the task, existing approaches predominantly rely on parametric human models (e.g., SMPL), which establish correspondences between images and contact regions through fixed SMPL vertex sequences. This actually completes the mapping from image features to an ordered sequence. However, this approach lacks consideration of geometry, limiting its generalizability in distinct human geometries. In this paper, we introduce GRACE (Geometry-level Reasoning for 3D Human-scene Contact Estimation), a new paradigm for 3D human contact estimation. GRACE incorporates a point cloud encoder-decoder architecture along with a hierarchical feature extraction and fusion module, enabling the effective integration of 3D human geometric structures with 2D interaction semantics derived from images. Guided by visual cues, GRACE establishes an implicit mapping from geometric features to the vertex space of the 3D human mesh, thereby achieving accurate modeling of contact regions. This design ensures high prediction accuracy and endows the framework with strong generalization capability across diverse human geometries. Extensive experiments on multiple benchmark datasets demonstrate that GRACE achieves state-of-the-art performance in contact estimation, with additional results further validating its robust generalization to unstructured human point clouds.</li>
</ul>

<h3>Title: POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yangguang Shao, Xinjie Lin, Haozheng Luo, Chengshang Hou, Gang Xiong, Jiahao Yu, Junzheng Shi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06579">https://arxiv.org/abs/2505.06579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06579">https://arxiv.org/pdf/2505.06579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06579]] POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models(https://arxiv.org/abs/2505.06579)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success in various domains, primarily due to their strong capabilities in reasoning and generating human-like text. Despite their impressive performance, LLMs are susceptible to hallucinations, which can lead to incorrect or misleading outputs. This is primarily due to the lack of up-to-date knowledge or domain-specific information. Retrieval-augmented generation (RAG) is a promising approach to mitigate hallucinations by leveraging external knowledge sources. However, the security of RAG systems has not been thoroughly studied. In this paper, we study a poisoning attack on RAG systems named POISONCRAFT, which can mislead the model to refer to fraudulent websites. Compared to existing poisoning attacks on RAG systems, our attack is more practical as it does not require access to the target user query's info or edit the user query. It not only ensures that injected texts can be retrieved by the model, but also ensures that the LLM will be misled to refer to the injected texts in its response. We demonstrate the effectiveness of POISONCRAFTacross different datasets, retrievers, and language models in RAG pipelines, and show that it remains effective when transferred across retrievers, including black-box systems. Moreover, we present a case study revealing how the attack influences both the retrieval behavior and the step-by-step reasoning trace within the generation model, and further evaluate the robustness of POISONCRAFTunder multiple defense mechanisms. These results validate the practicality of our threat model and highlight a critical security risk for RAG systems deployed in real-world applications. We release our code\footnote{this https URL} to support future research on the security and robustness of RAG systems in real-world settings.</li>
</ul>

<h3>Title: Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>H M Dipu Kabir, Subrota Kumar Mondal, Mohammad Ali Moni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06592">https://arxiv.org/abs/2505.06592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06592">https://arxiv.org/pdf/2505.06592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06592]] Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning(https://arxiv.org/abs/2505.06592)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper proposes batch augmentation with unimodal fine-tuning to detect the fetus's organs from ultrasound images and associated clinical textual information. We also prescribe pre-training initial layers with investigated medical data before the multimodal training. At first, we apply a transferred initialization with the unimodal image portion of the dataset with batch augmentation. This step adjusts the initial layer weights for medical data. Then, we apply neural networks (NNs) with fine-tuned initial layers to images in batches with batch augmentation to obtain features. We also extract information from descriptions of images. We combine this information with features obtained from images to train the head layer. We write a dataloader script to load the multimodal data and use existing unimodal image augmentation techniques with batch augmentation for the multimodal data. The dataloader brings a new random augmentation for each batch to get a good generalization. We investigate the FPU23 ultrasound and UPMC Food-101 multimodal datasets. The multimodal large language model (LLM) with the proposed training provides the best results among the investigated methods. We receive near state-of-the-art (SOTA) performance on the UPMC Food-101 dataset. We share the scripts of the proposed method with traditional counterparts at the following repository: this http URL</li>
</ul>

<h3>Title: Bridging the Gap: An Intermediate Language for Enhanced and Cost-Effective Grapheme-to-Phoneme Conversion with Homographs with Multiple Pronunciations Disambiguation</h3>
<ul>
<li><strong>Authors: </strong>Abbas Bertina, Shahab Beirami, Hossein Biniazian, Elham Esmaeilnia, Soheil Shahi, Mahdi Pirnia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06599">https://arxiv.org/abs/2505.06599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06599">https://arxiv.org/pdf/2505.06599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06599]] Bridging the Gap: An Intermediate Language for Enhanced and Cost-Effective Grapheme-to-Phoneme Conversion with Homographs with Multiple Pronunciations Disambiguation(https://arxiv.org/abs/2505.06599)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Grapheme-to-phoneme (G2P) conversion for Persian presents unique challenges due to its complex phonological features, particularly homographs and Ezafe, which exist in formal and informal language contexts. This paper introduces an intermediate language specifically designed for Persian language processing that addresses these challenges through a multi-faceted approach. Our methodology combines two key components: Large Language Model (LLM) prompting techniques and a specialized sequence-to-sequence machine transliteration architecture. We developed and implemented a systematic approach for constructing a comprehensive lexical database for homographs with multiple pronunciations disambiguation often termed polyphones, utilizing formal concept analysis for semantic differentiation. We train our model using two distinct datasets: the LLM-generated dataset for formal and informal Persian and the B-Plus podcasts for informal language variants. The experimental results demonstrate superior performance compared to existing state-of-the-art approaches, particularly in handling the complexities of Persian phoneme conversion. Our model significantly improves Phoneme Error Rate (PER) metrics, establishing a new benchmark for Persian G2P conversion accuracy. This work contributes to the growing research in low-resource language processing and provides a robust solution for Persian text-to-speech systems and demonstrating its applicability beyond Persian. Specifically, the approach can extend to languages with rich homographic phenomena such as Chinese and Arabic</li>
</ul>

<h3>Title: ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Lei Hu, Zhiyong Gan, Ling Deng, Jinglin Liang, Lingyu Liang, Shuangping Huang, Tianshui Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06603">https://arxiv.org/abs/2505.06603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06603">https://arxiv.org/pdf/2505.06603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06603]] ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection(https://arxiv.org/abs/2505.06603)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Continual Anomaly Detection (CAD) enables anomaly detection models in learning new classes while preserving knowledge of historical classes. CAD faces two key challenges: catastrophic forgetting and segmentation of small anomalous regions. Existing CAD methods store image distributions or patch features to mitigate catastrophic forgetting, but they fail to preserve pixel-level detailed features for accurate segmentation. To overcome this limitation, we propose ReplayCAD, a novel diffusion-driven generative replay framework that replay high-quality historical data, thus effectively preserving pixel-level detailed features. Specifically, we compress historical data by searching for a class semantic embedding in the conditional space of the pre-trained diffusion model, which can guide the model to replay data with fine-grained pixel details, thus improving the segmentation performance. However, relying solely on semantic features results in limited spatial diversity. Hence, we further use spatial features to guide data compression, achieving precise control of sample space, thereby generating more diverse data. Our method achieves state-of-the-art performance in both classification and segmentation, with notable improvements in segmentation: 11.5% on VisA and 8.1% on MVTec. Our source code is available at this https URL.</li>
</ul>

<h3>Title: Boosting Neural Language Inference via Cascaded Interactive Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Min Li, Chun Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06607">https://arxiv.org/abs/2505.06607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06607">https://arxiv.org/pdf/2505.06607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06607]] Boosting Neural Language Inference via Cascaded Interactive Reasoning(https://arxiv.org/abs/2505.06607)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Natural Language Inference (NLI) focuses on ascertaining the logical relationship (entailment, contradiction, or neutral) between a given premise and hypothesis. This task presents significant challenges due to inherent linguistic features such as diverse phrasing, semantic complexity, and contextual nuances. While Pre-trained Language Models (PLMs) built upon the Transformer architecture have yielded substantial advancements in NLI, prevailing methods predominantly utilize representations from the terminal layer. This reliance on final-layer outputs may overlook valuable information encoded in intermediate layers, potentially limiting the capacity to model intricate semantic interactions effectively. Addressing this gap, we introduce the Cascaded Interactive Reasoning Network (CIRN), a novel architecture designed for deeper semantic comprehension in NLI. CIRN implements a hierarchical feature extraction strategy across multiple network depths, operating within an interactive space where cross-sentence information is continuously integrated. This mechanism aims to mimic a process of progressive reasoning, transitioning from surface-level feature matching to uncovering more profound logical and semantic connections between the premise and hypothesis. By systematically mining latent semantic relationships at various representational levels, CIRN facilitates a more thorough understanding of the input pair. Comprehensive evaluations conducted on several standard NLI benchmark datasets reveal consistent performance gains achieved by CIRN over competitive baseline approaches, demonstrating the efficacy of leveraging multi-level interactive features for complex relational reasoning.</li>
</ul>

<h3>Title: AI-Powered Anomaly Detection with Blockchain for Real-Time Security and Reliability in Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Rathin Chandra Shit, Sharmila Subudhi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06632">https://arxiv.org/abs/2505.06632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06632">https://arxiv.org/pdf/2505.06632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06632]] AI-Powered Anomaly Detection with Blockchain for Real-Time Security and Reliability in Autonomous Vehicles(https://arxiv.org/abs/2505.06632)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Autonomous Vehicles (AV) proliferation brings important and pressing security and reliability issues that must be dealt with to guarantee public safety and help their widespread adoption. The contribution of the proposed research is towards achieving more secure, reliable, and trustworthy autonomous transportation system by providing more capabilities for anomaly detection, data provenance, and real-time response in safety critical AV deployments. In this research, we develop a new framework that combines the power of Artificial Intelligence (AI) for real-time anomaly detection with blockchain technology to detect and prevent any malicious activity including sensor failures in AVs. Through Long Short-Term Memory (LSTM) networks, our approach continually monitors associated multi-sensor data streams to detect anomalous patterns that may represent cyberattacks as well as hardware malfunctions. Further, this framework employs a decentralized platform for securely storing sensor data and anomaly alerts in a blockchain ledger for data incorruptibility and authenticity, while offering transparent forensic features. Moreover, immediate automated response mechanisms are deployed using smart contracts when anomalies are found. This makes the AV system more resilient to attacks from both cyberspace and hardware component failure. Besides, we identify potential challenges of scalability in handling high frequency sensor data, computational constraint in resource constrained environment, and of distributed data storage in terms of privacy.</li>
</ul>

<h3>Title: Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Isaac Gerber</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06633">https://arxiv.org/abs/2505.06633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06633">https://arxiv.org/pdf/2505.06633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06633]] Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models(https://arxiv.org/abs/2505.06633)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Decoder-only transformer networks have become incredibly popular for language modeling tasks. State-of-the-art models can have over a hundred transformer blocks, containing billions of trainable parameters, and are trained on trillions of tokens of text. Each transformer block typically consists of a multi-head attention (MHA) mechanism and a two-layer fully connected feedforward network (FFN). In this paper, we examine the importance of the FFN during the model pre-training process through a series of experiments, confirming that the FFN is important to model performance. Furthermore, we show that models using a transformer block configuration with three-layer FFNs with fewer such blocks outperform the standard two-layer configuration delivering lower training loss with fewer total parameters in less time.</li>
</ul>

<h3>Title: Reducing Unimodal Bias in Multi-Modal Semantic Segmentation with Multi-Scale Functional Entropy Regularization</h3>
<ul>
<li><strong>Authors: </strong>Xu Zheng, Yuanhuiyi Lyu, Lutao Jiang, Danda Pani Paudel, Luc Van Gool, Xuming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06635">https://arxiv.org/abs/2505.06635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06635">https://arxiv.org/pdf/2505.06635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06635]] Reducing Unimodal Bias in Multi-Modal Semantic Segmentation with Multi-Scale Functional Entropy Regularization(https://arxiv.org/abs/2505.06635)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Fusing and balancing multi-modal inputs from novel sensors for dense prediction tasks, particularly semantic segmentation, is critically important yet remains a significant challenge. One major limitation is the tendency of multi-modal frameworks to over-rely on easily learnable modalities, a phenomenon referred to as unimodal dominance or bias. This issue becomes especially problematic in real-world scenarios where the dominant modality may be unavailable, resulting in severe performance degradation. To this end, we apply a simple but effective plug-and-play regularization term based on functional entropy, which introduces no additional parameters or modules. This term is designed to intuitively balance the contribution of each visual modality to the segmentation results. Specifically, we leverage the log-Sobolev inequality to bound functional entropy using functional-Fisher-information. By maximizing the information contributed by each visual modality, our approach mitigates unimodal dominance and establishes a more balanced and robust segmentation framework. A multi-scale regularization module is proposed to apply our proposed plug-and-play term on high-level features and also segmentation predictions for more balanced multi-modal learning. Extensive experiments on three datasets demonstrate that our proposed method achieves superior performance, i.e., +13.94%, +3.25%, and +3.64%, without introducing any additional parameters.</li>
</ul>

<h3>Title: A Contrastive Federated Semi-Supervised Learning Intrusion Detection Framework for Internet of Robotic Things</h3>
<ul>
<li><strong>Authors: </strong>Yifan Zeng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06636">https://arxiv.org/abs/2505.06636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06636">https://arxiv.org/pdf/2505.06636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06636]] A Contrastive Federated Semi-Supervised Learning Intrusion Detection Framework for Internet of Robotic Things(https://arxiv.org/abs/2505.06636)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, robust, federate</a></li>
<li><strong>Abstract: </strong>In intelligent industry, autonomous driving and other environments, the Internet of Things (IoT) highly integrated with robotic to form the Internet of Robotic Things (IoRT). However, network intrusion to IoRT can lead to data leakage, service interruption in IoRT and even physical damage by controlling robots or vehicles. This paper proposes a Contrastive Federated Semi-Supervised Learning Network Intrusion Detection framework (CFedSSL-NID) for IoRT intrusion detection and defense, to address the practical scenario of IoRT where robots don't possess labeled data locally and the requirement for data privacy preserving. CFedSSL-NID integrates randomly weak and strong augmentation, latent contrastive learning, and EMA update to integrate supervised signals, thereby enhancing performance and robustness on robots' local unlabeled data. Extensive experiments demonstrate that CFedSSL-NID outperforms existing federated semi-supervised and fully supervised methods on benchmark dataset and has lower resource requirements.</li>
</ul>

<h3>Title: Practical Reasoning Interruption Attacks on Reasoning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Cui, Cong Zuo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06643">https://arxiv.org/abs/2505.06643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06643">https://arxiv.org/pdf/2505.06643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06643]] Practical Reasoning Interruption Attacks on Reasoning Large Language Models(https://arxiv.org/abs/2505.06643)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Reasoning large language models (RLLMs) have demonstrated outstanding performance across a variety of tasks, yet they also expose numerous security vulnerabilities. Most of these vulnerabilities have centered on the generation of unsafe content. However, recent work has identified a distinct "thinking-stopped" vulnerability in DeepSeek-R1: under adversarial prompts, the model's reasoning process ceases at the system level and produces an empty final answer. Building upon this vulnerability, researchers developed a novel prompt injection attack, termed reasoning interruption attack, and also offered an initial analysis of its root cause. Through extensive experiments, we verify the previous analyses, correct key errors based on three experimental findings, and present a more rigorous explanation of the fundamental causes driving the vulnerability. Moreover, existing attacks typically require over 2,000 tokens, impose significant overhead, reduce practicality, and are easily detected. To overcome these limitations, we propose the first practical reasoning interruption attack. It succeeds with just 109 tokens by exploiting our newly uncovered "reasoning token overflow" (RTO) effect to overwrite the model's final answer, forcing it to return an invalid response. Experimental results demonstrate that our proposed attack is highly effective. Furthermore, we discover that the method for triggering RTO differs between the official DeepSeek-R1 release and common unofficial deployments. As a broadened application of RTO, we also construct a novel jailbreak attack that enables the transfer of unsafe content within the reasoning tokens into final answer, thereby exposing it to the user. Our work carries significant implications for enhancing the security of RLLMs.</li>
</ul>

<h3>Title: Dataset Distillation with Probabilistic Latent Features</h3>
<ul>
<li><strong>Authors: </strong>Zhe Li, Sarah Cechnicka, Cheng Ouyang, Katharina Breininger, Peter Schüffler, Bernhard Kainz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06647">https://arxiv.org/abs/2505.06647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06647">https://arxiv.org/pdf/2505.06647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06647]] Dataset Distillation with Probabilistic Latent Features(https://arxiv.org/abs/2505.06647)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As deep learning models grow in complexity and the volume of training data increases, reducing storage and computational costs becomes increasingly important. Dataset distillation addresses this challenge by synthesizing a compact set of synthetic data that can effectively replace the original dataset in downstream classification tasks. While existing methods typically rely on mapping data from pixel space to the latent space of a generative model, we propose a novel stochastic approach that models the joint distribution of latent features. This allows our method to better capture spatial structures and produce diverse synthetic samples, which benefits model training. Specifically, we introduce a low-rank multivariate normal distribution parameterized by a lightweight network. This design maintains low computational complexity and is compatible with various matching networks used in dataset distillation. After distillation, synthetic images are generated by feeding the learned latent features into a pretrained generator. These synthetic images are then used to train classification models, and performance is evaluated on real test set. We validate our method on several benchmarks, including ImageNet subsets, CIFAR-10, and the MedMNIST histopathological dataset. Our approach achieves state-of-the-art cross architecture performance across a range of backbone architectures, demonstrating its generality and effectiveness.</li>
</ul>

<h3>Title: Dyn-D$^2$P: Dynamic Differentially Private Decentralized Learning with Provable Utility Guarantee</h3>
<ul>
<li><strong>Authors: </strong>Zehan Zhu, Yan Huang, Xin Wang, Shouling Ji, Jinming Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06651">https://arxiv.org/abs/2505.06651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06651">https://arxiv.org/pdf/2505.06651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06651]] Dyn-D$^2$P: Dynamic Differentially Private Decentralized Learning with Provable Utility Guarantee(https://arxiv.org/abs/2505.06651)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Most existing decentralized learning methods with differential privacy (DP) guarantee rely on constant gradient clipping bounds and fixed-level DP Gaussian noises for each node throughout the training process, leading to a significant accuracy degradation compared to non-private counterparts. In this paper, we propose a new Dynamic Differentially Private Decentralized learning approach (termed Dyn-D$^2$P) tailored for general time-varying directed networks. Leveraging the Gaussian DP (GDP) framework for privacy accounting, Dyn-D$^2$P dynamically adjusts gradient clipping bounds and noise levels based on gradient convergence. This proposed dynamic noise strategy enables us to enhance model accuracy while preserving the total privacy budget. Extensive experiments on benchmark datasets demonstrate the superiority of Dyn-D$^2$P over its counterparts employing fixed-level noises, especially under strong privacy guarantees. Furthermore, we provide a provable utility bound for Dyn-D$^2$P that establishes an explicit dependency on network-related parameters, with a scaling factor of $1/\sqrt{n}$ in terms of the number of nodes $n$ up to a bias error term induced by gradient clipping. To our knowledge, this is the first model utility analysis for differentially private decentralized non-convex optimization with dynamic gradient clipping bounds and noise levels.</li>
</ul>

<h3>Title: Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations</h3>
<ul>
<li><strong>Authors: </strong>Patrick Blumenberg, Thomas Graave, Tim Fingscheidt</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06653">https://arxiv.org/abs/2505.06653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06653">https://arxiv.org/pdf/2505.06653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06653]] Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations(https://arxiv.org/abs/2505.06653)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demand extensive memory capacity during both fine-tuning and inference. To enable memory-efficient fine-tuning, existing methods apply block-wise quantization techniques, such as NF4 and AF4, to the network weights. We show that these quantization techniques incur suboptimal quantization errors. Therefore, as a first novelty, we propose an optimization approach for block-wise quantization. Using this method, we design a family of quantizers named 4-bit block-wise optimal float (BOF4), which consistently reduces the quantization error compared to both baseline methods. We provide both a theoretical and a data-driven solution for the optimization process and prove their practical equivalence. Secondly, we propose a modification to the employed normalization method based on the signed absolute block maximum (BOF4-S), enabling further reduction of the quantization error and empirically achieving less degradation in language modeling performance. Thirdly, we explore additional variations of block-wise quantization methods applied to LLMs through an experimental study on the importance of accurately representing zero and large-amplitude weights on the one hand, and optimization towards various error metrics on the other hand. Lastly, we introduce a mixed-precision quantization strategy dubbed outlier-preserving quantization (OPQ) to address the distributional mismatch induced by outlier weights in block-wise quantization. By storing outlier weights in 16-bit precision (OPQ) while applying BOF4-S, we achieve top performance among 4-bit block-wise quantization techniques w.r.t. perplexity.</li>
</ul>

<h3>Title: MultiTaskVIF: Segmentation-oriented visible and infrared image fusion via multi-task learning</h3>
<ul>
<li><strong>Authors: </strong>Zixian Zhao, Andrew Howes, Xingchen Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06665">https://arxiv.org/abs/2505.06665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06665">https://arxiv.org/pdf/2505.06665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06665]] MultiTaskVIF: Segmentation-oriented visible and infrared image fusion via multi-task learning(https://arxiv.org/abs/2505.06665)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Visible and infrared image fusion (VIF) has attracted significant attention in recent years. Traditional VIF methods primarily focus on generating fused images with high visual quality, while recent advancements increasingly emphasize incorporating semantic information into the fusion model during training. However, most existing segmentation-oriented VIF methods adopt a cascade structure comprising separate fusion and segmentation models, leading to increased network complexity and redundancy. This raises a critical question: can we design a more concise and efficient structure to integrate semantic information directly into the fusion model during training-Inspired by multi-task learning, we propose a concise and universal training framework, MultiTaskVIF, for segmentation-oriented VIF models. In this framework, we introduce a multi-task head decoder (MTH) to simultaneously output both the fused image and the segmentation result during training. Unlike previous cascade training frameworks that necessitate joint training with a complete segmentation model, MultiTaskVIF enables the fusion model to learn semantic features by simply replacing its decoder with MTH. Extensive experimental evaluations validate the effectiveness of the proposed method. Our code will be released upon acceptance.</li>
</ul>

<h3>Title: StableMotion: Repurposing Diffusion-Based Image Priors for Motion Estimation</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Wang, Haipeng Li, Lin Sui, Tianhao Zhou, Hai Jiang, Lang Nie, Shuaicheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06668">https://arxiv.org/abs/2505.06668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06668">https://arxiv.org/pdf/2505.06668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06668]] StableMotion: Repurposing Diffusion-Based Image Priors for Motion Estimation(https://arxiv.org/abs/2505.06668)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present StableMotion, a novel framework leverages knowledge (geometry and content priors) from pretrained large-scale image diffusion models to perform motion estimation, solving single-image-based image rectification tasks such as Stitched Image Rectangling (SIR) and Rolling Shutter Correction (RSC). Specifically, StableMotion framework takes text-to-image Stable Diffusion (SD) models as backbone and repurposes it into an image-to-motion estimator. To mitigate inconsistent output produced by diffusion models, we propose Adaptive Ensemble Strategy (AES) that consolidates multiple outputs into a cohesive, high-fidelity result. Additionally, we present the concept of Sampling Steps Disaster (SSD), the counterintuitive scenario where increasing the number of sampling steps can lead to poorer outcomes, which enables our framework to achieve one-step inference. StableMotion is verified on two image rectification tasks and delivers state-of-the-art performance in both, as well as showing strong generalizability. Supported by SSD, StableMotion offers a speedup of 200 times compared to previous diffusion model-based methods.</li>
</ul>

<h3>Title: Video Dataset Condensation with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhe Li, Hadrien Reynaud, Mischa Dombrowski, Sarah Cechnicka, Franciskus Xaverius Erick, Bernhard Kainz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06670">https://arxiv.org/abs/2505.06670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06670">https://arxiv.org/pdf/2505.06670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06670]] Video Dataset Condensation with Diffusion Models(https://arxiv.org/abs/2505.06670)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In recent years, the rapid expansion of dataset sizes and the increasing complexity of deep learning models have significantly escalated the demand for computational resources, both for data storage and model training. Dataset distillation has emerged as a promising solution to address this challenge by generating a compact synthetic dataset that retains the essential information from a large real dataset. However, existing methods often suffer from limited performance and poor data quality, particularly in the video domain. In this paper, we focus on video dataset distillation by employing a video diffusion model to generate high-quality synthetic videos. To enhance representativeness, we introduce Video Spatio-Temporal U-Net (VST-UNet), a model designed to select a diverse and informative subset of videos that effectively captures the characteristics of the original dataset. To further optimize computational efficiency, we explore a training-free clustering algorithm, Temporal-Aware Cluster-based Distillation (TAC-DT), to select representative videos without requiring additional training overhead. We validate the effectiveness of our approach through extensive experiments on four benchmark datasets, demonstrating performance improvements of up to \(10.61\%\) over the state-of-the-art. Our method consistently outperforms existing approaches across all datasets, establishing a new benchmark for video dataset distillation.</li>
</ul>

<h3>Title: Jailbreaking the Text-to-Video Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Jiayang Liu, Siyuan Liang, Shiqian Zhao, Rongcheng Tu, Wenbo Zhou, Xiaochun Cao, Dacheng Tao, Siew Kei Lam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06679">https://arxiv.org/abs/2505.06679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06679">https://arxiv.org/pdf/2505.06679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06679]] Jailbreaking the Text-to-Video Generative Models(https://arxiv.org/abs/2505.06679)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-to-video generative models have achieved significant progress, driven by the rapid advancements in diffusion models, with notable examples including Pika, Luma, Kling, and Sora. Despite their remarkable generation ability, their vulnerability to jailbreak attack, i.e. to generate unsafe content, including pornography, violence, and discrimination, raises serious safety concerns. Existing efforts, such as T2VSafetyBench, have provided valuable benchmarks for evaluating the safety of text-to-video models against unsafe prompts but lack systematic studies for exploiting their vulnerabilities effectively. In this paper, we propose the \textit{first} optimization-based jailbreak attack against text-to-video models, which is specifically designed. Our approach formulates the prompt generation task as an optimization problem with three key objectives: (1) maximizing the semantic similarity between the input and generated prompts, (2) ensuring that the generated prompts can evade the safety filter of the text-to-video model, and (3) maximizing the semantic similarity between the generated videos and the original input prompts. To further enhance the robustness of the generated prompts, we introduce a prompt mutation strategy that creates multiple prompt variants in each iteration, selecting the most effective one based on the averaged score. This strategy not only improves the attack success rate but also boosts the semantic relevance of the generated video. We conduct extensive experiments across multiple text-to-video models, including Open-Sora, Pika, Luma, and Kling. The results demonstrate that our method not only achieves a higher attack success rate compared to baseline methods but also generates videos with greater semantic similarity to the original input prompts.</li>
</ul>

<h3>Title: UnfoldIR: Rethinking Deep Unfolding Network in Illumination Degradation Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Chunming He, Rihan Zhang, Fengyang Xiao, Chengyu Fang, Longxiang Tang, Yulun Zhang, Sina Farsiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06683">https://arxiv.org/abs/2505.06683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06683">https://arxiv.org/pdf/2505.06683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06683]] UnfoldIR: Rethinking Deep Unfolding Network in Illumination Degradation Image Restoration(https://arxiv.org/abs/2505.06683)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep unfolding networks (DUNs) are widely employed in illumination degradation image restoration (IDIR) to merge the interpretability of model-based approaches with the generalization of learning-based methods. However, the performance of DUN-based methods remains considerably inferior to that of state-of-the-art IDIR solvers. Our investigation indicates that this limitation does not stem from structural shortcomings of DUNs but rather from the limited exploration of the unfolding structure, particularly for (1) constructing task-specific restoration models, (2) integrating advanced network architectures, and (3) designing DUN-specific loss functions. To address these issues, we propose a novel DUN-based method, UnfoldIR, for IDIR tasks. UnfoldIR first introduces a new IDIR model with dedicated regularization terms for smoothing illumination and enhancing texture. We unfold the iterative optimized solution of this model into a multistage network, with each stage comprising a reflectance-assisted illumination correction (RAIC) module and an illumination-guided reflectance enhancement (IGRE) module. RAIC employs a visual state space (VSS) to extract non-local features, enforcing illumination smoothness, while IGRE introduces a frequency-aware VSS to globally align similar textures, enabling mildly degraded regions to guide the enhancement of details in more severely degraded areas. This suppresses noise while enhancing details. Furthermore, given the multistage structure, we propose an inter-stage information consistent loss to maintain network stability in the final stages. This loss contributes to structural preservation and sustains the model's performance even in unsupervised settings. Experiments verify our effectiveness across 5 IDIR tasks and 3 downstream problems.</li>
</ul>

<h3>Title: FNBench: Benchmarking Robust Federated Learning against Noisy Labels</h3>
<ul>
<li><strong>Authors: </strong>Xuefeng Jiang, Jia Li, Nannan Wu, Zhiyuan Wu, Xujing Li, Sheng Sun, Gang Xu, Yuwei Wang, Qi Li, Min Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06684">https://arxiv.org/abs/2505.06684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06684">https://arxiv.org/pdf/2505.06684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06684]] FNBench: Benchmarking Robust Federated Learning against Noisy Labels(https://arxiv.org/abs/2505.06684)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Robustness to label noise within data is a significant challenge in federated learning (FL). From the data-centric perspective, the data quality of distributed datasets can not be guaranteed since annotations of different clients contain complicated label noise of varying degrees, which causes the performance degradation. There have been some early attempts to tackle noisy labels in FL. However, there exists a lack of benchmark studies on comprehensively evaluating their practical performance under unified settings. To this end, we propose the first benchmark study FNBench to provide an experimental investigation which considers three diverse label noise patterns covering synthetic label noise, imperfect human-annotation errors and systematic errors. Our evaluation incorporates eighteen state-of-the-art methods over five image recognition datasets and one text classification dataset. Meanwhile, we provide observations to understand why noisy labels impair FL, and additionally exploit a representation-aware regularization method to enhance the robustness of existing methods against noisy labels based on our observations. Finally, we discuss the limitations of this work and propose three-fold future directions. To facilitate related communities, our source code is open-sourced at this https URL.</li>
</ul>

<h3>Title: A Novel Framework for Significant Wave Height Prediction based on Adaptive Feature Extraction Time-Frequency Network</h3>
<ul>
<li><strong>Authors: </strong>Jianxin Zhang, Lianzi Jiang, Xinyu Han, Xiangrong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06688">https://arxiv.org/abs/2505.06688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06688">https://arxiv.org/pdf/2505.06688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06688]] A Novel Framework for Significant Wave Height Prediction based on Adaptive Feature Extraction Time-Frequency Network(https://arxiv.org/abs/2505.06688)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Precise forecasting of significant wave height (Hs) is essential for the development and utilization of wave energy. The challenges in predicting Hs arise from its non-linear and non-stationary characteristics. The combination of decomposition preprocessing and machine learning models have demonstrated significant effectiveness in Hs prediction by extracting data features. However, decomposing the unknown data in the test set can lead to data leakage issues. To simultaneously achieve data feature extraction and prevent data leakage, a novel Adaptive Feature Extraction Time-Frequency Network (AFE-TFNet) is proposed to improve prediction accuracy and stability. It is encoder-decoder rolling framework. The encoder consists of two stages: feature extraction and feature fusion. In the feature extraction stage, global and local frequency domain features are extracted by combining Wavelet Transform (WT) and Fourier Transform (FT), and multi-scale frequency analysis is performed using Inception blocks. In the feature fusion stage, time-domain and frequency-domain features are integrated through dominant harmonic sequence energy weighting (DHSEW). The decoder employed an advanced long short-term memory (LSTM) model. Hourly measured wind speed (Ws), dominant wave period (DPD), average wave period (APD) and Hs from three stations are used as the dataset, and the four metrics are employed to evaluate the forecasting performance. Results show that AFE-TFNet significantly outperforms benchmark methods in terms of prediction accuracy. Feature extraction can significantly improve the prediction accuracy. DHSEW has substantially increased the accuracy of medium-term to long-term forecasting. The prediction accuracy of AFE-TFNet does not demonstrate significant variability with changes of rolling time window size. Overall, AFE-TFNet shows strong potential for handling complex signal forecasting.</li>
</ul>

<h3>Title: Underwater object detection in sonar imagery with detection transformer and Zero-shot neural architecture search</h3>
<ul>
<li><strong>Authors: </strong>XiaoTong Gu, Shengyu Tang, Yiming Cao, Changdong Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06694">https://arxiv.org/abs/2505.06694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06694">https://arxiv.org/pdf/2505.06694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06694]] Underwater object detection in sonar imagery with detection transformer and Zero-shot neural architecture search(https://arxiv.org/abs/2505.06694)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Underwater object detection using sonar imagery has become a critical and rapidly evolving research domain within marine technology. However, sonar images are characterized by lower resolution and sparser features compared to optical images, which seriously degrades the performance of object this http URL address these challenges, we specifically propose a Detection Transformer (DETR) architecture optimized with a Neural Architecture Search (NAS) approach called NAS-DETR for object detection in sonar images. First, an improved Zero-shot Neural Architecture Search (NAS) method based on the maximum entropy principle is proposed to identify a real-time, high-representational-capacity CNN-Transformer backbone for sonar image detection. This method enables the efficient discovery of high-performance network architectures with low computational and time overhead. Subsequently, the backbone is combined with a Feature Pyramid Network (FPN) and a deformable attention-based Transformer decoder to construct a complete network architecture. This architecture integrates various advanced components and training schemes to enhance overall performance. Extensive experiments demonstrate that this architecture achieves state-of-the-art performance on two Representative datasets, while maintaining minimal overhead in real-time efficiency and computational complexity. Furthermore, correlation analysis between the key parameters and differential entropy-based fitness function is performed to enhance the interpretability of the proposed framework. To the best of our knowledge, this is the first work in the field of sonar object detection to integrate the DETR architecture with a NAS search mechanism.</li>
</ul>

<h3>Title: Enhancing BERTopic with Intermediate Layer Representations</h3>
<ul>
<li><strong>Authors: </strong>Dominik Koterwa, Maciej Świtała</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06696">https://arxiv.org/abs/2505.06696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06696">https://arxiv.org/pdf/2505.06696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06696]] Enhancing BERTopic with Intermediate Layer Representations(https://arxiv.org/abs/2505.06696)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>BERTopic is a topic modeling algorithm that leverages transformer-based embeddings to create dense clusters, enabling the estimation of topic structures and the extraction of valuable insights from a corpus of documents. This approach allows users to efficiently process large-scale text data and gain meaningful insights into its structure. While BERTopic is a powerful tool, embedding preparation can vary, including extracting representations from intermediate model layers and applying transformations to these embeddings. In this study, we evaluate 18 different embedding representations and present findings based on experiments conducted on three diverse datasets. To assess the algorithm's performance, we report topic coherence and topic diversity metrics across all experiments. Our results demonstrate that, for each dataset, it is possible to find an embedding configuration that performs better than the default setting of BERTopic. Additionally, we investigate the influence of stop words on different embedding configurations.</li>
</ul>

<h3>Title: From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback</h3>
<ul>
<li><strong>Authors: </strong>Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06698">https://arxiv.org/abs/2505.06698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06698">https://arxiv.org/pdf/2505.06698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06698]] From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback(https://arxiv.org/abs/2505.06698)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automatic evaluation benchmarks such as MT-Bench, Arena-Hard, and Auto-Arena are seeing growing adoption for the evaluation of Large Language Models (LLMs). Existing research has primarily focused on approximating human-based model rankings using limited data and LLM-as-a-Judge. However, the fundamental premise of these studies, which attempts to replicate human rankings, is flawed. Specifically, these benchmarks typically offer only overall scores, limiting their utility to leaderboard rankings, rather than providing feedback that can guide model optimization and support model profiling. Therefore, we advocate for an evaluation paradigm shift from approximating human-based model rankings to providing feedback with analytical value. To this end, we introduce Feedbacker, an evaluation framework that provides comprehensive and fine-grained results, thereby enabling thorough identification of a model's specific strengths and weaknesses. Such feedback not only supports the targeted optimization of the model but also enhances the understanding of its behavior. Feedbacker comprises three key components: an extensible tree-based query taxonomy builder, an automated query synthesis scheme, and a suite of visualization and analysis tools. Furthermore, we propose a novel LLM-as-a-Judge method: PC2 (Pre-Comparison-derived Criteria) pointwise evaluation. This method derives evaluation criteria by pre-comparing the differences between several auxiliary responses, achieving the accuracy of pairwise evaluation while maintaining the time complexity of pointwise evaluation. Finally, leveraging the evaluation results of 17 mainstream LLMs, we demonstrate the usage of Feedbacker and highlight its effectiveness and potential. Our homepage project is available at this https URL.</li>
</ul>

<h3>Title: Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws</h3>
<ul>
<li><strong>Authors: </strong>Xiyuan Wei, Ming Lin, Fanjiang Ye, Fengguang Song, Liangliang Cao, My T. That, Tianbao Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06699">https://arxiv.org/abs/2505.06699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06699">https://arxiv.org/pdf/2505.06699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06699]] Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws(https://arxiv.org/abs/2505.06699)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper formalizes an emerging learning paradigm that uses a trained model as a reference to guide and enhance the training of a target model through strategic data selection or weighting, named $\textbf{model steering}$. While ad-hoc methods have been used in various contexts, including the training of large foundation models, its underlying principles remain insufficiently understood, leading to sub-optimal performance. In this work, we propose a theory-driven framework for model steering called $\textbf{DRRho risk minimization}$, which is rooted in Distributionally Robust Optimization (DRO). Through a generalization analysis, we provide theoretical insights into why this approach improves generalization and data efficiency compared to training without a reference model. To the best of our knowledge, this is the first time such theoretical insights are provided for the new learning paradigm, which significantly enhance our understanding and practice of model steering. Building on these insights and the connection between contrastive learning and DRO, we introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments validate the theoretical insights, reveal a superior scaling law compared to CLIP without a reference model, and demonstrate its strength over existing heuristic approaches.</li>
</ul>

<h3>Title: RuleGenie: SIEM Detection Rule Set Optimization</h3>
<ul>
<li><strong>Authors: </strong>Akansha Shukla, Parth Atulbhai Gandhi, Yuval Elovici, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06701">https://arxiv.org/abs/2505.06701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06701">https://arxiv.org/pdf/2505.06701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06701]] RuleGenie: SIEM Detection Rule Set Optimization(https://arxiv.org/abs/2505.06701)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>SIEM systems serve as a critical hub, employing rule-based logic to detect and respond to threats. Redundant or overlapping rules in SIEM systems lead to excessive false alerts, degrading analyst performance due to alert fatigue, and increase computational overhead and response latency for actual threats. As a result, optimizing SIEM rule sets is essential for efficient operations. Despite the importance of such optimization, research in this area is limited, with current practices relying on manual optimization methods that are both time-consuming and error-prone due to the scale and complexity of enterprise-level rule sets. To address this gap, we present RuleGenie, a novel large language model (LLM) aided recommender system designed to optimize SIEM rule sets. Our approach leverages transformer models' multi-head attention capabilities to generate SIEM rule embeddings, which are then analyzed using a similarity matching algorithm to identify the top-k most similar rules. The LLM then processes the rules identified, utilizing its information extraction, language understanding, and reasoning capabilities to analyze rule similarity, evaluate threat coverage and performance metrics, and deliver optimized recommendations for refining the rule set. By automating the rule optimization process, RuleGenie allows security teams to focus on more strategic tasks while enhancing the efficiency of SIEM systems and strengthening organizations' security posture. We evaluated RuleGenie on a comprehensive set of real-world SIEM rule formats, including Splunk, Sigma, and AQL (Ariel query language), demonstrating its platform-agnostic capabilities and adaptability across diverse security infrastructures. Our experimental results show that RuleGenie can effectively identify redundant rules, which in turn decreases false positive rates and enhances overall rule efficiency.</li>
</ul>

<h3>Title: Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free</h3>
<ul>
<li><strong>Authors: </strong>Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06708">https://arxiv.org/abs/2505.06708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06708">https://arxiv.org/pdf/2505.06708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06708]] Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free(https://arxiv.org/abs/2505.06708)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention. Yet, existing literature rarely examines the specific effects of gating. In this work, we conduct comprehensive experiments to systematically investigate gating-augmented softmax attention variants. Specifically, we perform a comprehensive comparison over 30 variants of 15B Mixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion token dataset. Our central finding is that a simple modification-applying a head-specific sigmoid gate after the Scaled Dot-Product Attention (SDPA)-consistently improves performance. This modification also enhances training stability, tolerates larger learning rates, and improves scaling properties. By comparing various gating positions and computational variants, we attribute this effectiveness to two key factors: (1) introducing non-linearity upon the low-rank mapping in the softmax attention, and (2) applying query-dependent sparse gating scores to modulate the SDPA output. Notably, we find this sparse gating mechanism mitigates 'attention sink' and enhances long-context extrapolation performance, and we also release related $\href{this https URL}{codes}$ and $\href{this https URL}{models}$ to facilitate future research.</li>
</ul>

<h3>Title: SimMIL: A Universal Weakly Supervised Pre-Training Framework for Multi-Instance Learning in Whole Slide Pathology Images</h3>
<ul>
<li><strong>Authors: </strong>Yicheng Song, Tiancheng Lin, Die Peng, Su Yang, Yi Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06710">https://arxiv.org/abs/2505.06710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06710">https://arxiv.org/pdf/2505.06710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06710]] SimMIL: A Universal Weakly Supervised Pre-Training Framework for Multi-Instance Learning in Whole Slide Pathology Images(https://arxiv.org/abs/2505.06710)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Various multi-instance learning (MIL) based approaches have been developed and successfully applied to whole-slide pathological images (WSI). Existing MIL methods emphasize the importance of feature aggregators, but largely neglect the instance-level representation learning. They assume that the availability of a pre-trained feature extractor can be directly utilized or fine-tuned, which is not always the case. This paper proposes to pre-train feature extractor for MIL via a weakly-supervised scheme, i.e., propagating the weak bag-level labels to the corresponding instances for supervised learning. To learn effective features for MIL, we further delve into several key components, including strong data augmentation, a non-linear prediction head and the robust loss function. We conduct experiments on common large-scale WSI datasets and find it achieves better performance than other pre-training schemes (e.g., ImageNet pre-training and self-supervised learning) in different downstream tasks. We further show the compatibility and scalability of the proposed scheme by deploying it in fine-tuning the pathological-specific models and pre-training on merged multiple datasets. To our knowledge, this is the first work focusing on the representation learning for MIL.</li>
</ul>

<h3>Title: Deeply Explainable Artificial Neural Network</h3>
<ul>
<li><strong>Authors: </strong>David Zucker</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06731">https://arxiv.org/abs/2505.06731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06731">https://arxiv.org/pdf/2505.06731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06731]] Deeply Explainable Artificial Neural Network(https://arxiv.org/abs/2505.06731)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>While deep learning models have demonstrated remarkable success in numerous domains, their black-box nature remains a significant limitation, especially in critical fields such as medical image analysis and inference. Existing explainability methods, such as SHAP, LIME, and Grad-CAM, are typically applied post hoc, adding computational overhead and sometimes producing inconsistent or ambiguous results. In this paper, we present the Deeply Explainable Artificial Neural Network (DxANN), a novel deep learning architecture that embeds explainability ante hoc, directly into the training process. Unlike conventional models that require external interpretation methods, DxANN is designed to produce per-sample, per-feature explanations as part of the forward pass. Built on a flow-based framework, it enables both accurate predictions and transparent decision-making, and is particularly well-suited for image-based tasks. While our focus is on medical imaging, the DxANN architecture is readily adaptable to other data modalities, including tabular and sequential data. DxANN marks a step forward toward intrinsically interpretable deep learning, offering a practical solution for applications where trust and accountability are essential.</li>
</ul>

<h3>Title: I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference</h3>
<ul>
<li><strong>Authors: </strong>Zibo Gao, Junjie Hu, Feng Guo, Yixin Zhang, Yinglong Han, Siyuan Liu, Haiyang Li, Zhiqiang Lv</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06738">https://arxiv.org/abs/2505.06738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06738">https://arxiv.org/pdf/2505.06738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06738]] I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference(https://arxiv.org/abs/2505.06738)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) that can be deployed locally have recently gained popularity for privacy-sensitive tasks, with companies such as Meta, Google, and Intel playing significant roles in their development. However, the security of local LLMs through the lens of hardware cache side-channels remains unexplored. In this paper, we unveil novel side-channel vulnerabilities in local LLM inference: token value and token position leakage, which can expose both the victim's input and output text, thereby compromising user privacy. Specifically, we found that adversaries can infer the token values from the cache access patterns of the token embedding operation, and deduce the token positions from the timing of autoregressive decoding phases. To demonstrate the potential of these leaks, we design a novel eavesdropping attack framework targeting both open-source and proprietary LLM inference systems. The attack framework does not directly interact with the victim's LLM and can be executed without privilege. We evaluate the attack on a range of practical local LLM deployments (e.g., Llama, Falcon, and Gemma), and the results show that our attack achieves promising accuracy. The restored output and input text have an average edit distance of 5.2% and 17.3% to the ground truth, respectively. Furthermore, the reconstructed texts achieve average cosine similarity scores of 98.7% (input) and 98.0% (output).</li>
</ul>

<h3>Title: Symbolic Rule Extraction from Attention-Guided Sparse Representations in Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Parth Padalkar, Gopal Gupta</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06745">https://arxiv.org/abs/2505.06745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06745">https://arxiv.org/pdf/2505.06745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06745]] Symbolic Rule Extraction from Attention-Guided Sparse Representations in Vision Transformers(https://arxiv.org/abs/2505.06745)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Recent neuro-symbolic approaches have successfully extracted symbolic rule-sets from CNN-based models to enhance interpretability. However, applying similar techniques to Vision Transformers (ViTs) remains challenging due to their lack of modular concept detectors and reliance on global self-attention mechanisms. We propose a framework for symbolic rule extraction from ViTs by introducing a sparse concept layer inspired by Sparse Autoencoders (SAEs). This linear layer operates on attention-weighted patch representations and learns a disentangled, binarized representation in which individual neurons activate for high-level visual concepts. To encourage interpretability, we apply a combination of L1 sparsity, entropy minimization, and supervised contrastive loss. These binarized concept activations are used as input to the FOLD-SE-M algorithm, which generates a rule-set in the form of logic programs. Our method achieves a 5.14% better classification accuracy than the standard ViT while enabling symbolic reasoning. Crucially, the extracted rule-set is not merely post-hoc but acts as a logic-based decision layer that operates directly on the sparse concept representations. The resulting programs are concise and semantically meaningful. This work is the first to extract executable logic programs from ViTs using sparse symbolic representations. It bridges the gap between transformer-based vision models and symbolic logic programming, providing a step forward in interpretable and verifiable neuro-symbolic AI.</li>
</ul>

<h3>Title: DPolicy: Managing Privacy Risks Across Multiple Releases with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Küchler, Alexander Viand, Hidde Lycklama, Anwar Hithnawi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06747">https://arxiv.org/abs/2505.06747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06747">https://arxiv.org/pdf/2505.06747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06747]] DPolicy: Managing Privacy Risks Across Multiple Releases with Differential Privacy(https://arxiv.org/abs/2505.06747)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Differential Privacy (DP) has emerged as a robust framework for privacy-preserving data releases and has been successfully applied in high-profile cases, such as the 2020 US Census. However, in organizational settings, the use of DP remains largely confined to isolated data releases. This approach restricts the potential of DP to serve as a framework for comprehensive privacy risk management at an organizational level. Although one might expect that the cumulative privacy risk of isolated releases could be assessed using DP's compositional property, in practice, individual DP guarantees are frequently tailored to specific releases, making it difficult to reason about their interaction or combined impact. At the same time, less tailored DP guarantees, which compose more easily, also offer only limited insight because they lead to excessively large privacy budgets that convey limited meaning. To address these limitations, we present DPolicy, a system designed to manage cumulative privacy risks across multiple data releases using DP. Unlike traditional approaches that treat each release in isolation or rely on a single (global) DP guarantee, our system employs a flexible framework that considers multiple DP guarantees simultaneously, reflecting the diverse contexts and scopes typical of real-world DP deployments. DPolicy introduces a high-level policy language to formalize privacy guarantees, making traditionally implicit assumptions on scopes and contexts explicit. By deriving the DP guarantees required to enforce complex privacy semantics from these high-level policies, DPolicy enables fine-grained privacy risk management on an organizational scale. We implement and evaluate DPolicy, demonstrating how it mitigates privacy risks that can emerge without comprehensive, organization-wide privacy risk management.</li>
</ul>

<h3>Title: Privacy-aware Berrut Approximated Coded Computing applied to general distributed learning</h3>
<ul>
<li><strong>Authors: </strong>Xavier Martínez-Luaña, Manuel Fernández-Veiga, Rebeca P. Díaz-Redondo, Ana Fernández-Vilas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06759">https://arxiv.org/abs/2505.06759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06759">https://arxiv.org/pdf/2505.06759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06759]] Privacy-aware Berrut Approximated Coded Computing applied to general distributed learning(https://arxiv.org/abs/2505.06759)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>Coded computing is one of the techniques that can be used for privacy protection in Federated Learning. However, most of the constructions used for coded computing work only under the assumption that the computations involved are exact, generally restricted to special classes of functions, and require quantized inputs. This paper considers the use of Private Berrut Approximate Coded Computing (PBACC) as a general solution to add strong but non-perfect privacy to federated learning. We derive new adapted PBACC algorithms for centralized aggregation, secure distributed training with centralized data, and secure decentralized training with decentralized data, thus enlarging significantly the applications of the method and the existing privacy protection tools available for these paradigms. Particularly, PBACC can be used robustly to attain privacy guarantees in decentralized federated learning for a variety of models. Our numerical results show that the achievable quality of different learning models (convolutional neural networks, variational autoencoders, and Cox regression) is minimally altered by using these new computing schemes, and that the privacy leakage can be bounded strictly to less than a fraction of one bit per participant. Additionally, the computational cost of the encoding and decoding processes depends only of the degree of decentralization of the data.</li>
</ul>

<h3>Title: Learning Graph Representation of Agent Diffuser</h3>
<ul>
<li><strong>Authors: </strong>Youcef Djenouri, Nassim Belmecheri, Tomasz Michalak, Jan Dubiński, Ahmed Nabil Belbachir, Anis Yazidi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06761">https://arxiv.org/abs/2505.06761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06761">https://arxiv.org/pdf/2505.06761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06761]] Learning Graph Representation of Agent Diffuser(https://arxiv.org/abs/2505.06761)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion-based generative models have significantly advanced text-to-image synthesis, demonstrating impressive text comprehension and zero-shot generalization. These models refine images from random noise based on textual prompts, with initial reliance on text input shifting towards enhanced visual fidelity over time. This transition suggests that static model parameters might not optimally address the distinct phases of generation. We introduce LGR-AD (Learning Graph Representation of Agent Diffusers), a novel multi-agent system designed to improve adaptability in dynamic computer vision tasks. LGR-AD models the generation process as a distributed system of interacting agents, each representing an expert sub-model. These agents dynamically adapt to varying conditions and collaborate through a graph neural network that encodes their relationships and performance metrics. Our approach employs a coordination mechanism based on top-$k$ maximum spanning trees, optimizing the generation process. Each agent's decision-making is guided by a meta-model that minimizes a novel loss function, balancing accuracy and diversity. Theoretical analysis and extensive empirical evaluations show that LGR-AD outperforms traditional diffusion models across various benchmarks, highlighting its potential for scalable and flexible solutions in complex image generation tasks. Code is available at: this https URL</li>
</ul>

<h3>Title: Utilizing LLMs to Investigate the Disputed Role of Evidence in Electronic Cigarette Health Policy Formation in Australia and the UK</h3>
<ul>
<li><strong>Authors: </strong>Damian Curran, Brian Chapman, Mike Conway</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06782">https://arxiv.org/abs/2505.06782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06782">https://arxiv.org/pdf/2505.06782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06782]] Utilizing LLMs to Investigate the Disputed Role of Evidence in Electronic Cigarette Health Policy Formation in Australia and the UK(https://arxiv.org/abs/2505.06782)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Australia and the UK have developed contrasting approaches to the regulation of electronic cigarettes, with - broadly speaking - Australia adopting a relatively restrictive approach and the UK adopting a more permissive approach. Notably, these divergent policies were developed from the same broad evidence base. In this paper, to investigate differences in how the two jurisdictions manage and present evidence, we developed and evaluated a Large Language Model-based sentence classifier to perform automated analyses of electronic cigarette-related policy documents drawn from official Australian and UK legislative processes (109 documents in total). Specifically, we utilized GPT-4 to automatically classify sentences based on whether they contained claims that e-cigarettes were broadly helpful or harmful for public health. Our LLM-based classifier achieved an F-score of 0.9. Further, when applying the classifier to our entire sentence-level corpus, we found that Australian legislative documents show a much higher proportion of harmful statements, and a lower proportion of helpful statements compared to the expected values, with the opposite holding for the UK. In conclusion, this work utilized an LLM-based approach to provide evidence to support the contention that - drawing on the same evidence base - Australian ENDS-related policy documents emphasize the harms associated with ENDS products and UK policy documents emphasize the benefits. Further, our approach provides a starting point for using LLM-based methods to investigate the complex relationship between evidence and health policy formation.</li>
</ul>

<h3>Title: Multimodal Fake News Detection: MFND Dataset and Shallow-Deep Multitask Learning</h3>
<ul>
<li><strong>Authors: </strong>Ye Zhu, Yunan Wang, Zitong Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06796">https://arxiv.org/abs/2505.06796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06796">https://arxiv.org/pdf/2505.06796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06796]] Multimodal Fake News Detection: MFND Dataset and Shallow-Deep Multitask Learning(https://arxiv.org/abs/2505.06796)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Multimodal news contains a wealth of information and is easily affected by deepfake modeling attacks. To combat the latest image and text generation methods, we present a new Multimodal Fake News Detection dataset (MFND) containing 11 manipulated types, designed to detect and localize highly authentic fake news. Furthermore, we propose a Shallow-Deep Multitask Learning (SDML) model for fake news, which fully uses unimodal and mutual modal features to mine the intrinsic semantics of news. Under shallow inference, we propose the momentum distillation-based light punishment contrastive learning for fine-grained uniform spatial image and text semantic alignment, and an adaptive cross-modal fusion module to enhance mutual modal features. Under deep inference, we design a two-branch framework to augment the image and text unimodal features, respectively merging with mutual modalities features, for four predictions via dedicated detection and localization projections. Experiments on both mainstream and our proposed datasets demonstrate the superiority of the model. Codes and dataset are released at this https URL.</li>
</ul>

<h3>Title: Topology Guidance: Controlling the Outputs of Generative Models via Vector Field Topology</h3>
<ul>
<li><strong>Authors: </strong>Xiaohan Wang, Matthew Berger</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06804">https://arxiv.org/abs/2505.06804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06804">https://arxiv.org/pdf/2505.06804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06804]] Topology Guidance: Controlling the Outputs of Generative Models via Vector Field Topology(https://arxiv.org/abs/2505.06804)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>For domains that involve numerical simulation, it can be computationally expensive to run an ensemble of simulations spanning a parameter space of interest to a user. To this end, an attractive surrogate for simulation is the generative modeling of fields produced by an ensemble, allowing one to synthesize fields in a computationally cheap, yet accurate, manner. However, for the purposes of visual analysis, a limitation of generative models is their lack of control, as it is unclear what one should expect when sampling a field from a model. In this paper we study how to make generative models of fields more controllable, so that users can specify features of interest, in particular topological features, that they wish to see in the output. We propose topology guidance, a method for guiding the sampling process of a generative model, specifically a diffusion model, such that a topological description specified as input is satisfied in the generated output. Central to our method, we couple a coordinate-based neural network used to represent fields, with a diffusion model used for generation. We show how to use topologically-relevant signals provided by the coordinate-based network to help guide the denoising process of a diffusion model. This enables us to faithfully represent a user's specified topology, while ensuring that the output field remains within the generative data distribution. Specifically, we study 2D vector field topology, evaluating our method over an ensemble of fluid flows, where we show that generated vector fields faithfully adhere to the location, and type, of critical points over the spatial domain. We further show the benefits of our method in aiding the comparison of ensembles, allowing one to explore commonalities and differences in distributions along prescribed topological features.</li>
</ul>

<h3>Title: ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification</h3>
<ul>
<li><strong>Authors: </strong>Dipayan Saha, Hasan Al Shaikh, Shams Tarek, Farimah Farahmandi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06821">https://arxiv.org/abs/2505.06821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06821">https://arxiv.org/pdf/2505.06821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06821]] ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification(https://arxiv.org/abs/2505.06821)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios.</li>
</ul>

<h3>Title: Hunting the Ghost: Towards Automatic Mining of IoT Hidden Services</h3>
<ul>
<li><strong>Authors: </strong>Shuaike Dong, Siyu Shen, Zhou Li, Kehuan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06822">https://arxiv.org/abs/2505.06822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06822">https://arxiv.org/pdf/2505.06822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06822]] Hunting the Ghost: Towards Automatic Mining of IoT Hidden Services(https://arxiv.org/abs/2505.06822)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In this paper, we proposes an automatic firmware analysis tool targeting at finding hidden services that may be potentially harmful to the IoT devices. Our approach uses static analysis and symbolic execution to search and filter services that are transparent to normal users but explicit to experienced attackers. A prototype is built and evaluated against a dataset of IoT firmware, and The evaluation shows our tool can find the suspicious hidden services effectively.</li>
</ul>

<h3>Title: Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06827">https://arxiv.org/abs/2505.06827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06827">https://arxiv.org/pdf/2505.06827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06827]] Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking(https://arxiv.org/abs/2505.06827)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Watermarking AI-generated text is critical for combating misuse. Yet recent theoretical work argues that any watermark can be erased via random walk attacks that perturb text while preserving quality. However, such attacks rely on two key assumptions: (1) rapid mixing (watermarks dissolve quickly under perturbations) and (2) reliable quality preservation (automated quality oracles perfectly guide edits). Through large-scale experiments and human-validated assessments, we find mixing is slow: 100% of perturbed texts retain traces of their origin after hundreds of edits, defying rapid mixing. Oracles falter, as state-of-the-art quality detectors misjudge edits (77% accuracy), compounding errors during attacks. Ultimately, attacks underperform: automated walks remove watermarks just 26% of the time -- dropping to 10% under human quality review. These findings challenge the inevitability of watermark removal. Instead, practical barriers -- slow mixing and imperfect quality control -- reveal watermarking to be far more robust than theoretical models suggest. The gap between idealized attacks and real-world feasibility underscores the need for stronger watermarking methods and more realistic attack models.</li>
</ul>

<h3>Title: Fine-Grained Bias Exploration and Mitigation for Group-Robust Classification</h3>
<ul>
<li><strong>Authors: </strong>Miaoyun Zhao, Qiang Zhang, Chenrong Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06831">https://arxiv.org/abs/2505.06831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06831">https://arxiv.org/pdf/2505.06831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06831]] Fine-Grained Bias Exploration and Mitigation for Group-Robust Classification(https://arxiv.org/abs/2505.06831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Achieving group-robust generalization in the presence of spurious correlations remains a significant challenge, particularly when bias annotations are unavailable. Recent studies on Class-Conditional Distribution Balancing (CCDB) reveal that spurious correlations often stem from mismatches between the class-conditional and marginal distributions of bias attributes. They achieve promising results by addressing this issue through simple distribution matching in a bias-agnostic manner. However, CCDB approximates each distribution using a single Gaussian, which is overly simplistic and rarely holds in real-world applications. To address this limitation, we propose a novel method called Bias Exploration via Overfitting (BEO), which captures each distribution in greater detail by modeling it as a mixture of latent groups. Building on these group-level descriptions, we introduce a fine-grained variant of CCDB, termed FG-CCDB, which performs more precise distribution matching and balancing within each group. Through group-level reweighting, FG-CCDB learns sample weights from a global perspective, achieving stronger mitigation of spurious correlations without incurring substantial storage or computational costs. Extensive experiments demonstrate that BEO serves as a strong proxy for ground-truth bias annotations and can be seamlessly integrated with bias-supervised methods. Moreover, when combined with FG-CCDB, our method performs on par with bias-supervised approaches on binary classification tasks and significantly outperforms them in highly biased multi-class scenarios.</li>
</ul>

<h3>Title: "Explain, Don't Just Warn!" -- A Real-Time Framework for Generating Phishing Warnings with Contextual Cues</h3>
<ul>
<li><strong>Authors: </strong>Sayak Saha Roy, Cesar Torres, Shirin Nilizadeh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06836">https://arxiv.org/abs/2505.06836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06836">https://arxiv.org/pdf/2505.06836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06836]] "Explain, Don't Just Warn!" -- A Real-Time Framework for Generating Phishing Warnings with Contextual Cues(https://arxiv.org/abs/2505.06836)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Anti-phishing tools typically display generic warnings that offer users limited explanation on why a website is considered malicious, which can prevent end-users from developing the mental models needed to recognize phishing cues on their own. This becomes especially problematic when these tools inevitably fail - particularly against evasive threats, and users are found to be ill-equipped to identify and avoid them independently. To address these limitations, we present PhishXplain (PXP), a real-time explainable phishing warning system designed to augment existing detection mechanisms. PXP empowers users by clearly articulating why a site is flagged as malicious, highlighting suspicious elements using a memory-efficient implementation of LLaMA 3.2. It utilizes a structured two-step prompt architecture to identify phishing features, generate contextual explanations, and render annotated screenshots that visually reinforce the warning. Longitudinally implementing PhishXplain over a month on 7,091 live phishing websites, we found that it can generate warnings for 94% of the sites, with a correctness of 96%. We also evaluated PhishXplain through a user study with 150 participants split into two groups: one received conventional, generic warnings, while the other interacted with PXP's explainable alerts. Participants who received the explainable warnings not only demonstrated a significantly better understanding of phishing indicators but also achieved higher accuracy in identifying phishing threats, even without any warning. Moreover, they reported greater satisfaction and trust in the warnings themselves. These improvements were especially pronounced among users with lower initial levels of cybersecurity proficiency and awareness. To encourage the adoption of this framework, we release PhishXplain as an open-source browser extension.</li>
</ul>

<h3>Title: Visual Instruction Tuning with Chain of Region-of-Interest</h3>
<ul>
<li><strong>Authors: </strong>Yixin Chen, Shuai Zhang, Boran Han, Bernie Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06840">https://arxiv.org/abs/2505.06840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06840">https://arxiv.org/pdf/2505.06840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06840]] Visual Instruction Tuning with Chain of Region-of-Interest(https://arxiv.org/abs/2505.06840)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>High-resolution (HR) images are pivotal for enhancing the recognition and understanding capabilities of multimodal large language models (MLLMs). However, directly increasing image resolution can significantly escalate computational demands. In this study, we propose a method called Chain of Region-of-Interest (CoRoI) for Visual Instruction Tuning, aimed at alleviating the computational burden associated with high-resolution images for MLLMs. Drawing inspiration from the selective nature of the human visual system, we recognize that not all regions within high-resolution images carry equal importance. CoRoI seeks to identify and prioritize the most informative regions, thereby enhancing multimodal visual comprehension and recognition while circumventing the need for processing lengthy HR image tokens. Through extensive experiments on 11 benchmarks, we validate the efficacy of CoRoI across varying sizes, ranging from 7B to 34B in parameters. Our models consistently demonstrate superior performance across diverse multimodal benchmarks and tasks. Notably, our method outperforms LLaVA-NeXT on almost all benchmarks and our finetuned 34B model surpasses proprietary methods like Gemini Pro 1.0 on six benchmarks, as well as outperforming GPT-4V on MMB, SEED-I, and MME.</li>
</ul>

<h3>Title: Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety</h3>
<ul>
<li><strong>Authors: </strong>Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06843">https://arxiv.org/abs/2505.06843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06843">https://arxiv.org/pdf/2505.06843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06843]] Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety(https://arxiv.org/abs/2505.06843)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have uncovered a troubling vulnerability in the fine-tuning stage of large language models (LLMs): even fine-tuning on entirely benign datasets can lead to a significant increase in the harmfulness of LLM outputs. Building on this finding, our red teaming study takes this threat one step further by developing a more effective attack. Specifically, we analyze and identify samples within benign datasets that contribute most to safety degradation, then fine-tune LLMs exclusively on these samples. We approach this problem from an outlier detection perspective and propose Self-Inf-N, to detect and extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs on 100 outlier samples selected by Self-Inf-N in the benign datasets severely compromises LLM safety alignment. Extensive experiments across seven mainstream LLMs demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios. Alarmingly, our results indicate that most existing mitigation strategies fail to defend against this attack, underscoring the urgent need for more robust alignment safeguards. Codes are available at this https URL.</li>
</ul>

<h3>Title: Predictive Digital Twins for Thermal Management Using Machine Learning and Reduced-Order Models</h3>
<ul>
<li><strong>Authors: </strong>Tamilselvan Subramani, Sebastian Bartscher</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06849">https://arxiv.org/abs/2505.06849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06849">https://arxiv.org/pdf/2505.06849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06849]] Predictive Digital Twins for Thermal Management Using Machine Learning and Reduced-Order Models(https://arxiv.org/abs/2505.06849)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Digital twins enable real-time simulation and prediction in engineering systems. This paper presents a novel framework for predictive digital twins of a headlamp heatsink, integrating physics-based reduced-order models (ROMs) from computational fluid dynamics (CFD) with supervised machine learning. A component-based ROM library, derived via proper orthogonal decomposition (POD), captures thermal dynamics efficiently. Machine learning models, including Decision Trees, k-Nearest Neighbors, Support Vector Regression (SVR), and Neural Networks, predict optimal ROM configurations, enabling rapid digital twin updates. The Neural Network achieves a mean absolute error (MAE) of 54.240, outperforming other models. Quantitative comparisons of predicted and original values demonstrate high accuracy. This scalable, interpretable framework advances thermal management in automotive systems, supporting robust design and predictive maintenance.</li>
</ul>

<h3>Title: Joint Low-level and High-level Textual Representation Learning with Multiple Masking Strategies</h3>
<ul>
<li><strong>Authors: </strong>Zhengmi Tang, Yuto Mitsui, Tomo Miyazaki, Shinichiro Omachi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06855">https://arxiv.org/abs/2505.06855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06855">https://arxiv.org/pdf/2505.06855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06855]] Joint Low-level and High-level Textual Representation Learning with Multiple Masking Strategies(https://arxiv.org/abs/2505.06855)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Most existing text recognition methods are trained on large-scale synthetic datasets due to the scarcity of labeled real-world datasets. Synthetic images, however, cannot faithfully reproduce real-world scenarios, such as uneven illumination, irregular layout, occlusion, and degradation, resulting in performance disparities when handling complex real-world images. Recent self-supervised learning techniques, notably contrastive learning and masked image modeling (MIM), narrow this domain gap by exploiting unlabeled real text images. This study first analyzes the original Masked AutoEncoder (MAE) and observes that random patch masking predominantly captures low-level textural features but misses high-level contextual representations. To fully exploit the high-level contextual representations, we introduce random blockwise and span masking in the text recognition task. These strategies can mask the continuous image patches and completely remove some characters, forcing the model to infer relationships among characters within a word. Our Multi-Masking Strategy (MMS) integrates random patch, blockwise, and span masking into the MIM frame, which jointly learns low and high-level textual representations. After fine-tuning with real data, MMS outperforms the state-of-the-art self-supervised methods in various text-related tasks, including text recognition, segmentation, and text-image super-resolution.</li>
</ul>

<h3>Title: DP-TRAE: A Dual-Phase Merging Transferable Reversible Adversarial Example for Image Privacy Protection</h3>
<ul>
<li><strong>Authors: </strong>Xia Du, Jiajie Zhu, Jizhe Zhou, Chi-man Pun, Zheng Lin, Cong Wu, Zhe Chen, Jun Luo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06860">https://arxiv.org/abs/2505.06860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06860">https://arxiv.org/pdf/2505.06860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06860]] DP-TRAE: A Dual-Phase Merging Transferable Reversible Adversarial Example for Image Privacy Protection(https://arxiv.org/abs/2505.06860)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>In the field of digital security, Reversible Adversarial Examples (RAE) combine adversarial attacks with reversible data hiding techniques to effectively protect sensitive data and prevent unauthorized analysis by malicious Deep Neural Networks (DNNs). However, existing RAE techniques primarily focus on white-box attacks, lacking a comprehensive evaluation of their effectiveness in black-box scenarios. This limitation impedes their broader deployment in complex, dynamic environments. Further more, traditional black-box attacks are often characterized by poor transferability and high query costs, significantly limiting their practical applicability. To address these challenges, we propose the Dual-Phase Merging Transferable Reversible Attack method, which generates highly transferable initial adversarial perturbations in a white-box model and employs a memory augmented black-box strategy to effectively mislead target mod els. Experimental results demonstrate the superiority of our approach, achieving a 99.0% attack success rate and 100% recovery rate in black-box scenarios, highlighting its robustness in privacy protection. Moreover, we successfully implemented a black-box attack on a commercial model, further substantiating the potential of this approach for practical use.</li>
</ul>

<h3>Title: Enhancing Time Series Forecasting via a Parallel Hybridization of ARIMA and Polynomial Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Thanh Son Nguyen, Van Thanh Nguyen, Dang Minh Duc Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06874">https://arxiv.org/abs/2505.06874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06874">https://arxiv.org/pdf/2505.06874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06874]] Enhancing Time Series Forecasting via a Parallel Hybridization of ARIMA and Polynomial Classifiers(https://arxiv.org/abs/2505.06874)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series forecasting has attracted significant attention, leading to the de-velopment of a wide range of approaches, from traditional statistical meth-ods to advanced deep learning models. Among them, the Auto-Regressive Integrated Moving Average (ARIMA) model remains a widely adopted linear technique due to its effectiveness in modeling temporal dependencies in economic, industrial, and social data. On the other hand, polynomial classifi-ers offer a robust framework for capturing non-linear relationships and have demonstrated competitive performance in domains such as stock price pre-diction. In this study, we propose a hybrid forecasting approach that inte-grates the ARIMA model with a polynomial classifier to leverage the com-plementary strengths of both models. The hybrid method is evaluated on multiple real-world time series datasets spanning diverse domains. Perfor-mance is assessed based on forecasting accuracy and computational effi-ciency. Experimental results reveal that the proposed hybrid model consist-ently outperforms the individual models in terms of prediction accuracy, al-beit with a modest increase in execution time.</li>
</ul>

<h3>Title: NeuRN: Neuro-inspired Domain Generalization for Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Hamd Jalil, Ahmed Qazi, Asim Iqbal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06881">https://arxiv.org/abs/2505.06881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06881">https://arxiv.org/pdf/2505.06881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06881]] NeuRN: Neuro-inspired Domain Generalization for Image Classification(https://arxiv.org/abs/2505.06881)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Domain generalization in image classification is a crucial challenge, with models often failing to generalize well across unseen datasets. We address this issue by introducing a neuro-inspired Neural Response Normalization (NeuRN) layer which draws inspiration from neurons in the mammalian visual cortex, which aims to enhance the performance of deep learning architectures on unseen target domains by training deep learning models on a source domain. The performance of these models is considered as a baseline and then compared against models integrated with NeuRN on image classification tasks. We perform experiments across a range of deep learning architectures, including ones derived from Neural Architecture Search and Vision Transformer. Additionally, in order to shortlist models for our experiment from amongst the vast range of deep neural networks available which have shown promising results, we also propose a novel method that uses the Needleman-Wunsch algorithm to compute similarity between deep learning architectures. Our results demonstrate the effectiveness of NeuRN by showing improvement against baseline in cross-domain image classification tasks. Our framework attempts to establish a foundation for future neuro-inspired deep learning models.</li>
</ul>

<h3>Title: Mice to Machines: Neural Representations from Visual Cortex for Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Qazi, Hamd Jalil, Asim Iqbal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06886">https://arxiv.org/abs/2505.06886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06886">https://arxiv.org/pdf/2505.06886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06886]] Mice to Machines: Neural Representations from Visual Cortex for Domain Generalization(https://arxiv.org/abs/2505.06886)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The mouse is one of the most studied animal models in the field of systems neuroscience. Understanding the generalized patterns and decoding the neural representations that are evoked by the diverse range of natural scene stimuli in the mouse visual cortex is one of the key quests in computational vision. In recent years, significant parallels have been drawn between the primate visual cortex and hierarchical deep neural networks. However, their generalized efficacy in understanding mouse vision has been limited. In this study, we investigate the functional alignment between the mouse visual cortex and deep learning models for object classification tasks. We first introduce a generalized representational learning strategy that uncovers a striking resemblance between the functional mapping of the mouse visual cortex and high-performing deep learning models on both top-down (population-level) and bottom-up (single cell-level) scenarios. Next, this representational similarity across the two systems is further enhanced by the addition of Neural Response Normalization (NeuRN) layer, inspired by the activation profile of excitatory and inhibitory neurons in the visual cortex. To test the performance effect of NeuRN on real-world tasks, we integrate it into deep learning models and observe significant improvements in their robustness against data shifts in domain generalization tasks. Our work proposes a novel framework for comparing the functional architecture of the mouse visual cortex with deep learning models. Our findings carry broad implications for the development of advanced AI models that draw inspiration from the mouse visual cortex, suggesting that these models serve as valuable tools for studying the neural representations of the mouse visual cortex and, as a result, enhancing their performance on real-world tasks.</li>
</ul>

<h3>Title: IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method</h3>
<ul>
<li><strong>Authors: </strong>Mihyeon Kim, Juhyoung Park, Youngbin Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06889">https://arxiv.org/abs/2505.06889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06889">https://arxiv.org/pdf/2505.06889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06889]] IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method(https://arxiv.org/abs/2505.06889)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Pre-trained Language Models (PLMs) have achieved remarkable performance on diverse NLP tasks through pre-training and fine-tuning. However, fine-tuning the model with a large number of parameters on limited downstream datasets often leads to vulnerability to adversarial attacks, causing overfitting of the model on standard datasets. To address these issues, we propose IM-BERT from the perspective of a dynamic system by conceptualizing a layer of BERT as a solution of Ordinary Differential Equations (ODEs). Under the situation of initial value perturbation, we analyze the numerical stability of two main numerical ODE solvers: the explicit and implicit Euler approaches. Based on these analyses, we introduce a numerically robust IM-connection incorporating BERT's layers. This strategy enhances the robustness of PLMs against adversarial attacks, even in low-resource scenarios, without introducing additional parameters or adversarial training strategies. Experimental results on the adversarial GLUE (AdvGLUE) dataset validate the robustness of IM-BERT under various conditions. Compared to the original BERT, IM-BERT exhibits a performance improvement of approximately 8.3\%p on the AdvGLUE dataset. Furthermore, in low-resource scenarios, IM-BERT outperforms BERT by achieving 5.9\%p higher accuracy.</li>
</ul>

<h3>Title: Image Classification Using a Diffusion Model as a Pre-Training Model</h3>
<ul>
<li><strong>Authors: </strong>Kosuke Ukita, Ye Xiaolong, Tsuyoshi Okita</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06890">https://arxiv.org/abs/2505.06890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06890">https://arxiv.org/pdf/2505.06890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06890]] Image Classification Using a Diffusion Model as a Pre-Training Model(https://arxiv.org/abs/2505.06890)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a diffusion model that integrates a representation-conditioning mechanism, where the representations derived from a Vision Transformer (ViT) are used to condition the internal process of a Transformer-based diffusion model. This approach enables representation-conditioned data generation, addressing the challenge of requiring large-scale labeled datasets by leveraging self-supervised learning on unlabeled data. We evaluate our method through a zero-shot classification task for hematoma detection in brain imaging. Compared to the strong contrastive learning baseline, DINOv2, our method achieves a notable improvement of +6.15% in accuracy and +13.60% in F1-score, demonstrating its effectiveness in image classification.</li>
</ul>

<h3>Title: Learning Soft Sparse Shapes for Efficient Time-Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Zhen Liu, Yicheng Luo, Boyuan Li, Emadeldeen Eldele, Min Wu, Qianli Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06892">https://arxiv.org/abs/2505.06892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06892">https://arxiv.org/pdf/2505.06892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06892]] Learning Soft Sparse Shapes for Efficient Time-Series Classification(https://arxiv.org/abs/2505.06892)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a \textbf{Soft} sparse \textbf{Shape}s (\textbf{SoftShape}) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results.</li>
</ul>

<h3>Title: NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Qazi, Abdul Basit, Asim Iqbal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06894">https://arxiv.org/abs/2505.06894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06894">https://arxiv.org/pdf/2505.06894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06894]] NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization(https://arxiv.org/abs/2505.06894)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural Radiance Fields (NeRF) have significantly advanced the field of novel view synthesis, yet their generalization across diverse scenes and conditions remains challenging. Addressing this, we propose the integration of a novel brain-inspired normalization technique Neural Generalization (NeuGen) into leading NeRF architectures which include MVSNeRF and GeoNeRF. NeuGen extracts the domain-invariant features, thereby enhancing the models' generalization capabilities. It can be seamlessly integrated into NeRF architectures and cultivates a comprehensive feature set that significantly improves accuracy and robustness in image rendering. Through this integration, NeuGen shows improved performance on benchmarks on diverse datasets across state-of-the-art NeRF architectures, enabling them to generalize better across varied scenes. Our comprehensive evaluations, both quantitative and qualitative, confirm that our approach not only surpasses existing models in generalizability but also markedly improves rendering quality. Our work exemplifies the potential of merging neuroscientific principles with deep learning frameworks, setting a new precedent for enhanced generalizability and efficiency in novel view synthesis. A demo of our study is available at this https URL.</li>
</ul>

<h3>Title: Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Honglong Yang, Shanshan Song, Yi Qin, Lehan Wang, Haonan Wang, Xinpeng Ding, Qixiang Zhang, Bodong Du, Xiaomeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06898">https://arxiv.org/abs/2505.06898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06898">https://arxiv.org/pdf/2505.06898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06898]] Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration(https://arxiv.org/abs/2505.06898)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Generalist Medical AI (GMAI) systems have demonstrated expert-level performance in biomedical perception tasks, yet their clinical utility remains limited by inadequate multi-modal explainability and suboptimal prognostic capabilities. Here, we present XMedGPT, a clinician-centric, multi-modal AI assistant that integrates textual and visual interpretability to support transparent and trustworthy medical decision-making. XMedGPT not only produces accurate diagnostic and descriptive outputs, but also grounds referenced anatomical sites within medical images, bridging critical gaps in interpretability and enhancing clinician usability. To support real-world deployment, we introduce a reliability indexing mechanism that quantifies uncertainty through consistency-based assessment via interactive question-answering. We validate XMedGPT across four pillars: multi-modal interpretability, uncertainty quantification, and prognostic modeling, and rigorous benchmarking. The model achieves an IoU of 0.703 across 141 anatomical regions, and a Kendall's tau-b of 0.479, demonstrating strong alignment between visual rationales and clinical outcomes. For uncertainty estimation, it attains an AUC of 0.862 on visual question answering and 0.764 on radiology report generation. In survival and recurrence prediction for lung and glioma cancers, it surpasses prior leading models by 26.9%, and outperforms GPT-4o by 25.0%. Rigorous benchmarking across 347 datasets covers 40 imaging modalities and external validation spans 4 anatomical systems confirming exceptional generalizability, with performance gains surpassing existing GMAI by 20.7% for in-domain evaluation and 16.7% on 11,530 in-house data evaluation. Together, XMedGPT represents a significant leap forward in clinician-centric AI integration, offering trustworthy and scalable support for diverse healthcare applications.</li>
</ul>

<h3>Title: CheXLearner: Text-Guided Fine-Grained Representation Learning for Progression Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuanzhuo Wang, Junwen Duan, Xinyu Li, Jianxin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06903">https://arxiv.org/abs/2505.06903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06903">https://arxiv.org/pdf/2505.06903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06903]] CheXLearner: Text-Guided Fine-Grained Representation Learning for Progression Detection(https://arxiv.org/abs/2505.06903)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Temporal medical image analysis is essential for clinical decision-making, yet existing methods either align images and text at a coarse level - causing potential semantic mismatches - or depend solely on visual information, lacking medical semantic integration. We present CheXLearner, the first end-to-end framework that unifies anatomical region detection, Riemannian manifold-based structure alignment, and fine-grained regional semantic guidance. Our proposed Med-Manifold Alignment Module (Med-MAM) leverages hyperbolic geometry to robustly align anatomical structures and capture pathologically meaningful discrepancies across temporal chest X-rays. By introducing regional progression descriptions as supervision, CheXLearner achieves enhanced cross-modal representation learning and supports dynamic low-level feature optimization. Experiments show that CheXLearner achieves 81.12% (+17.2%) average accuracy and 80.32% (+11.05%) F1-score on anatomical region progression detection - substantially outperforming state-of-the-art baselines, especially in structurally complex regions. Additionally, our model attains a 91.52% average AUC score in downstream disease classification, validating its superior feature representation.</li>
</ul>

<h3>Title: EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Mou, Chen Qian, Wei Liu, Xuanjing Huang, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06904">https://arxiv.org/abs/2505.06904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06904">https://arxiv.org/pdf/2505.06904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06904]] EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation(https://arxiv.org/abs/2505.06904)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated an impressive ability to role-play humans and replicate complex social dynamics. While large-scale social simulations are gaining increasing attention, they still face significant challenges, particularly regarding high time and computation costs. Existing solutions, such as distributed mechanisms or hybrid agent-based model (ABM) integrations, either fail to address inference costs or compromise accuracy and generalizability. To this end, we propose EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation. EcoLANG operates in two stages: (1) language evolution, where we filter synonymous words and optimize sentence-level rules through natural selection, and (2) language utilization, where agents in social simulations communicate using the evolved language. Experimental results demonstrate that EcoLANG reduces token consumption by over 20%, enhancing efficiency without sacrificing simulation accuracy.</li>
</ul>

<h3>Title: Enhancing Monocular Height Estimation via Sparse LiDAR-Guided Correction</h3>
<ul>
<li><strong>Authors: </strong>Jian Song, Hongruixuan Chen, Naoto Yokoya</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06905">https://arxiv.org/abs/2505.06905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06905">https://arxiv.org/pdf/2505.06905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06905]] Enhancing Monocular Height Estimation via Sparse LiDAR-Guided Correction(https://arxiv.org/abs/2505.06905)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Monocular height estimation (MHE) from very-high-resolution (VHR) remote sensing imagery via deep learning is notoriously challenging due to the lack of sufficient structural information. Conventional digital elevation models (DEMs), typically derived from airborne LiDAR or multi-view stereo, remain costly and geographically limited. Recently, models trained on synthetic data and refined through domain adaptation have shown remarkable performance in MHE, yet it remains unclear how these models make predictions or how reliable they truly are. In this paper, we investigate a state-of-the-art MHE model trained purely on synthetic data to explore where the model looks when making height predictions. Through systematic analyses, we find that the model relies heavily on shadow cues, a factor that can lead to overestimation or underestimation of heights when shadows deviate from expected norms. Furthermore, the inherent difficulty of evaluating regression tasks with the human eye underscores additional limitations of purely synthetic training. To address these issues, we propose a novel correction pipeline that integrates sparse, imperfect global LiDAR measurements (ICESat-2) with deep-learning outputs to improve local accuracy and achieve spatially consistent corrections. Our method comprises two stages: pre-processing raw ICESat-2 data, followed by a random forest-based approach to densely refine height estimates. Experiments in three representative urban regions -- Saint-Omer, Tokyo, and Sao Paulo -- reveal substantial error reductions, with mean absolute error (MAE) decreased by 22.8\%, 6.9\%, and 4.9\%, respectively. These findings highlight the critical role of shadow awareness in synthetic data-driven models and demonstrate how fusing imperfect real-world LiDAR data can bolster the robustness of MHE, paving the way for more reliable and scalable 3D mapping solutions.</li>
</ul>

<h3>Title: MMiC: Mitigating Modality Incompleteness in Clustered Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Lishan Yang, Wei Zhang, Quan Z. Sheng, Weitong Chen, Lina Yao, Weitong Chen, Ali Shakeri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06911">https://arxiv.org/abs/2505.06911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06911">https://arxiv.org/pdf/2505.06911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06911]] MMiC: Mitigating Modality Incompleteness in Clustered Federated Learning(https://arxiv.org/abs/2505.06911)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>In the era of big data, data mining has become indispensable for uncovering hidden patterns and insights from vast and complex datasets. The integration of multimodal data sources further enhances its potential. Multimodal Federated Learning (MFL) is a distributed approach that enhances the efficiency and quality of multimodal learning, ensuring collaborative work and privacy protection. However, missing modalities pose a significant challenge in MFL, often due to data quality issues or privacy policies across the clients. In this work, we present MMiC, a framework for Mitigating Modality incompleteness in MFL within the Clusters. MMiC replaces partial parameters within client models inside clusters to mitigate the impact of missing modalities. Furthermore, it leverages the Banzhaf Power Index to optimize client selection under these conditions. Finally, MMiC employs an innovative approach to dynamically control global aggregation by utilizing Markovitz Portfolio Optimization. Extensive experiments demonstrate that MMiC consistently outperforms existing federated learning architectures in both global and personalized performance on multimodal datasets with missing modalities, confirming the effectiveness of our proposed solution.</li>
</ul>

<h3>Title: Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI</h3>
<ul>
<li><strong>Authors: </strong>Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tianbin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06912">https://arxiv.org/abs/2505.06912</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06912">https://arxiv.org/pdf/2505.06912</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06912]] Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI(https://arxiv.org/abs/2505.06912)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite strong performance in medical question-answering, the clinical adoption of Large Language Models (LLMs) is critically hampered by their opaque 'black-box' reasoning, limiting clinician trust. This challenge is compounded by the predominant reliance of current medical LLMs on corpora from scientific literature or synthetic data, which often lack the granular expert validation and high clinical relevance essential for advancing their specialized medical capabilities. To address these critical gaps, we introduce a highly clinically relevant dataset with 31,247 medical question-answer pairs, each accompanied by expert-validated chain-of-thought (CoT) explanations. This resource, spanning multiple clinical domains, was curated via a scalable human-LLM hybrid pipeline: LLM-generated rationales were iteratively reviewed, scored, and refined by medical experts against a structured rubric, with substandard outputs revised through human effort or guided LLM regeneration until expert consensus. This publicly available dataset provides a vital source for the development of medical LLMs that capable of transparent and verifiable reasoning, thereby advancing safer and more interpretable AI in medicine.</li>
</ul>

<h3>Title: RedTeamLLM: an Agentic AI framework for offensive security</h3>
<ul>
<li><strong>Authors: </strong>Brian Challita, Pierre Parrend</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06913">https://arxiv.org/abs/2505.06913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06913">https://arxiv.org/pdf/2505.06913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06913]] RedTeamLLM: an Agentic AI framework for offensive security(https://arxiv.org/abs/2505.06913)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>From automated intrusion testing to discovery of zero-day attacks before software launch, agentic AI calls for great promises in security engineering. This strong capability is bound with a similar threat: the security and research community must build up its models before the approach is leveraged by malicious actors for cybercrime. We therefore propose and evaluate RedTeamLLM, an integrated architecture with a comprehensive security model for automatization of pentest tasks. RedTeamLLM follows three key steps: summarizing, reasoning and act, which embed its operational capacity. This novel framework addresses four open challenges: plan correction, memory management, context window constraint, and generality vs. specialization. Evaluation is performed through the automated resolution of a range of entry-level, but not trivial, CTF challenges. The contribution of the reasoning capability of our agentic AI framework is specifically evaluated.</li>
</ul>

<h3>Title: The Distracting Effect: Understanding Irrelevant Passages in RAG</h3>
<ul>
<li><strong>Authors: </strong>Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06914">https://arxiv.org/abs/2505.06914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06914">https://arxiv.org/pdf/2505.06914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06914]] The Distracting Effect: Understanding Irrelevant Passages in RAG(https://arxiv.org/abs/2505.06914)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A well-known issue with Retrieval Augmented Generation (RAG) is that retrieved passages that are irrelevant to the query sometimes distract the answer-generating LLM, causing it to provide an incorrect response. In this paper, we shed light on this core issue and formulate the distracting effect of a passage w.r.t. a query (and an LLM). We provide a quantifiable measure of the distracting effect of a passage and demonstrate its robustness across LLMs. Our research introduces novel methods for identifying and using hard distracting passages to improve RAG systems. By fine-tuning LLMs with these carefully selected distracting passages, we achieve up to a 7.5% increase in answering accuracy compared to counterparts fine-tuned on conventional RAG datasets. Our contribution is two-fold: first, we move beyond the simple binary classification of irrelevant passages as either completely unrelated vs. distracting, and second, we develop and analyze multiple methods for finding hard distracting passages. To our knowledge, no other research has provided such a comprehensive framework for identifying and utilizing hard distracting passages.</li>
</ul>

<h3>Title: Non-Stationary Time Series Forecasting Based on Fourier Analysis and Cross Attention Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Yuqi Xiong, Yang Wen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06917">https://arxiv.org/abs/2505.06917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06917">https://arxiv.org/pdf/2505.06917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06917]] Non-Stationary Time Series Forecasting Based on Fourier Analysis and Cross Attention Mechanism(https://arxiv.org/abs/2505.06917)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series forecasting has important applications in financial analysis, weather forecasting, and traffic management. However, existing deep learning models are limited in processing non-stationary time series data because they cannot effectively capture the statistical characteristics that change over time. To address this problem, this paper proposes a new framework, AEFIN, which enhances the information sharing ability between stable and unstable components by introducing a cross-attention mechanism, and combines Fourier analysis networks with MLP to deeply explore the seasonal patterns and trend characteristics in unstable components. In addition, we design a new loss function that combines time-domain stability constraints, time-domain instability constraints, and frequency-domain stability constraints to improve the accuracy and robustness of forecasting. Experimental results show that AEFIN outperforms the most common models in terms of mean square error and mean absolute error, especially under non-stationary data conditions, and shows excellent forecasting capabilities. This paper provides an innovative solution for the modeling and forecasting of non-stationary time series data, and contributes to the research of deep learning for complex time series.</li>
</ul>

<h3>Title: Transformer-Based Dual-Optical Attention Fusion Crowd Head Point Counting and Localization Network</h3>
<ul>
<li><strong>Authors: </strong>Fei Zhou, Yi Li, Mingqing Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06937">https://arxiv.org/abs/2505.06937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06937">https://arxiv.org/pdf/2505.06937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06937]] Transformer-Based Dual-Optical Attention Fusion Crowd Head Point Counting and Localization Network(https://arxiv.org/abs/2505.06937)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, the dual-optical attention fusion crowd head point counting model (TAPNet) is proposed to address the problem of the difficulty of accurate counting in complex scenes such as crowd dense occlusion and low light in crowd counting tasks under UAV view. The model designs a dual-optical attention fusion module (DAFP) by introducing complementary information from infrared images to improve the accuracy and robustness of all-day crowd counting. In order to fully utilize different modal information and solve the problem of inaccurate localization caused by systematic misalignment between image pairs, this paper also proposes an adaptive two-optical feature decomposition fusion module (AFDF). In addition, we optimize the training strategy to improve the model robustness through spatial random offset data augmentation. Experiments on two challenging public datasets, DroneRGBT and GAIIC2, show that the proposed method outperforms existing techniques in terms of performance, especially in challenging dense low-light scenes. Code is available at this https URL</li>
</ul>

<h3>Title: A systematic review of challenges and proposed solutions in modeling multimodal data</h3>
<ul>
<li><strong>Authors: </strong>Maryam Farhadizadeh (1 and 2), Maria Weymann (2 and 3), Michael Blaß (4), Johann Kraus (5), Christopher Gundler (4), Sebastian Walter (6), Noah Hempen (1), Harald Binde (2 and 3), Nadine Binder (1 and 2) ((1) Institute of General Practice/Family Medicine, Faculty of Medicine and Medical Center - University of Freiburg, Germany, (2) Freiburg Center for Data Analysis, Modeling and AI, University of Freiburg, Germany, (3) Institute of Medical Biometry and Statistics, Faculty of Medicine and Medical Center - University of Freiburg, Germany, (4) Institute for Applied Medical Informatics, University Medical Center Hamburg-Eppendorf, Germany, (5) Institute of Medical Systems Biology, Ulm University, Germany, (6) Department of Computer Science, Faculty of Engineering - University of Freiburg, Germany)</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06945">https://arxiv.org/abs/2505.06945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06945">https://arxiv.org/pdf/2505.06945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06945]] A systematic review of challenges and proposed solutions in modeling multimodal data(https://arxiv.org/abs/2505.06945)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Multimodal data modeling has emerged as a powerful approach in clinical research, enabling the integration of diverse data types such as imaging, genomics, wearable sensors, and electronic health records. Despite its potential to improve diagnostic accuracy and support personalized care, modeling such heterogeneous data presents significant technical challenges. This systematic review synthesizes findings from 69 studies to identify common obstacles, including missing modalities, limited sample sizes, dimensionality imbalance, interpretability issues, and finding the optimal fusion techniques. We highlight recent methodological advances, such as transfer learning, generative models, attention mechanisms, and neural architecture search that offer promising solutions. By mapping current trends and innovations, this review provides a comprehensive overview of the field and offers practical insights to guide future research and development in multimodal modeling for medical applications.</li>
</ul>

<h3>Title: Unsupervised Learning for Class Distribution Mismatch</h3>
<ul>
<li><strong>Authors: </strong>Pan Du, Wangbo Zhao, Xinai Lu, Nian Liu, Zhikai Li, Chaoyu Gong, Suyun Zhao, Hong Chen, Cuiping Li, Kai Wang, Yang You</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06948">https://arxiv.org/abs/2505.06948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06948">https://arxiv.org/pdf/2505.06948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06948]] Unsupervised Learning for Class Distribution Mismatch(https://arxiv.org/abs/2505.06948)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Class distribution mismatch (CDM) refers to the discrepancy between class distributions in training data and target tasks. Previous methods address this by designing classifiers to categorize classes known during training, while grouping unknown or new classes into an "other" category. However, they focus on semi-supervised scenarios and heavily rely on labeled data, limiting their applicability and performance. To address this, we propose Unsupervised Learning for Class Distribution Mismatch (UCDM), which constructs positive-negative pairs from unlabeled data for classifier training. Our approach randomly samples images and uses a diffusion model to add or erase semantic classes, synthesizing diverse training pairs. Additionally, we introduce a confidence-based labeling mechanism that iteratively assigns pseudo-labels to valuable real-world data and incorporates them into the training process. Extensive experiments on three datasets demonstrate UCDM's superiority over previous semi-supervised methods. Specifically, with a 60% mismatch proportion on Tiny-ImageNet dataset, our approach, without relying on labeled data, surpasses OpenMatch (with 40 labels per class) by 35.1%, 63.7%, and 72.5% in classifying known, unknown, and new classes.</li>
</ul>

<h3>Title: Boosting Cross-spectral Unsupervised Domain Adaptation for Thermal Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Seokjun Kwon, Jeongmin Shin, Namil Kim, Soonmin Hwang, Yukyung Choi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06951">https://arxiv.org/abs/2505.06951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06951">https://arxiv.org/pdf/2505.06951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06951]] Boosting Cross-spectral Unsupervised Domain Adaptation for Thermal Semantic Segmentation(https://arxiv.org/abs/2505.06951)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>In autonomous driving, thermal image semantic segmentation has emerged as a critical research area, owing to its ability to provide robust scene understanding under adverse visual conditions. In particular, unsupervised domain adaptation (UDA) for thermal image segmentation can be an efficient solution to address the lack of labeled thermal datasets. Nevertheless, since these methods do not effectively utilize the complementary information between RGB and thermal images, they significantly decrease performance during domain adaptation. In this paper, we present a comprehensive study on cross-spectral UDA for thermal image semantic segmentation. We first propose a novel masked mutual learning strategy that promotes complementary information exchange by selectively transferring results between each spectral model while masking out uncertain regions. Additionally, we introduce a novel prototypical self-supervised loss designed to enhance the performance of the thermal segmentation model in nighttime scenarios. This approach addresses the limitations of RGB pre-trained networks, which cannot effectively transfer knowledge under low illumination due to the inherent constraints of RGB sensors. In experiments, our method achieves higher performance over previous UDA methods and comparable performance to state-of-the-art supervised methods.</li>
</ul>

<h3>Title: High-Frequency Prior-Driven Adaptive Masking for Accelerating Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Wei Shang, Dongwei Ren, Wanying Zhang, Pengfei Zhu, Qinghua Hu, Wangmeng Zuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06975">https://arxiv.org/abs/2505.06975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06975">https://arxiv.org/pdf/2505.06975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06975]] High-Frequency Prior-Driven Adaptive Masking for Accelerating Image Super-Resolution(https://arxiv.org/abs/2505.06975)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The primary challenge in accelerating image super-resolution lies in reducing computation while maintaining performance and adaptability. Motivated by the observation that high-frequency regions (e.g., edges and textures) are most critical for reconstruction, we propose a training-free adaptive masking module for acceleration that dynamically focuses computation on these challenging areas. Specifically, our method first extracts high-frequency components via Gaussian blur subtraction and adaptively generates binary masks using K-means clustering to identify regions requiring intensive processing. Our method can be easily integrated with both CNNs and Transformers. For CNN-based architectures, we replace standard $3 \times 3$ convolutions with an unfold operation followed by $1 \times 1$ convolutions, enabling pixel-wise sparse computation guided by the mask. For Transformer-based models, we partition the mask into non-overlapping windows and selectively process tokens based on their average values. During inference, unnecessary pixels or windows are pruned, significantly reducing computation. Moreover, our method supports dilation-based mask adjustment to control the processing scope without retraining, and is robust to unseen degradations (e.g., noise, compression). Extensive experiments on benchmarks demonstrate that our method reduces FLOPs by 24--43% for state-of-the-art models (e.g., CARN, SwinIR) while achieving comparable or better quantitative metrics. The source code is available at this https URL</li>
</ul>

<h3>Title: Federated Learning with LoRA Optimized DeiT and Multiscale Patch Embedding for Secure Eye Disease Recognition</h3>
<ul>
<li><strong>Authors: </strong>Md. Naimur Asif Borno, Md Sakib Hossain Shovon, MD Hanif Sikder, Iffat Firozy Rimi, Tahani Jaser Alahmadi, Mohammad Ali Moni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06982">https://arxiv.org/abs/2505.06982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06982">https://arxiv.org/pdf/2505.06982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06982]] Federated Learning with LoRA Optimized DeiT and Multiscale Patch Embedding for Secure Eye Disease Recognition(https://arxiv.org/abs/2505.06982)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, extraction, federate, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Recent progress in image-based medical disease detection encounters challenges such as limited annotated data sets, inadequate spatial feature analysis, data security issues, and inefficient training frameworks. This study introduces a data-efficient image transformer (DeIT)-based approach that overcomes these challenges by utilizing multiscale patch embedding for better feature extraction and stratified weighted random sampling to address class imbalance. The model also incorporates a LoRA-enhanced transformer encoder, a distillation framework, and federated learning for decentralized training, improving both efficiency and data security. Consequently, it achieves state-of-the-art performance, with the highest AUC, F1 score, precision, minimal loss, and Top-5 accuracy. Additionally, Grad-CAM++ visualizations improve interpretability by highlighting critical pathological regions, enhancing the model's clinical relevance. These results highlight the potential of this approach to advance AI-powered medical imaging and disease detection.</li>
</ul>

<h3>Title: Convert Language Model into a Value-based Strategic Planner</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Wang, Yue Zhao, Qingqing Gu, Zhonglin Jiang, Xiaokai Chen, Yong Chen, Luo Ji</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06987">https://arxiv.org/abs/2505.06987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06987">https://arxiv.org/pdf/2505.06987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06987]] Convert Language Model into a Value-based Strategic Planner(https://arxiv.org/abs/2505.06987)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emotional support conversation (ESC) aims to alleviate the emotional distress of individuals through effective conversations. Although large language models (LLMs) have obtained remarkable progress on ESC, most of these studies might not define the diagram from the state model perspective, therefore providing a suboptimal solution for long-term satisfaction. To address such an issue, we leverage the Q-learning on LLMs, and propose a framework called straQ*. Our framework allows a plug-and-play LLM to bootstrap the planning during ESC, determine the optimal strategy based on long-term returns, and finally guide the LLM to response. Substantial experiments on ESC datasets suggest that straQ* outperforms many baselines, including direct inference, self-refine, chain of thought, finetuning, and finite state machines.</li>
</ul>

<h3>Title: Measuring the Accuracy and Effectiveness of PII Removal Services</h3>
<ul>
<li><strong>Authors: </strong>Jiahui He, Pete Snyder, Hamed Haddadi, Fabián E. Bustamante, Gareth Tyson</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06989">https://arxiv.org/abs/2505.06989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06989">https://arxiv.org/pdf/2505.06989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06989]] Measuring the Accuracy and Effectiveness of PII Removal Services(https://arxiv.org/abs/2505.06989)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper presents the first large-scale empirical study of commercial personally identifiable information (PII) removal systems -- commercial services that claim to improve privacy by automating the removal of PII from data broker's databases. Popular examples of such services include DeleteMe, Mozilla Monitor, Incogni, among many others. The claims these services make may be very appealing to privacy-conscious Web users, but how effective these services actually are at improving privacy has not been investigated. This work aims to improve our understanding of commercial PII removal services in multiple ways. First, we conduct a user study where participants purchase subscriptions from four popular PII removal services, and report (i) what PII the service find, (ii) from which data brokers, (iii) whether the service is able to have the information removed, and (iv) whether the identified information actually is PII describing the participant. And second, by comparing the claims and promises the services makes (e.g. which and how many data brokers each service claims to cover). We find that these services have significant accuracy and coverage issues that limit the usefulness of these services as a privacy-enhancing technology. For example, we find that the measured services are unable to remove the majority of the identified PII records from data broker's (48.2% of the successfully removed found records) and that most records identified by these services are not PII about the user (study participants found that only 41.1% of records identified by these services were PII about themselves).</li>
</ul>

<h3>Title: Technical Report for ICRA 2025 GOOSE 2D Semantic Segmentation Challenge: Leveraging Color Shift Correction, RoPE-Swin Backbone, and Quantile-based Label Denoising Strategy for Robust Outdoor Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Chih-Chung Hsu, I-Hsuan Wu, Wen-Hai Tseng, Ching-Heng Cheng, Ming-Hsuan Wu, Jin-Hui Jiang, Yu-Jou Hsiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06991">https://arxiv.org/abs/2505.06991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06991">https://arxiv.org/pdf/2505.06991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06991]] Technical Report for ICRA 2025 GOOSE 2D Semantic Segmentation Challenge: Leveraging Color Shift Correction, RoPE-Swin Backbone, and Quantile-based Label Denoising Strategy for Robust Outdoor Scene Understanding(https://arxiv.org/abs/2505.06991)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>This report presents our semantic segmentation framework developed by team ACVLAB for the ICRA 2025 GOOSE 2D Semantic Segmentation Challenge, which focuses on parsing outdoor scenes into nine semantic categories under real-world conditions. Our method integrates a Swin Transformer backbone enhanced with Rotary Position Embedding (RoPE) for improved spatial generalization, alongside a Color Shift Estimation-and-Correction module designed to compensate for illumination inconsistencies in natural environments. To further improve training stability, we adopt a quantile-based denoising strategy that downweights the top 2.5\% of highest-error pixels, treating them as noise and suppressing their influence during optimization. Evaluated on the official GOOSE test set, our approach achieved a mean Intersection over Union (mIoU) of 0.848, demonstrating the effectiveness of combining color correction, positional encoding, and error-aware denoising in robust semantic segmentation.</li>
</ul>

<h3>Title: Replay-Based Continual Learning with Dual-Layered Distillation and a Streamlined U-Net for Efficient Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Md. Naimur Asif Borno, Md Sakib Hossain Shovon, Asmaa Soliman Al-Moisheer, Mohammad Ali Moni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.06995">https://arxiv.org/abs/2505.06995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.06995">https://arxiv.org/pdf/2505.06995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.06995]] Replay-Based Continual Learning with Dual-Layered Distillation and a Streamlined U-Net for Efficient Text-to-Image Generation(https://arxiv.org/abs/2505.06995)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in text-to-image diffusion models are hindered by high computational demands, limiting accessibility and scalability. This paper introduces KDC-Diff, a novel stable diffusion framework that enhances efficiency while maintaining image quality. KDC-Diff features a streamlined U-Net architecture with nearly half the parameters of the original U-Net (482M), significantly reducing model complexity. We propose a dual-layered distillation strategy to ensure high-fidelity generation, transferring semantic and structural insights from a teacher to a compact student model while minimizing quality degradation. Additionally, replay-based continual learning is integrated to mitigate catastrophic forgetting, allowing the model to retain prior knowledge while adapting to new data. Despite operating under extremely low computational resources, KDC-Diff achieves state-of-the-art performance on the Oxford Flowers and Butterflies & Moths 100 Species datasets, demonstrating competitive metrics such as FID, CLIP, and LPIPS. Moreover, it significantly reduces inference time compared to existing models. These results establish KDC-Diff as a highly efficient and adaptable solution for text-to-image generation, particularly in computationally constrained environments.</li>
</ul>

<h3>Title: CMD: Controllable Multiview Diffusion for 3D Editing and Progressive Generation</h3>
<ul>
<li><strong>Authors: </strong>Peng Li, Suizhi Ma, Jialiang Chen, Yuan Liu, Chongyi Zhang, Wei Xue, Wenhan Luo, Alla Sheffer, Wenping Wang, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07003">https://arxiv.org/abs/2505.07003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07003">https://arxiv.org/pdf/2505.07003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07003]] CMD: Controllable Multiview Diffusion for 3D Editing and Progressive Generation(https://arxiv.org/abs/2505.07003)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, 3D generation methods have shown their powerful ability to automate 3D model creation. However, most 3D generation methods only rely on an input image or a text prompt to generate a 3D model, which lacks the control of each component of the generated 3D model. Any modifications of the input image lead to an entire regeneration of the 3D models. In this paper, we introduce a new method called CMD that generates a 3D model from an input image while enabling flexible local editing of each component of the 3D model. In CMD, we formulate the 3D generation as a conditional multiview diffusion model, which takes the existing or known parts as conditions and generates the edited or added components. This conditional multiview diffusion model not only allows the generation of 3D models part by part but also enables local editing of 3D models according to the local revision of the input image without changing other 3D parts. Extensive experiments are conducted to demonstrate that CMD decomposes a complex 3D generation task into multiple components, improving the generation quality. Meanwhile, CMD enables efficient and flexible local editing of a 3D model by just editing one rendered image.</li>
</ul>

<h3>Title: GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance</h3>
<ul>
<li><strong>Authors: </strong>Jinuk Kim, Marwa El Halabi, Wonpyo Park, Clemens JS Schaefer, Deokjae Lee, Yeonhong Park, Jae W. Lee, Hyun Oh Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07004">https://arxiv.org/abs/2505.07004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07004">https://arxiv.org/pdf/2505.07004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07004]] GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance(https://arxiv.org/abs/2505.07004)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Post-training quantization is a key technique for reducing the memory and inference latency of large language models by quantizing weights and activations without requiring retraining. However, existing methods either (1) fail to account for the varying importance of hidden features to the end loss or, when incorporating end loss, (2) neglect the critical interactions between model weights. To address these limitations, we propose GuidedQuant, a novel quantization approach that integrates gradient information from the end loss into the quantization objective while preserving cross-weight dependencies within output channels. GuidedQuant consistently boosts the performance of state-of-the-art quantization methods across weight-only scalar, weight-only vector, and weight-and-activation quantization. Additionally, we introduce a novel non-uniform scalar quantization algorithm, which is guaranteed to monotonically decrease the quantization objective value, and outperforms existing methods in this category. We release the code at this https URL.</li>
</ul>

<h3>Title: MELLM: Exploring LLM-Powered Micro-Expression Understanding Enhanced by Subtle Motion Perception</h3>
<ul>
<li><strong>Authors: </strong>Zhengye Zhang, Sirui Zhao, Shifeng Liu, Shukang Yin, Xinglong Mao, Tong Xu, Enhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07007">https://arxiv.org/abs/2505.07007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07007">https://arxiv.org/pdf/2505.07007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07007]] MELLM: Exploring LLM-Powered Micro-Expression Understanding Enhanced by Subtle Motion Perception(https://arxiv.org/abs/2505.07007)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Micro-expressions (MEs) are crucial psychological responses with significant potential for affective computing. However, current automatic micro-expression recognition (MER) research primarily focuses on discrete emotion classification, neglecting a convincing analysis of the subtle dynamic movements and inherent emotional cues. The rapid progress in multimodal large language models (MLLMs), known for their strong multimodal comprehension and language generation abilities, offers new possibilities. MLLMs have shown success in various vision-language tasks, indicating their potential to understand MEs comprehensively, including both fine-grained motion patterns and underlying emotional semantics. Nevertheless, challenges remain due to the subtle intensity and short duration of MEs, as existing MLLMs are not designed to capture such delicate frame-level facial dynamics. In this paper, we propose a novel Micro-Expression Large Language Model (MELLM), which incorporates a subtle facial motion perception strategy with the strong inference capabilities of MLLMs, representing the first exploration of MLLMs in the domain of ME analysis. Specifically, to explicitly guide the MLLM toward motion-sensitive regions, we construct an interpretable motion-enhanced color map by fusing onset-apex optical flow dynamics with the corresponding grayscale onset frame as the model input. Additionally, specialized fine-tuning strategies are incorporated to further enhance the model's visual perception of MEs. Furthermore, we construct an instruction-description dataset based on Facial Action Coding System (FACS) annotations and emotion labels to train our MELLM. Comprehensive evaluations across multiple benchmark datasets demonstrate that our model exhibits superior robustness and generalization capabilities in ME understanding (MEU). Code is available at this https URL.</li>
</ul>

<h3>Title: Source Anonymity for Private Random Walk Decentralized Learning</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Egger, Svenja Lage, Rawad Bitar, Antonia Wachter-Zeh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.IT, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07011">https://arxiv.org/abs/2505.07011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07011">https://arxiv.org/pdf/2505.07011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07011]] Source Anonymity for Private Random Walk Decentralized Learning(https://arxiv.org/abs/2505.07011)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper considers random walk-based decentralized learning, where at each iteration of the learning process, one user updates the model and sends it to a randomly chosen neighbor until a convergence criterion is met. Preserving data privacy is a central concern and open problem in decentralized learning. We propose a privacy-preserving algorithm based on public-key cryptography and anonymization. In this algorithm, the user updates the model and encrypts the result using a distant user's public key. The encrypted result is then transmitted through the network with the goal of reaching that specific user. The key idea is to hide the source's identity so that, when the destination user decrypts the result, it does not know who the source was. The challenge is to design a network-dependent probability distribution (at the source) over the potential destinations such that, from the receiver's perspective, all users have a similar likelihood of being the source. We introduce the problem and construct a scheme that provides anonymity with theoretical guarantees. We focus on random regular graphs to establish rigorous guarantees.</li>
</ul>

<h3>Title: Efficient and Robust Multidimensional Attention in Remote Physiological Sensing through Target Signal Constrained Factorization</h3>
<ul>
<li><strong>Authors: </strong>Jitesh Joshi, Youngjun Cho</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07013">https://arxiv.org/abs/2505.07013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07013">https://arxiv.org/pdf/2505.07013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07013]] Efficient and Robust Multidimensional Attention in Remote Physiological Sensing through Target Signal Constrained Factorization(https://arxiv.org/abs/2505.07013)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Remote physiological sensing using camera-based technologies offers transformative potential for non-invasive vital sign monitoring across healthcare and human-computer interaction domains. Although deep learning approaches have advanced the extraction of physiological signals from video data, existing methods have not been sufficiently assessed for their robustness to domain shifts. These shifts in remote physiological sensing include variations in ambient conditions, camera specifications, head movements, facial poses, and physiological states which often impact real-world performance significantly. Cross-dataset evaluation provides an objective measure to assess generalization capabilities across these domain shifts. We introduce Target Signal Constrained Factorization module (TSFM), a novel multidimensional attention mechanism that explicitly incorporates physiological signal characteristics as factorization constraints, allowing more precise feature extraction. Building on this innovation, we present MMRPhys, an efficient dual-branch 3D-CNN architecture designed for simultaneous multitask estimation of photoplethysmography (rPPG) and respiratory (rRSP) signals from multimodal RGB and thermal video inputs. Through comprehensive cross-dataset evaluation on five benchmark datasets, we demonstrate that MMRPhys with TSFM significantly outperforms state-of-the-art methods in generalization across domain shifts for rPPG and rRSP estimation, while maintaining a minimal inference latency suitable for real-time applications. Our approach establishes new benchmarks for robust multitask and multimodal physiological sensing and offers a computationally efficient framework for practical deployment in unconstrained environments. The web browser-based application featuring on-device real-time inference of MMRPhys model is available at this https URL</li>
</ul>

<h3>Title: A Vision-Language Foundation Model for Leaf Disease Identification</h3>
<ul>
<li><strong>Authors: </strong>Khang Nguyen Quoc, Lan Le Thi Thu, Luyl-Da Quach</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07019">https://arxiv.org/abs/2505.07019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07019">https://arxiv.org/pdf/2505.07019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07019]] A Vision-Language Foundation Model for Leaf Disease Identification(https://arxiv.org/abs/2505.07019)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Leaf disease identification plays a pivotal role in smart agriculture. However, many existing studies still struggle to integrate image and textual modalities to compensate for each other's limitations. Furthermore, many of these approaches rely on pretraining with constrained datasets such as ImageNet, which lack domain-specific information. We propose SCOLD (Soft-target COntrastive learning for Leaf Disease identification), a context-aware vision-language foundation model tailored to address these challenges for agricultural tasks. SCOLD is developed using a diverse corpus of plant leaf images and corresponding symptom descriptions, comprising over 186,000 image-caption pairs aligned with 97 unique concepts. Through task-agnostic pretraining, SCOLD leverages contextual soft targets to mitigate overconfidence in contrastive learning by smoothing labels, thereby improving model generalization and robustness on fine-grained classification tasks. Experimental results demonstrate that SCOLD outperforms existing vision-language models such as OpenAI-CLIP-L, BioCLIP, and SigLIP2 across several benchmarks, including zero-shot and few-shot classification, image-text retrieval, and image classification, while maintaining a competitive parameter footprint. Ablation studies further highlight SCOLD's effectiveness in contrast to its counterparts. The proposed approach significantly advances the agricultural vision-language foundation model, offering strong performance with minimal or no supervised fine-tuning. This work lays a solid groundwork for future research on models trained with long-form and simplified contexts, tasks involving class ambiguity, and multi-modal systems for intelligent plant disease diagnostics. The code for this study is available at this https URL</li>
</ul>

<h3>Title: MarkMatch: Same-Hand Stuffing Detection</h3>
<ul>
<li><strong>Authors: </strong>Fei Zhao, Runlin Zhang, Chengcui Zhang, Nitesh Saxena</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07032">https://arxiv.org/abs/2505.07032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07032">https://arxiv.org/pdf/2505.07032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07032]] MarkMatch: Same-Hand Stuffing Detection(https://arxiv.org/abs/2505.07032)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, extraction</a></li>
<li><strong>Abstract: </strong>We present MarkMatch, a retrieval system for detecting whether two paper ballot marks were filled by the same hand. Unlike the previous SOTA method BubbleSig, which used binary classification on isolated mark pairs, MarkMatch ranks stylistic similarity between a query mark and a mark in the database using contrastive learning. Our model is trained with a dense batch similarity matrix and a dual loss objective. Each sample is contrasted against many negatives within each batch, enabling the model to learn subtle handwriting difference and improve generalization under handwriting variation and visual noise, while diagonal supervision reinforces high confidence on true matches. The model achieves an F1 score of 0.943, surpassing BubbleSig's best performance. MarkMatch also integrates Segment Anything Model for flexible mark extraction via box- or point-based prompts. The system offers election auditors a practical tool for visual, non-biometric investigation of suspicious ballots.</li>
</ul>

<h3>Title: Predicting Diabetes Using Machine Learning: A Comparative Study of Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Mahade Hasan, Farhana Yasmin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07036">https://arxiv.org/abs/2505.07036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07036">https://arxiv.org/pdf/2505.07036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07036]] Predicting Diabetes Using Machine Learning: A Comparative Study of Classifiers(https://arxiv.org/abs/2505.07036)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Diabetes remains a significant health challenge globally, contributing to severe complications like kidney disease, vision loss, and heart issues. The application of machine learning (ML) in healthcare enables efficient and accurate disease prediction, offering avenues for early intervention and patient support. Our study introduces an innovative diabetes prediction framework, leveraging both traditional ML techniques such as Logistic Regression, SVM, Naïve Bayes, and Random Forest and advanced ensemble methods like AdaBoost, Gradient Boosting, Extra Trees, and XGBoost. Central to our approach is the development of a novel model, DNet, a hybrid architecture combining Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) layers for effective feature extraction and sequential learning. The DNet model comprises an initial convolutional block for capturing essential features, followed by a residual block with skip connections to facilitate efficient information flow. Batch Normalization and Dropout are employed for robust regularization, and an LSTM layer captures temporal dependencies within the data. Using a Kaggle-sourced real-world diabetes dataset, our model evaluation spans cross-validation accuracy, precision, recall, F1 score, and ROC-AUC. Among the models, DNet demonstrates the highest efficacy with an accuracy of 99.79% and an AUC-ROC of 99.98%, establishing its potential for superior diabetes prediction. This robust hybrid architecture showcases the value of combining CNN and LSTM layers, emphasizing its applicability in medical diagnostics and disease prediction tasks.</li>
</ul>

<h3>Title: Depth-Sensitive Soft Suppression with RGB-D Inter-Modal Stylization Flow for Domain Generalization Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Binbin Wei, Yuhang Zhang, Shishun Tian, Muxin Liao, Wei Li, Wenbin Zou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07050">https://arxiv.org/abs/2505.07050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07050">https://arxiv.org/pdf/2505.07050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07050]] Depth-Sensitive Soft Suppression with RGB-D Inter-Modal Stylization Flow for Domain Generalization Semantic Segmentation(https://arxiv.org/abs/2505.07050)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised Domain Adaptation (UDA) aims to align source and target domain distributions to close the domain gap, but still struggles with obtaining the target data. Fortunately, Domain Generalization (DG) excels without the need for any target data. Recent works expose that depth maps contribute to improved generalized performance in the UDA tasks, but they ignore the noise and holes in depth maps due to device and environmental factors, failing to sufficiently and effectively learn domain-invariant representation. Although high-sensitivity region suppression has shown promising results in learning domain-invariant features, existing methods cannot be directly applicable to depth maps due to their unique characteristics. Hence, we propose a novel framework, namely Depth-Sensitive Soft Suppression with RGB-D inter-modal stylization flow (DSSS), focusing on learning domain-invariant features from depth maps for the DG semantic segmentation. Specifically, we propose the RGB-D inter-modal stylization flow to generate stylized depth maps for sensitivity detection, cleverly utilizing RGB information as the stylization source. Then, a class-wise soft spatial sensitivity suppression is designed to identify and emphasize non-sensitive depth features that contain more domain-invariant information. Furthermore, an RGB-D soft alignment loss is proposed to ensure that the stylized depth maps only align part of the RGB features while still retaining the unique depth information. To our best knowledge, our DSSS framework is the first work to integrate RGB and Depth information in the multi-class DG semantic segmentation task. Extensive experiments over multiple backbone networks show that our framework achieves remarkable performance improvement.</li>
</ul>

<h3>Title: DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Junhao Xia, Chaoyang Zhang, Yecheng Zhang, Chengyang Zhou, Zhichang Wang, Bochun Liu, Dongshuo Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07057">https://arxiv.org/abs/2505.07057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07057">https://arxiv.org/pdf/2505.07057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07057]] DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models(https://arxiv.org/abs/2505.07057)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Video generation based on diffusion models presents a challenging multimodal task, with video editing emerging as a pivotal direction in this field. Recent video editing approaches primarily fall into two categories: training-required and training-free methods. While training-based methods incur high computational costs, training-free alternatives often yield suboptimal performance. To address these limitations, we propose DAPE, a high-quality yet cost-effective two-stage parameter-efficient fine-tuning (PEFT) framework for video editing. In the first stage, we design an efficient norm-tuning method to enhance temporal consistency in generated videos. The second stage introduces a vision-friendly adapter to improve visual quality. Additionally, we identify critical shortcomings in existing benchmarks, including limited category diversity, imbalanced object distribution, and inconsistent frame counts. To mitigate these issues, we curate a large dataset benchmark comprising 232 videos with rich annotations and 6 editing prompts, enabling objective and comprehensive evaluation of advanced methods. Extensive experiments on existing datasets (BalanceCC, LOVEU-TGVE, RAVE) and our proposed benchmark demonstrate that DAPE significantly improves temporal coherence and text-video alignment while outperforming previous state-of-the-art approaches.</li>
</ul>

<h3>Title: Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures</h3>
<ul>
<li><strong>Authors: </strong>Francesco Cagnetta, Alessandro Favero, Antonio Sclocchi, Matthieu Wyart</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07070">https://arxiv.org/abs/2505.07070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07070">https://arxiv.org/pdf/2505.07070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07070]] Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures(https://arxiv.org/abs/2505.07070)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>How do neural language models acquire a language's structure when trained for next-token prediction? We address this question by deriving theoretical scaling laws for neural network performance on synthetic datasets generated by the Random Hierarchy Model (RHM) -- an ensemble of probabilistic context-free grammars designed to capture the hierarchical structure of natural language while remaining analytically tractable. Previously, we developed a theory of representation learning based on data correlations that explains how deep learning models capture the hierarchical structure of the data sequentially, one layer at a time. Here, we extend our theoretical framework to account for architectural differences. In particular, we predict and empirically validate that convolutional networks, whose structure aligns with that of the generative process through locality and weight sharing, enjoy a faster scaling of performance compared to transformer models, which rely on global self-attention mechanisms. This finding clarifies the architectural biases underlying neural scaling laws and highlights how representation learning is shaped by the interaction between model architecture and the statistical properties of data.</li>
</ul>

<h3>Title: Semantic-Guided Diffusion Model for Single-Step Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Zihang Liu, Zhenyu Zhang, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07071">https://arxiv.org/abs/2505.07071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07071">https://arxiv.org/pdf/2505.07071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07071]] Semantic-Guided Diffusion Model for Single-Step Image Super-Resolution(https://arxiv.org/abs/2505.07071)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Diffusion-based image super-resolution (SR) methods have demonstrated remarkable performance. Recent advancements have introduced deterministic sampling processes that reduce inference from 15 iterative steps to a single step, thereby significantly improving the inference speed of existing diffusion models. However, their efficiency remains limited when handling complex semantic regions due to the single-step inference. To address this limitation, we propose SAMSR, a semantic-guided diffusion framework that incorporates semantic segmentation masks into the sampling process. Specifically, we introduce the SAM-Noise Module, which refines Gaussian noise using segmentation masks to preserve spatial and semantic features. Furthermore, we develop a pixel-wise sampling strategy that dynamically adjusts the residual transfer rate and noise strength based on pixel-level semantic weights, prioritizing semantically rich regions during the diffusion process. To enhance model training, we also propose a semantic consistency loss, which aligns pixel-wise semantic weights between predictions and ground truth. Extensive experiments on both real-world and synthetic datasets demonstrate that SAMSR significantly improves perceptual quality and detail recovery, particularly in semantically complex images. Our code is released at this https URL.</li>
</ul>

<h3>Title: Discovering Concept Directions from Diffusion-based Counterfactuals via Latent Clustering</h3>
<ul>
<li><strong>Authors: </strong>Payal Varshney, Adriano Lucieri, Christoph Balada, Andreas Dengel, Sheraz Ahmed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07073">https://arxiv.org/abs/2505.07073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07073">https://arxiv.org/pdf/2505.07073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07073]] Discovering Concept Directions from Diffusion-based Counterfactuals via Latent Clustering(https://arxiv.org/abs/2505.07073)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Concept-based explanations have emerged as an effective approach within Explainable Artificial Intelligence, enabling interpretable insights by aligning model decisions with human-understandable concepts. However, existing methods rely on computationally intensive procedures and struggle to efficiently capture complex, semantic concepts. Recently, the Concept Discovery through Latent Diffusion-based Counterfactual Trajectories (CDCT) framework, introduced by Varshney et al. (2025), attempts to identify concepts via dimension-wise traversal of the latent space of a Variational Autoencoder trained on counterfactual trajectories. Extending the CDCT framework, this work introduces Concept Directions via Latent Clustering (CDLC), which extracts global, class-specific concept directions by clustering latent difference vectors derived from factual and diffusion-generated counterfactual image pairs. CDLC substantially reduces computational complexity by eliminating the exhaustive latent dimension traversal required in CDCT and enables the extraction of multidimensional semantic concepts encoded across the latent dimensions. This approach is validated on a real-world skin lesion dataset, demonstrating that the extracted concept directions align with clinically recognized dermoscopic features and, in some cases, reveal dataset-specific biases or unknown biomarkers. These results highlight that CDLC is interpretable, scalable, and applicable across high-stakes domains and diverse data modalities.</li>
</ul>

<h3>Title: Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable Machine Learning Models to Individual Users</h3>
<ul>
<li><strong>Authors: </strong>Julian Rosenberger, Philipp Schröppel, Sven Kruschel, Mathias Kraus, Patrick Zschech, Maximilian Förster</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07100">https://arxiv.org/abs/2505.07100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07100">https://arxiv.org/pdf/2505.07100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07100]] Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable Machine Learning Models to Individual Users(https://arxiv.org/abs/2505.07100)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The Rashomon effect describes the observation that in machine learning (ML) multiple models often achieve similar predictive performance while explaining the underlying relationships in different ways. This observation holds even for intrinsically interpretable models, such as Generalized Additive Models (GAMs), which offer users valuable insights into the model's behavior. Given the existence of multiple GAM configurations with similar predictive performance, a natural question is whether we can personalize these configurations based on users' needs for interpretability. In our study, we developed an approach to personalize models based on contextual bandits. In an online experiment with 108 users in a personalized treatment and a non-personalized control group, we found that personalization led to individualized rather than one-size-fits-all configurations. Despite these individual adjustments, the interpretability remained high across both groups, with users reporting a strong understanding of the models. Our research offers initial insights into the potential for personalizing interpretable ML.</li>
</ul>

<h3>Title: Standing Firm in 5G: A Single-Round, Dropout-Resilient Secure Aggregation for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Zhang, Rouzbeh Behnia, Imtiaz Karim, Attila A. Yavuz, Elisa Bertino</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07148">https://arxiv.org/abs/2505.07148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07148">https://arxiv.org/pdf/2505.07148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07148]] Standing Firm in 5G: A Single-Round, Dropout-Resilient Secure Aggregation for Federated Learning(https://arxiv.org/abs/2505.07148)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is well-suited to 5G networks, where many mobile devices generate sensitive edge data. Secure aggregation protocols enhance privacy in FL by ensuring that individual user updates reveal no information about the underlying client data. However, the dynamic and large-scale nature of 5G-marked by high mobility and frequent dropouts-poses significant challenges to the effective adoption of these protocols. Existing protocols often require multi-round communication or rely on fixed infrastructure, limiting their practicality. We propose a lightweight, single-round secure aggregation protocol designed for 5G environments. By leveraging base stations for assisted computation and incorporating precomputation, key-homomorphic pseudorandom functions, and t-out-of-k secret sharing, our protocol ensures efficiency, robustness, and privacy. Experiments show strong security guarantees and significant gains in communication and computation efficiency, making the approach well-suited for real-world 5G FL deployments.</li>
</ul>

<h3>Title: AugMixCloak: A Defense against Membership Inference Attacks via Image Transformation</h3>
<ul>
<li><strong>Authors: </strong>Heqing Ren, Chao Feng, Alberto Huertas, Burkhard Stiller</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07149">https://arxiv.org/abs/2505.07149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07149">https://arxiv.org/pdf/2505.07149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07149]] AugMixCloak: A Defense against Membership Inference Attacks via Image Transformation(https://arxiv.org/abs/2505.07149)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, attack, membership infer, federate</a></li>
<li><strong>Abstract: </strong>Traditional machine learning (ML) raises serious privacy concerns, while federated learning (FL) mitigates the risk of data leakage by keeping data on local devices. However, the training process of FL can still leak sensitive information, which adversaries may exploit to infer private data. One of the most prominent threats is the membership inference attack (MIA), where the adversary aims to determine whether a particular data record was part of the training set. This paper addresses this problem through a two-stage defense called AugMixCloak. The core idea is to apply data augmentation and principal component analysis (PCA)-based information fusion to query images, which are detected by perceptual hashing (pHash) as either identical to or highly similar to images in the training set. Experimental results show that AugMixCloak successfully defends against both binary classifier-based MIA and metric-based MIA across five datasets and various decentralized FL (DFL) topologies. Compared with regularization-based defenses, AugMixCloak demonstrates stronger protection. Compared with confidence score masking, AugMixCloak exhibits better generalization.</li>
</ul>

<h3>Title: HAMLET: Healthcare-focused Adaptive Multilingual Learning Embedding-based Topic Modeling</h3>
<ul>
<li><strong>Authors: </strong>Hajar Sakai, Sarah S. Lam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07157">https://arxiv.org/abs/2505.07157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07157">https://arxiv.org/pdf/2505.07157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07157]] HAMLET: Healthcare-focused Adaptive Multilingual Learning Embedding-based Topic Modeling(https://arxiv.org/abs/2505.07157)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Traditional topic models often struggle with contextual nuances and fail to adequately handle polysemy and rare words. This limitation typically results in topics that lack coherence and quality. Large Language Models (LLMs) can mitigate this issue by generating an initial set of topics. However, these raw topics frequently lack refinement and representativeness, which leads to redundancy without lexical similarity and reduced interpretability. This paper introduces HAMLET, a graph-driven architecture for cross-lingual healthcare topic modeling that uses LLMs. The proposed approach leverages neural-enhanced semantic fusion to refine the embeddings of topics generated by the LLM. Instead of relying solely on statistical co-occurrence or human interpretation to extract topics from a document corpus, this method introduces a topic embedding refinement that uses Bidirectional Encoder Representations from Transformers (BERT) and Graph Neural Networks (GNN). After topic generation, a hybrid technique that involves BERT and Sentence-BERT (SBERT) is employed for embedding. The topic representations are further refined using a GNN, which establishes connections between documents, topics, words, similar topics, and similar words. A novel method is introduced to compute similarities. Consequently, the topic embeddings are refined, and the top k topics are extracted. Experiments were conducted using two healthcare datasets, one in English and one in French, from which six sets were derived. The results demonstrate the effectiveness of HAMLET.</li>
</ul>

<h3>Title: Real-Time Bit-Level Encryption of Full High-Definition Video Without Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Dong Jiang, Hui-ran Luo, Zi-jian Cui, Xi-jue Zhao, Lin-sheng Huang, Liang-liang Lu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07158">https://arxiv.org/abs/2505.07158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07158">https://arxiv.org/pdf/2505.07158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07158]] Real-Time Bit-Level Encryption of Full High-Definition Video Without Diffusion(https://arxiv.org/abs/2505.07158)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Despite the widespread adoption of Shannon's confusion-diffusion architecture in image encryption, the implementation of diffusion to sequentially establish inter-pixel dependencies for attaining plaintext sensitivity constrains algorithmic parallelism, while the execution of multiple rounds of diffusion operations to meet the required sensitivity metrics incurs excessive computational overhead. Consequently, the pursuit of plaintext sensitivity through diffusion operations is the primary factor limiting the computational efficiency and throughput of video encryption algorithms, rendering them inadequate to meet the demands of real-time encryption for high-resolution video. To address the performance limitation, this paper proposes a real-time video encryption protocol based on heterogeneous parallel computing, which incorporates the SHA-256 hashes of original frames as input, employs multiple CPU threads to concurrently generate encryption-related data, and deploys numerous GPU threads to simultaneously encrypt pixels. By leveraging the extreme input sensitivity of the SHA hash, the proposed protocol achieves the required plaintext sensitivity metrics with only a single round of confusion and XOR operations, significantly reducing computational overhead. Furthermore, through eliminating the reliance on diffusion, it realizes the allocation of a dedicated GPU thread for encrypting each pixel within every channel, effectively enhancing algorithm's parallelism. The experimental results demonstrate that our approach not only exhibits superior statistical properties and robust security but also achieving delay-free bit-level encryption for 1920$\times$1080 resolution (full high definition) video at 30 FPS, with an average encryption time of 25.84 ms on a server equipped with an Intel Xeon Gold 6226R CPU and an NVIDIA GeForce RTX 3090 GPU.</li>
</ul>

<h3>Title: KDH-MLTC: Knowledge Distillation for Healthcare Multi-Label Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Hajar Sakai, Sarah S. Lam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07162">https://arxiv.org/abs/2505.07162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07162">https://arxiv.org/pdf/2505.07162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07162]] KDH-MLTC: Knowledge Distillation for Healthcare Multi-Label Text Classification(https://arxiv.org/abs/2505.07162)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The increasing volume of healthcare textual data requires computationally efficient, yet highly accurate classification approaches able to handle the nuanced and complex nature of medical terminology. This research presents Knowledge Distillation for Healthcare Multi-Label Text Classification (KDH-MLTC), a framework leveraging model compression and Large Language Models (LLMs). The proposed approach addresses conventional healthcare Multi-Label Text Classification (MLTC) challenges by integrating knowledge distillation and sequential fine-tuning, subsequently optimized through Particle Swarm Optimization (PSO) for hyperparameter tuning. KDH-MLTC transfers knowledge from a more complex teacher LLM (i.e., BERT) to a lighter student LLM (i.e., DistilBERT) through sequential training adapted to MLTC that preserves the teacher's learned information while significantly reducing computational requirements. As a result, the classification is enabled to be conducted locally, making it suitable for healthcare textual data characterized by sensitivity and, therefore, ensuring HIPAA compliance. The experiments conducted on three medical literature datasets of different sizes, sampled from the Hallmark of Cancer (HoC) dataset, demonstrate that KDH-MLTC achieves superior performance compared to existing approaches, particularly for the largest dataset, reaching an F1 score of 82.70%. Additionally, statistical validation and an ablation study are carried out, proving the robustness of KDH-MLTC. Furthermore, the PSO-based hyperparameter optimization process allowed the identification of optimal configurations. The proposed approach contributes to healthcare text classification research, balancing efficiency requirements in resource-constrained healthcare settings with satisfactory accuracy demands.</li>
</ul>

<h3>Title: Generalizable Pancreas Segmentation via a Dual Self-Supervised Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Jun Li, Hongzhang Zhu, Tao Chen, Xiaohua Qian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07165">https://arxiv.org/abs/2505.07165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07165">https://arxiv.org/pdf/2505.07165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07165]] Generalizable Pancreas Segmentation via a Dual Self-Supervised Learning Framework(https://arxiv.org/abs/2505.07165)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recently, numerous pancreas segmentation methods have achieved promising performance on local single-source datasets. However, these methods don't adequately account for generalizability issues, and hence typically show limited performance and low stability on test data from other sources. Considering the limited availability of distinct data sources, we seek to improve the generalization performance of a pancreas segmentation model trained with a single-source dataset, i.e., the single source generalization task. In particular, we propose a dual self-supervised learning model that incorporates both global and local anatomical contexts. Our model aims to fully exploit the anatomical features of the intra-pancreatic and extra-pancreatic regions, and hence enhance the characterization of the high-uncertainty regions for more robust generalization. Specifically, we first construct a global-feature contrastive self-supervised learning module that is guided by the pancreatic spatial structure. This module obtains complete and consistent pancreatic features through promoting intra-class cohesion, and also extracts more discriminative features for differentiating between pancreatic and non-pancreatic tissues through maximizing inter-class separation. It mitigates the influence of surrounding tissue on the segmentation outcomes in high-uncertainty regions. Subsequently, a local-image restoration self-supervised learning module is introduced to further enhance the characterization of the high uncertainty regions. In this module, informative anatomical contexts are actually learned to recover randomly corrupted appearance patterns in those regions.</li>
</ul>

<h3>Title: One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07167">https://arxiv.org/abs/2505.07167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07167">https://arxiv.org/pdf/2505.07167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07167]] One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models(https://arxiv.org/abs/2505.07167)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been extensively used across diverse domains, including virtual assistants, automated code generation, and scientific research. However, they remain vulnerable to jailbreak attacks, which manipulate the models into generating harmful responses despite safety alignment. Recent studies have shown that current safety-aligned LLMs often undergo the shallow safety alignment, where the first few tokens largely determine whether the response will be harmful. Through comprehensive observations, we find that safety-aligned LLMs and various defense strategies generate highly similar initial tokens in their refusal responses, which we define as safety trigger tokens. Building on this insight, we propose \texttt{D-STT}, a simple yet effective defense algorithm that identifies and explicitly decodes safety trigger tokens of the given safety-aligned LLM to trigger the model's learned safety patterns. In this process, the safety trigger is constrained to a single token, which effectively preserves model usability by introducing minimum intervention in the decoding process. Extensive experiments across diverse jailbreak attacks and benign prompts demonstrate that \ours significantly reduces output harmfulness while preserving model usability and incurring negligible response time overhead, outperforming ten baseline methods.</li>
</ul>

<h3>Title: Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07184">https://arxiv.org/abs/2505.07184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07184">https://arxiv.org/pdf/2505.07184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07184]] Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs(https://arxiv.org/abs/2505.07184)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved unprecedented performance by leveraging vast pretraining corpora, yet their performance remains suboptimal in knowledge-intensive domains such as medicine and scientific research, where high factual precision is required. While synthetic data provides a promising avenue for augmenting domain knowledge, existing methods frequently generate redundant samples that do not align with the model's true knowledge gaps. To overcome this limitation, we propose a novel Structural Entropy-guided Knowledge Navigator (SENATOR) framework that addresses the intrinsic knowledge deficiencies of LLMs. Our approach employs the Structure Entropy (SE) metric to quantify uncertainty along knowledge graph paths and leverages Monte Carlo Tree Search (MCTS) to selectively explore regions where the model lacks domain-specific knowledge. Guided by these insights, the framework generates targeted synthetic data for supervised fine-tuning, enabling continuous self-improvement. Experimental results on LLaMA-3 and Qwen2 across multiple domain-specific benchmarks show that SENATOR effectively detects and repairs knowledge deficiencies, achieving notable performance improvements. The code and data for our methods and experiments are available at this https URL.</li>
</ul>

<h3>Title: Securing Genomic Data Against Inference Attacks in Federated Learning Environments</h3>
<ul>
<li><strong>Authors: </strong>Chetan Pathade, Shubham Patil</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07188">https://arxiv.org/abs/2505.07188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07188">https://arxiv.org/pdf/2505.07188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07188]] Securing Genomic Data Against Inference Attacks in Federated Learning Environments(https://arxiv.org/abs/2505.07188)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, membership infer, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) offers a promising framework for collaboratively training machine learning models across decentralized genomic datasets without direct data sharing. While this approach preserves data locality, it remains susceptible to sophisticated inference attacks that can compromise individual privacy. In this study, we simulate a federated learning setup using synthetic genomic data and assess its vulnerability to three key attack vectors: Membership Inference Attack (MIA), Gradient-Based Membership Inference Attack, and Label Inference Attack (LIA). Our experiments reveal that Gradient-Based MIA achieves the highest effectiveness, with a precision of 0.79 and F1-score of 0.87, underscoring the risk posed by gradient exposure in federated updates. Additionally, we visualize comparative attack performance through radar plots and quantify model leakage across clients. The findings emphasize the inadequacy of naïve FL setups in safeguarding genomic privacy and motivate the development of more robust privacy-preserving mechanisms tailored to the unique sensitivity of genomic data.</li>
</ul>

<h3>Title: Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030</h3>
<ul>
<li><strong>Authors: </strong>Mouxiao Bian, Rongzhao Zhang, Chao Ding, Xinwei Peng, Jie Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07205">https://arxiv.org/abs/2505.07205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07205">https://arxiv.org/pdf/2505.07205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07205]] Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030(https://arxiv.org/abs/2505.07205)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are poised to transform healthcare under China's Healthy China 2030 initiative, yet they introduce new ethical and patient-safety challenges. We present a novel 12,000-item Q&A benchmark covering 11 ethics and 9 safety dimensions in medical contexts, to quantitatively evaluate these risks. Using this dataset, we assess state-of-the-art Chinese medical LLMs (e.g., Qwen 2.5-32B, DeepSeek), revealing moderate baseline performance (accuracy 42.7% for Qwen 2.5-32B) and significant improvements after fine-tuning on our data (up to 50.8% accuracy). Results show notable gaps in LLM decision-making on ethics and safety scenarios, reflecting insufficient institutional oversight. We then identify systemic governance shortfalls-including the lack of fine-grained ethical audit protocols, slow adaptation by hospital IRBs, and insufficient evaluation tools-that currently hinder safe LLM deployment. Finally, we propose a practical governance framework for healthcare institutions (embedding LLM auditing teams, enacting data ethics guidelines, and implementing safety simulation pipelines) to proactively manage LLM risks. Our study highlights the urgent need for robust LLM governance in Chinese healthcare, aligning AI innovation with patient safety and ethical standards.</li>
</ul>

<h3>Title: Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Hongda Qin, Xiao Lu, Zhiyong Wei, Yihong Cao, Kailun Yang, Ningjiang Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07219">https://arxiv.org/abs/2505.07219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07219">https://arxiv.org/pdf/2505.07219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07219]] Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection(https://arxiv.org/abs/2505.07219)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Generalizing an object detector trained on a single domain to multiple unseen domains is a challenging task. Existing methods typically introduce image or feature augmentation to diversify the source domain to raise the robustness of the detector. Vision-Language Model (VLM)-based augmentation techniques have been proven to be effective, but they require that the detector's backbone has the same structure as the image encoder of VLM, limiting the detector framework selection. To address this problem, we propose Language-Driven Dual Style Mixing (LDDS) for single-domain generalization, which diversifies the source domain by fully utilizing the semantic information of the VLM. Specifically, we first construct prompts to transfer style semantics embedded in the VLM to an image translation network. This facilitates the generation of style diversified images with explicit semantic information. Then, we propose image-level style mixing between the diversified images and source domain images. This effectively mines the semantic information for image augmentation without relying on specific augmentation selections. Finally, we propose feature-level style mixing in a double-pipeline manner, allowing feature augmentation to be model-agnostic and can work seamlessly with the mainstream detector frameworks, including the one-stage, two-stage, and transformer-based detectors. Extensive experiments demonstrate the effectiveness of our approach across various benchmark datasets, including real to cartoon and normal to adverse weather tasks. The source code and pre-trained models will be publicly available at this https URL.</li>
</ul>

<h3>Title: Compression, Regularity, Randomness and Emergent Structure: Rethinking Physical Complexity in the Data-Driven Era</h3>
<ul>
<li><strong>Authors: </strong>Nima Dehghani</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.stat-mech, cs.IT, physics.bio-ph, physics.data-an</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07222">https://arxiv.org/abs/2505.07222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07222">https://arxiv.org/pdf/2505.07222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07222]] Compression, Regularity, Randomness and Emergent Structure: Rethinking Physical Complexity in the Data-Driven Era(https://arxiv.org/abs/2505.07222)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Complexity science offers a wide range of measures for quantifying unpredictability, structure, and information. Yet, a systematic conceptual organization of these measures is still missing. We present a unified framework that locates statistical, algorithmic, and dynamical measures along three axes (regularity, randomness, and complexity) and situates them in a common conceptual space. We map statistical, algorithmic, and dynamical measures into this conceptual space, discussing their computational accessibility and approximability. This taxonomy reveals the deep challenges posed by uncomputability and highlights the emergence of modern data-driven methods (including autoencoders, latent dynamical models, symbolic regression, and physics-informed neural networks) as pragmatic approximations to classical complexity ideals. Latent spaces emerge as operational arenas where regularity extraction, noise management, and structured compression converge, bridging theoretical foundations with practical modeling in high-dimensional systems. We close by outlining implications for physics-informed AI and AI-guided discovery in complex physical systems, arguing that classical questions of complexity remain central to next-generation scientific modeling.</li>
</ul>

<h3>Title: DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07233">https://arxiv.org/abs/2505.07233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07233">https://arxiv.org/pdf/2505.07233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07233]] DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation(https://arxiv.org/abs/2505.07233)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) systems combine large language models (LLMs) with external knowledge retrieval, making them highly effective for knowledge-intensive tasks. A crucial but often under-explored component of these systems is the reranker, which refines retrieved documents to enhance generation quality and explainability. The challenge of selecting the optimal number of documents (k) remains unsolved: too few may omit critical information, while too many introduce noise and inefficiencies. Although recent studies have explored LLM-based rerankers, they primarily leverage internal model knowledge and overlook the rich supervisory signals that LLMs can provide, such as using response quality as feedback for optimizing reranking decisions. In this paper, we propose DynamicRAG, a novel RAG framework where the reranker dynamically adjusts both the order and number of retrieved documents based on the query. We model the reranker as an agent optimized through reinforcement learning (RL), using rewards derived from LLM output quality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates superior performance, achieving state-of-the-art results. The model, data and code are available at this https URL</li>
</ul>

<h3>Title: Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Guang Yan, Yuhui Zhang, Zimu Guo, Lutan Zhao, Xiaojun Chen, Chen Wang, Wenhao Wang, Dan Meng, Rui Hou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07239">https://arxiv.org/abs/2505.07239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07239">https://arxiv.org/pdf/2505.07239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07239]] Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity(https://arxiv.org/abs/2505.07239)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>With the growing use of large language models (LLMs) hosted on cloud platforms to offer inference services, privacy concerns about the potential leakage of sensitive information are escalating. Secure multi-party computation (MPC) is a promising solution to protect the privacy in LLM inference. However, MPC requires frequent inter-server communication, causing high performance overhead. Inspired by the prevalent activation sparsity of LLMs, where most neuron are not activated after non-linear activation functions, we propose an efficient private inference system, Comet. This system employs an accurate and fast predictor to predict the sparsity distribution of activation function output. Additionally, we introduce a new private inference protocol. It efficiently and securely avoids computations involving zero values by exploiting the spatial locality of the predicted sparse distribution. While this computation-avoidance approach impacts the spatiotemporal continuity of KV cache entries, we address this challenge with a low-communication overhead cache refilling strategy that merges miss requests and incorporates a prefetching mechanism. Finally, we evaluate Comet on four common LLMs and compare it with six state-of-the-art private inference systems. Comet achieves a 1.87x-2.63x speedup and a 1.94x-2.64x communication reduction.</li>
</ul>

<h3>Title: SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Peichao Lai, Kexuan Zhang, Yi Lin, Linyihan Zhang, Feiyang Ye, Jinhao Yan, Yanwei Xu, Conghui He, Yilei Wang, Wentao Zhang, Bin Cui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07247">https://arxiv.org/abs/2505.07247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07247">https://arxiv.org/pdf/2505.07247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07247]] SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models(https://arxiv.org/abs/2505.07247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Subjective Answer Grading (SAG) plays a crucial role in education, standardized testing, and automated assessment systems, particularly for evaluating short-form responses in Short Answer Scoring (SAS). However, existing approaches often produce coarse-grained scores and lack detailed reasoning. Although large language models (LLMs) have demonstrated potential as zero-shot evaluators, they remain susceptible to bias, inconsistencies with human judgment, and limited transparency in scoring decisions. To overcome these limitations, we introduce SAS-Bench, a benchmark specifically designed for LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring, expert-annotated error categories, and a diverse range of question types derived from real-world subject-specific exams. This benchmark facilitates detailed evaluation of model reasoning processes and explainability. We also release an open-source dataset containing 1,030 questions and 4,109 student responses, each annotated by domain experts. Furthermore, we conduct comprehensive experiments with various LLMs, identifying major challenges in scoring science-related questions and highlighting the effectiveness of few-shot prompting in improving scoring accuracy. Our work offers valuable insights into the development of more robust, fair, and educationally meaningful LLM-based evaluation systems.</li>
</ul>

<h3>Title: No Query, No Access</h3>
<ul>
<li><strong>Authors: </strong>Wenqiang Wang, Siyuan Liang, Yangshijie Zhang, Xiaojun Jia, Hao Lin, Xiaochun Cao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07258">https://arxiv.org/abs/2505.07258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07258">https://arxiv.org/pdf/2505.07258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07258]] No Query, No Access(https://arxiv.org/abs/2505.07258)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Textual adversarial attacks mislead NLP models, including Large Language Models (LLMs), by subtly modifying text. While effective, existing attacks often require knowledge of the victim model, extensive queries, or access to training data, limiting real-world feasibility. To overcome these constraints, we introduce the \textbf{Victim Data-based Adversarial Attack (VDBA)}, which operates using only victim texts. To prevent access to the victim model, we create a shadow dataset with publicly available pre-trained models and clustering methods as a foundation for developing substitute models. To address the low attack success rate (ASR) due to insufficient information feedback, we propose the hierarchical substitution model design, generating substitute models to mitigate the failure of a single substitute model at the decision boundary. Concurrently, we use diverse adversarial example generation, employing various attack methods to generate and select the adversarial example with better similarity and attack effectiveness. Experiments on the Emotion and SST5 datasets show that VDBA outperforms state-of-the-art methods, achieving an ASR improvement of 52.08\% while significantly reducing attack queries to 0. More importantly, we discover that VDBA poses a significant threat to LLMs such as Qwen2 and the GPT family, and achieves the highest ASR of 45.99% even without access to the API, confirming that advanced NLP models still face serious security risks. Our codes can be found at this https URL</li>
</ul>

<h3>Title: UMoE: Unifying Attention and FFN with Shared Experts</h3>
<ul>
<li><strong>Authors: </strong>Yuanhang Yang, Chaozheng Wang, Jing Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07260">https://arxiv.org/abs/2505.07260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07260">https://arxiv.org/pdf/2505.07260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07260]] UMoE: Unifying Attention and FFN with Shared Experts(https://arxiv.org/abs/2505.07260)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sparse Mixture of Experts (MoE) architectures have emerged as a promising approach for scaling Transformer models. While initial works primarily incorporated MoE into feed-forward network (FFN) layers, recent studies have explored extending the MoE paradigm to attention layers to enhance model performance. However, existing attention-based MoE layers require specialized implementations and demonstrate suboptimal performance compared to their FFN-based counterparts. In this paper, we aim to unify the MoE designs in attention and FFN layers by introducing a novel reformulation of the attention mechanism, revealing an underlying FFN-like structure within attention modules. Our proposed architecture, UMoE, achieves superior performance through attention-based MoE layers while enabling efficient parameter sharing between FFN and attention components.</li>
</ul>

<h3>Title: On the Robustness of Reward Models for Language Model Alignment</h3>
<ul>
<li><strong>Authors: </strong>Jiwoo Hong, Noah Lee, Eunki Kim, Guijin Son, Woojin Chung, Aman Gupta, Shao Tang, James Thorne</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07271">https://arxiv.org/abs/2505.07271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07271">https://arxiv.org/pdf/2505.07271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07271]] On the Robustness of Reward Models for Language Model Alignment(https://arxiv.org/abs/2505.07271)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Bradley-Terry (BT) model is widely practiced in reward modeling for reinforcement learning with human feedback (RLHF). Despite its effectiveness, reward models (RMs) trained with BT model loss are prone to over-optimization, losing generalizability to unseen input distributions. In this paper, we study the cause of over-optimization in RM training and its downstream effects on the RLHF procedure, accentuating the importance of distributional robustness of RMs in unseen data. First, we show that the excessive dispersion of hidden state norms is the main source of over-optimization. Then, we propose batch-wise sum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch, constraining the rewards with extreme magnitudes. We assess the impact of BSR in improving robustness in RMs through four scenarios of over-optimization, where BSR consistently manifests better robustness. Subsequently, we compare the plain BT model and BSR on RLHF training and empirically show that robust RMs better align the policy to the gold preference model. Finally, we apply BSR to high-quality data and models, which surpasses state-of-the-art RMs in the 8B scale by adding more than 5% in complex preference prediction tasks. By conducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length by 40% while adding a 7% increase in win rate, further highlighting that robustness in RMs induces robustness in RLHF training. We release the code, data, and models: this https URL.</li>
</ul>

<h3>Title: Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains</h3>
<ul>
<li><strong>Authors: </strong>Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07274">https://arxiv.org/abs/2505.07274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07274">https://arxiv.org/pdf/2505.07274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07274]] Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains(https://arxiv.org/abs/2505.07274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Integrating large language models (LLMs) as priors in reinforcement learning (RL) offers significant advantages but comes with substantial computational costs. We present a principled cache-efficient framework for posterior sampling with LLM-derived priors that dramatically reduces these costs while maintaining high performance. At the core of our approach is an adaptive caching mechanism, where cache parameters are meta-optimized using surrogate gradients derived from policy performance. This design enables efficient inference across both discrete text environments (e.g., TextWorld, ALFWorld) and continuous control domains (e.g., MuJoCo), achieving a 3.8--4.7$\times$ reduction in LLM queries and 4.0--12.0$\times$ lower median latencies (85--93\,ms on a consumer GPU) while retaining 96--98\% of uncached performance. Our theoretical analysis provides KL divergence bounds on approximation quality, validated empirically. The framework extends to offline RL, where our CQL-Prior variant improves performance by 14--29\% and reduces training time by 38--40\%. Extensive evaluations across a diverse suite of eight tasks demonstrate the generalizability and practical viability of LLM-guided RL in resource-constrained settings.</li>
</ul>

<h3>Title: Semantic Retention and Extreme Compression in LLMs: Can We Have Both?</h3>
<ul>
<li><strong>Authors: </strong>Stanislas Laborde, Martin Cousseau, Antoun Yaacoub, Lionel Prevost</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07289">https://arxiv.org/abs/2505.07289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07289">https://arxiv.org/pdf/2505.07289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07289]] Semantic Retention and Extreme Compression in LLMs: Can We Have Both?(https://arxiv.org/abs/2505.07289)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The exponential growth in Large Language Model (LLM) deployment has intensified the need for efficient model compression techniques to reduce computational and memory costs. While pruning and quantization have shown promise, their combined potential remains largely unexplored. In this paper, we examine joint compression and how strategically combining pruning and quantization could yield superior performance-to-compression ratios compared to single-method approaches. Recognizing the challenges in accurately assessing LLM performance, we address key limitations of previous evaluation frameworks and introduce the Semantic Retention Compression Rate (SrCr), a novel metric that quantifies the trade-off between model compression and semantic preservation, facilitating the optimization of pruning-quantization configurations. Experiments demonstrate that our recommended combination achieves, on average, a 20% performance increase compared to an equivalent quantization-only model at the same theoretical compression rate.</li>
</ul>

<h3>Title: L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Sofia Casarin, Sergio Escalera, Oswald Lanz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07300">https://arxiv.org/abs/2505.07300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07300">https://arxiv.org/pdf/2505.07300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07300]] L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers(https://arxiv.org/abs/2505.07300)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Training-free Neural Architecture Search (NAS) efficiently identifies high-performing neural networks using zero-cost (ZC) proxies. Unlike multi-shot and one-shot NAS approaches, ZC-NAS is both (i) time-efficient, eliminating the need for model training, and (ii) interpretable, with proxy designs often theoretically grounded. Despite rapid developments in the field, current SOTA ZC proxies are typically constrained to well-established convolutional search spaces. With the rise of Large Language Models shaping the future of deep learning, this work extends ZC proxy applicability to Vision Transformers (ViTs). We present a new benchmark using the Autoformer search space evaluated on 6 distinct tasks and propose Layer-Sample Wise Activation with Gradients information (L-SWAG), a novel, generalizable metric that characterizes both convolutional and transformer architectures across 14 tasks. Additionally, previous works highlighted how different proxies contain complementary information, motivating the need for a ML model to identify useful combinations. To further enhance ZC-NAS, we therefore introduce LIBRA-NAS (Low Information gain and Bias Re-Alignment), a method that strategically combines proxies to best represent a specific benchmark. Integrated into the NAS search, LIBRA-NAS outperforms evolution and gradient-based NAS techniques by identifying an architecture with a 17.0% test error on ImageNet1k in just 0.1 GPU days.</li>
</ul>

<h3>Title: Enabling Privacy-Aware AI-Based Ergonomic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sander De Coninck, Emilio Gamba, Bart Van Doninck, Abdellatif Bey-Temsamani, Sam Leroux, Pieter Simoens</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07306">https://arxiv.org/abs/2505.07306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07306">https://arxiv.org/pdf/2505.07306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07306]] Enabling Privacy-Aware AI-Based Ergonomic Analysis(https://arxiv.org/abs/2505.07306)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect</a></li>
<li><strong>Abstract: </strong>Musculoskeletal disorders (MSDs) are a leading cause of injury and productivity loss in the manufacturing industry, incurring substantial economic costs. Ergonomic assessments can mitigate these risks by identifying workplace adjustments that improve posture and reduce strain. Camera-based systems offer a non-intrusive, cost-effective method for continuous ergonomic tracking, but they also raise significant privacy concerns. To address this, we propose a privacy-aware ergonomic assessment framework utilizing machine learning techniques. Our approach employs adversarial training to develop a lightweight neural network that obfuscates video data, preserving only the essential information needed for human pose estimation. This obfuscation ensures compatibility with standard pose estimation algorithms, maintaining high accuracy while protecting privacy. The obfuscated video data is transmitted to a central server, where state-of-the-art keypoint detection algorithms extract body landmarks. Using multi-view integration, 3D keypoints are reconstructed and evaluated with the Rapid Entire Body Assessment (REBA) method. Our system provides a secure, effective solution for ergonomic monitoring in industrial environments, addressing both privacy and workplace safety concerns.</li>
</ul>

<h3>Title: Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection</h3>
<ul>
<li><strong>Authors: </strong>Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07309">https://arxiv.org/abs/2505.07309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07309">https://arxiv.org/pdf/2505.07309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07309]] Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection(https://arxiv.org/abs/2505.07309)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often generate fluent but factually incorrect outputs, known as hallucinations, which undermine their reliability in real-world applications. While uncertainty estimation has emerged as a promising strategy for detecting such errors, current metrics offer limited interpretability and lack clarity about the types of uncertainty they capture. In this paper, we present a systematic framework for decomposing LLM uncertainty into four distinct sources, inspired by previous research. We develop a source-specific estimation pipeline to quantify these uncertainty types and evaluate how existing metrics relate to each source across tasks and models. Our results show that metrics, task, and model exhibit systematic variation in uncertainty characteristic. Building on this, we propose a method for task specific metric/model selection guided by the alignment or divergence between their uncertainty characteristics and that of a given task. Our experiments across datasets and models demonstrate that our uncertainty-aware selection strategy consistently outperforms baseline strategies, helping us select appropriate models or uncertainty metrics, and contributing to more reliable and efficient deployment in uncertainty estimation.</li>
</ul>

<h3>Title: RealRep: Generalized SDR-to-HDR Conversion with Style Disentangled Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Gang He, Siqi Wang, Kepeng Xu, Lin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07322">https://arxiv.org/abs/2505.07322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07322">https://arxiv.org/pdf/2505.07322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07322]] RealRep: Generalized SDR-to-HDR Conversion with Style Disentangled Representation Learning(https://arxiv.org/abs/2505.07322)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>High-Dynamic-Range Wide-Color-Gamut (HDR-WCG) technology is becoming increasingly prevalent, intensifying the demand for converting Standard Dynamic Range (SDR) content to HDR. Existing methods primarily rely on fixed tone mapping operators, which are inadequate for handling SDR inputs with diverse styles commonly found in real-world scenarios. To address this challenge, we propose a generalized SDR-to-HDR method that handles diverse styles in real-world SDR content, termed Realistic Style Disentangled Representation Learning (RealRep). By disentangling luminance and chrominance, we analyze the intrinsic differences between contents with varying styles and propose a disentangled multi-view style representation learning method. This approach captures the guidance prior of true luminance and chrominance distributions across different styles, even when the SDR style distributions exhibit significant variations, thereby establishing a robust embedding space for inverse tone mapping. Motivated by the difficulty of directly utilizing degradation representation priors, we further introduce the Degradation-Domain Aware Controlled Mapping Network (DDACMNet), a two-stage framework that performs adaptive hierarchical mapping guided by a control-aware normalization mechanism. DDACMNet dynamically modulates the mapping process via degradation-conditioned hierarchical features, enabling robust adaptation across diverse degradation domains. Extensive experiments show that RealRep consistently outperforms state-of-the-art methods with superior generalization and perceptually faithful HDR color gamut reconstruction.</li>
</ul>

<h3>Title: Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Jordan Frery, Roman Bredehoft, Jakub Klemsa, Arthur Meyre, Andrei Stoian</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07329">https://arxiv.org/abs/2505.07329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07329">https://arxiv.org/pdf/2505.07329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07329]] Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption(https://arxiv.org/abs/2505.07329)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Preserving data confidentiality during the fine-tuning of open-source Large Language Models (LLMs) is crucial for sensitive applications. This work introduces an interactive protocol adapting the Low-Rank Adaptation (LoRA) technique for private fine-tuning. Homomorphic Encryption (HE) protects the confidentiality of training data and gradients handled by remote worker nodes performing the bulk of computations involving the base model weights. The data owner orchestrates training, requiring minimal local computing power and memory, thus alleviating the need for expensive client-side GPUs. We demonstrate feasibility by fine-tuning a Llama-3.2-1B model, presenting convergence results using HE-compatible quantization and performance benchmarks for HE computations on GPU hardware. This approach enables applications such as confidential knowledge base question answering, private codebase fine-tuning for AI code assistants, AI agents for drafting emails based on a company's email archive, and adapting models to analyze sensitive legal or healthcare documents.</li>
</ul>

<h3>Title: SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Zhang, Xiaopeng Li, Qi Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07336">https://arxiv.org/abs/2505.07336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07336">https://arxiv.org/pdf/2505.07336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07336]] SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction(https://arxiv.org/abs/2505.07336)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Background subtraction (BGS) is utilized to detect moving objects in a video and is commonly employed at the onset of object tracking and human recognition processes. Nevertheless, existing BGS techniques utilizing deep learning still encounter challenges with various background noises in videos, including variations in lighting, shifts in camera angles, and disturbances like air turbulence or swaying trees. To address this problem, we design a spiking autoencoder network, termed SAEN-BGS, based on noise resilience and time-sequence sensitivity of spiking neural networks (SNNs) to enhance the separation of foreground and background. To eliminate unnecessary background noise and preserve the important foreground elements, we begin by creating the continuous spiking conv-and-dconv block, which serves as the fundamental building block for the decoder in SAEN-BGS. Moreover, in striving for enhanced energy efficiency, we introduce a novel self-distillation spiking supervised learning method grounded in ANN-to-SNN frameworks, resulting in decreased power consumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016 datasets, our approach demonstrates superior segmentation performance relative to other baseline methods, even when challenged by complex scenarios with dynamic backgrounds.</li>
</ul>

<h3>Title: Generative Pre-trained Autoregressive Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07344">https://arxiv.org/abs/2505.07344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07344">https://arxiv.org/pdf/2505.07344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07344]] Generative Pre-trained Autoregressive Diffusion Transformer(https://arxiv.org/abs/2505.07344)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>In this work, we present GPDiT, a Generative Pre-trained Autoregressive Diffusion Transformer that unifies the strengths of diffusion and autoregressive modeling for long-range video synthesis, within a continuous latent space. Instead of predicting discrete tokens, GPDiT autoregressively predicts future latent frames using a diffusion loss, enabling natural modeling of motion dynamics and semantic consistency across frames. This continuous autoregressive framework not only enhances generation quality but also endows the model with representation capabilities. Additionally, we introduce a lightweight causal attention variant and a parameter-free rotation-based time-conditioning mechanism, improving both the training and inference efficiency. Extensive experiments demonstrate that GPDiT achieves strong performance in video generation quality, video representation ability, and few-shot learning tasks, highlighting its potential as an effective framework for video modeling in continuous space.</li>
</ul>

<h3>Title: QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines</h3>
<ul>
<li><strong>Authors: </strong>Ohjoon Kwon, Changsu Lee, Jihye Back, Lim Sun Suk, Inho Kang, Donghyeon Jeon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07345">https://arxiv.org/abs/2505.07345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07345">https://arxiv.org/pdf/2505.07345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07345]] QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines(https://arxiv.org/abs/2505.07345)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been widely used for relevance assessment in information retrieval. However, our study demonstrates that combining two distinct small language models (SLMs) with different architectures can outperform LLMs in this task. Our approach -- QUPID -- integrates a generative SLM with an embedding-based SLM, achieving higher relevance judgment accuracy while reducing computational costs compared to state-of-the-art LLM solutions. This computational efficiency makes QUPID highly scalable for real-world search systems processing millions of queries daily. In experiments across diverse document types, our method demonstrated consistent performance improvements (Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x faster inference times. Furthermore, when integrated into production search pipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how architectural diversity in model combinations can significantly enhance both search relevance and operational efficiency in information retrieval systems.</li>
</ul>

<h3>Title: From Search To Sampling: Generative Models For Robust Algorithmic Recourse</h3>
<ul>
<li><strong>Authors: </strong>Prateek Garg, Lokesh Nagalapatti, Sunita Sarawagi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07351">https://arxiv.org/abs/2505.07351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07351">https://arxiv.org/pdf/2505.07351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07351]] From Search To Sampling: Generative Models For Robust Algorithmic Recourse(https://arxiv.org/abs/2505.07351)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Algorithmic Recourse provides recommendations to individuals who are adversely impacted by automated model decisions, on how to alter their profiles to achieve a favorable outcome. Effective recourse methods must balance three conflicting goals: proximity to the original profile to minimize cost, plausibility for realistic recourse, and validity to ensure the desired outcome. We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations. We introduce GenRe, a generative recourse model designed to train the three recourse objectives jointly. Training such generative models is non-trivial due to lack of direct recourse supervision. We propose efficient ways to synthesize such supervision and further show that GenRe's training leads to a consistent estimator. Unlike most prior methods, that employ non-robust gradient descent based search during inference, GenRe simply performs a forward sampling over the generative model to produce minimum cost recourse, leading to superior performance across multiple metrics. We also demonstrate GenRe provides the best trade-off between cost, plausibility and validity, compared to state-of-art baselines. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild</h3>
<ul>
<li><strong>Authors: </strong>Lintao Xiang, Hongpei Zheng, Bailin Deng, Hujun Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07373">https://arxiv.org/abs/2505.07373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07373">https://arxiv.org/pdf/2505.07373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07373]] Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild(https://arxiv.org/abs/2505.07373)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural implicit surface reconstruction using volume rendering techniques has recently achieved significant advancements in creating high-fidelity surfaces from multiple 2D images. However, current methods primarily target scenes with consistent illumination and struggle to accurately reconstruct 3D geometry in uncontrolled environments with transient occlusions or varying appearances. While some neural radiance field (NeRF)-based variants can better manage photometric variations and transient objects in complex scenes, they are designed for novel view synthesis rather than precise surface reconstruction due to limited surface constraints. To overcome this limitation, we introduce a novel approach that applies multiple geometric constraints to the implicit surface optimization process, enabling more accurate reconstructions from unconstrained image collections. First, we utilize sparse 3D points from structure-from-motion (SfM) to refine the signed distance function estimation for the reconstructed surface, with a displacement compensation to accommodate noise in the sparse points. Additionally, we employ robust normal priors derived from a normal predictor, enhanced by edge prior filtering and multi-view consistency constraints, to improve alignment with the actual surface geometry. Extensive testing on the Heritage-Recon benchmark and other datasets has shown that the proposed method can accurately reconstruct surfaces from in-the-wild images, yielding geometries with superior accuracy and granularity compared to existing techniques. Our approach enables high-quality 3D reconstruction of various landmarks, making it applicable to diverse scenarios such as digital preservation of cultural heritage sites.</li>
</ul>

<h3>Title: Apple's Synthetic Defocus Noise Pattern: Characterization and Forensic Applications</h3>
<ul>
<li><strong>Authors: </strong>David Vázquez-Padín, Fernando Pérez-González, Pablo Pérez-Miguélez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07380">https://arxiv.org/abs/2505.07380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07380">https://arxiv.org/pdf/2505.07380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07380]] Apple's Synthetic Defocus Noise Pattern: Characterization and Forensic Applications(https://arxiv.org/abs/2505.07380)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>iPhone portrait-mode images contain a distinctive pattern in out-of-focus regions simulating the bokeh effect, which we term Apple's Synthetic Defocus Noise Pattern (SDNP). If overlooked, this pattern can interfere with blind forensic analyses, especially PRNU-based camera source verification, as noted in earlier works. Since Apple's SDNP remains underexplored, we provide a detailed characterization, proposing a method for its precise estimation, modeling its dependence on scene brightness, ISO settings, and other factors. Leveraging this characterization, we explore forensic applications of the SDNP, including traceability of portrait-mode images across iPhone models and iOS versions in open-set scenarios, assessing its robustness under post-processing. Furthermore, we show that masking SDNP-affected regions in PRNU-based camera source verification significantly reduces false positives, overcoming a critical limitation in camera attribution, and improving state-of-the-art techniques.</li>
</ul>

<h3>Title: TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset</h3>
<ul>
<li><strong>Authors: </strong>Olaf Wysocki, Benedikt Schwab, Manoj Kumar Biswanath, Qilin Zhang, Jingwei Zhu, Thomas Froech, Medhini Heeramaglore, Ihab Hijazi, Khaoula Kanna, Mathias Pechinger, Zhaiyu Chen, Yao Sun, Alejandro Rueda Segura, Ziyang Xu, Omar AbdelGafar, Mansour Mehranfar, Chandan Yeshwanth, Yueh-Cheng Liu, Hadi Yazdi, Jiapan Wang, Stefan Auer, Katharina Anders, Klaus Bogenberger, Andre Borrmann, Angela Dai, Ludwig Hoegner, Christoph Holst, Thomas H. Kolbe, Ferdinand Ludwig, Matthias Nießner, Frank Petzold, Xiao Xiang Zhu, Boris Jutzi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07396">https://arxiv.org/abs/2505.07396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07396">https://arxiv.org/pdf/2505.07396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07396]] TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset(https://arxiv.org/abs/2505.07396)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Urban Digital Twins (UDTs) have become essential for managing cities and integrating complex, heterogeneous data from diverse sources. Creating UDTs involves challenges at multiple process stages, including acquiring accurate 3D source data, reconstructing high-fidelity 3D models, maintaining models' updates, and ensuring seamless interoperability to downstream tasks. Current datasets are usually limited to one part of the processing chain, hampering comprehensive UDTs validation. To address these challenges, we introduce the first comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN. This dataset includes georeferenced, semantically aligned 3D models and networks along with various terrestrial, mobile, aerial, and satellite observations boasting 32 data subsets over roughly 100,000 $m^2$ and currently 767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high accuracy, and multimodal data integration, the benchmark supports robust analysis of sensors and the development of advanced reconstruction methods. Additionally, we explore downstream tasks demonstrating the potential of TUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar potential analysis, point cloud semantic segmentation, and LoD3 building reconstruction. We are convinced this contribution lays a foundation for overcoming current limitations in UDT creation, fostering new research directions and practical solutions for smarter, data-driven urban environments. The project is available under: this https URL</li>
</ul>

<h3>Title: DepthFusion: Depth-Aware Hybrid Feature Fusion for LiDAR-Camera 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Mingqian Ji, Jian Yang, Shanshan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07398">https://arxiv.org/abs/2505.07398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07398">https://arxiv.org/pdf/2505.07398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07398]] DepthFusion: Depth-Aware Hybrid Feature Fusion for LiDAR-Camera 3D Object Detection(https://arxiv.org/abs/2505.07398)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>State-of-the-art LiDAR-camera 3D object detectors usually focus on feature fusion. However, they neglect the factor of depth while designing the fusion strategy. In this work, we are the first to observe that different modalities play different roles as depth varies via statistical analysis and visualization. Based on this finding, we propose a Depth-Aware Hybrid Feature Fusion (DepthFusion) strategy that guides the weights of point cloud and RGB image modalities by introducing depth encoding at both global and local levels. Specifically, the Depth-GFusion module adaptively adjusts the weights of image Bird's-Eye-View (BEV) features in multi-modal global features via depth encoding. Furthermore, to compensate for the information lost when transferring raw features to the BEV space, we propose a Depth-LFusion module, which adaptively adjusts the weights of original voxel features and multi-view image features in multi-modal local features via depth encoding. Extensive experiments on the nuScenes and KITTI datasets demonstrate that our DepthFusion method surpasses previous state-of-the-art methods. Moreover, our DepthFusion is more robust to various kinds of corruptions, outperforming previous methods on the nuScenes-C dataset.</li>
</ul>

<h3>Title: Computational Fact-Checking of Online Discourse: Scoring scientific accuracy in climate change related news articles</h3>
<ul>
<li><strong>Authors: </strong>Tim Wittenborg, Constantin Sebastian Tremel, Markus Stocker, Sören Auer</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07409">https://arxiv.org/abs/2505.07409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07409">https://arxiv.org/pdf/2505.07409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07409]] Computational Fact-Checking of Online Discourse: Scoring scientific accuracy in climate change related news articles(https://arxiv.org/abs/2505.07409)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair</a></li>
<li><strong>Abstract: </strong>Democratic societies need reliable information. Misinformation in popular media such as news articles or videos threatens to impair civic discourse. Citizens are, unfortunately, not equipped to verify this content flood consumed daily at increasing rates. This work aims to semi-automatically quantify scientific accuracy of online media. By semantifying media of unknown veracity, their statements can be compared against equally processed trusted sources. We implemented a workflow using LLM-based statement extraction and knowledge graph analysis. Our neurosymbolic system was able to evidently streamline state-of-the-art veracity quantification. Evaluated via expert interviews and a user survey, the tool provides a beneficial veracity indication. This indicator, however, is unable to annotate public media at the required granularity and scale. Further work towards a FAIR (Findable, Accessible, Interoperable, Reusable) ground truth and complementary metrics are required to scientifically support civic discourse.</li>
</ul>

<h3>Title: Learning Penalty for Optimal Partitioning via Automatic Feature Extraction</h3>
<ul>
<li><strong>Authors: </strong>Tung L Nguyen, Toby Hocking</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07413">https://arxiv.org/abs/2505.07413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07413">https://arxiv.org/pdf/2505.07413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07413]] Learning Penalty for Optimal Partitioning via Automatic Feature Extraction(https://arxiv.org/abs/2505.07413)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Changepoint detection identifies significant shifts in data sequences, making it important in areas like finance, genetics, and healthcare. The Optimal Partitioning algorithms efficiently detect these changes, using a penalty parameter to limit the changepoints number. Determining the appropriate value for this penalty can be challenging. Traditionally, this process involved manually extracting statistical features, such as sequence length or variance to make the prediction. This study proposes a novel approach that uses recurrent neural networks to learn this penalty directly from raw sequences by automatically extracting features. Experiments conducted on 20 benchmark genomic datasets show that this novel method surpasses traditional methods in partitioning accuracy in most cases.</li>
</ul>

<h3>Title: LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Xiaotian Lin, Yanlin Qi, Yizhang Zhu, Themis Palpanas, Chengliang Chai, Nan Tang, Yuyu Luo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07437">https://arxiv.org/abs/2505.07437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07437">https://arxiv.org/pdf/2505.07437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07437]] LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning(https://arxiv.org/abs/2505.07437)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning has emerged as a critical paradigm for improving the capabilities and alignment of large language models (LLMs). However, existing iterative model-aware data selection methods incur significant computational overhead, as they rely on repeatedly performing full-dataset model inference to estimate sample utility for subsequent training iterations, creating a fundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient iterative data selection framework that accurately estimates sample utility entirely within the standard training loop, eliminating the need for costly additional model inference. At its core, LEAD introduces Instance-Level Dynamic Uncertainty (IDU), a theoretically grounded utility function combining instantaneous training loss, gradient-based approximation of loss changes, and exponential smoothing of historical loss signals. To further scale efficiently to large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy, adaptively prioritizing informative clusters through a multi-armed bandit mechanism, followed by precise fine-grained selection of high-utility samples using IDU. Extensive experiments across four diverse benchmarks show that LEAD significantly outperforms state-of-the-art methods, improving average model performance by 6.1%-10.8% while using only 2.5% of the training data and reducing overall training time by 5-10x.</li>
</ul>

<h3>Title: Lightweight Multispectral Crop-Weed Segmentation for Precision Agriculture</h3>
<ul>
<li><strong>Authors: </strong>Zeynep Galymzhankyzy, Eric Martinson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07444">https://arxiv.org/abs/2505.07444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07444">https://arxiv.org/pdf/2505.07444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07444]] Lightweight Multispectral Crop-Weed Segmentation for Precision Agriculture(https://arxiv.org/abs/2505.07444)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Efficient crop-weed segmentation is critical for site-specific weed control in precision agriculture. Conventional CNN-based methods struggle to generalize and rely on RGB imagery, limiting performance under complex field conditions. To address these challenges, we propose a lightweight transformer-CNN hybrid. It processes RGB, Near-Infrared (NIR), and Red-Edge (RE) bands using specialized encoders and dynamic modality integration. Evaluated on the WeedsGalore dataset, the model achieves a segmentation accuracy (mean IoU) of 78.88%, outperforming RGB-only models by 15.8 percentage points. With only 8.7 million parameters, the model offers high accuracy, computational efficiency, and potential for real-time deployment on Unmanned Aerial Vehicles (UAVs) and edge devices, advancing precision weed management.</li>
</ul>

<h3>Title: Unified Continuous Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Peng Sun, Yi Jiang, Tao Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07447">https://arxiv.org/abs/2505.07447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07447">https://arxiv.org/pdf/2505.07447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07447]] Unified Continuous Generative Models(https://arxiv.org/abs/2505.07447)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in continuous generative models, including multi-step approaches like diffusion and flow-matching (typically requiring 8-1000 sampling steps) and few-step methods such as consistency models (typically 1-8 steps), have demonstrated impressive generative performance. However, existing work often treats these approaches as distinct paradigms, resulting in separate training and sampling methodologies. We introduce a unified framework for training, sampling, and analyzing these models. Our implementation, the Unified Continuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves state-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a 675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID in 20 steps and a few-step model reaching 1.42 FID in just 2 steps. Additionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at 250 steps) improves performance to 1.06 FID in only 40 steps. Code is available at: this https URL.</li>
</ul>

<h3>Title: You Only Look One Step: Accelerating Backpropagation in Diffusion Sampling with Gradient Shortcuts</h3>
<ul>
<li><strong>Authors: </strong>Hongkun Dou, Zeyu Li, Xingyu Jiang, Hongjue Li, Lijun Yang, Wen Yao, Yue Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07477">https://arxiv.org/abs/2505.07477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07477">https://arxiv.org/pdf/2505.07477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07477]] You Only Look One Step: Accelerating Backpropagation in Diffusion Sampling with Gradient Shortcuts(https://arxiv.org/abs/2505.07477)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have recently demonstrated remarkable success in modeling large-scale data distributions. However, many downstream tasks require guiding the generated content based on specific differentiable metrics, typically necessitating backpropagation during the generation process. This approach is computationally expensive, as generating with DMs often demands tens to hundreds of recursive network calls, resulting in high memory usage and significant time consumption. In this paper, we propose a more efficient alternative that approaches the problem from the perspective of parallel denoising. We show that full backpropagation throughout the entire generation process is unnecessary. The downstream metrics can be optimized by retaining the computational graph of only one step during generation, thus providing a shortcut for gradient propagation. The resulting method, which we call Shortcut Diffusion Optimization (SDO), is generic, high-performance, and computationally lightweight, capable of optimizing all parameter types in diffusion sampling. We demonstrate the effectiveness of SDO on several real-world tasks, including controlling generation by optimizing latent and aligning the DMs by fine-tuning network parameters. Compared to full backpropagation, our approach reduces computational costs by $\sim 90\%$ while maintaining superior performance. Code is available at this https URL.</li>
</ul>

<h3>Title: Addressing degeneracies in latent interpolation for diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Erik Landolsi, Fredrik Kahl</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07481">https://arxiv.org/abs/2505.07481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07481">https://arxiv.org/pdf/2505.07481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07481]] Addressing degeneracies in latent interpolation for diffusion models(https://arxiv.org/abs/2505.07481)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>There is an increasing interest in using image-generating diffusion models for deep data augmentation and image morphing. In this context, it is useful to interpolate between latents produced by inverting a set of input images, in order to generate new images representing some mixture of the inputs. We observe that such interpolation can easily lead to degenerate results when the number of inputs is large. We analyze the cause of this effect theoretically and experimentally, and suggest a suitable remedy. The suggested approach is a relatively simple normalization scheme that is easy to use whenever interpolation between latents is needed. We measure image quality using FID and CLIP embedding distance and show experimentally that baseline interpolation methods lead to a drop in quality metrics long before the degeneration issue is clearly visible. In contrast, our method significantly reduces the degeneration effect and leads to improved quality metrics also in non-degenerate situations.</li>
</ul>

<h3>Title: DocVXQA: Context-Aware Visual Explanations for Document Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Ali Souibgui, Changkyu Choi, Andrey Barsky, Kangsoo Jung, Ernest Valveny, Dimosthenis Karatzas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07496">https://arxiv.org/abs/2505.07496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07496">https://arxiv.org/pdf/2505.07496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07496]] DocVXQA: Context-Aware Visual Explanations for Document Question Answering(https://arxiv.org/abs/2505.07496)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We propose DocVXQA, a novel framework for visually self-explainable document question answering. The framework is designed not only to produce accurate answers to questions but also to learn visual heatmaps that highlight contextually critical regions, thereby offering interpretable justifications for the model's decisions. To integrate explanations into the learning process, we quantitatively formulate explainability principles as explicit learning objectives. Unlike conventional methods that emphasize only the regions pertinent to the answer, our framework delivers explanations that are \textit{contextually sufficient} while remaining \textit{representation-efficient}. This fosters user trust while achieving a balance between predictive performance and interpretability in DocVQA applications. Extensive experiments, including human evaluation, provide strong evidence supporting the effectiveness of our method. The code is available at this https URL.</li>
</ul>

<h3>Title: Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Bahram Mohammadi, Ehsan Abbasnejad, Yuankai Qi, Qi Wu, Anton Van Den Hengel, Javen Qinfeng Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07500">https://arxiv.org/abs/2505.07500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07500">https://arxiv.org/pdf/2505.07500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07500]] Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models(https://arxiv.org/abs/2505.07500)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The remote embodied referring expression (REVERIE) task requires an agent to navigate through complex indoor environments and localize a remote object specified by high-level instructions, such as "bring me a spoon", without pre-exploration. Hence, an efficient navigation plan is essential for the final success. This paper proposes a novel parameter-efficient action planner using large language models (PEAP-LLM) to generate a single-step instruction at each location. The proposed model consists of two modules, LLM goal planner (LGP) and LoRA action planner (LAP). Initially, LGP extracts the goal-oriented plan from REVERIE instructions, including the target object and room. Then, LAP generates a single-step instruction with the goal-oriented plan, high-level instruction, and current visual observation as input. PEAP-LLM enables the embodied agent to interact with LAP as the path planner on the fly. A simple direct application of LLMs hardly achieves good performance. Also, existing hard-prompt-based methods are error-prone in complicated scenarios and need human intervention. To address these issues and prevent the LLM from generating hallucinations and biased information, we propose a novel two-stage method for fine-tuning the LLM, consisting of supervised fine-tuning (STF) and direct preference optimization (DPO). SFT improves the quality of generated instructions, while DPO utilizes environmental feedback. Experimental results show the superiority of our proposed model on REVERIE compared to the previous state-of-the-art.</li>
</ul>

<h3>Title: MAIS: Memory-Attention for Interactive Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mauricio Orbes-Arteaga, Oeslle Lucena, Sabastien Ourselin, M. Jorge Cardoso</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07511">https://arxiv.org/abs/2505.07511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07511">https://arxiv.org/pdf/2505.07511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07511]] MAIS: Memory-Attention for Interactive Segmentation(https://arxiv.org/abs/2505.07511)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Interactive medical segmentation reduces annotation effort by refining predictions through user feedback. Vision Transformer (ViT)-based models, such as the Segment Anything Model (SAM), achieve state-of-the-art performance using user clicks and prior masks as prompts. However, existing methods treat interactions as independent events, leading to redundant corrections and limited refinement gains. We address this by introducing MAIS, a Memory-Attention mechanism for Interactive Segmentation that stores past user inputs and segmentation states, enabling temporal context integration. Our approach enhances ViT-based segmentation across diverse imaging modalities, achieving more efficient and accurate refinements.</li>
</ul>

<h3>Title: ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution</h3>
<ul>
<li><strong>Authors: </strong>Xu Huang, Weiwen Liu, Xingshan Zeng, Yuefeng Huang, Xinlong Hao, Yuxian Wang, Yirong Zeng, Chuhan Wu, Yasheng Wang, Ruiming Tang, Defu Lian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07512">https://arxiv.org/abs/2505.07512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07512">https://arxiv.org/pdf/2505.07512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07512]] ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution(https://arxiv.org/abs/2505.07512)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The tool-using capability of large language models (LLMs) enables them to access up-to-date external information and handle complex tasks. Current approaches to enhancing this capability primarily rely on distilling advanced models by data synthesis. However, this method incurs significant costs associated with advanced model usage and often results in data compatibility issues, led by the high discrepancy in the knowledge scope between the advanced model and the target model. To address these challenges, we propose ToolACE-DEV, a self-improving framework for tool learning. First, we decompose the tool-learning objective into sub-tasks that enhance basic tool-making and tool-using abilities. Then, we introduce a self-evolving paradigm that allows lightweight models to self-improve, reducing reliance on advanced LLMs. Extensive experiments validate the effectiveness of our approach across models of varying scales and architectures.</li>
</ul>

<h3>Title: Adaptive Latent-Space Constraints in Personalized FL</h3>
<ul>
<li><strong>Authors: </strong>Sana Ayromlou, D. B. Emerson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07525">https://arxiv.org/abs/2505.07525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07525">https://arxiv.org/pdf/2505.07525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07525]] Adaptive Latent-Space Constraints in Personalized FL(https://arxiv.org/abs/2505.07525)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has become an effective and widely used approach to training deep learning models on decentralized datasets held by distinct clients. FL also strengthens both security and privacy protections for training data. Common challenges associated with statistical heterogeneity between distributed datasets have spurred significant interest in personalized FL (pFL) methods, where models combine aspects of global learning with local modeling specific to each client's unique characteristics. In this work, the efficacy of theoretically supported, adaptive MMD measures within the Ditto framework, a state-of-the-art technique in pFL, are investigated. The use of such measures significantly improves model performance across a variety of tasks, especially those with pronounced feature heterogeneity. While the Ditto algorithm is specifically considered, such measures are directly applicable to a number of other pFL settings, and the results motivate the use of constraints tailored to the various kinds of heterogeneity expected in FL systems.</li>
</ul>

<h3>Title: FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images</h3>
<ul>
<li><strong>Authors: </strong>Raul Ismayilov, Luuk Spreeuwers, Dzemila Sero</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07530">https://arxiv.org/abs/2505.07530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07530">https://arxiv.org/pdf/2505.07530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07530]] FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images(https://arxiv.org/abs/2505.07530)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, biometric</a></li>
<li><strong>Abstract: </strong>Synthetic face datasets are increasingly used to overcome the limitations of real-world biometric data, including privacy concerns, demographic imbalance, and high collection costs. However, many existing methods lack fine-grained control over identity attributes and fail to produce paired, identity-consistent images under structured capture conditions. We introduce FLUXSynID, a framework for generating high-resolution synthetic face datasets with user-defined identity attribute distributions and paired document-style and trusted live capture images. The dataset generated using the FLUXSynID framework shows improved alignment with real-world identity distributions and greater inter-set diversity compared to prior work. The FLUXSynID framework for generating custom datasets, along with a dataset of 14,889 synthetic identities, is publicly released to support biometric research, including face recognition and morphing attack detection.</li>
</ul>

<h3>Title: Post-Quantum Secure Decentralized Random Number Generation Protocol with Two Rounds of Communication in the Standard Model</h3>
<ul>
<li><strong>Authors: </strong>Pham Nhat Minh, Khuong Nguyen-An</a></li>
<li><strong>Subjects: </strong>cs.CR, math.NT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07536">https://arxiv.org/abs/2505.07536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07536">https://arxiv.org/pdf/2505.07536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07536]] Post-Quantum Secure Decentralized Random Number Generation Protocol with Two Rounds of Communication in the Standard Model(https://arxiv.org/abs/2505.07536)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Randomness plays a vital role in numerous applications, including simulation, cryptography, distributed systems, and gaming. Consequently, extensive research has been conducted to generate randomness. One such method is to design a decentralized random number generator (DRNG), a protocol that enables multiple participants to collaboratively generate random outputs that must be publicly verifiable. However, existing DRNGs are either not secure against quantum computers or depend on the random oracle model (ROM) to achieve security. In this paper, we design a DRNG based on lattice-based publicly verifiable secret sharing (PVSS) that is post-quantum secure and proven secure in the standard model. Additionally, our DRNG requires only two rounds of communication to generate a single (pseudo)random value and can tolerate up to any t < n/2 dishonest participants. To our knowledge, the proposed DRNG construction is the first to achieve all these properties.</li>
</ul>

<h3>Title: Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Bohan Wang, Zhongqi Yue, Fengda Zhang, Shuo Chen, Li'an Bi, Junzhe Zhang, Xue Song, Kennard Yanting Chan, Jiachun Pan, Weijia Wu, Mingze Zhou, Wang Lin, Kaihang Pan, Saining Zhang, Liyu Jia, Wentao Hu, Wei Zhao, Hanwang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07538">https://arxiv.org/abs/2505.07538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07538">https://arxiv.org/pdf/2505.07538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07538]] Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning(https://arxiv.org/abs/2505.07538)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We completely discard the conventional spatial prior in image representation and introduce a novel discrete visual tokenizer: Self-consistency Tokenizer (Selftok). At its design core, we compose an autoregressive (AR) prior -- mirroring the causal structure of language -- into visual tokens by using the reverse diffusion process of image generation. The AR property makes Selftok fundamentally distinct from traditional spatial tokens in the following two key ways: - Selftok offers an elegant and minimalist approach to unify diffusion and AR for vision-language models (VLMs): By representing images with Selftok tokens, we can train a VLM using a purely discrete autoregressive architecture -- like that in LLMs -- without requiring additional modules or training objectives. - We theoretically show that the AR prior satisfies the Bellman equation, whereas the spatial prior does not. Therefore, Selftok supports reinforcement learning (RL) for visual generation with effectiveness comparable to that achieved in LLMs. Besides the AR property, Selftok is also a SoTA tokenizer that achieves a favorable trade-off between high-quality reconstruction and compression rate. We use Selftok to build a pure AR VLM for both visual comprehension and generation tasks. Impressively, without using any text-image training pairs, a simple policy gradient RL working in the visual tokens can significantly boost the visual generation benchmark, surpassing all the existing models by a large margin. Therefore, we believe that Selftok effectively addresses the long-standing challenge that visual tokens cannot support effective RL. When combined with the well-established strengths of RL in LLMs, this brings us one step closer to realizing a truly multimodal LLM. Project Page: this https URL.</li>
</ul>

<h3>Title: SynID: Passport Synthetic Dataset for Presentation Attack Detection</h3>
<ul>
<li><strong>Authors: </strong>Juan E. Tapia, Fabian Stockhardt, Lázaro Janier González-Soler, Christoph Busch</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07540">https://arxiv.org/abs/2505.07540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07540">https://arxiv.org/pdf/2505.07540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07540]] SynID: Passport Synthetic Dataset for Presentation Attack Detection(https://arxiv.org/abs/2505.07540)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>The demand for Presentation Attack Detection (PAD) to identify fraudulent ID documents in remote verification systems has significantly risen in recent years. This increase is driven by several factors, including the rise of remote work, online purchasing, migration, and advancements in synthetic images. Additionally, we have noticed a surge in the number of attacks aimed at the enrolment process. Training a PAD to detect fake ID documents is very challenging because of the limited number of ID documents available due to privacy concerns. This work proposes a new passport dataset generated from a hybrid method that combines synthetic data and open-access information using the ICAO requirement to obtain realistic training and testing images.</li>
</ul>

<h3>Title: Noise Optimized Conditional Diffusion for Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Lingkun Luo, Shiqiang Hu, Liming Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07548">https://arxiv.org/abs/2505.07548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07548">https://arxiv.org/pdf/2505.07548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07548]] Noise Optimized Conditional Diffusion for Domain Adaptation(https://arxiv.org/abs/2505.07548)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet the scarcity of High-Confidence Pseudo-Labeled Target Domain Samples (\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical alignment, causing DA failures. To address this challenge, we propose \textbf{N}oise \textbf{O}ptimized \textbf{C}onditional \textbf{D}iffusion for \textbf{D}omain \textbf{A}daptation (\textbf{NOCDDA}), which seamlessly integrates the generative capabilities of conditional diffusion models with the decision-making requirements of DA to achieve task-coupled optimization for efficient adaptation. For robust cross-domain consistency, we modify the DA classifier to align with the conditional diffusion classifier within a unified optimization framework, enabling forward training on noise-varying cross-domain samples. Furthermore, we argue that the conventional \( \mathcal{N}(\mathbf{0}, \mathbf{I}) \) initialization in diffusion models often generates class-confused hcpl-tds, compromising discriminative DA. To resolve this, we introduce a class-aware noise optimization strategy that refines sampling regions for reverse class-specific hcpl-tds generation, effectively enhancing cross-domain alignment. Extensive experiments across 5 benchmark datasets and 29 DA tasks demonstrate significant performance gains of \textbf{NOCDDA} over 31 state-of-the-art methods, validating its robustness and effectiveness.</li>
</ul>

<h3>Title: Injecting Knowledge Graphs into Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Erica Coppolillo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07554">https://arxiv.org/abs/2505.07554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07554">https://arxiv.org/pdf/2505.07554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07554]] Injecting Knowledge Graphs into Large Language Models(https://arxiv.org/abs/2505.07554)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Integrating structured knowledge from Knowledge Graphs (KGs) into Large Language Models (LLMs) remains a key challenge for symbolic reasoning. Existing methods mainly rely on prompt engineering or fine-tuning, which lose structural fidelity or incur high computational costs. Building on recent encoding techniques which integrate graph embeddings within the LLM input as tokens, we extend this paradigm to the KG domain by leveraging Knowledge Graph Embedding (KGE) models, thus enabling graph-aware reasoning. Our approach is model-agnostic, resource-efficient, and compatible with any LLMs. Extensive experimentation on synthetic and real-world datasets shows that our method improves reasoning performance over established baselines, further achieving the best trade-off in terms of accuracy and efficiency against state-of-the-art LLMs.</li>
</ul>

<h3>Title: Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs</h3>
<ul>
<li><strong>Authors: </strong>Kamil Jeziorek, Tomasz Kryjak</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07556">https://arxiv.org/abs/2505.07556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07556">https://arxiv.org/pdf/2505.07556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07556]] Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs(https://arxiv.org/abs/2505.07556)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Event cameras offer significant advantages over traditional frame-based sensors. These include microsecond temporal resolution, robustness under varying lighting conditions and low power consumption. Nevertheless, the effective processing of their sparse, asynchronous event streams remains challenging. Existing approaches to this problem can be categorised into two distinct groups. The first group involves the direct processing of event data with neural models, such as Spiking Neural Networks or Graph Convolutional Neural Networks. However, this approach is often accompanied by a compromise in terms of qualitative performance. The second group involves the conversion of events into dense representations with handcrafted aggregation functions, which can boost accuracy at the cost of temporal fidelity. This paper introduces a novel Self-Supervised Event Representation (SSER) method leveraging Gated Recurrent Unit (GRU) networks to achieve precise per-pixel encoding of event timestamps and polarities without temporal discretisation. The recurrent layers are trained in a self-supervised manner to maximise the fidelity of event-time encoding. The inference is performed with event representations generated asynchronously, thus ensuring compatibility with high-throughput sensors. The experimental validation demonstrates that SSER outperforms aggregation-based baselines, achieving improvements of 2.4% mAP and 0.6% on the Gen1 and 1 Mpx object detection datasets. Furthermore, the paper presents the first hardware implementation of recurrent representation for event data on a System-on-Chip FPGA, achieving sub-microsecond latency and power consumption between 1-2 W, suitable for real-time, power-efficient applications. Code is available at this https URL.</li>
</ul>

<h3>Title: Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Rei Higuchi, Taiji Suzuki</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07558">https://arxiv.org/abs/2505.07558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07558">https://arxiv.org/pdf/2505.07558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07558]] Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models(https://arxiv.org/abs/2505.07558)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human preferences is crucial for safe deployment, yet existing methods assume specific preference models like Bradley-Terry model. This assumption leads to statistical inconsistency, where more data doesn't guarantee convergence to true human preferences. To address this critical gap, we introduce a novel alignment method Direct Density Ratio Optimization (DDRO). DDRO directly estimates the density ratio between preferred and unpreferred output distributions, circumventing the need for explicit human preference modeling. We theoretically prove that DDRO is statistically consistent, ensuring convergence to the true preferred distribution as the data size grows, regardless of the underlying preference structure. Experiments demonstrate that DDRO achieves superior performance compared to existing methods on many major benchmarks. DDRO unlocks the potential for truly data-driven alignment, paving the way for more reliable and human-aligned LLMs.</li>
</ul>

<h3>Title: Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework</h3>
<ul>
<li><strong>Authors: </strong>Sarah de Boer, Hartmut Häntze, Kiran Vaidhya Venkadesh, Myrthe A. D. Buser, Gabriel E. Humpire Mamani, Lina Xu, Lisa C. Adams, Jawed Nawabi, Keno K. Bressem, Bram van Ginneken, Mathias Prokop, Alessa Hering</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07573">https://arxiv.org/abs/2505.07573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07573">https://arxiv.org/pdf/2505.07573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07573]] Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework(https://arxiv.org/abs/2505.07573)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Kidney abnormality segmentation has important potential to enhance the clinical workflow, especially in settings requiring quantitative assessments. Kidney volume could serve as an important biomarker for renal diseases, with changes in volume correlating directly with kidney function. Currently, clinical practice often relies on subjective visual assessment for evaluating kidney size and abnormalities, including tumors and cysts, which are typically staged based on diameter, volume, and anatomical location. To support a more objective and reproducible approach, this research aims to develop a robust, thoroughly validated kidney abnormality segmentation algorithm, made publicly available for clinical and research use. We employ publicly available training datasets and leverage the state-of-the-art medical image segmentation framework nnU-Net. Validation is conducted using both proprietary and public test datasets, with segmentation performance quantified by Dice coefficient and the 95th percentile Hausdorff distance. Furthermore, we analyze robustness across subgroups based on patient sex, age, CT contrast phases, and tumor histologic subtypes. Our findings demonstrate that our segmentation algorithm, trained exclusively on publicly available data, generalizes effectively to external test sets and outperforms existing state-of-the-art models across all tested datasets. Subgroup analyses reveal consistent high performance, indicating strong robustness and reliability. The developed algorithm and associated code are publicly accessible at this https URL.</li>
</ul>

<h3>Title: Security through the Eyes of AI: How Visualization is Shaping Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Asmitha K. A., Matteo Brosolo, Serena Nicolazzo, Antonino Nocera, Vinod P., Rafidha Rehiman K. A., Muhammed Shafi K. P</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07574">https://arxiv.org/abs/2505.07574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07574">https://arxiv.org/pdf/2505.07574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07574]] Security through the Eyes of AI: How Visualization is Shaping Malware Detection(https://arxiv.org/abs/2505.07574)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Malware, a persistent cybersecurity threat, increasingly targets interconnected digital systems such as desktop, mobile, and IoT platforms through sophisticated attack vectors. By exploiting these vulnerabilities, attackers compromise the integrity and resilience of modern digital ecosystems. To address this risk, security experts actively employ Machine Learning or Deep Learning-based strategies, integrating static, dynamic, or hybrid approaches to categorize malware instances. Despite their advantages, these methods have inherent drawbacks and malware variants persistently evolve with increased sophistication, necessitating advancements in detection strategies. Visualization-based techniques are emerging as scalable and interpretable solutions for detecting and understanding malicious behaviors across diverse platforms including desktop, mobile, IoT, and distributed systems as well as through analysis of network packet capture files. In this comprehensive survey of more than 100 high-quality research articles, we evaluate existing visualization-based approaches applied to malware detection and classification. As a first contribution, we propose a new all-encompassing framework to study the landscape of visualization-based malware detection techniques. Within this framework, we systematically analyze state-of-the-art approaches across the critical stages of the malware detection pipeline. By analyzing not only the single techniques but also how they are combined to produce the final solution, we shed light on the main challenges in visualization-based approaches and provide insights into the advancements and potential future directions in this critical field.</li>
</ul>

<h3>Title: Personalized Federated Learning under Model Dissimilarity Constraints</h3>
<ul>
<li><strong>Authors: </strong>Samuel Erickson, Mikael Johansson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07575">https://arxiv.org/abs/2505.07575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07575">https://arxiv.org/pdf/2505.07575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07575]] Personalized Federated Learning under Model Dissimilarity Constraints(https://arxiv.org/abs/2505.07575)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>One of the defining challenges in federated learning is that of statistical heterogeneity among clients. We address this problem with KARULA, a regularized strategy for personalized federated learning, which constrains the pairwise model dissimilarities between clients based on the difference in their distributions, as measured by a surrogate for the 1-Wasserstein distance adapted for the federated setting. This allows the strategy to adapt to highly complex interrelations between clients, that e.g., clustered approaches fail to capture. We propose an inexact projected stochastic gradient algorithm to solve the constrained problem that the strategy defines, and show theoretically that it converges with smooth, possibly non-convex losses to a neighborhood of a stationary point with rate O(1/K). We demonstrate the effectiveness of KARULA on synthetic and real federated data sets.</li>
</ul>

<h3>Title: SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Huining Cui, Wei Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07584">https://arxiv.org/abs/2505.07584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07584">https://arxiv.org/pdf/2505.07584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07584]] SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models(https://arxiv.org/abs/2505.07584)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>The increasing deployment of large language models in security-sensitive domains necessitates rigorous evaluation of their resilience against adversarial prompt-based attacks. While previous benchmarks have focused on security evaluations with limited and predefined attack domains, such as cybersecurity attacks, they often lack a comprehensive assessment of intent-driven adversarial prompts and the consideration of real-life scenario-based multi-turn attacks. To address this gap, we present SecReEvalBench, the Security Resilience Evaluation Benchmark, which defines four novel metrics: Prompt Attack Resilience Score, Prompt Attack Refusal Logic Score, Chain-Based Attack Resilience Score and Chain-Based Attack Rejection Time Score. Moreover, SecReEvalBench employs six questioning sequences for model assessment: one-off attack, successive attack, successive reverse attack, alternative attack, sequential ascending attack with escalating threat levels and sequential descending attack with diminishing threat levels. In addition, we introduce a dataset customized for the benchmark, which incorporates both neutral and malicious prompts, categorised across seven security domains and sixteen attack techniques. In applying this benchmark, we systematically evaluate five state-of-the-art open-weighted large language models, Llama 3.1, Gemma 2, Mistral v0.3, DeepSeek-R1 and Qwen 3. Our findings offer critical insights into the strengths and weaknesses of modern large language models in defending against evolving adversarial threats. The SecReEvalBench dataset is publicly available at this https URL, which provides a groundwork for advancing research in large language model security.</li>
</ul>

<h3>Title: A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junjie Ye, Caishuang Huang, Zhuohan Chen, Wenjie Fu, Chenyuan Yang, Leyi Yang, Yilong Wu, Peng Wang, Meng Zhou, Xiaolong Yang, Tao Gui, Qi Zhang, Zhongchao Shi, Jianping Fan, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07591">https://arxiv.org/abs/2505.07591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07591">https://arxiv.org/pdf/2505.07591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07591]] A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models(https://arxiv.org/abs/2505.07591)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction following evaluates large language models (LLMs) on their ability to generate outputs that adhere to user-defined constraints. However, existing benchmarks often rely on templated constraint prompts, which lack the diversity of real-world usage and limit fine-grained performance assessment. To fill this gap, we propose a multi-dimensional constraint framework encompassing three constraint patterns, four constraint categories, and four difficulty levels. Building on this framework, we develop an automated instruction generation pipeline that performs constraint expansion, conflict detection, and instruction rewriting, yielding 1,200 code-verifiable instruction-following test samples. We evaluate 19 LLMs across seven model families and uncover substantial variation in performance across constraint forms. For instance, average performance drops from 77.67% at Level I to 32.96% at Level IV. Furthermore, we demonstrate the utility of our approach by using it to generate data for reinforcement learning, achieving substantial gains in instruction following without degrading general performance. In-depth analysis indicates that these gains stem primarily from modifications in the model's attention modules parameters, which enhance constraint recognition and adherence. Code and data are available in this https URL.</li>
</ul>

<h3>Title: Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Huang, Xiaowei Yuan, Yiming Ju, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07596">https://arxiv.org/abs/2505.07596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07596">https://arxiv.org/pdf/2505.07596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07596]] Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent(https://arxiv.org/abs/2505.07596)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead to redundant retrievals, potential harmful knowledge conflicts, and increased inference latency. To address these limitations, an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric (internal) and retrieved (external) knowledge is in urgent need. This paper introduces the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge, resorting to external search only when internal knowledge is deemed insufficient. This is achieved using a novel knowledge-boundary aware reward function and a knowledge-boundary aware training dataset. These are designed for internal-external knowledge synergy oriented RL, incentivizing the model to deliver accurate answers, minimize unnecessary retrievals, and encourage appropriate external searches when its own knowledge is lacking. Evaluations across multiple knowledge reasoning tasks demonstrate that IKEA significantly outperforms baseline methods, reduces retrieval frequency significantly, and exhibits robust generalization capabilities.</li>
</ul>

<h3>Title: Characterizing the Investigative Methods of Fictional Detectives with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Edirlei Soares de Lima, Marco A. Casanova, Bruno Feijó, Antonio L. Furtado</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07601">https://arxiv.org/abs/2505.07601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07601">https://arxiv.org/pdf/2505.07601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07601]] Characterizing the Investigative Methods of Fictional Detectives with Large Language Models(https://arxiv.org/abs/2505.07601)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Detective fiction, a genre defined by its complex narrative structures and character-driven storytelling, presents unique challenges for computational narratology, a research field focused on integrating literary theory into automated narrative generation. While traditional literary studies have offered deep insights into the methods and archetypes of fictional detectives, these analyses often focus on a limited number of characters and lack the scalability needed for the extraction of unique traits that can be used to guide narrative generation methods. In this paper, we present an AI-driven approach for systematically characterizing the investigative methods of fictional detectives. Our multi-phase workflow explores the capabilities of 15 Large Language Models (LLMs) to extract, synthesize, and validate distinctive investigative traits of fictional detectives. This approach was tested on a diverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes, William Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin - capturing the distinctive investigative styles that define each character. The identified traits were validated against existing literary analyses and further tested in a reverse identification phase, achieving an overall accuracy of 91.43%, demonstrating the method's effectiveness in capturing the distinctive investigative approaches of each detective. This work contributes to the broader field of computational narratology by providing a scalable framework for character analysis, with potential applications in AI-driven interactive storytelling and automated narrative generation.</li>
</ul>

<h3>Title: MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining</h3>
<ul>
<li><strong>Authors: </strong>Xiaomi LLM-Core Team: Bingquan Xia, Bowen Shen, Cici, Dawei Zhu, Di Zhang, Gang Wang, Hailin Zhang, Huaqiu Liu, Jiebao Xiao, Jinhao Dong, Liang Zhao, Peidian Li, Peng Wang, Shihua Yu, Shimao Chen, Weikun Wang, Wenhan Ma, Xiangwei Deng, Yi Huang, Yifan Song, Zihan Jiang, Bowen Ye, Can Cai, Chenhong He, Dong Zhang, Duo Zhang, Guoan Wang, Hao Tian, Haochen Zhao, Heng Qu, Hongshen Xu, Jun Shi, Kainan Bao, QingKai Fang, Kang Zhou, Kangyang Zhou, Lei Li, Menghang Zhu, Nuo Chen, Qiantong Wang, Shaohui Liu, Shicheng Li, Shuhao Gu, Shuhuai Ren, Shuo Liu, Sirui Deng, Weiji Zhuang, Weiwei Lv, Wenyu Yang, Xin Zhang, Xing Yong, Xing Zhang, Xingchen Song, Xinzhe Xu, Xu Wang, Yihan Yan, Yu Tu, Yuanyuan Tian, Yudong Wang, Yue Yu, Zhenru Lin, Zhichao Song, Zihao Yue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07608">https://arxiv.org/abs/2505.07608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07608">https://arxiv.org/pdf/2505.07608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07608]] MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining(https://arxiv.org/abs/2505.07608)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing strategy to strengthen the base model's reasoning potential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional Multi-Token Prediction objective for enhanced performance and accelerated inference speed. During post-training, we curate a dataset of 130K verifiable mathematics and programming problems for reinforcement learning, integrating a test-difficulty-driven code-reward scheme to alleviate sparse-reward issues and employing strategic data resampling to stabilize training. Extensive evaluations show that MiMo-7B-Base possesses exceptional reasoning potential, outperforming even much larger 32B models. The final RL-tuned model, MiMo-7B-RL, achieves superior performance on mathematics, code and general reasoning tasks, surpassing the performance of OpenAI o1-mini. The model checkpoints are available at this https URL.</li>
</ul>

<h3>Title: Concept-Level Explainability for Auditing & Steering LLM Responses</h3>
<ul>
<li><strong>Authors: </strong>Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07610">https://arxiv.org/abs/2505.07610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07610">https://arxiv.org/pdf/2505.07610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07610]] Concept-Level Explainability for Auditing & Steering LLM Responses(https://arxiv.org/abs/2505.07610)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, explainability, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) become widely deployed, concerns about their safety and alignment grow. An approach to steer LLM behavior, such as mitigating biases or defending against jailbreaks, is to identify which parts of a prompt influence specific aspects of the model's output. Token-level attribution methods offer a promising solution, but still struggle in text generation, explaining the presence of each token in the output separately, rather than the underlying semantics of the entire LLM response. We introduce ConceptX, a model-agnostic, concept-level explainability method that identifies the concepts, i.e., semantically rich tokens in the prompt, and assigns them importance based on the outputs' semantic similarity. Unlike current token-level methods, ConceptX also offers to preserve context integrity through in-place token replacements and supports flexible explanation goals, e.g., gender bias. ConceptX enables both auditing, by uncovering sources of bias, and steering, by modifying prompts to shift the sentiment or reduce the harmfulness of LLM responses, without requiring retraining. Across three LLMs, ConceptX outperforms token-level methods like TokenSHAP in both faithfulness and human alignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for random edits and lower attack success rates from 0.463 to 0.242, outperforming attribution and paraphrasing baselines. While prompt engineering and self-explaining methods sometimes yield safer responses, ConceptX offers a transparent and faithful alternative for improving LLM safety and alignment, demonstrating the practical value of attribution-based explainability in guiding LLM behavior.</li>
</ul>

<h3>Title: Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods,Datasets,and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Yi Zhang, Wenye Zhou, Ruonan Lin, Xin Yang, Hao Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07611">https://arxiv.org/abs/2505.07611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07611">https://arxiv.org/pdf/2505.07611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07611]] Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods,Datasets,and Future Directions(https://arxiv.org/abs/2505.07611)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Traffic accident prediction and detection are critical for enhancing road safety,and vision-based traffic accident anticipation (Vision-TAA) has emerged as a promising approach in the era of deep this http URL paper reviews 147 recent studies,focusing on the application of supervised,unsupervised,and hybrid deep learning models for accident prediction,alongside the use of real-world and synthetic this http URL methodologies are categorized into four key approaches: image and video feature-based prediction, spatiotemporal feature-based prediction, scene understanding,and multimodal data this http URL these methods demonstrate significant potential,challenges such as data scarcity,limited generalization to complex scenarios,and real-time performance constraints remain prevalent. This review highlights opportunities for future research,including the integration of multimodal data fusion, self-supervised learning,and Transformer-based architectures to enhance prediction accuracy and this http URL synthesizing existing advancements and identifying critical gaps, this paper provides a foundational reference for developing robust and adaptive Vision-TAA systems,contributing to road safety and traffic management.</li>
</ul>

<h3>Title: Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy</h3>
<ul>
<li><strong>Authors: </strong>Gleb Molodtsov, Daniil Medyakov, Sergey Skorik, Nikolas Khachaturov, Shahane Tigranyan, Vladimir Aletov, Aram Avetisyan, Martin Takáč, Aleksandr Beznosikov</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07614">https://arxiv.org/abs/2505.07614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07614">https://arxiv.org/pdf/2505.07614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07614]] Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy(https://arxiv.org/abs/2505.07614)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Recent advancements in machine learning have improved performance while also increasing computational demands. While federated and distributed setups address these issues, their structure is vulnerable to malicious influences. In this paper, we address a specific threat, Byzantine attacks, where compromised clients inject adversarial updates to derail global convergence. We combine the trust scores concept with trial function methodology to dynamically filter outliers. Our methods address the critical limitations of previous approaches, allowing functionality even when Byzantine nodes are in the majority. Moreover, our algorithms adapt to widely used scaled methods like Adam and RMSProp, as well as practical scenarios, including local training and partial participation. We validate the robustness of our methods by conducting extensive experiments on both synthetic and real ECG data collected from medical institutions. Furthermore, we provide a broad theoretical analysis of our algorithms and their extensions to aforementioned practical setups. The convergence guarantees of our methods are comparable to those of classical algorithms developed without Byzantine interference.</li>
</ul>

<h3>Title: Enhancing Federated Learning with Kolmogorov-Arnold Networks: A Comparative Study Across Diverse Aggregation Strategies</h3>
<ul>
<li><strong>Authors: </strong>Yizhou Ma, Zhuoqin Yang, Luis-Daniel Ibáñez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07629">https://arxiv.org/abs/2505.07629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07629">https://arxiv.org/pdf/2505.07629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07629]] Enhancing Federated Learning with Kolmogorov-Arnold Networks: A Comparative Study Across Diverse Aggregation Strategies(https://arxiv.org/abs/2505.07629)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Multilayer Perceptron (MLP), as a simple yet powerful model, continues to be widely used in classification and regression tasks. However, traditional MLPs often struggle to efficiently capture nonlinear relationships in load data when dealing with complex datasets. Kolmogorov-Arnold Networks (KAN), inspired by the Kolmogorov-Arnold representation theorem, have shown promising capabilities in modeling complex nonlinear relationships. In this study, we explore the performance of KANs within federated learning (FL) frameworks and compare them to traditional Multilayer Perceptrons. Our experiments, conducted across four diverse datasets demonstrate that KANs consistently outperform MLPs in terms of accuracy, stability, and convergence efficiency. KANs exhibit remarkable robustness under varying client numbers and non-IID data distributions, maintaining superior performance even as client heterogeneity increases. Notably, KANs require fewer communication rounds to converge compared to MLPs, highlighting their efficiency in FL scenarios. Additionally, we evaluate multiple parameter aggregation strategies, with trimmed mean and FedProx emerging as the most effective for optimizing KAN performance. These findings establish KANs as a robust and scalable alternative to MLPs for federated learning tasks, paving the way for their application in decentralized and privacy-preserving environments.</li>
</ul>

<h3>Title: Generating Skyline Explanations for Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Dazhuo Qiu, Haolai Che, Arijit Khan, Yinghui Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07635">https://arxiv.org/abs/2505.07635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07635">https://arxiv.org/pdf/2505.07635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07635]] Generating Skyline Explanations for Graph Neural Networks(https://arxiv.org/abs/2505.07635)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>This paper proposes a novel approach to generate subgraph explanations for graph neural networks GNNs that simultaneously optimize multiple measures for explainability. Existing GNN explanation methods often compute subgraphs (called ``explanatory subgraphs'') that optimize a pre-defined, single explainability measure, such as fidelity or conciseness. This can lead to biased explanations that cannot provide a comprehensive explanation to clarify the output of GNN models. We introduce skyline explanation, a GNN explanation paradigm that aims to identify k explanatory subgraphs by simultaneously optimizing multiple explainability measures. (1) We formulate skyline explanation generation as a multi-objective optimization problem, and pursue explanations that approximate a skyline set of explanatory subgraphs. We show the hardness for skyline explanation generation. (2) We design efficient algorithms with an onion-peeling approach that strategically removes edges from neighbors of nodes of interests, and incrementally improves explanations as it explores an interpretation domain, with provable quality guarantees. (3) We further develop an algorithm to diversify explanations to provide more comprehensive perspectives. Using real-world graphs, we empirically verify the effectiveness, efficiency, and scalability of our algorithms.</li>
</ul>

<h3>Title: ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ozgur Kara, Krishna Kumar Singh, Feng Liu, Duygu Ceylan, James M. Rehg, Tobias Hinz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07652">https://arxiv.org/abs/2505.07652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07652">https://arxiv.org/pdf/2505.07652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07652]] ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models(https://arxiv.org/abs/2505.07652)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Current diffusion-based text-to-video methods are limited to producing short video clips of a single shot and lack the capability to generate multi-shot videos with discrete transitions where the same character performs distinct activities across the same or different backgrounds. To address this limitation we propose a framework that includes a dataset collection pipeline and architectural extensions to video diffusion models to enable text-to-multi-shot video generation. Our approach enables generation of multi-shot videos as a single video with full attention across all frames of all shots, ensuring character and background consistency, and allows users to control the number, duration, and content of shots through shot-specific conditioning. This is achieved by incorporating a transition token into the text-to-video model to control at which frames a new shot begins and a local attention masking strategy which controls the transition token's effect and allows shot-specific prompting. To obtain training data we propose a novel data collection pipeline to construct a multi-shot video dataset from existing single-shot video datasets. Extensive experiments demonstrate that fine-tuning a pre-trained text-to-video model for a few thousand iterations is enough for the model to subsequently be able to generate multi-shot videos with shot-specific control, outperforming the baselines. You can find more details in this https URL</li>
</ul>

<h3>Title: JobHop: A Large-Scale Dataset of Career Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Iman Johary, Raphael Romero, Alexandru C. Mara, Tijl De Bie</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07653">https://arxiv.org/abs/2505.07653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07653">https://arxiv.org/pdf/2505.07653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07653]] JobHop: A Large-Scale Dataset of Career Trajectories(https://arxiv.org/abs/2505.07653)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding labor market dynamics is essential for policymakers, employers, and job seekers. However, comprehensive datasets that capture real-world career trajectories are scarce. In this paper, we introduce JobHop, a large-scale public dataset derived from anonymized resumes provided by VDAB, the public employment service in Flanders, Belgium. Utilizing Large Language Models (LLMs), we process unstructured resume data to extract structured career information, which is then mapped to standardized ESCO occupation codes using a multi-label classification model. This results in a rich dataset of over 2.3 million work experiences, extracted from and grouped into more than 391,000 user resumes and mapped to standardized ESCO occupation codes, offering valuable insights into real-world occupational transitions. This dataset enables diverse applications, such as analyzing labor market mobility, job stability, and the effects of career breaks on occupational transitions. It also supports career path prediction and other data-driven decision-making processes. To illustrate its potential, we explore key dataset characteristics, including job distributions, career breaks, and job transitions, demonstrating its value for advancing labor market research.</li>
</ul>

<h3>Title: Benchmarking Retrieval-Augmented Generation for Chemistry</h3>
<ul>
<li><strong>Authors: </strong>Xianrui Zhong, Bowen Jin, Siru Ouyang, Yanzhen Shen, Qiao Jin, Yin Fang, Zhiyong Lu, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07671">https://arxiv.org/abs/2505.07671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07671">https://arxiv.org/pdf/2505.07671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07671]] Benchmarking Retrieval-Augmented Generation for Chemistry(https://arxiv.org/abs/2505.07671)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) has emerged as a powerful framework for enhancing large language models (LLMs) with external knowledge, particularly in scientific domains that demand specialized and dynamic information. Despite its promise, the application of RAG in the chemistry domain remains underexplored, primarily due to the lack of high-quality, domain-specific corpora and well-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a comprehensive benchmark designed to systematically assess the effectiveness of RAG across a diverse set of chemistry-related tasks. The accompanying chemistry corpus integrates heterogeneous knowledge sources, including scientific literature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia entries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG toolkit that supports five retrieval algorithms and eight LLMs. Using ChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain -- achieving an average relative improvement of 17.4% over direct inference methods. We further conduct in-depth analyses on retriever architectures, corpus selection, and the number of retrieved passages, culminating in practical recommendations to guide future research and deployment of RAG systems in the chemistry domain. The code and data is available at this https URL.</li>
</ul>

<h3>Title: OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit</h3>
<ul>
<li><strong>Authors: </strong>Arun S. Maiya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07672">https://arxiv.org/abs/2505.07672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07672">https://arxiv.org/pdf/2505.07672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07672]] OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit(https://arxiv.org/abs/2505.07672)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>We present this http URL, a Python-based toolkit for applying large language models (LLMs) to sensitive, non-public data in offline or restricted environments. The system is designed for privacy-preserving use cases and provides prebuilt pipelines for document processing and storage, retrieval-augmented generation (RAG), information extraction, summarization, classification, and prompt/output processing with minimal configuration. this http URL supports multiple LLM backends -- including this http URL, Ollama, vLLM, and Hugging Face Transformers -- with quantized model support, GPU acceleration, and seamless backend switching. Although designed for fully local execution, this http URL also supports integration with a wide range of cloud LLM providers when permitted, enabling hybrid deployments that balance performance with data control. A no-code web interface extends accessibility to non-technical users.</li>
</ul>

<h3>Title: Joint Graph Convolution and Sequential Modeling for Scalable Network Traffic Estimation</h3>
<ul>
<li><strong>Authors: </strong>Nan Jiang, Wenxuan Zhu, Xu Han, Weiqiang Huang, Yumeng Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07674">https://arxiv.org/abs/2505.07674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07674">https://arxiv.org/pdf/2505.07674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07674]] Joint Graph Convolution and Sequential Modeling for Scalable Network Traffic Estimation(https://arxiv.org/abs/2505.07674)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study focuses on the challenge of predicting network traffic within complex topological environments. It introduces a spatiotemporal modeling approach that integrates Graph Convolutional Networks (GCN) with Gated Recurrent Units (GRU). The GCN component captures spatial dependencies among network nodes, while the GRU component models the temporal evolution of traffic data. This combination allows for precise forecasting of future traffic patterns. The effectiveness of the proposed model is validated through comprehensive experiments on the real-world Abilene network traffic dataset. The model is benchmarked against several popular deep learning methods. Furthermore, a set of ablation experiments is conducted to examine the influence of various components on performance, including changes in the number of graph convolution layers, different temporal modeling strategies, and methods for constructing the adjacency matrix. Results indicate that the proposed approach achieves superior performance across multiple metrics, demonstrating robust stability and strong generalization capabilities in complex network traffic forecasting scenarios.</li>
</ul>

<h3>Title: SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hang Wu, Jianian Zhu, Yinghui Li, Haojie Wang, Biao Hou, Jidong Zhai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07680">https://arxiv.org/abs/2505.07680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07680">https://arxiv.org/pdf/2505.07680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07680]] SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models(https://arxiv.org/abs/2505.07680)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) present a critical trade-off between inference quality and computational cost: larger models offer superior capabilities but incur significant latency, while smaller models are faster but less powerful. Existing serving strategies often employ fixed model scales or static two-stage speculative decoding, failing to dynamically adapt to the varying complexities of user requests or fluctuations in system performance. This paper introduces \systemname{}, a novel framework that reimagines LLM inference as an adaptive routing problem solved through multi-level speculative decoding. \systemname{} dynamically constructs and optimizes inference "paths" (chains of models) based on real-time feedback, addressing the limitations of static approaches. Our contributions are threefold: (1) An \textbf{adaptive model chain scheduling} mechanism that leverages performance profiling (execution times) and predictive similarity metrics (derived from token distribution divergence) to continuously select the optimal sequence of draft and verifier models, minimizing predicted latency per generated token. (2) A \textbf{multi-level collaborative verification} framework where intermediate models within the selected chain can validate speculative tokens, reducing the verification burden on the final, most powerful target model. (3) A \textbf{synchronized state management} system providing efficient, consistent KV cache handling across heterogeneous models in the chain, including precise, low-overhead rollbacks tailored for asynchronous batch processing inherent in multi-level speculation. Preliminary experiments demonstrate the validity of our method.</li>
</ul>

<h3>Title: Multimodal Survival Modeling in the Age of Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Steven Song, Morgan Borjigin-Wang, Irene Madejski, Robert L. Grossman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07683">https://arxiv.org/abs/2505.07683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07683">https://arxiv.org/pdf/2505.07683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07683]] Multimodal Survival Modeling in the Age of Foundation Models(https://arxiv.org/abs/2505.07683)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a large-scale reference through its harmonized genomics, clinical, and image data. Prior studies have trained bespoke cancer survival prediction models from unimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning is the development of foundation models (FMs) to derive meaningful feature embeddings, agnostic to a specific modeling task. Biomedical text especially has seen growing development of FMs. While TCGA contains free-text data as pathology reports, these have been historically underutilized. Here, we investigate the feasibility of training classical, multimodal survival models over zero-shot embeddings extracted by FMs. We show the ease and additive effect of multimodal fusion, outperforming unimodal models. We demonstrate the benefit of including pathology report text and rigorously evaluate the effect of model-based text summarization and hallucination. Overall, we modernize survival modeling by leveraging FMs and information extraction from pathology reports.</li>
</ul>

<h3>Title: Anatomical Attention Alignment representation for Radiology Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Quang Vinh Nguyen, Minh Duc Nguyen, Thanh Hoang Son Vo, Hyung-Jeong Yang, Soo-Hyung Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07689">https://arxiv.org/abs/2505.07689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07689">https://arxiv.org/pdf/2505.07689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07689]] Anatomical Attention Alignment representation for Radiology Report Generation(https://arxiv.org/abs/2505.07689)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Automated Radiology report generation (RRG) aims at producing detailed descriptions of medical images, reducing radiologists' workload and improving access to high-quality diagnostic services. Existing encoder-decoder models only rely on visual features extracted from raw input images, which can limit the understanding of spatial structures and semantic relationships, often resulting in suboptimal text generation. To address this, we propose Anatomical Attention Alignment Network (A3Net), a framework that enhance visual-textual understanding by constructing hyper-visual representations. Our approach integrates a knowledge dictionary of anatomical structures with patch-level visual features, enabling the model to effectively associate image regions with their corresponding anatomical entities. This structured representation improves semantic reasoning, interpretability, and cross-modal alignment, ultimately enhancing the accuracy and clinical relevance of generated reports. Experimental results on IU X-Ray and MIMIC-CXR datasets demonstrate that A3Net significantly improves both visual perception and text generation quality. Our code is available at \href{this https URL}{GitHub}.</li>
</ul>

<h3>Title: Feedback-Driven Pseudo-Label Reliability Assessment: Redefining Thresholding for Semi-Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Negin Ghamsarian, Sahar Nasirihaghighi, Klaus Schoeffmann, Raphael Sznitman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07691">https://arxiv.org/abs/2505.07691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07691">https://arxiv.org/pdf/2505.07691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07691]] Feedback-Driven Pseudo-Label Reliability Assessment: Redefining Thresholding for Semi-Supervised Semantic Segmentation(https://arxiv.org/abs/2505.07691)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning leverages unlabeled data to enhance model performance, addressing the limitations of fully supervised approaches. Among its strategies, pseudo-supervision has proven highly effective, typically relying on one or multiple teacher networks to refine pseudo-labels before training a student network. A common practice in pseudo-supervision is filtering pseudo-labels based on pre-defined confidence thresholds or entropy. However, selecting optimal thresholds requires large labeled datasets, which are often scarce in real-world semi-supervised scenarios. To overcome this challenge, we propose Ensemble-of-Confidence Reinforcement (ENCORE), a dynamic feedback-driven thresholding strategy for pseudo-label selection. Instead of relying on static confidence thresholds, ENCORE estimates class-wise true-positive confidence within the unlabeled dataset and continuously adjusts thresholds based on the model's response to different levels of pseudo-label filtering. This feedback-driven mechanism ensures the retention of informative pseudo-labels while filtering unreliable ones, enhancing model training without manual threshold tuning. Our method seamlessly integrates into existing pseudo-supervision frameworks and significantly improves segmentation performance, particularly in data-scarce conditions. Extensive experiments demonstrate that integrating ENCORE with existing pseudo-supervision frameworks enhances performance across multiple datasets and network architectures, validating its effectiveness in semi-supervised learning.</li>
</ul>

<h3>Title: Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images</h3>
<ul>
<li><strong>Authors: </strong>Elisei Rykov, Kseniia Petrushina, Kseniia Titova, Anton Razzhigaev, Alexander Panchenko, Vasily Konovalov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07704">https://arxiv.org/abs/2505.07704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07704">https://arxiv.org/pdf/2505.07704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07704]] Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images(https://arxiv.org/abs/2505.07704)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Measuring how real images look is a complex task in artificial intelligence research. For example, an image of a boy with a vacuum cleaner in a desert violates common sense. We introduce a novel method, which we call Through the Looking Glass (TLG), to assess image common sense consistency using Large Vision-Language Models (LVLMs) and Transformer-based encoder. By leveraging LVLMs to extract atomic facts from these images, we obtain a mix of accurate facts. We proceed by fine-tuning a compact attention-pooling classifier over encoded atomic facts. Our TLG has achieved a new state-of-the-art performance on the WHOOPS! and WEIRD datasets while leveraging a compact fine-tuning component.</li>
</ul>

<h3>Title: Hybrid Spiking Vision Transformer for Object Detection with Event Cameras</h3>
<ul>
<li><strong>Authors: </strong>Qi Xu, Jie Deng, Jiangrong Shen, Biwu Chen, Huajin Tang, Gang Pan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07715">https://arxiv.org/abs/2505.07715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07715">https://arxiv.org/pdf/2505.07715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07715]] Hybrid Spiking Vision Transformer for Object Detection with Event Cameras(https://arxiv.org/abs/2505.07715)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Event-based object detection has gained increasing attention due to its advantages such as high temporal resolution, wide dynamic range, and asynchronous address-event representation. Leveraging these advantages, Spiking Neural Networks (SNNs) have emerged as a promising approach, offering low energy consumption and rich spatiotemporal dynamics. To further enhance the performance of event-based object detection, this study proposes a novel hybrid spike vision Transformer (HsVT) model. The HsVT model integrates a spatial feature extraction module to capture local and global features, and a temporal feature extraction module to model time dependencies and long-term patterns in event sequences. This combination enables HsVT to capture spatiotemporal features, improving its capability to handle complex event-based object detection tasks. To support research in this area, we developed and publicly released The Fall Detection Dataset as a benchmark for event-based object detection tasks. This dataset, captured using an event-based camera, ensures facial privacy protection and reduces memory usage due to the event representation format. We evaluated the HsVT model on GEN1 and Fall Detection datasets across various model sizes. Experimental results demonstrate that HsVT achieves significant performance improvements in event detection with fewer parameters.</li>
</ul>

<h3>Title: Securing WiFi Fingerprint-based Indoor Localization Systems from Malicious Access Points</h3>
<ul>
<li><strong>Authors: </strong>Fariha Tanjim Shifat, Sayma Sarwar Ela, Mosarrat Jahan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07724">https://arxiv.org/abs/2505.07724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07724">https://arxiv.org/pdf/2505.07724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07724]] Securing WiFi Fingerprint-based Indoor Localization Systems from Malicious Access Points(https://arxiv.org/abs/2505.07724)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>WiFi fingerprint-based indoor localization schemes deliver highly accurate location data by matching the received signal strength indicator (RSSI) with an offline database using machine learning (ML) or deep learning (DL) models. However, over time, RSSI values degrade due to the malicious behavior of access points (APs), causing low positional accuracy due to RSSI value mismatch with the offline database. Existing literature lacks detection of malicious APs in the online phase and mitigating their effects. This research addresses these limitations and proposes a long-term reliable indoor localization scheme by incorporating malicious AP detection and their effect mitigation techniques. The proposed scheme uses a Light Gradient-Boosting Machine (LGBM) classifier to estimate locations and integrates simple yet efficient techniques to detect malicious APs based on online query data. Subsequently, a mitigation technique is incorporated that updates the offline database and online queries by imputing stable values for malicious APs using LGBM Regressors. Additionally, we introduce a noise addition mechanism in the offline database to capture the dynamic environmental effects. Extensive experimental evaluation shows that the proposed scheme attains a detection accuracy above 95% for each attack type. The mitigation strategy effectively restores the system's performance nearly to its original state when no malicious AP is present. The noise addition module reduces localization errors by nearly 16%. Furthermore, the proposed solution is lightweight, reducing the execution time by approximately 94% compared to the existing methods.</li>
</ul>

<h3>Title: Spoken Language Understanding on Unseen Tasks With In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Neeraj Agrawal, Sriram Ganapathy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07731">https://arxiv.org/abs/2505.07731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07731">https://arxiv.org/pdf/2505.07731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07731]] Spoken Language Understanding on Unseen Tasks With In-Context Learning(https://arxiv.org/abs/2505.07731)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Spoken language understanding (SLU) tasks involve diverse skills that probe the information extraction, classification and/or generation capabilities of models. In this setting, task-specific training data may not always be available. While traditional task-specific SLU models are unable to cater to such requirements, the speech-text large language models (LLMs) offer a promising alternative with emergent abilities. However, out of-the-box, our evaluations indicate that the zero/few-shot performance of prominent open-source speech-text LLMs on SLU tasks are not up to the mark. In this paper, we introduce a novel approach to robust task-agnostic fine-tuning using randomized class labels. With this proposed fine-tuning, we illustrate that the performance of the speech-text LLMs on an unseen task is significantly improved over standard approaches. Critically, the proposed approach avoids the requirement of task-specific data annotations for enabling new tasks in speech-text LLMs.</li>
</ul>

<h3>Title: LAMM-ViT: AI Face Detection via Layer-Aware Modulation of Region-Guided Attention</h3>
<ul>
<li><strong>Authors: </strong>Jiangling Zhang, Weijie Zhu, Jirui Huang, Yaxiong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07734">https://arxiv.org/abs/2505.07734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07734">https://arxiv.org/pdf/2505.07734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07734]] LAMM-ViT: AI Face Detection via Layer-Aware Modulation of Region-Guided Attention(https://arxiv.org/abs/2505.07734)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Detecting AI-synthetic faces presents a critical challenge: it is hard to capture consistent structural relationships between facial regions across diverse generation techniques. Current methods, which focus on specific artifacts rather than fundamental inconsistencies, often fail when confronted with novel generative models. To address this limitation, we introduce Layer-aware Mask Modulation Vision Transformer (LAMM-ViT), a Vision Transformer designed for robust facial forgery detection. This model integrates distinct Region-Guided Multi-Head Attention (RG-MHA) and Layer-aware Mask Modulation (LAMM) components within each layer. RG-MHA utilizes facial landmarks to create regional attention masks, guiding the model to scrutinize architectural inconsistencies across different facial areas. Crucially, the separate LAMM module dynamically generates layer-specific parameters, including mask weights and gating values, based on network context. These parameters then modulate the behavior of RG-MHA, enabling adaptive adjustment of regional focus across network depths. This architecture facilitates the capture of subtle, hierarchical forgery cues ubiquitous among diverse generation techniques, such as GANs and Diffusion Models. In cross-model generalization tests, LAMM-ViT demonstrates superior performance, achieving 94.09% mean ACC (a +5.45% improvement over SoTA) and 98.62% mean AP (a +3.09% improvement). These results demonstrate LAMM-ViT's exceptional ability to generalize and its potential for reliable deployment against evolving synthetic media threats.</li>
</ul>

<h3>Title: Assessing the Chemical Intelligence of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nicholas T. Runcie, Charlotte M. Deane, Fergus Imrie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07735">https://arxiv.org/abs/2505.07735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07735">https://arxiv.org/pdf/2505.07735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07735]] Assessing the Chemical Intelligence of Large Language Models(https://arxiv.org/abs/2505.07735)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are versatile, general-purpose tools with a wide range of applications. Recently, the advent of "reasoning models" has led to substantial improvements in their abilities in advanced problem-solving domains such as mathematics and software engineering. In this work, we assessed the ability of reasoning models to directly perform chemistry tasks, without any assistance from external tools. We created a novel benchmark, called ChemIQ, which consists of 796 questions assessing core concepts in organic chemistry, focused on molecular comprehension and chemical reasoning. Unlike previous benchmarks, which primarily use multiple choice formats, our approach requires models to construct short-answer responses, more closely reflecting real-world applications. The reasoning models, exemplified by OpenAI's o3-mini, correctly answered 28%-59% of questions depending on the reasoning level used, with higher reasoning levels significantly increasing performance on all tasks. These models substantially outperformed the non-reasoning model, GPT-4o, which achieved only 7% accuracy. We found that Large Language Models can now convert SMILES strings to IUPAC names, a task earlier models were unable to perform. Additionally, we show that the latest reasoning models can elucidate structures from 1H and 13C NMR data, correctly generating SMILES strings for 74% of molecules containing up to 10 heavy atoms, and in one case solving a structure comprising 21 heavy atoms. For each task, we found evidence that the reasoning process mirrors that of a human chemist. Our results demonstrate that the latest reasoning models have the ability to perform advanced chemical reasoning.</li>
</ul>

<h3>Title: BodyGPS: Anatomical Positioning System</h3>
<ul>
<li><strong>Authors: </strong>Halid Ziya Yerebakan, Kritika Iyer, Xueqi Guo, Yoshihisa Shinagawa, Gerardo Hermosillo Valadez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07744">https://arxiv.org/abs/2505.07744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07744">https://arxiv.org/pdf/2505.07744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07744]] BodyGPS: Anatomical Positioning System(https://arxiv.org/abs/2505.07744)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We introduce a new type of foundational model for parsing human anatomy in medical images that works for different modalities. It supports supervised or unsupervised training and can perform matching, registration, classification, or segmentation with or without user interaction. We achieve this by training a neural network estimator that maps query locations to atlas coordinates via regression. Efficiency is improved by sparsely sampling the input, enabling response times of less than 1 ms without additional accelerator hardware. We demonstrate the utility of the algorithm in both CT and MRI modalities.</li>
</ul>

<h3>Title: Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets</h3>
<ul>
<li><strong>Authors: </strong>Weiyu Li, Xuanyang Zhang, Zheng Sun, Di Qi, Hao Li, Wei Cheng, Weiwei Cai, Shihao Wu, Jiarui Liu, Zihao Wang, Xiao Chen, Feipeng Tian, Jianxiong Pan, Zeming Li, Gang Yu, Xiangyu Zhang, Daxin Jiang, Ping Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07747">https://arxiv.org/abs/2505.07747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07747">https://arxiv.org/pdf/2505.07747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07747]] Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets(https://arxiv.org/abs/2505.07747)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>While generative artificial intelligence has advanced significantly across text, image, audio, and video domains, 3D generation remains comparatively underdeveloped due to fundamental challenges such as data scarcity, algorithmic limitations, and ecosystem fragmentation. To this end, we present Step1X-3D, an open framework addressing these challenges through: (1) a rigorous data curation pipeline processing >5M assets to create a 2M high-quality dataset with standardized geometric and textural properties; (2) a two-stage 3D-native architecture combining a hybrid VAE-DiT geometry generator with an diffusion-based texture synthesis module; and (3) the full open-source release of models, training code, and adaptation modules. For geometry generation, the hybrid VAE-DiT component produces TSDF representations by employing perceiver-based latent encoding with sharp edge sampling for detail preservation. The diffusion-based texture synthesis module then ensures cross-view consistency through geometric conditioning and latent-space synchronization. Benchmark results demonstrate state-of-the-art performance that exceeds existing open-source methods, while also achieving competitive quality with proprietary solutions. Notably, the framework uniquely bridges the 2D and 3D generation paradigms by supporting direct transfer of 2D control techniques~(e.g., LoRA) to 3D synthesis. By simultaneously advancing data quality, algorithmic fidelity, and reproducibility, Step1X-3D aims to establish new standards for open research in controllable 3D asset generation.</li>
</ul>

<h3>Title: Must Read: A Systematic Survey of Computational Persuasion</h3>
<ul>
<li><strong>Authors: </strong>Nimet Beyza Bozdag, Shuhaib Mehri, Xiaocheng Yang, Hyeonjeong Ha, Zirui Cheng, Esin Durmus, Jiaxuan You, Heng Ji, Gokhan Tur, Dilek Hakkani-Tür</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07775">https://arxiv.org/abs/2505.07775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07775">https://arxiv.org/pdf/2505.07775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07775]] Must Read: A Systematic Survey of Computational Persuasion(https://arxiv.org/abs/2505.07775)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, fair</a></li>
<li><strong>Abstract: </strong>Persuasion is a fundamental aspect of communication, influencing decision-making across diverse contexts, from everyday conversations to high-stakes scenarios such as politics, marketing, and law. The rise of conversational AI systems has significantly expanded the scope of persuasion, introducing both opportunities and risks. AI-driven persuasion can be leveraged for beneficial applications, but also poses threats through manipulation and unethical influence. Moreover, AI systems are not only persuaders, but also susceptible to persuasion, making them vulnerable to adversarial attacks and bias reinforcement. Despite rapid advancements in AI-generated persuasive content, our understanding of what makes persuasion effective remains limited due to its inherently subjective and context-dependent nature. In this survey, we provide a comprehensive overview of computational persuasion, structured around three key perspectives: (1) AI as a Persuader, which explores AI-generated persuasive content and its applications; (2) AI as a Persuadee, which examines AI's susceptibility to influence and manipulation; and (3) AI as a Persuasion Judge, which analyzes AI's role in evaluating persuasive strategies, detecting manipulation, and ensuring ethical persuasion. We introduce a taxonomy for computational persuasion research and discuss key challenges, including evaluating persuasiveness, mitigating manipulative persuasion, and developing responsible AI-driven persuasive systems. Our survey outlines future research directions to enhance the safety, fairness, and effectiveness of AI-powered persuasion while addressing the risks posed by increasingly capable language models.</li>
</ul>

<h3>Title: Synthesizing Diverse Network Flow Datasets with Scalable Dynamic Multigraph Generation</h3>
<ul>
<li><strong>Authors: </strong>Arya Grayeli, Vipin Swarup, Steven E. Noel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07777">https://arxiv.org/abs/2505.07777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07777">https://arxiv.org/pdf/2505.07777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07777]] Synthesizing Diverse Network Flow Datasets with Scalable Dynamic Multigraph Generation(https://arxiv.org/abs/2505.07777)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, generative</a></li>
<li><strong>Abstract: </strong>Obtaining real-world network datasets is often challenging because of privacy, security, and computational constraints. In the absence of such datasets, graph generative models become essential tools for creating synthetic datasets. In this paper, we introduce a novel machine learning model for generating high-fidelity synthetic network flow datasets that are representative of real-world networks. Our approach involves the generation of dynamic multigraphs using a stochastic Kronecker graph generator for structure generation and a tabular generative adversarial network for feature generation. We further employ an XGBoost (eXtreme Gradient Boosting) model for graph alignment, ensuring accurate overlay of features onto the generated graph structure. We evaluate our model using new metrics that assess both the accuracy and diversity of the synthetic graphs. Our results demonstrate improvements in accuracy over previous large-scale graph generation methods while maintaining similar efficiency. We also explore the trade-off between accuracy and diversity in synthetic graph dataset creation, a topic not extensively covered in related works. Our contributions include the synthesis and evaluation of large real-world netflow datasets and the definition of new metrics for evaluating synthetic graph generative models.</li>
</ul>

<h3>Title: MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering</h3>
<ul>
<li><strong>Authors: </strong>Rushi Qiang, Yuchen Zhuang, Yinghao Li, Dingu Sagar V K, Rongzhi Zhang, Changhao Li, Ian Shu-Hei Wong, Sherry Yang, Percy Liang, Chao Zhang, Bo Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07782">https://arxiv.org/abs/2505.07782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07782">https://arxiv.org/pdf/2505.07782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07782]] MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering(https://arxiv.org/abs/2505.07782)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement learning, evaluating, and improving autonomous large language model (LLM) agents in iterative machine learning engineering (MLE) workflows. Unlike existing benchmarks that primarily rely on static datasets or single-attempt evaluations, MLE-Dojo provides an interactive environment enabling agents to iteratively experiment, debug, and refine solutions through structured feedback loops. Built upon 200+ real-world Kaggle challenges, MLE-Dojo covers diverse, open-ended MLE tasks carefully curated to reflect realistic engineering scenarios such as data processing, architecture search, hyperparameter tuning, and code debugging. Its fully executable environment supports comprehensive agent training via both supervised fine-tuning and reinforcement learning, facilitating iterative experimentation, realistic data sampling, and real-time outcome verification. Extensive evaluations of eight frontier LLMs reveal that while current models achieve meaningful iterative improvements, they still exhibit significant limitations in autonomously generating long-horizon solutions and efficiently resolving complex errors. Furthermore, MLE-Dojo's flexible and extensible architecture seamlessly integrates diverse data sources, tools, and evaluation protocols, uniquely enabling model-based agent tuning and promoting interoperability, scalability, and reproducibility. We open-source our framework and benchmarks to foster community-driven innovation towards next-generation MLE agents.</li>
</ul>

<h3>Title: Relative Overfitting and Accept-Reject Framework</h3>
<ul>
<li><strong>Authors: </strong>Yanxin Liu, Yunqi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07783">https://arxiv.org/abs/2505.07783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07783">https://arxiv.org/pdf/2505.07783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07783]] Relative Overfitting and Accept-Reject Framework(https://arxiv.org/abs/2505.07783)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Currently, the scaling law of Large Language Models (LLMs) faces challenges and bottlenecks. This paper posits that noise effects, stemming from changes in the signal-to-noise ratio under diminishing marginal returns, are the root cause of these issues. To control this noise, we investigated the differences between models with performance advantages and disadvantages, introducing the concept of "relative overfitting." Based on their complementary strengths, we have proposed an application framework, Accept-Reject (AR). In Natural Language Processing (NLP), we use LLMs and Small Language Models (SLMs) as the medium for discussion. This framework enables SLMs to exert a universal positive influence on LLM decision outputs, rather than the intuitively expected negative influence. We validated our approach using self-built models based on mainstream architectures and pre-trained mainstream models across multiple datasets, including basic language modeling, long-context tasks, subject examination, and question-answering (QA) benchmarks. The results demonstrate that through our structure, compared to increasing the LLM's parameters, we can achieve better performance improvements with significantly lower parameter and computational costs in many scenarios. These improvements are universal, stable, and effective. Furthermore, we explore the potential of "relative overfitting" and the AR framework in other machine learning domains, such as computer vision (CV) and AI for science. We hope the proposed approach can help scale laws overcome existing bottlenecks.</li>
</ul>

<h3>Title: Domain Regeneration: How well do LLMs match syntactic properties of text domains?</h3>
<ul>
<li><strong>Authors: </strong>Da Ju, Hagen Blix, Adina Williams</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07784">https://arxiv.org/abs/2505.07784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07784">https://arxiv.org/pdf/2505.07784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07784]] Domain Regeneration: How well do LLMs match syntactic properties of text domains?(https://arxiv.org/abs/2505.07784)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Recent improvement in large language model performance have, in all likelihood, been accompanied by improvement in how well they can approximate the distribution of their training data. In this work, we explore the following question: which properties of text domains do LLMs faithfully approximate, and how well do they do so? Applying observational approaches familiar from corpus linguistics, we prompt a commonly used, opensource LLM to regenerate text from two domains of permissively licensed English text which are often contained in LLM training data -- Wikipedia and news text. This regeneration paradigm allows us to investigate whether LLMs can faithfully match the original human text domains in a fairly semantically-controlled setting. We investigate varying levels of syntactic abstraction, from more simple properties like sentence length, and article readability, to more complex and higher order properties such as dependency tag distribution, parse depth, and parse complexity. We find that the majority of the regenerated distributions show a shifted mean, a lower standard deviation, and a reduction of the long tail, as compared to the human originals.</li>
</ul>

<h3>Title: Learning from Peers in Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07787">https://arxiv.org/abs/2505.07787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07787">https://arxiv.org/pdf/2505.07787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07787]] Learning from Peers in Reasoning Models(https://arxiv.org/abs/2505.07787)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Reasoning Models (LRMs) have the ability to self-correct even when they make mistakes in their reasoning paths. However, our study reveals that when the reasoning process starts with a short but poor beginning, it becomes difficult for the model to recover. We refer to this phenomenon as the "Prefix Dominance Trap". Inspired by psychological findings that peer interaction can promote self-correction without negatively impacting already accurate individuals, we propose **Learning from Peers** (LeaP) to address this phenomenon. Specifically, every tokens, each reasoning path summarizes its intermediate reasoning and shares it with others through a routing mechanism, enabling paths to incorporate peer insights during inference. However, we observe that smaller models sometimes fail to follow summarization and reflection instructions effectively. To address this, we fine-tune them into our **LeaP-T** model series. Experiments on AIME 2024, AIME 2025, AIMO 2025, and GPQA Diamond show that LeaP provides substantial improvements. For instance, QwQ-32B with LeaP achieves nearly 5 absolute points higher than the baseline on average, and surpasses DeepSeek-R1-671B on three math benchmarks with an average gain of 3.3 points. Notably, our fine-tuned LeaP-T-7B matches the performance of DeepSeek-R1-Distill-Qwen-14B on AIME 2024. In-depth analysis reveals LeaP's robust error correction by timely peer insights, showing strong error tolerance and handling varied task difficulty. LeaP marks a milestone by enabling LRMs to collaborate during reasoning. Our code, datasets, and models are available at this https URL .</li>
</ul>

<h3>Title: Overflow Prevention Enhances Long-Context Recurrent LLMs</h3>
<ul>
<li><strong>Authors: </strong>Assaf Ben-Kish, Itamar Zimerman, M. Jehanzeb Mirza, James Glass, Leonid Karlinsky, Raja Giryes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07793">https://arxiv.org/abs/2505.07793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07793">https://arxiv.org/pdf/2505.07793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07793]] Overflow Prevention Enhances Long-Context Recurrent LLMs(https://arxiv.org/abs/2505.07793)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A recent trend in LLMs is developing recurrent sub-quadratic models that improve long-context processing efficiency. We investigate leading large long-context models, focusing on how their fixed-size recurrent memory affects their performance. Our experiments reveal that, even when these models are trained for extended contexts, their use of long contexts remains underutilized. Specifically, we demonstrate that a chunk-based inference procedure, which identifies and processes only the most relevant portion of the input can mitigate recurrent memory failures and be effective for many long-context tasks: On LongBench, our method improves the overall performance of Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%, RecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this simple approach also leads to state-of-the-art results in the challenging LongBench v2 benchmark, showing competitive performance with equivalent size Transformers. Furthermore, our findings raise questions about whether recurrent models genuinely exploit long-range dependencies, as our single-chunk strategy delivers stronger performance - even in tasks that presumably require cross-context relations.</li>
</ul>

<h3>Title: Learning Dynamics in Continual Pre-Training for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xingjin Wang, Howe Tissue, Lu Wang, Linjing Li, Daniel Dajun Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07796">https://arxiv.org/abs/2505.07796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07796">https://arxiv.org/pdf/2505.07796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07796]] Learning Dynamics in Continual Pre-Training for Large Language Models(https://arxiv.org/abs/2505.07796)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.</li>
</ul>

<h3>Title: A Comparative Analysis of Static Word Embeddings for Hungarian</h3>
<ul>
<li><strong>Authors: </strong>Máté Gedeon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07809">https://arxiv.org/abs/2505.07809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07809">https://arxiv.org/pdf/2505.07809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07809]] A Comparative Analysis of Static Word Embeddings for Hungarian(https://arxiv.org/abs/2505.07809)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper presents a comprehensive analysis of various static word embeddings for Hungarian, including traditional models such as Word2Vec, FastText, as well as static embeddings derived from BERT-based models using different extraction methods. We evaluate these embeddings on both intrinsic and extrinsic tasks to provide a holistic view of their performance. For intrinsic evaluation, we employ a word analogy task, which assesses the embeddings ability to capture semantic and syntactic relationships. Our results indicate that traditional static embeddings, particularly FastText, excel in this task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among the BERT-based models, the X2Static method for extracting static embeddings demonstrates superior performance compared to decontextualized and aggregate methods, approaching the effectiveness of traditional static embeddings. For extrinsic evaluation, we utilize a bidirectional LSTM model to perform Named Entity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results reveal that embeddings derived from dynamic models, especially those extracted using the X2Static method, outperform purely static embeddings. Notably, ELMo embeddings achieve the highest accuracy in both NER and POS tagging tasks, underscoring the benefits of contextualized representations even when used in a static form. Our findings highlight the continued relevance of static word embeddings in NLP applications and the potential of advanced extraction methods to enhance the utility of BERT-based models. This piece of research contributes to the understanding of embedding performance in the Hungarian language and provides valuable insights for future developments in the field. The training scripts, evaluation codes, restricted vocabulary, and extracted embeddings will be made publicly available to support further research and reproducibility.</li>
</ul>

<h3>Title: Continuous Visual Autoregressive Generation via Score Maximization</h3>
<ul>
<li><strong>Authors: </strong>Chenze Shao, Fandong Meng, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07812">https://arxiv.org/abs/2505.07812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07812">https://arxiv.org/pdf/2505.07812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07812]] Continuous Visual Autoregressive Generation via Score Maximization(https://arxiv.org/abs/2505.07812)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Conventional wisdom suggests that autoregressive models are used to process discrete data. When applied to continuous modalities such as visual data, Visual AutoRegressive modeling (VAR) typically resorts to quantization-based approaches to cast the data into a discrete space, which can introduce significant information loss. To tackle this issue, we introduce a Continuous VAR framework that enables direct visual autoregressive generation without vector quantization. The underlying theoretical foundation is strictly proper scoring rules, which provide powerful statistical tools capable of evaluating how well a generative model approximates the true distribution. Within this framework, all we need is to select a strictly proper score and set it as the training objective to optimize. We primarily explore a class of training objectives based on the energy score, which is likelihood-free and thus overcomes the difficulty of making probabilistic predictions in the continuous space. Previous efforts on continuous autoregressive generation, such as GIVT and diffusion loss, can also be derived from our framework using other strictly proper scores. Source code: this https URL.</li>
</ul>

<h3>Title: DanceGRPO: Unleashing GRPO on Visual Generation</h3>
<ul>
<li><strong>Authors: </strong>Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu, Mengzhao Chen, Zhiheng Liu, Wei Liu, Qiushan Guo, Weilin Huang, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.07818">https://arxiv.org/abs/2505.07818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.07818">https://arxiv.org/pdf/2505.07818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.07818]] DanceGRPO: Unleashing GRPO on Visual Generation(https://arxiv.org/abs/2505.07818)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent breakthroughs in generative models-particularly diffusion models and rectified flows-have revolutionized visual content creation, yet aligning model outputs with human preferences remains a critical challenge. Existing reinforcement learning (RL)-based methods for visual generation face critical limitations: incompatibility with modern Ordinary Differential Equations (ODEs)-based sampling paradigms, instability in large-scale training, and lack of validation for video generation. This paper introduces DanceGRPO, the first unified framework to adapt Group Relative Policy Optimization (GRPO) to visual generation paradigms, unleashing one unified RL algorithm across two generative paradigms (diffusion models and rectified flows), three tasks (text-to-image, text-to-video, image-to-video), four foundation models (Stable Diffusion, HunyuanVideo, FLUX, SkyReel-I2V), and five reward models (image/video aesthetics, text-image alignment, video motion quality, and binary reward). To our knowledge, DanceGRPO is the first RL-based unified framework capable of seamless adaptation across diverse generative paradigms, tasks, foundational models, and reward models. DanceGRPO demonstrates consistent and substantial improvements, which outperform baselines by up to 181% on benchmarks such as HPS-v2.1, CLIP Score, VideoAlign, and GenEval. Notably, DanceGRPO not only can stabilize policy optimization for complex video generation, but also enables generative policy to better capture denoising trajectories for Best-of-N inference scaling and learn from sparse binary feedback. Our results establish DanceGRPO as a robust and versatile solution for scaling Reinforcement Learning from Human Feedback (RLHF) tasks in visual generation, offering new insights into harmonizing reinforcement learning and visual synthesis. The code will be released.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
