<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-11-05</h1>
<h3>Title: Sentiment Analysis Based on RoBERTa for Amazon Review: An Empirical Study on Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Xinli Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00796">https://arxiv.org/abs/2411.00796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00796">https://arxiv.org/pdf/2411.00796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00796]] Sentiment Analysis Based on RoBERTa for Amazon Review: An Empirical Study on Decision Making(https://arxiv.org/abs/2411.00796)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this study, we leverage state-of-the-art Natural Language Processing (NLP) techniques to perform sentiment analysis on Amazon product reviews. By employing transformer-based models, RoBERTa, we analyze a vast dataset to derive sentiment scores that accurately reflect the emotional tones of the reviews. We provide an in-depth explanation of the underlying principles of these models and evaluate their performance in generating sentiment scores. Further, we conduct comprehensive data analysis and visualization to identify patterns and trends in sentiment scores, examining their alignment with behavioral economics principles such as electronic word of mouth (eWOM), consumer emotional reactions, and the confirmation bias. Our findings demonstrate the efficacy of advanced NLP models in sentiment analysis and offer valuable insights into consumer behavior, with implications for strategic decision-making and marketing practices.</li>
</ul>

<h3>Title: Unseen Power of Information Assurance over Information Security</h3>
<ul>
<li><strong>Authors: </strong>Guy Mouanda</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00799">https://arxiv.org/abs/2411.00799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00799">https://arxiv.org/pdf/2411.00799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00799]] Unseen Power of Information Assurance over Information Security(https://arxiv.org/abs/2411.00799)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>Information systems and data are necessary resources for several companies and individuals; but they likewise encounter numerous risks and dangers that can threaten their protection and value. Information security and information assurance are two connected expressions of protecting the confidentiality, integrity, and availability of information systems and data. Information security relates to the processes and methods that block unlawful entry, reform, or exposure of data; in contrast, information assurance covers the expansive aspirations of ensuring that data is responsible, consistent, and flexible. This paper leads the primary models, rules and challenges of information security and information assurance examines some of the top methods, principles, and guidelines that can aid in reaching them, and then investigate the modification in prominence for information security from being obscured in the information technology field to a liability pretending to be in the middle resolving all technology breaches around the world. This paper weighs the various controls and how information assurance can be used to spotlight security problems by focusing on human resource assets and technology. Finally, it demonstrates how information assurance must be considered above others' technology pretending to secure the information</li>
</ul>

<h3>Title: Integrating Symbolic Neural Networks with Building Physics: A Study and Proposal</h3>
<ul>
<li><strong>Authors: </strong>Xia Chen, Guoquan Lv, Xinwei Zhuang, Carlos Duarte, Stefano Schiavon, Philipp Geyer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00800">https://arxiv.org/abs/2411.00800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00800">https://arxiv.org/pdf/2411.00800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00800]] Integrating Symbolic Neural Networks with Building Physics: A Study and Proposal(https://arxiv.org/abs/2411.00800)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Symbolic neural networks, such as Kolmogorov-Arnold Networks (KAN), offer a promising approach for integrating prior knowledge with data-driven methods, making them valuable for addressing inverse problems in scientific and engineering domains. This study explores the application of KAN in building physics, focusing on predictive modeling, knowledge discovery, and continuous learning. Through four case studies, we demonstrate KAN's ability to rediscover fundamental equations, approximate complex formulas, and capture time-dependent dynamics in heat transfer. While there are challenges in extrapolation and interpretability, we highlight KAN's potential to combine advanced modeling methods for knowledge augmentation, which benefits energy efficiency, system optimization, and sustainability assessments beyond the personal knowledge constraints of the modelers. Additionally, we propose a model selection decision tree to guide practitioners in appropriate applications for building physics.</li>
</ul>

<h3>Title: Adaptive Dense Reward: Understanding the Gap Between Action and Reward Space in Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yanshi Li, Shaopan Xiong, Gengru Chen, Xiaoyang Li, Yijia Luo, Xingyao Zhang, Yanhui Huang, Xingyuan Bu, Yingshui Tan, Chun Yuan, Jiamang Wang, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00809">https://arxiv.org/abs/2411.00809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00809">https://arxiv.org/pdf/2411.00809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00809]] Adaptive Dense Reward: Understanding the Gap Between Action and Reward Space in Alignment(https://arxiv.org/abs/2411.00809)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) has proven highly effective in aligning Large Language Models (LLMs) with human preferences. However, the original RLHF typically optimizes under an overall reward, which can lead to a suboptimal learning process. This limitation stems from RLHF's lack of awareness regarding which specific tokens should be reinforced or suppressed. Moreover, conflicts in supervision can arise, for instance, when a chosen response includes erroneous tokens, while a rejected response contains accurate elements. To rectify these shortcomings, increasing dense reward methods, such as step-wise and token-wise RLHF, have been proposed. However, these existing methods are limited to specific tasks (like mathematics). In this paper, we propose the ``Adaptive Message-wise RLHF'' method, which robustly applies to various tasks. By defining pivot tokens as key indicators, our approach adaptively identifies essential information and converts sample-level supervision into fine-grained, subsequence-level supervision. This aligns the density of rewards and action spaces more closely with the information density of the input. Experiments demonstrate that our method can be integrated into various training methods, significantly mitigating hallucinations and catastrophic forgetting problems while outperforming other methods on multiple evaluation metrics. Our method improves the success rate on adversarial samples by 10\% compared to the sample-wise approach and achieves a 1.3\% improvement on evaluation benchmarks such as MMLU, GSM8K, and HumanEval et al.</li>
</ul>

<h3>Title: CycleResearcher: Improving Automated Research via Automated Review</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, Linyi Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00816">https://arxiv.org/abs/2411.00816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00816">https://arxiv.org/pdf/2411.00816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00816]] CycleResearcher: Improving Automated Research via Automated Review(https://arxiv.org/abs/2411.00816)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The automation of scientific discovery has been a long-standing goal within the research community, driven by the potential to accelerate knowledge creation. While significant progress has been made using commercial large language models (LLMs) as research assistants or idea generators, the possibility of automating the entire research process with open-source LLMs remains largely unexplored. This paper explores the feasibility of using open-source post-trained LLMs as autonomous agents capable of performing the full cycle of automated research and review, from literature review and manuscript preparation to peer review and paper revision. Our iterative preference training framework consists of CycleResearcher, which conducts research tasks, and CycleReviewer, which simulates the peer review process, providing iterative feedback via reinforcement learning. To train these models, we develop two new datasets, Review-5k and Research-14k, reflecting real-world machine learning research and peer review dynamics. Our results demonstrate that CycleReviewer achieves a 26.89\% improvement in mean absolute error (MAE) over individual human reviewers in predicting paper scores, indicating that LLMs can surpass expert-level performance in research evaluation. In research, the papers generated by the CycleResearcher model achieved a score of 5.36 in simulated peer reviews, surpassing the preprint level of 5.24 from human experts and approaching the accepted paper level of 5.69. This work represents a significant step toward fully automated scientific inquiry, providing ethical safeguards and advancing AI-driven research capabilities. The code, dataset and model weight are released at \url{http://github/minjun-zhu/Researcher}.</li>
</ul>

<h3>Title: On the Black-box Explainability of Object Detection Models for Safe and Trustworthy Industrial Applications</h3>
<ul>
<li><strong>Authors: </strong>Alain Andres, Aitor Martinez-Seras, Ibai Laña, Javier Del Ser</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00818">https://arxiv.org/abs/2411.00818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00818">https://arxiv.org/pdf/2411.00818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00818]] On the Black-box Explainability of Object Detection Models for Safe and Trustworthy Industrial Applications(https://arxiv.org/abs/2411.00818)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, segmentation</a></li>
<li><strong>Abstract: </strong>In the realm of human-machine interaction, artificial intelligence has become a powerful tool for accelerating data modeling tasks. Object detection methods have achieved outstanding results and are widely used in critical domains like autonomous driving and video surveillance. However, their adoption in high-risk applications, where errors may cause severe consequences, remains limited. Explainable Artificial Intelligence (XAI) methods aim to address this issue, but many existing techniques are model-specific and designed for classification tasks, making them less effective for object detection and difficult for non-specialists to interpret. In this work we focus on model-agnostic XAI methods for object detection models and propose D-MFPP, an extension of the Morphological Fragmental Perturbation Pyramid (MFPP), which uses segmentation-based mask generation. Additionally, we introduce D-Deletion, a novel metric combining faithfulness and localization, adapted specifically to meet the unique demands of object detectors. We evaluate these methods on real-world industrial and robotic datasets, examining the influence of parameters such as the number of masks, model size, and image resolution on the quality of explanations. Our experiments use single-stage object detection models applied to two safety-critical robotic environments: i) a shared human-robot workspace where safety is of paramount importance, and ii) an assembly area of battery kits, where safety is critical due to the potential for damage among high-risk components. Our findings evince that D-Deletion effectively gauges the performance of explanations when multiple elements of the same class appear in the same scene, while D-MFPP provides a promising alternative to D-RISE when fewer masks are used.</li>
</ul>

<h3>Title: EEG-based Multimodal Representation Learning for Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Kang Yin, Hye-Bin Shin, Dan Li, Seong-Whan Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00822">https://arxiv.org/abs/2411.00822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00822">https://arxiv.org/pdf/2411.00822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00822]] EEG-based Multimodal Representation Learning for Emotion Recognition(https://arxiv.org/abs/2411.00822)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal learning has been a popular area of research, yet integrating electroencephalogram (EEG) data poses unique challenges due to its inherent variability and limited availability. In this paper, we introduce a novel multimodal framework that accommodates not only conventional modalities such as video, images, and audio, but also incorporates EEG data. Our framework is designed to flexibly handle varying input sizes, while dynamically adjusting attention to account for feature importance across modalities. We evaluate our approach on a recently introduced emotion recognition dataset that combines data from three modalities, making it an ideal testbed for multimodal learning. The experimental results provide a benchmark for the dataset and demonstrate the effectiveness of the proposed framework. This work highlights the potential of integrating EEG into multimodal systems, paving the way for more robust and comprehensive applications in emotion recognition and beyond.</li>
</ul>

<h3>Title: Mobility-LLM: Learning Visiting Intentions and Travel Preferences from Human Mobility Data with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Letian Gong, Yan Lin, Xinyue Zhang, Yiwen Lu, Xuedi Han, Yichen Liu, Shengnan Guo, Youfang Lin, Huaiyu Wan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00823">https://arxiv.org/abs/2411.00823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00823">https://arxiv.org/pdf/2411.00823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00823]] Mobility-LLM: Learning Visiting Intentions and Travel Preferences from Human Mobility Data with Large Language Models(https://arxiv.org/abs/2411.00823)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Location-based services (LBS) have accumulated extensive human mobility data on diverse behaviors through check-in sequences. These sequences offer valuable insights into users' intentions and preferences. Yet, existing models analyzing check-in sequences fail to consider the semantics contained in these sequences, which closely reflect human visiting intentions and travel preferences, leading to an incomplete comprehension. Drawing inspiration from the exceptional semantic understanding and contextual information processing capabilities of large language models (LLMs) across various domains, we present Mobility-LLM, a novel framework that leverages LLMs to analyze check-in sequences for multiple tasks. Since LLMs cannot directly interpret check-ins, we reprogram these sequences to help LLMs comprehensively understand the semantics of human visiting intentions and travel preferences. Specifically, we introduce a visiting intention memory network (VIMN) to capture the visiting intentions at each record, along with a shared pool of human travel preference prompts (HTPP) to guide the LLM in understanding users' travel preferences. These components enhance the model's ability to extract and leverage semantic information from human mobility data effectively. Extensive experiments on four benchmark datasets and three downstream tasks demonstrate that our approach significantly outperforms existing models, underscoring the effectiveness of Mobility-LLM in advancing our understanding of human mobility data within LBS contexts.</li>
</ul>

<h3>Title: Uncertainty Quantification via H\"older Divergence for Multi-View Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>an Zhang, Ming Li, Chun Li, Zhaoxia Liu, Ye Zhang, Fei Richard Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00826">https://arxiv.org/abs/2411.00826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00826">https://arxiv.org/pdf/2411.00826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00826]] Uncertainty Quantification via H\"older Divergence for Multi-View Representation Learning(https://arxiv.org/abs/2411.00826)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Evidence-based deep learning represents a burgeoning paradigm for uncertainty estimation, offering reliable predictions with negligible extra computational overheads. Existing methods usually adopt Kullback-Leibler divergence to estimate the uncertainty of network predictions, ignoring domain gaps among various modalities. To tackle this issue, this paper introduces a novel algorithm based on Hölder Divergence (HD) to enhance the reliability of multi-view learning by addressing inherent uncertainty challenges from incomplete or noisy data. Generally, our method extracts the representations of multiple modalities through parallel network branches, and then employs HD to estimate the prediction uncertainties. Through the Dempster-Shafer theory, integration of uncertainty from different modalities, thereby generating a comprehensive result that considers all available representations. Mathematically, HD proves to better measure the ``distance'' between real data distribution and predictive distribution of the model and improve the performances of multi-class recognition tasks. Specifically, our method surpass the existing state-of-the-art counterparts on all evaluating benchmarks. We further conduct extensive experiments on different backbones to verify our superior robustness. It is demonstrated that our method successfully pushes the corresponding performance boundaries. Finally, we perform experiments on more challenging scenarios, \textit{i.e.}, learning with incomplete or noisy data, revealing that our method exhibits a high tolerance to such corrupted data.</li>
</ul>

<h3>Title: IDEATOR: Jailbreaking VLMs Using VLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruofan Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00827">https://arxiv.org/abs/2411.00827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00827">https://arxiv.org/pdf/2411.00827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00827]] IDEATOR: Jailbreaking VLMs Using VLMs(https://arxiv.org/abs/2411.00827)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>As large Vision-Language Models (VLMs) continue to gain prominence, ensuring their safety deployment in real-world applications has become a critical concern. Recently, significant research efforts have focused on evaluating the robustness of VLMs against jailbreak attacks. Due to challenges in obtaining multi-modal data, current studies often assess VLM robustness by generating adversarial or query-relevant images based on harmful text datasets. However, the jailbreak images generated this way exhibit certain limitations. Adversarial images require white-box access to the target VLM and are relatively easy to defend against, while query-relevant images must be linked to the target harmful content, limiting their diversity and effectiveness. In this paper, we propose a novel jailbreak method named IDEATOR, which autonomously generates malicious image-text pairs for black-box jailbreak attacks. IDEATOR is a VLM-based approach inspired by our conjecture that a VLM itself might be a powerful red team model for generating jailbreak prompts. Specifically, IDEATOR employs a VLM to generate jailbreak texts while leveraging a state-of-the-art diffusion model to create corresponding jailbreak images. Extensive experiments demonstrate the high effectiveness and transferability of IDEATOR. It successfully jailbreaks MiniGPT-4 with a 94% success rate and transfers seamlessly to LLaVA and InstructBLIP, achieving high success rates of 82% and 88%, respectively. IDEATOR uncovers previously unrecognized vulnerabilities in VLMs, calling for advanced safety mechanisms.</li>
</ul>

<h3>Title: Dreaming Out Loud: A Self-Synthesis Approach For Training Vision-Language Models With Developmentally Plausible Data</h3>
<ul>
<li><strong>Authors: </strong>Badr AlKhamissi, Yingtian Tang, Abdülkadir Gökce, Johannes Mehrer, Martin Schrimpf</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00828">https://arxiv.org/abs/2411.00828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00828">https://arxiv.org/pdf/2411.00828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00828]] Dreaming Out Loud: A Self-Synthesis Approach For Training Vision-Language Models With Developmentally Plausible Data(https://arxiv.org/abs/2411.00828)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While today's large language models exhibit impressive abilities in generating human-like text, they require massive amounts of data during training. We here take inspiration from human cognitive development to train models in limited data conditions. Specifically we present a self-synthesis approach that iterates through four phases: Phase 1 sets up fundamental language abilities, training the model from scratch on a small corpus. Language is then associated with the visual environment in phase 2, integrating the model with a vision encoder to generate descriptive captions from labeled images. In the "self-synthesis" phase 3, the model generates captions for unlabeled images, that it then uses to further train its language component with a mix of synthetic, and previous real-world text. This phase is meant to expand the model's linguistic repertoire, similar to humans self-annotating new experiences. Finally, phase 4 develops advanced cognitive skills, by training the model on specific tasks such as visual question answering and reasoning. Our approach offers a proof of concept for training a multimodal model using a developmentally plausible amount of data.</li>
</ul>

<h3>Title: Saliency-Based diversity and fairness Metric and FaceKeepOriginalAugment: A Novel Approach for Enhancing Fairness and Diversity</h3>
<ul>
<li><strong>Authors: </strong>Teerath Kumar, Alessandra Mileo, Malika Bendechache</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00831">https://arxiv.org/abs/2411.00831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00831">https://arxiv.org/pdf/2411.00831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00831]] Saliency-Based diversity and fairness Metric and FaceKeepOriginalAugment: A Novel Approach for Enhancing Fairness and Diversity(https://arxiv.org/abs/2411.00831)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer</a></li>
<li><strong>Abstract: </strong>Data augmentation has become a pivotal tool in enhancing the performance of computer vision tasks, with the KeepOriginalAugment method emerging as a standout technique for its intelligent incorporation of salient regions within less prominent areas, enabling augmentation in both regions. Despite its success in image classification, its potential in addressing biases remains unexplored. In this study, we introduce an extension of the KeepOriginalAugment method, termed FaceKeepOriginalAugment, which explores various debiasing aspects-geographical, gender, and stereotypical biases-in computer vision models. By maintaining a delicate balance between data diversity and information preservation, our approach empowers models to exploit both diverse salient and non-salient regions, thereby fostering increased diversity and debiasing effects. We investigate multiple strategies for determining the placement of the salient region and swapping perspectives to decide which part undergoes augmentation. Leveraging the Image Similarity Score (ISS), we quantify dataset diversity across a range of datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled Faces in the Wild (LFW), UTK Faces, and Diverse Dataset. We evaluate the effectiveness of FaceKeepOriginalAugment in mitigating gender bias across CEO, Engineer, Nurse, and School Teacher datasets, utilizing the Image-Image Association Score (IIAS) in convolutional neural networks (CNNs) and vision transformers (ViTs). Our findings shows the efficacy of FaceKeepOriginalAugment in promoting fairness and inclusivity within computer vision models, demonstrated by reduced gender bias and enhanced overall fairness. Additionally, we introduce a novel metric, Saliency-Based Diversity and Fairness Metric, which quantifies both diversity and fairness while handling data imbalance across various datasets.</li>
</ul>

<h3>Title: Scalable Message Passing Neural Networks: No Need for Attention in Large Graph Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Haitz Sáez de Ocáriz Borde, Artem Lukoianov, Anastasis Kratsios, Michael Bronstein, Xiaowen Dong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00835">https://arxiv.org/abs/2411.00835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00835">https://arxiv.org/pdf/2411.00835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00835]] Scalable Message Passing Neural Networks: No Need for Attention in Large Graph Representation Learning(https://arxiv.org/abs/2411.00835)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose Scalable Message Passing Neural Networks (SMPNNs) and demonstrate that, by integrating standard convolutional message passing into a Pre-Layer Normalization Transformer-style block instead of attention, we can produce high-performing deep message-passing-based Graph Neural Networks (GNNs). This modification yields results competitive with the state-of-the-art in large graph transductive learning, particularly outperforming the best Graph Transformers in the literature, without requiring the otherwise computationally and memory-expensive attention mechanism. Our architecture not only scales to large graphs but also makes it possible to construct deep message-passing networks, unlike simple GNNs, which have traditionally been constrained to shallow architectures due to oversmoothing. Moreover, we provide a new theoretical analysis of oversmoothing based on universal approximation which we use to motivate SMPNNs. We show that in the context of graph convolutions, residual connections are necessary for maintaining the universal approximation properties of downstream learners and that removing them can lead to a loss of universality.</li>
</ul>

<h3>Title: DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00836">https://arxiv.org/abs/2411.00836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00836">https://arxiv.org/pdf/2411.00836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00836]] DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models(https://arxiv.org/abs/2411.00836)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid advancements in Vision-Language Models (VLMs) have shown great potential in tackling mathematical reasoning tasks that involve visual context. Unlike humans who can reliably apply solution steps to similar problems with minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail in these scenarios, revealing limitations in their mathematical reasoning capabilities. In this paper, we investigate the mathematical reasoning robustness in VLMs and evaluate how well these models perform under different variants of the same question, such as changes in visual numerical values or function graphs. While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities, these benchmarks contain only static sets of problems and cannot easily evaluate mathematical reasoning robustness. To fill this gap, we introduce DynaMath, a dynamic visual math benchmark designed for in-depth assessment of VLMs. DynaMath includes 501 high-quality, multi-topic seed questions, each represented as a Python program. Those programs are carefully designed and annotated to enable the automatic generation of a much larger set of concrete questions, including many different types of visual and textual variations. DynaMath allows us to evaluate the generalization ability of VLMs, by assessing their performance under varying input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010 generated concrete questions. Our results show that the worst-case model accuracy, defined as the percentage of correctly answered seed questions in all 10 variants, is significantly lower than the average-case accuracy. Our analysis emphasizes the need to study the robustness of VLMs' reasoning abilities, and DynaMath provides valuable insights to guide the development of more reliable models for mathematical reasoning.</li>
</ul>

<h3>Title: Longitudinal Mammogram Exam-based Breast Cancer Diagnosis Models: Vulnerability to Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Zhengbo Zhou, Degan Hao, Dooman Arefan, Margarita Zuley, Jules Sumkin, Shandong Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00837">https://arxiv.org/abs/2411.00837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00837">https://arxiv.org/pdf/2411.00837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00837]] Longitudinal Mammogram Exam-based Breast Cancer Diagnosis Models: Vulnerability to Adversarial Attacks(https://arxiv.org/abs/2411.00837)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In breast cancer detection and diagnosis, the longitudinal analysis of mammogram images is crucial. Contemporary models excel in detecting temporal imaging feature changes, thus enhancing the learning process over sequential imaging exams. Yet, the resilience of these longitudinal models against adversarial attacks remains underexplored. In this study, we proposed a novel attack method that capitalizes on the feature-level relationship between two sequential mammogram exams of a longitudinal model, guided by both cross-entropy loss and distance metric learning, to achieve significant attack efficacy, as implemented using attack transferring in a black-box attacking manner. We performed experiments on a cohort of 590 breast cancer patients (each has two sequential mammogram exams) in a case-control setting. Results showed that our proposed method surpassed several state-of-the-art adversarial attacks in fooling the diagnosis models to give opposite outputs. Our method remained effective even if the model was trained with the common defending method of adversarial training.</li>
</ul>

<h3>Title: CausAdv: A Causal-based Framework for Detecting Adversarial Examples</h3>
<ul>
<li><strong>Authors: </strong>Hichem Debbi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00839">https://arxiv.org/abs/2411.00839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00839">https://arxiv.org/pdf/2411.00839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00839]] CausAdv: A Causal-based Framework for Detecting Adversarial Examples(https://arxiv.org/abs/2411.00839)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>Deep learning has led to tremendous success in many real-world applications of computer vision, thanks to sophisticated architectures such as Convolutional neural networks (CNNs). However, CNNs have been shown to be vulnerable to crafted adversarial perturbations in inputs. These inputs appear almost indistinguishable from natural images, yet they are incorrectly classified by CNN architectures. This vulnerability of adversarial examples has led researchers to focus on enhancing the robustness of deep learning models in general, and CNNs in particular, by creating defense and detection methods to distinguish adversarials inputs from natural ones. In this paper, we address the adversarial robustness of CNNs through causal reasoning. We propose CausAdv: a causal framework for detecting adversarial examples based on counterfactual reasoning. CausAdv learns causal and non-causal features of every input, and quantifies the counterfactual information (CI) of every filter of the last convolutional layer. Then we perform statistical analysis on the filters CI of every sample, whether clan or adversarials, to demonstrate how adversarial examples indeed exhibit different CI distributions compared to clean samples. Our results show that causal reasoning enhances the process of adversarials detection without the need to train a separate detector. In addition, we illustrate the efficiency of causal explanations as a helpful detection technique through visualizing the causal features. The results can be reproduced using the code available in the repository: this https URL.</li>
</ul>

<h3>Title: Peri-AIIMS: Perioperative Artificial Intelligence Driven Integrated Modeling of Surgeries using Anesthetic, Physical and Cognitive Statuses for Predicting Hospital Outcomes</h3>
<ul>
<li><strong>Authors: </strong>Sabyasachi Bandyopadhyay, Jiaqing Zhang, Ronald L. Ison, David J. Libon, Patrick Tighe, Catherine Price, Parisa Rashidi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00840">https://arxiv.org/abs/2411.00840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00840">https://arxiv.org/pdf/2411.00840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00840]] Peri-AIIMS: Perioperative Artificial Intelligence Driven Integrated Modeling of Surgeries using Anesthetic, Physical and Cognitive Statuses for Predicting Hospital Outcomes(https://arxiv.org/abs/2411.00840)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The association between preoperative cognitive status and surgical outcomes is a critical, yet scarcely explored area of research. Linking intraoperative data with postoperative outcomes is a promising and low-cost way of evaluating long-term impacts of surgical interventions. In this study, we evaluated how preoperative cognitive status as measured by the clock drawing test contributed to predicting length of hospital stay, hospital charges, average pain experienced during follow-up, and 1-year mortality over and above intraoperative variables, demographics, preoperative physical status and comorbidities. We expanded our analysis to 6 specific surgical groups where sufficient data was available for cross-validation. The clock drawing images were represented by 10 constructional features discovered by a semi-supervised deep learning algorithm, previously validated to differentiate between dementia and non-dementia patients. Different machine learning models were trained to classify postoperative outcomes in hold-out test sets. The models were compared to their relative performance, time complexity, and interpretability. Shapley Additive Explanations (SHAP) analysis was used to find the most predictive features for classifying different outcomes in different surgical contexts. Relative classification performances achieved by different feature sets showed that the perioperative cognitive dataset which included clock drawing features in addition to intraoperative variables, demographics, and comorbidities served as the best dataset for 12 of 18 possible surgery-outcome combinations...</li>
</ul>

<h3>Title: A Theoretical Perspective for Speculative Decoding Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Ming Yin, Minshuo Chen, Kaixuan Huang, Mengdi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00841">https://arxiv.org/abs/2411.00841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00841">https://arxiv.org/pdf/2411.00841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00841]] A Theoretical Perspective for Speculative Decoding Algorithm(https://arxiv.org/abs/2411.00841)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformer-based autoregressive sampling has been the major bottleneck for slowing down large language model inferences. One effective way to accelerate inference is \emph{Speculative Decoding}, which employs a small model to sample a sequence of draft tokens and a large model to validate. Given its empirical effectiveness, the theoretical understanding of Speculative Decoding is falling behind. This paper tackles this gap by conceptualizing the decoding problem via markov chain abstraction and studying the key properties, \emph{output quality and inference acceleration}, from a theoretical perspective. Our analysis covers the theoretical limits of speculative decoding, batch algorithms, and output quality-inference acceleration tradeoffs. Our results reveal the fundamental connections between different components of LLMs via total variation distances and show how they jointly affect the efficiency of decoding algorithms.</li>
</ul>

<h3>Title: The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation</h3>
<ul>
<li><strong>Authors: </strong>Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00843">https://arxiv.org/abs/2411.00843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00843">https://arxiv.org/pdf/2411.00843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00843]] The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation(https://arxiv.org/abs/2411.00843)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Logic synthesis is a crucial phase in the circuit design process, responsible for transforming hardware description language (HDL) designs into optimized netlists. However, traditional logic synthesis methods are computationally intensive, restricting their iterative use in refining chip designs. Recent advancements in large language models (LLMs), particularly those fine-tuned on programming languages, present a promising alternative. In this paper, we introduce VeriDistill, the first end-to-end machine learning model that directly processes raw Verilog code to predict circuit quality-of-result metrics. Our model employs a novel knowledge distillation method, transferring low-level circuit insights via graphs into the predictor based on LLM. Experiments show VeriDistill outperforms state-of-the-art baselines on large-scale Verilog datasets and demonstrates robust performance when evaluated on out-of-distribution datasets.</li>
</ul>

<h3>Title: End-to-end Graph Learning Approach for Cognitive Diagnosis of Student Tutorial</h3>
<ul>
<li><strong>Authors: </strong>Fulai Yang, Di Wu, Yi He, Li Tao, Xin Luo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00845">https://arxiv.org/abs/2411.00845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00845">https://arxiv.org/pdf/2411.00845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00845]] End-to-end Graph Learning Approach for Cognitive Diagnosis of Student Tutorial(https://arxiv.org/abs/2411.00845)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Cognitive diagnosis (CD) utilizes students' existing studying records to estimate their mastery of unknown knowledge concepts, which is vital for evaluating their learning abilities. Accurate CD is extremely challenging because CD is associated with complex relationships and mechanisms among students, knowledge concepts, studying records, etc. However, existing approaches loosely consider these relationships and mechanisms by a non-end-to-end learning framework, resulting in sub-optimal feature extractions and fusions for CD. Different from them, this paper innovatively proposes an End-to-end Graph Neural Networks-based Cognitive Diagnosis (EGNN-CD) model. EGNN-CD consists of three main parts: knowledge concept network (KCN), graph neural networks-based feature extraction (GNNFE), and cognitive ability prediction (CAP). First, KCN constructs CD-related interaction by comprehensively extracting physical information from students, exercises, and knowledge concepts. Second, a four-channel GNNFE is designed to extract high-order and individual features from the constructed KCN. Finally, CAP employs a multi-layer perceptron to fuse the extracted features to predict students' learning abilities in an end-to-end learning way. With such designs, the feature extractions and fusions are guaranteed to be comprehensive and optimal for CD. Extensive experiments on three real datasets demonstrate that our EGNN-CD achieves significantly higher accuracy than state-of-the-art models in CD.</li>
</ul>

<h3>Title: Explainable Artificial Intelligence for Dependent Features: Additive Effects of Collinearity</h3>
<ul>
<li><strong>Authors: </strong>Ahmed M Salih</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00846">https://arxiv.org/abs/2411.00846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00846">https://arxiv.org/pdf/2411.00846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00846]] Explainable Artificial Intelligence for Dependent Features: Additive Effects of Collinearity(https://arxiv.org/abs/2411.00846)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Explainable Artificial Intelligence (XAI) emerged to reveal the internal mechanism of machine learning models and how the features affect the prediction outcome. Collinearity is one of the big issues that XAI methods face when identifying the most informative features in the model. Current XAI approaches assume the features in the models are independent and calculate the effect of each feature toward model prediction independently from the rest of the features. However, such assumption is not realistic in real life applications. We propose an Additive Effects of Collinearity (AEC) as a novel XAI method that aim to considers the collinearity issue when it models the effect of each feature in the model on the outcome. AEC is based on the idea of dividing multivariate models into several univariate models in order to examine their impact on each other and consequently on the outcome. The proposed method is implemented using simulated and real data to validate its efficiency comparing with the a state of arts XAI method. The results indicate that AEC is more robust and stable against the impact of collinearity when it explains AI models compared with the state of arts XAI method.</li>
</ul>

<h3>Title: GWQ: Gradient-Aware Weight Quantization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yihua Shao, Siyu Liang, Xiaolin Lin, Zijian Ling, Zixian Zhu, Minxi Yan, Haiyang Liu, Siyu Chen, Ziyang Yan, Yilan Meng, Chenyu Zhang, Haotong Qin, Michele Magno, Yang Yang, Zhen Lei, Yan Wang, Jingcai Guo, Ling Shao, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00850">https://arxiv.org/abs/2411.00850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00850">https://arxiv.org/pdf/2411.00850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00850]] GWQ: Gradient-Aware Weight Quantization for Large Language Models(https://arxiv.org/abs/2411.00850)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show impressive performance in solving complex languagetasks. However, its large number of parameterspresent significant challenges for the deployment and application of the model on edge devices. Compressing large language models to low bits can enable them to run on resource-constrained devices, often leading to performance degradation. To address this problem, we propose gradient-aware weight quantization (GWQ), the first quantization approach for low-bit weight quantization that leverages gradients to localize outliers, requiring only a minimal amount of calibration data for outlier detection. GWQ retains the weights corresponding to the top 1% outliers preferentially at FP16 precision, while the remaining non-outlier weights are stored in a low-bit format. GWQ found experimentally that utilizing the sensitive weights in the gradient localization model is more scientific compared to utilizing the sensitive weights in the Hessian matrix localization model. Compared to current quantization methods, GWQ can be applied to multiple language models and achieves lower PPL on the WikiText2 and C4 dataset. In the zero-shot task, GWQ quantized models have higher accuracy compared to other quantization this http URL is also suitable for multimodal model quantization, and the quantized Qwen-VL family model is more accurate than other methods. zero-shot target detection task dataset RefCOCO outperforms the current stat-of-the-arts method SPQR. GWQ achieves 1.2x inference speedup in comparison to the original model, and effectively reduces the inference memory.</li>
</ul>

<h3>Title: Automatic feature selection and weighting using Differentiable Information Imbalance</h3>
<ul>
<li><strong>Authors: </strong>Romina Wild, Vittorio Del Tatto, Felix Wodaczek, Bingqing Cheng, Alessandro Laio</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00851">https://arxiv.org/abs/2411.00851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00851">https://arxiv.org/pdf/2411.00851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00851]] Automatic feature selection and weighting using Differentiable Information Imbalance(https://arxiv.org/abs/2411.00851)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Feature selection is a common process in many applications, but it is accompanied by uncertainties such as: What is the optimal dimensionality of an interpretable, reduced feature space to retain a maximum amount of information? How to account for different units of measure in features? How to weight different features according to their importance? To address these challenges, we introduce the Differentiable Information Imbalance (DII), an automatic data analysis method to rank information content between sets of features. Based on the nearest neighbors according to distances in the ground truth feature space, the method finds a low-dimensional subset of the input features, within which the pairwise distance relations are most similar to the ground truth. By employing the Differentiable Information Imbalance as a loss function, the relative feature weights of the inputs are optimized, simultaneously performing unit alignment and relative importance scaling, while preserving interpretability. Furthermore, this method can generate sparse solutions and determine the optimal size of the reduced feature space. We illustrate the usefulness of this approach on two prototypical benchmark problems: (1) Identifying a small set of collective variables capable of describing the conformational space of a biomolecule, and (2) selecting a subset of features for training a machine-learning force field. The results highlight the potential of the Differentiable Information Imbalance in addressing feature selection challenges and optimizing dimensionality in various applications. The method is implemented in the Python library DADApy.</li>
</ul>

<h3>Title: FPE-LLM: Highly Intelligent Time-Series Forecasting and Language Interaction LLM in Energy Systems</h3>
<ul>
<li><strong>Authors: </strong>Zihang Qiu, Chaojie Li, Zhongyang Wang, Huadong Mo, Renyou Xie, Guo Chen, Zhaoyang Dong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00852">https://arxiv.org/abs/2411.00852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00852">https://arxiv.org/pdf/2411.00852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00852]] FPE-LLM: Highly Intelligent Time-Series Forecasting and Language Interaction LLM in Energy Systems(https://arxiv.org/abs/2411.00852)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces Fusion PEFT Energy LLM (FPE-LLM), a large language model (LLM) fine-tuned for energy system forecasting using a combination of Prefix and Lora Parameter-Efficient Fine-Tuning (PEFT) methods. FPE-LLM addresses three key challenges in the energy system and LLM fields: 1. Enhancing few-shot learning for handling extreme environmental conditions. FPE-LLM can leverage both textual and time-series data to achieve accurate predictions in few-shot contexts. 2. Reducing dependence on expert input to improve efficiency. FPE-LLM can provide guidance and results on related problems, acting like an expert system. Even non-experts can use FPE-LLM to complete all tasks related to forecasting and its associated tasks. 3. Mitigating hallucination risks through standardized fine-tuning. We validated this through multi-task learning and the self-reasoning characteristics of LLMs. Our research opens the door to fully realizing the intelligent potential of FPE-LLM in the energy forecasting field. With the injection of more knowledge and data, FPE-LLM is expected to replace a significant amount of manual work and contribute to the stability and efficiency of energy forecasting.</li>
</ul>

<h3>Title: Accelerated AI Inference via Dynamic Execution Methods</h3>
<ul>
<li><strong>Authors: </strong>Haim Barad, Jascha Achterberg, Tien Pei Chou, Jean Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00853">https://arxiv.org/abs/2411.00853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00853">https://arxiv.org/pdf/2411.00853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00853]] Accelerated AI Inference via Dynamic Execution Methods(https://arxiv.org/abs/2411.00853)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we focus on Dynamic Execution techniques that optimize the computation flow based on input. This aims to identify simpler problems that can be solved using fewer resources, similar to human cognition. The techniques discussed include early exit from deep networks, speculative sampling for language models, and adaptive steps for diffusion models. Experimental results demonstrate that these dynamic approaches can significantly improve latency and throughput without compromising quality. When combined with model-based optimizations, such as quantization, dynamic execution provides a powerful multi-pronged strategy to optimize AI inference. Generative AI requires a large amount of compute resources. This is expected to grow, and demand for resources in data centers through to the edge is expected to continue to increase at high rates. We take advantage of existing research and provide additional innovations for some generative optimizations. In the case of LLMs, we provide more efficient sampling methods that depend on the complexity of the data. In the case of diffusion model generation, we provide a new method that also leverages the difficulty of the input prompt to predict an optimal early stopping point. Therefore, dynamic execution methods are relevant because they add another dimension of performance optimizations. Performance is critical from a competitive point of view, but increasing capacity can result in significant power savings and cost savings. We have provided several integrations of these techniques into several Intel performance libraries and Huggingface Optimum. These integrations will make them easier to use and increase the adoption of these techniques.</li>
</ul>

<h3>Title: Vision-Language Models Can Self-Improve Reasoning via Reflection</h3>
<ul>
<li><strong>Authors: </strong>Kanzhi Cheng, Yantao Li, Fangzhi Xu, Jianbing Zhang, Hao Zhou, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00855">https://arxiv.org/abs/2411.00855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00855">https://arxiv.org/pdf/2411.00855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00855]] Vision-Language Models Can Self-Improve Reasoning via Reflection(https://arxiv.org/abs/2411.00855)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-thought (CoT) has proven to improve the reasoning capability of large language models (LLMs). However, due to the complexity of multimodal scenarios and the difficulty in collecting high-quality CoT data, CoT reasoning in multimodal LLMs has been largely overlooked. To this end, we propose a simple yet effective self-training framework, R3V, which iteratively enhances the model's Vision-language Reasoning by Reflecting on CoT Rationales. Our framework consists of two interleaved parts: (1) iteratively bootstrapping positive and negative solutions for reasoning datasets, and (2) reflection on rationale for learning from mistakes. Specifically, we introduce the self-refine and self-select losses, enabling the model to refine flawed rationale and derive the correct answer by comparing rationale candidates. Experiments on a wide range of vision-language tasks show that R3V consistently improves multimodal LLM reasoning, achieving a relative improvement of 23 to 60 percent over GPT-distilled baselines. Additionally, our approach supports self-reflection on generated solutions, further boosting performance through test-time computation.</li>
</ul>

<h3>Title: AI in Investment Analysis: LLMs for Equity Stock Ratings</h3>
<ul>
<li><strong>Authors: </strong>Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, Tucker Balch</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00856">https://arxiv.org/abs/2411.00856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00856">https://arxiv.org/pdf/2411.00856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00856]] AI in Investment Analysis: LLMs for Equity Stock Ratings(https://arxiv.org/abs/2411.00856)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Investment Analysis is a cornerstone of the Financial Services industry. The rapid integration of advanced machine learning techniques, particularly Large Language Models (LLMs), offers opportunities to enhance the equity rating process. This paper explores the application of LLMs to generate multi-horizon stock ratings by ingesting diverse datasets. Traditional stock rating methods rely heavily on the expertise of financial analysts, and face several challenges such as data overload, inconsistencies in filings, and delayed reactions to market events. Our study addresses these issues by leveraging LLMs to improve the accuracy and consistency of stock ratings. Additionally, we assess the efficacy of using different data modalities with LLMs for the financial domain. We utilize varied datasets comprising fundamental financial, market, and news data from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a training cutoff in Sep. 2021 to prevent information leakage). Our results show that our benchmark method outperforms traditional stock rating methods when assessed by forward returns, specially when incorporating financial fundamentals. While integrating news data improves short-term performance, substituting detailed news summaries with sentiment scores reduces token use without loss of performance. In many cases, omitting news data entirely enhances performance by reducing bias. Our research shows that LLMs can be leveraged to effectively utilize large amounts of multimodal financial data, as showcased by their effectiveness at the stock rating prediction task. Our work provides a reproducible and efficient framework for generating accurate stock ratings, serving as a cost-effective alternative to traditional methods. Future work will extend to longer timeframes, incorporate diverse data, and utilize newer models for enhanced insights.</li>
</ul>

<h3>Title: DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection</h3>
<ul>
<li><strong>Authors: </strong>Vahideh Hayyolalam, Öznur Özkasap</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00858">https://arxiv.org/abs/2411.00858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00858">https://arxiv.org/pdf/2411.00858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00858]] DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection(https://arxiv.org/abs/2411.00858)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Diabetes is a chronic disorder identified by the high sugar level in the blood that can cause various different disorders such as kidney failure, heart attack, sightlessness, and stroke. Developments in the healthcare domain by facilitating the early detection of diabetes risk can help not only caregivers but also patients. AIoMT is a recent technology that integrates IoT and machine learning methods to give services for medical purposes, which is a powerful technology for the early detection of diabetes. In this paper, we take advantage of AIoMT and propose a hybrid diabetes risk detection method, DiabML, which uses the BWO algorithm and ML methods. BWO is utilized for feature selection and SMOTE for imbalance handling in the pre-processing procedure. The simulation results prove the superiority of the proposed DiabML method compared to the existing works. DiabML achieves 86.1\% classification accuracy by AdaBoost classifier outperforms the relevant existing methods.</li>
</ul>

<h3>Title: Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems</h3>
<ul>
<li><strong>Authors: </strong>Juan Marcelo Parra-Ullauri, Oscar Dilley, Hari Madhukumar, Dimitra Simeonidou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.ET, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00859">https://arxiv.org/abs/2411.00859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00859">https://arxiv.org/pdf/2411.00859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00859]] Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems(https://arxiv.org/abs/2411.00859)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rapid growth of end-user AI applications, such as computer vision and generative AI, has led to immense data and processing demands often exceeding user devices' capabilities. Edge AI addresses this by offloading computation to the network edge, crucial for future services in 6G networks. However, it faces challenges such as limited resources during simultaneous offloads and the unrealistic assumption of homogeneous system architecture. To address these, we propose a research roadmap focused on profiling AI models, capturing data about model types, hyperparameters, and underlying hardware to predict resource utilisation and task completion time. Initial experiments with over 3,000 runs show promise in optimising resource allocation and enhancing Edge AI performance.</li>
</ul>

<h3>Title: Survey of Cultural Awareness in Language Models: Text and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Siddhesh Pawar, Junyeong Park, Jiho Jin, Arnav Arora, Junho Myung, Srishti Yadav, Faiz Ghifari Haznitrama, Inhwa Song, Alice Oh, Isabelle Augenstein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00860">https://arxiv.org/abs/2411.00860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00860">https://arxiv.org/pdf/2411.00860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00860]] Survey of Cultural Awareness in Language Models: Text and Beyond(https://arxiv.org/abs/2411.00860)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large-scale deployment of large language models (LLMs) in various applications, such as chatbots and virtual assistants, requires LLMs to be culturally sensitive to the user to ensure inclusivity. Culture has been widely studied in psychology and anthropology, and there has been a recent surge in research on making LLMs more culturally inclusive in LLMs that goes beyond multilinguality and builds on findings from psychology and anthropology. In this paper, we survey efforts towards incorporating cultural awareness into text-based and multimodal LLMs. We start by defining cultural awareness in LLMs, taking the definitions of culture from anthropology and psychology as a point of departure. We then examine methodologies adopted for creating cross-cultural datasets, strategies for cultural inclusion in downstream tasks, and methodologies that have been used for benchmarking cultural awareness in LLMs. Further, we discuss the ethical implications of cultural alignment, the role of Human-Computer Interaction in driving cultural inclusion in LLMs, and the role of cultural alignment in driving social science research. We finally provide pointers to future research based on our findings about gaps in the literature.</li>
</ul>

<h3>Title: Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation</h3>
<ul>
<li><strong>Authors: </strong>Chenyang An, Shima Imani, Feng Yao, Chengyu Dong, Ali Abbasi, Harsh Shrivastava, Samuel Buss, Jingbo Shang, Gayathri Mahalingam, Pramod Sharma, Maurice Diesendruck</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00863">https://arxiv.org/abs/2411.00863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00863">https://arxiv.org/pdf/2411.00863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00863]] Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation(https://arxiv.org/abs/2411.00863)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the field of large language model (LLM)-based proof generation, despite being trained on extensive corpora such as OpenWebMath and Arxiv, these models still exhibit only modest performance on proving tasks of moderate difficulty. We believe that this is partly due to the suboptimal order of each proof data used in training. Published proofs often follow a purely logical order, where each step logically proceeds from the previous steps based on the deductive rules. However, this order aims to facilitate the verification of the proof's soundness, rather than to help people and models learn the discovery process of the proof. In proof generation, we argue that the optimal order for one training data sample occurs when the relevant intermediate supervision for a particular proof step in the proof is always positioned to the left of that proof step. We call such order the intuitively sequential order. We validate our claims using two tasks: intuitionistic propositional logic theorem-proving and digit multiplication. Our experiments verify the order effect and provide support for our explanations. We demonstrate that training is most effective when the proof is in the intuitively sequential order. Moreover, the order effect and the performance gap between models trained on different data orders are substantial -- with an 11 percent improvement in proof success rate observed in the propositional logic theorem-proving task, between models trained on the optimal order compared to the worst order.</li>
</ul>

<h3>Title: Mechanistic Interpretability of Reinforcement Learning Agents</h3>
<ul>
<li><strong>Authors: </strong>Tristan Trim, Triston Grayston</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00867">https://arxiv.org/abs/2411.00867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00867">https://arxiv.org/pdf/2411.00867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00867]] Mechanistic Interpretability of Reinforcement Learning Agents(https://arxiv.org/abs/2411.00867)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This paper explores the mechanistic interpretability of reinforcement learning (RL) agents through an analysis of a neural network trained on procedural maze environments. By dissecting the network's inner workings, we identified fundamental features like maze walls and pathways, forming the basis of the model's decision-making process. A significant observation was the goal misgeneralization, where the RL agent developed biases towards certain navigation strategies, such as consistently moving towards the top right corner, even in the absence of explicit goals. Using techniques like saliency mapping and feature mapping, we visualized these biases. We furthered this exploration with the development of novel tools for interactively exploring layer activations.</li>
</ul>

<h3>Title: LLaMo: Large Language Model-based Molecular Graph Assistant</h3>
<ul>
<li><strong>Authors: </strong>Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.MN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00871">https://arxiv.org/abs/2411.00871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00871">https://arxiv.org/pdf/2411.00871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00871]] LLaMo: Large Language Model-based Molecular Graph Assistant(https://arxiv.org/abs/2411.00871)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable generalization and instruction-following capabilities with instruction tuning. The advancements in LLMs and instruction tuning have led to the development of Large Vision-Language Models (LVLMs). However, the competency of the LLMs and instruction tuning have been less explored in the molecular domain. Thus, we propose LLaMo: Large Language Model-based Molecular graph assistant, which is an end-to-end trained large molecular graph-language model. To bridge the discrepancy between the language and graph modalities, we present the multi-level graph projector that transforms graph representations into graph tokens by abstracting the output representations of each GNN layer and motif representations with the cross-attention mechanism. We also introduce machine-generated molecular graph instruction data to instruction-tune the large molecular graph-language model for general-purpose molecule and language understanding. Our extensive experiments demonstrate that LLaMo shows the best performance on diverse tasks, such as molecular description generation, property prediction, and IUPAC name prediction. The code of LLaMo is available at this https URL.</li>
</ul>

<h3>Title: CleaR: Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning</h3>
<ul>
<li><strong>Authors: </strong>Yeachan Kim, Junho Kim, SangKeun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00873">https://arxiv.org/abs/2411.00873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00873">https://arxiv.org/pdf/2411.00873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00873]] CleaR: Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning(https://arxiv.org/abs/2411.00873)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization of cumbersome language models in real-world settings. However, as datasets in such environments often contain noisy labels that adversely affect performance, PEFT methods are inevitably exposed to noisy labels. Despite this challenge, the adaptability of PEFT to noisy environments remains underexplored. To bridge this gap, we investigate various PEFT methods under noisy labels. Interestingly, our findings reveal that PEFT has difficulty in memorizing noisy labels due to its inherently limited capacity, resulting in robustness. However, we also find that such limited capacity simultaneously makes PEFT more vulnerable to interference of noisy labels, impeding the learning of clean samples. To address this issue, we propose Clean Routing (CleaR), a novel routing-based PEFT approach that adaptively activates PEFT modules. In CleaR, PEFT modules are preferentially exposed to clean data while bypassing the noisy ones, thereby minimizing the noisy influence. To verify the efficacy of CleaR, we perform extensive experiments on diverse configurations of noisy labels. The results convincingly demonstrate that CleaR leads to substantially improved performance in noisy environments.</li>
</ul>

<h3>Title: Resilience to the Flowing Unknown: an Open Set Recognition Framework for Data Streams</h3>
<ul>
<li><strong>Authors: </strong>Marcos Barcina-Blanco, Jesus L. Lobo, Pablo Garcia-Bringas, Javier Del Ser</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00876">https://arxiv.org/abs/2411.00876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00876">https://arxiv.org/pdf/2411.00876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00876]] Resilience to the Flowing Unknown: an Open Set Recognition Framework for Data Streams(https://arxiv.org/abs/2411.00876)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern digital applications extensively integrate Artificial Intelligence models into their core systems, offering significant advantages for automated decision-making. However, these AI-based systems encounter reliability and safety challenges when handling continuously generated data streams in complex and dynamic scenarios. This work explores the concept of resilient AI systems, which must operate in the face of unexpected events, including instances that belong to patterns that have not been seen during the training process. This is an issue that regular closed-set classifiers commonly encounter in streaming scenarios, as they are designed to compulsory classify any new observation into one of the training patterns (i.e., the so-called \textit{over-occupied space} problem). In batch learning, the Open Set Recognition research area has consistently confronted this issue by requiring models to robustly uphold their classification performance when processing query instances from unknown patterns. In this context, this work investigates the application of an Open Set Recognition framework that combines classification and clustering to address the \textit{over-occupied space} problem in streaming scenarios. Specifically, we systematically devise a benchmark comprising different classification datasets with varying ratios of known to unknown classes. Experiments are presented on this benchmark to compare the performance of the proposed hybrid framework with that of individual incremental classifiers. Discussions held over the obtained results highlight situations where the proposed framework performs best, and delineate the limitations and hurdles encountered by incremental classifiers in effectively resolving the challenges posed by open-world streaming environments.</li>
</ul>

<h3>Title: Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models</h3>
<ul>
<li><strong>Authors: </strong>Phil Wee, Riyadh Baghdadi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00878">https://arxiv.org/abs/2411.00878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00878">https://arxiv.org/pdf/2411.00878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00878]] Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models(https://arxiv.org/abs/2411.00878)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, there has been an explosion of large language models created through fine-tuning with data from larger models. These small models able to produce outputs that appear qualitatively similar to significantly larger models. However, one of the key limitations that have been observed with these models is their propensity to hallucinate significantly more often than larger models. In particular, they have been observed to generate coherent outputs that involve factually incorrect information and spread misinformation, toxicity, and stereotypes. There are many potential causes of hallucination, of which, one hypothesis is that fine-tuning a model on data produced by a larger model leads to a knowledge mismatch which contributes to hallucination. In particular, it is hypothesized that there is a mismatch between the knowledge that is fed to the model to fine-tune it and the knowledge that is already present in the graph. Fine-tuning the model on data that has such mismatch could contribute to an increased propensity to hallucinate. We show that on an unseen test set, a smaller model fine-tuned on data generated from a larger model produced more wrong answers when compared to models fine-tuned on data created by the small model, which confirms the hypothesis.</li>
</ul>

<h3>Title: Technical Report for ActivityNet Challenge 2022 -- Temporal Action Localization</h3>
<ul>
<li><strong>Authors: </strong>Shimin Chen, Wei Li, Jianyang Gu, Chen Chen, Yandong Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00883">https://arxiv.org/abs/2411.00883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00883">https://arxiv.org/pdf/2411.00883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00883]] Technical Report for ActivityNet Challenge 2022 -- Temporal Action Localization(https://arxiv.org/abs/2411.00883)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In the task of temporal action localization of ActivityNet-1.3 datasets, we propose to locate the temporal boundaries of each action and predict action class in untrimmed videos. We first apply VideoSwinTransformer as feature extractor to extract different features. Then we apply a unified network following Faster-TAD to simultaneously obtain proposals and semantic labels. Last, we ensemble the results of different temporal action detection models which complement each other. Faster-TAD simplifies the pipeline of TAD and gets remarkable performance, obtaining comparable results as those of multi-step approaches.</li>
</ul>

<h3>Title: MESS+: Energy-Optimal Inferencing in Language Model Zoos with Service Level Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Ryan Zhang, Herbert Woisetschläger, Shiqiang Wang, Hans Arno Jacobsen</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00889">https://arxiv.org/abs/2411.00889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00889">https://arxiv.org/pdf/2411.00889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00889]] MESS+: Energy-Optimal Inferencing in Language Model Zoos with Service Level Guarantees(https://arxiv.org/abs/2411.00889)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Open-weight large language model (LLM) zoos allow users to quickly integrate state-of-the-art models into systems. Despite increasing availability, selecting the most appropriate model for a given task still largely relies on public benchmark leaderboards and educated guesses. This can be unsatisfactory for both inference service providers and end users, where the providers usually prioritize cost efficiency, while the end users usually prioritize model output quality for their inference requests. In commercial settings, these two priorities are often brought together in Service Level Agreements (SLA). We present MESS+, an online stochastic optimization algorithm for energy-optimal model selection from a model zoo, which works on a per-inference-request basis. For a given SLA that requires high accuracy, we are up to 2.5x more energy efficient with MESS+ than with randomly selecting an LLM from the zoo while maintaining SLA quality constraints.</li>
</ul>

<h3>Title: Rethinking Scale: The Efficacy of Fine-Tuned Open-Source LLMs in Large-Scale Reproducible Social Science Research</h3>
<ul>
<li><strong>Authors: </strong>Marcello Carammia, Stefano Maria Iacus, Giuseppe Porro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00890">https://arxiv.org/abs/2411.00890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00890">https://arxiv.org/pdf/2411.00890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00890]] Rethinking Scale: The Efficacy of Fine-Tuned Open-Source LLMs in Large-Scale Reproducible Social Science Research(https://arxiv.org/abs/2411.00890)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are distinguished by their architecture, which dictates their parameter size and performance capabilities. Social scientists have increasingly adopted LLMs for text classification tasks, which are difficult to scale with human coders. While very large, closed-source models often deliver superior performance, their use presents significant risks. These include lack of transparency, potential exposure of sensitive data, challenges to replicability, and dependence on proprietary systems. Additionally, their high costs make them impractical for large-scale research projects. In contrast, open-source models, although available in various sizes, may underperform compared to commercial alternatives if used without further fine-tuning. However, open-source models offer distinct advantages: they can be run locally (ensuring data privacy), fine-tuned for specific tasks, shared within the research community, and integrated into reproducible workflows. This study demonstrates that small, fine-tuned open-source LLMs can achieve equal or superior performance to models such as ChatGPT-4. We further explore the relationship between training set size and fine-tuning efficacy in open-source models. Finally, we propose a hybrid workflow that leverages the strengths of both open and closed models, offering a balanced approach to performance, transparency, and reproducibility.</li>
</ul>

<h3>Title: Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback</h3>
<ul>
<li><strong>Authors: </strong>Song Yu, Xiaofei Xu, Fangfei Xu, Li Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00897">https://arxiv.org/abs/2411.00897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00897">https://arxiv.org/pdf/2411.00897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00897]] Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback(https://arxiv.org/abs/2411.00897)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models perform well in understanding and responding to user intent, their performance in specialized domains such as Traditional Chinese Medicine (TCM) remains limited due to lack of expertise. In addition, high-quality data related to TCM is scarce and difficult to obtain, making large language models ineffective in handling TCM tasks. In this work, we propose a framework to improve the performance of large language models for TCM tasks using only a small amount of data. First, we use medical case data for supervised fine-tuning of the large model, making it initially capable of performing TCM tasks. Subsequently, we further optimize the model's performance using reinforcement learning from AI feedback (RLAIF) to align it with the preference data. The ablation study also demonstrated the performance gain is attributed to both supervised fine-tuning and the direct policy optimization. The experimental results show that the model trained with a small amount of data achieves a significant performance improvement on a representative TCM task.</li>
</ul>

<h3>Title: Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jonggyu Jang, Hyeonsu Lyu, Jungyeon Koh, Hyun Jong Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00898">https://arxiv.org/abs/2411.00898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00898">https://arxiv.org/pdf/2411.00898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00898]] Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models(https://arxiv.org/abs/2411.00898)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, segmentation</a></li>
<li><strong>Abstract: </strong>The conventional targeted adversarial attacks add a small perturbation to an image to make neural network models estimate the image as a predefined target class, even if it is not the correct target class. Recently, for visual-language models (VLMs), the focus of targeted adversarial attacks is to generate a perturbation that makes VLMs answer intended target text outputs. For example, they aim to make a small perturbation on an image to make VLMs' answers change from "there is an apple" to "there is a baseball." However, answering just intended text outputs is insufficient for tricky questions like "if there is a baseball, tell me what is below it." This is because the target of the adversarial attacks does not consider the overall integrity of the original image, thereby leading to a lack of visual reasoning. In this work, we focus on generating targeted adversarial examples with visual reasoning against VLMs. To this end, we propose 1) a novel adversarial attack procedure -- namely, Replace-then-Perturb and 2) a contrastive learning-based adversarial loss -- namely, Contrastive-Adv. In Replace-then-Perturb, we first leverage a text-guided segmentation model to find the target object in the image. Then, we get rid of the target object and inpaint the empty space with the desired prompt. By doing this, we can generate a target image corresponding to the desired prompt, while maintaining the overall integrity of the original image. Furthermore, in Contrastive-Adv, we design a novel loss function to obtain better adversarial examples. Our extensive benchmark results demonstrate that Replace-then-Perturb and Contrastive-Adv outperform the baseline adversarial attack algorithms. We note that the source code to reproduce the results will be available.</li>
</ul>

<h3>Title: Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing</h3>
<ul>
<li><strong>Authors: </strong>Weizhi Gao, Zhichao Hou, Han Xu, Xiaorui Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00899">https://arxiv.org/abs/2411.00899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00899">https://arxiv.org/pdf/2411.00899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00899]] Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing(https://arxiv.org/abs/2411.00899)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, robust</a></li>
<li><strong>Abstract: </strong>Implicit models such as Deep Equilibrium Models (DEQs) have emerged as promising alternative approaches for building deep neural networks. Their certified robustness has gained increasing research attention due to security concerns. Existing certified defenses for DEQs employing deterministic certification methods such as interval bound propagation and Lipschitz-bounds can not certify on large-scale datasets. Besides, they are also restricted to specific forms of DEQs. In this paper, we provide the first randomized smoothing certified defense for DEQs to solve these limitations. Our study reveals that simply applying randomized smoothing to certify DEQs provides certified robustness generalized to large-scale datasets but incurs extremely expensive computation costs. To reduce computational redundancy, we propose a novel Serialized Randomized Smoothing (SRS) approach that leverages historical information. Additionally, we derive a new certified radius estimation for SRS to theoretically ensure the correctness of our algorithm. Extensive experiments and ablation studies on image recognition demonstrate that our algorithm can significantly accelerate the certification of DEQs by up to 7x almost without sacrificing the certified accuracy. Our code is available at this https URL.</li>
</ul>

<h3>Title: Similarity and Dissimilarity Guided Co-association Matrix Construction for Ensemble Clustering</h3>
<ul>
<li><strong>Authors: </strong>Xu Zhang, Yuheng Jia, Mofei Song, Ran Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00904">https://arxiv.org/abs/2411.00904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00904">https://arxiv.org/pdf/2411.00904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00904]] Similarity and Dissimilarity Guided Co-association Matrix Construction for Ensemble Clustering(https://arxiv.org/abs/2411.00904)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ensemble clustering aggregates multiple weak clusterings to achieve a more accurate and robust consensus result. The Co-Association matrix (CA matrix) based method is the mainstream ensemble clustering approach that constructs the similarity relationships between sample pairs according the weak clustering partitions to generate the final clustering result. However, the existing methods neglect that the quality of cluster is related to its size, i.e., a cluster with smaller size tends to higher accuracy. Moreover, they also do not consider the valuable dissimilarity information in the base clusterings which can reflect the varying importance of sample pairs that are completely disconnected. To this end, we propose the Similarity and Dissimilarity Guided Co-association matrix (SDGCA) to achieve ensemble clustering. First, we introduce normalized ensemble entropy to estimate the quality of each cluster, and construct a similarity matrix based on this estimation. Then, we employ the random walk to explore high-order proximity of base clusterings to construct a dissimilarity matrix. Finally, the adversarial relationship between the similarity matrix and the dissimilarity matrix is utilized to construct a promoted CA matrix for ensemble clustering. We compared our method with 13 state-of-the-art methods across 12 datasets, and the results demonstrated the superiority clustering ability and robustness of the proposed approach. The code is available at this https URL.</li>
</ul>

<h3>Title: AAD-LLM: Adaptive Anomaly Detection Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alicia Russell-Gilbert, Alexander Sommers, Andrew Thompson, Logan Cummins, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jaboure, Thomas Arnold, Joshua Church</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00914">https://arxiv.org/abs/2411.00914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00914">https://arxiv.org/pdf/2411.00914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00914]] AAD-LLM: Adaptive Anomaly Detection Using Large Language Models(https://arxiv.org/abs/2411.00914)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>For data-constrained, complex and dynamic industrial environments, there is a critical need for transferable and multimodal methodologies to enhance anomaly detection and therefore, prevent costs associated with system failures. Typically, traditional PdM approaches are not transferable or multimodal. This work examines the use of Large Language Models (LLMs) for anomaly detection in complex and dynamic manufacturing systems. The research aims to improve the transferability of anomaly detection models by leveraging Large Language Models (LLMs) and seeks to validate the enhanced effectiveness of the proposed approach in data-sparse industrial applications. The research also seeks to enable more collaborative decision-making between the model and plant operators by allowing for the enriching of input series data with semantics. Additionally, the research aims to address the issue of concept drift in dynamic industrial settings by integrating an adaptability mechanism. The literature review examines the latest developments in LLM time series tasks alongside associated adaptive anomaly detection methods to establish a robust theoretical framework for the proposed architecture. This paper presents a novel model framework (AAD-LLM) that doesn't require any training or finetuning on the dataset it is applied to and is multimodal. Results suggest that anomaly detection can be converted into a "language" task to deliver effective, context-aware detection in data-constrained industrial applications. This work, therefore, contributes significantly to advancements in anomaly detection methodologies.</li>
</ul>

<h3>Title: V-LoRA: An Efficient and Flexible System Boosts Vision Applications with LoRA LMM</h3>
<ul>
<li><strong>Authors: </strong>Liang Mi, Weijun Wang, Wenming Tu, Qingfeng He, Rui Kong, Xinyu Fang, Yazhu Dong, Yikang Zhang, Yunchun Li, Meng Li, Haipeng Dai, Guihai Chen, Yunxin Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00915">https://arxiv.org/abs/2411.00915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00915">https://arxiv.org/pdf/2411.00915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00915]] V-LoRA: An Efficient and Flexible System Boosts Vision Applications with LoRA LMM(https://arxiv.org/abs/2411.00915)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Multimodal Models (LMMs) have shown significant progress in various complex vision tasks with the solid linguistic and reasoning capacity inherited from large language models (LMMs). Low-rank adaptation (LoRA) offers a promising method to integrate external knowledge into LMMs, compensating for their limitations on domain-specific tasks. However, the existing LoRA model serving is excessively computationally expensive and causes extremely high latency. In this paper, we present an end-to-end solution that empowers diverse vision tasks and enriches vision applications with LoRA LMMs. Our system, VaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware LoRA adapter generation approach that generates LoRA adapters rich in domain-specific knowledge to meet application-specific accuracy requirements, 2) an adaptive-tiling LoRA adapters batching operator that efficiently computes concurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter orchestration mechanism that manages application requests and LoRA adapters to achieve the lowest average response latency. We prototype VaLoRA on five popular vision tasks on three LMMs. Experiment results reveal that VaLoRA improves 24-62% of the accuracy compared to the original LMMs and reduces 20-89% of the latency compared to the state-of-the-art LoRA model serving systems.</li>
</ul>

<h3>Title: Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, U. Rajendra Acharya, Oliver Faust</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00916">https://arxiv.org/abs/2411.00916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00916">https://arxiv.org/pdf/2411.00916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00916]] Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering(https://arxiv.org/abs/2411.00916)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Osteoporosis is a common condition that increases fracture risk, especially in older adults. Early diagnosis is vital for preventing fractures, reducing treatment costs, and preserving mobility. However, healthcare providers face challenges like limited labeled data and difficulties in processing medical images. This study presents a novel multi-modal learning framework that integrates clinical and imaging data to improve diagnostic accuracy and model interpretability. The model utilizes three pre-trained networks-VGG19, InceptionV3, and ResNet50-to extract deep features from X-ray images. These features are transformed using PCA to reduce dimensionality and focus on the most relevant components. A clustering-based selection process identifies the most representative components, which are then combined with preprocessed clinical data and processed through a fully connected network (FCN) for final classification. A feature importance plot highlights key variables, showing that Medical History, BMI, and Height were the main contributors, emphasizing the significance of patient-specific data. While imaging features were valuable, they had lower importance, indicating that clinical data are crucial for accurate predictions. This framework promotes precise and interpretable predictions, enhancing transparency and building trust in AI-driven diagnoses for clinical integration.</li>
</ul>

<h3>Title: LIBMoE: A Library for comprehensive benchmarking Mixture of Experts in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nam V. Nguyen, Thong T. Doan, Luong Tran, Van Nguyen, Quang Pham</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00918">https://arxiv.org/abs/2411.00918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00918">https://arxiv.org/pdf/2411.00918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00918]] LIBMoE: A Library for comprehensive benchmarking Mixture of Experts in Large Language Models(https://arxiv.org/abs/2411.00918)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoEs) plays an important role in the development of more efficient and effective large language models (LLMs). Due to the enormous resource requirements, studying large scale MoE algorithms remain in-accessible to many researchers. This work develops \emph{LibMoE}, a comprehensive and modular framework to streamline the research, training, and evaluation of MoE algorithms. Built upon three core principles: (i) modular design, (ii) efficient training; (iii) comprehensive evaluation, LibMoE brings MoE in LLMs more accessible to a wide range of researchers by standardizing the training and evaluation pipelines. Using LibMoE, we extensively benchmarked five state-of-the-art MoE algorithms over three different LLMs and 11 datasets under the zero-shot setting. The results show that despite the unique characteristics, all MoE algorithms perform roughly similar when averaged across a wide range of tasks. With the modular design and extensive evaluation, we believe LibMoE will be invaluable for researchers to make meaningful progress towards the next generation of MoE and LLMs. Project page: \url{this https URL}.</li>
</ul>

<h3>Title: ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents</h3>
<ul>
<li><strong>Authors: </strong>Vardhan Dongre, Xiaocheng Yang, Emre Can Acikgoz, Suvodip Dey, Gokhan Tur, Dilek Hakkani-Tür</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00927">https://arxiv.org/abs/2411.00927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00927">https://arxiv.org/pdf/2411.00927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00927]] ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents(https://arxiv.org/abs/2411.00927)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM)-based agents have been increasingly used to interact with external environments (e.g., games, APIs, etc.) and solve tasks. However, current frameworks do not enable these agents to work with users and interact with them to align on the details of their tasks and reach user-defined goals; instead, in ambiguous situations, these agents may make decisions based on assumptions. This work introduces ReSpAct (Reason, Speak, and Act), a novel framework that synergistically combines the essential skills for building task-oriented "conversational" agents. ReSpAct addresses this need for agents, expanding on the ReAct approach. The ReSpAct framework enables agents to interpret user instructions, reason about complex tasks, execute appropriate actions, and engage in dynamic dialogue to seek guidance, clarify ambiguities, understand user preferences, resolve problems, and use the intermediate feedback and responses of users to update their plans. We evaluated ReSpAct in environments supporting user interaction, such as task-oriented dialogue (MultiWOZ) and interactive decision-making (AlfWorld, WebShop). ReSpAct is flexible enough to incorporate dynamic user feedback and addresses prevalent issues like error propagation and agents getting stuck in reasoning loops. This results in more interpretable, human-like task-solving trajectories than relying solely on reasoning traces. In two interactive decision-making benchmarks, AlfWorld and WebShop, ReSpAct outperform the strong reasoning-only method ReAct by an absolute success rate of 6% and 4%, respectively. In the task-oriented dialogue benchmark MultiWOZ, ReSpAct improved Inform and Success scores by 5.5% and 3%, respectively.</li>
</ul>

<h3>Title: Scalable AI Framework for Defect Detection in Metal Additive Manufacturing</h3>
<ul>
<li><strong>Authors: </strong>Duy Nhat Phan, Sushant Jha, James P. Mavo, Erin L. Lanigan, Linh Nguyen, Lokendra Poudel, Rahul Bhowmik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00960">https://arxiv.org/abs/2411.00960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00960">https://arxiv.org/pdf/2411.00960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00960]] Scalable AI Framework for Defect Detection in Metal Additive Manufacturing(https://arxiv.org/abs/2411.00960)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Additive Manufacturing (AM) is transforming the manufacturing sector by enabling efficient production of intricately designed products and small-batch components. However, metal parts produced via AM can include flaws that cause inferior mechanical properties, including reduced fatigue response, yield strength, and fracture toughness. To address this issue, we leverage convolutional neural networks (CNN) to analyze thermal images of printed layers, automatically identifying anomalies that impact these properties. We also investigate various synthetic data generation techniques to address limited and imbalanced AM training data. Our models' defect detection capabilities were assessed using images of Nickel alloy 718 layers produced on a laser powder bed fusion AM machine and synthetic datasets with and without added noise. Our results show significant accuracy improvements with synthetic data, emphasizing the importance of expanding training sets for reliable defect detection. Specifically, Generative Adversarial Networks (GAN)-generated datasets streamlined data preparation by eliminating human intervention while maintaining high performance, thereby enhancing defect detection capabilities. Additionally, our denoising approach effectively improves image quality, ensuring reliable defect detection. Finally, our work integrates these models in the CLoud ADditive MAnufacturing (CLADMA) module, a user-friendly interface, to enhance their accessibility and practicality for AM applications. This integration supports broader adoption and practical implementation of advanced defect detection in AM processes.</li>
</ul>

<h3>Title: Does the Definition of Difficulty Matter? Scoring Functions and their Role for Curriculum Learning</h3>
<ul>
<li><strong>Authors: </strong>Simon Rampp, Manuel Milling, Andreas Triantafyllopoulos, Björn W. Schuller</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00973">https://arxiv.org/abs/2411.00973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00973">https://arxiv.org/pdf/2411.00973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00973]] Does the Definition of Difficulty Matter? Scoring Functions and their Role for Curriculum Learning(https://arxiv.org/abs/2411.00973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Curriculum learning (CL) describes a machine learning training strategy in which samples are gradually introduced into the training process based on their difficulty. Despite a partially contradictory body of evidence in the literature, CL finds popularity in deep learning research due to its promise of leveraging human-inspired curricula to achieve higher model performance. Yet, the subjectivity and biases that follow any necessary definition of difficulty, especially for those found in orderings derived from models or training statistics, have rarely been investigated. To shed more light on the underlying unanswered questions, we conduct an extensive study on the robustness and similarity of the most common scoring functions for sample difficulty estimation, as well as their potential benefits in CL, using the popular benchmark dataset CIFAR-10 and the acoustic scene classification task from the DCASE2020 challenge as representatives of computer vision and computer audition, respectively. We report a strong dependence of scoring functions on the training setting, including randomness, which can partly be mitigated through ensemble scoring. While we do not find a general advantage of CL over uniform sampling, we observe that the ordering in which data is presented for CL-based training plays an important role in model performance. Furthermore, we find that the robustness of scoring functions across random seeds positively correlates with CL performance. Finally, we uncover that models trained with different CL strategies complement each other by boosting predictive power through late fusion, likely due to differences in the learnt concepts. Alongside our findings, we release the aucurriculum toolkit (this https URL), implementing sample difficulty and CL-based training in a modular fashion.</li>
</ul>

<h3>Title: Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An Evaluation Using TORGO</h3>
<ul>
<li><strong>Authors: </strong>Macarious Hui, Jinda Zhang, Aanchan Mohan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00980">https://arxiv.org/abs/2411.00980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00980">https://arxiv.org/pdf/2411.00980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00980]] Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An Evaluation Using TORGO(https://arxiv.org/abs/2411.00980)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS) frequently face challenges with articulation, leading to dysarthria and resulting in atypical speech patterns. In healthcare settings, coomunication breakdowns reduce the quality of care. While building an augmentative and alternative communication (AAC) tool to enable fluid communication we found that state-of-the-art (SOTA) automatic speech recognition (ASR) technology like Whisper and Wav2vec2.0 marginalizes atypical speakers largely due to the lack of training data. Our work looks to leverage SOTA ASR followed by domain specific error-correction. English dysarthric ASR performance is often evaluated on the TORGO dataset. Prompt-overlap is a well-known issue with this dataset where phrases overlap between training and test speakers. Our work proposes an algorithm to break this prompt-overlap. After reducing prompt-overlap, results with SOTA ASR models produce extremely high word error rates for speakers with mild and severe dysarthria. Furthermore, to improve ASR, our work looks at the impact of n-gram language models and large-language model (LLM) based multi-modal generative error-correction algorithms like Whispering-LLaMA for a second pass ASR. Our work highlights how much more needs to be done to improve ASR for atypical speakers to enable equitable healthcare access both in-person and in e-health settings.</li>
</ul>

<h3>Title: FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Wu, Simin Chen, Yuzhe Yang, Yijiang Li, Shiyue Hou, Rui Jing, Zehua Wang, Wei Chen, Zijian Tian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00985">https://arxiv.org/abs/2411.00985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00985">https://arxiv.org/pdf/2411.00985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00985]] FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models(https://arxiv.org/abs/2411.00985)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, large language models (LLMs) have significantly advanced the field of natural language processing (NLP). By fine-tuning LLMs with data from specific scenarios, these foundation models can better adapt to various downstream tasks. However, the fine-tuning process poses privacy leakage risks, particularly in centralized data processing scenarios. To address user privacy concerns, federated learning (FL) has been introduced to mitigate the risks associated with centralized data collection from multiple sources. Nevertheless, the privacy of LLMs themselves is equally critical, as potential malicious attacks challenge their security, an issue that has received limited attention in current research. Consequently, establishing a trusted multi-party model fine-tuning environment is essential. Additionally, the local deployment of large LLMs incurs significant storage costs and high computational demands. To address these challenges, we propose for the first time a federated discrete and transferable prompt tuning, namely FedDTPT, for black-box large language models. In the client optimization phase, we adopt a token-level discrete prompt optimization method that leverages a feedback loop based on prediction accuracy to drive gradient-free prompt optimization through the MLM API. For server optimization, we employ an attention mechanism based on semantic similarity to filter all local prompt tokens, along with an embedding distance elbow detection and DBSCAN clustering strategy to enhance the filtering process. Experimental results demonstrate that, compared to state-of-the-art methods, our approach achieves higher accuracy, reduced communication overhead, and robustness to non-iid data in a black-box setting. Moreover, the optimized prompts are transferable.</li>
</ul>

<h3>Title: Identifying Implicit Social Biases in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kimia Hamidieh, Haoran Zhang, Walter Gerych, Thomas Hartvigsen, Marzyeh Ghassemi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00997">https://arxiv.org/abs/2411.00997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00997">https://arxiv.org/pdf/2411.00997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00997]] Identifying Implicit Social Biases in Vision-Language Models(https://arxiv.org/abs/2411.00997)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Vision-language models, like CLIP (Contrastive Language Image Pretraining), are becoming increasingly popular for a wide range of multimodal retrieval tasks. However, prior work has shown that large language and deep vision models can learn historical biases contained in their training sets, leading to perpetuation of stereotypes and potential downstream harm. In this work, we conduct a systematic analysis of the social biases that are present in CLIP, with a focus on the interaction between image and text modalities. We first propose a taxonomy of social biases called So-B-IT, which contains 374 words categorized across ten types of bias. Each type can lead to societal harm if associated with a particular demographic group. Using this taxonomy, we examine images retrieved by CLIP from a facial image dataset using each word as part of a prompt. We find that CLIP frequently displays undesirable associations between harmful words and specific demographic groups, such as retrieving mostly pictures of Middle Eastern men when asked to retrieve images of a "terrorist". Finally, we conduct an analysis of the source of such biases, by showing that the same harmful stereotypes are also present in a large image-text dataset used to train CLIP models for examples of biases that we find. Our findings highlight the importance of evaluating and addressing bias in vision-language models, and suggest the need for transparency and fairness-aware curation of large pre-training datasets.</li>
</ul>

<h3>Title: Normalization Layer Per-Example Gradients are Sufficient to Predict Gradient Noise Scale in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Gavia Gray, Aman Tiwari, Shane Bergsma, Joel Hestness</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00999">https://arxiv.org/abs/2411.00999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00999">https://arxiv.org/pdf/2411.00999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00999]] Normalization Layer Per-Example Gradients are Sufficient to Predict Gradient Noise Scale in Transformers(https://arxiv.org/abs/2411.00999)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Per-example gradient norms are a vital ingredient for estimating gradient noise scale (GNS) with minimal variance. Observing the tensor contractions required to compute them, we propose a method with minimal FLOPs in 3D or greater tensor regimes by simultaneously computing the norms while computing the parameter gradients. Using this method we are able to observe the GNS of different layers at higher accuracy than previously possible. We find that the total GNS of contemporary transformer models is predicted well by the GNS of only the normalization layers. As a result, focusing only on the normalization layer, we develop a custom kernel to compute the per-example gradient norms while performing the LayerNorm backward pass with zero throughput overhead. Tracking GNS on only those layers, we are able to guide a practical batch size schedule that reduces training time by 18% on a Chinchilla-optimal language model.</li>
</ul>

<h3>Title: Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula</h3>
<ul>
<li><strong>Authors: </strong>Sam Blouir, Jimmy Smith, Antonios Anastasopoulos, Amarda Shehu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01030">https://arxiv.org/abs/2411.01030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01030">https://arxiv.org/pdf/2411.01030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01030]] Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula(https://arxiv.org/abs/2411.01030)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Efficient state space models (SSMs), including linear recurrent neural networks and linear attention variants, have emerged as potential alternative language models to Transformers. While efficient, SSMs struggle with tasks requiring in-context retrieval, such as text copying and associative recall, limiting their usefulness in practical settings. Prior work on how to meet this challenge has focused on the internal model architecture and not investigated the role of the training procedure. This paper proposes a new training procedure that strongly improves the performance of SSMs on retrieval-intensive tasks. This novel pre-training procedure combines a bidirectional processing of the input with dynamic mixtures of pre-training objectives to improve the utilization of the SSM's fixed-size state. Our experimental evaluations show that Birdie significantly improves performance on retrieval-intensive tasks that challenge current SSMs, such as phone book lookup, long paragraph question-answering, and infilling tasks. Our findings offer insights into a new direction to advance the training of SSMs to close the performance gap with Transformers.</li>
</ul>

<h3>Title: Identify Backdoored Model in Federated Learning via Individual Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Xu, Zikai Zhang, Rui Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01040">https://arxiv.org/abs/2411.01040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01040">https://arxiv.org/pdf/2411.01040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01040]] Identify Backdoored Model in Federated Learning via Individual Unlearning(https://arxiv.org/abs/2411.01040)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal, federate</a></li>
<li><strong>Abstract: </strong>Backdoor attacks present a significant threat to the robustness of Federated Learning (FL) due to their stealth and effectiveness. They maintain both the main task of the FL system and the backdoor task simultaneously, causing malicious models to appear statistically similar to benign ones, which enables them to evade detection by existing defense methods. We find that malicious parameters in backdoored models are inactive on the main task, resulting in a significantly large empirical loss during the machine unlearning process on clean inputs. Inspired by this, we propose MASA, a method that utilizes individual unlearning on local models to identify malicious models in FL. To improve the performance of MASA in challenging non-independent and identically distributed (non-IID) settings, we design pre-unlearning model fusion that integrates local models with knowledge learned from other datasets to mitigate the divergence in their unlearning behaviors caused by the non-IID data distributions of clients. Additionally, we propose a new anomaly detection metric with minimal hyperparameters to filter out malicious models efficiently. Extensive experiments on IID and non-IID datasets across six different attacks validate the effectiveness of MASA. To the best of our knowledge, this is the first work to leverage machine unlearning to identify malicious models in FL. Code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Towards Robust Text Classification: Mitigating Spurious Correlations with Causal Learning</h3>
<ul>
<li><strong>Authors: </strong>Yuqing Zhou, Ziwei Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01045">https://arxiv.org/abs/2411.01045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01045">https://arxiv.org/pdf/2411.01045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01045]] Towards Robust Text Classification: Mitigating Spurious Correlations with Causal Learning(https://arxiv.org/abs/2411.01045)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In text classification tasks, models often rely on spurious correlations for predictions, incorrectly associating irrelevant features with the target labels. This issue limits the robustness and generalization of models, especially when faced with out-of-distribution data where such spurious correlations no longer hold. To address this challenge, we propose the Causally Calibrated Robust Classifier (CCR), which aims to reduce models' reliance on spurious correlations and improve model robustness. Our approach integrates a causal feature selection method based on counterfactual reasoning, along with an unbiased inverse propensity weighting (IPW) loss function. By focusing on selecting causal features, we ensure that the model relies less on spurious features during prediction. We theoretically justify our approach and empirically show that CCR achieves state-of-the-art performance among methods without group labels, and in some cases, it can compete with the models that utilize group labels.</li>
</ul>

<h3>Title: MultiDepth: Multi-Sample Priors for Refining Monocular Metric Depth Estimations in Indoor Scenes</h3>
<ul>
<li><strong>Authors: </strong>Sanghyun Byun, Jacob Song, Woo Seong Chung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01048">https://arxiv.org/abs/2411.01048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01048">https://arxiv.org/pdf/2411.01048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01048]] MultiDepth: Multi-Sample Priors for Refining Monocular Metric Depth Estimations in Indoor Scenes(https://arxiv.org/abs/2411.01048)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Monocular metric depth estimation (MMDE) is a crucial task to solve for indoor scene reconstruction on edge devices. Despite this importance, existing models are sensitive to factors such as boundary frequency of objects in the scene and scene complexity, failing to fully capture many indoor scenes. In this work, we propose to close this gap through the task of monocular metric depth refinement (MMDR) by leveraging state-of-the-art MMDE models. MultiDepth proposes a solution by taking samples of the image along with the initial depth map prediction made by a pre-trained MMDE model. Compared to existing iterative depth refinement techniques, MultiDepth does not employ normal map prediction as part of its architecture, effectively lowering the model size and computation overhead while outputting impactful changes from refining iterations. MultiDepth implements a lightweight encoder-decoder architecture for the refinement network, processing multiple samples from the given image, including segmentation masking. We evaluate MultiDepth on four datasets and compare them to state-of-the-art methods to demonstrate its effective refinement with minimal overhead, displaying accuracy improvement upward of 45%.</li>
</ul>

<h3>Title: BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks</h3>
<ul>
<li><strong>Authors: </strong>Sushilkumar Yadav, Irem Bor-Yaliniz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01050">https://arxiv.org/abs/2411.01050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01050">https://arxiv.org/pdf/2411.01050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01050]] BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks(https://arxiv.org/abs/2411.01050)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a transformative approach in healthcare, enabling collaborative model training across decentralized data sources while preserving user privacy. However, performance of FL rapidly degrades in practical scenarios due to the inherent bias in non Independent and Identically distributed (non-IID) data among participating clients, which poses significant challenges to model accuracy and generalization. Therefore, we propose the Bias-Aware Client Selection Algorithm (BACSA), which detects user bias and strategically selects clients based on their bias profiles. In addition, the proposed algorithm considers privacy preservation, fairness and constraints of wireless network environments, making it suitable for sensitive healthcare applications where Quality of Service (QoS), privacy and security are paramount. Our approach begins with a novel method for detecting user bias by analyzing model parameters and correlating them with the distribution of class-specific data samples. We then formulate a mixed-integer non-linear client selection problem leveraging the detected bias, alongside wireless network constraints, to optimize FL performance. We demonstrate that BACSA improves convergence and accuracy, compared to existing benchmarks, through evaluations on various data distributions, including Dirichlet and class-constrained scenarios. Additionally, we explore the trade-offs between accuracy, fairness, and network constraints, indicating the adaptability and robustness of BACSA to address diverse healthcare applications.</li>
</ul>

<h3>Title: Explainable Spatio-Temporal GCNNs for Irregular Multivariate Time Series: Architecture and Application to ICU Patient Data</h3>
<ul>
<li><strong>Authors: </strong>Óscar Escudero-Arnanz, Cristina Soguero-Ruiz, Antonio G. Marques</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01070">https://arxiv.org/abs/2411.01070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01070">https://arxiv.org/pdf/2411.01070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01070]] Explainable Spatio-Temporal GCNNs for Irregular Multivariate Time Series: Architecture and Application to ICU Patient Data(https://arxiv.org/abs/2411.01070)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>In this paper, we present XST-GCNN (eXplainable Spatio-Temporal Graph Convolutional Neural Network), a novel architecture for processing heterogeneous and irregular Multivariate Time Series (MTS) data. Our approach captures temporal and feature dependencies within a unified spatio-temporal pipeline by leveraging a GCNN that uses a spatio-temporal graph aimed at optimizing predictive accuracy and interoperability. For graph estimation, we introduce techniques, including one based on the (heterogeneous) Gower distance. Once estimated, we propose two methods for graph construction: one based on the Cartesian product, treating temporal instants homogeneously, and another spatio-temporal approach with distinct graphs per time step. We also propose two GCNN architectures: a standard GCNN with a normalized adjacency matrix and a higher-order polynomial GCNN. In addition to accuracy, we emphasize explainability by designing an inherently interpretable model and performing a thorough interpretability analysis, identifying key feature-time combinations that drive predictions. We evaluate XST-GCNN using real-world Electronic Health Record data from University Hospital of Fuenlabrada to predict Multidrug Resistance (MDR) in ICU patients, a critical healthcare challenge linked to high mortality and complex treatments. Our architecture outperforms traditional models, achieving a mean ROC-AUC score of 81.03 +- 2.43. Furthermore, the interpretability analysis provides actionable insights into clinical factors driving MDR predictions, enhancing model transparency. This work sets a benchmark for tackling complex inference tasks with heterogeneous MTS, offering a versatile, interpretable solution for real-world applications.</li>
</ul>

<h3>Title: AttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs</h3>
<ul>
<li><strong>Authors: </strong>Varun Badrinath Krishna</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01073">https://arxiv.org/abs/2411.01073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01073">https://arxiv.org/pdf/2411.01073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01073]] AttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs(https://arxiv.org/abs/2411.01073)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) on specialized domain datasets has shown improved performance when large language models (LLMs) are fine-tuned for generating responses to user queries. In this study, we develop a cybersecurity question-answering (Q\&A) dataset, called AttackQA, and employ it to build a RAG-based Q\&A system designed for analysts in security operations centers. The dataset comprises 25,335 Q\&A pairs, accompanied by rationales to facilitate fine-tuning and evaluation. 80\% of the dataset was generated with help of a lightweight open-source LLM (LLama 3 8B), which produced over 1100 tokens per second with full 16-bit precision on SambaNova System's SN40L specialized hardware. To ensure dataset quality, we fine-tuned LLama 3 70B to detect and reject low-quality Q\&A pairs. In using the dataset for RAG, we demonstrate that fine-tuning open-source embeddings and LLMs can yield superior accuracy compared to OpenAI's state-of-the-art proprietary embedding and LLM (GPT-4o). Furthermore, we use Llama 3.1 405B as a judge to evaluate answer correctness, enabling the creation of a fully open-source, high-speed RAG and evaluation pipeline with a benchmark for model accuracy.</li>
</ul>

<h3>Title: Privacy Risks of Speculative Decoding in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiankun Wei, Abdulrahman Abdulrazzag, Tianchen Zhang, Adel Muursepp, Gururaj Saileshwar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01076">https://arxiv.org/abs/2411.01076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01076">https://arxiv.org/pdf/2411.01076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01076]] Privacy Risks of Speculative Decoding in Large Language Models(https://arxiv.org/abs/2411.01076)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding in large language models (LLMs) accelerates token generation by speculatively predicting multiple tokens cheaply and verifying them in parallel, and has been widely deployed. In this paper, we provide the first study demonstrating the privacy risks of speculative decoding. We observe that input-dependent patterns of correct and incorrect predictions can be leaked out to an adversary monitoring token generation times and packet sizes, leading to privacy breaches. By observing the pattern of correctly and incorrectly speculated tokens, we show that a malicious adversary can fingerprint queries and learn private user inputs with more than $90\%$ accuracy across three different speculative decoding techniques - BiLD (almost $100\%$ accuracy), LADE (up to $92\%$ accuracy), and REST (up to $95\%$ accuracy). We show that an adversary can also leak out confidential intellectual property used to design these techniques, such as data from data-stores used for prediction (in REST) at a rate of more than $25$ tokens per second, or even hyper-parameters used for prediction (in LADE). We also discuss mitigation strategies, such as aggregating tokens across multiple iterations and padding packets with additional bytes, to avoid such privacy or confidentiality breaches.</li>
</ul>

<h3>Title: Emoji Attack: A Method for Misleading Judge LLMs in Safety Risk Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhipeng Wei, Yuqi Liu, N. Benjamin Erichson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01077">https://arxiv.org/abs/2411.01077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01077">https://arxiv.org/pdf/2411.01077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01077]] Emoji Attack: A Method for Misleading Judge LLMs in Safety Risk Detection(https://arxiv.org/abs/2411.01077)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Jailbreaking attacks show how Large Language Models (LLMs) can be tricked into generating harmful outputs using malicious prompts. To prevent these attacks, other LLMs are often used as judges to evaluate the harmfulness of the generated content. However, relying on LLMs as judges can introduce biases into the detection process, which in turn compromises the effectiveness of the evaluation. In this paper, we show that Judge LLMs, like other LLMs, are also affected by token segmentation bias. This bias occurs when tokens are split into smaller sub-tokens, altering their embeddings. This makes it harder for the model to detect harmful content. Specifically, this bias can cause sub-tokens to differ significantly from the original token in the embedding space, leading to incorrect "safe" predictions for harmful content. To exploit this bias in Judge LLMs, we introduce the Emoji Attack -- a method that places emojis within tokens to increase the embedding differences between sub-tokens and their originals. These emojis create new tokens that further distort the token embeddings, exacerbating the bias. To counter the Emoji Attack, we design prompts that help LLMs filter out unusual characters. However, this defense can still be bypassed by using a mix of emojis and other characters. The Emoji Attack can also be combined with existing jailbreaking prompts using few-shot learning, which enables LLMs to generate harmful responses with emojis. These responses are often mistakenly labeled as "safe" by Judge LLMs, allowing the attack to slip through. Our experiments with six state-of-the-art Judge LLMs show that the Emoji Attack allows 25\% of harmful responses to bypass detection by Llama Guard and Llama Guard 2, and up to 75\% by ShieldLM. These results highlight the need for stronger Judge LLMs to address this vulnerability.</li>
</ul>

<h3>Title: Plentiful Jailbreaks with String Compositions</h3>
<ul>
<li><strong>Authors: </strong>Brian R.Y. Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01084">https://arxiv.org/abs/2411.01084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01084">https://arxiv.org/pdf/2411.01084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01084]] Plentiful Jailbreaks with String Compositions(https://arxiv.org/abs/2411.01084)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) remain vulnerable to a slew of adversarial attacks and jailbreaking methods. One common approach employed by white-hat attackers, or \textit{red-teamers}, is to process model inputs and outputs using string-level obfuscations, which can include leetspeak, rotary ciphers, Base64, ASCII, and more. Our work extends these encoding-based attacks by unifying them in a framework of invertible string transformations. With invertibility, we can devise arbitrary \textit{string compositions}, defined as sequences of transformations, that we can encode and decode end-to-end programmatically. We devise a automated best-of-n attack that samples from a combinatorially large number of string compositions. Our jailbreaks obtain competitive attack success rates on several leading frontier models when evaluated on HarmBench, highlighting that encoding-based attacks remain a persistent vulnerability even in advanced LLMs.</li>
</ul>

<h3>Title: TabVer: Tabular Fact Verification with Natural Logic</h3>
<ul>
<li><strong>Authors: </strong>Rami Aly, Andreas Vlachos</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01093">https://arxiv.org/abs/2411.01093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01093">https://arxiv.org/pdf/2411.01093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01093]] TabVer: Tabular Fact Verification with Natural Logic(https://arxiv.org/abs/2411.01093)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fact verification on tabular evidence incentivises the use of symbolic reasoning models where a logical form is constructed (e.g. a LISP-style program), providing greater verifiability than fully neural approaches. However, these systems typically rely on well-formed tables, restricting their use in many scenarios. An emerging symbolic reasoning paradigm for textual evidence focuses on natural logic inference, which constructs proofs by modelling set-theoretic relations between a claim and its evidence in natural language. This approach provides flexibility and transparency but is less compatible with tabular evidence since the relations do not extend to arithmetic functions. We propose a set-theoretic interpretation of numerals and arithmetic functions in the context of natural logic, enabling the integration of arithmetic expressions in deterministic proofs. We leverage large language models to generate arithmetic expressions by generating questions about salient parts of a claim which are answered by executing appropriate functions on tables. In a few-shot setting on FEVEROUS, we achieve an accuracy of 71.4, outperforming both fully neural and symbolic reasoning models by 3.4 points. When evaluated on TabFact without any further training, our method remains competitive with an accuracy lead of 0.5 points.</li>
</ul>

<h3>Title: Few-Class Arena: A Benchmark for Efficient Selection of Vision Models and Dataset Difficulty Measurement</h3>
<ul>
<li><strong>Authors: </strong>Bryan Bo Cao, Lawrence O'Gorman, Michael Coss, Shubham Jain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01099">https://arxiv.org/abs/2411.01099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01099">https://arxiv.org/pdf/2411.01099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01099]] Few-Class Arena: A Benchmark for Efficient Selection of Vision Models and Dataset Difficulty Measurement(https://arxiv.org/abs/2411.01099)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose Few-Class Arena (FCA), as a unified benchmark with focus on testing efficient image classification models for few classes. A wide variety of benchmark datasets with many classes (80-1000) have been created to assist Computer Vision architectural evolution. An increasing number of vision models are evaluated with these many-class datasets. However, real-world applications often involve substantially fewer classes of interest (2-10). This gap between many and few classes makes it difficult to predict performance of the few-class applications using models trained on the available many-class datasets. To date, little has been offered to evaluate models in this Few-Class Regime. We conduct a systematic evaluation of the ResNet family trained on ImageNet subsets from 2 to 1000 classes, and test a wide spectrum of Convolutional Neural Networks and Transformer architectures over ten datasets by using our newly proposed FCA tool. Furthermore, to aid an up-front assessment of dataset difficulty and a more efficient selection of models, we incorporate a difficulty measure as a function of class similarity. FCA offers a new tool for efficient machine learning in the Few-Class Regime, with goals ranging from a new efficient class similarity proposal, to lightweight model architecture design, to a new scaling law. FCA is user-friendly and can be easily extended to new models and datasets, facilitating future research work. Our benchmark is available at this https URL.</li>
</ul>

<h3>Title: How Effective Is Self-Consistency for Long-Context Problems?</h3>
<ul>
<li><strong>Authors: </strong>Adam Byerly, Daniel Khashabi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01101">https://arxiv.org/abs/2411.01101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01101">https://arxiv.org/pdf/2411.01101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01101]] How Effective Is Self-Consistency for Long-Context Problems?(https://arxiv.org/abs/2411.01101)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-consistency (SC) has been demonstrated to enhance the performance of large language models (LLMs) across various tasks and domains involving short content. However, does this evidence support its effectiveness for long-context problems? This study examines the role of SC in long-context scenarios, where LLMs often struggle with position bias, hindering their ability to utilize information effectively from all parts of their long input context. We examine a range of design parameters, including different models, context lengths, prompt formats, and types of datasets and tasks. Our findings demonstrate that SC, while effective for short-context problems, fundamentally fails for long-context tasks -- not only does it fail to mitigate position bias, but it can also actively degrade performance. We observe that the effectiveness of SC varies with context length and model size but remains mainly unaffected by prompt format or task type. These results provide valuable insight into the limitations of current LLMs in long-context understanding and highlight the need for more sophisticated approaches to address position bias in these models.</li>
</ul>

<h3>Title: Relax and Merge: A Simple Yet Effective Framework for Solving Fair $k$-Means and $k$-sparse Wasserstein Barycenter Problems</h3>
<ul>
<li><strong>Authors: </strong>Shihong Song, Guanlin Mo, Qingyuan Yang, Hu Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01115">https://arxiv.org/abs/2411.01115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01115">https://arxiv.org/pdf/2411.01115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01115]] Relax and Merge: A Simple Yet Effective Framework for Solving Fair $k$-Means and $k$-sparse Wasserstein Barycenter Problems(https://arxiv.org/abs/2411.01115)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The fairness of clustering algorithms has gained widespread attention across various areas, including machine learning, In this paper, we study fair $k$-means clustering in Euclidean space. Given a dataset comprising several groups, the fairness constraint requires that each cluster should contain a proportion of points from each group within specified lower and upper bounds. Due to these fairness constraints, determining the optimal locations of $k$ centers is a quite challenging task. We propose a novel ``Relax and Merge'' framework that returns a $(1+4\rho + O(\epsilon))$-approximate solution, where $\rho$ is the approximate ratio of an off-the-shelf vanilla $k$-means algorithm and $O(\epsilon)$ can be an arbitrarily small positive number. If equipped with a PTAS of $k$-means, our solution can achieve an approximation ratio of $(5+O(\epsilon))$ with only a slight violation of the fairness constraints, which improves the current state-of-the-art approximation guarantee. Furthermore, using our framework, we can also obtain a $(1+4\rho +O(\epsilon))$-approximate solution for the $k$-sparse Wasserstein Barycenter problem, which is a fundamental optimization problem in the field of optimal transport, and a $(2+6\rho)$-approximate solution for the strictly fair $k$-means clustering with no violation, both of which are better than the current state-of-the-art methods. In addition, the empirical results demonstrate that our proposed algorithm can significantly outperform baseline approaches in terms of clustering cost.</li>
</ul>

<h3>Title: Test-Time Adaptation in Point Clouds: Leveraging Sampling Variation with Weight Averaging</h3>
<ul>
<li><strong>Authors: </strong>Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, Sahar Dastani Oghani, Milad Cheraghalikhani, David Osowiech, Farzad Beizaee, Gustavo adolfo.vargas-hakim, Ismail Ben Ayed, Christian Desrosiers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01116">https://arxiv.org/abs/2411.01116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01116">https://arxiv.org/pdf/2411.01116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01116]] Test-Time Adaptation in Point Clouds: Leveraging Sampling Variation with Weight Averaging(https://arxiv.org/abs/2411.01116)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test-Time Adaptation (TTA) addresses distribution shifts during testing by adapting a pretrained model without access to source data. In this work, we propose a novel TTA approach for 3D point cloud classification, combining sampling variation with weight averaging. Our method leverages Farthest Point Sampling (FPS) and K-Nearest Neighbors (KNN) to create multiple point cloud representations, adapting the model for each variation using the TENT algorithm. The final model parameters are obtained by averaging the adapted weights, leading to improved robustness against distribution shifts. Extensive experiments on ModelNet40-C, ShapeNet-C, and ScanObjectNN-C datasets, with different backbones (Point-MAE, PointNet, DGCNN), demonstrate that our approach consistently outperforms existing methods while maintaining minimal resource overhead. The proposed method effectively enhances model generalization and stability in challenging real-world conditions.</li>
</ul>

<h3>Title: OnlineTAS: An Online Baseline for Temporal Action Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Qing Zhong, Guodong Ding, Angela Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01122">https://arxiv.org/abs/2411.01122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01122">https://arxiv.org/pdf/2411.01122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01122]] OnlineTAS: An Online Baseline for Temporal Action Segmentation(https://arxiv.org/abs/2411.01122)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Temporal context plays a significant role in temporal action segmentation. In an offline setting, the context is typically captured by the segmentation network after observing the entire sequence. However, capturing and using such context information in an online setting remains an under-explored problem. This work presents the an online framework for temporal action segmentation. At the core of the framework is an adaptive memory designed to accommodate dynamic changes in context over time, alongside a feature augmentation module that enhances the frames with the memory. In addition, we propose a post-processing approach to mitigate the severe over-segmentation in the online setting. On three common segmentation benchmarks, our approach achieves state-of-the-art performance.</li>
</ul>

<h3>Title: X-Drive: Cross-modality consistent multi-sensor data synthesis for driving scenarios</h3>
<ul>
<li><strong>Authors: </strong>Yichen Xie, Chenfeng Xu, Chensheng Peng, Shuqi Zhao, Nhat Ho, Alexander T. Pham, Mingyu Ding, Masayoshi Tomizuka, Wei Zhan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01123">https://arxiv.org/abs/2411.01123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01123">https://arxiv.org/pdf/2411.01123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01123]] X-Drive: Cross-modality consistent multi-sensor data synthesis for driving scenarios(https://arxiv.org/abs/2411.01123)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements have exploited diffusion models for the synthesis of either LiDAR point clouds or camera image data in driving scenarios. Despite their success in modeling single-modality data marginal distribution, there is an under-exploration in the mutual reliance between different modalities to describe complex driving scenes. To fill in this gap, we propose a novel framework, X-DRIVE, to model the joint distribution of point clouds and multi-view images via a dual-branch latent diffusion model architecture. Considering the distinct geometrical spaces of the two modalities, X-DRIVE conditions the synthesis of each modality on the corresponding local regions from the other modality, ensuring better alignment and realism. To further handle the spatial ambiguity during denoising, we design the cross-modality condition module based on epipolar lines to adaptively learn the cross-modality local correspondence. Besides, X-DRIVE allows for controllable generation through multi-level input conditions, including text, bounding box, image, and point clouds. Extensive results demonstrate the high-fidelity synthetic results of X-DRIVE for both point clouds and multi-view images, adhering to input conditions while ensuring reliable cross-modality consistency. Our code will be made publicly available at this https URL.</li>
</ul>

<h3>Title: Axiomatic Explainer Globalness via Optimal Transport</h3>
<ul>
<li><strong>Authors: </strong>Davin Hill, Josh Bone, Aria Masoomi, Max Torop, Jennifer Dy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01126">https://arxiv.org/abs/2411.01126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01126">https://arxiv.org/pdf/2411.01126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01126]] Axiomatic Explainer Globalness via Optimal Transport(https://arxiv.org/abs/2411.01126)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Explainability methods are often challenging to evaluate and compare. With a multitude of explainers available, practitioners must often compare and select explainers based on quantitative evaluation metrics. One particular differentiator between explainers is the diversity of explanations for a given dataset; i.e. whether all explanations are identical, unique and uniformly distributed, or somewhere between these two extremes. In this work, we define a complexity measure for explainers, globalness, which enables deeper understanding of the distribution of explanations produced by feature attribution and feature selection methods for a given dataset. We establish the axiomatic properties that any such measure should possess and prove that our proposed measure, Wasserstein Globalness, meets these criteria. We validate the utility of Wasserstein Globalness using image, tabular, and synthetic datasets, empirically showing that it both facilitates meaningful comparison between explainers and improves the selection process for explainability methods.</li>
</ul>

<h3>Title: Do LLMs Know to Respect Copyright Notice?</h3>
<ul>
<li><strong>Authors: </strong>Jialiang Xu, Shenglan Li, Zhaozhuo Xu, Denghui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01136">https://arxiv.org/abs/2411.01136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01136">https://arxiv.org/pdf/2411.01136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01136]] Do LLMs Know to Respect Copyright Notice?(https://arxiv.org/abs/2411.01136)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Prior study shows that LLMs sometimes generate content that violates copyright. In this paper, we study another important yet underexplored problem, i.e., will LLMs respect copyright information in user input, and behave accordingly? The research problem is critical, as a negative answer would imply that LLMs will become the primary facilitator and accelerator of copyright infringement behavior. We conducted a series of experiments using a diverse set of language models, user prompts, and copyrighted materials, including books, news articles, API documentation, and movie scripts. Our study offers a conservative evaluation of the extent to which language models may infringe upon copyrights when processing user input containing protected material. This research emphasizes the need for further investigation and the importance of ensuring LLMs respect copyright regulations when handling user input to prevent unauthorized use or reproduction of protected content. We also release a benchmark dataset serving as a test bed for evaluating infringement behaviors by LLMs and stress the need for future alignment.</li>
</ul>

<h3>Title: HIP: Hierarchical Point Modeling and Pre-training for Visual Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Rujiao Long, Pengfei Wang, Zhibo Yang, Cong Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01139">https://arxiv.org/abs/2411.01139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01139">https://arxiv.org/pdf/2411.01139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01139]] HIP: Hierarchical Point Modeling and Pre-training for Visual Information Extraction(https://arxiv.org/abs/2411.01139)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>End-to-end visual information extraction (VIE) aims at integrating the hierarchical subtasks of VIE, including text spotting, word grouping, and entity labeling, into a unified framework. Dealing with the gaps among the three subtasks plays a pivotal role in designing an effective VIE model. OCR-dependent methods heavily rely on offline OCR engines and inevitably suffer from OCR errors, while OCR-free methods, particularly those employing a black-box model, might produce outputs that lack interpretability or contain hallucinated content. Inspired by CenterNet, DeepSolo, and ESP, we propose HIP, which models entities as HIerarchical Points to better conform to the hierarchical nature of the end-to-end VIE task. Specifically, such hierarchical points can be flexibly encoded and subsequently decoded into desired text transcripts, centers of various regions, and categories of entities. Furthermore, we devise corresponding hierarchical pre-training strategies, categorized as image reconstruction, layout learning, and language enhancement, to reinforce the cross-modality representation of the hierarchical encoders. Quantitative experiments on public benchmarks demonstrate that HIP outperforms previous state-of-the-art methods, while qualitative results show its excellent interpretability.</li>
</ul>

<h3>Title: Privacy-Preserving Federated Learning with Differentially Private Hyperdimensional Computing</h3>
<ul>
<li><strong>Authors: </strong>Fardin Jalil Piran, Zhiling Chen, Mohsen Imani, Farhad Imani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01140">https://arxiv.org/abs/2411.01140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01140">https://arxiv.org/pdf/2411.01140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01140]] Privacy-Preserving Federated Learning with Differentially Private Hyperdimensional Computing(https://arxiv.org/abs/2411.01140)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, membership infer, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is essential for efficient data exchange in Internet of Things (IoT) environments, as it trains Machine Learning (ML) models locally and shares only model updates. However, FL is vulnerable to privacy threats like model inversion and membership inference attacks, which can expose sensitive training data. To address these privacy concerns, Differential Privacy (DP) mechanisms are often applied. Yet, adding DP noise to black-box ML models degrades performance, especially in dynamic IoT systems where continuous, lifelong FL learning accumulates excessive noise over time. To mitigate this issue, we introduce Federated HyperDimensional computing with Privacy-preserving (FedHDPrivacy), an eXplainable Artificial Intelligence (XAI) framework that combines the neuro-symbolic paradigm with DP. FedHDPrivacy carefully manages the balance between privacy and performance by theoretically tracking cumulative noise from previous rounds and adding only the necessary incremental noise to meet privacy requirements. In a real-world case study involving in-process monitoring of manufacturing machining operations, FedHDPrivacy demonstrates robust performance, outperforming standard FL frameworks-including Federated Averaging (FedAvg), Federated Stochastic Gradient Descent (FedSGD), Federated Proximal (FedProx), Federated Normalized Averaging (FedNova), and Federated Adam (FedAdam)-by up to 38%. FedHDPrivacy also shows potential for future enhancements, such as multimodal data fusion.</li>
</ul>

<h3>Title: Dictionary Insertion Prompting for Multilingual Reasoning on Multilingual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongyuan Lu, Zixuan Li, Wai Lam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01141">https://arxiv.org/abs/2411.01141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01141">https://arxiv.org/pdf/2411.01141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01141]] Dictionary Insertion Prompting for Multilingual Reasoning on Multilingual Large Language Models(https://arxiv.org/abs/2411.01141)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As current training data for Large Language Models (LLMs) are dominated by English corpus, they are English-centric and they present impressive performance on English reasoning tasks.\footnote{This paper primarily studies English-centric models, but our method could be universal by using the centric language in the dictionary for non-English-centric LLMs.} Yet, they usually suffer from lower performance in other languages. There are about 7,000 languages over the world, and many are low-resourced on English-centric LLMs. For the sake of people who primarily speak these languages, it is especially urgent to enable our LLMs in those languages. Model training is usually effective, but computationally expensive and requires experienced NLP practitioners. This paper presents a novel and simple yet effective method called \textbf{D}ictionary \textbf{I}nsertion \textbf{P}rompting (\textbf{DIP}). When providing a non-English prompt, DIP looks up a word dictionary and inserts words' English counterparts into the prompt for LLMs. It then enables better translation into English and better English model thinking steps which leads to obviously better results. We experiment with about 200 languages from FLORES-200. Since there are no adequate datasets, we use the NLLB translator to create synthetic multilingual benchmarks from the existing 4 English reasoning benchmarks such as GSM8K and AQuA. Despite the simplicity and computationally lightweight, we surprisingly found the effectiveness of DIP on math and commonsense reasoning tasks on multiple open-source and close-source LLMs.\footnote{Our dictionaries, code, and synthetic benchmarks will be open-sourced to facilitate future research.}</li>
</ul>

<h3>Title: Task-Aware Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziqing Fan, Shengchao Hu, Yuhang Zhou, Li Shen, Ya Zhang, Yanfeng Wang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01146">https://arxiv.org/abs/2411.01146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01146">https://arxiv.org/pdf/2411.01146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01146]] Task-Aware Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning(https://arxiv.org/abs/2411.01146)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The purpose of offline multi-task reinforcement learning (MTRL) is to develop a unified policy applicable to diverse tasks without the need for online environmental interaction. Recent advancements approach this through sequence modeling, leveraging the Transformer architecture's scalability and the benefits of parameter sharing to exploit task similarities. However, variations in task content and complexity pose significant challenges in policy formulation, necessitating judicious parameter sharing and management of conflicting gradients for optimal policy performance. Furthermore, identifying the optimal parameter subspace for each task often necessitates prior knowledge of the task identifier during inference, limiting applicability in real-world scenarios with variable task content and unknown current tasks. In this work, we introduce the Harmony Multi-Task Decision Transformer (HarmoDT), a novel solution designed to identify an optimal harmony subspace of parameters for each task. We formulate this as a bi-level optimization problem within a meta-learning framework, where the upper level learns masks to define the harmony subspace, while the inner level focuses on updating parameters to improve the overall performance of the unified policy. To eliminate the need for task identifiers, we further design a group-wise variant (G-HarmoDT) that clusters tasks into coherent groups based on gradient information, and utilizes a gating network to determine task identifiers during inference. Empirical evaluations across various benchmarks highlight the superiority of our approach, demonstrating its effectiveness in the multi-task context with specific improvements of 8% gain in task-provided settings, 5% in task-agnostic settings, and 10% in unseen settings.</li>
</ul>

<h3>Title: Designing a Robust Radiology Report Generation System</h3>
<ul>
<li><strong>Authors: </strong>Sonit Singh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01153">https://arxiv.org/abs/2411.01153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01153">https://arxiv.org/pdf/2411.01153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01153]] Designing a Robust Radiology Report Generation System(https://arxiv.org/abs/2411.01153)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in deep learning have enabled researchers to explore tasks at the intersection of computer vision and natural language processing, such as image captioning, visual question answering, visual dialogue, and visual language navigation. Taking inspiration from image captioning, the task of radiology report generation aims at automatically generating radiology reports by having a comprehensive understanding of medical images. However, automatically generating radiology reports from medical images is a challenging task due to the complexity, diversity, and nature of medical images. In this paper, we outline the design of a robust radiology report generation system by integrating different modules and highlighting best practices drawing upon lessons from our past work and also from relevant studies in the literature. We also discuss the impact of integrating different components to form a single integrated system. We believe that these best practices, when implemented, could improve automatic radiology report generation, augment radiologists in decision making, and expedite diagnostic workflow, in turn improve healthcare and save human lives.</li>
</ul>

<h3>Title: Supervised Score-Based Modeling by Gradient Boosting</h3>
<ul>
<li><strong>Authors: </strong>Changyuan Zhao, Hongyang Du, Guangyuan Liu, Dusit Niyato</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01159">https://arxiv.org/abs/2411.01159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01159">https://arxiv.org/pdf/2411.01159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01159]] Supervised Score-Based Modeling by Gradient Boosting(https://arxiv.org/abs/2411.01159)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Score-based generative models can effectively learn the distribution of data by estimating the gradient of the distribution. Due to the multi-step denoising characteristic, researchers have recently considered combining score-based generative models with the gradient boosting algorithm, a multi-step supervised learning algorithm, to solve supervised learning tasks. However, existing generative model algorithms are often limited by the stochastic nature of the models and the long inference time, impacting prediction performances. Therefore, we propose a Supervised Score-based Model (SSM), which can be viewed as a gradient boosting algorithm combining score matching. We provide a theoretical analysis of learning and sampling for SSM to balance inference time and prediction accuracy. Via the ablation experiment in selected examples, we demonstrate the outstanding performances of the proposed techniques. Additionally, we compare our model with other probabilistic models, including Natural Gradient Boosting (NGboost), Classification and Regression Diffusion Models (CARD), Diffusion Boosted Trees (DBT), and Bayesian neural network-based models. The experimental results show that our model outperforms existing models in both accuracy and inference time.</li>
</ul>

<h3>Title: Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization</h3>
<ul>
<li><strong>Authors: </strong>Shengchao Hu, Wanru Zhao, Weixiong Lin, Li Shen, Ya Zhang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01168">https://arxiv.org/abs/2411.01168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01168">https://arxiv.org/pdf/2411.01168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01168]] Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization(https://arxiv.org/abs/2411.01168)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) methods harness previous experiences to derive an optimal policy, forming the foundation for pre-trained large-scale models (PLMs). When encountering tasks not seen before, PLMs often utilize several expert trajectories as prompts to expedite their adaptation to new requirements. Though a range of prompt-tuning methods have been proposed to enhance the quality of prompts, these methods often face optimization restrictions due to prompt initialization, which can significantly constrain the exploration domain and potentially lead to suboptimal solutions. To eliminate the reliance on the initial prompt, we shift our perspective towards the generative model, framing the prompt-tuning process as a form of conditional generative modeling, where prompts are generated from random noise. Our innovation, the Prompt Diffuser, leverages a conditional diffusion model to produce prompts of exceptional quality. Central to our framework is the approach to trajectory reconstruction and the meticulous integration of downstream task guidance during the training phase. Further experimental results underscore the potency of the Prompt Diffuser as a robust and effective tool for the prompt-tuning process, demonstrating strong performance in the meta-RL tasks.</li>
</ul>

<h3>Title: Bi-Level Graph Structure Learning for Next POI Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Liang Wang, Shu Wu, Qiang Liu, Yanqiao Zhu, Xiang Tao, Mengdi Zhang, Liang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01169">https://arxiv.org/abs/2411.01169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01169">https://arxiv.org/pdf/2411.01169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01169]] Bi-Level Graph Structure Learning for Next POI Recommendation(https://arxiv.org/abs/2411.01169)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Next point-of-interest (POI) recommendation aims to predict a user's next destination based on sequential check-in history and a set of POI candidates. Graph neural networks (GNNs) have demonstrated a remarkable capability in this endeavor by exploiting the extensive global collaborative signals present among POIs. However, most of the existing graph-based approaches construct graph structures based on pre-defined heuristics, failing to consider inherent hierarchical structures of POI features such as geographical locations and visiting peaks, or suffering from noisy and incomplete structures in graphs. To address the aforementioned issues, this paper presents a novel Bi-level Graph Structure Learning (BiGSL) for next POI recommendation. BiGSL first learns a hierarchical graph structure to capture the fine-to-coarse connectivity between POIs and prototypes, and then uses a pairwise learning module to dynamically infer relationships between POI pairs and prototype pairs. Based on the learned bi-level graphs, our model then employs a multi-relational graph network that considers both POI- and prototype-level neighbors, resulting in improved POI representations. Our bi-level structure learning scheme is more robust to data noise and incompleteness, and improves the exploration ability for recommendation by alleviating sparsity issues. Experimental results on three real-world datasets demonstrate the superiority of our model over existing state-of-the-art methods, with a significant improvement in recommendation accuracy and exploration performance.</li>
</ul>

<h3>Title: Fast and Memory-Efficient Video Diffusion Using Streamlined Inference</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhan, Yushu Wu, Yifan Gong, Zichong Meng, Zhenglun Kong, Changdi Yang, Geng Yuan, Pu Zhao, Wei Niu, Yanzhi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01171">https://arxiv.org/abs/2411.01171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01171">https://arxiv.org/pdf/2411.01171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01171]] Fast and Memory-Efficient Video Diffusion Using Streamlined Inference(https://arxiv.org/abs/2411.01171)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid progress in artificial intelligence-generated content (AIGC), especially with diffusion models, has significantly advanced development of high-quality video generation. However, current video diffusion models exhibit demanding computational requirements and high peak memory usage, especially for generating longer and higher-resolution videos. These limitations greatly hinder the practical application of video diffusion models on standard hardware platforms. To tackle this issue, we present a novel, training-free framework named Streamlined Inference, which leverages the temporal and spatial properties of video diffusion models. Our approach integrates three core components: Feature Slicer, Operator Grouping, and Step Rehash. Specifically, Feature Slicer effectively partitions input features into sub-features and Operator Grouping processes each sub-feature with a group of consecutive operators, resulting in significant memory reduction without sacrificing the quality or speed. Step Rehash further exploits the similarity between adjacent steps in diffusion, and accelerates inference through skipping unnecessary steps. Extensive experiments demonstrate that our approach significantly reduces peak memory and computational overhead, making it feasible to generate high-quality videos on a single consumer GPU (e.g., reducing peak memory of AnimateDiff from 42GB to 11GB, featuring faster inference on 2080Ti).</li>
</ul>

<h3>Title: CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research</h3>
<ul>
<li><strong>Authors: </strong>Sian-Yao Huang, Cheng-Lin Yang, Che-Yu Lin, Chun-Ying Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01176">https://arxiv.org/abs/2411.01176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01176">https://arxiv.org/pdf/2411.01176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01176]] CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research(https://arxiv.org/abs/2411.01176)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>This research addresses command-line embedding in cybersecurity, a field obstructed by the lack of comprehensive datasets due to privacy and regulation concerns. We propose the first dataset of similar command lines, named CyPHER, for training and unbiased evaluation. The training set is generated using a set of large language models (LLMs) comprising 28,520 similar command-line pairs. Our testing dataset consists of 2,807 similar command-line pairs sourced from authentic command-line data. In addition, we propose a command-line embedding model named CmdCaliper, enabling the computation of semantic similarity with command lines. Performance evaluations demonstrate that the smallest version of CmdCaliper (30 million parameters) suppresses state-of-the-art (SOTA) sentence embedding models with ten times more parameters across various tasks (e.g., malicious command-line detection and similar command-line retrieval). Our study explores the feasibility of data generation using LLMs in the cybersecurity domain. Furthermore, we release our proposed command-line dataset, embedding models' weights and all program codes to the public. This advancement paves the way for more effective command-line embedding for future researchers.</li>
</ul>

<h3>Title: Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Wonguk Cho, Seokeon Choi, Debasmit Das, Matthias Reisser, Taesup Kim, Sungrack Yun, Fatih Porikli</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01179">https://arxiv.org/abs/2411.01179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01179">https://arxiv.org/pdf/2411.01179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01179]] Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models(https://arxiv.org/abs/2411.01179)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in text-to-image diffusion models have enabled the personalization of these models to generate custom images from textual prompts. This paper presents an efficient LoRA-based personalization approach for on-device subject-driven generation, where pre-trained diffusion models are fine-tuned with user-specific data on resource-constrained devices. Our method, termed Hollowed Net, enhances memory efficiency during fine-tuning by modifying the architecture of a diffusion U-Net to temporarily remove a fraction of its deep layers, creating a hollowed structure. This approach directly addresses on-device memory constraints and substantially reduces GPU memory requirements for training, in contrast to previous methods that primarily focus on minimizing training steps and reducing the number of parameters to update. Additionally, the personalized Hollowed Net can be transferred back into the original U-Net, enabling inference without additional memory overhead. Quantitative and qualitative analyses demonstrate that our approach not only reduces training memory to levels as low as those required for inference but also maintains or improves personalization performance compared to existing methods.</li>
</ul>

<h3>Title: Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Gagan Bhatia, El Moatez Billah Nagoudi, Abdellah El Mekki, Fakhraddin Alwajih, Muhammad Abdul-Mageed</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01192">https://arxiv.org/abs/2411.01192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01192">https://arxiv.org/pdf/2411.01192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01192]] Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks(https://arxiv.org/abs/2411.01192)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce Swan, a family of embedding models centred around the Arabic language, addressing both small-scale and large-scale use cases. Swan includes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on ArMistral, a pretrained Arabic large language model. To evaluate these models, we propose ArabicMTEB, a comprehensive benchmark suite that assesses cross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text embedding performance, covering eight diverse tasks and spanning 94 datasets. Swan-Large achieves state-of-the-art results, outperforming Multilingual-E5-large in most Arabic tasks, while the Swan-Small consistently surpasses Multilingual-E5 base. Our extensive evaluations demonstrate that Swan models are both dialectally and culturally aware, excelling across various Arabic domains while offering significant monetary efficiency. This work significantly advances the field of Arabic language modelling and provides valuable resources for future research and applications in Arabic natural language processing. Our models and benchmark will be made publicly accessible for research.</li>
</ul>

<h3>Title: Transfer Learning for Finetuning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tobias Strangmann, Lennart Purucker, Jörg K.H. Franke, Ivo Rapant, Fabio Ferreira, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01195">https://arxiv.org/abs/2411.01195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01195">https://arxiv.org/pdf/2411.01195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01195]] Transfer Learning for Finetuning Large Language Models(https://arxiv.org/abs/2411.01195)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the landscape of large language models expands, efficiently finetuning for specific tasks becomes increasingly crucial. At the same time, the landscape of parameter-efficient finetuning methods rapidly expands. Consequently, practitioners face a multitude of complex choices when searching for an optimal finetuning pipeline for large language models. To reduce the complexity for practitioners, we investigate transfer learning for finetuning large language models and aim to transfer knowledge about configurations from related finetuning tasks to a new task. In this work, we transfer learn finetuning by meta-learning performance and cost surrogate models for grey-box meta-optimization from a new meta-dataset. Counter-intuitively, we propose to rely only on transfer learning for new datasets. Thus, we do not use task-specific Bayesian optimization but prioritize knowledge transferred from related tasks over task-specific feedback. We evaluate our method on eight synthetic question-answer datasets and a meta-dataset consisting of 1,800 runs of finetuning Microsoft's Phi-3. Our transfer learning is superior to zero-shot, default finetuning, and meta-optimization baselines. Our results demonstrate the transferability of finetuning to adapt large language models more effectively.</li>
</ul>

<h3>Title: XNB: Explainable Class-Specific NaIve-Bayes Classifier</h3>
<ul>
<li><strong>Authors: </strong>Jesus S. Aguilar-Ruiz, Cayetano Romero, Andrea Cicconardi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01203">https://arxiv.org/abs/2411.01203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01203">https://arxiv.org/pdf/2411.01203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01203]] XNB: Explainable Class-Specific NaIve-Bayes Classifier(https://arxiv.org/abs/2411.01203)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>In today's data-intensive landscape, where high-dimensional datasets are increasingly common, reducing the number of input features is essential to prevent overfitting and improve model accuracy. Despite numerous efforts to tackle dimensionality reduction, most approaches apply a universal set of features across all classes, potentially missing the unique characteristics of individual classes. This paper presents the Explainable Class-Specific Naive Bayes (XNB) classifier, which introduces two critical innovations: 1) the use of Kernel Density Estimation to calculate posterior probabilities, allowing for a more accurate and flexible estimation process, and 2) the selection of class-specific feature subsets, ensuring that only the most relevant variables for each class are utilized. Extensive empirical analysis on high-dimensional genomic datasets shows that XNB matches the classification performance of traditional Naive Bayes while drastically improving model interpretability. By isolating the most relevant features for each class, XNB not only reduces the feature set to a minimal, distinct subset for each class but also provides deeper insights into how the model makes predictions. This approach offers significant advantages in fields where both precision and explainability are critical.</li>
</ul>

<h3>Title: Class-specific feature selection for classification explainability</h3>
<ul>
<li><strong>Authors: </strong>Jesus S. Aguilar-Ruiz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01204">https://arxiv.org/abs/2411.01204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01204">https://arxiv.org/pdf/2411.01204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01204]] Class-specific feature selection for classification explainability(https://arxiv.org/abs/2411.01204)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Feature Selection techniques aim at finding a relevant subset of features that perform equally or better than the original set of features at explaining the behavior of data. Typically, features are extracted from feature ranking or subset selection techniques, and the performance is measured by classification or regression tasks. However, while selected features may not have equal importance for the task, they do have equal importance for each class. This work first introduces a comprehensive review of the concept of class-specific, with a focus on feature selection and classification. The fundamental idea of the class-specific concept resides in the understanding that the significance of each feature can vary from one class to another. This contrasts with the traditional class-independent approach, which evaluates the importance of attributes collectively for all classes. For example, in tumor prediction scenarios, each type of tumor may be associated with a distinct subset of relevant features. These features possess significant discriminatory power, enabling the differentiation of one tumor type from others. This class-specific perspective offers a more effective approach to classification tasks by recognizing and leveraging the unique characteristics of each class. Secondly, classification schemes from one-versus-all and one-versus-each strategies are described, and a novel deep one-versus-each strategy is introduced, which offers advantages from the point of view of explainability (feature selection) and decomposability (classification). Thirdly, a novel class-specific relevance matrix is presented, from which some more sophisticated classification schemes can be derived, such as the three-layer class-specific scheme. The potential for further advancements is wide and will open new horizons for exploring novel research directions in multiclass hyperdimensional contexts.</li>
</ul>

<h3>Title: PRIMO: Progressive Induction for Multi-hop Open Rule Generation</h3>
<ul>
<li><strong>Authors: </strong>Jianyu Liu, Sheng Bi, Guilin Qi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01205">https://arxiv.org/abs/2411.01205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01205">https://arxiv.org/pdf/2411.01205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01205]] PRIMO: Progressive Induction for Multi-hop Open Rule Generation(https://arxiv.org/abs/2411.01205)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Open rule refer to the implication from premise atoms to hypothesis atoms, which captures various relations between instances in the real world. Injecting open rule knowledge into the machine helps to improve the performance of downstream tasks such as dialogue and relation extraction. Existing approaches focus on single-hop open rule generation, ignoring multi-hop scenarios, leading to logical inconsistencies between premise and hypothesis atoms, as well as semantic duplication of generated rule atoms. To address these issues, we propose a progressive multi-stage open rule generation method called PRIMO. We introduce ontology information during the rule generation stage to reduce ambiguity and improve rule accuracy. PRIMO constructs a multi-stage structure consisting of generation, extraction, and ranking modules to fully leverage the latent knowledge within the language model across multiple dimensions. Furthermore, we employ reinforcement learning from human feedback to further optimize model, enhancing the model's understanding of commonsense knowledge. Experiments show that compared to baseline models, PRIMO significantly improves rule quality and diversity while reducing the repetition rate of rule atoms.</li>
</ul>

<h3>Title: Infinite-Resolution Integral Noise Warping for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yitong Deng, Winnie Lin, Lingxiao Li, Dmitriy Smirnov, Ryan Burgert, Ning Yu, Vincent Dedun, Mohammad H. Taghavi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01212">https://arxiv.org/abs/2411.01212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01212">https://arxiv.org/pdf/2411.01212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01212]] Infinite-Resolution Integral Noise Warping for Diffusion Models(https://arxiv.org/abs/2411.01212)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Adapting pretrained image-based diffusion models to generate temporally consistent videos has become an impactful generative modeling research direction. Training-free noise-space manipulation has proven to be an effective technique, where the challenge is to preserve the Gaussian white noise distribution while adding in temporal consistency. Recently, Chang et al. (2024) formulated this problem using an integral noise representation with distribution-preserving guarantees, and proposed an upsampling-based algorithm to compute it. However, while their mathematical formulation is advantageous, the algorithm incurs a high computational cost. Through analyzing the limiting-case behavior of their algorithm as the upsampling resolution goes to infinity, we develop an alternative algorithm that, by gathering increments of multiple Brownian bridges, achieves their infinite-resolution accuracy while simultaneously reducing the computational cost by orders of magnitude. We prove and experimentally validate our theoretical claims, and demonstrate our method's effectiveness in real-world applications. We further show that our method readily extends to the 3-dimensional space.</li>
</ul>

<h3>Title: One Arrow, Many Targets: Probing LLMs for Multi-Attribute Controllable Text Summarization</h3>
<ul>
<li><strong>Authors: </strong>Tathagato Roy, Rahul Mishra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01213">https://arxiv.org/abs/2411.01213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01213">https://arxiv.org/pdf/2411.01213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01213]] One Arrow, Many Targets: Probing LLMs for Multi-Attribute Controllable Text Summarization(https://arxiv.org/abs/2411.01213)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text summarization is a well-established task within the natural language processing (NLP) community. However, the focus on controllable summarization tailored to user requirements is gaining traction only recently. While several efforts explore controllability in text summarization, the investigation of Multi-Attribute Controllable Summarization (MACS) remains limited. This work addresses this gap by examining the MACS task through the lens of large language models (LLMs), using various learning paradigms, particularly low-rank adapters. We experiment with different popular adapter fine-tuning strategies to assess the effectiveness of the resulting models in retaining cues and patterns associated with multiple controllable attributes. Additionally, we propose and evaluate a novel hierarchical adapter fusion technique to integrate learnings from two distinct controllable attributes. Subsquently, we present our findings, discuss the challenges encountered, and suggest potential avenues for advancing the MACS task.</li>
</ul>

<h3>Title: Enhancing Neural Network Interpretability with Feature-Aligned Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Luke Marks, Alisdair Paren, David Krueger, Fazl Barez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01220">https://arxiv.org/abs/2411.01220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01220">https://arxiv.org/pdf/2411.01220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01220]] Enhancing Neural Network Interpretability with Feature-Aligned Sparse Autoencoders(https://arxiv.org/abs/2411.01220)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Sparse Autoencoders (SAEs) have shown promise in improving the interpretability of neural network activations, but can learn features that are not features of the input, limiting their effectiveness. We propose \textsc{Mutual Feature Regularization} \textbf{(MFR)}, a regularization technique for improving feature learning by encouraging SAEs trained in parallel to learn similar features. We motivate \textsc{MFR} by showing that features learned by multiple SAEs are more likely to correlate with features of the input. By training on synthetic data with known features of the input, we show that \textsc{MFR} can help SAEs learn those features, as we can directly compare the features learned by the SAE with the input features for the synthetic data. We then scale \textsc{MFR} to SAEs that are trained to denoise electroencephalography (EEG) data and SAEs that are trained to reconstruct GPT-2 Small activations. We show that \textsc{MFR} can improve the reconstruction loss of SAEs by up to 21.21\% on GPT-2 Small, and 6.67\% on EEG data. Our results suggest that the similarity between features learned by different SAEs can be leveraged to improve SAE training, thereby enhancing performance and the usefulness of SAEs for model interpretability.</li>
</ul>

<h3>Title: $B^4$: A Black-Box Scrubbing Attack on LLM Watermarks</h3>
<ul>
<li><strong>Authors: </strong>Baizhou Huang, Xiao Pu, Xiaojun Wan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01222">https://arxiv.org/abs/2411.01222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01222">https://arxiv.org/pdf/2411.01222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01222]] $B^4$: A Black-Box Scrubbing Attack on LLM Watermarks(https://arxiv.org/abs/2411.01222)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Watermarking has emerged as a prominent technique for LLM-generated content detection by embedding imperceptible patterns. Despite supreme performance, its robustness against adversarial attacks remains underexplored. Previous work typically considers a grey-box attack setting, where the specific type of watermark is already known. Some even necessitates knowledge about hyperparameters of the watermarking method. Such prerequisites are unattainable in real-world scenarios. Targeting at a more realistic black-box threat model with fewer assumptions, we here propose $\mathcal{B}^4$, a black-box scrubbing attack on watermarks. Specifically, we formulate the watermark scrubbing attack as a constrained optimization problem by capturing its objectives with two distributions, a Watermark Distribution and a Fidelity Distribution. This optimization problem can be approximately solved using two proxy distributions. Experimental results across 12 different settings demonstrate the superior performance of $\mathcal{B}^4$ compared with other baselines.</li>
</ul>

<h3>Title: MonoPlane: Exploiting Monocular Geometric Cues for Generalizable 3D Plane Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Wang Zhao, Jiachen Liu, Sheng Zhang, Yishu Li, Sili Chen, Sharon X Huang, Yong-Jin Liu, Hengkai Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01226">https://arxiv.org/abs/2411.01226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01226">https://arxiv.org/pdf/2411.01226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01226]] MonoPlane: Exploiting Monocular Geometric Cues for Generalizable 3D Plane Reconstruction(https://arxiv.org/abs/2411.01226)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a generalizable 3D plane detection and reconstruction framework named MonoPlane. Unlike previous robust estimator-based works (which require multiple images or RGB-D input) and learning-based works (which suffer from domain shift), MonoPlane combines the best of two worlds and establishes a plane reconstruction pipeline based on monocular geometric cues, resulting in accurate, robust and scalable 3D plane detection and reconstruction in the wild. Specifically, we first leverage large-scale pre-trained neural networks to obtain the depth and surface normals from a single image. These monocular geometric cues are then incorporated into a proximity-guided RANSAC framework to sequentially fit each plane instance. We exploit effective 3D point proximity and model such proximity via a graph within RANSAC to guide the plane fitting from noisy monocular depths, followed by image-level multi-plane joint optimization to improve the consistency among all plane instances. We further design a simple but effective pipeline to extend this single-view solution to sparse-view 3D plane reconstruction. Extensive experiments on a list of datasets demonstrate our superior zero-shot generalizability over baselines, achieving state-of-the-art plane reconstruction performance in a transferring setting. Our code is available at this https URL .</li>
</ul>

<h3>Title: Strengthening DeFi Security: A Static Analysis Approach to Flash Loan Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Ka Wai Wu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01230">https://arxiv.org/abs/2411.01230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01230">https://arxiv.org/pdf/2411.01230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01230]] Strengthening DeFi Security: A Static Analysis Approach to Flash Loan Vulnerabilities(https://arxiv.org/abs/2411.01230)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The rise of Decentralized Finance (DeFi) has brought novel financial opportunities but also exposed serious security vulnerabilities, with flash loans frequently exploited for price manipulation attacks. These attacks, leveraging the atomic nature of flash loans, allow malicious actors to manipulate DeFi protocol oracles and pricing mechanisms within a single transaction, causing substantial financial losses. Traditional smart contract analysis tools address some security risks but often struggle to detect the complex, inter-contract dependencies that make flash loan attacks challenging to identify. In response, we introduce FlashDeFier, an advanced detection framework that enhances static taint analysis to target price manipulation vulnerabilities arising from flash loans. FlashDeFier expands the scope of taint sources and sinks, enabling comprehensive analysis of data flows across DeFi protocols. The framework constructs detailed inter-contract call graphs to capture sophisticated data flow patterns, significantly improving detection accuracy. Tested against a dataset of high-profile DeFi incidents, FlashDeFier identifies 76.4% of price manipulation vulnerabilities, marking a 30% improvement over DeFiTainter. These results highlight the importance of adaptive detection frameworks that evolve alongside DeFi threats, underscoring the need for hybrid approaches combining static, dynamic, and symbolic analysis methods for resilient DeFi security.</li>
</ul>

<h3>Title: AutoPT: How Far Are We from the End2End Automated Web Penetration Testing?</h3>
<ul>
<li><strong>Authors: </strong>Benlong Wu, Guoqiang Chen, Kejiang Chen, Xiuwei Shang, Jiapeng Han, Yanru He, Weiming Zhang, Nenghai Yu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01236">https://arxiv.org/abs/2411.01236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01236">https://arxiv.org/pdf/2411.01236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01236]] AutoPT: How Far Are We from the End2End Automated Web Penetration Testing?(https://arxiv.org/abs/2411.01236)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Penetration testing is essential to ensure Web security, which can detect and fix vulnerabilities in advance, and prevent data leakage and serious consequences. The powerful inference capabilities of large language models (LLMs) have made significant progress in various fields, and the development potential of LLM-based agents can revolutionize the cybersecurity penetration testing industry. In this work, we establish a comprehensive end-to-end penetration testing benchmark using a real-world penetration testing environment to explore the capabilities of LLM-based agents in this domain. Our results reveal that the agents are familiar with the framework of penetration testing tasks, but they still face limitations in generating accurate commands and executing complete processes. Accordingly, we summarize the current challenges, including the difficulty of maintaining the entire message history and the tendency for the agent to become stuck. Based on the above insights, we propose a Penetration testing State Machine (PSM) that utilizes the Finite State Machine (FSM) methodology to address these limitations. Then, we introduce AutoPT, an automated penetration testing agent based on the principle of PSM driven by LLMs, which utilizes the inherent inference ability of LLM and the constraint framework of state machines. Our evaluation results show that AutoPT outperforms the baseline framework ReAct on the GPT-4o mini model and improves the task completion rate from 22% to 41% on the benchmark target. Compared with the baseline framework and manual work, AutoPT also reduces time and economic costs further. Hence, our AutoPT has facilitated the development of automated penetration testing and significantly impacted both academia and industry.</li>
</ul>

<h3>Title: Optimizing Federated Learning by Entropy-Based Client Selection</h3>
<ul>
<li><strong>Authors: </strong>Andreas Lutz, Gabriele Steidl, Karsten Müller, Wojciech Samek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01240">https://arxiv.org/abs/2411.01240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01240">https://arxiv.org/pdf/2411.01240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01240]] Optimizing Federated Learning by Entropy-Based Client Selection(https://arxiv.org/abs/2411.01240)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Deep learning is an emerging field revolutionizing various industries, including natural language processing, computer vision, and many more. These domains typically require an extensive amount of data for optimal performance, potentially utilizing huge centralized data repositories. However, such centralization could raise privacy issues concerning the storage of sensitive data. To address this issue, federated learning was developed. It is a newly distributed learning technique that enables to collaboratively train a deep learning model on decentralized devices, referred to as clients, without compromising their data privacy. Traditional federated learning methods often suffer from severe performance degradation when the data distribution among clients differs significantly. This becomes especially problematic in the case of label distribution skew, where the distribution of labels varies across clients. To address this, a novel method called FedEntOpt is proposed. FedEntOpt is designed to mitigate performance issues caused by label distribution skew by maximizing the entropy of the global label distribution of the selected client subset in each federated learning round. This ensures that the aggregated model parameters from the clients were exhibited to data from all available labels, which improves the accuracy of the global model. Extensive experiments on several benchmark datasets show that the proposed method outperforms several state-of-the-art algorithms by up to 6% in classification accuracy, demonstrating robust and superior performance, particularly under low participation rates. In addition, it offers the flexibility to be combined with them, enhancing their performance by over 40%.</li>
</ul>

<h3>Title: PMoL: Parameter Efficient MoE for Preference Mixing of LLM Alignment</h3>
<ul>
<li><strong>Authors: </strong>Dongxu Liu, Bing Xu, Yinzhuo Chen, Bufan Xu, Wenpeng Lu, Muyun Yang, Tiejun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01245">https://arxiv.org/abs/2411.01245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01245">https://arxiv.org/pdf/2411.01245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01245]] PMoL: Parameter Efficient MoE for Preference Mixing of LLM Alignment(https://arxiv.org/abs/2411.01245)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) has been proven to be an effective method for preference alignment of large language models (LLMs) and is widely used in the post-training process of LLMs. However, RLHF struggles with handling multiple competing preferences. This leads to a decrease in the alignment of LLMs with human preferences. To address this issue, we propose Preference Mixture of LoRAs (PMoL) from the perspective of model architecture, which can adapt to any number of preferences to mix. PMoL combines Mixture of Experts (MoE) and Low Rank Adaptor (LoRA). This architecture is innovatively applied to the research of preference alignment and has achieved significant performance improvement. The expert group soft loss is used to enable MoE with the ability to mix preferences. Through comprehensive evaluation by the reward model and GPT-4o, the experiment results show that PMoL has superior preference mixing capabilities compared to baseline methods. PMoL achieves better preference alignment with lower training costs.</li>
</ul>

<h3>Title: Diversidade lingu\'istica e inclus\~ao digital: desafios para uma ia brasileira</h3>
<ul>
<li><strong>Authors: </strong>Raquel Meister Ko Freitag</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01259">https://arxiv.org/abs/2411.01259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01259">https://arxiv.org/pdf/2411.01259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01259]] Diversidade lingu\'istica e inclus\~ao digital: desafios para uma ia brasileira(https://arxiv.org/abs/2411.01259)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Linguistic diversity is a human attribute which, with the advance of generative AIs, is coming under threat. This paper, based on the contributions of sociolinguistics, examines the consequences of the variety selection bias imposed by technological applications and the vicious circle of preserving a variety that becomes dominant and standardized because it has linguistic documentation to feed the large language models for machine learning.</li>
</ul>

<h3>Title: Confidence Aware Learning for Reliable Face Anti-spoofing</h3>
<ul>
<li><strong>Authors: </strong>Xingming Long, Jie Zhang, Shiguang Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01263">https://arxiv.org/abs/2411.01263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01263">https://arxiv.org/pdf/2411.01263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01263]] Confidence Aware Learning for Reliable Face Anti-spoofing(https://arxiv.org/abs/2411.01263)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Current Face Anti-spoofing (FAS) models tend to make overly confident predictions even when encountering unfamiliar scenarios or unknown presentation attacks, which leads to serious potential risks. To solve this problem, we propose a Confidence Aware Face Anti-spoofing (CA-FAS) model, which is aware of its capability boundary, thus achieving reliable liveness detection within this boundary. To enable the CA-FAS to "know what it doesn't know", we propose to estimate its confidence during the prediction of each sample. Specifically, we build Gaussian distributions for both the live faces and the known attacks. The prediction confidence for each sample is subsequently assessed using the Mahalanobis distance between the sample and the Gaussians for the "known data". We further introduce the Mahalanobis distance-based triplet mining to optimize the parameters of both the model and the constructed Gaussians as a whole. Extensive experiments show that the proposed CA-FAS can effectively recognize samples with low prediction confidence and thus achieve much more reliable performance than other FAS models by filtering out samples that are beyond its reliable range.</li>
</ul>

<h3>Title: An Innovative CGL-MHA Model for Sarcasm Sentiment Recognition Using the MindSpore Framework</h3>
<ul>
<li><strong>Authors: </strong>Zhenkai Qin, Qining Luo, Xunyi Nong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01264">https://arxiv.org/abs/2411.01264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01264">https://arxiv.org/pdf/2411.01264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01264]] An Innovative CGL-MHA Model for Sarcasm Sentiment Recognition Using the MindSpore Framework(https://arxiv.org/abs/2411.01264)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The pervasive use of the Internet and social media introduces significant challenges to automated sentiment analysis, particularly for sarcastic expressions in user-generated content. Sarcasm conveys negative emotions through ostensibly positive or exaggerated language, complicating its detection within natural language processing tasks. To address this, we propose an innovative sarcasm detection model integrating Convolutional Neural Networks (CNN), Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), and Multi-Head Attention mechanisms. The CNN component captures local n-gram features, while GRU and LSTM layers model sequential dependencies and contextual information. Multi-Head Attention enhances the model's focus on relevant parts of the input, improving interpretability. Experiments on two sarcasm detection datasets, Headlines and Riloff, demonstrate that the model achieves an accuracy of 81.20% and an F1 score of 80.77% on Headlines, and an accuracy of 79.72% with an F1 score of 61.39% on Riloff, outperforming traditional models. These results validate the effectiveness of our hybrid approach for sarcasm detection in social media texts.</li>
</ul>

<h3>Title: Conformalized High-Density Quantile Regression via Dynamic Prototypes-based Probability Density Estimation</h3>
<ul>
<li><strong>Authors: </strong>Batuhan Cengiz, Halil Faruk Karagoz, Tufan Kumbasar</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01266">https://arxiv.org/abs/2411.01266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01266">https://arxiv.org/pdf/2411.01266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01266]] Conformalized High-Density Quantile Regression via Dynamic Prototypes-based Probability Density Estimation(https://arxiv.org/abs/2411.01266)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent methods in quantile regression have adopted a classification perspective to handle challenges posed by heteroscedastic, multimodal, or skewed data by quantizing outputs into fixed bins. Although these regression-as-classification frameworks can capture high-density prediction regions and bypass convex quantile constraints, they are restricted by quantization errors and the curse of dimensionality due to a constant number of bins per dimension. To address these limitations, we introduce a conformalized high-density quantile regression approach with a dynamically adaptive set of prototypes. Our method optimizes the set of prototypes by adaptively adding, deleting, and relocating quantization bins throughout the training process. Moreover, our conformal scheme provides valid coverage guarantees, focusing on regions with the highest probability density. Experiments across diverse datasets and dimensionalities confirm that our method consistently achieves high-quality prediction regions with enhanced coverage and robustness, all while utilizing fewer prototypes and memory, ensuring scalability to higher dimensions. The code is available at this https URL .</li>
</ul>

<h3>Title: ProGen: Revisiting Probabilistic Spatial-Temporal Time Series Forecasting from a Continuous Generative Perspective Using Stochastic Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Mingze Gong, Lei Chen, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01267">https://arxiv.org/abs/2411.01267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01267">https://arxiv.org/pdf/2411.01267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01267]] ProGen: Revisiting Probabilistic Spatial-Temporal Time Series Forecasting from a Continuous Generative Perspective Using Stochastic Differential Equations(https://arxiv.org/abs/2411.01267)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Accurate forecasting of spatiotemporal data remains challenging due to complex spatial dependencies and temporal dynamics. The inherent uncertainty and variability in such data often render deterministic models insufficient, prompting a shift towards probabilistic approaches, where diffusion-based generative models have emerged as effective solutions. In this paper, we present ProGen, a novel framework for probabilistic spatiotemporal time series forecasting that leverages Stochastic Differential Equations (SDEs) and diffusion-based generative modeling techniques in the continuous domain. By integrating a novel denoising score model, graph neural networks, and a tailored SDE, ProGen provides a robust solution that effectively captures spatiotemporal dependencies while managing uncertainty. Our extensive experiments on four benchmark traffic datasets demonstrate that ProGen outperforms state-of-the-art deterministic and probabilistic models. This work contributes a continuous, diffusion-based generative approach to spatiotemporal forecasting, paving the way for future research in probabilistic modeling and stochastic processes.</li>
</ul>

<h3>Title: Interacting Large Language Model Agents. Interpretable Models and Social Learning</h3>
<ul>
<li><strong>Authors: </strong>Adit Jain, Vikram Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.ET, cs.MA, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01271">https://arxiv.org/abs/2411.01271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01271">https://arxiv.org/pdf/2411.01271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01271]] Interacting Large Language Model Agents. Interpretable Models and Social Learning(https://arxiv.org/abs/2411.01271)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper develops theory and algorithms for interacting large language model agents (LLMAs) using methods from statistical signal processing and microeconomics. While both fields are mature, their application to decision-making by interacting LLMAs remains unexplored. Motivated by Bayesian sentiment analysis on online platforms, we construct interpretable models and stochastic control algorithms that enable LLMAs to interact and perform Bayesian inference. Because interacting LLMAs learn from prior decisions and external inputs, they exhibit bias and herding behavior. Thus, developing interpretable models and stochastic control algorithms is essential to understand and mitigate these behaviors. This paper has three main results. First, we show using Bayesian revealed preferences from microeconomics that an individual LLMA satisfies the sufficient conditions for rationally inattentive (bounded rationality) utility maximization and, given an observation, the LLMA chooses an action that maximizes a regularized utility. Second, we utilize Bayesian social learning to construct interpretable models for LLMAs that interact sequentially with each other and the environment while performing Bayesian inference. Our models capture the herding behavior exhibited by interacting LLMAs. Third, we propose a stochastic control framework to delay herding and improve state estimation accuracy under two settings: (a) centrally controlled LLMAs and (b) autonomous LLMAs with incentives. Throughout the paper, we demonstrate the efficacy of our methods on real datasets for hate speech classification and product quality assessment, using open-source models like Mistral and closed-source models like ChatGPT. The main takeaway of this paper, based on substantial empirical analysis and mathematical formalism, is that LLMAs act as rationally bounded Bayesian agents that exhibit social learning when interacting.</li>
</ul>

<h3>Title: PARIS: A Practical, Adaptive Trace-Fetching and Real-Time Malicious Behavior Detection System</h3>
<ul>
<li><strong>Authors: </strong>Jian Wang, Lingzhi Wang, Husheng Yu, Xiangmin Shen, Yan Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01273">https://arxiv.org/abs/2411.01273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01273">https://arxiv.org/pdf/2411.01273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01273]] PARIS: A Practical, Adaptive Trace-Fetching and Real-Time Malicious Behavior Detection System(https://arxiv.org/abs/2411.01273)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>The escalating sophistication of cyber-attacks and the widespread utilization of stealth tactics have led to significant security threats globally. Nevertheless, the existing static detection methods exhibit limited coverage, and traditional dynamic monitoring approaches encounter challenges in bypassing evasion techniques. Thus, it has become imperative to implement nuanced and dynamic analysis to achieve precise behavior detection in real time. There are two pressing concerns associated with current dynamic malware behavior detection solutions. Firstly, the collection and processing of data entail a significant amount of overhead, making it challenging to be employed for real-time detection on the end host. Secondly, these approaches tend to treat malware as a singular entity, thereby overlooking varied behaviors within one instance. To fill these gaps, we propose PARIS, an adaptive trace fetching, lightweight, real-time malicious behavior detection system. Specifically, we monitor malicious behavior with Event Tracing for Windows (ETW) and learn to selectively collect maliciousness-related APIs or call stacks, significantly reducing the data collection overhead. As a result, we can monitor a wider range of APIs and detect more intricate attack behavior. We implemented a prototype of PARIS and evaluated the system overhead, the accuracy of comparative behavior recognition, and the impact of different models and parameters. The result demonstrates that PARIS can reduce over 98.8% of data compared to the raw ETW trace and hence decreases the overhead on the host in terms of memory, bandwidth, and CPU usage with a similar detection accuracy to the baselines that suffer from the high overhead. Furthermore, a breakdown evaluation shows that 80% of the memory and bandwidth savings and a complete reduction in CPU usage can be attributed to our adaptive trace-fetching collector.</li>
</ul>

<h3>Title: Varco Arena: A Tournament Approach to Reference-Free Benchmarking Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Seonil Son, Ju-Min Oh, Heegon Jin, Cheolhun Jang, Jeongbeom Jeong, Kuntae Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01281">https://arxiv.org/abs/2411.01281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01281">https://arxiv.org/pdf/2411.01281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01281]] Varco Arena: A Tournament Approach to Reference-Free Benchmarking Large Language Models(https://arxiv.org/abs/2411.01281)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) necessitates robust evaluation methodologies. Current benchmarking approaches often rely on comparing model outputs against predefined prompts and reference outputs. Relying on predefined reference outputs hinders flexible adaptation of benchmarks to the rapidly evolving capabilities of LLMs. This limitation necessitates periodic efforts to prepare new benchmarks. To keep pace with rapidly evolving LLM capabilities, we propose a more flexible benchmarking approach. Our method, \textit{\textbf{Varco Arena}}, provides reference-free benchmarking of LLMs in tournament style. \textit{\textbf{Varco Arena}} directly compares LLM outputs across a diverse set of prompts, determining model rankings through a single-elimination tournament structure. This direct pairwise comparison offers two key advantages: (1) Direct comparison, unmediated by reference text, more effectively orders competing LLMs, resulting in more reliable rankings, and (2) reference-free approach to benchmarking adds flexibility in updating benchmark prompts by eliminating the need for quality references. Our empirical results, supported by simulation experiments, demonstrate that the \textit{\textbf{Varco Arena}} tournament approach aligns better with the current Elo model for benchmarking LLMs. The alignment is measured in terms of Spearman correlation, showing improvement over current practice of benchmarking that use reference outputs as comparison \textit{anchor}s.</li>
</ul>

<h3>Title: Diffusion Models as Cartoonists! The Curious Case of High Density Regions</h3>
<ul>
<li><strong>Authors: </strong>Rafał Karczewski, Markus Heinonen, Vikas Garg</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01293">https://arxiv.org/abs/2411.01293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01293">https://arxiv.org/pdf/2411.01293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01293]] Diffusion Models as Cartoonists! The Curious Case of High Density Regions(https://arxiv.org/abs/2411.01293)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We investigate what kind of images lie in the high-density regions of diffusion models. We introduce a theoretical mode-tracking process capable of pinpointing the exact mode of the denoising distribution, and we propose a practical high-probability sampler that consistently generates images of higher likelihood than usual samplers. Our empirical findings reveal the existence of significantly higher likelihood samples that typical samplers do not produce, often manifesting as cartoon-like drawings or blurry images depending on the noise level. Curiously, these patterns emerge in datasets devoid of such examples. We also present a novel approach to track sample likelihoods in diffusion SDEs, which remarkably incurs no additional computational cost.</li>
</ul>

<h3>Title: Marginal Causal Flows for Validation and Inference</h3>
<ul>
<li><strong>Authors: </strong>Daniel de Vassimon Manela, Laura Battaglia, Robin J. Evans</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01295">https://arxiv.org/abs/2411.01295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01295">https://arxiv.org/pdf/2411.01295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01295]] Marginal Causal Flows for Validation and Inference(https://arxiv.org/abs/2411.01295)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Investigating the marginal causal effect of an intervention on an outcome from complex data remains challenging due to the inflexibility of employed models and the lack of complexity in causal benchmark datasets, which often fail to reproduce intricate real-world data patterns. In this paper we introduce Frugal Flows, a novel likelihood-based machine learning model that uses normalising flows to flexibly learn the data-generating process, while also directly inferring the marginal causal quantities from observational data. We propose that these models are exceptionally well suited for generating synthetic data to validate causal methods. They can create synthetic datasets that closely resemble the empirical dataset, while automatically and exactly satisfying a user-defined average treatment effect. To our knowledge, Frugal Flows are the first generative model to both learn flexible data representations and also exactly parameterise quantities such as the average treatment effect and the degree of unobserved confounding. We demonstrate the above with experiments on both simulated and real-world datasets.</li>
</ul>

<h3>Title: Regret of exploratory policy improvement and $q$-learning</h3>
<ul>
<li><strong>Authors: </strong>Wenpin Tang, Xun Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01302">https://arxiv.org/abs/2411.01302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01302">https://arxiv.org/pdf/2411.01302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01302]] Regret of exploratory policy improvement and $q$-learning(https://arxiv.org/abs/2411.01302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We study the convergence of $q$-learning and related algorithms introduced by Jia and Zhou (J. Mach. Learn. Res., 24 (2023), 161) for controlled diffusion processes. Under suitable conditions on the growth and regularity of the model parameters, we provide a quantitative error and regret analysis of both the exploratory policy improvement algorithm and the $q$-learning algorithm.</li>
</ul>

<h3>Title: Can Multimodal Large Language Model Think Analogically?</h3>
<ul>
<li><strong>Authors: </strong>Diandian Guo, Cong Cao, Fangfang Yuan, Dakui Wang, Wei Ma, Yanbing Liu, Jianhui Fu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01307">https://arxiv.org/abs/2411.01307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01307">https://arxiv.org/pdf/2411.01307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01307]] Can Multimodal Large Language Model Think Analogically?(https://arxiv.org/abs/2411.01307)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Analogical reasoning, particularly in multimodal contexts, is the foundation of human perception and creativity. Multimodal Large Language Model (MLLM) has recently sparked considerable discussion due to its emergent capabilities. In this paper, we delve into the multimodal analogical reasoning capability of MLLM. Specifically, we explore two facets: \textit{MLLM as an explainer} and \textit{MLLM as a predictor}. In \textit{MLLM as an explainer}, we primarily focus on whether MLLM can deeply comprehend multimodal analogical reasoning problems. We propose a unified prompt template and a method for harnessing the comprehension capabilities of MLLM to augment existing models. In \textit{MLLM as a predictor}, we aim to determine whether MLLM can directly solve multimodal analogical reasoning problems. The experiments show that our approach outperforms existing methods on popular datasets, providing preliminary evidence for the analogical reasoning capability of MLLM.</li>
</ul>

<h3>Title: ECG-PPS: Privacy Preserving Disease Diagnosis and Monitoring System for Real-Time ECG Signal</h3>
<ul>
<li><strong>Authors: </strong>Beyazit Bestami Yuksel, Ayse Yilmazer Metin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01308">https://arxiv.org/abs/2411.01308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01308">https://arxiv.org/pdf/2411.01308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01308]] ECG-PPS: Privacy Preserving Disease Diagnosis and Monitoring System for Real-Time ECG Signal(https://arxiv.org/abs/2411.01308)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust</a></li>
<li><strong>Abstract: </strong>This study introduces the development of a state of the art, real time ECG monitoring and analysis system, incorporating cutting edge medical technology and innovative data security measures. Our system performs three distinct functions thaat real time ECG monitoring and disease detection, encrypted storage and synchronized visualization, and statistical analysis on encrypted data. At its core, the system uses a three lead ECG preamplifier connected through a serial port to capture, display, and record real time ECG data. These signals are securely stored in the cloud using robust encryption methods. Authorized medical personnel can access and decrypt this data on their computers, with AES encryption ensuring synchronized real time data tracking and visualization. Furthermore, the system performs statistical operations on the ECG data stored in the cloud without decrypting it, using Fully Homomorphic Encryption (FHE). This enables privacy preserving data analysis while ensuring the security and confidentiality of patient information. By integrating these independent functions, our system significantly enhances the security and efficiency of health monitoring. It supports critical tasks such as disease detection, patient monitoring, and preliminary intervention, all while upholding stringent data privacy standards. We provided detailed discussions on the system's architecture, hardware configuration, software implementation, and clinical performance. The results highlight the potential of this system to improve patient care through secure and efficient ECG monitoring and analysis. This work represents a significant leap forward in medical technology. By incorporating FHE into both data transmission and storage processes, we ensure continuous encryption of data throughout its lifecycle while enabling real time disease diagnosis.</li>
</ul>

<h3>Title: Advancing Biomedical Signal Security: Real-Time ECG Monitoring with Chaotic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Beyazit Bestami Yuksel, Ayse Yilmazer Metin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01310">https://arxiv.org/abs/2411.01310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01310">https://arxiv.org/pdf/2411.01310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01310]] Advancing Biomedical Signal Security: Real-Time ECG Monitoring with Chaotic Encryption(https://arxiv.org/abs/2411.01310)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>The real time analysis and secure transmission of electrocardiogram (ECG) signals are critical for ensuring both effective medical diagnosis and patient data privacy. In this study, we developed a real time ECG monitoring system that integrates chaotic encryption to protect the integrity and confidentiality of ECG signals during acquisition, transmission, and storage. By leveraging the logistic map as the chaotic function for encryption, our system offers a highly secure framework that dynamically encrypts ECG signals without adding significant latency. To validate the system's reliability, we applied a series of security tests. The results demonstrate that chaotic encryption is effective in enhancing data security, as evidenced by high entropy values and strong key sensitivity, ensuring protection against common cryptographic attacks. Additionally, the system's real time disease detection model, based on deep learning, operates seamlessly with encrypted data, providing accurate diagnosis without compromising security. Our findings indicate that chaotic encryption, paired with real time analysis, is a powerful method for protecting sensitive medical data, making this approach particularly relevant for telemedicine and remote patient monitoring applications. The success of this system highlights its potential for broader application to other biomedical signals, providing a secure infrastructure for the future of digital health.</li>
</ul>

<h3>Title: From Federated Learning to Quantum Federated Learning for Space-Air-Ground Integrated Networks</h3>
<ul>
<li><strong>Authors: </strong>Vu Khanh Quy, Nguyen Minh Quy, Tran Thi Hoai, Shaba Shaon, Md Raihan Uddin, Tien Nguyen, Dinh C. Nguyen, Aryan Kaushik, Periklis Chatzimisios</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01312">https://arxiv.org/abs/2411.01312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01312">https://arxiv.org/pdf/2411.01312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01312]] From Federated Learning to Quantum Federated Learning for Space-Air-Ground Integrated Networks(https://arxiv.org/abs/2411.01312)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>6G wireless networks are expected to provide seamless and data-based connections that cover space-air-ground and underwater networks. As a core partition of future 6G networks, Space-Air-Ground Integrated Networks (SAGIN) have been envisioned to provide countless real-time intelligent applications. To realize this, promoting AI techniques into SAGIN is an inevitable trend. Due to the distributed and heterogeneous architecture of SAGIN, federated learning (FL) and then quantum FL are emerging AI model training techniques for enabling future privacy-enhanced and computation-efficient SAGINs. In this work, we explore the vision of using FL/QFL in SAGINs. We present a few representative applications enabled by the integration of FL and QFL in SAGINs. A case study of QFL over UAV networks is also given, showing the merit of quantum-enabled training approach over the conventional FL benchmark. Research challenges along with standardization for QFL adoption in future SAGINs are also highlighted.</li>
</ul>

<h3>Title: False Data Injection Attack Detection in Edge-based Smart Metering Networks with Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Md Raihan Uddin, Ratun Rahman, Dinh C. Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01313">https://arxiv.org/abs/2411.01313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01313">https://arxiv.org/pdf/2411.01313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01313]] False Data Injection Attack Detection in Edge-based Smart Metering Networks with Federated Learning(https://arxiv.org/abs/2411.01313)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate, transformer</a></li>
<li><strong>Abstract: </strong>Smart metering networks are increasingly susceptible to cyber threats, where false data injection (FDI) appears as a critical attack. Data-driven-based machine learning (ML) methods have shown immense benefits in detecting FDI attacks via data learning and prediction abilities. Literature works have mostly focused on centralized learning and deploying FDI attack detection models at the control center, which requires data collection from local utilities like meters and transformers. However, this data sharing may raise privacy concerns due to the potential disclosure of household information like energy usage patterns. This paper proposes a new privacy-preserved FDI attack detection by developing an efficient federated learning (FL) framework in the smart meter network with edge computing. Distributed edge servers located at the network edge run an ML-based FDI attack detection model and share the trained model with the grid operator, aiming to build a strong FDI attack detection model without data sharing. Simulation results demonstrate the efficiency of our proposed FL method over the conventional method without collaboration.</li>
</ul>

<h3>Title: FEED: Fairness-Enhanced Meta-Learning for Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Kai Jiang, Chen Zhao, Haoliang Wang, Feng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01316">https://arxiv.org/abs/2411.01316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01316">https://arxiv.org/pdf/2411.01316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01316]] FEED: Fairness-Enhanced Meta-Learning for Domain Generalization(https://arxiv.org/abs/2411.01316)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Generalizing to out-of-distribution data while being aware of model fairness is a significant and challenging problem in meta-learning. The goal of this problem is to find a set of fairness-aware invariant parameters of classifier that is trained using data drawn from a family of related training domains with distribution shift on non-sensitive features as well as different levels of dependence between model predictions and sensitive features so that the classifier can achieve good generalization performance on unknown but distinct test domains. To tackle this challenge, existing state-of-the-art methods either address the domain generalization problem but completely ignore learning with fairness or solely specify shifted domains with various fairness levels. This paper introduces an approach to fairness-aware meta-learning that significantly enhances domain generalization capabilities. Our framework, Fairness-Enhanced Meta-Learning for Domain Generalization (FEED), disentangles latent data representations into content, style, and sensitive vectors. This disentanglement facilitates the robust generalization of machine learning models across diverse domains while adhering to fairness constraints. Unlike traditional methods that focus primarily on domain invariance or sensitivity to shifts, our model integrates a fairness-aware invariance criterion directly into the meta-learning process. This integration ensures that the learned parameters uphold fairness consistently, even when domain characteristics vary widely. We validate our approach through extensive experiments across multiple benchmarks, demonstrating not only superior performance in maintaining high accuracy and fairness but also significant improvements over existing state-of-the-art methods in domain generalization tasks.</li>
</ul>

<h3>Title: Generalized Eigenvalue Problems with Generative Priors</h3>
<ul>
<li><strong>Authors: </strong>Zhaoqiang Liu, Wen Li, Junren Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01326">https://arxiv.org/abs/2411.01326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01326">https://arxiv.org/pdf/2411.01326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01326]] Generalized Eigenvalue Problems with Generative Priors(https://arxiv.org/abs/2411.01326)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generalized eigenvalue problems (GEPs) find applications in various fields of science and engineering. For example, principal component analysis, Fisher's discriminant analysis, and canonical correlation analysis are specific instances of GEPs and are widely used in statistical data processing. In this work, we study GEPs under generative priors, assuming that the underlying leading generalized eigenvector lies within the range of a Lipschitz continuous generative model. Under appropriate conditions, we show that any optimal solution to the corresponding optimization problems attains the optimal statistical rate. Moreover, from a computational perspective, we propose an iterative algorithm called the Projected Rayleigh Flow Method (PRFM) to approximate the optimal solution. We theoretically demonstrate that under suitable assumptions, PRFM converges linearly to an estimated vector that achieves the optimal statistical rate. Numerical results are provided to demonstrate the effectiveness of the proposed method.</li>
</ul>

<h3>Title: Visual Fourier Prompt Tuning</h3>
<ul>
<li><strong>Authors: </strong>Runjia Zeng, Cheng Han, Qifan Wang, Chunshu Wu, Tong Geng, Lifu Huang, Ying Nian Wu, Dongfang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01327">https://arxiv.org/abs/2411.01327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01327">https://arxiv.org/pdf/2411.01327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01327]] Visual Fourier Prompt Tuning(https://arxiv.org/abs/2411.01327)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>With the scale of vision Transformer-based models continuing to grow, finetuning these large-scale pretrained models for new tasks has become increasingly parameter-intensive. Visual prompt tuning is introduced as a parameter-efficient finetuning (PEFT) method to this trend. Despite its successes, a notable research challenge persists within almost all PEFT approaches: significant performance degradation is observed when there is a substantial disparity between the datasets applied in pretraining and finetuning phases. To address this challenge, we draw inspiration from human visual cognition, and propose the Visual Fourier Prompt Tuning (VFPT) method as a general and effective solution for adapting large-scale transformer-based models. Our approach innovatively incorporates the Fast Fourier Transform into prompt embeddings and harmoniously considers both spatial and frequency domain information. Apart from its inherent simplicity and intuitiveness, VFPT exhibits superior performance across all datasets, offering a general solution to dataset challenges, irrespective of data disparities. Empirical results demonstrate that our approach outperforms current state-of-the-art baselines on two benchmarks, with low parameter usage (e.g., 0.57% of model parameters on VTAB-1k) and notable performance enhancements (e.g., 73.20% of mean accuracy on VTAB-1k). Our code is avaliable at this https URL.</li>
</ul>

<h3>Title: A Mechanistic Explanatory Strategy for XAI</h3>
<ul>
<li><strong>Authors: </strong>Marcin Rabiza</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01332">https://arxiv.org/abs/2411.01332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01332">https://arxiv.org/pdf/2411.01332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01332]] A Mechanistic Explanatory Strategy for XAI(https://arxiv.org/abs/2411.01332)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Despite significant advancements in XAI, scholars note a persistent lack of solid conceptual foundations and integration with broader scientific discourse on explanation. In response, emerging XAI research draws on explanatory strategies from various sciences and philosophy of science literature to fill these gaps. This paper outlines a mechanistic strategy for explaining the functional organization of deep learning systems, situating recent advancements in AI explainability within a broader philosophical context. According to the mechanistic approach, the explanation of opaque AI systems involves identifying mechanisms that drive decision-making. For deep neural networks, this means discerning functionally relevant components -- such as neurons, layers, circuits, or activation patterns -- and understanding their roles through decomposition, localization, and recomposition. Proof-of-principle case studies from image recognition and language modeling align these theoretical approaches with the latest research from AI labs like OpenAI and Anthropic. This research suggests that a systematic approach to studying model organization can reveal elements that simpler (or ''more modest'') explainability techniques might miss, fostering more thoroughly explainable AI. The paper concludes with a discussion on the epistemic relevance of the mechanistic approach positioned in the context of selected philosophical debates on XAI.</li>
</ul>

<h3>Title: RA-WEBs: Remote Attestation for WEB services</h3>
<ul>
<li><strong>Authors: </strong>Kosei Akama, Yoshimichi Nakatsuka, Korry Luke, Masaaki Sato, Keisuke Uehara</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01340">https://arxiv.org/abs/2411.01340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01340">https://arxiv.org/pdf/2411.01340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01340]] RA-WEBs: Remote Attestation for WEB services(https://arxiv.org/abs/2411.01340)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect</a></li>
<li><strong>Abstract: </strong>Data theft and leakage, caused by external adversaries and insiders, demonstrate the need for protecting user data. Trusted Execution Environments (TEEs) offer a promising solution by creating secure environments that protect data and code from such threats. The rise of confidential computing on cloud platforms facilitates the deployment of TEE-enabled server applications, which are expected to be widely adopted in web services such as privacy-preserving LLM inference and secure data logging. One key feature is Remote Attestation (RA), which enables integrity verification of a TEE. However, $\textit{compatibility}$ issues with RA verification arise as no browsers natively support this feature, making prior solutions cumbersome and risky. To address these challenges, we propose $\texttt{RA-WEBs}$ ($\textbf{R}$emote $\textbf{A}$ttestation for $\textbf{Web}$ $\textbf{s}$ervices), a novel RA protocol designed for high compatibility with the current web ecosystem. $\texttt{RA-WEBs}$ leverages established web mechanisms for immediate deployability, enabling RA verification on existing browsers. We conduct a comprehensive security analysis, demonstrating $\texttt{RA-WEBs}$'s resilience against various threats. Our contributions include the $\texttt{RA-WEBs}$ proposal, a proof-of-concept implementation, an in-depth security analysis, and publicly available code for reproducible research.</li>
</ul>

<h3>Title: Adaptive World Models: Learning Behaviors by Latent Imagination Under Non-Stationarity</h3>
<ul>
<li><strong>Authors: </strong>Emiliyan Gospodinov, Vaisakh Shaj, Philipp Becker, Stefan Geyer, Gerhard Neumann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01342">https://arxiv.org/abs/2411.01342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01342">https://arxiv.org/pdf/2411.01342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01342]] Adaptive World Models: Learning Behaviors by Latent Imagination Under Non-Stationarity(https://arxiv.org/abs/2411.01342)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Developing foundational world models is a key research direction for embodied intelligence, with the ability to adapt to non-stationary environments being a crucial criterion. In this work, we introduce a new formalism, Hidden Parameter-POMDP, designed for control with adaptive world models. We demonstrate that this approach enables learning robust behaviors across a variety of non-stationary RL benchmarks. Additionally, this formalism effectively learns task abstractions in an unsupervised manner, resulting in structured, task-aware latent spaces.</li>
</ul>

<h3>Title: Optimizing Violence Detection in Video Classification Accuracy through 3D Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Aarjav Kavathia, Simeon Sayer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01348">https://arxiv.org/abs/2411.01348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01348">https://arxiv.org/pdf/2411.01348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01348]] Optimizing Violence Detection in Video Classification Accuracy through 3D Convolutional Neural Networks(https://arxiv.org/abs/2411.01348)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As violent crimes continue to happen, it becomes necessary to have security cameras that can rapidly identify moments of violence with excellent accuracy. The purpose of this study is to identify how many frames should be analyzed at a time in order to optimize a violence detection model's accuracy as a parameter of the depth of a 3D convolutional network. Previous violence classification models have been created, but their application to live footage may be flawed. In this project, a convolutional neural network was created to analyze optical flow frames of each video. The number of frames analyzed at a time would vary with one, two, three, ten, and twenty frames, and each model would be trained for 20 epochs. The greatest validation accuracy was 94.87% and occurred with the model that analyzed three frames at a time. This means that machine learning models to detect violence may function better when analyzing three frames at a time for this dataset. The methodology used to identify the optimal number of frames to analyze at a time could be used in other applications of video classification, especially those of complex or abstract actions, such as violence.</li>
</ul>

<h3>Title: Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles</h3>
<ul>
<li><strong>Authors: </strong>Tim Ruschke, Jonathan Frederik Carlsen, Adam Espe Hansen, Ulrich Lindberg, Amalie Monberg Hindsholm, Martin Norgaard, Claes Nøhr Ladefoged</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01351">https://arxiv.org/abs/2411.01351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01351">https://arxiv.org/pdf/2411.01351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01351]] Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles(https://arxiv.org/abs/2411.01351)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning models in medical contexts face challenges like data scarcity, inhomogeneity, and privacy concerns. This study focuses on improving ventricular segmentation in brain MRI images using synthetic data. We employed two latent diffusion models (LDMs): a mask generator trained using 10,000 masks, and a corresponding SPADE image generator optimized using 6,881 scans to create an MRI conditioned on a 3D brain mask. Conditioning the mask generator on ventricular volume in combination with classifier-free guidance enabled the control of the ventricular volume distribution of the generated synthetic images. Next, the performance of the synthetic data was tested using three nnU-Net segmentation models trained on a real, augmented and entirely synthetic data, respectively. The resulting models were tested on a completely independent hold-out dataset of patients with enlarged ventricles, with manual delineation of the ventricles used as ground truth. The model trained on real data showed a mean absolute error (MAE) of 9.09 \pm 12.18 mL in predicted ventricular volume, while the models trained on synthetic and augmented data showed MAEs of 7.52 \pm 4.81 mL and 6.23 \pm 4.33 mL, respectively. Both the synthetic and augmented model also outperformed the state-of-the-art model SynthSeg, which due to limited performance in cases of large ventricular volumes, showed an MAE of 7.73 \pm 12.12 mL with a factor of 3 higher standard deviation. The model trained on augmented data showed the highest Dice score of 0.892 \pm 0.05, slightly outperforming SynthSeg and on par with the model trained on real data. The synthetic model performed similar to SynthSeg. In summary, we provide evidence that guided synthesis of labeled brain MRI data using LDMs improves the segmentation of enlarged ventricles and outperforms existing state-of-the-art segmentation models.</li>
</ul>

<h3>Title: Can Large Language Model Predict Employee Attrition?</h3>
<ul>
<li><strong>Authors: </strong>Xiaoye Ma, Weiheng Liu, Changyi Zhao, Liliya R. Tukhvatulina</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01353">https://arxiv.org/abs/2411.01353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01353">https://arxiv.org/pdf/2411.01353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01353]] Can Large Language Model Predict Employee Attrition?(https://arxiv.org/abs/2411.01353)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Employee attrition poses significant costs for organizations, with traditional statistical prediction methods often struggling to capture modern workforce complexities. Machine learning (ML) advancements offer more scalable and accurate solutions, but large language models (LLMs) introduce new potential in human resource management by interpreting nuanced employee communication and detecting subtle turnover cues. This study leverages the IBM HR Analytics Attrition dataset to compare the predictive accuracy and interpretability of a fine-tuned GPT-3.5 model against traditional ML classifiers, including Logistic Regression, k-Nearest Neighbors (KNN), Support Vector Machine (SVM), Decision Tree, Random Forest, AdaBoost, and XGBoost. While traditional models are easier to use and interpret, LLMs can reveal deeper patterns in employee behavior. Our findings show that the fine-tuned GPT-3.5 model outperforms traditional methods with a precision of 0.91, recall of 0.94, and an F1-score of 0.92, while the best traditional model, SVM, achieved an F1-score of 0.82, with Random Forest and XGBoost reaching 0.80. These results highlight GPT-3.5's ability to capture complex patterns in attrition risk, offering organizations improved insights for retention strategies and underscoring the value of LLMs in HR applications.</li>
</ul>

<h3>Title: WaKA: Data Attribution using K-Nearest Neighbors and Membership Privacy Principles</h3>
<ul>
<li><strong>Authors: </strong>Patrick Mesana, Clément Bénesse, Hadrien Lautraite, Gilles Caporossi, Sébastien Gambs</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01357">https://arxiv.org/abs/2411.01357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01357">https://arxiv.org/pdf/2411.01357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01357]] WaKA: Data Attribution using K-Nearest Neighbors and Membership Privacy Principles(https://arxiv.org/abs/2411.01357)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce WaKA (Wasserstein K-nearest neighbors Attribution), a novel attribution method that leverages principles from the LiRA (Likelihood Ratio Attack) framework and applies them to \( k \)-nearest neighbors classifiers (\( k \)-NN). WaKA efficiently measures the contribution of individual data points to the model's loss distribution, analyzing every possible \( k \)-NN that can be constructed using the training set, without requiring sampling or shadow model training. WaKA can be used \emph{a posteriori} as a membership inference attack (MIA) to assess privacy risks, and \emph{a priori} for data minimization and privacy influence measurement. Thus, WaKA can be seen as bridging the gap between data attribution and membership inference attack (MIA) literature by distinguishing between the value of a data point and its privacy risk. For instance, we show that self-attribution values are more strongly correlated with the attack success rate than the contribution of a point to model generalization. WaKA's different usages were also evaluated across diverse real-world datasets, demonstrating performance very close to LiRA when used as an MIA on \( k \)-NN classifiers, but with greater computational efficiency.</li>
</ul>

<h3>Title: Artificial Intelligence Driven Course Generation: A Case Study Using ChatGPT</h3>
<ul>
<li><strong>Authors: </strong>Djaber Rouabhia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01369">https://arxiv.org/abs/2411.01369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01369">https://arxiv.org/pdf/2411.01369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01369]] Artificial Intelligence Driven Course Generation: A Case Study Using ChatGPT(https://arxiv.org/abs/2411.01369)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This study explores Artificial Intelligence use, specifically ChatGPT, in creating educational content. The study aims to elaborate on using ChatGPT to create course materials. The main objective is to assess the efficiency, quality, and impact of AI-driven course generation, and to create a Multimedia Databases course as a case study. The study highlights the potential of AI to revolutionize educational content creation, making it more accessible, personalized, and efficient. The course content was generated in less than one day through iterative methods, using prompts for translation, content expansion, practical examples, assignments, supplementary materials, and LaTeX formatting. Each part was verified immediately after generation to ensure accuracy. Post-generation analysis with Detectia and Turnitin showed similarity rates of 8.7% and 13%, indicating high originality. Experts and university committees reviewed and approved the course, with English university teachers praising its language quality. ChatGPT also created a well-structured and diversified exam for the module. Key findings reveal significant time efficiency, comprehensive content coverage, and high flexibility. The study underscores AI's transformative potential in education, addressing challenges related to data privacy, technology dependence, content accuracy, and algorithmic biases. The conclusions emphasize the need for collaboration between educators, policymakers, and technology developers to harness AI's benefits in education fully.</li>
</ul>

<h3>Title: How Memory-Safe is IoT? Assessing the Impact of Memory-Protection Solutions for Securing Wireless Gateways</h3>
<ul>
<li><strong>Authors: </strong>Vadim Safronov, Ionut Bostan, Nicholas Allott, Andrew Martin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01377">https://arxiv.org/abs/2411.01377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01377">https://arxiv.org/pdf/2411.01377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01377]] How Memory-Safe is IoT? Assessing the Impact of Memory-Protection Solutions for Securing Wireless Gateways(https://arxiv.org/abs/2411.01377)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapid development of the Internet of Things (IoT) has enabled novel user-centred applications, including many in safety-critical areas such as healthcare, smart environment security, and emergency response systems. The diversity in IoT manufacturers, standards, and devices creates a combinatorial explosion of such deployment scenarios, leading to increased security and safety threats due to the difficulty of managing such heterogeneity. In almost every IoT deployment, wireless gateways are crucial for interconnecting IoT devices and providing services, yet they are vulnerable to external threats and serve as key entry points for large-scale IoT attacks. Memory-based vulnerabilities are among the most serious threats in software, with no universal solution yet available. Legacy memory protection mechanisms, such as canaries, RELRO, NX, and Fortify, have enhanced memory safety but remain insufficient for comprehensive protection. Emerging technologies like ARM-MTE, CHERI, and Rust are based on more universal and robust Secure-by-Design (SbD) memory safety principles, yet each entails different trade-offs in hardware or code modifications. Given the challenges of balancing security levels with associated overheads in IoT systems, this paper explores the impact of memory safety on the IoT domain through an empirical large-scale analysis of memory-related vulnerabilities in modern wireless gateways. Our results show that memory vulnerabilities constitute the majority of IoT gateway threats, underscoring the necessity for SbD solutions, with the choice of memory-protection technology depending on specific use cases and associated overheads.</li>
</ul>

<h3>Title: Signer-Optimal Multiple-Time Post-Quantum Hash-Based Signature for Heterogeneous IoT Systems</h3>
<ul>
<li><strong>Authors: </strong>Kiarash Sedghighadikolaei, Attila A. Yavuz, Saif E. Nouma</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01380">https://arxiv.org/abs/2411.01380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01380">https://arxiv.org/pdf/2411.01380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01380]] Signer-Optimal Multiple-Time Post-Quantum Hash-Based Signature for Heterogeneous IoT Systems(https://arxiv.org/abs/2411.01380)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Heterogeneous Internet of Things (IoTs) harboring resource-limited devices like wearable sensors are essential for next-generation networks. Ensuring the authentication and integrity of security-sensitive telemetry in these applications is vital. Digital signatures provide scalable authentication with non-repudiation and public verifiability, making them essential tools for IoTs. However, emerging quantum computers necessitate post-quantum (PQ) secure solutions, yet existing NIST-PQC standards are costlier than their conventional counterparts and unsuitable for resource-limited IoTs. There is a significant need for lightweight PQ-secure digital signatures that respect the resource constraints of low-end IoTs. We propose a new multiple-time hash-based signature called Maximum Utilization Multiple HORS (MUM-HORS) that offers PQ security, short signatures, fast signing, and high key utilization for an extended lifespan. MUM-HORS addresses the inefficiency and key loss issues of HORS in offline/online settings by introducing compact key management data structures and optimized resistance to weak-message attacks. We tested MUM-HORS on two embedded platforms (ARM Cortex A-72 and 8-bit AVR ATmega2560) and commodity hardware. Our experiments confirm up to 40x better utilization with the same signing capacity (2^20 messages, 128-bit security) compared to multiple-time HORS while achieving 2x and 156-2463x faster signing than conventional-secure and NIST PQ-secure schemes, respectively, on an ARM Cortex. These features make MUM-HORS ideal multiple-time PQ-secure signature for heterogeneous IoTs.</li>
</ul>

<h3>Title: A New Logic For Pediatric Brain Tumor Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Max Bengtsson, Elif Keles, Gorkem Durak, Syed Anwar, Yuri S. Velichko, Marius G. Linguraru, Angela J. Waanders, Ulas Bagci</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01390">https://arxiv.org/abs/2411.01390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01390">https://arxiv.org/pdf/2411.01390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01390]] A New Logic For Pediatric Brain Tumor Segmentation(https://arxiv.org/abs/2411.01390)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel approach for segmenting pediatric brain tumors using a deep learning architecture, inspired by expert radiologists' segmentation strategies. Our model delineates four distinct tumor labels and is benchmarked on a held-out PED BraTS 2024 test set (i.e., pediatric brain tumor datasets introduced by BraTS). Furthermore, we evaluate our model's performance against the state-of-the-art (SOTA) model using a new external dataset of 30 patients from CBTN (Children's Brain Tumor Network), labeled in accordance with the PED BraTS 2024 guidelines. We compare segmentation outcomes with the winning algorithm from the PED BraTS 2023 challenge as the SOTA model. Our proposed algorithm achieved an average Dice score of 0.642 and an HD95 of 73.0 mm on the CBTN test data, outperforming the SOTA model, which achieved a Dice score of 0.626 and an HD95 of 84.0 mm. Our results indicate that the proposed model is a step towards providing more accurate segmentation for pediatric brain tumors, which is essential for evaluating therapy response and monitoring patient progress.</li>
</ul>

<h3>Title: MambaReg: Mamba-Based Disentangled Convolutional Sparse Coding for Unsupervised Deformable Multi-Modal Image Registration</h3>
<ul>
<li><strong>Authors: </strong>Kaiang Wen, Bin Xie, Bin Duan, Yan Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01399">https://arxiv.org/abs/2411.01399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01399">https://arxiv.org/pdf/2411.01399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01399]] MambaReg: Mamba-Based Disentangled Convolutional Sparse Coding for Unsupervised Deformable Multi-Modal Image Registration(https://arxiv.org/abs/2411.01399)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Precise alignment of multi-modal images with inherent feature discrepancies poses a pivotal challenge in deformable image registration. Traditional learning-based approaches often consider registration networks as black boxes without interpretability. One core insight is that disentangling alignment features and non-alignment features across modalities bring benefits. Meanwhile, it is challenging for the prominent methods for image registration tasks, such as convolutional neural networks, to capture long-range dependencies by their local receptive fields. The methods often fail when the given image pair has a large misalignment due to the lack of effectively learning long-range dependencies and correspondence. In this paper, we propose MambaReg, a novel Mamba-based architecture that integrates Mamba's strong capability in capturing long sequences to address these challenges. With our proposed several sub-modules, MambaReg can effectively disentangle modality-independent features responsible for registration from modality-dependent, non-aligning features. By selectively attending to the relevant features, our network adeptly captures the correlation between multi-modal images, enabling focused deformation field prediction and precise image alignment. The Mamba-based architecture seamlessly integrates the local feature extraction power of convolutional layers with the long-range dependency modeling capabilities of Mamba. Experiments on public non-rigid RGB-IR image datasets demonstrate the superiority of our method, outperforming existing approaches in terms of registration accuracy and deformation field smoothness.</li>
</ul>

<h3>Title: Hyperbox Mixture Regression for Process Performance Prediction in Antibody Production</h3>
<ul>
<li><strong>Authors: </strong>Ali Nik-Khorasani, Thanh Tung Khuat, Bogdan Gabrys</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01404">https://arxiv.org/abs/2411.01404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01404">https://arxiv.org/pdf/2411.01404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01404]] Hyperbox Mixture Regression for Process Performance Prediction in Antibody Production(https://arxiv.org/abs/2411.01404)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenges of predicting bioprocess performance, particularly in monoclonal antibody (mAb) production, where conventional statistical methods often fall short due to time-series data's complexity and high dimensionality. We propose a novel Hyperbox Mixture Regression (HMR) model which employs hyperbox-based input space partitioning to enhance predictive accuracy while managing uncertainty inherent in bioprocess data. The HMR model is designed to dynamically generate hyperboxes for input samples in a single-pass process, thereby improving learning speed and reducing computational complexity. Our experimental study utilizes a dataset that contains 106 bioreactors. This study evaluates the model's performance in predicting critical quality attributes in monoclonal antibody manufacturing over a 15-day cultivation period. The results demonstrate that the HMR model outperforms comparable approximators in accuracy and learning speed and maintains interpretability and robustness under uncertain conditions. These findings underscore the potential of HMR as a powerful tool for enhancing predictive analytics in bioprocessing applications.</li>
</ul>

<h3>Title: Classifier-guided Gradient Modulation for Enhanced Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>Zirun Guo, Tao Jin, Jingyuan Chen, Zhou Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01409">https://arxiv.org/abs/2411.01409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01409">https://arxiv.org/pdf/2411.01409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01409]] Classifier-guided Gradient Modulation for Enhanced Multimodal Learning(https://arxiv.org/abs/2411.01409)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Multimodal learning has developed very fast in recent years. However, during the multimodal training process, the model tends to rely on only one modality based on which it could learn faster, thus leading to inadequate use of other modalities. Existing methods to balance the training process always have some limitations on the loss functions, optimizers and the number of modalities and only consider modulating the magnitude of the gradients while ignoring the directions of the gradients. To solve these problems, in this paper, we present a novel method to balance multimodal learning with Classifier-Guided Gradient Modulation (CGGM), considering both the magnitude and directions of the gradients. We conduct extensive experiments on four multimodal datasets: UPMC-Food 101, CMU-MOSI, IEMOCAP and BraTS 2021, covering classification, regression and segmentation tasks. The results show that CGGM outperforms all the baselines and other state-of-the-art methods consistently, demonstrating its effectiveness and versatility. Our code is available at this https URL.</li>
</ul>

<h3>Title: Enhancing Glucose Level Prediction of ICU Patients through Irregular Time-Series Analysis and Integrated Representation</h3>
<ul>
<li><strong>Authors: </strong>Hadi Mehdizavareh, Arijit Khan, Simon Lebech Cichosz</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01418">https://arxiv.org/abs/2411.01418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01418">https://arxiv.org/pdf/2411.01418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01418]] Enhancing Glucose Level Prediction of ICU Patients through Irregular Time-Series Analysis and Integrated Representation(https://arxiv.org/abs/2411.01418)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurately predicting blood glucose (BG) levels of ICU patients is critical, as both hypoglycemia (BG < 70 mg/dL) and hyperglycemia (BG > 180 mg/dL) are associated with increased morbidity and mortality. We develop the Multi-source Irregular Time-Series Transformer (MITST), a novel machine learning-based model to forecast the next BG level, classifying it into hypoglycemia, hyperglycemia, or euglycemia (70-180 mg/dL). The irregularity and complexity of Electronic Health Record (EHR) data, spanning multiple heterogeneous clinical sources like lab results, medications, and vital signs, pose significant challenges for prediction tasks. MITST addresses these using hierarchical Transformer architectures, which include a feature-level, a timestamp-level, and a source-level Transformer. This design captures fine-grained temporal dynamics and allows learning-based data integration instead of traditional predefined aggregation. In a large-scale evaluation using the eICU database (200,859 ICU stays across 208 hospitals), MITST achieves an average improvement of 1.7% (p < 0.001) in AUROC and 1.8% (p < 0.001) in AUPRC over a state-of-the-art baseline. For hypoglycemia, MITST achieves an AUROC of 0.915 and an AUPRC of 0.247, both significantly higher than the baseline's AUROC of 0.862 and AUPRC of 0.208 (p < 0.001). The flexible architecture of MITST allows seamless integration of new data sources without retraining the entire model, enhancing its adaptability in clinical decision support. Although this study focuses on predicting BG levels, MITST can easily be extended to other critical event prediction tasks in ICU settings, offering a robust solution for analyzing complex, multi-source, irregular time-series data.</li>
</ul>

<h3>Title: PSformer: Parameter-efficient Transformer with Segment Attention for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Yanlong Wang, Jian Xu, Fei Ma, Shao-Lun Huang, Danny Dongning Sun, Xiao-Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01419">https://arxiv.org/abs/2411.01419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01419">https://arxiv.org/pdf/2411.01419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01419]] PSformer: Parameter-efficient Transformer with Segment Attention for Time Series Forecasting(https://arxiv.org/abs/2411.01419)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Time series forecasting remains a critical challenge across various domains, often complicated by high-dimensional data and long-term dependencies. This paper presents a novel transformer architecture for time series forecasting, incorporating two key innovations: parameter sharing (PS) and Spatial-Temporal Segment Attention (SegAtt). We also define the time series segment as the concatenation of sequence patches from the same positions across different variables. The proposed model, PSformer, reduces the number of training parameters through the parameter sharing mechanism, thereby improving model efficiency and scalability. The introduction of SegAtt could enhance the capability of capturing local spatio-temporal dependencies by computing attention over the segments, and improve global representation by integrating information across segments. The combination of parameter sharing and SegAtt significantly improves the forecasting performance. Extensive experiments on benchmark datasets demonstrate that PSformer outperforms popular baselines and other transformer-based approaches in terms of accuracy and scalability, establishing itself as an accurate and scalable tool for time series forecasting.</li>
</ul>

<h3>Title: Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision</h3>
<ul>
<li><strong>Authors: </strong>Xiangzhong Luo, Di Liu, Hao Kong, Shuo Huai, Hui Chen, Guochu Xiong, Weichen Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01431">https://arxiv.org/abs/2411.01431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01431">https://arxiv.org/pdf/2411.01431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01431]] Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision(https://arxiv.org/abs/2411.01431)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) have recently achieved impressive success across a wide range of real-world vision and language processing tasks, spanning from image classification to many other downstream vision tasks, such as object detection, tracking, and segmentation. However, previous well-established DNNs, despite being able to maintain superior accuracy, have also been evolving to be deeper and wider and thus inevitably necessitate prohibitive computational resources for both training and inference. This trend further enlarges the computational gap between computation-intensive DNNs and resource-constrained embedded computing systems, making it challenging to deploy powerful DNNs upon real-world embedded computing systems towards ubiquitous embedded intelligence. To alleviate the above computational gap and enable ubiquitous embedded intelligence, we, in this survey, focus on discussing recent efficient deep learning infrastructures for embedded computing systems, spanning from training to inference, from manual to automated, from convolutional neural networks to transformers, from transformers to vision transformers, from vision models to large language models, from software to hardware, and from algorithms to applications. Specifically, we discuss recent efficient deep learning infrastructures for embedded computing systems from the lens of (1) efficient manual network design for embedded computing systems, (2) efficient automated network design for embedded computing systems, (3) efficient network compression for embedded computing systems, (4) efficient on-device learning for embedded computing systems, (5) efficient large language models for embedded computing systems, (6) efficient deep learning software and hardware for embedded computing systems, and (7) efficient intelligent applications for embedded computing systems.</li>
</ul>

<h3>Title: Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Fei Zhou, Peng Wang, Lei Zhang, Zhenghua Chen, Wei Wei, Chen Ding, Guosheng Lin, Yanning Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01432">https://arxiv.org/abs/2411.01432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01432">https://arxiv.org/pdf/2411.01432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01432]] Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning(https://arxiv.org/abs/2411.01432)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Meta-learning offers a promising avenue for few-shot learning (FSL), enabling models to glean a generalizable feature embedding through episodic training on synthetic FSL tasks in a source domain. Yet, in practical scenarios where the target task diverges from that in the source domain, meta-learning based method is susceptible to over-fitting. To overcome this, we introduce a novel framework, Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning, which is crafted to comprehensively exploit the cross-domain transferable image prior that each image can be decomposed into complementary low-frequency content details and high-frequency robust structural characteristics. Motivated by this insight, we propose to decompose each query image into its high-frequency and low-frequency components, and parallel incorporate them into the feature embedding network to enhance the final category prediction. More importantly, we introduce a feature reconstruction prior and a prediction consistency prior to separately encourage the consistency of the intermediate feature as well as the final category prediction between the original query image and its decomposed frequency components. This allows for collectively guiding the network's meta-learning process with the aim of learning generalizable image feature embeddings, while not introducing any extra computational cost in the inference phase. Our framework establishes new state-of-the-art results on multiple cross-domain few-shot learning benchmarks.</li>
</ul>

<h3>Title: HOBBIT: A Mixed Precision Expert Offloading System for Fast MoE Inference</h3>
<ul>
<li><strong>Authors: </strong>Peng Tang, Jiacheng Liu, Xiaofeng Hou, Yifei Pu, Jing Wang, Pheng-Ann Heng, Chao Li, Minyi Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01433">https://arxiv.org/abs/2411.01433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01433">https://arxiv.org/pdf/2411.01433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01433]] HOBBIT: A Mixed Precision Expert Offloading System for Fast MoE Inference(https://arxiv.org/abs/2411.01433)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Mixture-of-Experts (MoE) architecture has demonstrated significant advantages in the era of Large Language Models (LLMs), offering enhanced capabilities with reduced inference costs. However, deploying MoE-based LLMs on memoryconstrained edge devices remains challenging due to their substantial memory requirements. While existing expertoffloading methods alleviate the memory requirements, they often incur significant expert-loading costs or compromise model accuracy. We present HOBBIT, a mixed precision expert offloading system to enable flexible and efficient MoE inference. Our key insight is that dynamically replacing less critical cache-miss experts with low precision versions can substantially reduce expert-loading latency while preserving model accuracy. HOBBIT introduces three innovative techniques that map the natural hierarchy of MoE computation: (1) a token-level dynamic expert loading mechanism, (2) a layer-level adaptive expert prefetching technique, and (3) a sequence-level multidimensional expert caching policy. These innovations fully leverage the benefits of mixedprecision expert inference. By implementing HOBBIT on top of the renowned LLM inference framework this http URL, we evaluate its performance across different edge devices with representative MoE models. The results demonstrate that HOBBIT achieves up to a 9.93x speedup in decoding compared to state-of-the-art MoE offloading systems.</li>
</ul>

<h3>Title: Activating Self-Attention for Multi-Scene Absolute Pose Regression</h3>
<ul>
<li><strong>Authors: </strong>Miso Lee, Jihwan Kim, Jae-Pil Heo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01443">https://arxiv.org/abs/2411.01443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01443">https://arxiv.org/pdf/2411.01443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01443]] Activating Self-Attention for Multi-Scene Absolute Pose Regression(https://arxiv.org/abs/2411.01443)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multi-scene absolute pose regression addresses the demand for fast and memory-efficient camera pose estimation across various real-world environments. Nowadays, transformer-based model has been devised to regress the camera pose directly in multi-scenes. Despite its potential, transformer encoders are underutilized due to the collapsed self-attention map, having low representation capacity. This work highlights the problem and investigates it from a new perspective: distortion of query-key embedding space. Based on the statistical analysis, we reveal that queries and keys are mapped in completely different spaces while only a few keys are blended into the query region. This leads to the collapse of the self-attention map as all queries are considered similar to those few keys. Therefore, we propose simple but effective solutions to activate self-attention. Concretely, we present an auxiliary loss that aligns queries and keys, preventing the distortion of query-key space and encouraging the model to find global relations by self-attention. In addition, the fixed sinusoidal positional encoding is adopted instead of undertrained learnable one to reflect appropriate positional clues into the inputs of self-attention. As a result, our approach resolves the aforementioned problem effectively, thus outperforming existing methods in both outdoor and indoor scenes.</li>
</ul>

<h3>Title: A Visual Question Answering Method for SAR Ship: Breaking the Requirement for Multimodal Dataset Construction and Model Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Fei Wang, Chengcheng Chen, Hongyu Chen, Yugang Chang, Weiming Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01445">https://arxiv.org/abs/2411.01445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01445">https://arxiv.org/pdf/2411.01445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01445]] A Visual Question Answering Method for SAR Ship: Breaking the Requirement for Multimodal Dataset Construction and Model Fine-Tuning(https://arxiv.org/abs/2411.01445)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current visual question answering (VQA) tasks often require constructing multimodal datasets and fine-tuning visual language models, which demands significant time and resources. This has greatly hindered the application of VQA to downstream tasks, such as ship information analysis based on Synthetic Aperture Radar (SAR) imagery. To address this challenge, this letter proposes a novel VQA approach that integrates object detection networks with visual language models, specifically designed for analyzing ships in SAR images. This integration aims to enhance the capabilities of VQA systems, focusing on aspects such as ship location, density, and size analysis, as well as risk behavior detection. Initially, we conducted baseline experiments using YOLO networks on two representative SAR ship detection datasets, SSDD and HRSID, to assess each model's performance in terms of detection accuracy. Based on these results, we selected the optimal model, YOLOv8n, as the most suitable detection network for this task. Subsequently, leveraging the vision-language model Qwen2-VL, we designed and implemented a VQA task specifically for SAR scenes. This task employs the ship location and size information output by the detection network to generate multi-turn dialogues and scene descriptions for SAR imagery. Experimental results indicate that this method not only enables fundamental SAR scene question-answering without the need for additional datasets or fine-tuning but also dynamically adapts to complex, multi-turn dialogue requirements, demonstrating robust semantic understanding and adaptability.</li>
</ul>

<h3>Title: Privacy-Preserving Customer Churn Prediction Model in the Context of Telecommunication Industry</h3>
<ul>
<li><strong>Authors: </strong>Joydeb Kumar Sana, M Sohel Rahman, M Saifur Rahman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01447">https://arxiv.org/abs/2411.01447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01447">https://arxiv.org/pdf/2411.01447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01447]] Privacy-Preserving Customer Churn Prediction Model in the Context of Telecommunication Industry(https://arxiv.org/abs/2411.01447)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, generative</a></li>
<li><strong>Abstract: </strong>Data is the main fuel of a successful machine learning model. A dataset may contain sensitive individual records e.g. personal health records, financial data, industrial information, etc. Training a model using this sensitive data has become a new privacy concern when someone uses third-party cloud computing. Trained models also suffer privacy attacks which leads to the leaking of sensitive information of the training data. This study is conducted to preserve the privacy of training data in the context of customer churn prediction modeling for the telecommunications industry (TCI). In this work, we propose a framework for privacy-preserving customer churn prediction (PPCCP) model in the cloud environment. We have proposed a novel approach which is a combination of Generative Adversarial Networks (GANs) and adaptive Weight-of-Evidence (aWOE). Synthetic data is generated from GANs, and aWOE is applied on the synthetic training dataset before feeding the data to the classification algorithms. Our experiments were carried out using eight different machine learning (ML) classifiers on three openly accessible datasets from the telecommunication sector. We then evaluated the performance using six commonly employed evaluation metrics. In addition to presenting a data privacy analysis, we also performed a statistical significance test. The training and prediction processes achieve data privacy and the prediction classifiers achieve high prediction performance (87.1\% in terms of F-Measure for GANs-aWOE based Na\"ıve Bayes model). In contrast to earlier studies, our suggested approach demonstrates a prediction enhancement of up to 28.9\% and 27.9\% in terms of accuracy and F-measure, respectively.</li>
</ul>

<h3>Title: HiMemFormer: Hierarchical Memory-Aware Transformer for Multi-Agent Action Anticipation</h3>
<ul>
<li><strong>Authors: </strong>Zirui Wang, Xinran Zhao, Simon Stepputtis, Woojun Kim, Tongshuang Wu, Katia Sycara, Yaqi Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01455">https://arxiv.org/abs/2411.01455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01455">https://arxiv.org/pdf/2411.01455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01455]] HiMemFormer: Hierarchical Memory-Aware Transformer for Multi-Agent Action Anticipation(https://arxiv.org/abs/2411.01455)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding and predicting human actions has been a long-standing challenge and is a crucial measure of perception in robotics AI. While significant progress has been made in anticipating the future actions of individual agents, prior work has largely overlooked a key aspect of real-world human activity -- interactions. To address this gap in human-like forecasting within multi-agent environments, we present the Hierarchical Memory-Aware Transformer (HiMemFormer), a transformer-based model for online multi-agent action anticipation. HiMemFormer integrates and distributes global memory that captures joint historical information across all agents through a transformer framework, with a hierarchical local memory decoder that interprets agent-specific features based on these global representations using a coarse-to-fine strategy. In contrast to previous approaches, HiMemFormer uniquely hierarchically applies the global context with agent-specific preferences to avoid noisy or redundant information in multi-agent action anticipation. Extensive experiments on various multi-agent scenarios demonstrate the significant performance of HiMemFormer, compared with other state-of-the-art methods.</li>
</ul>

<h3>Title: Two-Timescale Model Caching and Resource Allocation for Edge-Enabled AI-Generated Content Services</h3>
<ul>
<li><strong>Authors: </strong>Zhang Liu, Hongyang Du, Xiangwang Hou, Lianfen Huang, Seyyedali Hosseinalipour, Dusit Niyato, Khaled Ben Letaief</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01458">https://arxiv.org/abs/2411.01458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01458">https://arxiv.org/pdf/2411.01458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01458]] Two-Timescale Model Caching and Resource Allocation for Edge-Enabled AI-Generated Content Services(https://arxiv.org/abs/2411.01458)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative AI (GenAI) has emerged as a transformative technology, enabling customized and personalized AI-generated content (AIGC) services. In this paper, we address challenges of edge-enabled AIGC service provisioning, which remain underexplored in the literature. These services require executing GenAI models with billions of parameters, posing significant obstacles to resource-limited wireless edge. We subsequently introduce the formulation of joint model caching and resource allocation for AIGC services to balance a trade-off between AIGC quality and latency metrics. We obtain mathematical relationships of these metrics with the computational resources required by GenAI models via experimentation. Afterward, we decompose the formulation into a model caching subproblem on a long-timescale and a resource allocation subproblem on a short-timescale. Since the variables to be solved are discrete and continuous, respectively, we leverage a double deep Q-network (DDQN) algorithm to solve the former subproblem and propose a diffusion-based deep deterministic policy gradient (D3PG) algorithm to solve the latter. The proposed D3PG algorithm makes an innovative use of diffusion models as the actor network to determine optimal resource allocation decisions. Consequently, we integrate these two learning methods within the overarching two-timescale deep reinforcement learning (T2DRL) algorithm, the performance of which is studied through comparative numerical simulations.</li>
</ul>

<h3>Title: Efficient Non-Exemplar Class-Incremental Learning with Retrospective Feature Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Liang Bai, Hong Song, Yucong Lin, Tianyu Fu, Deqiang Xiao, Danni Ai, Jingfan Fan, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01465">https://arxiv.org/abs/2411.01465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01465">https://arxiv.org/pdf/2411.01465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01465]] Efficient Non-Exemplar Class-Incremental Learning with Retrospective Feature Synthesis(https://arxiv.org/abs/2411.01465)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite the outstanding performance in many individual tasks, deep neural networks suffer from catastrophic forgetting when learning from continuous data streams in real-world scenarios. Current Non-Exemplar Class-Incremental Learning (NECIL) methods mitigate forgetting by storing a single prototype per class, which serves to inject previous information when sequentially learning new classes. However, these stored prototypes or their augmented variants often fail to simultaneously capture spatial distribution diversity and precision needed for representing old classes. Moreover, as the model acquires new knowledge, these prototypes gradually become outdated, making them less effective. To overcome these limitations, we propose a more efficient NECIL method that replaces prototypes with synthesized retrospective features for old classes. Specifically, we model each old class's feature space using a multivariate Gaussian distribution and generate deep representations by sampling from high-likelihood regions. Additionally, we introduce a similarity-based feature compensation mechanism that integrates generated old class features with similar new class features to synthesize robust retrospective representations. These retrospective features are then incorporated into our incremental learning framework to preserve the decision boundaries of previous classes while learning new ones. Extensive experiments on CIFAR-100, TinyImageNet, and ImageNet-Subset demonstrate that our method significantly improves the efficiency of non-exemplar class-incremental learning and achieves state-of-the-art performance.</li>
</ul>

<h3>Title: Exploring PCA-based feature representations of image pixels via CNN to enhance food image segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ying Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01469">https://arxiv.org/abs/2411.01469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01469">https://arxiv.org/pdf/2411.01469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01469]] Exploring PCA-based feature representations of image pixels via CNN to enhance food image segmentation(https://arxiv.org/abs/2411.01469)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>For open vocabulary recognition of ingredients in food images, segmenting the ingredients is a crucial step. This paper proposes a novel approach that explores PCA-based feature representations of image pixels using a convolutional neural network (CNN) to enhance segmentation. An internal clustering metric based on the silhouette score is defined to evaluate the clustering quality of various pixel-level feature representations generated by different feature maps derived from various CNN backbones. Using this metric, the paper explores optimal feature representation selection and suitable clustering methods for ingredient segmentation. Additionally, it is found that principal component (PC) maps derived from concatenations of backbone feature maps improve the clustering quality of pixel-level feature representations, resulting in stable segmentation outcomes. Notably, the number of selected eigenvalues can be used as the number of clusters to achieve good segmentation results. The proposed method performs well on the ingredient-labeled dataset FoodSeg103, achieving a mean Intersection over Union (mIoU) score of 0.5423. Importantly, the proposed method is unsupervised, and pixel-level feature representations from backbones are not fine-tuned on specific datasets. This demonstrates the flexibility, generalizability, and interpretability of the proposed method, while reducing the need for extensive labeled datasets.</li>
</ul>

<h3>Title: A Practical and Privacy-Preserving Framework for Real-World Large Language Model Services</h3>
<ul>
<li><strong>Authors: </strong>Yu Mao, Xueping Liao, Wei Liu, Anjia Yang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01471">https://arxiv.org/abs/2411.01471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01471">https://arxiv.org/pdf/2411.01471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01471]] A Practical and Privacy-Preserving Framework for Real-World Large Language Model Services(https://arxiv.org/abs/2411.01471)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated exceptional capabilities in text understanding and generation, and they are increasingly being utilized across various domains to enhance productivity. However, due to the high costs of training and maintaining these models, coupled with the fact that some LLMs are proprietary, individuals often rely on online AI as a Service (AIaaS) provided by LLM companies. This business model poses significant privacy risks, as service providers may exploit users' trace patterns and behavioral data. In this paper, we propose a practical and privacy-preserving framework that ensures user anonymity by preventing service providers from linking requests to the individuals who submit them. Our framework is built on partially blind signatures, which guarantee the unlinkability of user requests. Furthermore, we introduce two strategies tailored to both subscription-based and API-based service models, ensuring the protection of both users' privacy and service providers' interests. The framework is designed to integrate seamlessly with existing LLM systems, as it does not require modifications to the underlying architectures. Experimental results demonstrate that our framework incurs minimal computation and communication overhead, making it a feasible solution for real-world applications.</li>
</ul>

<h3>Title: Efficient Medical Image Retrieval Using DenseNet and FAISS for BIRADS Classification</h3>
<ul>
<li><strong>Authors: </strong>MD Shaikh Rahman, Feiroz Humayara, Syed Maudud E Rabbi, Muhammad Mahbubur Rashid</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01473">https://arxiv.org/abs/2411.01473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01473">https://arxiv.org/pdf/2411.01473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01473]] Efficient Medical Image Retrieval Using DenseNet and FAISS for BIRADS Classification(https://arxiv.org/abs/2411.01473)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>That datasets that are used in todays research are especially vast in the medical field. Different types of medical images such as X-rays, MRI, CT scan etc. take up large amounts of space. This volume of data introduces challenges like accessing and retrieving specific images due to the size of the database. An efficient image retrieval system is essential as the database continues to grow to save time and resources. In this paper, we propose an approach to medical image retrieval using DenseNet for feature extraction and use FAISS for similarity search. DenseNet is well-suited for feature extraction in complex medical images and FAISS enables efficient handling of high-dimensional data in large-scale datasets. Unlike existing methods focused solely on classification accuracy, our method prioritizes both retrieval speed and diagnostic relevance, addressing a critical gap in real-time case comparison for radiologists. We applied the classification of breast cancer images using the BIRADS system. We utilized DenseNet's powerful feature representation and FAISSs efficient indexing capabilities to achieve high precision and recall in retrieving relevant images for diagnosis. We experimented on a dataset of 2006 images from the Categorized Digital Database for Low Energy and Subtracted Contrast Enhanced Spectral Mammography (CDD-CESM) images available on The Cancer Imaging Archive (TCIA). Our method outperforms conventional retrieval techniques, achieving a precision of 80% at k=5 for BIRADS classification. The dataset includes annotated CESM images and medical reports, providing a comprehensive foundation for our research.</li>
</ul>

<h3>Title: DPCL-Diff: The Temporal Knowledge Graph Reasoning based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yukun Cao, Lisheng Wang, Luobing Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01477">https://arxiv.org/abs/2411.01477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01477">https://arxiv.org/pdf/2411.01477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01477]] DPCL-Diff: The Temporal Knowledge Graph Reasoning based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning(https://arxiv.org/abs/2411.01477)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Temporal knowledge graph (TKG) reasoning that infers future missing facts is an essential and challenging task. Predicting future events typically relies on closely related historical facts, yielding more accurate results for repetitive or periodic events. However, for future events with sparse historical interactions, the effectiveness of this method, which focuses on leveraging high-frequency historical information, diminishes. Recently, the capabilities of diffusion models in image generation have opened new opportunities for TKG reasoning. Therefore, we propose a graph node diffusion model with dual-domain periodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff) introduces noise into sparsely related events to simulate new events, generating high-quality data that better conforms to the actual distribution. This generative mechanism significantly enhances the model's ability to reason about new events. Additionally, the dual-domain periodic contrastive learning (DPCL) maps periodic and non-periodic event entities to Poincaré and Euclidean spaces, leveraging their characteristics to distinguish similar periodic events effectively. Experimental results on four public datasets demonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG models in event prediction, demonstrating our approach's effectiveness. This study also investigates the combined effectiveness of GNDiff and DPCL in TKG tasks.</li>
</ul>

<h3>Title: Teaching Models to Improve on Tape</h3>
<ul>
<li><strong>Authors: </strong>Liat Bezalel, Eyal Orgad, Amir Globerson</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01483">https://arxiv.org/abs/2411.01483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01483">https://arxiv.org/pdf/2411.01483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01483]] Teaching Models to Improve on Tape(https://arxiv.org/abs/2411.01483)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often struggle when prompted to generate content under specific constraints. However, in such cases it is often easy to check whether these constraints are satisfied or violated. Recent works have shown that LLMs can benefit from such ``corrective feedback''. Here we claim that this skill of LLMs can be significantly enhanced via training. We introduce an RL framework for teaching models to use such rewards, by simulating interaction sessions, and rewarding the model according to its ability to satisfy the constraints. We refer to our method as CORGI (Controlled Generation with RL for Guided Interaction), and evaluate it on a variety of controlled generation tasks using unlabeled training data. We find that CORGI consistently outperforms the baseline reinforcement learning method that does not incorporate conversational feedback. Furthermore, CORGI's interactive framework enables meta-learning, allowing the LLM to generalize better to guided interaction in new tasks. Our results clearly show that conversational optimization, when combined with reinforcement learning, significantly improves the effectiveness of LLMs in controlled generation contexts.</li>
</ul>

<h3>Title: Anomalous Client Detection in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Dipanwita Thakur, Antonella Guzzo, Giancarlo Fortino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01490">https://arxiv.org/abs/2411.01490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01490">https://arxiv.org/pdf/2411.01490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01490]] Anomalous Client Detection in Federated Learning(https://arxiv.org/abs/2411.01490)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL), with the growing IoT and edge computing, is seen as a promising solution for applications that are latency- and privacy-aware. However, due to the widespread dispersion of data across many clients, it is challenging to monitor client anomalies caused by malfunctioning devices or unexpected events. The majority of FL solutions now in use concentrate on the classification problem, ignoring situations in which anomaly detection may also necessitate privacy preservation and effectiveness. The system in federated learning is unable to manage the potentially flawed behavior of its clients completely. These behaviors include sharing arbitrary parameter values and causing a delay in convergence since clients are chosen at random without knowing the malfunctioning behavior of the client. Client selection is crucial in terms of the efficiency of the federated learning framework. The challenges such as client drift and handling slow clients with low computational capability are well-studied in FL. However, the detection of anomalous clients either for security or for overall performance in the FL frameworks is hardly studied in the literature. In this paper, we propose an anomaly client detection algorithm to overcome malicious client attacks and client drift in FL frameworks. Instead of random client selection, our proposed method utilizes anomaly client detection to remove clients from the FL framework, thereby enhancing the security and efficiency of the overall system. This proposed method improves the global model convergence in almost 50\% fewer communication rounds compared with widely used random client selection using the MNIST dataset.</li>
</ul>

<h3>Title: EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Ming Li, Jike Zhong, Tianle Chen, Yuxiang Lai, Konstantinos Psounis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01492">https://arxiv.org/abs/2411.01492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01492">https://arxiv.org/pdf/2411.01492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01492]] EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark(https://arxiv.org/abs/2411.01492)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies on large language models (LLMs) and large multimodal models (LMMs) have demonstrated promising skills in various domains including science and mathematics. However, their capability in more challenging and real-world related scenarios like engineering has not been systematically studied. To bridge this gap, we propose EEE-Bench, a multimodal benchmark aimed at assessing LMMs' capabilities in solving practical engineering tasks, using electrical and electronics engineering (EEE) as the testbed. Our benchmark consists of 2860 carefully curated problems spanning 10 essential subdomains such as analog circuits, control systems, etc. Compared to benchmarks in other domains, engineering problems are intrinsically 1) more visually complex and versatile and 2) less deterministic in solutions. Successful solutions to these problems often demand more-than-usual rigorous integration of visual and textual information as models need to understand intricate images like abstract circuits and system diagrams while taking professional instructions, making them excellent candidates for LMM evaluations. Alongside EEE-Bench, we provide extensive quantitative evaluations and fine-grained analysis of 17 widely-used open and closed-sourced LLMs and LMMs. Our results demonstrate notable deficiencies of current foundation models in EEE, with an average performance ranging from 19.48% to 46.78%. Finally, we reveal and explore a critical shortcoming in LMMs which we term laziness: the tendency to take shortcuts by relying on the text while overlooking the visual context when reasoning for technical image problems. In summary, we believe EEE-Bench not only reveals some noteworthy limitations of LMMs but also provides a valuable resource for advancing research on their application in practical engineering tasks, driving future improvements in their capability to handle complex, real-world scenarios.</li>
</ul>

<h3>Title: Sample-Efficient Alignment for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zichen Liu, Changyu Chen, Chao Du, Wee Sun Lee, Min Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01493">https://arxiv.org/abs/2411.01493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01493">https://arxiv.org/pdf/2411.01493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01493]] Sample-Efficient Alignment for LLMs(https://arxiv.org/abs/2411.01493)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study methods for efficiently aligning large language models (LLMs) with human preferences given budgeted online feedback. We first formulate the LLM alignment problem in the frame of contextual dueling bandits. This formulation, subsuming recent paradigms such as online RLHF and online DPO, inherently quests for sample-efficient algorithms that incorporate online active exploration. Leveraging insights from bandit theory, we introduce a unified algorithm based on Thompson sampling and highlight its applications in two distinct LLM alignment scenarios. The practical agent that efficiently implements this algorithm, named SEA (Sample-Efficient Alignment), is empirically validated through extensive experiments across three model scales (1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The results demonstrate that SEA achieves highly sample-efficient alignment with oracle's preferences, outperforming recent active exploration methods for LLMs. Additionally, we release the implementation of SEA together with an efficient codebase designed for online alignment of LLMs, aiming to accelerate future research in this field.</li>
</ul>

<h3>Title: Finding NeMo: Negative-mined Mosaic Augmentation for Referring Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Seongsu Ha, Chaeyun Kim, Donghwa Kim, Junho Lee, Sangho Lee, Joonseok Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01494">https://arxiv.org/abs/2411.01494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01494">https://arxiv.org/pdf/2411.01494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01494]] Finding NeMo: Negative-mined Mosaic Augmentation for Referring Image Segmentation(https://arxiv.org/abs/2411.01494)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Referring Image Segmentation is a comprehensive task to segment an object referred by a textual query from an image. In nature, the level of difficulty in this task is affected by the existence of similar objects and the complexity of the referring expression. Recent RIS models still show a significant performance gap between easy and hard scenarios. We pose that the bottleneck exists in the data, and propose a simple but powerful data augmentation method, Negative-mined Mosaic Augmentation (NeMo). This method augments a training image into a mosaic with three other negative images carefully curated by a pretrained multimodal alignment model, e.g., CLIP, to make the sample more challenging. We discover that it is critical to properly adjust the difficulty level, neither too ambiguous nor too trivial. The augmented training data encourages the RIS model to recognize subtle differences and relationships between similar visual entities and to concretely understand the whole expression to locate the right target better. Our approach shows consistent improvements on various datasets and models, verified by extensive experiments.</li>
</ul>

<h3>Title: Object segmentation from common fate: Motion energy processing enables human-like zero-shot generalization to random dot stimuli</h3>
<ul>
<li><strong>Authors: </strong>Matthias Tangemann, Matthias Kümmerer, Matthias Bethge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01505">https://arxiv.org/abs/2411.01505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01505">https://arxiv.org/pdf/2411.01505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01505]] Object segmentation from common fate: Motion energy processing enables human-like zero-shot generalization to random dot stimuli(https://arxiv.org/abs/2411.01505)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Humans excel at detecting and segmenting moving objects according to the Gestalt principle of "common fate". Remarkably, previous works have shown that human perception generalizes this principle in a zero-shot fashion to unseen textures or random dots. In this work, we seek to better understand the computational basis for this capability by evaluating a broad range of optical flow models and a neuroscience inspired motion energy model for zero-shot figure-ground segmentation of random dot stimuli. Specifically, we use the extensively validated motion energy model proposed by Simoncelli and Heeger in 1998 which is fitted to neural recordings in cortex area MT. We find that a cross section of 40 deep optical flow models trained on different datasets struggle to estimate motion patterns in random dot videos, resulting in poor figure-ground segmentation performance. Conversely, the neuroscience-inspired model significantly outperforms all optical flow models on this task. For a direct comparison to human perception, we conduct a psychophysical study using a shape identification task as a proxy to measure human segmentation performance. All state-of-the-art optical flow models fall short of human performance, but only the motion energy model matches human capability. This neuroscience-inspired model successfully addresses the lack of human-like zero-shot generalization to random dot stimuli in current computer vision models, and thus establishes a compelling link between the Gestalt psychology of human object perception and cortical motion processing in the brain. Code, models and datasets are available at this https URL</li>
</ul>

<h3>Title: FaceDig: Automated tool for placing landmarks on facial portraits for geometric morphometrics users</h3>
<ul>
<li><strong>Authors: </strong>Karel Kleisner, Jaroslav Trnka, Petr Turecek</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01508">https://arxiv.org/abs/2411.01508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01508">https://arxiv.org/pdf/2411.01508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01508]] FaceDig: Automated tool for placing landmarks on facial portraits for geometric morphometrics users(https://arxiv.org/abs/2411.01508)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Landmark digitization is essential in geometric morphometrics, enabling the quantification of biological shapes, such as facial structures, for in-depth morphological analysis. Traditional landmarking, which identifies specific anatomical points, can be complemented by semilandmarks when precise locations are challenging to define. However, manual placement of numerous landmarks is time-consuming and prone to human error, leading to inconsistencies across studies. To address this, we introduce FaceDig, an AI-powered tool designed to automate landmark placement with human-level precision, focusing on anatomically sound facial points. FaceDig is open-source and integrates seamlessly with analytical platforms like R and Python. It was trained using one of the largest and most ethnically diverse face datasets, applying a landmark configuration optimized for 2D enface photographs. Our results demonstrate that FaceDig provides reliable landmark coordinates, comparable to those placed manually by experts. The tool's output is compatible with the widely-used TpsDig2 software, facilitating adoption and ensuring consistency across studies. Users are advised to work with standardized facial images and visually inspect the results for potential corrections. Despite the growing preference for 3D morphometrics, 2D facial photographs remain valuable due to their cultural and practical significance. Future enhancements to FaceDig will include support for profile views, further expanding its utility. By offering a standardized approach to landmark placement, FaceDig promotes reproducibility in facial morphology research and provides a robust alternative to existing 2D tools.</li>
</ul>

<h3>Title: SinaTools: Open Source Toolkit for Arabic Natural Language Processing</h3>
<ul>
<li><strong>Authors: </strong>Tymaa Hammouda, Mustafa Jarrar, Mohammed Khalilia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01523">https://arxiv.org/abs/2411.01523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01523">https://arxiv.org/pdf/2411.01523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01523]] SinaTools: Open Source Toolkit for Arabic Natural Language Processing(https://arxiv.org/abs/2411.01523)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We introduce SinaTools, an open-source Python package for Arabic natural language processing and understanding. SinaTools is a unified package allowing people to integrate it into their system workflow, offering solutions for various tasks such as flat and nested Named Entity Recognition (NER), fully-flagged Word Sense Disambiguation (WSD), Semantic Relatedness, Synonymy Extractions and Evaluation, Lemmatization, Part-of-speech Tagging, Root Tagging, and additional helper utilities such as corpus processing, text stripping methods, and diacritic-aware word matching. This paper presents SinaTools and its benchmarking results, demonstrating that SinaTools outperforms all similar tools on the aforementioned tasks, such as Flat NER (87.33%), Nested NER (89.42%), WSD (82.63%), Semantic Relatedness (0.49 Spearman rank), Lemmatization (90.5%), POS tagging (97.5%), among others. SinaTools can be downloaded from (this https URL).</li>
</ul>

<h3>Title: Enhancing LLM Evaluations: The Garbling Trick</h3>
<ul>
<li><strong>Authors: </strong>William F. Bradley</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01533">https://arxiv.org/abs/2411.01533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01533">https://arxiv.org/pdf/2411.01533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01533]] Enhancing LLM Evaluations: The Garbling Trick(https://arxiv.org/abs/2411.01533)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) become increasingly powerful, traditional evaluation metrics tend to saturate, making it challenging to distinguish between models based on their performance. We propose a general method to transform existing LLM evaluations into a series of progressively more difficult tasks. These enhanced evaluations emphasize reasoning capabilities and can reveal relative performance differences that are not apparent in the original assessments. To demonstrate the effectiveness of our approach, we create a new multiple-choice test corpus, extend it into a family of evaluations, and assess a collection of LLMs. Our results offer insights into the comparative reasoning abilities of these models, particularly highlighting distinctions between OpenAI's o1-preview and Google's gemini-pro-1.5-002.</li>
</ul>

<h3>Title: Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction</h3>
<ul>
<li><strong>Authors: </strong>Haotong Du, Quanming Yao, Juzheng Zhang, Yang Liu, Zhen Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01535">https://arxiv.org/abs/2411.01535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01535">https://arxiv.org/pdf/2411.01535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01535]] Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction(https://arxiv.org/abs/2411.01535)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Subgraph-based methods have proven to be effective and interpretable in predicting drug-drug interactions (DDIs), which are essential for medical practice and drug development. Subgraph selection and encoding are critical stages in these methods, yet customizing these components remains underexplored due to the high cost of manual adjustments. In this study, inspired by the success of neural architecture search (NAS), we propose a method to search for data-specific components within subgraph-based frameworks. Specifically, we introduce extensive subgraph selection and encoding spaces that account for the diverse contexts of drug interactions in DDI prediction. To address the challenge of large search spaces and high sampling costs, we design a relaxation mechanism that uses an approximation strategy to efficiently explore optimal subgraph configurations. This approach allows for robust exploration of the search space. Extensive experiments demonstrate the effectiveness and superiority of the proposed method, with the discovered subgraphs and encoding functions highlighting the model's adaptability.</li>
</ul>

<h3>Title: LLMs and the Madness of Crowds</h3>
<ul>
<li><strong>Authors: </strong>William F. Bradley</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01539">https://arxiv.org/abs/2411.01539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01539">https://arxiv.org/pdf/2411.01539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01539]] LLMs and the Madness of Crowds(https://arxiv.org/abs/2411.01539)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate the patterns of incorrect answers produced by large language models (LLMs) during evaluation. These errors exhibit highly non-intuitive behaviors unique to each model. By analyzing these patterns, we measure the similarities between LLMs and construct a taxonomy that categorizes them based on their error correlations. Our findings reveal that the incorrect responses are not randomly distributed but systematically correlated across models, providing new insights into the underlying structures and relationships among LLMs.</li>
</ul>

<h3>Title: FactorizePhys: Matrix Factorization for Multidimensional Attention in Remote Physiological Sensing</h3>
<ul>
<li><strong>Authors: </strong>Jitesh Joshi, Sos S. Agaian, Youngjun Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01542">https://arxiv.org/abs/2411.01542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01542">https://arxiv.org/pdf/2411.01542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01542]] FactorizePhys: Matrix Factorization for Multidimensional Attention in Remote Physiological Sensing(https://arxiv.org/abs/2411.01542)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Remote photoplethysmography (rPPG) enables non-invasive extraction of blood volume pulse signals through imaging, transforming spatial-temporal data into time series signals. Advances in end-to-end rPPG approaches have focused on this transformation where attention mechanisms are crucial for feature extraction. However, existing methods compute attention disjointly across spatial, temporal, and channel dimensions. Here, we propose the Factorized Self-Attention Module (FSAM), which jointly computes multidimensional attention from voxel embeddings using nonnegative matrix factorization. To demonstrate FSAM's effectiveness, we developed FactorizePhys, an end-to-end 3D-CNN architecture for estimating blood volume pulse signals from raw video frames. Our approach adeptly factorizes voxel embeddings to achieve comprehensive spatial, temporal, and channel attention, enhancing performance of generic signal extraction tasks. Furthermore, we deploy FSAM within an existing 2D-CNN-based rPPG architecture to illustrate its versatility. FSAM and FactorizePhys are thoroughly evaluated against state-of-the-art rPPG methods, each representing different types of architecture and attention mechanism. We perform ablation studies to investigate the architectural decisions and hyperparameters of FSAM. Experiments on four publicly available datasets and intuitive visualization of learned spatial-temporal features substantiate the effectiveness of FSAM and enhanced cross-dataset generalization in estimating rPPG signals, suggesting its broader potential as a multidimensional attention mechanism. The code is accessible at this https URL.</li>
</ul>

<h3>Title: Towards Small Object Editing: A Benchmark Dataset and A Training-Free Approach</h3>
<ul>
<li><strong>Authors: </strong>Qihe Pan, Zhen Zhao, Zicheng Wang, Sifan Long, Yiming Wu, Wei Ji, Haoran Liang, Ronghua Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01545">https://arxiv.org/abs/2411.01545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01545">https://arxiv.org/pdf/2411.01545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01545]] Towards Small Object Editing: A Benchmark Dataset and A Training-Free Approach(https://arxiv.org/abs/2411.01545)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>A plethora of text-guided image editing methods has recently been developed by leveraging the impressive capabilities of large-scale diffusion-based generative models especially Stable Diffusion. Despite the success of diffusion models in producing high-quality images, their application to small object generation has been limited due to difficulties in aligning cross-modal attention maps between text and these objects. Our approach offers a training-free method that significantly mitigates this alignment issue with local and global attention guidance , enhancing the model's ability to accurately render small objects in accordance with textual descriptions. We detail the methodology in our approach, emphasizing its divergence from traditional generation techniques and highlighting its advantages. What's more important is that we also provide~\textit{SOEBench} (Small Object Editing), a standardized benchmark for quantitatively evaluating text-based small object generation collected from \textit{MSCOCO} and \textit{OpenImage}. Preliminary results demonstrate the effectiveness of our method, showing marked improvements in the fidelity and accuracy of small object generation compared to existing models. This advancement not only contributes to the field of AI and computer vision but also opens up new possibilities for applications in various industries where precise image generation is critical. We will release our dataset on our project page: \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Analysis of regularized federated learning</h3>
<ul>
<li><strong>Authors: </strong>Langming Liu, Dingxuan Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01548">https://arxiv.org/abs/2411.01548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01548">https://arxiv.org/pdf/2411.01548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01548]] Analysis of regularized federated learning(https://arxiv.org/abs/2411.01548)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is an efficient machine learning tool for dealing with heterogeneous big data and privacy protection. Federated learning methods with regularization can control the level of communications between the central and local machines. Stochastic gradient descent is often used for implementing such methods on heterogeneous big data, to reduce the communication costs. In this paper, we consider such an algorithm called Loopless Local Gradient Descent which has advantages in reducing the expected communications by controlling a probability level. We improve the method by allowing flexible step sizes and carry out novel analysis for the convergence of the algorithm in a non-convex setting in addition to the standard strongly convex setting. In the non-convex setting, we derive rates of convergence when the smooth objective function satisfies a Polyak-Łojasiewicz condition. When the objective function is strongly convex, a sufficient and necessary condition for the convergence in expectation is presented.</li>
</ul>

<h3>Title: Are LLMs good pragmatic speakers?</h3>
<ul>
<li><strong>Authors: </strong>Mingyue Jian, Siddharth Narayanaswamy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01562">https://arxiv.org/abs/2411.01562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01562">https://arxiv.org/pdf/2411.01562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01562]] Are LLMs good pragmatic speakers?(https://arxiv.org/abs/2411.01562)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are trained on data assumed to include natural language pragmatics, but do they actually behave like pragmatic speakers? We attempt to answer this question using the Rational Speech Act (RSA) framework, which models pragmatic reasoning in human communication. Using the paradigm of a reference game constructed from the TUNA corpus, we score candidate referential utterances in both a state-of-the-art LLM (Llama3-8B-Instruct) and in the RSA model, comparing and contrasting these scores. Given that RSA requires defining alternative utterances and a truth-conditional meaning function, we explore such comparison for different choices of each of these requirements. We find that while scores from the LLM have some positive correlation with those from RSA, there isn't sufficient evidence to claim that it behaves like a pragmatic speaker. This initial study paves way for further targeted efforts exploring different models and settings, including human-subject evaluation, to see if LLMs truly can, or be made to, behave like pragmatic speakers.</li>
</ul>

<h3>Title: ParseCaps: An Interpretable Parsing Capsule Network for Medical Image Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Geng, Jiaming Wang, Jun Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01564">https://arxiv.org/abs/2411.01564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01564">https://arxiv.org/pdf/2411.01564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01564]] ParseCaps: An Interpretable Parsing Capsule Network for Medical Image Diagnosis(https://arxiv.org/abs/2411.01564)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Deep learning has excelled in medical image classification, but its clinical application is limited by poor interpretability. Capsule networks, known for encoding hierarchical relationships and spatial features, show potential in addressing this issue. Nevertheless, traditional capsule networks often underperform due to their shallow structures, and deeper variants lack hierarchical architectures, thereby compromising interpretability. This paper introduces a novel capsule network, ParseCaps, which utilizes the sparse axial attention routing and parse convolutional capsule layer to form a parse-tree-like structure, enhancing both depth and interpretability. Firstly, sparse axial attention routing optimizes connections between child and parent capsules, as well as emphasizes the weight distribution across instantiation parameters of parent capsules. Secondly, the parse convolutional capsule layer generates capsule predictions aligning with the parse tree. Finally, based on the loss design that is effective whether concept ground truth exists or not, ParseCaps advances interpretability by associating each dimension of the global capsule with a comprehensible concept, thereby facilitating clinician trust and understanding of the model's classification results. Experimental results on CE-MRI, PH$^2$, and Derm7pt datasets show that ParseCaps not only outperforms other capsule network variants in classification accuracy, redundancy reduction and robustness, but also provides interpretable explanations, regardless of the availability of concept labels.</li>
</ul>

<h3>Title: SQL Injection Jailbreak: a structural disaster of large language models</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01565">https://arxiv.org/abs/2411.01565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01565">https://arxiv.org/pdf/2411.01565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01565]] SQL Injection Jailbreak: a structural disaster of large language models(https://arxiv.org/abs/2411.01565)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, the rapid development of large language models (LLMs) has brought new vitality to the various domains and generated substantial social and economic benefits. However, the swift advancement of LLMs has introduced new security vulnerabilities. Jailbreak, a form of attack that induces LLMs to output harmful content through carefully crafted prompts, poses a challenge to the safe and trustworthy development of LLMs. Previous jailbreak attack methods primarily exploited the internal capabilities of the model. Among them, one category leverages the model's implicit capabilities for jailbreak attacks, where the attacker is unaware of the exact reasons for the attack's success. The other category utilizes the model's explicit capabilities for jailbreak attacks, where the attacker understands the reasons for the attack's success. For example, these attacks exploit the model's abilities in coding, contextual learning, or understanding ASCII characters. However, these earlier jailbreak attacks have certain limitations, as they only exploit the inherent capabilities of the model. In this paper, we propose a novel jailbreak method, SQL Injection Jailbreak (SIJ), which utilizes the construction of input prompts by LLMs to inject jailbreak information into user prompts, enabling successful jailbreak of the LLMs. Our SIJ method achieves nearly 100\% attack success rates on five well-known open-source LLMs in the context of AdvBench, while incurring lower time costs compared to previous methods. More importantly, SIJ reveals a new vulnerability in LLMs that urgently needs to be addressed. To this end, we propose a defense method called Self-Reminder-Key and demonstrate its effectiveness through experiments. Our code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Conditional Controllable Image Fusion</h3>
<ul>
<li><strong>Authors: </strong>Bing Cao, Xingxin Xu, Pengfei Zhu, Qilong Wang, Qinghua Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01573">https://arxiv.org/abs/2411.01573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01573">https://arxiv.org/pdf/2411.01573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01573]] Conditional Controllable Image Fusion(https://arxiv.org/abs/2411.01573)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Image fusion aims to integrate complementary information from multiple input images acquired through various sources to synthesize a new fused image. Existing methods usually employ distinct constraint designs tailored to specific scenes, forming fixed fusion paradigms. However, this data-driven fusion approach is challenging to deploy in varying scenarios, especially in rapidly changing environments. To address this issue, we propose a conditional controllable fusion (CCF) framework for general image fusion tasks without specific training. Due to the dynamic differences of different samples, our CCF employs specific fusion constraints for each individual in practice. Given the powerful generative capabilities of the denoising diffusion model, we first inject the specific constraints into the pre-trained DDPM as adaptive fusion conditions. The appropriate conditions are dynamically selected to ensure the fusion process remains responsive to the specific requirements in each reverse diffusion stage. Thus, CCF enables conditionally calibrating the fused images step by step. Extensive experiments validate our effectiveness in general fusion tasks across diverse scenarios against the competing methods without additional training.</li>
</ul>

<h3>Title: Decision Trees for Interpretable Clusters in Mixture Models and Deep Representations</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Fleissner, Maedeh Zarvandi, Debarghya Ghoshdastidar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01576">https://arxiv.org/abs/2411.01576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01576">https://arxiv.org/pdf/2411.01576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01576]] Decision Trees for Interpretable Clusters in Mixture Models and Deep Representations(https://arxiv.org/abs/2411.01576)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Decision Trees are one of the backbones of explainable machine learning, and often serve as interpretable alternatives to black-box models. Traditionally utilized in the supervised setting, there has recently also been a surge of interest in decision trees for unsupervised learning. While several works with worst-case guarantees on the clustering cost have appeared, these results are distribution-agnostic, and do not give insight into when decision trees can actually recover the underlying distribution of the data (up to some small error). In this paper, we therefore introduce the notion of an explainability-to-noise ratio for mixture models, formalizing the intuition that well-clustered data can indeed be explained well using a decision tree. We propose an algorithm that takes as input a mixture model and constructs a suitable tree in data-independent time. Assuming sub-Gaussianity of the mixture components, we prove upper and lower bounds on the error rate of the resulting decision tree. In addition, we demonstrate how concept activation vectors can be used to extend explainable clustering to neural networks. We empirically demonstrate the efficacy of our approach on standard tabular and image datasets.</li>
</ul>

<h3>Title: Federated Learning Clients Clustering with Adaptation to Data Drifts</h3>
<ul>
<li><strong>Authors: </strong>Minghao Li (1), Dmitrii Avdiukhin (2), Rana Shahout (1), Nikita Ivkin (3), Vladimir Braverman (4), Minlan Yu (1) ((1) Harvard University, (2) Northwestern University, (3) Amazon, (4) Rice University)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01580">https://arxiv.org/abs/2411.01580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01580">https://arxiv.org/pdf/2411.01580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01580]] Federated Learning Clients Clustering with Adaptation to Data Drifts(https://arxiv.org/abs/2411.01580)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables deep learning model training across edge devices and protects user privacy by retaining raw data locally. Data heterogeneity in client distributions slows model convergence and leads to plateauing with reduced precision. Clustered FL solutions address this by grouping clients with statistically similar data and training models for each cluster. However, maintaining consistent client similarity within each group becomes challenging when data drifts occur, significantly impacting model accuracy. In this paper, we introduce Fielding, a clustered FL framework that handles data drifts promptly with low overheads. Fielding detects drifts on all clients and performs selective label distribution-based re-clustering to balance cluster optimality and model performance, remaining robust to malicious clients and varied heterogeneity degrees. Our evaluations show that Fielding improves model final accuracy by 1.9%-5.9% and reaches target accuracies 1.16x-2.61x faster.</li>
</ul>

<h3>Title: Trustworthy Federated Learning: Privacy, Security, and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Chunlu Chen, Ji Liu, Haowen Tan, Xingjian Li, Kevin I-Kai Wang, Peng Li, Kouichi Sakurai, Dejing Dou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01583">https://arxiv.org/abs/2411.01583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01583">https://arxiv.org/pdf/2411.01583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01583]] Trustworthy Federated Learning: Privacy, Security, and Beyond(https://arxiv.org/abs/2411.01583)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>While recent years have witnessed the advancement in big data and Artificial Intelligence (AI), it is of much importance to safeguard data privacy and security. As an innovative approach, Federated Learning (FL) addresses these concerns by facilitating collaborative model training across distributed data sources without transferring raw data. However, the challenges of robust security and privacy across decentralized networks catch significant attention in dealing with the distributed data in FL. In this paper, we conduct an extensive survey of the security and privacy issues prevalent in FL, underscoring the vulnerability of communication links and the potential for cyber threats. We delve into various defensive strategies to mitigate these risks, explore the applications of FL across different sectors, and propose research directions. We identify the intricate security challenges that arise within the FL frameworks, aiming to contribute to the development of secure and efficient FL systems.</li>
</ul>

<h3>Title: RS-MoE: Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Hui Lin, Danfeng Hong, Shuhang Ge, Chuyao Luo, Kai Jiang, Hao Jin, Congcong Wen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01595">https://arxiv.org/abs/2411.01595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01595">https://arxiv.org/pdf/2411.01595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01595]] RS-MoE: Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering(https://arxiv.org/abs/2411.01595)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Remote Sensing Image Captioning (RSIC) presents unique challenges and plays a critical role in applications. Traditional RSIC methods often struggle to produce rich and diverse descriptions. Recently, with advancements in VLMs, efforts have emerged to integrate these models into the remote sensing domain and to introduce descriptive datasets specifically designed to enhance VLM training. This paper proposes RS-MoE, a first Mixture of Expert based VLM specifically customized for remote sensing domain. Unlike traditional MoE models, the core of RS-MoE is the MoE Block, which incorporates a novel Instruction Router and multiple lightweight Large Language Models (LLMs) as expert models. The Instruction Router is designed to generate specific prompts tailored for each corresponding LLM, guiding them to focus on distinct aspects of the RSIC task. This design not only allows each expert LLM to concentrate on a specific subset of the task, thereby enhancing the specificity and accuracy of the generated captions, but also improves the scalability of the model by facilitating parallel processing of sub-tasks. Additionally, we present a two-stage training strategy for tuning our RS-MoE model to prevent performance degradation due to sparsity. We fine-tuned our model on the RSICap dataset using our proposed training strategy. Experimental results on the RSICap dataset, along with evaluations on other traditional datasets where no additional fine-tuning was applied, demonstrate that our model achieves state-of-the-art performance in generating precise and contextually relevant captions. Notably, our RS-MoE-1B variant achieves performance comparable to 13B VLMs, demonstrating the efficiency of our model design. Moreover, our model demonstrates promising generalization capabilities by consistently achieving state-of-the-art performance on the Remote Sensing Visual Question Answering (RSVQA) task.</li>
</ul>

<h3>Title: OSAD: Open-Set Aircraft Detection in SAR Images</h3>
<ul>
<li><strong>Authors: </strong>Xiayang Xiao, Zhuoxuan Li, Haipeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01597">https://arxiv.org/abs/2411.01597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01597">https://arxiv.org/pdf/2411.01597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01597]] OSAD: Open-Set Aircraft Detection in SAR Images(https://arxiv.org/abs/2411.01597)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current mainstream SAR image object detection methods still lack robustness when dealing with unknown objects in open environments. Open-set detection aims to enable detectors trained on a closed set to detect all known objects and identify unknown objects in open-set environments. The key challenges are how to improve the generalization to potential unknown objects and reduce the empirical classification risk of known categories under strong supervision. To address these challenges, a novel open-set aircraft detector for SAR images is proposed, named Open-Set Aircraft Detection (OSAD), which is equipped with three dedicated components: global context modeling (GCM), location quality-driven pseudo labeling generation (LPG), and prototype contrastive learning (PCL). GCM effectively enhances the network's representation of objects by attention maps which is formed through the capture of long sequential positional relationships. LPG leverages clues about object positions and shapes to optimize localization quality, avoiding overfitting to known category information and enhancing generalization to potential unknown objects. PCL employs prototype-based contrastive encoding loss to promote instance-level intra-class compactness and inter-class variance, aiming to minimize the overlap between known and unknown distributions and reduce the empirical classification risk of known categories. Extensive experiments have demonstrated that the proposed method can effectively detect unknown objects and exhibit competitive performance without compromising closed-set performance. The highest absolute gain which ranges from 0 to 18.36% can be achieved on the average precision of unknown objects.</li>
</ul>

<h3>Title: DreamPolish: Domain Score Distillation With Progressive Geometry Generation</h3>
<ul>
<li><strong>Authors: </strong>Yean Cheng, Ziqi Cai, Ming Ding, Wendi Zheng, Shiyu Huang, Yuxiao Dong, Jie Tang, Boxin Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01602">https://arxiv.org/abs/2411.01602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01602">https://arxiv.org/pdf/2411.01602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01602]] DreamPolish: Domain Score Distillation With Progressive Geometry Generation(https://arxiv.org/abs/2411.01602)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a view-conditioned diffusion prior in the novel sampled views, which often leads to undesired artifacts in the geometric surface, we incorporate an additional normal estimator to polish the geometry details, conditioned on viewpoints with varying field-of-views. We propose to add a surface polishing stage with only a few training steps, which can effectively refine the artifacts attributed to limited guidance from previous stages and produce 3D objects with more desirable geometry. The key topic of texture generation using pretrained text-to-image models is to find a suitable domain in the vast latent distribution of these models that contains photorealistic and consistent renderings. In the texture generation phase, we introduce a novel score distillation objective, namely domain score distillation (DSD), to guide neural representations toward such a domain. We draw inspiration from the classifier-free guidance (CFG) in textconditioned image generation tasks and show that CFG and variational distribution guidance represent distinct aspects in gradient guidance and are both imperative domains for the enhancement of texture quality. Extensive experiments show our proposed model can produce 3D assets with polished surfaces and photorealistic textures, outperforming existing state-of-the-art methods.</li>
</ul>

<h3>Title: Large Language Model Supply Chain: Open Problems From the Security Perspective</h3>
<ul>
<li><strong>Authors: </strong>Qiang Hu, Xiaofei Xie, Sen Chen, Lei Ma</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01604">https://arxiv.org/abs/2411.01604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01604">https://arxiv.org/pdf/2411.01604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01604]] Large Language Model Supply Chain: Open Problems From the Security Perspective(https://arxiv.org/abs/2411.01604)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) is changing the software development paradigm and has gained huge attention from both academia and industry. Researchers and developers collaboratively explore how to leverage the powerful problem-solving ability of LLMs for specific domain tasks. Due to the wide usage of LLM-based applications, e.g., ChatGPT, multiple works have been proposed to ensure the security of LLM systems. However, a comprehensive understanding of the entire processes of LLM system construction (the LLM supply chain) is crucial but relevant works are limited. More importantly, the security issues hidden in the LLM SC which could highly impact the reliable usage of LLMs are lack of exploration. Existing works mainly focus on assuring the quality of LLM from the model level, security assurance for the entire LLM SC is ignored. In this work, we take the first step to discuss the potential security risks in each component as well as the integration between components of LLM SC. We summarize 12 security-related risks and provide promising guidance to help build safer LLM systems. We hope our work can facilitate the evolution of artificial general intelligence with secure LLM ecosystems.</li>
</ul>

<h3>Title: GITSR: Graph Interaction Transformer-based Scene Representation for Multi Vehicle Collaborative Decision-making</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Hu, Lijun Zhang, Dejian Meng, Ye Han, Lisha Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.MA, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01608">https://arxiv.org/abs/2411.01608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01608">https://arxiv.org/pdf/2411.01608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01608]] GITSR: Graph Interaction Transformer-based Scene Representation for Multi Vehicle Collaborative Decision-making(https://arxiv.org/abs/2411.01608)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this study, we propose GITSR, an effective framework for Graph Interaction Transformer-based Scene Representation for multi-vehicle collaborative decision-making in intelligent transportation system. In the context of mixed traffic where Connected Automated Vehicles (CAVs) and Human Driving Vehicles (HDVs) coexist, in order to enhance the understanding of the environment by CAVs to improve decision-making capabilities, this framework focuses on efficient scene representation and the modeling of spatial interaction behaviors of traffic states. We first extract features of the driving environment based on the background of intelligent networking. Subsequently, the local scene representation, which is based on the agent-centric and dynamic occupation grid, is calculated by the Transformer module. Besides, feasible region of the map is captured through the multi-head attention mechanism to reduce the collision of vehicles. Notably, spatial interaction behaviors, based on motion information, are modeled as graph structures and extracted via Graph Neural Network (GNN). Ultimately, the collaborative decision-making among multiple vehicles is formulated as a Markov Decision Process (MDP), with driving actions output by Reinforcement Learning (RL) algorithms. Our algorithmic validation is executed within the extremely challenging scenario of highway off-ramp task, thereby substantiating the superiority of agent-centric approach to scene representation. Simulation results demonstrate that the GITSR method can not only effectively capture scene representation but also extract spatial interaction data, outperforming the baseline method across various comparative metrics.</li>
</ul>

<h3>Title: ANNE: Adaptive Nearest Neighbors and Eigenvector-based Sample Selection for Robust Learning with Noisy Labels</h3>
<ul>
<li><strong>Authors: </strong>Filipe R. Cordeiro, Gustavo Carneiro</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01613">https://arxiv.org/abs/2411.01613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01613">https://arxiv.org/pdf/2411.01613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01613]] ANNE: Adaptive Nearest Neighbors and Eigenvector-based Sample Selection for Robust Learning with Noisy Labels(https://arxiv.org/abs/2411.01613)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>An important stage of most state-of-the-art (SOTA) noisy-label learning methods consists of a sample selection procedure that classifies samples from the noisy-label training set into noisy-label or clean-label subsets. The process of sample selection typically consists of one of the two approaches: loss-based sampling, where high-loss samples are considered to have noisy labels, or feature-based sampling, where samples from the same class tend to cluster together in the feature space and noisy-label samples are identified as anomalies within those clusters. Empirically, loss-based sampling is robust to a wide range of noise rates, while feature-based sampling tends to work effectively in particular scenarios, e.g., the filtering of noisy instances via their eigenvectors (FINE) sampling exhibits greater robustness in scenarios with low noise rates, and the K nearest neighbor (KNN) sampling mitigates better high noise-rate problems. This paper introduces the Adaptive Nearest Neighbors and Eigenvector-based (ANNE) sample selection methodology, a novel approach that integrates loss-based sampling with the feature-based sampling methods FINE and Adaptive KNN to optimize performance across a wide range of noise rate scenarios. ANNE achieves this integration by first partitioning the training set into high-loss and low-loss sub-groups using loss-based sampling. Subsequently, within the low-loss subset, sample selection is performed using FINE, while the high-loss subset employs Adaptive KNN for effective sample selection. We integrate ANNE into the noisy-label learning state of the art (SOTA) method SSR+, and test it on CIFAR-10/-100 (with symmetric, asymmetric and instance-dependent noise), Webvision and ANIMAL-10, where our method shows better accuracy than the SOTA in most experiments, with a competitive training time.</li>
</ul>

<h3>Title: VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Zhang, Jin Gao, Fudong Ge, Guan Luo, Bing Li, Zhaoxiang Zhang, Haibin Ling, Weiming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01618">https://arxiv.org/abs/2411.01618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01618">https://arxiv.org/pdf/2411.01618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01618]] VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization(https://arxiv.org/abs/2411.01618)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Bird's-eye-view (BEV) map layout estimation requires an accurate and full understanding of the semantics for the environmental elements around the ego car to make the results coherent and realistic. Due to the challenges posed by occlusion, unfavourable imaging conditions and low resolution, \emph{generating} the BEV semantic maps corresponding to corrupted or invalid areas in the perspective view (PV) is appealing very recently. \emph{The question is how to align the PV features with the generative models to facilitate the map estimation}. In this paper, we propose to utilize a generative model similar to the Vector Quantized-Variational AutoEncoder (VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in the tokenized discrete space. Thanks to the obtained BEV tokens accompanied with a codebook embedding encapsulating the semantics for different BEV elements in the groundtruth maps, we are able to directly align the sparse backbone image features with the obtained BEV tokens from the discrete representation learning based on a specialized token decoder module, and finally generate high-quality BEV maps with the BEV codebook embedding serving as a bridge between PV and BEV. We evaluate the BEV map layout estimation performance of our model, termed VQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 mean IoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU for monocular evaluation on Argoverse, which all set a new record for this map layout estimation task. The code and models are available on \url{this https URL}.</li>
</ul>

<h3>Title: FilterNet: Harnessing Frequency Filters for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Kun Yi, Jingru Fei, Qi Zhang, Hui He, Shufeng Hao, Defu Lian, Wei Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01623">https://arxiv.org/abs/2411.01623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01623">https://arxiv.org/pdf/2411.01623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01623]] FilterNet: Harnessing Frequency Filters for Time Series Forecasting(https://arxiv.org/abs/2411.01623)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While numerous forecasters have been proposed using different network architectures, the Transformer-based models have state-of-the-art performance in time series forecasting. However, forecasters based on Transformers are still suffering from vulnerability to high-frequency signals, efficiency in computation, and bottleneck in full-spectrum utilization, which essentially are the cornerstones for accurately predicting time series with thousands of points. In this paper, we explore a novel perspective of enlightening signal processing for deep time series forecasting. Inspired by the filtering process, we introduce one simple yet effective network, namely FilterNet, built upon our proposed learnable frequency filters to extract key informative temporal patterns by selectively passing or attenuating certain components of time series signals. Concretely, we propose two kinds of learnable filters in the FilterNet: (i) Plain shaping filter, that adopts a universal frequency kernel for signal filtering and temporal modeling; (ii) Contextual shaping filter, that utilizes filtered frequencies examined in terms of its compatibility with input signals for dependency learning. Equipped with the two filters, FilterNet can approximately surrogate the linear and attention mappings widely adopted in time series literature, while enjoying superb abilities in handling high-frequency noises and utilizing the whole frequency spectrum that is beneficial for forecasting. Finally, we conduct extensive experiments on eight time series forecasting benchmarks, and experimental results have demonstrated our superior performance in terms of both effectiveness and efficiency compared with state-of-the-art methods. Code is available at this repository: $\href{this https URL}{\small\text{this https URL.}}$</li>
</ul>

<h3>Title: PreCM: The Padding-based Rotation Equivariant Convolution Mode for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Xu, Huazhen Liu, Huilin Xiong, Wenxian Yu, Tao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01624">https://arxiv.org/abs/2411.01624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01624">https://arxiv.org/pdf/2411.01624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01624]] PreCM: The Padding-based Rotation Equivariant Convolution Mode for Semantic Segmentation(https://arxiv.org/abs/2411.01624)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation is an important branch of image processing and computer vision. With the popularity of deep learning, various deep semantic segmentation networks have been proposed for pixel-level classification and segmentation tasks. However, the imaging angles are often arbitrary in real world, such as water body images in remote sensing, and capillary and polyp images in medical field, and we usually cannot obtain prior orientation information to guide these networks to extract more effective features. Additionally, learning the features of objects with multiple orientation information is also challenging, as most CNN-based semantic segmentation networks do not have rotation equivariance to resist the disturbance from orientation information. To address the same, in this paper, we first establish a universal convolution-group framework to more fully utilize the orientation information and make the networks rotation equivariant. Then, we mathematically construct the padding-based rotation equivariant convolution mode (PreCM), which can be used not only for multi-scale images and convolution kernels, but also as a replacement component to replace multiple convolutions, like dilated convolution, transposed convolution, variable stride convolution, etc. In order to verify the realization of rotation equivariance, a new evaluation metric named rotation difference (RD) is finally proposed. The experiments carried out on the datesets Satellite Images of Water Bodies, DRIVE and Floodnet show that the PreCM-based networks can achieve better segmentation performance than the original and data augmentation-based networks. In terms of the average RD value, the former is 0% and the latter two are respectively 7.0503% and 3.2606%. Last but not least, PreCM also effectively enhances the robustness of networks to rotation perturbations.</li>
</ul>

<h3>Title: Lorentz-Equivariant Quantum Graph Neural Network for High-Energy Physics</h3>
<ul>
<li><strong>Authors: </strong>Md Abrar Jahin, Md. Akmol Masud, Md Wahiduzzaman Suva, M. F. Mridha, Nilanjan Dey</a></li>
<li><strong>Subjects: </strong>cs.LG, hep-ex, physics.ins-det</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01641">https://arxiv.org/abs/2411.01641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01641">https://arxiv.org/pdf/2411.01641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01641]] Lorentz-Equivariant Quantum Graph Neural Network for High-Energy Physics(https://arxiv.org/abs/2411.01641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid data surge from the high-luminosity Large Hadron Collider introduces critical computational challenges requiring novel approaches for efficient data processing in particle physics. Quantum machine learning, with its capability to leverage the extensive Hilbert space of quantum hardware, offers a promising solution. However, current quantum graph neural networks (GNNs) lack robustness to noise and are often constrained by fixed symmetry groups, limiting adaptability in complex particle interaction modeling. This paper demonstrates that replacing the Lorentz Group Equivariant Block modules in LorentzNet with a dressed quantum circuit significantly enhances performance despite using nearly 5.5 times fewer parameters. Our Lorentz-Equivariant Quantum Graph Neural Network (Lorentz-EQGNN) achieved 74.00% test accuracy and an AUC of 87.38% on the Quark-Gluon jet tagging dataset, outperforming the classical and quantum GNNs with a reduced architecture using only 4 qubits. On the Electron-Photon dataset, Lorentz-EQGNN reached 67.00% test accuracy and an AUC of 68.20%, demonstrating competitive results with just 800 training samples. Evaluation of our model on generic MNIST and FashionMNIST datasets confirmed Lorentz-EQGNN's efficiency, achieving 88.10% and 74.80% test accuracy, respectively. Ablation studies validated the impact of quantum components on performance, with notable improvements in background rejection rates over classical counterparts. These results highlight Lorentz-EQGNN's potential for immediate applications in noise-resilient jet tagging, event classification, and broader data-scarce HEP tasks.</li>
</ul>

<h3>Title: Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination</h3>
<ul>
<li><strong>Authors: </strong>Md Abrar Jahin, Md. Akmol Masud, M. F. Mridha, Nilanjan Dey</a></li>
<li><strong>Subjects: </strong>cs.LG, hep-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01642">https://arxiv.org/abs/2411.01642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01642">https://arxiv.org/pdf/2411.01642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01642]] Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination(https://arxiv.org/abs/2411.01642)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In high-energy physics, particle jet tagging plays a pivotal role in distinguishing quark from gluon jets using data from collider experiments. While graph-based deep learning methods have advanced this task beyond traditional feature-engineered approaches, the complex data structure and limited labeled samples present ongoing challenges. However, existing contrastive learning (CL) frameworks struggle to leverage rationale-aware augmentations effectively, often lacking supervision signals that guide the extraction of salient features and facing computational efficiency issues such as high parameter counts. In this study, we demonstrate that integrating a quantum rationale generator (QRG) within our proposed Quantum Rationale-aware Graph Contrastive Learning (QRGCL) framework significantly enhances jet discrimination performance, reducing reliance on labeled data and capturing discriminative features. Evaluated on the quark-gluon jet dataset, QRGCL achieves an AUC score of 77.53% while maintaining a compact architecture of only 45 QRG parameters, outperforming classical, quantum, and hybrid GCL and GNN benchmarks. These results highlight QRGCL's potential to advance jet tagging and other complex classification tasks in high-energy physics, where computational efficiency and feature extraction limitations persist.</li>
</ul>

<h3>Title: Achieving Domain-Independent Certified Robustness via Knowledge Continuity</h3>
<ul>
<li><strong>Authors: </strong>Alan Sun, Chiyu Ma, Kenneth Ge, Soroush Vosoughi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01644">https://arxiv.org/abs/2411.01644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01644">https://arxiv.org/pdf/2411.01644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01644]] Achieving Domain-Independent Certified Robustness via Knowledge Continuity(https://arxiv.org/abs/2411.01644)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present knowledge continuity, a novel definition inspired by Lipschitz continuity which aims to certify the robustness of neural networks across input domains (such as continuous and discrete domains in vision and language, respectively). Most existing approaches that seek to certify robustness, especially Lipschitz continuity, lie within the continuous domain with norm and distribution-dependent guarantees. In contrast, our proposed definition yields certification guarantees that depend only on the loss function and the intermediate learned metric spaces of the neural network. These bounds are independent of domain modality, norms, and distribution. We further demonstrate that the expressiveness of a model class is not at odds with its knowledge continuity. This implies that achieving robustness by maximizing knowledge continuity should not theoretically hinder inferential performance. Finally, to complement our theoretical results, we present several applications of knowledge continuity such as regularization, a certification algorithm, and show that knowledge continuity can be used to localize vulnerable components of a neural network.</li>
</ul>

<h3>Title: Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Gjergji Kasneci, Enkelejda Kasneci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01645">https://arxiv.org/abs/2411.01645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01645">https://arxiv.org/pdf/2411.01645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01645]] Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers(https://arxiv.org/abs/2411.01645)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Feature engineering is crucial for optimizing machine learning model performance, particularly in tabular data classification tasks. Leveraging advancements in natural language processing, this study presents a systematic approach to enrich tabular datasets with features derived from large language model embeddings. Through a comprehensive ablation study on diverse datasets, we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers, including Random Forest, XGBoost, and CatBoost. Results indicate that integrating embeddings with traditional numerical and categorical features often enhances predictive performance, especially on datasets with class imbalance or limited features and samples, such as UCI Adult, Heart Disease, Titanic, and Pima Indian Diabetes, with improvements particularly notable in XGBoost and CatBoost classifiers. Additionally, feature importance analysis reveals that LLM-derived features frequently rank among the most impactful for the predictions. This study provides a structured approach to embedding-based feature enrichment and illustrates its benefits in ensemble learning for tabular data.</li>
</ul>

<h3>Title: Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01647">https://arxiv.org/abs/2411.01647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01647">https://arxiv.org/pdf/2411.01647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01647]] Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation(https://arxiv.org/abs/2411.01647)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Medical video generation models are expected to have a profound impact on the healthcare industry, including but not limited to medical education and training, surgical planning, and simulation. Current video diffusion models typically build on image diffusion architecture by incorporating temporal operations (such as 3D convolution and temporal attention). Although this approach is effective, its oversimplification limits spatio-temporal performance and consumes substantial computational resources. To counter this, we propose Medical Simulation Video Generator (MedSora), which incorporates three key elements: i) a video diffusion framework integrates the advantages of attention and Mamba, balancing low computational load with high-quality video generation, ii) an optical flow representation alignment method that implicitly enhances attention to inter-frame pixels, and iii) a video variational autoencoder (VAE) with frequency compensation addresses the information loss of medical features that occurs when transforming pixel space into latent features and then back to pixel frames. Extensive experiments and applications demonstrate that MedSora exhibits superior visual quality in generating medical videos, outperforming the most advanced baseline methods. Further results and code are available at this https URL</li>
</ul>

<h3>Title: Degradation-Aware Residual-Conditioned Optimal Transport for Unified Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Xiaole Tang, Xiang Gu, Xiaoyi He, Xin Hu, Jian Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01656">https://arxiv.org/abs/2411.01656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01656">https://arxiv.org/pdf/2411.01656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01656]] Degradation-Aware Residual-Conditioned Optimal Transport for Unified Image Restoration(https://arxiv.org/abs/2411.01656)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>All-in-one image restoration has emerged as a practical and promising low-level vision task for real-world applications. In this context, the key issue lies in how to deal with different types of degraded images simultaneously. In this work, we present a Degradation-Aware Residual-Conditioned Optimal Transport (DA-RCOT) approach that models (all-in-one) image restoration as an optimal transport (OT) problem for unpaired and paired settings, introducing the transport residual as a degradation-specific cue for both the transport cost and the transport map. Specifically, we formalize image restoration with a residual-guided OT objective by exploiting the degradation-specific patterns of the Fourier residual in the transport cost. More crucially, we design the transport map for restoration as a two-pass DA-RCOT map, in which the transport residual is computed in the first pass and then encoded as multi-scale residual embeddings to condition the second-pass restoration. This conditioning process injects intrinsic degradation knowledge (e.g., degradation type and level) and structural information from the multi-scale residual embeddings into the OT map, which thereby can dynamically adjust its behaviors for all-in-one restoration. Extensive experiments across five degradations demonstrate the favorable performance of DA-RCOT as compared to state-of-the-art methods, in terms of distortion measures, perceptual quality, and image structure preservation. Notably, DA-RCOT delivers superior adaptability to real-world scenarios even with multiple degradations and shows distinctive robustness to both degradation levels and the number of degradations.</li>
</ul>

<h3>Title: Unlocking the Theory Behind Scaling 1-Bit Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Majid Daliri, Zhao Song, Chiwun Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CC, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01663">https://arxiv.org/abs/2411.01663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01663">https://arxiv.org/pdf/2411.01663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01663]] Unlocking the Theory Behind Scaling 1-Bit Neural Networks(https://arxiv.org/abs/2411.01663)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an impressive combination of efficiency and performance that rivals traditional LLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the performance of these 1-bit LLMs progressively improves as the number of parameters increases, hinting at the potential existence of a Scaling Law for 1-bit Neural Networks. In this paper, we present the first theoretical result that rigorously establishes this scaling law for 1-bit models. We prove that, despite the constraint of weights restricted to $\{-1, +1\}$, the dynamics of model training inevitably align with kernel behavior as the network width grows. This theoretical breakthrough guarantees convergence of the 1-bit model to an arbitrarily small loss as width increases. Furthermore, we introduce the concept of the generalization difference, defined as the gap between the outputs of 1-bit networks and their full-precision counterparts, and demonstrate that this difference maintains a negligible level as network width scales. Building on the work of Kaplan et al. (2020), we conclude by examining how the training loss scales as a power-law function of the model size, dataset size, and computational resources utilized for training. Our findings underscore the promising potential of scaling 1-bit neural networks, suggesting that int1 could become the standard in future neural network precision.</li>
</ul>

<h3>Title: GraphXForm: Graph transformer for computer-aided molecular design with application to extraction</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Pirnay, Jan G. Rittig, Alexander B. Wolf, Martin Grohe, Jakob Burger, Alexander Mitsos, Dominik G. Grimm</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01667">https://arxiv.org/abs/2411.01667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01667">https://arxiv.org/pdf/2411.01667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01667]] GraphXForm: Graph transformer for computer-aided molecular design with application to extraction(https://arxiv.org/abs/2411.01667)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, generative</a></li>
<li><strong>Abstract: </strong>Generative deep learning has become pivotal in molecular design for drug discovery and materials science. A widely used paradigm is to pretrain neural networks on string representations of molecules and fine-tune them using reinforcement learning on specific objectives. However, string-based models face challenges in ensuring chemical validity and enforcing structural constraints like the presence of specific substructures. We propose to instead combine graph-based molecular representations, which can naturally ensure chemical validity, with transformer architectures, which are highly expressive and capable of modeling long-range dependencies between atoms. Our approach iteratively modifies a molecular graph by adding atoms and bonds, which ensures chemical validity and facilitates the incorporation of structural constraints. We present GraphXForm, a decoder-only graph transformer architecture, which is pretrained on existing compounds and then fine-tuned using a new training algorithm that combines elements of the deep cross-entropy method with self-improvement learning from language modeling, allowing stable fine-tuning of deep transformers with many layers. We evaluate GraphXForm on two solvent design tasks for liquid-liquid extraction, showing that it outperforms four state-of-the-art molecular design techniques, while it can flexibly enforce structural constraints or initiate the design from existing molecular structures.</li>
</ul>

<h3>Title: Robust Neural Processes for Noisy Data</h3>
<ul>
<li><strong>Authors: </strong>Chen Shapira, Dan Rosenbaum</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01670">https://arxiv.org/abs/2411.01670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01670">https://arxiv.org/pdf/2411.01670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01670]] Robust Neural Processes for Noisy Data(https://arxiv.org/abs/2411.01670)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Models that adapt their predictions based on some given contexts, also known as in-context learning, have become ubiquitous in recent years. We propose to study the behavior of such models when data is contaminated by noise. Towards this goal we use the Neural Processes (NP) framework, as a simple and rigorous way to learn a distribution over functions, where predictions are based on a set of context points. Using this framework, we find that the models that perform best on clean data, are different than the models that perform best on noisy data. Specifically, models that process the context using attention, are more severely affected by noise, leading to in-context overfitting. We propose a simple method to train NP models that makes them more robust to noisy data. Experiments on 1D functions and 2D image datasets demonstrate that our method leads to models that outperform all other NP models for all noise levels.</li>
</ul>

<h3>Title: Autoformulation of Mathematical Optimization Models Using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Nicolás Astorga, Tennison Liu, Yuanzhang Xiao, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01679">https://arxiv.org/abs/2411.01679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01679">https://arxiv.org/pdf/2411.01679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01679]] Autoformulation of Mathematical Optimization Models Using LLMs(https://arxiv.org/abs/2411.01679)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mathematical optimization is fundamental to decision-making across diverse domains, from operations research to healthcare. Yet, translating real-world problems into optimization models remains a formidable challenge, often demanding specialized expertise. This paper formally introduces the concept of $\textbf{autoformulation}$ -- an automated approach to creating optimization models from natural language descriptions for commercial solvers. We identify the three core challenges of autoformulation: (1) defining the vast, problem-dependent hypothesis space, (2) efficiently searching this space under uncertainty, and (3) evaluating formulation correctness (ensuring a formulation accurately represents the problem). To address these challenges, we introduce a novel method leveraging $\textit{Large Language Models}$ (LLMs) within a $\textit{Monte-Carlo Tree Search}$ framework. This approach systematically explores the space of possible formulations by exploiting the hierarchical nature of optimization modeling. LLMs serve two key roles: as dynamic formulation hypothesis generators and as evaluators of formulation correctness. To enhance search efficiency, we introduce a pruning technique to remove trivially equivalent formulations. Empirical evaluations across benchmarks containing linear and mixed-integer programming problems demonstrate our method's superior performance. Additionally, we observe significant efficiency gains from employing LLMs for correctness evaluation and from our pruning techniques.</li>
</ul>

<h3>Title: ROAD-Waymo: Action Awareness at Scale for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Salman Khan, Izzeddin Teeti, Reza Javanmard Alitappeh, Mihaela C. Stoian, Eleonora Giunchiglia, Gurkirt Singh, Andrew Bradley, Fabio Cuzzolin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01683">https://arxiv.org/abs/2411.01683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01683">https://arxiv.org/pdf/2411.01683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01683]] ROAD-Waymo: Action Awareness at Scale for Autonomous Driving(https://arxiv.org/abs/2411.01683)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Autonomous Vehicle (AV) perception systems require more than simply seeing, via e.g., object detection or scene segmentation. They need a holistic understanding of what is happening within the scene for safe interaction with other road users. Few datasets exist for the purpose of developing and training algorithms to comprehend the actions of other road users. This paper presents ROAD-Waymo, an extensive dataset for the development and benchmarking of techniques for agent, action, location and event detection in road scenes, provided as a layer upon the (US) Waymo Open dataset. Considerably larger and more challenging than any existing dataset (and encompassing multiple cities), it comes with 198k annotated video frames, 54k agent tubes, 3.9M bounding boxes and a total of 12.4M labels. The integrity of the dataset has been confirmed and enhanced via a novel annotation pipeline designed for automatically identifying violations of requirements specifically designed for this dataset. As ROAD-Waymo is compatible with the original (UK) ROAD dataset, it provides the opportunity to tackle domain adaptation between real-world road scenarios in different countries within a novel benchmark: ROAD++.</li>
</ul>

<h3>Title: Mitigating Matching Biases Through Score Calibration</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Hossein Moslemi, Mostafa Milani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01685">https://arxiv.org/abs/2411.01685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01685">https://arxiv.org/pdf/2411.01685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01685]] Mitigating Matching Biases Through Score Calibration(https://arxiv.org/abs/2411.01685)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Record matching, the task of identifying records that correspond to the same real-world entities across databases, is critical for data integration in domains like healthcare, finance, and e-commerce. While traditional record matching models focus on optimizing accuracy, fairness issues, such as demographic disparities in model performance, have attracted increasing attention. Biased outcomes in record matching can result in unequal error rates across demographic groups, raising ethical and legal concerns. Existing research primarily addresses fairness at specific decision thresholds, using bias metrics like Demographic Parity (DP), Equal Opportunity (EO), and Equalized Odds (EOD) differences. However, threshold-specific metrics may overlook cumulative biases across varying thresholds. In this paper, we adapt fairness metrics traditionally applied in regression models to evaluate cumulative bias across all thresholds in record matching. We propose a novel post-processing calibration method, leveraging optimal transport theory and Wasserstein barycenters, to balance matching scores across demographic groups. This approach treats any matching model as a black box, making it applicable to a wide range of models without access to their training data. Our experiments demonstrate the effectiveness of the calibration method in reducing demographic parity difference in matching scores. To address limitations in reducing EOD and EO differences, we introduce a conditional calibration method, which empirically achieves fairness across widely used benchmarks and state-of-the-art matching methods. This work provides a comprehensive framework for fairness-aware record matching, setting the foundation for more equitable data integration processes.</li>
</ul>

<h3>Title: UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sejoon Oh, Yiqiao Jin, Megha Sharma, Donghyun Kim, Eric Ma, Gaurav Verma, Srijan Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01703">https://arxiv.org/abs/2411.01703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01703">https://arxiv.org/pdf/2411.01703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01703]] UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models(https://arxiv.org/abs/2411.01703)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have revolutionized vision-language understanding but are vulnerable to multimodal jailbreak attacks, where adversaries meticulously craft inputs to elicit harmful or inappropriate responses. We propose UniGuard, a novel multimodal safety guardrail that jointly considers the unimodal and cross-modal harmful signals. UniGuard is trained such that the likelihood of generating harmful responses in a toxic corpus is minimized, and can be seamlessly applied to any input prompt during inference with minimal computational costs. Extensive experiments demonstrate the generalizability of UniGuard across multiple modalities and attack strategies. It demonstrates impressive generalizability across multiple state-of-the-art MLLMs, including LLaVA, Gemini Pro, GPT-4, MiniGPT-4, and InstructBLIP, thereby broadening the scope of our solution.</li>
</ul>

<h3>Title: Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors</h3>
<ul>
<li><strong>Authors: </strong>Yuefeng Peng, Junda Wang, Hong Yu, Amir Houmansadr</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01705">https://arxiv.org/abs/2411.01705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01705">https://arxiv.org/pdf/2411.01705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01705]] Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors(https://arxiv.org/abs/2411.01705)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant advancements, large language models (LLMs) still struggle with providing accurate answers when lacking domain-specific or up-to-date knowledge. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external knowledge bases, but it also introduces new attack surfaces. In this paper, we investigate data extraction attacks targeting the knowledge databases of RAG systems. We demonstrate that previous attacks on RAG largely depend on the instruction-following capabilities of LLMs, and that simple fine-tuning can reduce the success rate of such attacks to nearly zero. This makes these attacks impractical since fine-tuning is a common practice when deploying LLMs in specific domains. To further reveal the vulnerability, we propose to backdoor RAG, where a small portion of poisoned data is injected during the fine-tuning phase to create a backdoor within the LLM. When this compromised LLM is integrated into a RAG system, attackers can exploit specific triggers in prompts to manipulate the LLM to leak documents from the retrieval database. By carefully designing the poisoned data, we achieve both verbatim and paraphrased document extraction. We show that with only 3\% poisoned data, our method achieves an average success rate of 79.7\% in verbatim extraction on Llama2-7B, with a ROUGE-L score of 64.21, and a 68.6\% average success rate in paraphrased extraction, with an average ROUGE score of 52.6 across four datasets. These results underscore the privacy risks associated with the supply chain when deploying RAG systems.</li>
</ul>

<h3>Title: Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups</h3>
<ul>
<li><strong>Authors: </strong>Răzvan-Alexandru Smădu, David-Gabriel Ion, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01706">https://arxiv.org/abs/2411.01706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01706">https://arxiv.org/pdf/2411.01706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01706]] Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups(https://arxiv.org/abs/2411.01706)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Complex Word Identification (CWI) is an essential step in the lexical simplification task and has recently become a task on its own. Some variations of this binary classification task have emerged, such as lexical complexity prediction (LCP) and complexity evaluation of multi-word expressions (MWE). Large language models (LLMs) recently became popular in the Natural Language Processing community because of their versatility and capability to solve unseen tasks in zero/few-shot settings. Our work investigates LLM usage, specifically open-source models such as Llama 2, Llama 3, and Vicuna v1.5, and closed-source, such as ChatGPT-3.5-turbo and GPT-4o, in the CWI, LCP, and MWE settings. We evaluate zero-shot, few-shot, and fine-tuning settings and show that LLMs struggle in certain conditions or achieve comparable results against existing methods. In addition, we provide some views on meta-learning combined with prompt learning. In the end, we conclude that the current state of LLMs cannot or barely outperform existing methods, which are usually much smaller.</li>
</ul>

<h3>Title: SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Dennis Fucci, Marco Gaido, Beatrice Savoldi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01710">https://arxiv.org/abs/2411.01710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01710">https://arxiv.org/pdf/2411.01710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01710]] SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation(https://arxiv.org/abs/2411.01710)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Spurred by the demand for interpretable models, research on eXplainable AI for language technologies has experienced significant growth, with feature attribution methods emerging as a cornerstone of this progress. While prior work in NLP explored such methods for classification tasks and textual applications, explainability intersecting generation and speech is lagging, with existing techniques failing to account for the autoregressive nature of state-of-the-art models and to provide fine-grained, phonetically meaningful explanations. We address this gap by introducing Spectrogram Perturbation for Explainable Speech-to-text Generation (SPES), a feature attribution technique applicable to sequence generation tasks with autoregressive models. SPES provides explanations for each predicted token based on both the input spectrogram and the previously generated tokens. Extensive evaluation on speech recognition and translation demonstrates that SPES generates explanations that are faithful and plausible to humans.</li>
</ul>

<h3>Title: Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Junjiao Tian, Chengyue Huang, Zsolt Kira</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01713">https://arxiv.org/abs/2411.01713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01713">https://arxiv.org/pdf/2411.01713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01713]] Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models(https://arxiv.org/abs/2411.01713)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern optimizers such as AdamW, equipped with momentum and adaptive learning rate, are designed to escape local minima and explore the vast parameter space. This exploration is beneficial for finding good loss basins when training from scratch. It is not necessarily ideal when resuming from a powerful foundation model because it can lead to large deviations from the pre-trained initialization and, consequently, worse robustness and generalization. At the same time, strong regularization on all parameters can lead to under-fitting. We hypothesize that selectively regularizing the parameter space is the key to fitting and retraining the pre-trained knowledge. This paper proposes a new weight decay technique, Selective Projection Decay (SPD), that selectively imposes a strong penalty on certain layers while allowing others to change freely. Intuitively, SPD expands and contracts the parameter search space for layers with consistent and inconsistent loss reduction, respectively. Experimentally, when equipped with SPD, Adam consistently provides better in-distribution generalization and out-of-distribution robustness performance on multiple popular vision and language benchmarks. Code available at~\url{this https URL}</li>
</ul>

<h3>Title: A General Recipe for Contractive Graph Neural Networks -- Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Maya Bechler-Speicher, Moshe Eliasof</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01717">https://arxiv.org/abs/2411.01717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01717">https://arxiv.org/pdf/2411.01717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01717]] A General Recipe for Contractive Graph Neural Networks -- Technical Report(https://arxiv.org/abs/2411.01717)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have gained significant popularity for learning representations of graph-structured data due to their expressive power and scalability. However, despite their success in domains such as social network analysis, recommendation systems, and bioinformatics, GNNs often face challenges related to stability, generalization, and robustness to noise and adversarial attacks. Regularization techniques have shown promise in addressing these challenges by controlling model complexity and improving robustness. Building on recent advancements in contractive GNN architectures, this paper presents a novel method for inducing contractive behavior in any GNN through SVD regularization. By deriving a sufficient condition for contractiveness in the update step and applying constraints on network parameters, we demonstrate the impact of SVD regularization on the Lipschitz constant of GNNs. Our findings highlight the role of SVD regularization in enhancing the stability and generalization of GNNs, contributing to the development of more robust graph-based learning algorithms dynamics.</li>
</ul>

<h3>Title: Learning from Convolution-based Unlearnable Datastes</h3>
<ul>
<li><strong>Authors: </strong>Dohyun Kim, Pedro Sandoval-Segura</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01742">https://arxiv.org/abs/2411.01742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01742">https://arxiv.org/pdf/2411.01742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01742]] Learning from Convolution-based Unlearnable Datastes(https://arxiv.org/abs/2411.01742)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>The construction of large datasets for deep learning has raised concerns regarding unauthorized use of online data, leading to increased interest in protecting data from third-parties who want to use it for training. The Convolution-based Unlearnable DAtaset (CUDA) method aims to make data unlearnable by applying class-wise blurs to every image in the dataset so that neural networks learn relations between blur kernels and labels, as opposed to informative features for classifying clean data. In this work, we evaluate whether CUDA data remains unlearnable after image sharpening and frequency filtering, finding that this combination of simple transforms improves the utility of CUDA data for training. In particular, we observe a substantial increase in test accuracy over adversarial training for models trained with CUDA unlearnable data from CIFAR-10, CIFAR-100, and ImageNet-100. In training models to high accuracy using unlearnable data, we underscore the need for ongoing refinement in data poisoning techniques to ensure data privacy. Our method opens new avenues for enhancing the robustness of unlearnable datasets by highlighting that simple methods such as sharpening and frequency filtering are capable of breaking convolution-based unlearnable datasets.</li>
</ul>

<h3>Title: Rotation Perturbation Robustness in Point Cloud Analysis: A Perspective of Manifold Distillation</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Xu, Huazhen Liu, Feiming Wei, Huilin Xiong, Wenxian Yu, Tao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01748">https://arxiv.org/abs/2411.01748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01748">https://arxiv.org/pdf/2411.01748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01748]] Rotation Perturbation Robustness in Point Cloud Analysis: A Perspective of Manifold Distillation(https://arxiv.org/abs/2411.01748)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Point cloud is often regarded as a discrete sampling of Riemannian manifold and plays a pivotal role in the 3D image interpretation. Particularly, rotation perturbation, an unexpected small change in rotation caused by various factors (like equipment offset, system instability, measurement errors and so on), can easily lead to the inferior results in point cloud learning tasks. However, classical point cloud learning methods are sensitive to rotation perturbation, and the existing networks with rotation robustness also have much room for improvements in terms of performance and noise tolerance. Given these, this paper remodels the point cloud from the perspective of manifold as well as designs a manifold distillation method to achieve the robustness of rotation perturbation without any coordinate transformation. In brief, during the training phase, we introduce a teacher network to learn the rotation robustness information and transfer this information to the student network through online distillation. In the inference phase, the student network directly utilizes the original 3D coordinate information to achieve the robustness of rotation perturbation. Experiments carried out on four different datasets verify the effectiveness of our method. Averagely, on the Modelnet40 and ScanobjectNN classification datasets with random rotation perturbations, our classification accuracy has respectively improved by 4.92% and 4.41%, compared to popular rotation-robust networks; on the ShapeNet and S3DIS segmentation datasets, compared to the rotation-robust networks, the improvements of mIoU are 7.36% and 4.82%, respectively. Besides, from the experimental results, the proposed algorithm also shows excellent performance in resisting noise and outliers.</li>
</ul>

<h3>Title: Multi-task Geometric Estimation of Depth and Surface Normal from Monocular 360{\deg} Images</h3>
<ul>
<li><strong>Authors: </strong>Kun Huang, Fang-Lue Zhang, Fangfang Zhang, Yu-Kun Lai, Paul Rosin, Neil A. Dodgson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01749">https://arxiv.org/abs/2411.01749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01749">https://arxiv.org/pdf/2411.01749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01749]] Multi-task Geometric Estimation of Depth and Surface Normal from Monocular 360{\deg} Images(https://arxiv.org/abs/2411.01749)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Geometric estimation is required for scene understanding and analysis in panoramic 360° images. Current methods usually predict a single feature, such as depth or surface normal. These methods can lack robustness, especially when dealing with intricate textures or complex object surfaces. We introduce a novel multi-task learning (MTL) network that simultaneously estimates depth and surface normals from 360° images. Our first innovation is our MTL architecture, which enhances predictions for both tasks by integrating geometric information from depth and surface normal estimation, enabling a deeper understanding of 3D scene structure. Another innovation is our fusion module, which bridges the two tasks, allowing the network to learn shared representations that improve accuracy and robustness. Experimental results demonstrate that our MTL architecture significantly outperforms state-of-the-art methods in both depth and surface normal estimation, showing superior performance in complex and diverse scenes. Our model's effectiveness and generalizability, particularly in handling intricate surface textures, establish it as a new benchmark in 360° image geometric estimation. The code and model are available at \url{this https URL}.</li>
</ul>

<h3>Title: Show, Don't Tell: Learning Reward Machines from Demonstrations for Reinforcement Learning-Based Cardiac Pacemaker Synthesis</h3>
<ul>
<li><strong>Authors: </strong>John Komp, Dananjay Srinivas, Maria Pacheco, Ashutosh Trivedi</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01750">https://arxiv.org/abs/2411.01750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01750">https://arxiv.org/pdf/2411.01750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01750]] Show, Don't Tell: Learning Reward Machines from Demonstrations for Reinforcement Learning-Based Cardiac Pacemaker Synthesis(https://arxiv.org/abs/2411.01750)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>An (artificial cardiac) pacemaker is an implantable electronic device that sends electrical impulses to the heart to regulate the heartbeat. As the number of pacemaker users continues to rise, so does the demand for features with additional sensors, adaptability, and improved battery performance. Reinforcement learning (RL) has recently been proposed as a performant algorithm for creative design space exploration, adaptation, and statistical verification of cardiac pacemakers. The design of correct reward functions, expressed as a reward machine, is a key programming activity in this process. In 2007, Boston Scientific published a detailed description of their pacemaker specifications. This document has since formed the basis for several formal characterizations of pacemaker specifications using real-time automata and logic. However, because these translations are done manually, they are challenging to verify. Moreover, capturing requirements in automata or logic is notoriously difficult. We posit that it is significantly easier for domain experts, such as electrophysiologists, to observe and identify abnormalities in electrocardiograms that correspond to patient-pacemaker interactions. Therefore, we explore the possibility of learning correctness specifications from such labeled demonstrations in the form of a reward machine and training an RL agent to synthesize a cardiac pacemaker based on the resulting reward machine. We leverage advances in machine learning to extract signals from labeled demonstrations as reward machines using recurrent neural networks and transformer architectures. These reward machines are then used to design a simple pacemaker with RL. Finally, we validate the resulting pacemaker using properties extracted from the Boston Scientific document.</li>
</ul>

<h3>Title: RAGViz: Diagnose and Visualize Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Tevin Wang, Jingyuan He, Chenyan Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01751">https://arxiv.org/abs/2411.01751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01751">https://arxiv.org/pdf/2411.01751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01751]] RAGViz: Diagnose and Visualize Retrieval-Augmented Generation(https://arxiv.org/abs/2411.01751)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) combines knowledge from domain-specific sources into large language models to ground answer generation. Current RAG systems lack customizable visibility on the context documents and the model's attentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool that visualizes the attentiveness of the generated tokens in retrieved documents. With a built-in user interface, retrieval index, and Large Language Model (LLM) backbone, RAGViz provides two main functionalities: (1) token and document-level attention visualization, and (2) generation comparison upon context document addition and removal. As an open-source toolkit, RAGViz can be easily hosted with a custom embedding model and HuggingFace-supported LLM backbone. Using a hybrid ANN (Approximate Nearest Neighbor) index, memory-efficient LLM inference tool, and custom context snippet method, RAGViz operates efficiently with a median query time of about 5 seconds on a moderate GPU node. Our code is available at this https URL. A demo video of RAGViz can be found at this https URL.</li>
</ul>

<h3>Title: ChatTracker: Enhancing Visual Tracking Performance via Chatting with Multimodal Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Yiming Sun, Fan Yu, Shaoxiang Chen, Yu Zhang, Junwei Huang, Chenhui Li, Yang Li, Changbo Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01756">https://arxiv.org/abs/2411.01756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01756">https://arxiv.org/pdf/2411.01756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01756]] ChatTracker: Enhancing Visual Tracking Performance via Chatting with Multimodal Large Language Model(https://arxiv.org/abs/2411.01756)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual object tracking aims to locate a targeted object in a video sequence based on an initial bounding box. Recently, Vision-Language~(VL) trackers have proposed to utilize additional natural language descriptions to enhance versatility in various applications. However, VL trackers are still inferior to State-of-The-Art (SoTA) visual trackers in terms of tracking performance. We found that this inferiority primarily results from their heavy reliance on manual textual annotations, which include the frequent provision of ambiguous language descriptions. In this paper, we propose ChatTracker to leverage the wealth of world knowledge in the Multimodal Large Language Model (MLLM) to generate high-quality language descriptions and enhance tracking performance. To this end, we propose a novel reflection-based prompt optimization module to iteratively refine the ambiguous and inaccurate descriptions of the target with tracking feedback. To further utilize semantic information produced by MLLM, a simple yet effective VL tracking framework is proposed and can be easily integrated as a plug-and-play module to boost the performance of both VL and visual trackers. Experimental results show that our proposed ChatTracker achieves a performance comparable to existing methods.</li>
</ul>

<h3>Title: Mitigating Spurious Correlations via Disagreement Probability</h3>
<ul>
<li><strong>Authors: </strong>Hyeonggeun Han, Sehwan Kim, Hyungjun Joo, Sangwoo Hong, Jungwoo Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01757">https://arxiv.org/abs/2411.01757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01757">https://arxiv.org/pdf/2411.01757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01757]] Mitigating Spurious Correlations via Disagreement Probability(https://arxiv.org/abs/2411.01757)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Models trained with empirical risk minimization (ERM) are prone to be biased towards spurious correlations between target labels and bias attributes, which leads to poor performance on data groups lacking spurious correlations. It is particularly challenging to address this problem when access to bias labels is not permitted. To mitigate the effect of spurious correlations without bias labels, we first introduce a novel training objective designed to robustly enhance model performance across all data samples, irrespective of the presence of spurious correlations. From this objective, we then derive a debiasing method, Disagreement Probability based Resampling for debiasing (DPR), which does not require bias labels. DPR leverages the disagreement between the target label and the prediction of a biased model to identify bias-conflicting samples-those without spurious correlations-and upsamples them according to the disagreement probability. Empirical evaluations on multiple benchmarks demonstrate that DPR achieves state-of-the-art performance over existing baselines that do not use bias labels. Furthermore, we provide a theoretical analysis that details how DPR reduces dependency on spurious correlations.</li>
</ul>

<h3>Title: Automatic Structured Pruning for Efficient Architecture in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Thai Vu Nguyen, Long Bao Le, Anderson Avila</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01759">https://arxiv.org/abs/2411.01759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01759">https://arxiv.org/pdf/2411.01759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01759]] Automatic Structured Pruning for Efficient Architecture in Federated Learning(https://arxiv.org/abs/2411.01759)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In Federated Learning (FL), training is conducted on client devices, typically with limited computational resources and storage capacity. To address these constraints, we propose an automatic pruning scheme tailored for FL systems. Our solution improves computation efficiency on client devices, while minimizing communication costs. One of the challenges of tuning pruning hyper-parameters in FL systems is the restricted access to local data. Thus, we introduce an automatic pruning paradigm that dynamically determines pruning boundaries. Additionally, we utilized a structured pruning algorithm optimized for mobile devices that lack hardware support for sparse computations. Experimental results demonstrate the effectiveness of our approach, achieving accuracy comparable to existing methods. Our method notably reduces the number of parameters by 89% and FLOPS by 90%, with minimal impact on the accuracy of the FEMNIST and CelebFaces datasets. Furthermore, our pruning method decreases communication overhead by up to 5x and halves inference time when deployed on Android devices.</li>
</ul>

<h3>Title: Towards Pedagogical LLMs with Supervised Fine Tuning for Computing Education</h3>
<ul>
<li><strong>Authors: </strong>Alexandra Vassar, Jake Renzella, Emily Ross, Andrew Taylor</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01765">https://arxiv.org/abs/2411.01765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01765">https://arxiv.org/pdf/2411.01765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01765]] Towards Pedagogical LLMs with Supervised Fine Tuning for Computing Education(https://arxiv.org/abs/2411.01765)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates supervised fine-tuning of large language models (LLMs) to improve their pedagogical alignment in computing education, addressing concerns that LLMs may hinder learning outcomes. The project utilised a proprietary dataset of 2,500 high quality question/answer pairs from programming course forums, and explores two research questions: the suitability of university course forums in contributing to fine-tuning datasets, and how supervised fine-tuning can improve LLMs' alignment with educational principles such as constructivism. Initial findings suggest benefits in pedagogical alignment of LLMs, with deeper evaluations required.</li>
</ul>

<h3>Title: Learning predictable and robust neural representations by straightening image sequences</h3>
<ul>
<li><strong>Authors: </strong>Xueyan Niu, Cristina Savin, Eero P. Simoncelli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01777">https://arxiv.org/abs/2411.01777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01777">https://arxiv.org/pdf/2411.01777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01777]] Learning predictable and robust neural representations by straightening image sequences(https://arxiv.org/abs/2411.01777)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Prediction is a fundamental capability of all living organisms, and has been proposed as an objective for learning sensory representations. Recent work demonstrates that in primate visual systems, prediction is facilitated by neural representations that follow straighter temporal trajectories than their initial photoreceptor encoding, which allows for prediction by linear extrapolation. Inspired by these experimental findings, we develop a self-supervised learning (SSL) objective that explicitly quantifies and promotes straightening. We demonstrate the power of this objective in training deep feedforward neural networks on smoothly-rendered synthetic image sequences that mimic commonly-occurring properties of natural videos. The learned model contains neural embeddings that are predictive, but also factorize the geometric, photometric, and semantic attributes of objects. The representations also prove more robust to noise and adversarial attacks compared to previous SSL methods that optimize for invariance to random augmentations. Moreover, these beneficial properties can be transferred to other training procedures by using the straightening objective as a regularizer, suggesting a broader utility for straightening as a principle for robust unsupervised learning.</li>
</ul>

<h3>Title: TabSec: A Collaborative Framework for Novel Insider Threat Detection</h3>
<ul>
<li><strong>Authors: </strong>Zilin Huang, Xiangyan Tang, Hongyu Li, Xinyi Cao, Jieren Cheng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01779">https://arxiv.org/abs/2411.01779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01779">https://arxiv.org/pdf/2411.01779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01779]] TabSec: A Collaborative Framework for Novel Insider Threat Detection(https://arxiv.org/abs/2411.01779)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>In the era of the Internet of Things (IoT) and data sharing, users frequently upload their personal information to enterprise databases to enjoy enhanced service experiences provided by various online services. However, the widespread presence of system vulnerabilities, remote network intrusions, and insider threats significantly increases the exposure of private enterprise data on the internet. If such data is stolen or leaked by attackers, it can result in severe asset losses and business operation disruptions. To address these challenges, this paper proposes a novel threat detection framework, TabITD. This framework integrates Intrusion Detection Systems (IDS) with User and Entity Behavior Analytics (UEBA) strategies to form a collaborative detection system that bridges the gaps in existing systems' capabilities. It effectively addresses the blurred boundaries between external and insider threats caused by the diversification of attack methods, thereby enhancing the model's learning ability and overall detection performance. Moreover, the proposed method leverages the TabNet architecture, which employs a sparse attention feature selection mechanism that allows TabNet to select the most relevant features at each decision step, thereby improving the detection of rare-class attacks. We evaluated our proposed solution on two different datasets, achieving average accuracies of 96.71% and 97.25%, respectively. The results demonstrate that this approach can effectively detect malicious behaviors such as masquerade attacks and external threats, significantly enhancing network security defenses and the efficiency of network attack detection.</li>
</ul>

<h3>Title: MSTA3D: Multi-scale Twin-attention for 3D Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Duc Dang Trung Tran, Byeongkeun Kang, Yeejin Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01781">https://arxiv.org/abs/2411.01781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01781">https://arxiv.org/pdf/2411.01781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01781]] MSTA3D: Multi-scale Twin-attention for 3D Instance Segmentation(https://arxiv.org/abs/2411.01781)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Recently, transformer-based techniques incorporating superpoints have become prevalent in 3D instance segmentation. However, they often encounter an over-segmentation problem, especially noticeable with large objects. Additionally, unreliable mask predictions stemming from superpoint mask prediction further compound this issue. To address these challenges, we propose a novel framework called MSTA3D. It leverages multi-scale feature representation and introduces a twin-attention mechanism to effectively capture them. Furthermore, MSTA3D integrates a box query with a box regularizer, offering a complementary spatial constraint alongside semantic queries. Experimental evaluations on ScanNetV2, ScanNet200 and S3DIS datasets demonstrate that our approach surpasses state-of-the-art 3D instance segmentation methods.</li>
</ul>

<h3>Title: AIWR: Aerial Image Water Resource Dataset for Segmentation Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sangdaow Noppitaka, Emmanuel Okafor, Olarik Surinta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01797">https://arxiv.org/abs/2411.01797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01797">https://arxiv.org/pdf/2411.01797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01797]] AIWR: Aerial Image Water Resource Dataset for Segmentation Analysis(https://arxiv.org/abs/2411.01797)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Effective water resource management is crucial in agricultural regions like northeastern Thailand, where limited water retention in sandy soils poses significant challenges. In response to this issue, the Aerial Image Water Resource (AIWR) dataset was developed, comprising 800 aerial images focused on natural and artificial water bodies in this region. The dataset was created using Bing Maps and follows the standards of the Fundamental Geographic Data Set (FGDS). It includes ground truth annotations validated by experts in remote sensing, making it an invaluable resource for researchers in geoinformatics, computer vision, and artificial intelligence. The AIWR dataset presents considerable challenges, such as segmentation due to variations in the size, color, shape, and similarity of water bodies, which often resemble other land use categories.</li>
</ul>

<h3>Title: SALSA: Soup-based Alignment Learning for Stronger Adaptation in RLHF</h3>
<ul>
<li><strong>Authors: </strong>Atoosa Chegini, Hamid Kazemi, Iman Mirzadeh, Dong Yin, Maxwell Horton, Moin Nabi, Mehrdad Farajtabar, Keivan Alizadeh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01798">https://arxiv.org/abs/2411.01798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01798">https://arxiv.org/pdf/2411.01798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01798]] SALSA: Soup-based Alignment Learning for Stronger Adaptation in RLHF(https://arxiv.org/abs/2411.01798)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In Large Language Model (LLM) development, Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning models with human values and preferences. RLHF traditionally relies on the Kullback-Leibler (KL) divergence between the current policy and a frozen initial policy as a reference, which is added as a penalty in policy optimization algorithms like Proximal Policy Optimization (PPO). While this constraint prevents models from deviating too far from the initial checkpoint, it limits exploration of the reward landscape, reducing the model's ability to discover higher-quality solutions. As a result, policy optimization is often trapped in a narrow region of the parameter space, leading to suboptimal alignment and performance. This paper presents SALSA (Soup-based Alignment Learning for Stronger Adaptation), a novel approach designed to overcome these limitations by creating a more flexible and better located reference model through weight-space averaging of two independent supervised fine-tuned (SFT) models. This model soup allows for larger deviation in KL divergence and exploring a promising region of the solution space without sacrificing stability. By leveraging this more robust reference model, SALSA fosters better exploration, achieving higher rewards and improving model robustness, out-of-distribution generalization, and performance. We validate the effectiveness of SALSA through extensive experiments on popular open models (Llama2-7B, Mistral-7B, and Gemma-2B) across various benchmarks (MT-Bench, Arena-Hard, UltraFeedback), where it consistently surpasses PPO by fostering deeper exploration and achieving superior alignment in LLMs.</li>
</ul>

<h3>Title: Shrinking the Giant : Quasi-Weightless Transformers for Low Energy Inference</h3>
<ul>
<li><strong>Authors: </strong>Shashank Nag, Alan T. L. Bacellar, Zachary Susskind, Anshul Jha, Logan Liberty, Aishwarya Sivakumar, Eugene B. John, Krishnan Kailas, Priscila M. V. Lima, Neeraja J. Yadwadkar, Felipe M. G. Franca, Lizy K. John</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01818">https://arxiv.org/abs/2411.01818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01818">https://arxiv.org/pdf/2411.01818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01818]] Shrinking the Giant : Quasi-Weightless Transformers for Low Energy Inference(https://arxiv.org/abs/2411.01818)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers are set to become ubiquitous with applications ranging from chatbots and educational assistants to visual recognition and remote sensing. However, their increasing computational and memory demands is resulting in growing energy consumption. Building models with fast and energy-efficient inference is imperative to enable a variety of transformer-based applications. Look Up Table (LUT) based Weightless Neural Networks are faster than the conventional neural networks as their inference only involves a few lookup operations. Recently, an approach for learning LUT networks directly via an Extended Finite Difference method was proposed. We build on this idea, extending it for performing the functions of the Multi Layer Perceptron (MLP) layers in transformer models and integrating them with transformers to propose Quasi Weightless Transformers (QuWeiT). This allows for a computational and energy-efficient inference solution for transformer-based models. On I-ViT-T, we achieve a comparable accuracy of 95.64% on CIFAR-10 dataset while replacing approximately 55% of all the multiplications in the entire model and achieving a 2.2x energy efficiency. We also observe similar savings on experiments with the nanoGPT framework.</li>
</ul>

<h3>Title: DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability</h3>
<ul>
<li><strong>Authors: </strong>Bo Gao, Fangxu Xing, Daniel Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01819">https://arxiv.org/abs/2411.01819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01819">https://arxiv.org/pdf/2411.01819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01819]] DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability(https://arxiv.org/abs/2411.01819)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation models, like mask2former, often demand a substantial amount of manually annotated data, which is time-consuming and inefficient to acquire. Leveraging state-of-the-art text-to-image models like Midjourney and Stable Diffusion has emerged as an effective strategy for automatically generating synthetic data instead of human annotations. However, prior approaches have been constrained to synthesizing single-instance images due to the instability inherent in generating multiple instances with Stable Diffusion. To expand the domains and diversity of synthetic datasets, this paper introduces a novel paradigm named DiffuMask-Editor, which combines the Diffusion Model for Segmentation with Image Editing. By integrating multiple objects into images using Text2Image models, our method facilitates the creation of more realistic datasets that closely resemble open-world settings while simultaneously generating accurate masks. Our approach significantly reduces the laborious effort associated with manual annotation while ensuring precise mask generation. Experimental results demonstrate that synthetic data generated by DiffuMask-Editor enable segmentation methods to achieve superior performance compared to real data. Particularly in zero-shot backgrounds, DiffuMask-Editor achieves new state-of-the-art results on Unseen classes of VOC 2012. The code and models will be publicly available soon.</li>
</ul>

<h3>Title: FedReMa: Improving Personalized Federated Learning via Leveraging the Most Relevant Clients</h3>
<ul>
<li><strong>Authors: </strong>Han Liang, Ziwei Zhan, Weijie Liu, Xiaoxi Zhang, Chee Wei Tan, Xu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01825">https://arxiv.org/abs/2411.01825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01825">https://arxiv.org/pdf/2411.01825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01825]] FedReMa: Improving Personalized Federated Learning via Leveraging the Most Relevant Clients(https://arxiv.org/abs/2411.01825)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, segmentation</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a distributed machine learning paradigm that achieves a globally robust model through decentralized computation and periodic model synthesis, primarily focusing on the global model's accuracy over aggregated datasets of all participating clients. Personalized Federated Learning (PFL) instead tailors exclusive models for each client, aiming to enhance the accuracy of clients' individual models on specific local data distributions. Despite of their wide adoption, existing FL and PFL works have yet to comprehensively address the class-imbalance issue, one of the most critical challenges within the realm of data heterogeneity in PFL and FL research. In this paper, we propose FedReMa, an efficient PFL algorithm that can tackle class-imbalance by 1) utilizing an adaptive inter-client co-learning approach to identify and harness different clients' expertise on different data classes throughout various phases of the training process, and 2) employing distinct aggregation methods for clients' feature extractors and classifiers, with the choices informed by the different roles and implications of these model components. Specifically, driven by our experimental findings on inter-client similarity dynamics, we develop critical co-learning period (CCP), wherein we introduce a module named maximum difference segmentation (MDS) to assess and manage task relevance by analyzing the similarities between clients' logits of their classifiers. Outside the CCP, we employ an additional scheme for model aggregation that utilizes historical records of each client's most relevant peers to further enhance the personalization stability. We demonstrate the superiority of our FedReMa in extensive experiments.</li>
</ul>

<h3>Title: Formal Theorem Proving by Rewarding LLMs to Decompose Proofs Hierarchically</h3>
<ul>
<li><strong>Authors: </strong>Kefan Dong, Arvind Mahankali, Tengyu Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01829">https://arxiv.org/abs/2411.01829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01829">https://arxiv.org/pdf/2411.01829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01829]] Formal Theorem Proving by Rewarding LLMs to Decompose Proofs Hierarchically(https://arxiv.org/abs/2411.01829)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mathematical theorem proving is an important testbed for large language models' deep and abstract reasoning capability. This paper focuses on improving LLMs' ability to write proofs in formal languages that permit automated proof verification/evaluation. Most previous results provide human-written lemmas to the theorem prover, which is an arguably oversimplified setting that does not sufficiently test the provers' planning and decomposition capabilities. Instead, we work in a more natural setup where the lemmas that are directly relevant to the theorem are not given to the theorem prover at test time. We design an RL-based training algorithm that encourages the model to decompose a theorem into lemmas, prove the lemmas, and then prove the theorem by using the lemmas. Our reward mechanism is inspired by how mathematicians train themselves: even if a theorem is too challenging to be proved by the current model, a positive reward is still given to the model for any correct and novel lemmas that are proposed and proved in this process. During training, our model proposes and proves lemmas that are not in the training dataset. In fact, these newly-proposed correct lemmas consist of 37.7% of the training replay buffer when we train on the dataset extracted from Archive of Formal Proofs (AFP). The model trained by our RL algorithm outperforms that trained by supervised finetuning, improving the pass rate from 40.8% to 45.5% on AFP test set, and from 36.5% to 39.5% on an out-of-distribution test set.</li>
</ul>

<h3>Title: OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Shengjie Niu, Lifan Lin, Jian Huang, Chao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01833">https://arxiv.org/abs/2411.01833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01833">https://arxiv.org/pdf/2411.01833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01833]] OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning(https://arxiv.org/abs/2411.01833)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning (SSL) offers a robust framework for harnessing the potential of unannotated data. Traditionally, SSL mandates that all classes possess labeled instances. However, the emergence of open-world SSL (OwSSL) introduces a more practical challenge, wherein unlabeled data may encompass samples from unseen classes. This scenario leads to misclassification of unseen classes as known ones, consequently undermining classification accuracy. To overcome this challenge, this study revisits two methodologies from self-supervised and semi-supervised learning, self-labeling and consistency, tailoring them to address the OwSSL problem. Specifically, we propose an effective framework called OwMatch, combining conditional self-labeling and open-world hierarchical thresholding. Theoretically, we analyze the estimation of class distribution on unlabeled data through rigorous statistical analysis, thus demonstrating that OwMatch can ensure the unbiasedness of the self-label assignment estimator with reliability. Comprehensive empirical analyses demonstrate that our method yields substantial performance enhancements across both known and unknown classes in comparison to previous studies. Code is available at this https URL.</li>
</ul>

<h3>Title: Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback</h3>
<ul>
<li><strong>Authors: </strong>Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hung-yi Lee, Ivan Bulyko</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01834">https://arxiv.org/abs/2411.01834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01834">https://arxiv.org/pdf/2411.01834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01834]] Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback(https://arxiv.org/abs/2411.01834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While textless Spoken Language Models (SLMs) have shown potential in end-to-end speech-to-speech modeling, they still lag behind text-based Large Language Models (LLMs) in terms of semantic coherence and relevance. This work introduces the Align-SLM framework, which leverages preference optimization inspired by Reinforcement Learning with AI Feedback (RLAIF) to enhance the semantic understanding of SLMs. Our approach generates multiple speech continuations from a given prompt and uses semantic metrics to create preference data for Direct Preference Optimization (DPO). We evaluate the framework using ZeroSpeech 2021 benchmarks for lexical and syntactic modeling, the spoken version of the StoryCloze dataset for semantic coherence, and other speech generation metrics, including the GPT4-o score and human evaluation. Experimental results show that our method achieves state-of-the-art performance for SLMs on most benchmarks, highlighting the importance of preference optimization to improve the semantics of SLMs.</li>
</ul>

<h3>Title: TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Rina Carines Cabral, Soyeon Caren Han, Areej Alhassan, Riza Batista-Navarro, Goran Nenadic, Josiah Poon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01839">https://arxiv.org/abs/2411.01839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01839">https://arxiv.org/pdf/2411.01839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01839]] TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition(https://arxiv.org/abs/2411.01839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Discontinuous Named Entity Recognition (DNER) presents a challenging problem where entities may be scattered across multiple non-adjacent tokens, making traditional sequence labelling approaches inadequate. Existing methods predominantly rely on custom tagging schemes to handle these discontinuous entities, resulting in models tightly coupled to specific tagging strategies and lacking generalisability across diverse datasets. To address these challenges, we propose TriG-NER, a novel Triplet-Grid Framework that introduces a generalisable approach to learning robust token-level representations for discontinuous entity extraction. Our framework applies triplet loss at the token level, where similarity is defined by word pairs existing within the same entity, effectively pulling together similar and pushing apart dissimilar ones. This approach enhances entity boundary detection and reduces the dependency on specific tagging schemes by focusing on word-pair relationships within a flexible grid structure. We evaluate TriG-NER on three benchmark DNER datasets and demonstrate significant improvements over existing grid-based architectures. These results underscore our framework's effectiveness in capturing complex entity structures and its adaptability to various tagging schemes, setting a new benchmark for discontinuous entity extraction.</li>
</ul>

<h3>Title: ElasTST: Towards Robust Varied-Horizon Forecasting with Elastic Time-Series Transformer</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Zhang, Shun Zheng, Xumeng Wen, Xiaofang Zhou, Jiang Bian, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01842">https://arxiv.org/abs/2411.01842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01842">https://arxiv.org/pdf/2411.01842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01842]] ElasTST: Towards Robust Varied-Horizon Forecasting with Elastic Time-Series Transformer(https://arxiv.org/abs/2411.01842)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Numerous industrial sectors necessitate models capable of providing robust forecasts across various horizons. Despite the recent strides in crafting specific architectures for time-series forecasting and developing pre-trained universal models, a comprehensive examination of their capability in accommodating varied-horizon forecasting during inference is still lacking. This paper bridges this gap through the design and evaluation of the Elastic Time-Series Transformer (ElasTST). The ElasTST model incorporates a non-autoregressive design with placeholders and structured self-attention masks, warranting future outputs that are invariant to adjustments in inference horizons. A tunable version of rotary position embedding is also integrated into ElasTST to capture time-series-specific periods and enhance adaptability to different horizons. Additionally, ElasTST employs a multi-scale patch design, effectively integrating both fine-grained and coarse-grained information. During the training phase, ElasTST uses a horizon reweighting strategy that approximates the effect of random sampling across multiple horizons with a single fixed horizon setting. Through comprehensive experiments and comparisons with state-of-the-art time-series architectures and contemporary foundation models, we demonstrate the efficacy of ElasTST's unique design elements. Our findings position ElasTST as a robust solution for the practical necessity of varied-horizon forecasting.</li>
</ul>

<h3>Title: KptLLM: Unveiling the Power of Large Language Model for Keypoint Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Jie Yang, Wang Zeng, Sheng Jin, Lumin Xu, Wentao Liu, Chen Qian, Ruimao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01846">https://arxiv.org/abs/2411.01846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01846">https://arxiv.org/pdf/2411.01846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01846]] KptLLM: Unveiling the Power of Large Language Model for Keypoint Comprehension(https://arxiv.org/abs/2411.01846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Multimodal Large Language Models (MLLMs) have greatly improved their abilities in image understanding. However, these models often struggle with grasping pixel-level semantic details, e.g., the keypoints of an object. To bridge this gap, we introduce the novel challenge of Semantic Keypoint Comprehension, which aims to comprehend keypoints across different task scenarios, including keypoint semantic understanding, visual prompt-based keypoint detection, and textual prompt-based keypoint detection. Moreover, we introduce KptLLM, a unified multimodal model that utilizes an identify-then-detect strategy to effectively address these challenges. KptLLM underscores the initial discernment of semantics in keypoints, followed by the precise determination of their positions through a chain-of-thought process. With several carefully designed modules, KptLLM adeptly handles various modality inputs, facilitating the interpretation of both semantic contents and keypoint locations. Our extensive experiments demonstrate KptLLM's superiority in various keypoint detection benchmarks and its unique semantic capabilities in interpreting keypoints.</li>
</ul>

<h3>Title: Silver medal Solution for Image Matching Challenge 2024</h3>
<ul>
<li><strong>Authors: </strong>Yian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01851">https://arxiv.org/abs/2411.01851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01851">https://arxiv.org/pdf/2411.01851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01851]] Silver medal Solution for Image Matching Challenge 2024(https://arxiv.org/abs/2411.01851)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Image Matching Challenge 2024 is a competition focused on building 3D maps from diverse image sets, requiring participants to solve fundamental computer vision challenges in image matching across varying angles, lighting, and seasonal changes. This project develops a Pipeline method that combines multiple advanced techniques: using pre-trained EfficientNet-B7 for initial feature extraction and cosine distance-based image pair filtering, employing both KeyNetAffNetHardNet and SuperPoint for keypoint feature extraction, utilizing AdaLAM and SuperGlue for keypoint matching, and finally applying Pycolmap for 3D spatial analysis. The methodology achieved an excellent score of 0.167 on the private leaderboard, with experimental results demonstrating that the combination of KeyNetAffNetHardNet and SuperPoint provides significant advantages in keypoint detection and matching, particularly when dealing with challenging variations in surface texture and environmental conditions that typically degrade traditional algorithm performance.</li>
</ul>

<h3>Title: MeToken: Uniform Micro-environment Token Boosts Post-Translational Modification Prediction</h3>
<ul>
<li><strong>Authors: </strong>Cheng Tan, Zhenxiao Cao, Zhangyang Gao, Lirong Wu, Siyuan Li, Yufei Huang, Jun Xia, Bozhen Hu, Stan Z. Li</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01856">https://arxiv.org/abs/2411.01856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01856">https://arxiv.org/pdf/2411.01856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01856]] MeToken: Uniform Micro-environment Token Boosts Post-Translational Modification Prediction(https://arxiv.org/abs/2411.01856)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Post-translational modifications (PTMs) profoundly expand the complexity and functionality of the proteome, regulating protein attributes and interactions that are crucial for biological processes. Accurately predicting PTM sites and their specific types is therefore essential for elucidating protein function and understanding disease mechanisms. Existing computational approaches predominantly focus on protein sequences to predict PTM sites, driven by the recognition of sequence-dependent motifs. However, these approaches often overlook protein structural contexts. In this work, we first compile a large-scale sequence-structure PTM dataset, which serves as the foundation for fair comparison. We introduce the MeToken model, which tokenizes the micro-environment of each amino acid, integrating both sequence and structural information into unified discrete tokens. This model not only captures the typical sequence motifs associated with PTMs but also leverages the spatial arrangements dictated by protein tertiary structures, thus providing a holistic view of the factors influencing PTM sites. Designed to address the long-tail distribution of PTM types, MeToken employs uniform sub-codebooks that ensure even the rarest PTMs are adequately represented and distinguished. We validate the effectiveness and generalizability of MeToken across multiple datasets, demonstrating its superior performance in accurately identifying PTM types. The results underscore the importance of incorporating structural data and highlight MeToken's potential in facilitating accurate and comprehensive PTM predictions, which could significantly impact proteomics research. The code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Mining and Transferring Feature-Geometry Coherence for Unsupervised Point Cloud Registration</h3>
<ul>
<li><strong>Authors: </strong>Kezheng Xiong, Haoen Xiang, Qingshan Xu, Chenglu Wen, Siqi Shen, Jonathan Li, Cheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01870">https://arxiv.org/abs/2411.01870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01870">https://arxiv.org/pdf/2411.01870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01870]] Mining and Transferring Feature-Geometry Coherence for Unsupervised Point Cloud Registration(https://arxiv.org/abs/2411.01870)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Point cloud registration, a fundamental task in 3D vision, has achieved remarkable success with learning-based methods in outdoor environments. Unsupervised outdoor point cloud registration methods have recently emerged to circumvent the need for costly pose annotations. However, they fail to establish reliable optimization objectives for unsupervised training, either relying on overly strong geometric assumptions, or suffering from poor-quality pseudo-labels due to inadequate integration of low-level geometric and high-level contextual information. We have observed that in the feature space, latent new inlier correspondences tend to cluster around respective positive anchors that summarize features of existing inliers. Motivated by this observation, we propose a novel unsupervised registration method termed INTEGER to incorporate high-level contextual information for reliable pseudo-label mining. Specifically, we propose the Feature-Geometry Coherence Mining module to dynamically adapt the teacher for each mini-batch of data during training and discover reliable pseudo-labels by considering both high-level feature representations and low-level geometric cues. Furthermore, we propose Anchor-Based Contrastive Learning to facilitate contrastive learning with anchors for a robust feature space. Lastly, we introduce a Mixed-Density Student to learn density-invariant features, addressing challenges related to density variation and low overlap in the outdoor scenario. Extensive experiments on KITTI and nuScenes datasets demonstrate that our INTEGER achieves competitive performance in terms of accuracy and generalizability.</li>
</ul>

<h3>Title: Quantum One-Time Programs, Revisited</h3>
<ul>
<li><strong>Authors: </strong>Aparna Gupte, Jiahui Liu, Justin Raizes, Bhaskar Roberts, Vinod Vaikuntanathan</a></li>
<li><strong>Subjects: </strong>cs.CR, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01876">https://arxiv.org/abs/2411.01876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01876">https://arxiv.org/pdf/2411.01876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01876]] Quantum One-Time Programs, Revisited(https://arxiv.org/abs/2411.01876)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>One-time programs (Goldwasser, Kalai and Rothblum, CRYPTO 2008) are functions that can be run on any single input of a user's choice, but not on a second input. Classically, they are unachievable without trusted hardware, but the destructive nature of quantum measurements seems to provide a quantum path to constructing them. Unfortunately, Broadbent, Gutoski and Stebila showed that even with quantum techniques, a strong notion of one-time programs, similar to ideal obfuscation, cannot be achieved for any non-trivial quantum function. On the positive side, Ben-David and Sattath (Quantum, 2023) showed how to construct a one-time program for a certain (probabilistic) digital signature scheme, under a weaker notion of one-time program security. There is a vast gap between achievable and provably impossible notions of one-time program security, and it is unclear what functionalities are one-time programmable under the achievable notions of security. In this work, we present new, meaningful, yet achievable definitions of one-time program security for probabilistic classical functions. We show how to construct one time programs satisfying these definitions for all functions in the classical oracle model and for constrained pseudorandom functions in the plain model. Finally, we examine the limits of these notions: we show a class of functions which cannot be one-time programmed in the plain model, as well as a class of functions which appears to be highly random given a single query, but whose one-time program form leaks the entire function even in the oracle model.</li>
</ul>

<h3>Title: LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Jinyin Chen, Danxin Liao, Sheng Xiang, Haibin Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01889">https://arxiv.org/abs/2411.01889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01889">https://arxiv.org/pdf/2411.01889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01889]] LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection(https://arxiv.org/abs/2411.01889)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Since DNN is vulnerable to carefully crafted adversarial examples, adversarial attack on LiDAR sensors have been extensively studied. We introduce a robust black-box attack dubbed LiDAttack. It utilizes a genetic algorithm with a simulated annealing strategy to strictly limit the location and number of perturbation points, achieving a stealthy and effective attack. And it simulates scanning deviations, allowing it to adapt to dynamic changes in real world scenario variations. Extensive experiments are conducted on 3 datasets (i.e., KITTI, nuScenes, and self-constructed data) with 3 dominant object detection models (i.e., PointRCNN, PointPillar, and PV-RCNN++). The results reveal the efficiency of the LiDAttack when targeting a wide range of object detection models, with an attack success rate (ASR) up to 90%.</li>
</ul>

<h3>Title: A Global Depth-Range-Free Multi-View Stereo Transformer Network with Pose Embedding</h3>
<ul>
<li><strong>Authors: </strong>Yitong Dong, Yijin Li, Zhaoyang Huang, Weikang Bian, Jingbo Liu, Hujun Bao, Zhaopeng Cui, Hongsheng Li, Guofeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01893">https://arxiv.org/abs/2411.01893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01893">https://arxiv.org/pdf/2411.01893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01893]] A Global Depth-Range-Free Multi-View Stereo Transformer Network with Pose Embedding(https://arxiv.org/abs/2411.01893)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a novel multi-view stereo (MVS) framework that gets rid of the depth range prior. Unlike recent prior-free MVS methods that work in a pair-wise manner, our method simultaneously considers all the source images. Specifically, we introduce a Multi-view Disparity Attention (MDA) module to aggregate long-range context information within and across multi-view images. Considering the asymmetry of the epipolar disparity flow, the key to our method lies in accurately modeling multi-view geometric constraints. We integrate pose embedding to encapsulate information such as multi-view camera poses, providing implicit geometric constraints for multi-view disparity feature fusion dominated by attention. Additionally, we construct corresponding hidden states for each source image due to significant differences in the observation quality of the same pixel in the reference frame across multiple source frames. We explicitly estimate the quality of the current pixel corresponding to sampled points on the epipolar line of the source image and dynamically update hidden states through the uncertainty estimation module. Extensive results on the DTU dataset and Tanks&Temple benchmark demonstrate the effectiveness of our method. The code is available at our project page: this https URL.</li>
</ul>

<h3>Title: LE-PDE++: Mamba for accelerating PDEs Simulations</h3>
<ul>
<li><strong>Authors: </strong>Aoming Liang, Zhaoyang Mu, Qi liu, Ruipeng Li, Mingming Ge, Dixia Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01897">https://arxiv.org/abs/2411.01897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01897">https://arxiv.org/pdf/2411.01897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01897]] LE-PDE++: Mamba for accelerating PDEs Simulations(https://arxiv.org/abs/2411.01897)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Partial Differential Equations are foundational in modeling science and natural systems such as fluid dynamics and weather forecasting. The Latent Evolution of PDEs method is designed to address the computational intensity of classical and deep learning-based PDE solvers by proposing a scalable and efficient alternative. To enhance the efficiency and accuracy of LE-PDE, we incorporate the Mamba model, an advanced machine learning model known for its predictive efficiency and robustness in handling complex dynamic systems with a progressive learning strategy. The LE-PDE was tested on several benchmark problems. The method demonstrated a marked reduction in computational time compared to traditional solvers and standalone deep learning models while maintaining high accuracy in predicting system behavior over time. Our method doubles the inference speed compared to the LE-PDE while retaining the same level of parameter efficiency, making it well-suited for scenarios requiring long-term predictions.</li>
</ul>

<h3>Title: FPPL: An Efficient and Non-IID Robust Federated Continual Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Yuchen He, Chuyun Shen, Xiangfeng Wang, Bo Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01904">https://arxiv.org/abs/2411.01904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01904">https://arxiv.org/pdf/2411.01904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01904]] FPPL: An Efficient and Non-IID Robust Federated Continual Learning Framework(https://arxiv.org/abs/2411.01904)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated continual learning (FCL) aims to learn from sequential data stream in the decentralized federated learning setting, while simultaneously mitigating the catastrophic forgetting issue in classical continual learning. Existing FCL methods usually employ typical rehearsal mechanisms, which could result in privacy violations or additional onerous storage and computational burdens. In this work, an efficient and non-IID robust federated continual learning framework, called Federated Prototype-Augmented Prompt Learning (FPPL), is proposed. The FPPL can collaboratively learn lightweight prompts augmented by prototypes without rehearsal. On the client side, a fusion function is employed to fully leverage the knowledge contained in task-specific prompts for alleviating catastrophic forgetting. Additionally, global prototypes aggregated from the server are used to obtain unified representation through contrastive learning, mitigating the impact of non-IID-derived data heterogeneity. On the server side, locally uploaded prototypes are utilized to perform debiasing on the classifier, further alleviating the performance degradation caused by both non-IID and catastrophic forgetting. Empirical evaluations demonstrate the effectiveness of FPPL, achieving notable performance with an efficient design while remaining robust to diverse non-IID degrees. Code is available at: this https URL.</li>
</ul>

<h3>Title: Masked Autoencoders are Parameter-Efficient Federated Continual Learners</h3>
<ul>
<li><strong>Authors: </strong>Yuchen He, Xiangfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01916">https://arxiv.org/abs/2411.01916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01916">https://arxiv.org/pdf/2411.01916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01916]] Masked Autoencoders are Parameter-Efficient Federated Continual Learners(https://arxiv.org/abs/2411.01916)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, transformer</a></li>
<li><strong>Abstract: </strong>Federated learning is a specific distributed learning paradigm in which a central server aggregates updates from multiple clients' local models, thereby enabling the server to learn without requiring clients to upload their private data, maintaining data privacy. While existing federated learning methods are primarily designed for static data, real-world applications often require clients to learn new categories over time. This challenge necessitates the integration of continual learning techniques, resulting in federated continual learning (FCL). Although advanced prompt-based continual learning methods leverage pre-trained transformers to mitigate catastrophic forgetting, they do not adequately address the non-IID challenges in federated learning. To address both catastrophic forgetting and non-IID issues, we propose to use masked autoencoders (MAEs) as parameter-efficient federated continual learners, called pMAE. pMAE learns reconstructive prompt on the client side through image reconstruction using MAEs. On the server side, it reconstructs the uploaded restore information to capture the data distribution across previous tasks and different clients, using these reconstructed images to finetune discriminative prompt and classifier parameters designed for classification, thereby alleviating catastrophic forgetting and non-IID challenges on a global scale. Experimental results demonstrate that pMAE achieves performance comparable to existing prompt-based methods and can enhance their effectiveness, particularly when using self-supervised pre-trained transformers as the backbone. Code is available at: this https URL.</li>
</ul>

<h3>Title: Exploiting Contextual Uncertainty of Visual Data for Efficient Training of Deep Models</h3>
<ul>
<li><strong>Authors: </strong>Sharat Agarwal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01925">https://arxiv.org/abs/2411.01925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01925">https://arxiv.org/pdf/2411.01925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01925]] Exploiting Contextual Uncertainty of Visual Data for Efficient Training of Deep Models(https://arxiv.org/abs/2411.01925)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, segmentation</a></li>
<li><strong>Abstract: </strong>Objects, in the real world, rarely occur in isolation and exhibit typical arrangements governed by their independent utility, and their expected interaction with humans and other objects in the context. For example, a chair is expected near a table, and a computer is expected on top. Humans use this spatial context and relative placement as an important cue for visual recognition in case of ambiguities. Similar to human's, DNN's exploit contextual information from data to learn representations. Our research focuses on harnessing the contextual aspects of visual data to optimize data annotation and enhance the training of deep networks. Our contributions can be summarized as follows: (1) We introduce the notion of contextual diversity for active learning CDAL and show its applicability in three different visual tasks semantic segmentation, object detection and image classification, (2) We propose a data repair algorithm to curate contextually fair data to reduce model bias, enabling the model to detect objects out of their obvious context, (3) We propose Class-based annotation, where contextually relevant classes are selected that are complementary for model training under domain shift. Understanding the importance of well-curated data, we also emphasize the necessity of involving humans in the loop to achieve accurate annotations and to develop novel interaction strategies that allow humans to serve as fact-checkers. In line with this we are working on developing image retrieval system for wildlife camera trap images and reliable warning system for poor quality rural roads. For large-scale annotation, we are employing a strategic combination of human expertise and zero-shot models, while also integrating human input at various stages for continuous feedback.</li>
</ul>

<h3>Title: Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Zbeeb, Mohammad Ghorayeb, Mariam Salman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01929">https://arxiv.org/abs/2411.01929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01929">https://arxiv.org/pdf/2411.01929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01929]] Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis(https://arxiv.org/abs/2411.01929)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) research often aims to develop models that generalize reliably across complex datasets, yet this remains challenging in fields where data is scarce, intricate, or inaccessible. This paper introduces a novel approach leveraging three generative models of varying complexity to synthesize one of the most demanding structured datasets: Malicious Network Traffic. Our approach transforms numerical data into text, reframing data generation as a language modeling task, which enhances data regularization and significantly improves generalization and the quality of the synthetic data. Extensive statistical analyses demonstrate that our method surpasses state-of-the-art generative models in producing high-fidelity synthetic data. Additionally, we conduct a comprehensive study on synthetic data applications, effectiveness, and evaluation strategies, offering valuable insights into its role across various domains. Our code and pre-trained models are openly accessible at this https URL, enabling further exploration and application of our methodology. Index Terms: Data synthesis, machine learning, traffic generation, privacy-preserving data, generative models.</li>
</ul>

<h3>Title: Differentially private and decentralized randomized power method</h3>
<ul>
<li><strong>Authors: </strong>Julien Nicolas, César Sabater, Mohamed Maouche, Sonia Ben Mokhtar, Mark Coates</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, math.NA, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01931">https://arxiv.org/abs/2411.01931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01931">https://arxiv.org/pdf/2411.01931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01931]] Differentially private and decentralized randomized power method(https://arxiv.org/abs/2411.01931)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. As modern datasets contain sensitive private information, we need to give formal guarantees on the possible privacy leaks caused by this method. This paper focuses on enhancing privacy preserving variants of the method. We propose a strategy to reduce the variance of the noise introduced to achieve Differential Privacy (DP). We also adapt the method to a decentralized framework with a low computational and communication overhead, while preserving the accuracy. We leverage Secure Aggregation (a form of Multi-Party Computation) to allow the algorithm to perform computations using data distributed among multiple users or devices, without revealing individual data. We show that it is possible to use a noise scale in the decentralized setting that is similar to the one in the centralized setting. We improve upon existing convergence bounds for both the centralized and decentralized versions. The proposed method is especially relevant for decentralized applications such as distributed recommender systems, where privacy concerns are paramount.</li>
</ul>

<h3>Title: Learning Where to Edit Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yunqiao Yang, Long-Kai Huang, Shengzhuang Chen, Kede Ma, Ying Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01948">https://arxiv.org/abs/2411.01948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01948">https://arxiv.org/pdf/2411.01948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01948]] Learning Where to Edit Vision Transformers(https://arxiv.org/abs/2411.01948)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Model editing aims to data-efficiently correct predictive errors of large pre-trained models while ensuring generalization to neighboring failures and locality to minimize unintended effects on unrelated examples. While significant progress has been made in editing Transformer-based large language models, effective strategies for editing vision Transformers (ViTs) in computer vision remain largely untapped. In this paper, we take initial steps towards correcting predictive errors of ViTs, particularly those arising from subpopulation shifts. Taking a locate-then-edit approach, we first address the where-to-edit challenge by meta-learning a hypernetwork on CutMix-augmented data generated for editing reliability. This trained hypernetwork produces generalizable binary masks that identify a sparse subset of structured model parameters, responsive to real-world failure samples. Afterward, we solve the how-to-edit problem by simply fine-tuning the identified parameters using a variant of gradient descent to achieve successful edits. To validate our method, we construct an editing benchmark that introduces subpopulation shifts towards natural underrepresented images and AI-generated images, thereby revealing the limitations of pre-trained ViTs for object recognition. Our approach not only achieves superior performance on the proposed benchmark but also allows for adjustable trade-offs between generalization and locality. Our code is available at this https URL.</li>
</ul>

<h3>Title: EXAGREE: Towards Explanation Agreement in Explainable Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Sichao Li, Quanling Deng, Amanda S. Barnard</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01956">https://arxiv.org/abs/2411.01956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01956">https://arxiv.org/pdf/2411.01956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01956]] EXAGREE: Towards Explanation Agreement in Explainable Machine Learning(https://arxiv.org/abs/2411.01956)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Explanations in machine learning are critical for trust, transparency, and fairness. Yet, complex disagreements among these explanations limit the reliability and applicability of machine learning models, especially in high-stakes environments. We formalize four fundamental ranking-based explanation disagreement problems and introduce a novel framework, EXplanation AGREEment (EXAGREE), to bridge diverse interpretations in explainable machine learning, particularly from stakeholder-centered perspectives. Our approach leverages a Rashomon set for attribution predictions and then optimizes within this set to identify Stakeholder-Aligned Explanation Models (SAEMs) that minimize disagreement with diverse stakeholder needs while maintaining predictive performance. Rigorous empirical analysis on synthetic and real-world datasets demonstrates that EXAGREE reduces explanation disagreement and improves fairness across subgroups in various domains. EXAGREE not only provides researchers with a new direction for studying explanation disagreement problems but also offers data scientists a tool for making better-informed decisions in practical applications.</li>
</ul>

<h3>Title: N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs</h3>
<ul>
<li><strong>Authors: </strong>Ilya Zisman, Alexander Nikulin, Andrei Polubarov, Nikita Lyubaykin, Vladislav Kurenkov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01958">https://arxiv.org/abs/2411.01958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01958">https://arxiv.org/pdf/2411.01958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01958]] N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs(https://arxiv.org/abs/2411.01958)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In-context learning allows models like transformers to adapt to new tasks from a few examples without updating their weights, a desirable trait for reinforcement learning (RL). However, existing in-context RL methods, such as Algorithm Distillation (AD), demand large, carefully curated datasets and can be unstable and costly to train due to the transient nature of in-context learning abilities. In this work we integrated the n-gram induction heads into transformers for in-context RL. By incorporating these n-gram attention patterns, we significantly reduced the data required for generalization - up to 27 times fewer transitions in the Key-to-Door environment - and eased the training process by making models less sensitive to hyperparameters. Our approach not only matches but often surpasses the performance of AD, demonstrating the potential of n-gram induction heads to enhance the efficiency of in-context RL.</li>
</ul>

<h3>Title: Deep Learning for Leopard Individual Identification: An Adaptive Angular Margin Approach</h3>
<ul>
<li><strong>Authors: </strong>David Colomer Matachana</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01962">https://arxiv.org/abs/2411.01962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01962">https://arxiv.org/pdf/2411.01962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01962]] Deep Learning for Leopard Individual Identification: An Adaptive Angular Margin Approach(https://arxiv.org/abs/2411.01962)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Accurate identification of individual leopards across camera trap images is critical for population monitoring and ecological studies. This paper introduces a deep learning framework to distinguish between individual leopards based on their unique spot patterns. This approach employs a novel adaptive angular margin method in the form of a modified CosFace architecture. In addition, I propose a preprocessing pipeline that combines RGB channels with an edge detection channel to underscore the critical features learned by the model. This approach significantly outperforms the Triplet Network baseline, achieving a Dynamic Top-5 Average Precision of 0.8814 and a Top-5 Rank Match Detection of 0.9533, demonstrating its potential for open-set learning in wildlife identification. While not surpassing the performance of the SIFT-based Hotspotter algorithm, this method represents a substantial advancement in applying deep learning to patterned wildlife identification. This research contributes to the field of computer vision and provides a valuable tool for biologists aiming to study and protect leopard populations. It also serves as a stepping stone for applying the power of deep learning in Capture-Recapture studies for other patterned species.</li>
</ul>

<h3>Title: UnSegMedGAT: Unsupervised Medical Image Segmentation using Graph Attention Networks Clustering</h3>
<ul>
<li><strong>Authors: </strong>A. Mudit Adityaja, Saurabh J. Shigwan, Nitin Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01966">https://arxiv.org/abs/2411.01966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01966">https://arxiv.org/pdf/2411.01966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01966]] UnSegMedGAT: Unsupervised Medical Image Segmentation using Graph Attention Networks Clustering(https://arxiv.org/abs/2411.01966)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The data-intensive nature of supervised classification drives the interest of the researchers towards unsupervised approaches, especially for problems such as medical image segmentation, where labeled data is scarce. Building on the recent advancements of Vision transformers (ViT) in computer vision, we propose an unsupervised segmentation framework using a pre-trained Dino-ViT. In the proposed method, we leverage the inherent graph structure within the image to realize a significant performance gain for segmentation in medical images. For this, we introduce a modularity-based loss function coupled with a Graph Attention Network (GAT) to effectively capture the inherent graph topology within the image. Our method achieves state-of-the-art performance, even significantly surpassing or matching that of existing (semi)supervised technique such as MedSAM which is a Segment Anything Model in medical images. We demonstrate this using two challenging medical image datasets ISIC-2018 and CVC-ColonDB. This work underscores the potential of unsupervised approaches in advancing medical image analysis in scenarios where labeled data is scarce. The github repository of the code is available on [this https URL].</li>
</ul>

<h3>Title: Active Gaze Behavior Boosts Self-Supervised Object Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhengyang Yu, Arthur Aubret, Marcel C. Raabe, Jane Yang, Chen Yu, Jochen Triesch</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01969">https://arxiv.org/abs/2411.01969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01969">https://arxiv.org/pdf/2411.01969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01969]] Active Gaze Behavior Boosts Self-Supervised Object Learning(https://arxiv.org/abs/2411.01969)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Due to significant variations in the projection of the same object from different viewpoints, machine learning algorithms struggle to recognize the same object across various perspectives. In contrast, toddlers quickly learn to recognize objects from different viewpoints with almost no supervision. Recent works argue that toddlers develop this ability by mapping close-in-time visual inputs to similar representations while interacting with objects. High acuity vision is only available in the central visual field, which may explain why toddlers (much like adults) constantly move their gaze around during such interactions. It is unclear whether/how much toddlers curate their visual experience through these eye movements to support learning object representations. In this work, we explore whether a bio inspired visual learning model can harness toddlers' gaze behavior during a play session to develop view-invariant object recognition. Exploiting head-mounted eye tracking during dyadic play, we simulate toddlers' central visual field experience by cropping image regions centered on the gaze location. This visual stream feeds a time-based self-supervised learning algorithm. Our experiments demonstrate that toddlers' gaze strategy supports the learning of invariant object representations. Our analysis also reveals that the limited size of the central visual field where acuity is high is crucial for this. We further find that toddlers' visual experience elicits more robust representations compared to adults' mostly because toddlers look at objects they hold themselves for longer bouts. Overall, our work reveals how toddlers' gaze behavior supports self-supervised learning of view-invariant object recognition.</li>
</ul>

<h3>Title: Adaptive Optimization of TLS Overhead for Wireless Communication in Critical Infrastructure</h3>
<ul>
<li><strong>Authors: </strong>Jörn Bodenhausen, Laurenz Grote, Michael Rademacher, Martin Henze</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01971">https://arxiv.org/abs/2411.01971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01971">https://arxiv.org/pdf/2411.01971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01971]] Adaptive Optimization of TLS Overhead for Wireless Communication in Critical Infrastructure(https://arxiv.org/abs/2411.01971)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With critical infrastructure increasingly relying on wireless communication, using end-to-end security such as TLS becomes imperative. However, TLS introduces significant overhead for resource-constrained devices and networks prevalent in critical infrastructure. In this paper, we propose to leverage the degrees of freedom in configuring TLS to dynamically adapt algorithms, parameters, and other settings to best meet the currently occurring resource and security constraints in a wireless communication scenario. Consequently, we can make the best use of scarce resources to provide tightened security for wireless networks in critical infrastructure.</li>
</ul>

<h3>Title: The Certainty Ratio $C_\rho$: a novel metric for assessing the reliability of classifier predictions</h3>
<ul>
<li><strong>Authors: </strong>Jesus S. Aguilar-Ruiz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01973">https://arxiv.org/abs/2411.01973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01973">https://arxiv.org/pdf/2411.01973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01973]] The Certainty Ratio $C_\rho$: a novel metric for assessing the reliability of classifier predictions(https://arxiv.org/abs/2411.01973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Evaluating the performance of classifiers is critical in machine learning, particularly in high-stakes applications where the reliability of predictions can significantly impact decision-making. Traditional performance measures, such as accuracy and F-score, often fail to account for the uncertainty inherent in classifier predictions, leading to potentially misleading assessments. This paper introduces the Certainty Ratio ($C_\rho$), a novel metric designed to quantify the contribution of confident (certain) versus uncertain predictions to any classification performance measure. By integrating the Probabilistic Confusion Matrix ($CM^\star$) and decomposing predictions into certainty and uncertainty components, $C_\rho$ provides a more comprehensive evaluation of classifier reliability. Experimental results across 26 datasets and multiple classifiers, including Decision Trees, Naive-Bayes, 3-Nearest Neighbors, and Random Forests, demonstrate that $C_\rho$ reveals critical insights that conventional metrics often overlook. These findings emphasize the importance of incorporating probabilistic information into classifier evaluation, offering a robust tool for researchers and practitioners seeking to improve model trustworthiness in complex environments.</li>
</ul>

<h3>Title: Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance</h3>
<ul>
<li><strong>Authors: </strong>Charles Camboulin, Diego Doimo, Aldo Glielmo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01978">https://arxiv.org/abs/2411.01978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01978">https://arxiv.org/pdf/2411.01978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01978]] Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance(https://arxiv.org/abs/2411.01978)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This work presents an analysis of the hidden representations of Variational Autoencoders (VAEs) using the Intrinsic Dimension (ID) and the Information Imbalance (II). We show that VAEs undergo a transition in behaviour once the bottleneck size is larger than the ID of the data, manifesting in a double hunchback ID profile and a qualitative shift in information processing as captured by the II. Our results also highlight two distinct training phases for architectures with sufficiently large bottleneck sizes, consisting of a rapid fit and a slower generalisation, as assessed by a differentiated behaviour of ID, II, and KL loss. These insights demonstrate that II and ID could be valuable tools for aiding architecture search, for diagnosing underfitting in VAEs, and, more broadly, they contribute to advancing a unified understanding of deep generative models through geometric analysis.</li>
</ul>

<h3>Title: Ask, and it shall be given: Turing completeness of prompting</h3>
<ul>
<li><strong>Authors: </strong>Ruizhong Qiu, Zhe Xu, Wenxuan Bao, Hanghang Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01992">https://arxiv.org/abs/2411.01992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01992">https://arxiv.org/pdf/2411.01992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01992]] Ask, and it shall be given: Turing completeness of prompting(https://arxiv.org/abs/2411.01992)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Since the success of GPT, large language models (LLMs) have been revolutionizing machine learning and have initiated the so-called LLM prompting paradigm. In the era of LLMs, people train a single general-purpose LLM and provide the LLM with different prompts to perform different tasks. However, such empirical success largely lacks theoretical understanding. Here, we present the first theoretical study on the LLM prompting paradigm to the best of our knowledge. In this work, we show that prompting is in fact Turing-complete: there exists a finite-size Transformer such that for any computable function, there exists a corresponding prompt following which the Transformer computes the function. Furthermore, we show that even though we use only a single finite-size Transformer, it can still achieve nearly the same complexity bounds as that of the class of all unbounded-size Transformers. Overall, our result reveals that prompting can enable a single finite-size Transformer to be efficiently universal, which establishes a theoretical underpinning for prompt engineering in practice.</li>
</ul>

<h3>Title: Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task</h3>
<ul>
<li><strong>Authors: </strong>Hoonick Lee, Mogan Gim, Donghyeon Park, Donghee Choi, Jaewoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01996">https://arxiv.org/abs/2411.01996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01996">https://arxiv.org/pdf/2411.01996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01996]] Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task(https://arxiv.org/abs/2411.01996)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) have shown promise in various creative domains, including culinary arts. However, many LLMs still struggle to deliver the desired level of culinary creativity, especially when tasked with adapting recipes to meet specific cultural requirements. This study focuses on cuisine transfer-applying elements of one cuisine to another-to assess LLMs' culinary creativity. We employ a diverse set of LLMs to generate and evaluate culturally adapted recipes, comparing their evaluations against LLM and human judgments. We introduce the ASH (authenticity, sensitivity, harmony) benchmark to evaluate LLMs' recipe generation abilities in the cuisine transfer task, assessing their cultural accuracy and creativity in the culinary domain. Our findings reveal crucial insights into both generative and evaluative capabilities of LLMs in the culinary domain, highlighting strengths and limitations in understanding and applying cultural nuances in recipe creation. The code and dataset used in this project will be openly available in \url{this http URL}.</li>
</ul>

<h3>Title: Against Multifaceted Graph Heterogeneity via Asymmetric Federated Prompt Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhuoning Guo, Ruiqian Han, Hao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02003">https://arxiv.org/abs/2411.02003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02003">https://arxiv.org/pdf/2411.02003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02003]] Against Multifaceted Graph Heterogeneity via Asymmetric Federated Prompt Learning(https://arxiv.org/abs/2411.02003)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Graph Learning (FGL) aims to collaboratively and privately optimize graph models on divergent data for different tasks. A critical challenge in FGL is to enable effective yet efficient federated optimization against multifaceted graph heterogeneity to enhance mutual performance. However, existing FGL works primarily address graph data heterogeneity and perform incapable of graph task heterogeneity. To address the challenge, we propose a Federated Graph Prompt Learning (FedGPL) framework to efficiently enable prompt-based asymmetric graph knowledge transfer between multifaceted heterogeneous federated participants. Generally, we establish a split federated framework to preserve universal and domain-specific graph knowledge, respectively. Moreover, we develop two algorithms to eliminate task and data heterogeneity for advanced federated knowledge preservation. First, a Hierarchical Directed Transfer Aggregator (HiDTA) delivers cross-task beneficial knowledge that is hierarchically distilled according to the directional transferability. Second, a Virtual Prompt Graph (VPG) adaptively generates graph structures to enhance data utility by distinguishing dominant subgraphs and neutralizing redundant ones. We conduct theoretical analyses and extensive experiments to demonstrate the significant accuracy and efficiency effectiveness of FedGPL against multifaceted graph heterogeneity compared to state-of-the-art baselines on large-scale federated graph datasets.</li>
</ul>

<h3>Title: Tree level change detection over Ahmedabad city using very high resolution satellite images and Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Jai G Singla, Gautam Jaiswal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02009">https://arxiv.org/abs/2411.02009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02009">https://arxiv.org/pdf/2411.02009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02009]] Tree level change detection over Ahmedabad city using very high resolution satellite images and Deep Learning(https://arxiv.org/abs/2411.02009)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this study, 0.5m high resolution satellite datasets over Indian urban region was used to demonstrate the applicability of deep learning models over Ahmedabad, India. Here, YOLOv7 instance segmentation model was trained on well curated trees canopy dataset (6500 images) in order to carry out the change detection. During training, evaluation metrics such as bounding box regression and mask regression loss, mean average precision (mAP) and stochastic gradient descent algorithm were used for evaluating and optimizing the performance of model. After the 500 epochs, the mAP of 0.715 and 0.699 for individual tree detection and tree canopy mask segmentation were obtained. However, by further tuning hyper parameters of the model, maximum accuracy of 80 % of trees detection with false segmentation rate of 2% on data was obtained.</li>
</ul>

<h3>Title: Shortcut Learning in In-Context Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Rui Song, Yingji Li, Fausto Giunchiglia, Hao Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02018">https://arxiv.org/abs/2411.02018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02018">https://arxiv.org/pdf/2411.02018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02018]] Shortcut Learning in In-Context Learning: A Survey(https://arxiv.org/abs/2411.02018)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Shortcut learning refers to the phenomenon where models employ simple, non-robust decision rules in practical tasks, which hinders their generalization and robustness. With the rapid development of large language models (LLMs) in recent years, an increasing number of studies have shown the impact of shortcut learning on LLMs. This paper provides a novel perspective to review relevant research on shortcut learning in In-Context Learning (ICL). It conducts a detailed exploration of the types of shortcuts in ICL tasks, their causes, available benchmarks, and strategies for mitigating shortcuts. Based on corresponding observations, it summarizes the unresolved issues in existing research and attempts to outline the future research landscape of shortcut learning.</li>
</ul>

<h3>Title: Optimal Classification under Performative Distribution Shift</h3>
<ul>
<li><strong>Authors: </strong>Edwige Cyffers (MAGNET), Muni Sreenivas Pydi (MILES, LAMSADE), Jamal Atif (LAMSADE), Olivier Cappé (DI-ENS)</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02023">https://arxiv.org/abs/2411.02023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02023">https://arxiv.org/pdf/2411.02023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02023]] Optimal Classification under Performative Distribution Shift(https://arxiv.org/abs/2411.02023)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Performative learning addresses the increasingly pervasive situations in which algorithmic decisions may induce changes in the data distribution as a consequence of their public deployment. We propose a novel view in which these performative effects are modelled as push-forward measures. This general framework encompasses existing models and enables novel performative gradient estimation methods, leading to more efficient and scalable learning strategies. For distribution shifts, unlike previous models which require full specification of the data distribution, we only assume knowledge of the shift operator that represents the performative changes. This approach can also be integrated into various change-of-variablebased models, such as VAEs or normalizing flows. Focusing on classification with a linear-in-parameters performative effect, we prove the convexity of the performative risk under a new set of assumptions. Notably, we do not limit the strength of performative effects but rather their direction, requiring only that classification becomes harder when deploying more accurate models. In this case, we also establish a connection with adversarially robust classification by reformulating the minimization of the performative risk as a min-max variational problem. Finally, we illustrate our approach on synthetic and real datasets.</li>
</ul>

<h3>Title: Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Francisco de Arriba-Pérez, Silvia García-Méndez, Javier Otero-Mosquera, Francisco J. González-Castaño</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02036">https://arxiv.org/abs/2411.02036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02036">https://arxiv.org/pdf/2411.02036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02036]] Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models(https://arxiv.org/abs/2411.02036)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Cognitive and neurological impairments are very common, but only a small proportion of affected individuals are diagnosed and treated, partly because of the high costs associated with frequent screening. Detecting pre-illness stages and analyzing the progression of neurological disorders through effective and efficient intelligent systems can be beneficial for timely diagnosis and early intervention. We propose using Large Language Models to extract features from free dialogues to detect cognitive decline. These features comprise high-level reasoning content-independent features (such as comprehension, decreased awareness, increased distraction, and memory problems). Our solution comprises (i) preprocessing, (ii) feature engineering via Natural Language Processing techniques and prompt engineering, (iii) feature analysis and selection to optimize performance, and (iv) classification, supported by automatic explainability. We also explore how to improve Chatgpt's direct cognitive impairment prediction capabilities using the best features in our models. Evaluation metrics obtained endorse the effectiveness of a mixed approach combining feature extraction with Chatgpt and a specialized Machine Learning model to detect cognitive decline within free-form conversational dialogues with older adults. Ultimately, our work may facilitate the development of an inexpensive, non-invasive, and rapid means of detecting and explaining cognitive decline.</li>
</ul>

<h3>Title: Addressing Representation Collapse in Vector Quantized Models with One Linear Layer</h3>
<ul>
<li><strong>Authors: </strong>Yongxin Zhu, Bocheng Li, Yifei Xin, Linli Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02038">https://arxiv.org/abs/2411.02038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02038">https://arxiv.org/pdf/2411.02038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02038]] Addressing Representation Collapse in Vector Quantized Models with One Linear Layer(https://arxiv.org/abs/2411.02038)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vector Quantization (VQ) is a widely used method for converting continuous representations into discrete codes, which has become fundamental in unsupervised representation learning and latent generative models. However, VQ models are often hindered by the problem of representation collapse in the latent space, which leads to low codebook utilization and limits the scalability of the codebook for large-scale training. Existing methods designed to mitigate representation collapse typically reduce the dimensionality of latent space at the expense of model capacity, which do not fully resolve the core issue. In this study, we conduct a theoretical analysis of representation collapse in VQ models and identify its primary cause as the disjoint optimization of the codebook, where only a small subset of code vectors are updated through gradient descent. To address this issue, we propose \textbf{SimVQ}, a novel method which reparameterizes the code vectors through a linear transformation layer based on a learnable latent basis. This transformation optimizes the \textit{entire linear space} spanned by the codebook, rather than merely updating \textit{the code vector} selected by the nearest-neighbor search in vanilla VQ models. Although it is commonly understood that the multiplication of two linear matrices is equivalent to applying a single linear layer, our approach works surprisingly well in resolving the collapse issue in VQ models with just one linear layer. We validate the efficacy of SimVQ through extensive experiments across various modalities, including image and audio data with different model architectures. Our code is available at \url{this https URL}.</li>
</ul>

<h3>Title: R+R:Understanding Hyperparameter Effects in DP-SGD</h3>
<ul>
<li><strong>Authors: </strong>Felix Morsbach, Jan Reubold, Thorsten Strufe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02051">https://arxiv.org/abs/2411.02051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02051">https://arxiv.org/pdf/2411.02051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02051]] R+R:Understanding Hyperparameter Effects in DP-SGD(https://arxiv.org/abs/2411.02051)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Research on the effects of essential hyperparameters of DP-SGD lacks consensus, verification, and replication. Contradictory and anecdotal statements on their influence make matters worse. While DP-SGD is the standard optimization algorithm for privacy-preserving machine learning, its adoption is still commonly challenged by low performance compared to non-private learning approaches. As proper hyperparameter settings can improve the privacy-utility trade-off, understanding the influence of the hyperparameters promises to simplify their optimization towards better performance, and likely foster acceptance of private learning. To shed more light on these influences, we conduct a replication study: We synthesize extant research on hyperparameter influences of DP-SGD into conjectures, conduct a dedicated factorial study to independently identify hyperparameter effects, and assess which conjectures can be replicated across multiple datasets, model architectures, and differential privacy budgets. While we cannot (consistently) replicate conjectures about the main and interaction effects of the batch size and the number of epochs, we were able to replicate the conjectured relationship between the clipping threshold and learning rate. Furthermore, we were able to quantify the significant importance of their combination compared to the other hyperparameters.</li>
</ul>

<h3>Title: Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yan Li, Weiwei Guo, Xue Yang, Ning Liao, Shaofeng Zhang, Yi Yu, Wenxian Yu, Junchi Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02057">https://arxiv.org/abs/2411.02057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02057">https://arxiv.org/pdf/2411.02057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02057]] Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation(https://arxiv.org/abs/2411.02057)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, aerial object detection has been increasingly pivotal in various earth observation applications. However, current algorithms are limited to detecting a set of pre-defined object categories, demanding sufficient annotated training samples, and fail to detect novel object categories. In this paper, we put forth a novel formulation of the aerial object detection problem, namely open-vocabulary aerial object detection (OVAD), which can detect objects beyond training categories without costly collecting new labeled data. We propose CastDet, a CLIP-activated student-teacher detection framework that serves as the first OVAD detector specifically designed for the challenging aerial scenario, where objects often exhibit weak appearance features and arbitrary orientations. Our framework integrates a robust localization teacher along with several box selection strategies to generate high-quality proposals for novel objects. Additionally, the RemoteCLIP model is adopted as an omniscient teacher, which provides rich knowledge to enhance classification capabilities for novel categories. A dynamic label queue is devised to maintain high-quality pseudo-labels during training. By doing so, the proposed CastDet boosts not only novel object proposals but also classification. Furthermore, we extend our approach from horizontal OVAD to oriented OVAD with tailored algorithm designs to effectively manage bounding box representation and pseudo-label generation. Extensive experiments for both tasks on multiple existing aerial object detection datasets demonstrate the effectiveness of our approach. The code is available at this https URL.</li>
</ul>

<h3>Title: TableGPT2: A Large Multimodal Model with Tabular Data Integration</h3>
<ul>
<li><strong>Authors: </strong>Aofeng Su, Aowen Wang, Chao Ye, Chen Zhou, Ga Zhang, Guangcheng Zhu, Haobo Wang, Haokai Xu, Hao Chen, Haoze Li, Haoxuan Lan, Jiaming Tian, Jing Yuan, Junbo Zhao, Junlin Zhou, Kaizhe Shou, Liangyu Zha, Lin Long, Liyao Li, Pengzuo Wu, Qi Zhang, Qingyi Huang, Saisai Yang, Tao Zhang, Wentao Ye, Wufang Zhu, Xiaomeng Hu, Xijun Gu, Xinjie Sun, Xiang Li, Yuhang Yang, Zhiqing Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02059">https://arxiv.org/abs/2411.02059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02059">https://arxiv.org/pdf/2411.02059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02059]] TableGPT2: A Large Multimodal Model with Tabular Data Integration(https://arxiv.org/abs/2411.02059)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The emergence of models like GPTs, Claude, LLaMA, and Qwen has reshaped AI applications, presenting vast new opportunities across industries. Yet, the integration of tabular data remains notably underdeveloped, despite its foundational role in numerous real-world domains. This gap is critical for three main reasons. First, database or data warehouse data integration is essential for advanced applications; second, the vast and largely untapped resource of tabular data offers immense potential for analysis; and third, the business intelligence domain specifically demands adaptable, precise solutions that many current LLMs may struggle to provide. In response, we introduce TableGPT2, a model rigorously pre-trained and fine-tuned with over 593.8K tables and 2.36M high-quality query-table-output tuples, a scale of table-related data unprecedented in prior research. This extensive training enables TableGPT2 to excel in table-centric tasks while maintaining strong general language and coding abilities. One of TableGPT2's key innovations is its novel table encoder, specifically designed to capture schema-level and cell-level information. This encoder strengthens the model's ability to handle ambiguous queries, missing column names, and irregular tables commonly encountered in real-world applications. Similar to visual language models, this pioneering approach integrates with the decoder to form a robust large multimodal model. We believe the results are compelling: over 23 benchmarking metrics, TableGPT2 achieves an average performance improvement of 35.20% in the 7B model and 49.32% in the 72B model over prior benchmark-neutral LLMs, with robust general-purpose capabilities intact.</li>
</ul>

<h3>Title: Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention</h3>
<ul>
<li><strong>Authors: </strong>Xingtai Lv, Ning Ding, Kaiyan Zhang, Ermo Hua, Ganqu Cui, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02063">https://arxiv.org/abs/2411.02063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02063">https://arxiv.org/pdf/2411.02063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02063]] Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention(https://arxiv.org/abs/2411.02063)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Improving the effectiveness and efficiency of large language models (LLMs) simultaneously is a critical yet challenging research goal. In this paper, we find that low-rank pre-training, normally considered as efficient methods that will compromise performance, can be scalably effective when reduced parameters are precisely targeted. Specifically, applying the low-dimensional module only to the attention layer -- resolves this issue and enhances both effectiveness and efficiency. We refer to this structure as Low-dimensional Projected Attention (LPA) and provide an explanatory analysis. Through extensive experimentation at parameter scales of 130M, 370M, and scaling up to 3B, we have validated the effectiveness and scalability of LPA. Our results show that LPA model can save up to 12.4% in time while achieving an approximate 5% improvement in test perplexity (ppl) and on downstream tasks compared with the vanilla Transformer.</li>
</ul>

<h3>Title: AM Flow: Adapters for Temporal Processing in Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Tanay Agrawal, Abid Ali, Antitza Dantcheva, Francois Bremond</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02065">https://arxiv.org/abs/2411.02065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02065">https://arxiv.org/pdf/2411.02065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02065]] AM Flow: Adapters for Temporal Processing in Action Recognition(https://arxiv.org/abs/2411.02065)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning models, in particular \textit{image} models, have recently gained generalisability and robustness. %are becoming more general and robust by the day. In this work, we propose to exploit such advances in the realm of \textit{video} classification. Video foundation models suffer from the requirement of extensive pretraining and a large training time. Towards mitigating such limitations, we propose "\textit{Attention Map (AM) Flow}" for image models, a method for identifying pixels relevant to motion in each input video frame. In this context, we propose two methods to compute AM flow, depending on camera motion. AM flow allows the separation of spatial and temporal processing, while providing improved results over combined spatio-temporal processing (as in video models). Adapters, one of the popular techniques in parameter efficient transfer learning, facilitate the incorporation of AM flow into pretrained image models, mitigating the need for full-finetuning. We extend adapters to "\textit{temporal processing adapters}" by incorporating a temporal processing unit into the adapters. Our work achieves faster convergence, therefore reducing the number of epochs needed for training. Moreover, we endow an image model with the ability to achieve state-of-the-art results on popular action recognition datasets. This reduces training time and simplifies pretraining. We present experiments on Kinetics-400, Something-Something v2, and Toyota Smarthome datasets, showcasing state-of-the-art or comparable results.</li>
</ul>

<h3>Title: Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling</h3>
<ul>
<li><strong>Authors: </strong>Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Hao Wang, Yin Gu, Zheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02066">https://arxiv.org/abs/2411.02066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02066">https://arxiv.org/pdf/2411.02066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02066]] Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling(https://arxiv.org/abs/2411.02066)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Learners sharing similar implicit cognitive states often display comparable observable problem-solving performances. Leveraging collaborative connections among such similar learners proves valuable in comprehending human learning. Motivated by the success of collaborative modeling in various domains, such as recommender systems, we aim to investigate how collaborative signals among learners contribute to the diagnosis of human cognitive states (i.e., knowledge proficiency) in the context of intelligent education. The primary challenges lie in identifying implicit collaborative connections and disentangling the entangled cognitive factors of learners for improved explainability and controllability in learner Cognitive Diagnosis (CD). However, there has been no work on CD capable of simultaneously modeling collaborative and disentangled cognitive states. To address this gap, we present Coral, a Collaborative cognitive diagnosis model with disentangled representation learning. Specifically, Coral first introduces a disentangled state encoder to achieve the initial disentanglement of learners' states. Subsequently, a meticulously designed collaborative representation learning procedure captures collaborative signals. It dynamically constructs a collaborative graph of learners by iteratively searching for optimal neighbors in a context-aware manner. Using the constructed graph, collaborative information is extracted through node representation learning. Finally, a decoding process aligns the initial cognitive states and collaborative states, achieving co-disentanglement with practice performance reconstructions. Extensive experiments demonstrate the superior performance of Coral, showcasing significant improvements over state-of-the-art methods across several real-world datasets. Our code is available at this https URL.</li>
</ul>

<h3>Title: Model Integrity when Unlearning with T2I Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Andrea Schioppa, Emiel Hoogeboom, Jonathan Heek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02068">https://arxiv.org/abs/2411.02068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02068">https://arxiv.org/pdf/2411.02068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02068]] Model Integrity when Unlearning with T2I Diffusion Models(https://arxiv.org/abs/2411.02068)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid advancement of text-to-image Diffusion Models has led to their widespread public accessibility. However these models, trained on large internet datasets, can sometimes generate undesirable outputs. To mitigate this, approximate Machine Unlearning algorithms have been proposed to modify model weights to reduce the generation of specific types of images, characterized by samples from a ``forget distribution'', while preserving the model's ability to generate other images, characterized by samples from a ``retain distribution''. While these methods aim to minimize the influence of training data in the forget distribution without extensive additional computation, we point out that they can compromise the model's integrity by inadvertently affecting generation for images in the retain distribution. Recognizing the limitations of FID and CLIPScore in capturing these effects, we introduce a novel retention metric that directly assesses the perceptual difference between outputs generated by the original and the unlearned models. We then propose unlearning algorithms that demonstrate superior effectiveness in preserving model integrity compared to existing baselines. Given their straightforward implementation, these algorithms serve as valuable benchmarks for future advancements in approximate Machine Unlearning for Diffusion Models.</li>
</ul>

<h3>Title: BlindexTEE: A Blind Index Approach towards TEE-supported End-to-end Encrypted DBMS</h3>
<ul>
<li><strong>Authors: </strong>Louis Vialar, Jämes Ménétrey, Valerio Schiavoni, Pascal Felber</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02084">https://arxiv.org/abs/2411.02084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02084">https://arxiv.org/pdf/2411.02084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02084]] BlindexTEE: A Blind Index Approach towards TEE-supported End-to-end Encrypted DBMS(https://arxiv.org/abs/2411.02084)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Using cloud-based applications comes with privacy implications, as the end-user looses control over their data. While encrypting all data on the client is possible, it largely reduces the usefulness of database management systems (DBMS) that are typically built to efficiently query large quantities of data. We present BlindexTEE, a new component that sits between the application business-logic and the database. BlindexTEE is shielded from malicious users or compromised environments by executing inside an SEV-SNP confidential VM, AMD's trusted execution environment (TEE). BlindexTEE is in charge of end-to-end encryption of user data while preserving the ability of the DBMS to efficiently filter data. By decrypting and re-encrypting data, it builds blind indices, used later on to efficiently query the DBMS. We demonstrate the practicality of BlindexTEE with MySQL in several micro- and macro-benchmarks, achieving overheads between 36.1% and 462% over direct database access depending on the usage scenario.</li>
</ul>

<h3>Title: Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Idris Zakariyya, Linda Tran, Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02099">https://arxiv.org/abs/2411.02099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02099">https://arxiv.org/pdf/2411.02099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02099]] Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition(https://arxiv.org/abs/2411.02099)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust, membership infer</a></li>
<li><strong>Abstract: </strong>Human motion analysis offers significant potential for healthcare monitoring and early detection of diseases. The advent of radar-based sensing systems has captured the spotlight for they are able to operate without physical contact and they can integrate with pre-existing Wi-Fi networks. They are also seen as less privacy-invasive compared to camera-based systems. However, recent research has shown high accuracy in recognizing subjects or gender from radar gait patterns, raising privacy concerns. This study addresses these issues by investigating privacy vulnerabilities in radar-based Human Activity Recognition (HAR) systems and proposing a novel method for privacy preservation using Differential Privacy (DP) driven by attributions derived with Integrated Decision Gradient (IDG) algorithm. We investigate Black-box Membership Inference Attack (MIA) Models in HAR settings across various levels of attacker-accessible information. We extensively evaluated the effectiveness of the proposed IDG-DP method by designing a CNN-based HAR model and rigorously assessing its resilience against MIAs. Experimental results demonstrate the potential of IDG-DP in mitigating privacy attacks while maintaining utility across all settings, particularly excelling against label-only and shadow model black-box MIA attacks. This work represents a crucial step towards balancing the need for effective radar-based HAR with robust privacy protection in healthcare environments.</li>
</ul>

<h3>Title: Deep Learning on 3D Semantic Segmentation: A Detailed Review</h3>
<ul>
<li><strong>Authors: </strong>Thodoris Betsas, Andreas Georgopoulos, Anastasios Doulamis, Pierre Grussenmeyer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02104">https://arxiv.org/abs/2411.02104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02104">https://arxiv.org/pdf/2411.02104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02104]] Deep Learning on 3D Semantic Segmentation: A Detailed Review(https://arxiv.org/abs/2411.02104)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper an exhaustive review and comprehensive analysis of recent and former deep learning methods in 3D Semantic Segmentation (3DSS) is presented. In the related literature, the taxonomy scheme used for the classification of the 3DSS deep learning methods is ambiguous. Based on the taxonomy schemes of 9 existing review papers, a new taxonomy scheme of the 3DSS deep learning methods is proposed, aiming to standardize it and improve the comparability and clarity across related studies. Furthermore, an extensive overview of the available 3DSS indoor and outdoor datasets is provided along with their links. The core part of the review is the detailed presentation of recent and former 3DSS deep learning methods and their classification using the proposed taxonomy scheme along with their GitHub repositories. Additionally, a brief but informative analysis of the evaluation metrics and loss functions used in 3DSS is included. Finally, a fruitful discussion of the examined 3DSS methods and datasets, is presented to foster new research directions and applications in the field of 3DSS. Supplementary, to this review a GitHub repository is provided (this https URL Detailed-Review) including a quick classification of over 400 3DSS methods, using the proposed taxonomy scheme.</li>
</ul>

<h3>Title: Multi-modal biometric authentication: Leveraging shared layer architectures for enhanced security</h3>
<ul>
<li><strong>Authors: </strong>Vatchala S, Yogesh C, Yeshwanth Govindarajan, Krithik Raja M, Vishal Pramav Amirtha Ganesan, Aashish Vinod A, Dharun Ramesh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02112">https://arxiv.org/abs/2411.02112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02112">https://arxiv.org/pdf/2411.02112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02112]] Multi-modal biometric authentication: Leveraging shared layer architectures for enhanced security(https://arxiv.org/abs/2411.02112)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust, biometric, extraction</a></li>
<li><strong>Abstract: </strong>In this study, we introduce a novel multi-modal biometric authentication system that integrates facial, vocal, and signature data to enhance security measures. Utilizing a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), our model architecture uniquely incorporates dual shared layers alongside modality-specific enhancements for comprehensive feature extraction. The system undergoes rigorous training with a joint loss function, optimizing for accuracy across diverse biometric inputs. Feature-level fusion via Principal Component Analysis (PCA) and classification through Gradient Boosting Machines (GBM) further refine the authentication process. Our approach demonstrates significant improvements in authentication accuracy and robustness, paving the way for advanced secure identity verification solutions.</li>
</ul>

<h3>Title: FedMoE-DA: Federated Mixture of Experts via Domain Aware Fine-grained Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Ziwei Zhan, Wenkuan Zhao, Yuanqing Li, Weijie Liu, Xiaoxi Zhang, Chee Wei Tan, Chuan Wu, Deke Guo, Xu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02115">https://arxiv.org/abs/2411.02115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02115">https://arxiv.org/pdf/2411.02115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02115]] FedMoE-DA: Federated Mixture of Experts via Domain Aware Fine-grained Aggregation(https://arxiv.org/abs/2411.02115)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a collaborative machine learning approach that enables multiple clients to train models without sharing their private data. With the rise of deep learning, large-scale models have garnered significant attention due to their exceptional performance. However, a key challenge in FL is the limitation imposed by clients with constrained computational and communication resources, which hampers the deployment of these large models. The Mixture of Experts (MoE) architecture addresses this challenge with its sparse activation property, which reduces computational workload and communication demands during inference and updates. Additionally, MoE facilitates better personalization by allowing each expert to specialize in different subsets of the data distribution. To alleviate the communication burdens between the server and clients, we propose FedMoE-DA, a new FL model training framework that leverages the MoE architecture and incorporates a novel domain-aware, fine-grained aggregation strategy to enhance the robustness, personalizability, and communication efficiency simultaneously. Specifically, the correlation between both intra-client expert models and inter-client data heterogeneity is exploited. Moreover, we utilize peer-to-peer (P2P) communication between clients for selective expert model synchronization, thus significantly reducing the server-client transmissions. Experiments demonstrate that our FedMoE-DA achieves excellent performance while reducing the communication pressure on the server.</li>
</ul>

<h3>Title: Advancements and limitations of LLMs in replicating human color-word associations</h3>
<ul>
<li><strong>Authors: </strong>Makoto Fukushima, Shusuke Eshita, Hiroshige Fukuhara</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.GR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02116">https://arxiv.org/abs/2411.02116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02116">https://arxiv.org/pdf/2411.02116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02116]] Advancements and limitations of LLMs in replicating human color-word associations(https://arxiv.org/abs/2411.02116)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Color-word associations play a fundamental role in human cognition and design applications. Large Language Models (LLMs) have become widely available and demonstrated intelligent behaviors in various benchmarks with natural conversation skills. However, their ability to replicate human color-word associations remains understudied. We compared multiple generations of LLMs (from GPT-3 to GPT- 4o) against human color-word associations using data collected from over 10,000 Japanese participants, involving 17 colors and words from eight categories in Japanese. Our findings reveal a clear progression in LLM performance across generations, with GPT-4o achieving the highest accuracy in predicting the best voted word for each color and category, particularly when using visual inputs rather than text-based color codes. However, the highest median performance was approximately 50% even for GPT4-o with visual inputs (chance level is 10%), and the performance levels varied significantly across word categories and colors, indicating a failure to fully replicate human color-word associations. On the other hand, color discrimination ability estimated from our color-word association data showed that LLMs demonstrated high correlation with human color discrimination patterns, similarly to previous studies. Our study highlights both the advancements in LLM capabilities and their persistent limitations, suggesting differences in semantic memory structures between humans and LLMs in representing color-word associations.</li>
</ul>

<h3>Title: AVSS: Layer Importance Evaluation in Large Language Models via Activation Variance-Sparsity Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zichen Song, Yuxin Wu, Sitan Huang, Zhongfeng Kang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02117">https://arxiv.org/abs/2411.02117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02117">https://arxiv.org/pdf/2411.02117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02117]] AVSS: Layer Importance Evaluation in Large Language Models via Activation Variance-Sparsity Analysis(https://arxiv.org/abs/2411.02117)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The evaluation of layer importance in deep learning has been an active area of research, with significant implications for model optimization and interpretability. Recently, large language models (LLMs) have gained prominence across various domains, yet limited studies have explored the functional importance and performance contributions of individual layers within LLMs, especially from the perspective of activation distribution. In this work, we propose the Activation Variance-Sparsity Score (AVSS), a novel metric combining normalized activation variance and sparsity to assess each layer's contribution to model performance. By identifying and removing approximately the lowest 25% of layers based on AVSS, we achieve over 90% of original model performance across tasks such as question answering, language modeling, and sentiment classification, indicating that these layers may be non-essential. Our approach provides a systematic method for identifying less critical layers, contributing to efficient large language model architectures.</li>
</ul>

<h3>Title: Bridge-IF: Learning Inverse Protein Folding with Markov Bridges</h3>
<ul>
<li><strong>Authors: </strong>Yiheng Zhu, Jialu Wu, Qiuyi Li, Jiahuan Yan, Mingze Yin, Wei Wu, Mingyang Li, Jieping Ye, Zheng Wang, Jian Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02120">https://arxiv.org/abs/2411.02120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02120">https://arxiv.org/pdf/2411.02120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02120]] Bridge-IF: Learning Inverse Protein Folding with Markov Bridges(https://arxiv.org/abs/2411.02120)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Inverse protein folding is a fundamental task in computational protein design, which aims to design protein sequences that fold into the desired backbone structures. While the development of machine learning algorithms for this task has seen significant success, the prevailing approaches, which predominantly employ a discriminative formulation, frequently encounter the error accumulation issue and often fail to capture the extensive variety of plausible sequences. To fill these gaps, we propose Bridge-IF, a generative diffusion bridge model for inverse folding, which is designed to learn the probabilistic dependency between the distributions of backbone structures and protein sequences. Specifically, we harness an expressive structure encoder to propose a discrete, informative prior derived from structures, and establish a Markov bridge to connect this prior with native sequences. During the inference stage, Bridge-IF progressively refines the prior sequence, culminating in a more plausible design. Moreover, we introduce a reparameterization perspective on Markov bridge models, from which we derive a simplified loss function that facilitates more effective training. We also modulate protein language models (PLMs) with structural conditions to precisely approximate the Markov bridge process, thereby significantly enhancing generation performance while maintaining parameter-efficient training. Extensive experiments on well-established benchmarks demonstrate that Bridge-IF predominantly surpasses existing baselines in sequence recovery and excels in the design of plausible proteins with high foldability. The code is available at this https URL.</li>
</ul>

<h3>Title: Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Kola Ayonrinde</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02124">https://arxiv.org/abs/2411.02124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02124">https://arxiv.org/pdf/2411.02124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02124]] Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders(https://arxiv.org/abs/2411.02124)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) are a promising approach to extracting features from neural networks, enabling model interpretability as well as causal interventions on model internals. SAEs generate sparse feature representations using a sparsifying activation function that implicitly defines a set of token-feature matches. We frame the token-feature matching as a resource allocation problem constrained by a total sparsity upper bound. For example, TopK SAEs solve this allocation problem with the additional constraint that each token matches with at most $k$ features. In TopK SAEs, the $k$ active features per token constraint is the same across tokens, despite some tokens being more difficult to reconstruct than others. To address this limitation, we propose two novel SAE variants, Feature Choice SAEs and Mutual Choice SAEs, which each allow for a variable number of active features per token. Feature Choice SAEs solve the sparsity allocation problem under the additional constraint that each feature matches with at most $m$ tokens. Mutual Choice SAEs solve the unrestricted allocation problem where the total sparsity budget can be allocated freely between tokens and features. Additionally, we introduce a new auxiliary loss function, $\mathtt{aux\_zipf\_loss}$, which generalises the $\mathtt{aux\_k\_loss}$ to mitigate dead and underutilised features. Our methods result in SAEs with fewer dead features and improved reconstruction loss at equivalent sparsity levels as a result of the inherent adaptive computation. More accurate and scalable feature extraction methods provide a path towards better understanding and more precise control of foundation models.</li>
</ul>

<h3>Title: Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery</h3>
<ul>
<li><strong>Authors: </strong>Robert Fonod, Haechan Cho, Hwasoo Yeo, Nikolas Geroliminis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02136">https://arxiv.org/abs/2411.02136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02136">https://arxiv.org/pdf/2411.02136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02136]] Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery(https://arxiv.org/abs/2411.02136)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a framework for extracting georeferenced vehicle trajectories from high-altitude drone footage, addressing key challenges in urban traffic monitoring and limitations of traditional ground-based systems. We employ state-of-the-art computer vision and deep learning to create an end-to-end pipeline that enhances vehicle detection, tracking, and trajectory stabilization. Conducted in the Songdo International Business District, South Korea, the study used a multi-drone experiment over 20 intersections, capturing approximately 12TB of 4K video data over four days. We developed a novel track stabilization method that uses detected vehicle bounding boxes as exclusion masks during image registration, which, combined with advanced georeferencing techniques, accurately transforms vehicle coordinates into real-world geographical data. Additionally, our framework includes robust vehicle dimension estimation and detailed road segmentation for in-depth traffic analysis. The framework produced two high-quality datasets: the Songdo Traffic dataset, comprising nearly 1 million unique vehicle trajectories, and the Songdo Vision dataset, containing over 5,000 human-annotated frames with about 300,000 vehicle instances in four classes. Comparisons between drone-derived data and high-precision sensor data from an instrumented probe vehicle highlight the accuracy and consistency of our framework's extraction in dense urban settings. By publicly releasing these datasets and the pipeline source code, this work sets new benchmarks for data quality, reproducibility, and scalability in traffic research. Results demonstrate the potential of integrating drone technology with advanced computer vision for precise, cost-effective urban traffic monitoring, providing valuable resources for the research community to develop intelligent transportation systems and improve traffic management strategies.</li>
</ul>

<h3>Title: Training Compute-Optimal Protein Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xingyi Cheng, Bo Chen, Pan Li, Jing Gong, Jie Tang, Le Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02142">https://arxiv.org/abs/2411.02142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02142">https://arxiv.org/pdf/2411.02142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02142]] Training Compute-Optimal Protein Language Models(https://arxiv.org/abs/2411.02142)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We explore optimally training protein language models, an area of significant interest in biological research where guidance on best practices is limited. Most models are trained with extensive compute resources until performance gains plateau, focusing primarily on increasing model sizes rather than optimizing the efficient compute frontier that balances performance and compute budgets. Our investigation is grounded in a massive dataset consisting of 939 million protein sequences. We trained over 300 models ranging from 3.5 million to 10.7 billion parameters on 5 to 200 billion unique tokens, to investigate the relations between model sizes, training token numbers, and objectives. First, we observed the effect of diminishing returns for the Causal Language Model (CLM) and that of overfitting for the Masked Language Model~(MLM) when repeating the commonly used Uniref database. To address this, we included metagenomic protein sequences in the training set to increase the diversity and avoid the plateau or overfitting effects. Second, we obtained the scaling laws of CLM and MLM on Transformer, tailored to the specific characteristics of protein sequence data. Third, we observe a transfer scaling phenomenon from CLM to MLM, further demonstrating the effectiveness of transfer through scaling behaviors based on estimated Effectively Transferred Tokens. Finally, to validate our scaling laws, we compare the large-scale versions of ESM-2 and PROGEN2 on downstream tasks, encompassing evaluations of protein generation as well as structure- and function-related tasks, all within less or equivalent pre-training compute budgets.</li>
</ul>

<h3>Title: CryptoEL: A Novel Experiential Learning Tool for Enhancing K-12 Cryptography Education</h3>
<ul>
<li><strong>Authors: </strong>Pranathi Rayavaram, Ukaegbu Onyinyechukwu, Maryam Abbasalizadeh, Krishnaa Vellamchetty, Sashank Narain</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02143">https://arxiv.org/abs/2411.02143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02143">https://arxiv.org/pdf/2411.02143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02143]] CryptoEL: A Novel Experiential Learning Tool for Enhancing K-12 Cryptography Education(https://arxiv.org/abs/2411.02143)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>This paper presents an educational tool designed to enhance cryptography education for K-12 students, utilizing Kolb's Experiential Learning (EL) model and engaging visual components. Our tool incorporates the four stages of EL -- Concrete Experience, Reflective Observation, Abstract Conceptualization, and Active Experimentation -- to teach key cryptographic concepts, including hashing, symmetric cryptography, and asymmetric cryptography. The learning experience is enriched with real-world simulations, customized AI-based conversation agents, video demonstrations, interactive scenarios, and a simplified Python coding terminal focused on cryptography. Targeted at beginners in cybersecurity, the tool encourages independent learning with minimal instructor involvement. An evaluation with 51 middle and high school students showed positive feedback from 93% of participants, who found the simulations, visualizations, AI reflections, scenarios, and coding capabilities engaging and conducive to learning. Comprehension surveys indicated a high understanding of cryptography concepts: hashing (middle school: 89%, high school: 92%), symmetric cryptography (middle school: 93%, high school: 97%), and asymmetric cryptography (middle school: 91%, high school: 94%).</li>
</ul>

<h3>Title: FedPID: An Aggregation Method for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Leon Mächler, Gustav Grimberg, Ivan Ezhov, Manuel Nickel, Suprosanna Shit, David Naccache, Johannes C. Paetzold</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02152">https://arxiv.org/abs/2411.02152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02152">https://arxiv.org/pdf/2411.02152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02152]] FedPID: An Aggregation Method for Federated Learning(https://arxiv.org/abs/2411.02152)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents FedPID, our submission to the Federated Tumor Segmentation Challenge 2024 (FETS24). Inspired by FedCostWAvg and FedPIDAvg, our winning contributions to FETS21 and FETS2022, we propose an improved aggregation strategy for federated and collaborative learning. FedCostWAvg is a method that averages results by considering both the number of training samples in each group and how much the cost function decreased in the last round of training. This is similar to how the derivative part of a PID controller works. In FedPIDAvg, we also included the integral part that was missing. Another challenge we faced were vastly differing dataset sizes at each center. We solved this by assuming the sizes follow a Poisson distribution and adjusting the training iterations for each center accordingly. Essentially, this part of the method controls that outliers that require too much training time are less frequently used. Based on these contributions we now adapted FedPIDAvg by changing how the integral part is computed. Instead of integrating the loss function we measure the global drop in cost since the first round.</li>
</ul>

<h3>Title: Do graph neural network states contain graph properties?</h3>
<ul>
<li><strong>Authors: </strong>Tom Pelletreau-Duris, Ruud van Bakel, Michael Cochez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02168">https://arxiv.org/abs/2411.02168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02168">https://arxiv.org/pdf/2411.02168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02168]] Do graph neural network states contain graph properties?(https://arxiv.org/abs/2411.02168)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Graph learning models achieve state-of-the-art performance on many tasks, but this often requires increasingly large model sizes. Accordingly, the complexity of their representations increase. Explainability techniques (XAI) have made remarkable progress in the interpretability of ML models. However, the non-relational nature of Graph Neural Networks (GNNs) make it difficult to reuse already existing XAI methods. While other works have focused on instance-based explanation methods for GNNs, very few have investigated model-based methods and, to our knowledge, none have tried to probe the embedding of the GNNs for well-known structural graph properties. In this paper we present a model agnostic explainability pipeline for Graph Neural Networks (GNNs) employing diagnostic classifiers. This pipeline aims to probe and interpret the learned representations in GNNs across various architectures and datasets, refining our understanding and trust in these models.</li>
</ul>

<h3>Title: Behavioral Sequence Modeling with Ensemble Learning</h3>
<ul>
<li><strong>Authors: </strong>Maxime Kawawa-Beaudan, Srijan Sood, Soham Palande, Ganapathy Mani, Tucker Balch, Manuela Veloso</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02174">https://arxiv.org/abs/2411.02174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02174">https://arxiv.org/pdf/2411.02174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02174]] Behavioral Sequence Modeling with Ensemble Learning(https://arxiv.org/abs/2411.02174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We investigate the use of sequence analysis for behavior modeling, emphasizing that sequential context often outweighs the value of aggregate features in understanding human behavior. We discuss framing common problems in fields like healthcare, finance, and e-commerce as sequence modeling tasks, and address challenges related to constructing coherent sequences from fragmented data and disentangling complex behavior patterns. We present a framework for sequence modeling using Ensembles of Hidden Markov Models, which are lightweight, interpretable, and efficient. Our ensemble-based scoring method enables robust comparison across sequences of different lengths and enhances performance in scenarios with imbalanced or scarce data. The framework scales in real-world scenarios, is compatible with downstream feature-based modeling, and is applicable in both supervised and unsupervised learning settings. We demonstrate the effectiveness of our method with results on a longitudinal human behavior dataset.</li>
</ul>

<h3>Title: CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality</h3>
<ul>
<li><strong>Authors: </strong>Yiqin Zhao, Mallesham Dasari, Tian Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02179">https://arxiv.org/abs/2411.02179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02179">https://arxiv.org/pdf/2411.02179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02179]] CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality(https://arxiv.org/abs/2411.02179)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>High-quality environment lighting is the foundation of creating immersive user experiences in mobile augmented reality (AR) applications. However, achieving visually coherent environment lighting estimation for Mobile AR is challenging due to several key limitations associated with AR device sensing capabilities, including limitations in device camera FoV and pixel dynamic ranges. Recent advancements in generative AI, which can generate high-quality images from different types of prompts, including texts and images, present a potential solution for high-quality lighting estimation. Still, to effectively use generative image diffusion models, we must address their key limitations of generation hallucination and slow inference process. To do so, in this work, we design and implement a generative lighting estimation system called CleAR that can produce high-quality and diverse environment maps in the format of 360$^\circ$ images. Specifically, we design a two-step generation pipeline guided by AR environment context data to ensure the results follow physical environment visual context and color appearances. To improve the estimation robustness under different lighting conditions, we design a real-time refinement component to adjust lighting estimation results on AR devices. To train and test our generative models, we curate a large-scale environment lighting estimation dataset with diverse lighting conditions. Through quantitative evaluation and user study, we show that CleAR outperforms state-of-the-art lighting estimation methods on both estimation accuracy and robustness. Moreover, CleAR supports real-time refinement of lighting estimation results, ensuring robust and timely environment lighting updates for AR applications. Our end-to-end generative estimation takes as fast as 3.2 seconds, outperforming state-of-the-art methods by 110x.</li>
</ul>

<h3>Title: Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition via Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Anjith George, Sebastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02188">https://arxiv.org/abs/2411.02188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02188">https://arxiv.org/pdf/2411.02188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02188]] Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition via Foundation Models(https://arxiv.org/abs/2411.02188)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>The accuracy of face recognition systems has improved significantly in the past few years, thanks to the large amount of data collected and the advancement in neural network architectures. However, these large-scale datasets are often collected without explicit consent, raising ethical and privacy concerns. To address this, there have been proposals to use synthetic datasets for training face recognition models. Yet, such models still rely on real data to train the generative models and generally exhibit inferior performance compared to those trained on real datasets. One of these datasets, DigiFace, uses a graphics pipeline to generate different identities and different intra-class variations without using real data in training the models. However, the performance of this approach is poor on face recognition benchmarks, possibly due to the lack of realism in the images generated from the graphics pipeline. In this work, we introduce a novel framework for realism transfer aimed at enhancing the realism of synthetically generated face images. Our method leverages the large-scale face foundation model, and we adapt the pipeline for realism enhancement. By integrating the controllable aspects of the graphics pipeline with our realism enhancement technique, we generate a large amount of realistic variations-combining the advantages of both approaches. Our empirical evaluations demonstrate that models trained using our enhanced dataset significantly improve the performance of face recognition systems over the baseline. The source code and datasets will be made available publicly.</li>
</ul>

<h3>Title: Improving Steering Vectors by Targeting Sparse Autoencoder Features</h3>
<ul>
<li><strong>Authors: </strong>Sviatoslav Chalnev, Matthew Siu, Arthur Conmy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02193">https://arxiv.org/abs/2411.02193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02193">https://arxiv.org/pdf/2411.02193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02193]] Improving Steering Vectors by Targeting Sparse Autoencoder Features(https://arxiv.org/abs/2411.02193)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>To control the behavior of language models, steering methods attempt to ensure that outputs of the model satisfy specific pre-defined properties. Adding steering vectors to the model is a promising method of model control that is easier than finetuning, and may be more robust than prompting. However, it can be difficult to anticipate the effects of steering vectors produced by almost all existing methods, such as CAA (Panickssery et al., 2024) or the direct use of SAE latents (Templeton et al., 2024). In our work, we address this issue by using SAEs to measure the effects of steering vectors, giving us a method that can be used to understand the causal effect of any steering vector intervention. We use this method for measuring causal effects to develop an improved steering method, SAE-Targeted Steering (SAE-TS), which finds steering vectors to target specific SAE features while minimizing unintended side effects. We show that overall, SAE-TS balances steering effects with coherence better than CAA and SAE feature steering, when evaluated on a range of tasks.</li>
</ul>

<h3>Title: Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Taiji Suzuki, Qingfu Zhang, Hau-San Wong</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02199">https://arxiv.org/abs/2411.02199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02199">https://arxiv.org/pdf/2411.02199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02199]] Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning(https://arxiv.org/abs/2411.02199)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformer-based large language models (LLMs) have displayed remarkable creative prowess and emergence capabilities. Existing empirical studies have revealed a strong connection between these LLMs' impressive emergence abilities and their in-context learning (ICL) capacity, allowing them to solve new tasks using only task-specific prompts without further fine-tuning. On the other hand, existing empirical and theoretical studies also show that there is a linear regularity of the multi-concept encoded semantic representation behind transformer-based LLMs. However, existing theoretical work fail to build up an understanding of the connection between this regularity and the innovative power of ICL. Additionally, prior work often focuses on simplified, unrealistic scenarios involving linear transformers or unrealistic loss functions, and they achieve only linear or sub-linear convergence rates. In contrast, this work provides a fine-grained mathematical analysis to show how transformers leverage the multi-concept semantics of words to enable powerful ICL and excellent out-of-distribution ICL abilities, offering insights into how transformers innovate solutions for certain unseen tasks encoded with multiple cross-concept semantics. Inspired by empirical studies on the linear latent geometry of LLMs, the analysis is based on a concept-based low-noise sparse coding prompt model. Leveraging advanced techniques, this work showcases the exponential 0-1 loss convergence over the highly non-convex training dynamics, which pioneeringly incorporates the challenges of softmax self-attention, ReLU-activated MLPs, and cross-entropy loss. Empirical simulations corroborate the theoretical findings.</li>
</ul>

<h3>Title: One VLM to Keep it Learning: Generation and Balancing for Data-free Continual Visual Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Deepayan Das, Davide Talon, Massimiliano Mancini, Yiming Wang, Elisa Ricci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02210">https://arxiv.org/abs/2411.02210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02210">https://arxiv.org/pdf/2411.02210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02210]] One VLM to Keep it Learning: Generation and Balancing for Data-free Continual Visual Question Answering(https://arxiv.org/abs/2411.02210)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, data-free</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have shown significant promise in Visual Question Answering (VQA) tasks by leveraging web-scale multimodal datasets. However, these models often struggle with continual learning due to catastrophic forgetting when adapting to new tasks. As an effective remedy to mitigate catastrophic forgetting, rehearsal strategy uses the data of past tasks upon learning new task. However, such strategy incurs the need of storing past data, which might not be feasible due to hardware constraints or privacy concerns. In this work, we propose the first data-free method that leverages the language generation capability of a VLM, instead of relying on external models, to produce pseudo-rehearsal data for addressing continual VQA. Our proposal, named as GaB, generates pseudo-rehearsal data by posing previous task questions on new task data. Yet, despite being effective, the distribution of generated questions skews towards the most frequently posed questions due to the limited and task-specific training data. To mitigate this issue, we introduce a pseudo-rehearsal balancing module that aligns the generated data towards the ground-truth data distribution using either the question meta-statistics or an unsupervised clustering method. We evaluate our proposed method on two recent benchmarks, \ie VQACL-VQAv2 and CLOVE-function benchmarks. GaB outperforms all the data-free baselines with substantial improvement in maintaining VQA performance across evolving tasks, while being on-par with methods with access to the past data.</li>
</ul>

<h3>Title: SIRA: Scalable Inter-frame Relation and Association for Radar Perception</h3>
<ul>
<li><strong>Authors: </strong>Ryoma Yataka, Pu Perry Wang, Petros Boufounos, Ryuhei Takahashi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02220">https://arxiv.org/abs/2411.02220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02220">https://arxiv.org/pdf/2411.02220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02220]] SIRA: Scalable Inter-frame Relation and Association for Radar Perception(https://arxiv.org/abs/2411.02220)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Conventional radar feature extraction faces limitations due to low spatial resolution, noise, multipath reflection, the presence of ghost targets, and motion blur. Such limitations can be exacerbated by nonlinear object motion, particularly from an ego-centric viewpoint. It becomes evident that to address these challenges, the key lies in exploiting temporal feature relation over an extended horizon and enforcing spatial motion consistency for effective association. To this end, this paper proposes SIRA (Scalable Inter-frame Relation and Association) with two designs. First, inspired by Swin Transformer, we introduce extended temporal relation, generalizing the existing temporal relation layer from two consecutive frames to multiple inter-frames with temporally regrouped window attention for scalability. Second, we propose motion consistency track with the concept of a pseudo-tracklet generated from observational data for better trajectory prediction and subsequent object association. Our approach achieves 58.11 mAP@0.5 for oriented object detection and 47.79 MOTA for multiple object tracking on the Radiate dataset, surpassing previous state-of-the-art by a margin of +4.11 mAP@0.5 and +9.94 MOTA, respectively.</li>
</ul>

<h3>Title: Positive Experience Reflection for Agents in Interactive Text Environments</h3>
<ul>
<li><strong>Authors: </strong>Philip Lippmann, Matthijs T.J. Spaan, Jie Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02223">https://arxiv.org/abs/2411.02223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02223">https://arxiv.org/pdf/2411.02223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02223]] Positive Experience Reflection for Agents in Interactive Text Environments(https://arxiv.org/abs/2411.02223)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Intelligent agents designed for interactive environments face significant challenges in text-based games, a domain that demands complex reasoning and adaptability. While agents based on large language models (LLMs) using self-reflection have shown promise, they struggle when initially successful and exhibit reduced effectiveness when using smaller LLMs. We introduce Sweet&Sour, a novel approach that addresses these limitations in existing reflection methods by incorporating positive experiences and managed memory to enrich the context available to the agent at decision time. Our comprehensive analysis spans both closed- and open-source LLMs and demonstrates the effectiveness of Sweet&Sour in improving agent performance, particularly in scenarios where previous approaches fall short.</li>
</ul>

<h3>Title: FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training</h3>
<ul>
<li><strong>Authors: </strong>Ruihong Yin, Vladimir Yugay, Yue Li, Sezer Karaoglu, Theo Gevers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02229">https://arxiv.org/abs/2411.02229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02229">https://arxiv.org/pdf/2411.02229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02229]] FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training(https://arxiv.org/abs/2411.02229)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The field of novel view synthesis from images has seen rapid advancements with the introduction of Neural Radiance Fields (NeRF) and more recently with 3D Gaussian Splatting. Gaussian Splatting became widely adopted due to its efficiency and ability to render novel views accurately. While Gaussian Splatting performs well when a sufficient amount of training images are available, its unstructured explicit representation tends to overfit in scenarios with sparse input images, resulting in poor rendering performance. To address this, we present a 3D Gaussian-based novel view synthesis method using sparse input images that can accurately render the scene from the viewpoints not covered by the training images. We propose a multi-stage training scheme with matching-based consistency constraints imposed on the novel views without relying on pre-trained depth estimation or diffusion models. This is achieved by using the matches of the available training images to supervise the generation of the novel views sampled between the training frames with color, geometry, and semantic losses. In addition, we introduce a locality preserving regularization for 3D Gaussians which removes rendering artifacts by preserving the local color structure of the scene. Evaluation on synthetic and real-world datasets demonstrates competitive or superior performance of our method in few-shot novel view synthesis compared to existing state-of-the-art methods.</li>
</ul>

<h3>Title: 3D Audio-Visual Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Artem Sokolov, Swapnil Bhosale, Xiatian Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02236">https://arxiv.org/abs/2411.02236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02236">https://arxiv.org/pdf/2411.02236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02236]] 3D Audio-Visual Segmentation(https://arxiv.org/abs/2411.02236)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recognizing the sounding objects in scenes is a longstanding objective in embodied AI, with diverse applications in robotics and AR/VR/MR. To that end, Audio-Visual Segmentation (AVS), taking as condition an audio signal to identify the masks of the target sounding objects in an input image with synchronous camera and microphone sensors, has been recently advanced. However, this paradigm is still insufficient for real-world operation, as the mapping from 2D images to 3D scenes is missing. To address this fundamental limitation, we introduce a novel research problem, 3D Audio-Visual Segmentation, extending the existing AVS to the 3D output space. This problem poses more challenges due to variations in camera extrinsics, audio scattering, occlusions, and diverse acoustics across sounding object categories. To facilitate this research, we create the very first simulation based benchmark, 3DAVS-S34-O7, providing photorealistic 3D scene environments with grounded spatial audio under single-instance and multi-instance settings, across 34 scenes and 7 object categories. This is made possible by re-purposing the Habitat simulator to generate comprehensive annotations of sounding object locations and corresponding 3D masks. Subsequently, we propose a new approach, EchoSegnet, characterized by integrating the ready-to-use knowledge from pretrained 2D audio-visual foundation models synergistically with 3D visual scene representation through spatial audio-aware mask alignment and refinement. Extensive experiments demonstrate that EchoSegnet can effectively segment sounding objects in 3D space on our new benchmark, representing a significant advancement in the field of embodied AI. Project page: this https URL</li>
</ul>

<h3>Title: Counterfactual Explanations via Riemannian Latent Space Traversal</h3>
<ul>
<li><strong>Authors: </strong>Paraskevas Pegios, Aasa Feragen, Andreas Abildtrup Hansen, Georgios Arvanitidis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02259">https://arxiv.org/abs/2411.02259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02259">https://arxiv.org/pdf/2411.02259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02259]] Counterfactual Explanations via Riemannian Latent Space Traversal(https://arxiv.org/abs/2411.02259)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The adoption of increasingly complex deep models has fueled an urgent need for insight into how these models make predictions. Counterfactual explanations form a powerful tool for providing actionable explanations to practitioners. Previously, counterfactual explanation methods have been designed by traversing the latent space of generative models. Yet, these latent spaces are usually greatly simplified, with most of the data distribution complexity contained in the decoder rather than the latent embedding. Thus, traversing the latent space naively without taking the nonlinear decoder into account can lead to unnatural counterfactual trajectories. We introduce counterfactual explanations obtained using a Riemannian metric pulled back via the decoder and the classifier under scrutiny. This metric encodes information about the complex geometric structure of the data and the learned representation, enabling us to obtain robust counterfactual trajectories with high fidelity, as demonstrated by our experiments in real-world tabular datasets.</li>
</ul>

<h3>Title: Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent</h3>
<ul>
<li><strong>Authors: </strong>Xingwu Sun, Yanfeng Chen, Yiqing Huang, Ruobing Xie, Jiaqi Zhu, Kai Zhang, Shuaipeng Li, Zhen Yang, Jonny Han, Xiaobo Shu, Jiahao Bu, Zhongzhi Chen, Xuemeng Huang, Fengzong Lian, Saiyong Yang, Jianfeng Yan, Yuyuan Zeng, Xiaoqin Ren, Chao Yu, Lulu Wu, Yue Mao, Tao Yang, Suncong Zheng, Kan Wu, Dian Jiao, Jinbao Xue, Xipeng Zhang, Decheng Wu, Kai Liu, Dengpeng Wu, Guanghui Xu, Shaohua Chen, Shuang Chen, Xiao Feng, Yigeng Hong, Junqiang Zheng, Chengcheng Xu, Zongwei Li, Xiong Kuang, Jianglu Hu, Yiqi Chen, Yuchi Deng, Guiyang Li, Ao Liu, Chenchen Zhang, Shihui Hu, Zilong Zhao, Zifan Wu, Yao Ding, Weichao Wang, Han Liu, Roberts Wang, Hao Fei, Peijie She, Ze Zhao, Xun Cao, Hai Wang, Fusheng Xiang, Mengyuan Huang, Zhiyuan Xiong, Bin Hu, Xuebin Hou, Lei Jiang, Jiajia Wu, Yaping Deng, Yi Shen, Qian Wang, Weijie Liu, Jie Liu, Meng Chen, Liang Dong, Weiwen Jia, Hu Chen, Feifei Liu, Rui Yuan, Huilin Xu, Zhenxiang Yan, Tengfei Cao, Zhichao Hu, Xinhua Feng, Dong Du, Tinghao She, Yangyu Tao, Feng Zhang, Jianchen Zhu, Chengzhong Xu, Xirui Li, Chong Zha, Wen Ouyang, Yinben Xia, Xiang Li, Zekun He, Rongpeng Chen, Jiawei Song, Ruibin Chen, Fan Jiang, Chongqing Zhao, Bo Wang, Hao Gong, Rong Gan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02265">https://arxiv.org/abs/2411.02265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02265">https://arxiv.org/pdf/2411.02265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02265]] Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent(https://arxiv.org/abs/2411.02265)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce Hunyuan-Large, which is currently the largest open-source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior performance across various benchmarks including language understanding and generation, logical reasoning, mathematical problem-solving, coding, long-context, and aggregated tasks, where it outperforms LLama3.1-70B and exhibits comparable performance when compared to the significantly larger LLama3.1-405B model. Key practice of Hunyuan-Large include large-scale synthetic data that is orders larger than in previous literature, a mixed expert routing strategy, a key-value cache compression technique, and an expert-specific learning rate strategy. Additionally, we also investigate the scaling laws and learning rate schedule of mixture of experts models, providing valuable insights and guidances for future model development and optimization. The code and checkpoints of Hunyuan-Large are released to facilitate future innovations and applications. Codes: this https URL Models: this https URL</li>
</ul>

<h3>Title: The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units</h3>
<ul>
<li><strong>Authors: </strong>Badr AlKhamissi, Greta Tuckute, Antoine Bosselut, Martin Schrimpf</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02280">https://arxiv.org/abs/2411.02280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02280">https://arxiv.org/pdf/2411.02280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02280]] The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units(https://arxiv.org/abs/2411.02280)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit remarkable capabilities on not just language tasks, but also various tasks that are not linguistic in nature, such as logical reasoning and social inference. In the human brain, neuroscience has identified a core language system that selectively and causally supports language processing. We here ask whether similar specialization for language emerges in LLMs. We identify language-selective units within 18 popular LLMs, using the same localization approach that is used in neuroscience. We then establish the causal role of these units by demonstrating that ablating LLM language-selective units -- but not random units -- leads to drastic deficits in language tasks. Correspondingly, language-selective LLM units are more aligned to brain recordings from the human language system than random units. Finally, we investigate whether our localization method extends to other cognitive domains: while we find specialized networks in some LLMs for reasoning and social capabilities, there are substantial differences among models. These findings provide functional and causal evidence for specialization in large language models, and highlight parallels with the functional organization in the brain.</li>
</ul>

<h3>Title: Conformal-in-the-Loop for Learning with Imbalanced Noisy Data</h3>
<ul>
<li><strong>Authors: </strong>John Brandon Graham-Knight, Jamil Fayyad, Nourhan Bayasi, Patricia Lasserre, Homayoun Najjaran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02281">https://arxiv.org/abs/2411.02281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02281">https://arxiv.org/pdf/2411.02281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02281]] Conformal-in-the-Loop for Learning with Imbalanced Noisy Data(https://arxiv.org/abs/2411.02281)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Class imbalance and label noise are pervasive in large-scale datasets, yet much of machine learning research assumes well-labeled, balanced data, which rarely reflects real world conditions. Existing approaches typically address either label noise or class imbalance in isolation, leading to suboptimal results when both issues coexist. In this work, we propose Conformal-in-the-Loop (CitL), a novel training framework that addresses both challenges with a conformal prediction-based approach. CitL evaluates sample uncertainty to adjust weights and prune unreliable examples, enhancing model resilience and accuracy with minimal computational cost. Our extensive experiments include a detailed analysis showing how CitL effectively emphasizes impactful data in noisy, imbalanced datasets. Our results show that CitL consistently boosts model performance, achieving up to a 6.1% increase in classification accuracy and a 5.0 mIoU improvement in segmentation. Our code is publicly available: CitL.</li>
</ul>

<h3>Title: Federated GNNs for EEG-Based Stroke Assessment</h3>
<ul>
<li><strong>Authors: </strong>Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02286">https://arxiv.org/abs/2411.02286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02286">https://arxiv.org/pdf/2411.02286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02286]] Federated GNNs for EEG-Based Stroke Assessment(https://arxiv.org/abs/2411.02286)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) has the potential to become an essential tool in supporting clinical decision-making processes, offering enhanced diagnostic capabilities and personalized treatment plans. However, outsourcing medical records to train ML models using patient data raises legal, privacy, and security concerns. Federated learning has emerged as a promising paradigm for collaborative ML, meeting healthcare institutions' requirements for robust models without sharing sensitive data and compromising patient privacy. This study proposes a novel method that combines federated learning (FL) and Graph Neural Networks (GNNs) to predict stroke severity using electroencephalography (EEG) signals across multiple medical institutions. Our approach enables multiple hospitals to jointly train a shared GNN model on their local EEG data without exchanging patient information. Specifically, we address a regression problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a key indicator of stroke severity. The proposed model leverages a masked self-attention mechanism to capture salient brain connectivity patterns and employs EdgeSHAP to provide post-hoc explanations of the neurological states after a stroke. We evaluated our method on EEG recordings from four institutions, achieving a mean absolute error (MAE) of 3.23 in predicting NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0). This demonstrates the method's effectiveness in providing accurate and explainable predictions while maintaining data privacy.</li>
</ul>

<h3>Title: Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Xianghui Yang, Huiwen Shi, Bowen Zhang, Fan Yang, Jiacheng Wang, Hongxu Zhao, Xinhai Liu, Xinzhou Wang, Qingxiang Lin, Jiaao Yu, Lifu Wang, Zhuo Chen, Sicong Liu, Yuhong Liu, Yong Yang, Di Wang, Jie Jiang, Chunchao Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02293">https://arxiv.org/abs/2411.02293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02293">https://arxiv.org/pdf/2411.02293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02293]] Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation(https://arxiv.org/abs/2411.02293)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>While 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization. To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text- and image-conditioned generation. In the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds. These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction. In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds. The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure. % Extensive experimental results demonstrate the effectiveness of Hunyuan3D-1.0 in generating high-quality 3D assets. Our framework involves the text-to-image model ~\ie, Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation. Our standard version has $10\times$ more parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets.</li>
</ul>

<h3>Title: Sample-Efficient Private Learning of Mixtures of Gaussians</h3>
<ul>
<li><strong>Authors: </strong>Hassan Ashtiani, Mahbod Majid, Shyam Narayanan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02298">https://arxiv.org/abs/2411.02298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02298">https://arxiv.org/pdf/2411.02298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02298]] Sample-Efficient Private Learning of Mixtures of Gaussians(https://arxiv.org/abs/2411.02298)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We study the problem of learning mixtures of Gaussians with approximate differential privacy. We prove that roughly $kd^2 + k^{1.5} d^{1.75} + k^2 d$ samples suffice to learn a mixture of $k$ arbitrary $d$-dimensional Gaussians up to low total variation distance, with differential privacy. Our work improves over the previous best result [AAL24b] (which required roughly $k^2 d^4$ samples) and is provably optimal when $d$ is much larger than $k^2$. Moreover, we give the first optimal bound for privately learning mixtures of $k$ univariate (i.e., $1$-dimensional) Gaussians. Importantly, we show that the sample complexity for privately learning mixtures of univariate Gaussians is linear in the number of components $k$, whereas the previous best sample complexity [AAL21] was quadratic in $k$. Our algorithms utilize various techniques, including the inverse sensitivity mechanism [AD20b, AD20a, HKMN23], sample compression for distributions [ABDH+20], and methods for bounding volumes of sumsets.</li>
</ul>

<h3>Title: Grouped Discrete Representation for Object-Centric Learning</h3>
<ul>
<li><strong>Authors: </strong>Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02299">https://arxiv.org/abs/2411.02299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02299">https://arxiv.org/pdf/2411.02299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02299]] Grouped Discrete Representation for Object-Centric Learning(https://arxiv.org/abs/2411.02299)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Object-Centric Learning (OCL) can discover objects in images or videos by simply reconstructing the input. For better object discovery, representative OCL methods reconstruct the input as its Variational Autoencoder (VAE) intermediate representation, which suppresses pixel noises and promotes object separability by discretizing continuous super-pixels with template features. However, treating features as units overlooks their composing attributes, thus impeding model generalization; indexing features with scalar numbers loses attribute-level similarities and differences, thus hindering model convergence. We propose \textit{Grouped Discrete Representation} (GDR) for OCL. We decompose features into combinatorial attributes via organized channel grouping, and compose these attributes into discrete representation via tuple indexes. Experiments show that our GDR improves both Transformer- and Diffusion-based OCL methods consistently on various datasets. Visualizations show that our GDR captures better object separability.</li>
</ul>

<h3>Title: MdEval: Massively Multilingual Code Debugging</h3>
<ul>
<li><strong>Authors: </strong>Shukai Liu, Linzheng Chai, Jian Yang, Jiajun Shi, He Zhu, Liran Wang, Ke Jin, Wei Zhang, Hualei Zhu, Shuyue Guo, Tao Sun, Jiaheng Liu, Yunlong Duan, Yu Hao, Liqun Yang, Guanglin Niu, Ge Zhang, Zhoujun Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02310">https://arxiv.org/abs/2411.02310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02310">https://arxiv.org/pdf/2411.02310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02310]] MdEval: Massively Multilingual Code Debugging(https://arxiv.org/abs/2411.02310)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Code large language models (LLMs) have made significant progress in code debugging by directly generating the correct code based on the buggy code snippet. Programming benchmarks, typically consisting of buggy code snippet and their associated test cases, are used to assess the debugging capabilities of LLMs. However, many existing benchmarks primarily focus on Python and are often limited in terms of language diversity (e.g., DebugBench and DebugEval). To advance the field of multilingual debugging with LLMs, we propose the first massively multilingual debugging benchmark, which includes 3.6K test samples of 18 programming languages and covers the automated program repair (APR) task, the code review (CR) task, and the bug identification (BI) task. Further, we introduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs into the correct multilingual queries and solutions (xDebugGen). Further, a multilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong baseline specifically to handle the bugs of a wide range of programming languages (e.g. "Missing Mut" in language Rust and "Misused Macro Definition" in language C). Our extensive experiments on MDEVAL reveal a notable performance gap between open-source models and closed-source LLMs (e.g., GPT and Claude series), highlighting huge room for improvement in multilingual code debugging scenarios.</li>
</ul>

<h3>Title: Evaluating Creative Short Story Generation in Humans and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mete Ismayilzada, Claire Stevenson, Lonneke van der Plas</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02316">https://arxiv.org/abs/2411.02316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02316">https://arxiv.org/pdf/2411.02316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02316]] Evaluating Creative Short Story Generation in Humans and Large Language Models(https://arxiv.org/abs/2411.02316)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Storytelling is a fundamental aspect of human communication, relying heavily on creativity to produce narratives that are novel, appropriate, and surprising. While large language models (LLMs) have recently demonstrated the ability to generate high-quality stories, their creative capabilities remain underexplored. Previous research has either focused on creativity tests requiring short responses or primarily compared model performance in story generation to that of professional writers. However, the question of whether LLMs exhibit creativity in writing short stories on par with the average human remains unanswered. In this work, we conduct a systematic analysis of creativity in short story generation across LLMs and everyday people. Using a five-sentence creative story task, commonly employed in psychology to assess human creativity, we automatically evaluate model- and human-generated stories across several dimensions of creativity, including novelty, surprise, and diversity. Our findings reveal that while LLMs can generate stylistically complex stories, they tend to fall short in terms of creativity when compared to average human writers.</li>
</ul>

<h3>Title: Defining and Evaluating Physical Safety for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yung-Chen Tang, Pin-Yu Chen, Tsung-Yi Ho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02317">https://arxiv.org/abs/2411.02317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02317">https://arxiv.org/pdf/2411.02317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02317]] Defining and Evaluating Physical Safety for Large Language Models(https://arxiv.org/abs/2411.02317)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used to control robotic systems such as drones, but their risks of causing physical threats and harm in real-world applications remain unexplored. Our study addresses the critical gap in evaluating LLM physical safety by developing a comprehensive benchmark for drone control. We classify the physical safety risks of drones into four categories: (1) human-targeted threats, (2) object-targeted threats, (3) infrastructure attacks, and (4) regulatory violations. Our evaluation of mainstream LLMs reveals an undesirable trade-off between utility and safety, with models that excel in code generation often performing poorly in crucial safety aspects. Furthermore, while incorporating advanced prompt engineering techniques such as In-Context Learning and Chain-of-Thought can improve safety, these methods still struggle to identify unintentional attacks. In addition, larger models demonstrate better safety capabilities, particularly in refusing dangerous commands. Our findings and benchmark can facilitate the design and evaluation of physical safety for LLMs. The project page is available at this http URL.</li>
</ul>

<h3>Title: LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Mufei Li, Viraj Shitole, Eli Chien, Changhai Man, Zhaodong Wang, Srinivas Sridharan, Ying Zhang, Tushar Krishna, Pan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02322">https://arxiv.org/abs/2411.02322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02322">https://arxiv.org/pdf/2411.02322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02322]] LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation(https://arxiv.org/abs/2411.02322)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Directed acyclic graphs (DAGs) serve as crucial data representations in domains such as hardware synthesis and compiler/program optimization for computing systems. DAG generative models facilitate the creation of synthetic DAGs, which can be used for benchmarking computing systems while preserving intellectual property. However, generating realistic DAGs is challenging due to their inherent directional and logical dependencies. This paper introduces LayerDAG, an autoregressive diffusion model, to address these challenges. LayerDAG decouples the strong node dependencies into manageable units that can be processed sequentially. By interpreting the partial order of nodes as a sequence of bipartite graphs, LayerDAG leverages autoregressive generation to model directional dependencies and employs diffusion models to capture logical dependencies within each bipartite graph. Comparative analyses demonstrate that LayerDAG outperforms existing DAG generative models in both expressiveness and generalization, particularly for generating large-scale DAGs with up to 400 nodes-a critical scenario for system benchmarking. Extensive experiments on both synthetic and real-world flow graphs from various computing platforms show that LayerDAG generates valid DAGs with superior statistical properties and benchmarking performance. The synthetic DAGs generated by LayerDAG enhance the training of ML-based surrogate models, resulting in improved accuracy in predicting performance metrics of real-world DAGs across diverse computing platforms.</li>
</ul>

<h3>Title: Digital Twin-Assisted Federated Learning with Blockchain in Multi-tier Computing Systems</h3>
<ul>
<li><strong>Authors: </strong>Yongyi Tang, Kunlun Wang, Dusit Niyato, Wen Chen, George K. Karagiannidis</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02323">https://arxiv.org/abs/2411.02323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02323">https://arxiv.org/pdf/2411.02323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02323]] Digital Twin-Assisted Federated Learning with Blockchain in Multi-tier Computing Systems(https://arxiv.org/abs/2411.02323)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>In Industry 4.0 systems, a considerable number of resource-constrained Industrial Internet of Things (IIoT) devices engage in frequent data interactions due to the necessity for model training, which gives rise to concerns pertaining to security and privacy. In order to address these challenges, this paper considers a digital twin (DT) and blockchain-assisted federated learning (FL) scheme. To facilitate the FL process, we initially employ fog devices with abundant computational capabilities to generate DT for resource-constrained edge devices, thereby aiding them in local training. Subsequently, we formulate an FL delay minimization problem for FL, which considers both of model transmission time and synchronization time, also incorporates cooperative jamming to ensure secure synchronization of DT. To address this non-convex optimization problem, we propose a decomposition algorithm. In particular, we introduce upper limits on the local device training delay and the effects of aggregation jamming as auxiliary variables, thereby transforming the problem into a convex optimization problem that can be decomposed for independent solution. Finally, a blockchain verification mechanism is employed to guarantee the integrity of the model uploading throughout the FL process and the identities of the participants. The final global model is obtained from the verified local and global models within the blockchain through the application of deep learning techniques. The efficacy of our proposed cooperative interference-based FL process has been verified through numerical analysis, which demonstrates that the integrated DT blockchain-assisted FL scheme significantly outperforms the benchmark schemes in terms of execution time, block optimization, and accuracy.</li>
</ul>

<h3>Title: PPLLaVA: Varied Video Sequence Understanding With Prompt Guidance</h3>
<ul>
<li><strong>Authors: </strong>Ruyang Liu, Haoran Tang, Haibo Liu, Yixiao Ge, Ying Shan, Chen Li, Jiankun Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02327">https://arxiv.org/abs/2411.02327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02327">https://arxiv.org/pdf/2411.02327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02327]] PPLLaVA: Varied Video Sequence Understanding With Prompt Guidance(https://arxiv.org/abs/2411.02327)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The past year has witnessed the significant advancement of video-based large language models. However, the challenge of developing a unified model for both short and long video understanding remains unresolved. Most existing video LLMs cannot handle hour-long videos, while methods custom for long videos tend to be ineffective for shorter videos and images. In this paper, we identify the key issue as the redundant content in videos. To address this, we propose a novel pooling strategy that simultaneously achieves token compression and instruction-aware visual feature aggregation. Our model is termed Prompt-guided Pooling LLaVA, or PPLLaVA for short. Specifically, PPLLaVA consists of three core components: the CLIP-based visual-prompt alignment that extracts visual information relevant to the user's instructions, the prompt-guided pooling that compresses the visual sequence to arbitrary scales using convolution-style pooling, and the clip context extension designed for lengthy prompt common in visual dialogue. Moreover, our codebase also integrates the most advanced video Direct Preference Optimization (DPO) and visual interleave training. Extensive experiments have validated the performance of our model. With superior throughput and only 1024 visual context, PPLLaVA achieves better results on image benchmarks as a video LLM, while achieving state-of-the-art performance across various video benchmarks, excelling in tasks ranging from caption generation to multiple-choice questions, and handling video lengths from seconds to hours. Codes have been available at this https URL.</li>
</ul>

<h3>Title: Sparsing Law: Towards Large Language Models with Greater Activation Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Yuqi Luo, Chenyang Song, Xu Han, Yingfa Chen, Chaojun Xiao, Zhiyuan Liu, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02335">https://arxiv.org/abs/2411.02335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02335">https://arxiv.org/pdf/2411.02335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02335]] Sparsing Law: Towards Large Language Models with Greater Activation Sparsity(https://arxiv.org/abs/2411.02335)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Activation sparsity denotes the existence of substantial weakly-contributed elements within activation outputs that can be eliminated, benefiting many important applications concerned with large language models (LLMs). Although promoting greater activation sparsity within LLMs deserves deep studies, existing works lack comprehensive and quantitative research on the correlation between activation sparsity and potentially influential factors. In this paper, we present a comprehensive study on the quantitative scaling properties and influential factors of the activation sparsity within decoder-only Transformer-based LLMs. Specifically, we propose PPL-$p\%$ sparsity, a precise and performance-aware activation sparsity metric that is applicable to any activation function. Through extensive experiments, we find several important phenomena. Firstly, different activation functions exhibit comparable performance but opposite training-time sparsity trends. The activation ratio (i.e., $1-\mathrm{sparsity\ ratio}$) evolves as a convergent increasing power-law and decreasing logspace power-law with the amount of training data for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate that ReLU is more efficient as the activation function than SiLU and can leverage more training data to improve activation sparsity. Secondly, the activation ratio linearly increases with the width-depth ratio below a certain bottleneck point, indicating the potential advantage of a deeper architecture at a fixed parameter scale. Finally, at similar width-depth ratios, we surprisingly find that the limit value of activation sparsity varies weakly with the parameter scale, i.e., the activation patterns within LLMs are insensitive to the parameter scale. These empirical laws towards LLMs with greater activation sparsity have important implications for making LLMs more efficient and interpretable.</li>
</ul>

<h3>Title: MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D</h3>
<ul>
<li><strong>Authors: </strong>Wei Cheng, Juncheng Mu, Xianfang Zeng, Xin Chen, Anqi Pang, Chi Zhang, Zhibin Wang, Bin Fu, Gang Yu, Ziwei Liu, Liang Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02336">https://arxiv.org/abs/2411.02336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02336">https://arxiv.org/pdf/2411.02336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02336]] MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D(https://arxiv.org/abs/2411.02336)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Texturing is a crucial step in the 3D asset production workflow, which enhances the visual appeal and diversity of 3D assets. Despite recent advancements in Text-to-Texture (T2T) generation, existing methods often yield subpar results, primarily due to local discontinuities, inconsistencies across multiple views, and their heavy dependence on UV unwrapping outcomes. To tackle these challenges, we propose a novel generation-refinement 3D texturing framework called MVPaint, which can generate high-resolution, seamless textures while emphasizing multi-view consistency. MVPaint mainly consists of three key modules. 1) Synchronized Multi-view Generation (SMG). Given a 3D mesh model, MVPaint first simultaneously generates multi-view images by employing an SMG model, which leads to coarse texturing results with unpainted parts due to missing observations. 2) Spatial-aware 3D Inpainting (S3I). To ensure complete 3D texturing, we introduce the S3I method, specifically designed to effectively texture previously unobserved areas. 3) UV Refinement (UVR). Furthermore, MVPaint employs a UVR module to improve the texture quality in the UV space, which first performs a UV-space Super-Resolution, followed by a Spatial-aware Seam-Smoothing algorithm for revising spatial texturing discontinuities caused by UV unwrapping. Moreover, we establish two T2T evaluation benchmarks: the Objaverse T2T benchmark and the GSO T2T benchmark, based on selected high-quality 3D meshes from the Objaverse dataset and the entire GSO dataset, respectively. Extensive experimental results demonstrate that MVPaint surpasses existing state-of-the-art methods. Notably, MVPaint could generate high-fidelity textures with minimal Janus issues and highly enhanced cross-view consistency.</li>
</ul>

<h3>Title: WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zehan Qi, Xiao Liu, Iat Long Iong, Hanyu Lai, Xueqiao Sun, Xinyue Yang, Jiadai Sun, Yu Yang, Shuntian Yao, Tianjie Zhang, Wei Xu, Jie Tang, Yuxiao Dong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02337">https://arxiv.org/abs/2411.02337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02337">https://arxiv.org/pdf/2411.02337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02337]] WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning(https://arxiv.org/abs/2411.02337)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks. However, existing LLM web agents heavily rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities. This paper introduces WebRL, a self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs. WebRL addresses three key challenges in building LLM web agents, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning. Specifically, WebRL incorporates 1) a self-evolving curriculum that generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure consistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4 models into proficient web agents. On WebArena-Lite, WebRL improves the success rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B. These open models significantly surpass the performance of GPT-4-Turbo (17.6%) and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems.</li>
</ul>

<h3>Title: Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Md Rifat Arefin, Gopeshh Subbaraj, Nicolas Gontier, Yann LeCun, Irina Rish, Ravid Shwartz-Ziv, Christopher Pal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02344">https://arxiv.org/abs/2411.02344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02344">https://arxiv.org/pdf/2411.02344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02344]] Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning(https://arxiv.org/abs/2411.02344)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Decoder-only Transformers often struggle with complex reasoning tasks, particularly arithmetic reasoning requiring multiple sequential operations. In this work, we identify representation collapse in the model's intermediate layers as a key factor limiting their reasoning capabilities. To address this, we propose Sequential Variance-Covariance Regularization (Seq-VCR), which enhances the entropy of intermediate representations and prevents collapse. Combined with dummy pause tokens as substitutes for chain-of-thought (CoT) tokens, our method significantly improves performance in arithmetic reasoning problems. In the challenging $5 \times 5$ integer multiplication task, our approach achieves $99.5\%$ exact match accuracy, outperforming models of the same size (which yield $0\%$ accuracy) and GPT-4 with five-shot CoT prompting ($44\%$). We also demonstrate superior results on arithmetic expression and longest increasing subsequence (LIS) datasets. Our findings highlight the importance of preventing intermediate layer representation collapse to enhance the reasoning capabilities of Transformers and show that Seq-VCR offers an effective solution without requiring explicit CoT supervision.</li>
</ul>

<h3>Title: "Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization</h3>
<ul>
<li><strong>Authors: </strong>Eldar Kurtic, Alexandre Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02355">https://arxiv.org/abs/2411.02355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02355">https://arxiv.org/pdf/2411.02355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02355]] "Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization(https://arxiv.org/abs/2411.02355)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the popularity of large language model (LLM) quantization for inference acceleration, significant uncertainty remains regarding the accuracy-performance trade-offs associated with various quantization formats. We present a comprehensive empirical study of quantized accuracy, evaluating popular quantization formats (FP8, INT8, INT4) across academic benchmarks and real-world tasks, on the entire Llama-3.1 model family. Additionally, our study examines the difference in text generated by quantized models versus their uncompressed counterparts. Beyond benchmarks, we also present a couple of quantization improvements which allowed us to obtain state-of-the-art accuracy recovery results. Our investigation, encompassing over 500,000 individual evaluations, yields several key findings: (1) FP8 weight and activation quantization (W8A8-FP) is lossless across all model scales, (2) INT8 weight and activation quantization (W8A8-INT), when properly tuned, incurs surprisingly low 1-3% accuracy degradation, and (3) INT4 weight-only quantization (W4A16-INT) is competitive with 8-bit integer weight and activation quantization. To address the question of the "best" format for a given deployment environment, we conduct inference performance analysis using the popular open-source vLLM framework on various GPU architectures. We find that W4A16 offers the best cost-efficiency for synchronous deployments, and for asynchronous deployment on mid-tier GPUs. At the same time, W8A8 formats excel in asynchronous "continuous batching" deployment of mid- and large-size models on high-end GPUs. Our results provide a set of practical guidelines for deploying quantized LLMs across scales and performance requirements.</li>
</ul>

<h3>Title: Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Neel Dey, Benjamin Billot, Hallee E. Wong, Clinton J. Wang, Mengwei Ren, P. Ellen Grant, Adrian V. Dalca, Polina Golland</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02372">https://arxiv.org/abs/2411.02372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02372">https://arxiv.org/pdf/2411.02372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02372]] Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis(https://arxiv.org/abs/2411.02372)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets. As a result, we set new standards across both multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images.</li>
</ul>

<h3>Title: Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02382">https://arxiv.org/abs/2411.02382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02382">https://arxiv.org/pdf/2411.02382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02382]] Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models(https://arxiv.org/abs/2411.02382)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in various scientific domains, from natural language processing to complex problem-solving tasks. Their ability to understand and generate human-like text has opened up new possibilities for advancing scientific research, enabling tasks such as data analysis, literature review, and even experimental design. One of the most promising applications of LLMs in this context is hypothesis generation, where they can identify novel research directions by analyzing existing knowledge. However, despite their potential, LLMs are prone to generating ``hallucinations'', outputs that are plausible-sounding but factually incorrect. Such a problem presents significant challenges in scientific fields that demand rigorous accuracy and verifiability, potentially leading to erroneous or misleading conclusions. To overcome these challenges, we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that enhances LLM hypothesis generation by integrating external, structured knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured reasoning process, organizing their output as a chain of ideas (CoI), and includes a KG-supported module for the detection of hallucinations. With experiments on our newly constructed hypothesis generation dataset, we demonstrate that KG-CoI not only improves the accuracy of LLM-generated hypotheses but also reduces the hallucination in their reasoning chains, highlighting its effectiveness in advancing real-world scientific research.</li>
</ul>

<h3>Title: How Far is Video Generation from World Model: A Physical Law Perspective</h3>
<ul>
<li><strong>Authors: </strong>Bingyi Kang, Yang Yue, Rui Lu, Zhijie Lin, Yang Zhao, Kaixin Wang, Gao Huang, Jiashi Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02385">https://arxiv.org/abs/2411.02385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02385">https://arxiv.org/pdf/2411.02385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02385]] How Far is Video Generation from World Model: A Physical Law Perspective(https://arxiv.org/abs/2411.02385)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>OpenAI's Sora highlights the potential of video generation for developing world models that adhere to fundamental physical laws. However, the ability of video generation models to discover such laws purely from visual data without human priors can be questioned. A world model learning the true law should give predictions robust to nuances and correctly extrapolate on unseen scenarios. In this work, we evaluate across three key scenarios: in-distribution, out-of-distribution, and combinatorial generalization. We developed a 2D simulation testbed for object movement and collisions to generate videos deterministically governed by one or more classical mechanics laws. This provides an unlimited supply of data for large-scale experimentation and enables quantitative evaluation of whether the generated videos adhere to physical laws. We trained diffusion-based video generation models to predict object movements based on initial frames. Our scaling experiments show perfect generalization within the distribution, measurable scaling behavior for combinatorial generalization, but failure in out-of-distribution scenarios. Further experiments reveal two key insights about the generalization mechanisms of these models: (1) the models fail to abstract general physical rules and instead exhibit "case-based" generalization behavior, i.e., mimicking the closest training example; (2) when generalizing to new cases, models are observed to prioritize different factors when referencing training data: color > size > velocity > shape. Our study suggests that scaling alone is insufficient for video generation models to uncover fundamental physical laws, despite its role in Sora's broader success. See our project page at this https URL</li>
</ul>

<h3>Title: Attacking Vision-Language Computer Agents via Pop-ups</h3>
<ul>
<li><strong>Authors: </strong>Yanzhe Zhang, Tao Yu, Diyi Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02391">https://arxiv.org/abs/2411.02391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02391">https://arxiv.org/pdf/2411.02391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02391]] Attacking Vision-Language Computer Agents via Pop-ups(https://arxiv.org/abs/2411.02391)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Autonomous agents powered by large vision and language models (VLM) have demonstrated significant potential in completing daily computer tasks, such as browsing the web to book travel and operating desktop software, which requires agents to understand these interfaces. Despite such visual inputs becoming more integrated into agentic applications, what types of risks and attacks exist around them still remain unclear. In this work, we demonstrate that VLM agents can be easily attacked by a set of carefully designed adversarial pop-ups, which human users would typically recognize and ignore. This distraction leads agents to click these pop-ups instead of performing the tasks as usual. Integrating these pop-ups into existing agent testing environments like OSWorld and VisualWebArena leads to an attack success rate (the frequency of the agent clicking the pop-ups) of 86% on average and decreases the task success rate by 47%. Basic defense techniques such as asking the agent to ignore pop-ups or including an advertisement notice, are ineffective against the attack.</li>
</ul>

<h3>Title: Adaptive Length Image Tokenization via Recurrent Allocation</h3>
<ul>
<li><strong>Authors: </strong>Shivam Duggal, Phillip Isola, Antonio Torralba, William T. Freeman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02393">https://arxiv.org/abs/2411.02393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02393">https://arxiv.org/pdf/2411.02393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02393]] Adaptive Length Image Tokenization via Recurrent Allocation(https://arxiv.org/abs/2411.02393)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current vision systems typically assign fixed-length representations to images, regardless of the information content. This contrasts with human intelligence - and even large language models - which allocate varying representational capacities based on entropy, context and familiarity. Inspired by this, we propose an approach to learn variable-length token representations for 2D images. Our encoder-decoder architecture recursively processes 2D image tokens, distilling them into 1D latent tokens over multiple iterations of recurrent rollouts. Each iteration refines the 2D tokens, updates the existing 1D latent tokens, and adaptively increases representational capacity by adding new tokens. This enables compression of images into a variable number of tokens, ranging from 32 to 256. We validate our tokenizer using reconstruction loss and FID metrics, demonstrating that token count aligns with image entropy, familiarity and downstream task requirements. Recurrent token processing with increasing representational capacity in each iteration shows signs of token specialization, revealing potential for object / part discovery.</li>
</ul>

<h3>Title: AutoVFX: Physically Realistic Video Editing from Natural Language Instructions</h3>
<ul>
<li><strong>Authors: </strong>Hao-Yu Hsu, Zhi-Hao Lin, Albert Zhai, Hongchi Xia, Shenlong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02394">https://arxiv.org/abs/2411.02394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02394">https://arxiv.org/pdf/2411.02394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02394]] AutoVFX: Physically Realistic Video Editing from Natural Language Instructions(https://arxiv.org/abs/2411.02394)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern visual effects (VFX) software has made it possible for skilled artists to create imagery of virtually anything. However, the creation process remains laborious, complex, and largely inaccessible to everyday users. In this work, we present AutoVFX, a framework that automatically creates realistic and dynamic VFX videos from a single video and natural language instructions. By carefully integrating neural scene modeling, LLM-based code generation, and physical simulation, AutoVFX is able to provide physically-grounded, photorealistic editing effects that can be controlled directly using natural language instructions. We conduct extensive experiments to validate AutoVFX's efficacy across a diverse spectrum of videos and instructions. Quantitative and qualitative results suggest that AutoVFX outperforms all competing methods by a large margin in generative quality, instruction alignment, editing versatility, and physical plausibility.</li>
</ul>

<h3>Title: Training-free Regional Prompting for Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Anthony Chen, Jianjin Xu, Wenzhao Zheng, Gaole Dai, Yida Wang, Renrui Zhang, Haofan Wang, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02395">https://arxiv.org/abs/2411.02395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02395">https://arxiv.org/pdf/2411.02395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02395]] Training-free Regional Prompting for Diffusion Transformers(https://arxiv.org/abs/2411.02395)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated excellent capabilities in text-to-image generation. Their semantic understanding (i.e., prompt following) ability has also been greatly improved with large language models (e.g., T5, Llama). However, existing models cannot perfectly handle long and complex text prompts, especially when the text prompts contain various objects with numerous attributes and interrelated spatial relationships. While many regional prompting methods have been proposed for UNet-based models (SD1.5, SDXL), but there are still no implementations based on the recent Diffusion Transformer (DiT) architecture, such as SD3 and this http URL this report, we propose and implement regional prompting for FLUX.1 based on attention manipulation, which enables DiT with fined-grained compositional text-to-image generation capability in a training-free manner. Code is available at this https URL.</li>
</ul>

<h3>Title: Adaptive Caching for Faster Video Generation with Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Kumara Kahatapitiya, Haozhe Liu, Sen He, Ding Liu, Menglin Jia, Michael S. Ryoo, Tian Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02397">https://arxiv.org/abs/2411.02397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02397">https://arxiv.org/pdf/2411.02397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02397]] Adaptive Caching for Faster Video Generation with Diffusion Transformers(https://arxiv.org/abs/2411.02397)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Generating temporally-consistent high-fidelity videos can be computationally expensive, especially over longer temporal spans. More-recent Diffusion Transformers (DiTs) -- despite making significant headway in this context -- have only heightened such challenges as they rely on larger models and heavier attention mechanisms, resulting in slower inference speeds. In this paper, we introduce a training-free method to accelerate video DiTs, termed Adaptive Caching (AdaCache), which is motivated by the fact that "not all videos are created equal": meaning, some videos require fewer denoising steps to attain a reasonable quality than others. Building on this, we not only cache computations through the diffusion process, but also devise a caching schedule tailored to each video generation, maximizing the quality-latency trade-off. We further introduce a Motion Regularization (MoReg) scheme to utilize video information within AdaCache, essentially controlling the compute allocation based on motion content. Altogether, our plug-and-play contributions grant significant inference speedups (e.g. up to 4.7x on Open-Sora 720p - 2s video generation) without sacrificing the generation quality, across multiple video DiT baselines.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
