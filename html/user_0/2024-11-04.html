<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-11-04</h1>
<h3>Title: A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges</h3>
<ul>
<li><strong>Authors: </strong>Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajun Wang, Pranav Rajpurkar, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00024">https://arxiv.org/abs/2411.00024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00024">https://arxiv.org/pdf/2411.00024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00024]] A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges(https://arxiv.org/abs/2411.00024)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>The integration of Large Language Models (LLMs) into medical applications has sparked widespread interest across the healthcare industry, from drug discovery and development to clinical decision support, assisting telemedicine, medical devices, and healthcare insurance applications. This perspective paper aims to discuss the inner workings of building LLM-powered medical AI applications and introduces a comprehensive framework for their development. We review existing literature and outline the unique challenges of applying LLMs in specialized medical contexts. Additionally, we introduce a three-step framework to organize medical LLM research activities: 1) Modeling: breaking down complex medical workflows into manageable steps for developing medical-specific models; 2) Optimization: optimizing the model performance with crafted prompts and integrating external knowledge and tools, and 3) System engineering: decomposing complex tasks into subtasks and leveraging human expertise for building medical AI applications. Furthermore, we offer a detailed use case playbook that describes various LLM-powered medical AI applications, such as optimizing clinical trial design, enhancing clinical decision support, and advancing medical imaging analysis. Finally, we discuss various challenges and considerations for building medical AI applications with LLMs, such as handling hallucination issues, data ownership and compliance, privacy, intellectual property considerations, compute cost, sustainability issues, and responsible AI requirements.</li>
</ul>

<h3>Title: Personalization of Large Language Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00027">https://arxiv.org/abs/2411.00027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00027">https://arxiv.org/pdf/2411.00027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00027]] Personalization of Large Language Models: A Survey(https://arxiv.org/abs/2411.00027)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs for personalization-related downstream applications, such as recommendation systems. In this work, we bridge the gap between these two separate main directions for the first time by introducing a taxonomy for personalized LLM usage and summarizing the key differences and challenges. We provide a formalization of the foundations of personalized LLMs that consolidates and expands notions of personalization of LLMs, defining and discussing novel facets of personalization, usage, and desiderata of personalized LLMs. We then unify the literature across these diverse fields and usage scenarios by proposing systematic taxonomies for the granularity of personalization, personalization techniques, datasets, evaluation methods, and applications of personalized LLMs. Finally, we highlight challenges and important open problems that remain to be addressed. By unifying and surveying recent research using the proposed taxonomies, we aim to provide a clear guide to the existing literature and different facets of personalization in LLMs, empowering both researchers and practitioners.</li>
</ul>

<h3>Title: Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN</h3>
<ul>
<li><strong>Authors: </strong>Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00028">https://arxiv.org/abs/2411.00028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00028">https://arxiv.org/pdf/2411.00028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00028]] Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN(https://arxiv.org/abs/2411.00028)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The fast development of location-based social networks (LBSNs) has led to significant changes in society, resulting in popular studies of using LBSN data for socioeconomic prediction, e.g., regional population and commercial activity estimation. Existing studies design various graphs to model heterogeneous LBSN data, and further apply graph representation learning methods for socioeconomic prediction. However, these approaches heavily rely on heuristic ideas and expertise to extract task-relevant knowledge from diverse data, which may not be optimal for specific tasks. Additionally, they tend to overlook the inherent relationships between different indicators, limiting the prediction accuracy. Motivated by the remarkable abilities of large language models (LLMs) in commonsense reasoning, embedding, and multi-agent collaboration, in this work, we synergize LLM agents and knowledge graph for socioeconomic prediction. We first construct a location-based knowledge graph (LBKG) to integrate multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to identify relevant meta-paths in the LBKG for each type of socioeconomic prediction task, and design a semantic-guided attention module for knowledge fusion with meta-paths. Moreover, we introduce a cross-task communication mechanism to further enhance performance by enabling knowledge sharing across tasks at both LLM agent and KG levels. On the one hand, the LLM agents for different tasks collaborate to generate more diverse and comprehensive meta-paths. On the other hand, the embeddings from different tasks are adaptively merged for better socioeconomic prediction. Experiments on two datasets demonstrate the effectiveness of the synergistic design between LLM and KG, providing insights for information sharing across socioeconomic prediction tasks.</li>
</ul>

<h3>Title: Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot</h3>
<ul>
<li><strong>Authors: </strong>Herman Lassche (1 and 2), Michiel Overeem (1), Ayushi Rastogi (2) ((1) AFAS Software, (2) University Groningen)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00034">https://arxiv.org/abs/2411.00034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00034">https://arxiv.org/pdf/2411.00034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00034]] Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot(https://arxiv.org/abs/2411.00034)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Companies support their customers using live chats and chatbots to gain their loyalty. AFAS is a Dutch company aiming to leverage the opportunity large language models (LLMs) offer to answer customer queries with minimal to no input from its customer support team. Adding to its complexity, it is unclear what makes a response correct, and that too in Dutch. Further, with minimal data available for training, the challenge is to identify whether an answer generated by a large language model is correct and do it on the fly. This study is the first to define the correctness of a response based on how the support team at AFAS makes decisions. It leverages literature on natural language generation and automated answer grading systems to automate the decision-making of the customer support team. We investigated questions requiring a binary response (e.g., Would it be possible to adjust tax rates manually?) or instructions (e.g., How would I adjust tax rate manually?) to test how close our automated approach reaches support rating. Our approach can identify wrong messages in 55\% of the cases. This work shows the viability of automatically assessing when our chatbot tell lies.</li>
</ul>

<h3>Title: Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yulong Wang, Chang Zuo, Yin Xuan, Hong Li, Ni Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00039">https://arxiv.org/abs/2411.00039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00039">https://arxiv.org/pdf/2411.00039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00039]] Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models(https://arxiv.org/abs/2411.00039)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) has become essential for adapting pretrained models to specific downstream tasks. In this paper, we propose Linear Chain Transformation (LinChain), a novel approach that introduces a sequence of linear transformations during fine-tuning to enrich optimization dynamics. By incorporating multiple linear transformations into the parameter update process, LinChain expands the effective rank of updates and enhances the model's ability to learn complex task-specific representations. We demonstrate that this method significantly improves the performance of LLM fine-tuning over state-of-the-art methods by providing more flexible optimization paths during training, while maintaining the inference efficiency of the resulting model. Our experiments on various benchmark tasks show that LinChain leads to better generalization, fewer learnable parameters, and improved task adaptation, making it a compelling strategy for LLM fine-tuning.</li>
</ul>

<h3>Title: NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Parvez Zamil, Gollam Rabby, Md. Sadekur Rahman, Sören Auer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00041">https://arxiv.org/abs/2411.00041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00041">https://arxiv.org/pdf/2411.00041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00041]] NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering(https://arxiv.org/abs/2411.00041)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The growing volume of biomedical scholarly document abstracts presents an increasing challenge in efficiently retrieving accurate and relevant information. To address this, we introduce a novel approach that integrates an optimized topic modelling framework, OVB-LDA, with the BI-POP CMA-ES optimization technique for enhanced scholarly document abstract categorization. Complementing this, we employ the distilled MiniLM model, fine-tuned on domain-specific data, for high-precision answer extraction. Our approach is evaluated across three configurations: scholarly document abstract retrieval, gold-standard scholarly documents abstract, and gold-standard snippets, consistently outperforming established methods such as RYGH and bio-answer finder. Notably, we demonstrate that extracting answers from scholarly documents abstracts alone can yield high accuracy, underscoring the sufficiency of abstracts for many biomedical queries. Despite its compact size, MiniLM exhibits competitive performance, challenging the prevailing notion that only large, resource-intensive models can handle such complex tasks. Our results, validated across various question types and evaluation batches, highlight the robustness and adaptability of our method in real-world biomedical applications. While our approach shows promise, we identify challenges in handling complex list-type questions and inconsistencies in evaluation metrics. Future work will focus on refining the topic model with more extensive domain-specific datasets, further optimizing MiniLM and utilizing large language models (LLM) to improve both precision and efficiency in biomedical question answering.</li>
</ul>

<h3>Title: Problem Categorization Can Help Large Language Models Solve Math Problems</h3>
<ul>
<li><strong>Authors: </strong>Amogh Akella</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00042">https://arxiv.org/abs/2411.00042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00042">https://arxiv.org/pdf/2411.00042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00042]] Problem Categorization Can Help Large Language Models Solve Math Problems(https://arxiv.org/abs/2411.00042)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we explore how to optimize the usage of Large-Language Models to quickly and accurately solve mathematical problems. In particular, we show the effectiveness of using the classification of problems into different categories to facilitate problem-solving. Additionally, we optimize the classification of problems into categories by creating an accurate dataset. We believe that our technique for problem-solving works by helping mitigate hallucination in LLMs which is key to unlocking their ability to solve math problems.</li>
</ul>

<h3>Title: MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary embolism phenotype in the MIMIC-IV dataset</h3>
<ul>
<li><strong>Authors: </strong>B. D. Lam, S. Ma, I. Kovalenko, P. Wang, O. Jafari, A. Li, S. Horng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00044">https://arxiv.org/abs/2411.00044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00044">https://arxiv.org/pdf/2411.00044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00044]] MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary embolism phenotype in the MIMIC-IV dataset(https://arxiv.org/abs/2411.00044)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Pulmonary embolism (PE) is a leading cause of preventable in-hospital mortality. Advances in diagnosis, risk stratification, and prevention can improve outcomes. There are few large publicly available datasets that contain PE labels for research. Using the MIMIC-IV database, we extracted all available radiology reports of computed tomography pulmonary angiography (CTPA) scans and two physicians manually labeled the results as PE positive (acute PE) or PE negative. We then applied a previously finetuned Bio_ClinicalBERT transformer language model, VTE-BERT, to extract labels automatically. We verified VTE-BERT's reliability by measuring its performance against manual adjudication. We also compared the performance of VTE-BERT to diagnosis codes. We found that VTE-BERT has a sensitivity of 92.4% and positive predictive value (PPV) of 87.8% on all 19,942 patients with CTPA radiology reports from the emergency room and/or hospital admission. In contrast, diagnosis codes have a sensitivity of 95.4% and PPV of 83.8% on the subset of 11,990 hospitalized patients with discharge diagnosis codes. We successfully add nearly 20,000 labels to CTPAs in a publicly available dataset and demonstrate the external validity of a semi-supervised language model in accelerating hematologic research.</li>
</ul>

<h3>Title: A Novel Psychometrics-Based Approach to Developing Professional Competency Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Elena Kardanova, Alina Ivanova, Ksenia Tarasova, Taras Pashchenko, Aleksei Tikhoniuk, Elen Yusupova, Anatoly Kasprzhak, Yaroslav Kuzminov, Ekaterina Kruchinskaia, Irina Brun (National Research University Higher School of Economics, Moscow, Russia)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00045">https://arxiv.org/abs/2411.00045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00045">https://arxiv.org/pdf/2411.00045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00045]] A Novel Psychometrics-Based Approach to Developing Professional Competency Benchmark for Large Language Models(https://arxiv.org/abs/2411.00045)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>The era of large language models (LLM) raises questions not only about how to train models, but also about how to evaluate them. Despite numerous existing benchmarks, insufficient attention is often given to creating assessments that test LLMs in a valid and reliable manner. To address this challenge, we accommodate the Evidence-centered design (ECD) methodology and propose a comprehensive approach to benchmark development based on rigorous psychometric principles. In this paper, we have made the first attempt to illustrate this approach by creating a new benchmark in the field of pedagogy and education, highlighting the limitations of existing benchmark development approach and taking into account the development of LLMs. We conclude that a new approach to benchmarking is required to match the growing complexity of AI applications in the educational context. We construct a novel benchmark guided by the Bloom's taxonomy and rigorously designed by a consortium of education experts trained in test development. Thus the current benchmark provides an academically robust and practical assessment tool tailored for LLMs, rather than human participants. Tested empirically on the GPT model in the Russian language, it evaluates model performance across varied task complexities, revealing critical gaps in current LLM capabilities. Our results indicate that while generative AI tools hold significant promise for education - potentially supporting tasks such as personalized tutoring, real-time feedback, and multilingual learning - their reliability as autonomous teachers' assistants right now remain rather limited, particularly in tasks requiring deeper cognitive engagement.</li>
</ul>

<h3>Title: CurateGPT: A flexible language-model assisted biocuration tool</h3>
<ul>
<li><strong>Authors: </strong>Harry Caufield, Carlo Kroll, Shawn T O'Neil, Justin T Reese, Marcin P Joachimiak, Harshad Hegde, Nomi L Harris, Madan Krishnamurthy, James A McLaughlin, Damian Smedley, Melissa A Haendel, Peter N Robinson, Christopher J Mungall</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00046">https://arxiv.org/abs/2411.00046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00046">https://arxiv.org/pdf/2411.00046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00046]] CurateGPT: A flexible language-model assisted biocuration tool(https://arxiv.org/abs/2411.00046)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative, large language model</a></li>
<li><strong>Abstract: </strong>Effective data-driven biomedical discovery requires data curation: a time-consuming process of finding, organizing, distilling, integrating, interpreting, annotating, and validating diverse information into a structured form suitable for databases and knowledge bases. Accurate and efficient curation of these digital assets is critical to ensuring that they are FAIR, trustworthy, and sustainable. Unfortunately, expert curators face significant time and resource constraints. The rapid pace of new information being published daily is exceeding their capacity for curation. Generative AI, exemplified by instruction-tuned large language models (LLMs), has opened up new possibilities for assisting human-driven curation. The design philosophy of agents combines the emerging abilities of generative AI with more precise methods. A curator's tasks can be aided by agents for performing reasoning, searching ontologies, and integrating knowledge across external sources, all efforts otherwise requiring extensive manual effort. Our LLM-driven annotation tool, CurateGPT, melds the power of generative AI together with trusted knowledge bases and literature sources. CurateGPT streamlines the curation process, enhancing collaboration and efficiency in common workflows. Compared to direct interaction with an LLM, CurateGPT's agents enable access to information beyond that in the LLM's training data and they provide direct links to the data supporting each claim. This helps curators, researchers, and engineers scale up curation efforts to keep pace with the ever-increasing volume of scientific data.</li>
</ul>

<h3>Title: Rule by Rule: Learning with Confidence through Vocabulary Expansion</h3>
<ul>
<li><strong>Authors: </strong>Albert Nössig, Tobias Hell, Georg Moser</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00049">https://arxiv.org/abs/2411.00049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00049">https://arxiv.org/pdf/2411.00049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00049]] Rule by Rule: Learning with Confidence through Vocabulary Expansion(https://arxiv.org/abs/2411.00049)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present an innovative iterative approach to rule learning specifically designed for (but not limited to) text-based data. Our method focuses on progressively expanding the vocabulary utilized in each iteration resulting in a significant reduction of memory consumption. Moreover, we introduce a Value of Confidence as an indicator of the reliability of the generated rules. By leveraging the Value of Confidence, our approach ensures that only the most robust and trustworthy rules are retained, thereby improving the overall quality of the rule learning process. We demonstrate the effectiveness of our method through extensive experiments on various textual as well as non-textual datasets including a use case of significant interest to insurance industries, showcasing its potential for real-world applications.</li>
</ul>

<h3>Title: ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate</h3>
<ul>
<li><strong>Authors: </strong>Andrew Estornell, Jean-Francois Ton, Yuanshun Yao, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00053">https://arxiv.org/abs/2411.00053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00053">https://arxiv.org/pdf/2411.00053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00053]] ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate(https://arxiv.org/abs/2411.00053)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models, frequently referred to as multi-agent debate (MAD). While debate shows promise as a means of improving model efficacy, most works in this area treat debate as an emergent behavior, rather than a learned behavior. In doing so, current debate frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Debate, an Actor-Critic based learning framework to produce a two-agent team specialized in debate. We demonstrate that ACC-Debate outperforms SotA debate techniques on a wide array of benchmarks.</li>
</ul>

<h3>Title: Generating Diverse Negations from Affirmative Sentences</h3>
<ul>
<li><strong>Authors: </strong>Darian Rodriguez Vasquez, Afroditi Papadaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00056">https://arxiv.org/abs/2411.00056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00056">https://arxiv.org/pdf/2411.00056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00056]] Generating Diverse Negations from Affirmative Sentences(https://arxiv.org/abs/2411.00056)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the impressive performance of large language models across various tasks, they often struggle with reasoning under negated statements. Negations are important in real-world applications as they encode negative polarity in verb phrases, clauses, or other expressions. Nevertheless, they are underrepresented in current benchmarks, which mainly include basic negation forms and overlook more complex ones, resulting in insufficient data for training a language model. In this work, we propose NegVerse, a method that tackles the lack of negation datasets by producing a diverse range of negation types from affirmative sentences, including verbal, non-verbal, and affixal forms commonly found in English text. We provide new rules for masking parts of sentences where negations are most likely to occur, based on syntactic structure and use a frozen baseline LLM and prompt tuning to generate negated sentences. We also propose a filtering mechanism to identify negation cues and remove degenerate examples, producing a diverse range of meaningful perturbations. Our results show that NegVerse outperforms existing methods and generates negations with higher lexical similarity to the original sentences, better syntactic preservation and negation diversity. The code is available in this https URL</li>
</ul>

<h3>Title: Evolving Alignment via Asymmetric Self-Play</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Ye, Rishabh Agarwal, Tianqi Liu, Rishabh Joshi, Sarmishta Velury, Quoc V. Le, Qijun Tan, Yuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, physics.data-an, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00062">https://arxiv.org/abs/2411.00062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00062">https://arxiv.org/pdf/2411.00062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00062]] Evolving Alignment via Asymmetric Self-Play(https://arxiv.org/abs/2411.00062)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Current RLHF frameworks for aligning large language models (LLMs) typically assume a fixed prompt distribution, which is sub-optimal and limits the scalability of alignment and generalizability of models. To address this, we introduce a general open-ended RLHF framework that casts alignment as an asymmetric game between two players: (i) a creator that generates increasingly informative prompt distributions using the reward model, and (ii) a solver that learns to produce more preferred responses on prompts produced by the creator. This framework of Evolving Alignment via Asymmetric Self-Play (eva), results in a simple and efficient approach that can utilize any existing RLHF algorithm for scalable alignment. eva outperforms state-of-the-art methods on widely-used benchmarks, without the need of any additional human crafted prompts. Specifically, eva improves the win rate of Gemma-2-9B-it on Arena-Hard from 51.6% to 60.1% with DPO, from 55.7% to 58.9% with SPPO, from 52.3% to 60.7% with SimPO, and from 54.8% to 60.3% with ORPO, surpassing its 27B version and matching claude-3-opus. This improvement is persistent even when new human crafted prompts are introduced. Finally, we show eva is effective and robust under various ablation settings.</li>
</ul>

<h3>Title: Interpretable Language Modeling via Induction-head Ngram Models</h3>
<ul>
<li><strong>Authors: </strong>Eunji Kim, Sriya Mantena, Weiwei Yang, Chandan Singh, Sungroh Yoon, Jianfeng Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00066">https://arxiv.org/abs/2411.00066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00066">https://arxiv.org/pdf/2411.00066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00066]] Interpretable Language Modeling via Induction-head Ngram Models(https://arxiv.org/abs/2411.00066)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) have excelled across a wide range of tasks, but their use in high-stakes and compute-limited settings has intensified the demand for interpretability and efficiency. We address this need by proposing Induction-head ngram models (Induction-Gram), a method that builds an efficient, interpretable LM by bolstering modern ngram models with a hand-engineered "induction head". This induction head uses a custom neural similarity metric to efficiently search the model's input context for potential next-word completions. This process enables Induction-Gram to provide ngram-level grounding for each generated token. Moreover, experiments show that this simple method significantly improves next-word prediction over baseline interpretable models (up to 26%p) and can be used to speed up LLM inference for large models through speculative decoding. We further study Induction-Gram in a natural-language neuroscience setting, where the goal is to predict the next fMRI response in a sequence. It again provides a significant improvement over interpretable models (20% relative increase in the correlation of predicted fMRI responses), potentially enabling deeper scientific investigation of language selectivity in the brain. The code is available at this https URL.</li>
</ul>

<h3>Title: Masking Gaussian Elimination at Arbitrary Order, with Application to Multivariate- and Code-Based PQC</h3>
<ul>
<li><strong>Authors: </strong>Quinten Norga, Suparna Kundu, Uttam Kumar Ojha, Anindya Ganguly, Angshuman Karmakar, Ingrid Verbauwhede</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00067">https://arxiv.org/abs/2411.00067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00067">https://arxiv.org/pdf/2411.00067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00067]] Masking Gaussian Elimination at Arbitrary Order, with Application to Multivariate- and Code-Based PQC(https://arxiv.org/abs/2411.00067)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Digital signature schemes based on multivariate- and code-based hard problems are promising alternatives for lattice-based signature schemes due to their smaller signature size. Hence, several candidates in the ongoing additional standardization for quantum secure digital signature (DS) schemes by the NIST rely on such alternate hard problems. Gaussian Elimination (GE) is a critical component in the signing procedure of these schemes. In this paper, we provide a masking scheme for GE with back substitution to defend against first- and higher-order attacks. To the best of our knowledge, this work is the first to analyze and propose masking techniques for multivariate- or code-based DS algorithms. We propose a masked algorithm for transforming a system of linear equations into row-echelon form. This is realized by introducing techniques for efficiently making leading (pivot) elements one while avoiding costly conversions between Boolean and multiplicative masking at all orders. We also propose a technique for efficient masked back substitution, which eventually enables a secure unmasking of the public output. We evaluate the overhead of our countermeasure for several post-quantum candidates and their different security levels at first-, second-, and third-order, including UOV, MAYO, SNOVA, QR-UOV, and MQ-Sign. Notably, the operational cost of first-, second-, and third-order masked GE is 2.3x higher, and the randomness cost is 1.2x higher in MAYO compared to UOV for security levels III and V. We also show detailed performance results for masked GE implementations for all three security versions of UOV on the Arm Cortex-M4 and compare them with unmasked results. Our first-order implementations targeting UOV parameters have overheads of factor 6.5x, 5.9x, and 5.7x compared to the unprotected implementation for NIST security level I, III, and V.</li>
</ul>

<h3>Title: RSL-SQL: Robust Schema Linking in Text-to-SQL Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhenbiao Cao, Yuanlei Zheng, Zhihao Fan, Xiaojin Zhang, Wei Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00073">https://arxiv.org/abs/2411.00073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00073">https://arxiv.org/pdf/2411.00073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00073]] RSL-SQL: Robust Schema Linking in Text-to-SQL Generation(https://arxiv.org/abs/2411.00073)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Text-to-SQL generation aims to translate natural language questions into SQL statements. In large language models (LLMs) based Text-to-SQL, schema linking is a widely adopted strategy to streamline the input for LLMs by selecting only relevant schema elements, therefore reducing noise and computational overhead. However, schema linking faces risks that requires caution, including the potential omission of necessary elements and disruption of database structural integrity. To address these challenges, we propose a novel framework called RSL-SQL that combines bidirectional schema linking, contextual information augmentation, binary selection strategy, and multi-turn self-correction. Our approach improves the recall of schema linking through forward and backward pruning and hedges the risk by voting between full schema and contextual information augmented simplified schema. Experiments on the BIRD and Spider benchmarks demonstrate that our approach achieves state-of-the-art execution accuracy among open-source solutions, with 67.2% on BIRD and 87.9% on Spider using GPT-4o. Furthermore, our approach outperforms a series of GPT-4 based Text-to-SQL systems when adopting DeepSeek (much cheaper) with same intact prompts. Extensive analysis and ablation studies confirm the effectiveness of each component in our framework. The codes are available at this https URL.</li>
</ul>

<h3>Title: $\boldsymbol{\mu}\mathbf{P^2}$: Effective Sharpness Aware Minimization Requires Layerwise Perturbation Scaling</h3>
<ul>
<li><strong>Authors: </strong>Moritz Haas, Jin Xu, Volkan Cevher, Leena Chennuru Vankadara</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00075">https://arxiv.org/abs/2411.00075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00075">https://arxiv.org/pdf/2411.00075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00075]] $\boldsymbol{\mu}\mathbf{P^2}$: Effective Sharpness Aware Minimization Requires Layerwise Perturbation Scaling(https://arxiv.org/abs/2411.00075)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sharpness Aware Minimization (SAM) enhances performance across various neural architectures and datasets. As models are continually scaled up to improve performance, a rigorous understanding of SAM's scaling behaviour is paramount. To this end, we study the infinite-width limit of neural networks trained with SAM, using the Tensor Programs framework. Our findings reveal that the dynamics of standard SAM effectively reduce to applying SAM solely in the last layer in wide neural networks, even with optimal hyperparameters. In contrast, we identify a stable parameterization with layerwise perturbation scaling, which we call $\textit{Maximal Update and Perturbation Parameterization}$ ($\mu$P$^2$), that ensures all layers are both feature learning and effectively perturbed in the limit. Through experiments with MLPs, ResNets and Vision Transformers, we empirically demonstrate that $\mu$P$^2$ is the first parameterization to achieve hyperparameter transfer of the joint optimum of learning rate and perturbation radius across model scales. Moreover, we provide an intuitive condition to derive $\mu$P$^2$ for other perturbation rules like Adaptive SAM and SAM-ON, also ensuring balanced perturbation effects across all layers.</li>
</ul>

<h3>Title: Blockchain Services for Digital Government: An Exploration of NFT Applications in the Metaverse</h3>
<ul>
<li><strong>Authors: </strong>Zachary Roch, Ramya Akula</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00076">https://arxiv.org/abs/2411.00076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00076">https://arxiv.org/pdf/2411.00076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00076]] Blockchain Services for Digital Government: An Exploration of NFT Applications in the Metaverse(https://arxiv.org/abs/2411.00076)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The full implementation of the metaverse requires the integration of the physical and digital worlds. Applications built on Distributed Ledger Technology (DLT) hold the power to move society closer towards the ideal metaverse through innovations like Non-Fungible Tokens (NFTs). Due to a combination of the infancy of this technology and the significant implications it holds in the public and private sectors, adoption across both sectors is currently limited. To foster the creation of sustainable smart cities built on this technology, education on how this technology may function in an integrated metaverse is paramount. This is due to the necessary compatibility across industries needed between public and private data. As certain industries are more regulated than others, such as finance or healthcare, a robust system is needed to allow for varying degrees of freedom. This chapter illustrates numerous facets of this conceptual framework.</li>
</ul>

<h3>Title: How Good Are We? Evaluating Cell AI Foundation Models in Kidney Pathology with Human-in-the-Loop Enrichment</h3>
<ul>
<li><strong>Authors: </strong>Junlin Guo, Siqi Lu, Can Cui, Ruining Deng, Tianyuan Yao, Zhewen Tao, Yizhe Lin, Marilyn Lionts, Quan Liu, Juming Xiong, Yu Wang, Shilin Zhao, Catie Chang, Mitchell Wilkes, Mengmeng Yin, Haichun Yang, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00078">https://arxiv.org/abs/2411.00078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00078">https://arxiv.org/pdf/2411.00078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00078]] How Good Are We? Evaluating Cell AI Foundation Models in Kidney Pathology with Human-in-the-Loop Enrichment(https://arxiv.org/abs/2411.00078)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Training AI foundation models has emerged as a promising large-scale learning approach for addressing real-world healthcare challenges, including digital pathology. While many of these models have been developed for tasks like disease diagnosis and tissue quantification using extensive and diverse training datasets, their readiness for deployment on some arguably simplest tasks, such as nuclei segmentation within a single organ (e.g., the kidney), remains uncertain. This paper seeks to answer this key question, "How good are we?", by thoroughly evaluating the performance of recent cell foundation models on a curated multi-center, multi-disease, and multi-species external testing dataset. Additionally, we tackle a more challenging question, "How can we improve?", by developing and assessing human-in-the-loop data enrichment strategies aimed at enhancing model performance while minimizing the reliance on pixel-level human annotation. To address the first question, we curated a multicenter, multidisease, and multispecies dataset consisting of 2,542 kidney whole slide images (WSIs). Three state-of-the-art (SOTA) cell foundation models-Cellpose, StarDist, and CellViT-were selected for evaluation. To tackle the second question, we explored data enrichment algorithms by distilling predictions from the different foundation models with a human-in-the-loop framework, aiming to further enhance foundation model performance with minimal human efforts. Our experimental results showed that all three foundation models improved over their baselines with model fine-tuning with enriched data. Interestingly, the baseline model with the highest F1 score does not yield the best segmentation outcomes after fine-tuning. This study establishes a benchmark for the development and deployment of cell vision foundation models tailored for real-world data applications.</li>
</ul>

<h3>Title: LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators</h3>
<ul>
<li><strong>Authors: </strong>Krishna Teja Chitty-Venkata, Siddhisanket Raskar, Bharat Kale, Farah Ferdaus, Aditya Tanikanti, Ken Raffenetti, Valerie Taylor, Murali Emani, Venkatram Vishwanath</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00136">https://arxiv.org/abs/2411.00136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00136">https://arxiv.org/pdf/2411.00136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00136]] LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators(https://arxiv.org/abs/2411.00136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have propelled groundbreaking advancements across several domains and are commonly used for text generation applications. However, the computational demands of these complex models pose significant challenges, requiring efficient hardware acceleration. Benchmarking the performance of LLMs across diverse hardware platforms is crucial to understanding their scalability and throughput characteristics. We introduce LLM-Inference-Bench, a comprehensive benchmarking suite to evaluate the hardware inference performance of LLMs. We thoroughly analyze diverse hardware platforms, including GPUs from Nvidia and AMD and specialized AI accelerators, Intel Habana and SambaNova. Our evaluation includes several LLM inference frameworks and models from LLaMA, Mistral, and Qwen families with 7B and 70B parameters. Our benchmarking results reveal the strengths and limitations of various models, hardware platforms, and inference frameworks. We provide an interactive dashboard to help identify configurations for optimal performance for a given hardware platform.</li>
</ul>

<h3>Title: Learning local discrete features in explainable-by-design convolutional neural networks</h3>
<ul>
<li><strong>Authors: </strong>Pantelis I. Kaplanoglou, Konstantinos Diamantaras</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00139">https://arxiv.org/abs/2411.00139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00139">https://arxiv.org/pdf/2411.00139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00139]] Learning local discrete features in explainable-by-design convolutional neural networks(https://arxiv.org/abs/2411.00139)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Our proposed framework attempts to break the trade-off between performance and explainability by introducing an explainable-by-design convolutional neural network (CNN) based on the lateral inhibition mechanism. The ExplaiNet model consists of the predictor, that is a high-accuracy CNN with residual or dense skip connections, and the explainer probabilistic graph that expresses the spatial interactions of the network neurons. The value on each graph node is a local discrete feature (LDF) vector, a patch descriptor that represents the indices of antagonistic neurons ordered by the strength of their activations, which are learned with gradient descent. Using LDFs as sequences we can increase the conciseness of explanations by repurposing EXTREME, an EM-based sequence motif discovery method that is typically used in molecular biology. Having a discrete feature motif matrix for each one of intermediate image representations, instead of a continuous activation tensor, allows us to leverage the inherent explainability of Bayesian networks. By collecting observations and directly calculating probabilities, we can explain causal relationships between motifs of adjacent levels and attribute the model's output to global motifs. Moreover, experiments on various tiny image benchmark datasets confirm that our predictor ensures the same level of performance as the baseline architecture for a given count of parameters and/or layers. Our novel method shows promise to exceed this performance while providing an additional stream of explanations. In the solved MNIST classification task, it reaches a comparable to the state-of-the-art performance for single models, using standard training setup and 0.75 million parameters.</li>
</ul>

<h3>Title: JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking</h3>
<ul>
<li><strong>Authors: </strong>Tong Niu, Shafiq Joty, Ye Liu, Caiming Xiong, Yingbo Zhou, Semih Yavuz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00142">https://arxiv.org/abs/2411.00142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00142">https://arxiv.org/pdf/2411.00142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00142]] JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking(https://arxiv.org/abs/2411.00142)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate document retrieval is crucial for the success of retrieval-augmented generation (RAG) applications, including open-domain question answering and code completion. While large language models (LLMs) have been employed as dense encoders or listwise rerankers in RAG systems, they often struggle with reasoning-intensive tasks because they lack nuanced analysis when judging document relevance. To address this limitation, we introduce JudgeRank, a novel agentic reranker that emulates human cognitive processes when assessing document relevance. Our approach consists of three key steps: (1) query analysis to identify the core problem, (2) document analysis to extract a query-aware summary, and (3) relevance judgment to provide a concise assessment of document relevance. We evaluate JudgeRank on the reasoning-intensive BRIGHT benchmark, demonstrating substantial performance improvements over first-stage retrieval methods and outperforming other popular reranking approaches. In addition, JudgeRank performs on par with fine-tuned state-of-the-art rerankers on the popular BEIR benchmark, validating its zero-shot generalization capability. Through comprehensive ablation studies, we demonstrate that JudgeRank's performance generalizes well across LLMs of various sizes while ensembling them yields even more accurate reranking than individual models.</li>
</ul>

<h3>Title: Self-Ensembling Gaussian Splatting for Few-shot Novel View Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Chen Zhao, Xuan Wang, Tong Zhang, Saqib Javed, Mathieu Salzmann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00144">https://arxiv.org/abs/2411.00144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00144">https://arxiv.org/pdf/2411.00144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00144]] Self-Ensembling Gaussian Splatting for Few-shot Novel View Synthesis(https://arxiv.org/abs/2411.00144)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has demonstrated remarkable effectiveness for novel view synthesis (NVS). However, the 3DGS model tends to overfit when trained with sparse posed views, limiting its generalization capacity for broader pose variations. In this paper, we alleviate the overfitting problem by introducing a self-ensembling Gaussian Splatting (SE-GS) approach. We present two Gaussian Splatting models named the $\mathbf{\Sigma}$-model and the $\mathbf{\Delta}$-model. The $\mathbf{\Sigma}$-model serves as the primary model that generates novel-view images during inference. At the training stage, the $\mathbf{\Sigma}$-model is guided away from specific local optima by an uncertainty-aware perturbing strategy. We dynamically perturb the $\mathbf{\Delta}$-model based on the uncertainties of novel-view renderings across different training steps, resulting in diverse temporal models sampled from the Gaussian parameter space without additional training costs. The geometry of the $\mathbf{\Sigma}$-model is regularized by penalizing discrepancies between the $\mathbf{\Sigma}$-model and the temporal samples. Therefore, our SE-GS conducts an effective and efficient regularization across a large number of Gaussian Splatting models, resulting in a robust ensemble, the $\mathbf{\Sigma}$-model. Experimental results on the LLFF, Mip-NeRF360, DTU, and MVImgNet datasets show that our approach improves NVS quality with few-shot training views, outperforming existing state-of-the-art methods. The code is released at this https URL.</li>
</ul>

<h3>Title: Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking</h3>
<ul>
<li><strong>Authors: </strong>Christopher Richardson, Roshan Sharma, Neeraj Gaur, Parisa Haghani, Anirudh Sundar, Bhuvana Ramabhadran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00150">https://arxiv.org/abs/2411.00150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00150">https://arxiv.org/pdf/2411.00150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00150]] Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking(https://arxiv.org/abs/2411.00150)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Zero-shot domain adaptation for dialogue state tracking (DST) remains a challenging problem in task-oriented dialogue (TOD) systems, where models must generalize to target domains unseen at training time. Current large language model approaches for zero-shot domain adaptation rely on prompting to introduce knowledge pertaining to the target domains. However, their efficacy strongly depends on prompt engineering, as well as the zero-shot ability of the underlying language model. In this work, we devise a novel data augmentation approach, Schema Augmentation, that improves the zero-shot domain adaptation of language models through fine-tuning. Schema Augmentation is a simple but effective technique that enhances generalization by introducing variations of slot names within the schema provided in the prompt. Experiments on MultiWOZ and SpokenWOZ showed that the proposed approach resulted in a substantial improvement over the baseline, in some experiments achieving over a twofold accuracy gain over unseen domains while maintaining equal or superior performance over all domains.</li>
</ul>

<h3>Title: NIMBA: Towards Robust and Principled Processing of Point Clouds With SSMs</h3>
<ul>
<li><strong>Authors: </strong>Nursena Köprücü, Destiny Okpekpe, Antonio Orvieto</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00151">https://arxiv.org/abs/2411.00151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00151">https://arxiv.org/pdf/2411.00151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00151]] NIMBA: Towards Robust and Principled Processing of Point Clouds With SSMs(https://arxiv.org/abs/2411.00151)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have become dominant in large-scale deep learning tasks across various domains, including text, 2D and 3D vision. However, the quadratic complexity of their attention mechanism limits their efficiency as the sequence length increases, particularly in high-resolution 3D data such as point clouds. Recently, state space models (SSMs) like Mamba have emerged as promising alternatives, offering linear complexity, scalability, and high performance in long-sequence tasks. The key challenge in the application of SSMs in this domain lies in reconciling the non-sequential structure of point clouds with the inherently directional (or bi-directional) order-dependent processing of recurrent models like Mamba. To achieve this, previous research proposed reorganizing point clouds along multiple directions or predetermined paths in 3D space, concatenating the results to produce a single 1D sequence capturing different views. In our work, we introduce a method to convert point clouds into 1D sequences that maintain 3D spatial structure with no need for data replication, allowing Mamba sequential processing to be applied effectively in an almost permutation-invariant manner. In contrast to other works, we found that our method does not require positional embeddings and allows for shorter sequence lengths while still achieving state-of-the-art results in ModelNet40 and ScanObjectNN datasets and surpassing Transformer-based models in both accuracy and efficiency.</li>
</ul>

<h3>Title: Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haritz Puerto, Martin Gubri, Sangdoo Yun, Seong Joon Oh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00154">https://arxiv.org/abs/2411.00154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00154">https://arxiv.org/pdf/2411.00154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00154]] Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models(https://arxiv.org/abs/2411.00154)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, membership infer, large language model</a></li>
<li><strong>Abstract: </strong>Membership inference attacks (MIA) attempt to verify the membership of a given data sample in the training set for a model. MIA has become relevant in recent years, following the rapid development of large language models (LLM). Many are concerned about the usage of copyrighted materials for training them and call for methods for detecting such usage. However, recent research has largely concluded that current MIA methods do not work on LLMs. Even when they seem to work, it is usually because of the ill-designed experimental setup where other shortcut features enable "cheating." In this work, we argue that MIA still works on LLMs, but only when multiple documents are presented for testing. We construct new benchmarks that measure the MIA performances at a continuous scale of data samples, from sentences (n-grams) to a collection of documents (multiple chunks of tokens). To validate the efficacy of current MIA approaches at greater scales, we adapt a recent work on Dataset Inference (DI) for the task of binary membership detection that aggregates paragraph-level MIA features to enable MIA at document and collection of documents level. This baseline achieves the first successful MIA on pre-trained and fine-tuned LLMs.</li>
</ul>

<h3>Title: PSL: Rethinking and Improving Softmax Loss from Pairwise Perspective for Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Weiqin Yang, Jiawei Chen, Xin Xin, Sheng Zhou, Binbin Hu, Yan Feng, Chun Chen, Can Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00163">https://arxiv.org/abs/2411.00163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00163">https://arxiv.org/pdf/2411.00163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00163]] PSL: Rethinking and Improving Softmax Loss from Pairwise Perspective for Recommendation(https://arxiv.org/abs/2411.00163)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Softmax Loss (SL) is widely applied in recommender systems (RS) and has demonstrated effectiveness. This work analyzes SL from a pairwise perspective, revealing two significant limitations: 1) the relationship between SL and conventional ranking metrics like DCG is not sufficiently tight; 2) SL is highly sensitive to false negative instances. Our analysis indicates that these limitations are primarily due to the use of the exponential function. To address these issues, this work extends SL to a new family of loss functions, termed Pairwise Softmax Loss (PSL), which replaces the exponential function in SL with other appropriate activation functions. While the revision is minimal, we highlight three merits of PSL: 1) it serves as a tighter surrogate for DCG with suitable activation functions; 2) it better balances data contributions; and 3) it acts as a specific BPR loss enhanced by Distributionally Robust Optimization (DRO). We further validate the effectiveness and robustness of PSL through empirical experiments. The code is available at this https URL.</li>
</ul>

<h3>Title: A Recipe for Geometry-Aware 3D Mesh Transformers</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Farazi, Yalin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00164">https://arxiv.org/abs/2411.00164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00164">https://arxiv.org/pdf/2411.00164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00164]] A Recipe for Geometry-Aware 3D Mesh Transformers(https://arxiv.org/abs/2411.00164)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Utilizing patch-based transformers for unstructured geometric data such as polygon meshes presents significant challenges, primarily due to the absence of a canonical ordering and variations in input sizes. Prior approaches to handling 3D meshes and point clouds have either relied on computationally intensive node-level tokens for large objects or resorted to resampling to standardize patch size. Moreover, these methods generally lack a geometry-aware, stable Structural Embedding (SE), often depending on simplistic absolute SEs such as 3D coordinates, which compromise isometry invariance essential for tasks like semantic segmentation. In our study, we meticulously examine the various components of a geometry-aware 3D mesh transformer, from tokenization to structural encoding, assessing the contribution of each. Initially, we introduce a spectral-preserving tokenization rooted in algebraic multigrid methods. Subsequently, we detail an approach for embedding features at the patch level, accommodating patches with variable node counts. Through comparative analyses against a baseline model employing simple point-wise Multi-Layer Perceptrons (MLP), our research highlights critical insights: 1) the importance of structural and positional embeddings facilitated by heat diffusion in general 3D mesh transformers; 2) the effectiveness of novel components such as geodesic masking and feature interaction via cross-attention in enhancing learning; and 3) the superior performance and efficiency of our proposed methods in challenging segmentation and classification tasks.</li>
</ul>

<h3>Title: Aerial Flood Scene Classification Using Fine-Tuned Attention-based Architecture for Flood-Prone Countries in South Asia</h3>
<ul>
<li><strong>Authors: </strong>Ibne Hassan, Aman Mujahid, Abdullah Al Hasib, Andalib Rahman Shagoto, Joyanta Jyoti Mondal, Meem Arafat Manab, Jannatun Noor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00169">https://arxiv.org/abs/2411.00169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00169">https://arxiv.org/pdf/2411.00169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00169]] Aerial Flood Scene Classification Using Fine-Tuned Attention-based Architecture for Flood-Prone Countries in South Asia(https://arxiv.org/abs/2411.00169)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Countries in South Asia experience many catastrophic flooding events regularly. Through image classification, it is possible to expedite search and rescue initiatives by classifying flood zones, including houses and humans. We create a new dataset collecting aerial imagery of flooding events across South Asian countries. For the classification, we propose a fine-tuned Compact Convolutional Transformer (CCT) based approach and some other cutting-edge transformer-based and Convolutional Neural Network-based architectures (CNN). We also implement the YOLOv8 object detection model and detect houses and humans within the imagery of our proposed dataset, and then compare the performance with our classification-based approach. Since the countries in South Asia have similar topography, housing structure, the color of flood water, and vegetation, this work can be more applicable to such a region as opposed to the rest of the world. The images are divided evenly into four classes: 'flood', 'flood with domicile', 'flood with humans', and 'no flood'. After experimenting with our proposed dataset on our fine-tuned CCT model, which has a comparatively lower number of weight parameters than many other transformer-based architectures designed for computer vision, it exhibits an accuracy and macro average precision of 98.62% and 98.50%. The other transformer-based architectures that we implement are the Vision Transformer (ViT), Swin Transformer, and External Attention Transformer (EANet), which give an accuracy of 88.66%, 84.74%, and 66.56% respectively. We also implement DCECNN (Deep Custom Ensembled Convolutional Neural Network), which is a custom ensemble model that we create by combining MobileNet, InceptionV3, and EfficientNetB0, and we obtain an accuracy of 98.78%. The architectures we implement are fine-tuned to achieve optimal performance on our dataset.</li>
</ul>

<h3>Title: SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey</h3>
<ul>
<li><strong>Authors: </strong>Kien X. Nguyen, Fengchun Qiao, Arthur Trembanis, Xi Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00172">https://arxiv.org/abs/2411.00172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00172">https://arxiv.org/pdf/2411.00172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00172]] SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey(https://arxiv.org/abs/2411.00172)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>A major obstacle to the advancements of machine learning models in marine science, particularly in sonar imagery analysis, is the scarcity of AI-ready datasets. While there have been efforts to make AI-ready sonar image dataset publicly available, they suffer from limitations in terms of environment setting and scale. To bridge this gap, we introduce SeafloorAI, the first extensive AI-ready datasets for seafloor mapping across 5 geological layers that is curated in collaboration with marine scientists. We further extend the dataset to SeafloorGenAI by incorporating the language component in order to facilitate the development of both vision- and language-capable machine learning models for sonar imagery. The dataset consists of 62 geo-distributed data surveys spanning 17,300 square kilometers, with 696K sonar images, 827K annotated segmentation masks, 696K detailed language descriptions and approximately 7M question-answer pairs. By making our data processing source code publicly available, we aim to engage the marine science community to enrich the data pool and inspire the machine learning community to develop more robust models. This collaborative approach will enhance the capabilities and applications of our datasets within both fields.</li>
</ul>

<h3>Title: Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning</h3>
<ul>
<li><strong>Authors: </strong>John Wu, David Wu, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00173">https://arxiv.org/abs/2411.00173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00173">https://arxiv.org/pdf/2411.00173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00173]] Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning(https://arxiv.org/abs/2411.00173)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Medical coding, the translation of unstructured clinical text into standardized medical codes, is a crucial but time-consuming healthcare practice. Though large language models (LLM) could automate the coding process and improve the efficiency of such tasks, interpretability remains paramount for maintaining patient trust. Current efforts in interpretability of medical coding applications rely heavily on label attention mechanisms, which often leads to the highlighting of extraneous tokens irrelevant to the ICD code. To facilitate accurate interpretability in medical language models, this paper leverages dictionary learning that can efficiently extract sparsely activated representations from dense language model embeddings in superposition. Compared with common label attention mechanisms, our model goes beyond token-level representations by building an interpretable dictionary which enhances the mechanistic-based explanations for each ICD code prediction, even when the highlighted tokens are medically irrelevant. We show that dictionary features can steer model behavior, elucidate the hidden meanings of upwards of 90% of medically irrelevant tokens, and are human interpretable.</li>
</ul>

<h3>Title: Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy</h3>
<ul>
<li><strong>Authors: </strong>Panagiota Gatoula, Dimitrios E. Diamantis, Anastasios Koulaouzidis, Cristina Carretero, Stefania Chetcuti-Zammit, Pablo Cortegoso Valdivia, Begoña González-Suárez, Alessandro Mussetto, John Plevris, Alexander Robertson, Bruno Rosa, Ervin Toth, Dimitris K. Iakovidis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00178">https://arxiv.org/abs/2411.00178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00178">https://arxiv.org/pdf/2411.00178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00178]] Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy(https://arxiv.org/abs/2411.00178)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Sharing retrospectively acquired data is essential for both clinical research and training. Synthetic Data Generation (SDG), using Artificial Intelligence (AI) models, can overcome privacy barriers in sharing clinical data, enabling advancements in medical diagnostics. This study focuses on the clinical evaluation of medical SDG, with a proof-of-concept investigation on diagnosing Inflammatory Bowel Disease (IBD) using Wireless Capsule Endoscopy (WCE) images. The paper contributes by a) presenting a protocol for the systematic evaluation of synthetic images by medical experts and b) applying it to assess TIDE-II, a novel variational autoencoder-based model for high-resolution WCE image synthesis, with a comprehensive qualitative evaluation conducted by 10 international WCE specialists, focusing on image quality, diversity, realism, and clinical decision-making. The results show that TIDE-II generates clinically relevant WCE images, helping to address data scarcity and enhance diagnostic tools. The proposed protocol serves as a reference for future research on medical image-generation techniques.</li>
</ul>

<h3>Title: Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments</h3>
<ul>
<li><strong>Authors: </strong>Paulius Rauba, Nabeel Seedat, Krzysztof Kacprzyk, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00186">https://arxiv.org/abs/2411.00186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00186">https://arxiv.org/pdf/2411.00186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00186]] Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments(https://arxiv.org/abs/2411.00186)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Real-world machine learning systems often encounter model performance degradation due to distributional shifts in the underlying data generating process (DGP). Existing approaches to addressing shifts, such as concept drift adaptation, are limited by their reason-agnostic nature. By choosing from a pre-defined set of actions, such methods implicitly assume that the causes of model degradation are irrelevant to what actions should be taken, limiting their ability to select appropriate adaptations. In this paper, we propose an alternative paradigm to overcome these limitations, called self-healing machine learning (SHML). Contrary to previous approaches, SHML autonomously diagnoses the reason for degradation and proposes diagnosis-based corrective actions. We formalize SHML as an optimization problem over a space of adaptation actions to minimize the expected risk under the shifted DGP. We introduce a theoretical framework for self-healing systems and build an agentic self-healing solution H-LLM which uses large language models to perform self-diagnosis by reasoning about the structure underlying the DGP, and self-adaptation by proposing and evaluating corrective actions. Empirically, we analyze different components of H-LLM to understand why and when it works, demonstrating the potential of self-healing ML.</li>
</ul>

<h3>Title: Monitoring fairness in machine learning models that predict patient mortality in the ICU</h3>
<ul>
<li><strong>Authors: </strong>Tempest A. van Schaik, Xinggang Liu, Louis Atallah, Omar Badawi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00190">https://arxiv.org/abs/2411.00190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00190">https://arxiv.org/pdf/2411.00190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00190]] Monitoring fairness in machine learning models that predict patient mortality in the ICU(https://arxiv.org/abs/2411.00190)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This work proposes a fairness monitoring approach for machine learning models that predict patient mortality in the ICU. We investigate how well models perform for patient groups with different race, sex and medical diagnoses. We investigate Documentation bias in clinical measurement, showing how fairness analysis provides a more detailed and insightful comparison of model performance than traditional accuracy metrics alone.</li>
</ul>

<h3>Title: Optical Lens Attack on Monocular Depth Estimation for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Ce Zhou (1), Qiben Yan (1), Daniel Kent (1), Guangjing Wang (2), Weikang Ding (1), Ziqi Zhang (3), Hayder Radha (1) ((1) Michigan State University, (2) University of South Florida, (3) Peking University)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00192">https://arxiv.org/abs/2411.00192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00192">https://arxiv.org/pdf/2411.00192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00192]] Optical Lens Attack on Monocular Depth Estimation for Autonomous Driving(https://arxiv.org/abs/2411.00192)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Monocular Depth Estimation (MDE) is a pivotal component of vision-based Autonomous Driving (AD) systems, enabling vehicles to estimate the depth of surrounding objects using a single camera image. This estimation guides essential driving decisions, such as braking before an obstacle or changing lanes to avoid collisions. In this paper, we explore vulnerabilities of MDE algorithms in AD systems, presenting LensAttack, a novel physical attack that strategically places optical lenses on the camera of an autonomous vehicle to manipulate the perceived object depths. LensAttack encompasses two attack formats: concave lens attack and convex lens attack, each utilizing different optical lenses to induce false depth perception. We first develop a mathematical model that outlines the parameters of the attack, followed by simulations and real-world evaluations to assess its efficacy on state-of-the-art MDE models. Additionally, we adopt an attack optimization method to further enhance the attack success rate by optimizing the attack focal length. To better evaluate the implications of LensAttack on AD, we conduct comprehensive end-to-end system simulations using the CARLA platform. The results reveal that LensAttack can significantly disrupt the depth estimation processes in AD systems, posing a serious threat to their reliability and safety. Finally, we discuss some potential defense methods to mitigate the effects of the proposed attack.</li>
</ul>

<h3>Title: Evaluating the Evolution of YOLO (You Only Look Once) Models: A Comprehensive Benchmark Study of YOLO11 and Its Predecessors</h3>
<ul>
<li><strong>Authors: </strong>Nidhal Jegham, Chan Young Koh, Marwan Abdelatti, Abdeltawab Hendawi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00201">https://arxiv.org/abs/2411.00201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00201">https://arxiv.org/pdf/2411.00201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00201]] Evaluating the Evolution of YOLO (You Only Look Once) Models: A Comprehensive Benchmark Study of YOLO11 and Its Predecessors(https://arxiv.org/abs/2411.00201)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study presents a comprehensive benchmark analysis of various YOLO (You Only Look Once) algorithms, from YOLOv3 to the newest addition. It represents the first research to comprehensively evaluate the performance of YOLO11, the latest addition to the YOLO family. It evaluates their performance on three diverse datasets: Traffic Signs (with varying object sizes), African Wildlife (with diverse aspect ratios and at least one instance of the object per image), and Ships and Vessels (with small-sized objects of a single class), ensuring a comprehensive assessment across datasets with distinct challenges. To ensure a robust evaluation, we employ a comprehensive set of metrics, including Precision, Recall, Mean Average Precision (mAP), Processing Time, GFLOPs count, and Model Size. Our analysis highlights the distinctive strengths and limitations of each YOLO version. For example: YOLOv9 demonstrates substantial accuracy but struggles with detecting small objects and efficiency whereas YOLOv10 exhibits relatively lower accuracy due to architectural choices that affect its performance in overlapping object detection but excels in speed and efficiency. Additionally, the YOLO11 family consistently shows superior performance in terms of accuracy, speed, computational efficiency, and model size. YOLO11m achieved a remarkable balance of accuracy and efficiency, scoring mAP50-95 scores of 0.795, 0.81, and 0.325 on the Traffic Signs, African Wildlife, and Ships datasets, respectively, while maintaining an average inference time of 2.4ms, a model size of 38.8Mb, and around 67.6 GFLOPs on average. These results provide critical insights for both industry and academia, facilitating the selection of the most suitable YOLO algorithm for diverse applications and guiding future enhancements.</li>
</ul>

<h3>Title: RESTOR: Knowledge Recovery through Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Keivan Rezaei, Khyathi Chandu, Soheil Feizi, Yejin Choi, Faeze Brahman, Abhilasha Ravichander</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00204">https://arxiv.org/abs/2411.00204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00204">https://arxiv.org/pdf/2411.00204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00204]] RESTOR: Knowledge Recovery through Machine Unlearning(https://arxiv.org/abs/2411.00204)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models trained on web-scale corpora can memorize undesirable datapoints such as incorrect facts, copyrighted content or sensitive data. Recently, many machine unlearning methods have been proposed that aim to 'erase' these datapoints from trained models -- that is, revert model behavior to be similar to a model that had never been trained on these datapoints. However, evaluating the success of unlearning algorithms remains challenging. In this work, we propose the RESTOR framework for machine unlearning based on the following dimensions: (1) a task setting that focuses on real-world factual knowledge, (2) a variety of corruption scenarios that emulate different kinds of datapoints that might need to be unlearned, and (3) evaluation metrics that emphasize not just forgetting undesirable knowledge, but also recovering the model's original state before encountering these datapoints, or restorative unlearning. RESTOR helps uncover several novel insights about popular unlearning algorithms, and the mechanisms through which they operate -- for instance, identifying that some algorithms merely emphasize forgetting the knowledge to be unlearned, and that localizing unlearning targets can enhance unlearning performance. Code/data is available at this http URL.</li>
</ul>

<h3>Title: Semantic Knowledge Distillation for Onboard Satellite Earth Observation Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Thanh-Dung Le, Vu Nguyen Ha, Ti Ti Nguyen, Geoffrey Eappen, Prabhu Thiruvasagam, Hong-fu Chou, Duc-Dung Tran, Luis M. Garces-Socarras, Jorge L. Gonzalez-Rios, Juan Carlos Merlano-Duncan, Symeon Chatzinotas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00209">https://arxiv.org/abs/2411.00209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00209">https://arxiv.org/pdf/2411.00209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00209]] Semantic Knowledge Distillation for Onboard Satellite Earth Observation Image Classification(https://arxiv.org/abs/2411.00209)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study presents an innovative dynamic weighting knowledge distillation (KD) framework tailored for efficient Earth observation (EO) image classification (IC) in resource-constrained settings. Utilizing EfficientViT and MobileViT as teacher models, this framework enables lightweight student models, particularly ResNet8 and ResNet16, to surpass 90% in accuracy, precision, and recall, adhering to the stringent confidence thresholds necessary for reliable classification tasks. Unlike conventional KD methods that rely on static weight distribution, our adaptive weighting mechanism responds to each teacher model's confidence, allowing student models to prioritize more credible sources of knowledge dynamically. Remarkably, ResNet8 delivers substantial efficiency gains, achieving a 97.5% reduction in parameters, a 96.7% decrease in FLOPs, an 86.2% cut in power consumption, and a 63.5% increase in inference speed over MobileViT. This significant optimization of complexity and resource demands establishes ResNet8 as an optimal candidate for EO tasks, combining robust performance with feasibility in deployment. The confidence-based, adaptable KD approach underscores the potential of dynamic distillation strategies to yield high-performing, resource-efficient models tailored for satellite-based EO applications. The reproducible code is accessible on our GitHub repository.</li>
</ul>

<h3>Title: ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing</h3>
<ul>
<li><strong>Authors: </strong>Haozhe Lei, Yunfei Ge, Quanyan Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00217">https://arxiv.org/abs/2411.00217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00217">https://arxiv.org/pdf/2411.00217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00217]] ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing(https://arxiv.org/abs/2411.00217)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI.</li>
</ul>

<h3>Title: Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Ganjidoost, Jeff Orchard</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00222">https://arxiv.org/abs/2411.00222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00222">https://arxiv.org/pdf/2411.00222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00222]] Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding(https://arxiv.org/abs/2411.00222)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>An adversarial example is a modified input image designed to cause a Machine Learning (ML) model to make a mistake; these perturbations are often invisible or subtle to human observers and highlight vulnerabilities in a model's ability to generalize from its training data. Several adversarial attacks can create such examples, each with a different perspective, effectiveness, and perceptibility of changes. Conversely, defending against such adversarial attacks improves the robustness of ML models in image processing and other domains of deep learning. Most defence mechanisms require either a level of model awareness, changes to the model, or access to a comprehensive set of adversarial examples during training, which is impractical. Another option is to use an auxiliary model in a preprocessing manner without changing the primary model. This study presents a practical and effective solution -- using predictive coding networks (PCnets) as an auxiliary step for adversarial defence. By seamlessly integrating PCnets into feed-forward networks as a preprocessing step, we substantially bolster resilience to adversarial perturbations. Our experiments on MNIST and CIFAR10 demonstrate the remarkable effectiveness of PCnets in mitigating adversarial examples with about 82% and 65% improvements in robustness, respectively. The PCnet, trained on a small subset of the dataset, leverages its generative nature to effectively counter adversarial efforts, reverting perturbed images closer to their original forms. This innovative approach holds promise for enhancing the security and reliability of neural network classifiers in the face of the escalating threat of adversarial attacks.</li>
</ul>

<h3>Title: Fashion-VDM: Video Diffusion Model for Virtual Try-On</h3>
<ul>
<li><strong>Authors: </strong>Johanna Karras, Yingwei Li, Nan Liu, Luyang Zhu, Innfarn Yoo, Andreas Lugmayr, Chris Lee, Ira Kemelmacher-Shlizerman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00225">https://arxiv.org/abs/2411.00225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00225">https://arxiv.org/pdf/2411.00225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00225]] Fashion-VDM: Video Diffusion Model for Virtual Try-On(https://arxiv.org/abs/2411.00225)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present Fashion-VDM, a video diffusion model (VDM) for generating virtual try-on videos. Given an input garment image and person video, our method aims to generate a high-quality try-on video of the person wearing the given garment, while preserving the person's identity and motion. Image-based virtual try-on has shown impressive results; however, existing video virtual try-on (VVT) methods are still lacking garment details and temporal consistency. To address these issues, we propose a diffusion-based architecture for video virtual try-on, split classifier-free guidance for increased control over the conditioning inputs, and a progressive temporal training strategy for single-pass 64-frame, 512px video generation. We also demonstrate the effectiveness of joint image-video training for video try-on, especially when video data is limited. Our qualitative and quantitative experiments show that our approach sets the new state-of-the-art for video virtual try-on. For additional results, visit our project page: this https URL.</li>
</ul>

<h3>Title: SambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models</h3>
<ul>
<li><strong>Authors: </strong>José Ignacio Olalde-Verano, Sascha Kirch, Clara Pérez-Molina, Sergio Martin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00233">https://arxiv.org/abs/2411.00233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00233">https://arxiv.org/pdf/2411.00233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00233]] SambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models(https://arxiv.org/abs/2411.00233)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The state of health (SOH) of a Li-ion battery is a critical parameter that determines the remaining capacity and the remaining lifetime of the battery. In this paper, we propose SambaMixer a novel structured state space model (SSM) for predicting the state of health of Li-ion batteries. The proposed SSM is based on the MambaMixer architecture, which is designed to handle multi-variate time signals. We evaluate our model on the NASA battery discharge dataset and show that our model outperforms the state-of-the-art on this dataset. We further introduce a novel anchor-based resampling method which ensures time signals are of the expected length while also serving as augmentation technique. Finally, we condition prediction on the sample time and the cycle time difference using positional encodings to improve the performance of our model and to learn recuperation effects. Our results proof that our model is able to predict the SOH of Li-ion batteries with high accuracy and robustness.</li>
</ul>

<h3>Title: ResiDual Transformer Alignment with Spectral Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Basile, Valentino Maiorca, Luca Bortolussi, Emanuele Rodolà, Francesco Locatello</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00246">https://arxiv.org/abs/2411.00246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00246">https://arxiv.org/pdf/2411.00246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00246]] ResiDual Transformer Alignment with Spectral Decomposition(https://arxiv.org/abs/2411.00246)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>When examined through the lens of their residual streams, a puzzling property emerges in transformer networks: residual contributions (e.g., attention heads) sometimes specialize in specific tasks or input attributes. In this paper, we analyze this phenomenon in vision transformers, focusing on the spectral geometry of residuals, and explore its implications for modality alignment in vision-language models. First, we link it to the intrinsically low-dimensional structure of visual head representations, zooming into their principal components and showing that they encode specialized roles across a wide variety of input data distributions. Then, we analyze the effect of head specialization in multimodal models, focusing on how improved alignment between text and specialized heads impacts zero-shot classification performance. This specialization-performance link consistently holds across diverse pre-training data, network sizes, and objectives, demonstrating a powerful new mechanism for boosting zero-shot classification through targeted alignment. Ultimately, we translate these insights into actionable terms by introducing ResiDual, a technique for spectral alignment of the residual stream. Much like panning for gold, it lets the noise from irrelevant unit principal components (i.e., attributes) wash away to amplify task-relevant ones. Remarkably, this dual perspective on modality alignment yields fine-tuning level performances on different data distributions while modeling an extremely interpretable and parameter-efficient transformation, as we extensively show on more than 50 (pre-trained network, dataset) pairs.</li>
</ul>

<h3>Title: A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Yubin Kim, Chanwoo Park, Hyewon Jeong, Cristina Grau-Vilchez, Yik Siu Chan, Xuhai Xu, Daniel McDuff, Hyeonhoon Lee, Marzyeh Ghassemi, Cynthia Breazeal, Hae Won Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00248">https://arxiv.org/abs/2411.00248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00248">https://arxiv.org/pdf/2411.00248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00248]] A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making(https://arxiv.org/abs/2411.00248)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Medical Decision-Making (MDM) is a multi-faceted process that requires clinicians to assess complex multi-modal patient data patient, often collaboratively. Large Language Models (LLMs) promise to streamline this process by synthesizing vast medical knowledge and multi-modal health data. However, single-agent are often ill-suited for nuanced medical contexts requiring adaptable, collaborative problem-solving. Our MDAgents addresses this need by dynamically assigning collaboration structures to LLMs based on task complexity, mimicking real-world clinical collaboration and decision-making. This framework improves diagnostic accuracy and supports adaptive responses in complex, real-world medical scenarios, making it a valuable tool for clinicians in various healthcare settings, and at the same time, being more efficient in terms of computing cost than static multi-agent decision making methods.</li>
</ul>

<h3>Title: IO Transformer: Evaluating SwinV2-Based Reward Models for Computer Vision</h3>
<ul>
<li><strong>Authors: </strong>Maxwell Meyer, Jack Spruyt</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00252">https://arxiv.org/abs/2411.00252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00252">https://arxiv.org/pdf/2411.00252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00252]] IO Transformer: Evaluating SwinV2-Based Reward Models for Computer Vision(https://arxiv.org/abs/2411.00252)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Transformers and their derivatives have achieved state-of-the-art performance across text, vision, and speech recognition tasks. However, minimal effort has been made to train transformers capable of evaluating the output quality of other models. This paper examines SwinV2-based reward models, called the Input-Output Transformer (IO Transformer) and the Output Transformer. These reward models can be leveraged for tasks such as inference quality evaluation, data categorization, and policy optimization. Our experiments demonstrate highly accurate model output quality assessment across domains where the output is entirely dependent on the input, with the IO Transformer achieving perfect evaluation accuracy on the Change Dataset 25 (CD25). We also explore modified Swin V2 architectures. Ultimately Swin V2 remains on top with a score of 95.41 % on the IO Segmentation Dataset, outperforming the IO Transformer in scenarios where the output is not entirely dependent on the input. Our work expands the application of transformer architectures to reward modeling in computer vision and provides critical insights into optimizing these models for various tasks.</li>
</ul>

<h3>Title: Pipe-Cleaner: Flexible Fuzzing Using Security Policies</h3>
<ul>
<li><strong>Authors: </strong>Allison Naaktgeboren, Sean Noble Anderson, Andrew Tolmach, Greg Sullivan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00261">https://arxiv.org/abs/2411.00261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00261">https://arxiv.org/pdf/2411.00261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00261]] Pipe-Cleaner: Flexible Fuzzing Using Security Policies(https://arxiv.org/abs/2411.00261)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Fuzzing has proven to be very effective for discovering certain classes of software flaws, but less effective in helping developers process these discoveries. Conventional crash-based fuzzers lack enough information about failures to determine their root causes, or to differentiate between new or known crashes, forcing developers to manually process long, repetitious lists of crash reports. Also, conventional fuzzers typically cannot be configured to detect the variety of bugs developers care about, many of which are not easily converted into crashes. To address these limitations, we propose Pipe-Cleaner, a system for detecting and analyzing C code vulnerabilities using a refined fuzzing approach. Pipe-Cleaner is based on flexible developer-designed security policies enforced by a tag-based runtime reference monitor, which communicates with a policy-aware fuzzer. Developers are able to customize the types of faults the fuzzer detects and the level of detail in fault reports. Adding more detail helps the fuzzer to differentiate new bugs, discard duplicate bugs, and improve the clarity of results for bug triage. We demonstrate the potential of this approach on several heap-related security vulnerabilities, including classic memory safety violations and two novel non-crashing classes outside the reach of conventional fuzzers: leftover secret disclosure, and heap address leaks.</li>
</ul>

<h3>Title: Space for Improvement: Navigating the Design Space for Federated Learning in Satellite Constellations</h3>
<ul>
<li><strong>Authors: </strong>Grace Kim, Luca Powell, Filip Svoboda, Nicholas Lane</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00263">https://arxiv.org/abs/2411.00263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00263">https://arxiv.org/pdf/2411.00263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00263]] Space for Improvement: Navigating the Design Space for Federated Learning in Satellite Constellations(https://arxiv.org/abs/2411.00263)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Space has emerged as an exciting new application area for machine learning, with several missions equipping deep learning capabilities on-board spacecraft. Pre-processing satellite data through on-board training is necessary to address the satellite downlink deficit, as not enough transmission opportunities are available to match the high rates of data generation. To scale this effort across entire constellations, collaborated training in orbit has been enabled through federated learning (FL). While current explorations of FL in this context have successfully adapted FL algorithms for scenario-specific constraints, these theoretical FL implementations face several limitations that prevent progress towards real-world deployment. To address this gap, we provide a holistic exploration of the FL in space domain on several fronts. 1) We develop a method for space-ification of existing FL algorithms, evaluated on 2) FLySTacK, our novel satellite constellation design and hardware aware testing platform where we perform rigorous algorithm evaluations. Finally we introduce 3) AutoFLSat, a generalized, hierarchical, autonomous FL algorithm for space that provides a 12.5% to 37.5% reduction in model training time than leading alternatives.</li>
</ul>

<h3>Title: Unsupervised Feature Selection Algorithm Based on Graph Filtering and Self-representation</h3>
<ul>
<li><strong>Authors: </strong>Yunhui Liang, Jianwen Gan, Yan Chen, Peng Zhou, Liang Du</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00270">https://arxiv.org/abs/2411.00270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00270">https://arxiv.org/pdf/2411.00270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00270]] Unsupervised Feature Selection Algorithm Based on Graph Filtering and Self-representation(https://arxiv.org/abs/2411.00270)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Aiming at the problem that existing methods could not fully capture the intrinsic structure of data without considering the higher-order neighborhood information of the data, we proposed an unsupervised feature selection algorithm based on graph filtering and self-representation. Firstly,a higher-order graph filter was applied to the data to obtain its smooth representation,and a regularizer was designed to combine the higher-order graph information for the self-representation matrix learning to capture the intrinsic structure of the data. Secondly,l2,1 norm was used to reconstruct the error term and feature selection matrix to enhance the robustness and row sparsity of the model to select the discriminant features. Finally, an iterative algorithm was applied to effectively solve the proposed objective function and simulation experiments were carried out to verify the effectiveness of the proposed algorithm.</li>
</ul>

<h3>Title: Efficient Model Compression for Bayesian Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Diptarka Saha, Zihe Liu, Feng Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00273">https://arxiv.org/abs/2411.00273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00273">https://arxiv.org/pdf/2411.00273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00273]] Efficient Model Compression for Bayesian Neural Networks(https://arxiv.org/abs/2411.00273)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Model Compression has drawn much attention within the deep learning community recently. Compressing a dense neural network offers many advantages including lower computation cost, deployability to devices of limited storage and memories, and resistance to adversarial attacks. This may be achieved via weight pruning or fully discarding certain input features. Here we demonstrate a novel strategy to emulate principles of Bayesian model selection in a deep learning setup. Given a fully connected Bayesian neural network with spike-and-slab priors trained via a variational algorithm, we obtain the posterior inclusion probability for every node that typically gets lost. We employ these probabilities for pruning and feature selection on a host of simulated and real-world benchmark data and find evidence of better generalizability of the pruned model in all our experiments.</li>
</ul>

<h3>Title: Adaptive Residual Transformation for Enhanced Feature-Based OOD Detection in SAR Imagery</h3>
<ul>
<li><strong>Authors: </strong>Kyung-hwan Lee, Kyung-tae Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00274">https://arxiv.org/abs/2411.00274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00274">https://arxiv.org/pdf/2411.00274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00274]] Adaptive Residual Transformation for Enhanced Feature-Based OOD Detection in SAR Imagery(https://arxiv.org/abs/2411.00274)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in deep learning architectures have enabled efficient and accurate classification of pre-trained targets in Synthetic Aperture Radar (SAR) images. Nevertheless, the presence of unknown targets in real battlefield scenarios is unavoidable, resulting in misclassification and reducing the accuracy of the classifier. Over the past decades, various feature-based out-of-distribution (OOD) approaches have been developed to address this issue, yet defining the decision boundary between known and unknown targets remains challenging. Additionally, unlike optical images, detecting unknown targets in SAR imagery is further complicated by high speckle noise, the presence of clutter, and the inherent similarities in back-scattered microwave signals. In this work, we propose transforming feature-based OOD detection into a class-localized feature-residual-based approach, demonstrating that this method can improve stability across varying unknown targets' distribution conditions. Transforming feature-based OOD detection into a residual-based framework offers a more robust reference space for distinguishing between in-distribution (ID) and OOD data, particularly within the unique characteristics of SAR imagery. This adaptive residual transformation method standardizes feature-based inputs into distributional representations, enhancing OOD detection in noisy, low-information images. Our approach demonstrates promising performance in real-world SAR scenarios, effectively adapting to the high levels of noise and clutter inherent in these environments. These findings highlight the practical relevance of residual-based OOD detection for SAR applications and suggest a foundation for further advancements in unknown target detection in complex, operational settings.</li>
</ul>

<h3>Title: Detection and tracking of gas plumes in LWIR hyperspectral video sequence data</h3>
<ul>
<li><strong>Authors: </strong>Torin Gerhart, Justin Sunu, Ekaterina Merkurjev, Jen-Mei Chang, Jerome Gilles, Andrea L. Bertozzi</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00281">https://arxiv.org/abs/2411.00281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00281">https://arxiv.org/pdf/2411.00281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00281]] Detection and tracking of gas plumes in LWIR hyperspectral video sequence data(https://arxiv.org/abs/2411.00281)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated detection of chemical plumes presents a segmentation challenge. The segmentation problem for gas plumes is difficult due to the diffusive nature of the cloud. The advantage of considering hyperspectral images in the gas plume detection problem over the conventional RGB imagery is the presence of non-visual data, allowing for a richer representation of information. In this paper we present an effective method of visualizing hyperspectral video sequences containing chemical plumes and investigate the effectiveness of segmentation techniques on these post-processed videos. Our approach uses a combination of dimension reduction and histogram equalization to prepare the hyperspectral videos for segmentation. First, Principal Components Analysis (PCA) is used to reduce the dimension of the entire video sequence. This is done by projecting each pixel onto the first few Principal Components resulting in a type of spectral filter. Next, a Midway method for histogram equalization is used. These methods redistribute the intensity values in order to reduce flicker between frames. This properly prepares these high-dimensional video sequences for more traditional segmentation techniques. We compare the ability of various clustering techniques to properly segment the chemical plume. These include K-means, spectral clustering, and the Ginzburg-Landau functional.</li>
</ul>

<h3>Title: LLM-Ref: Enhancing Reference Handling in Technical Writing with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kazi Ahmed Asif Fuad, Lizhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00294">https://arxiv.org/abs/2411.00294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00294">https://arxiv.org/pdf/2411.00294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00294]] LLM-Ref: Enhancing Reference Handling in Technical Writing with Large Language Models(https://arxiv.org/abs/2411.00294)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in data synthesis but can be inaccurate in domain-specific tasks, which retrieval-augmented generation (RAG) systems address by leveraging user-provided data. However, RAGs require optimization in both retrieval and generation stages, which can affect output quality. In this paper, we present LLM-Ref, a writing assistant tool that aids researchers in writing articles from multiple source documents with enhanced reference synthesis and handling capabilities. Unlike traditional RAG systems that use chunking and indexing, our tool retrieves and generates content directly from text paragraphs. This method facilitates direct reference extraction from the generated outputs, a feature unique to our tool. Additionally, our tool employs iterative response generation, effectively managing lengthy contexts within the language model's constraints. Compared to baseline RAG-based systems, our approach achieves a $3.25\times$ to $6.26\times$ increase in Ragas score, a comprehensive metric that provides a holistic view of a RAG system's ability to produce accurate, relevant, and contextually appropriate responses. This improvement shows our method enhances the accuracy and contextual relevance of writing assistance tools.</li>
</ul>

<h3>Title: RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sraavya Sambara (1), Serena Zhang (2), Oishi Banerjee (1), Julian Acosta (1), John Fahrner (1), Pranav Rajpurkar (1) ((1) Harvard University, (2) Stanford University)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00299">https://arxiv.org/abs/2411.00299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00299">https://arxiv.org/pdf/2411.00299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00299]] RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models(https://arxiv.org/abs/2411.00299)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Generating accurate radiology reports from medical images is a clinically important but challenging task. While current Vision Language Models (VLMs) show promise, they are prone to generating hallucinations, potentially compromising patient care. We introduce RadFlag, a black-box method to enhance the accuracy of radiology report generation. Our method uses a sampling-based flagging technique to find hallucinatory generations that should be removed. We first sample multiple reports at varying temperatures and then use a Large Language Model (LLM) to identify claims that are not consistently supported across samples, indicating that the model has low confidence in those claims. Using a calibrated threshold, we flag a fraction of these claims as likely hallucinations, which should undergo extra review or be automatically rejected. Our method achieves high precision when identifying both individual hallucinatory sentences and reports that contain hallucinations. As an easy-to-use, black-box system that only requires access to a model's temperature parameter, RadFlag is compatible with a wide range of radiology report generation models and has the potential to broadly improve the quality of automated radiology reporting.</li>
</ul>

<h3>Title: Rationale-Guided Retrieval Augmented Generation for Medical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Jiwoong Sohn, Yein Park, Chanwoong Yoon, Sihyeon Park, Hyeon Hwang, Mujeen Sung, Hyunjae Kim, Jaewoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00300">https://arxiv.org/abs/2411.00300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00300">https://arxiv.org/pdf/2411.00300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00300]] Rationale-Guided Retrieval Augmented Generation for Medical Question Answering(https://arxiv.org/abs/2411.00300)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLM) hold significant potential for applications in biomedicine, but they struggle with hallucinations and outdated knowledge. While retrieval-augmented generation (RAG) is generally employed to address these issues, it also has its own set of challenges: (1) LLMs are vulnerable to irrelevant or incorrect context, (2) medical queries are often not well-targeted for helpful information, and (3) retrievers are prone to bias toward the specific source corpus they were trained on. In this study, we present RAG$^2$ (RAtionale-Guided RAG), a new framework for enhancing the reliability of RAG in biomedical contexts. RAG$^2$ incorporates three key innovations: a small filtering model trained on perplexity-based labels of rationales, which selectively augments informative snippets of documents while filtering out distractors; LLM-generated rationales as queries to improve the utility of retrieved snippets; a structure designed to retrieve snippets evenly from a comprehensive set of four biomedical corpora, effectively mitigating retriever bias. Our experiments demonstrate that RAG$^2$ improves the state-of-the-art LLMs of varying sizes, with improvements of up to 6.1\%, and it outperforms the previous best medical RAG model by up to 5.6\% across three medical question-answering benchmarks. Our code is available at this https URL.</li>
</ul>

<h3>Title: Unified Generative and Discriminative Training for Multi-modal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wei Chow, Juncheng Li, Qifan Yu, Kaihang Pan, Hao Fei, Zhiqi Ge, Shuai Yang, Siliang Tang, Hanwang Zhang, Qianru Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00304">https://arxiv.org/abs/2411.00304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00304">https://arxiv.org/pdf/2411.00304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00304]] Unified Generative and Discriminative Training for Multi-modal Large Language Models(https://arxiv.org/abs/2411.00304)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In recent times, Vision-Language Models (VLMs) have been trained under two predominant paradigms. Generative training has enabled Multimodal Large Language Models (MLLMs) to tackle various complex tasks, yet issues such as hallucinations and weak object discrimination persist. Discriminative training, exemplified by models like CLIP, excels in zero-shot image-text classification and retrieval, yet struggles with complex scenarios requiring fine-grained semantic differentiation. This paper addresses these challenges by proposing a unified approach that integrates the strengths of both paradigms. Considering interleaved image-text sequences as the general format of input samples, we introduce a structure-induced training strategy that imposes semantic relationships between input samples and the MLLM's hidden state. This approach enhances the MLLM's ability to capture global semantics and distinguish fine-grained semantics. By leveraging dynamic sequence alignment within the Dynamic Time Warping framework and integrating a novel kernel for fine-grained semantic differentiation, our method effectively balances generative and discriminative tasks. Extensive experiments demonstrate the effectiveness of our approach, achieving state-of-the-art results in multiple generative tasks, especially those requiring cognitive and discrimination abilities. Additionally, our method surpasses discriminative benchmarks in interleaved and fine-grained retrieval tasks. By employing a retrieval-augmented generation strategy, our approach further enhances performance in some generative tasks within one model, offering a promising direction for future research in vision-language modeling.</li>
</ul>

<h3>Title: C2A: Client-Customized Adaptation for Parameter-Efficient Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yeachan Kim, Junho Kim, Wing-Lam Mok, Jun-Hyung Park, SangKeun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00311">https://arxiv.org/abs/2411.00311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00311">https://arxiv.org/pdf/2411.00311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00311]] C2A: Client-Customized Adaptation for Parameter-Efficient Federated Learning(https://arxiv.org/abs/2411.00311)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Despite the versatility of pre-trained language models (PLMs) across domains, their large memory footprints pose significant challenges in federated learning (FL), where the training model has to be distributed between a server and clients. One potential solution to bypass such constraints might be the use of parameter-efficient fine-tuning (PEFT) in the context of FL. However, we have observed that typical PEFT tends to severely suffer from heterogeneity among clients in FL scenarios, resulting in unstable and slow convergence. In this paper, we propose Client-Customized Adaptation (C2A), a novel hypernetwork-based FL framework that generates client-specific adapters by conditioning the client information. With the effectiveness of the hypernetworks in generating customized weights through learning to adopt the different characteristics of inputs, C2A can maximize the utility of shared model parameters while minimizing the divergence caused by client heterogeneity. To verify the efficacy of C2A, we perform extensive evaluations on FL scenarios involving heterogeneity in label and language distributions. Comprehensive evaluation results clearly support the superiority of C2A in terms of both efficiency and effectiveness in FL scenarios.</li>
</ul>

<h3>Title: Personalized Federated Learning via Feature Distribution Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Connor J. Mclaughlin, Lili Su</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00329">https://arxiv.org/abs/2411.00329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00329">https://arxiv.org/pdf/2411.00329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00329]] Personalized Federated Learning via Feature Distribution Adaptation(https://arxiv.org/abs/2411.00329)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, generative</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a distributed learning framework that leverages commonalities between distributed client datasets to train a global model. Under heterogeneous clients, however, FL can fail to produce stable training results. Personalized federated learning (PFL) seeks to address this by learning individual models tailored to each client. One approach is to decompose model training into shared representation learning and personalized classifier training. Nonetheless, previous works struggle to navigate the bias-variance trade-off in classifier learning, relying solely on limited local datasets or introducing costly techniques to improve generalization. In this work, we frame representation learning as a generative modeling task, where representations are trained with a classifier based on the global feature distribution. We then propose an algorithm, pFedFDA, that efficiently generates personalized models by adapting global generative classifiers to their local feature distributions. Through extensive computer vision benchmarks, we demonstrate that our method can adjust to complex distribution shifts with significant improvements over current state-of-the-art in data-scarce settings.</li>
</ul>

<h3>Title: Multiple Information Prompt Learning for Cloth-Changing Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Shengxun Wei, Zan Gao, Yibo Zhao, Weili Guan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00330">https://arxiv.org/abs/2411.00330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00330">https://arxiv.org/pdf/2411.00330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00330]] Multiple Information Prompt Learning for Cloth-Changing Person Re-Identification(https://arxiv.org/abs/2411.00330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cloth-changing person re-identification is a subject closer to the real world, which focuses on solving the problem of person re-identification after pedestrians change clothes. The primary challenge in this field is to overcome the complex interplay between intra-class and inter-class variations and to identify features that remain unaffected by changes in appearance. Sufficient data collection for model training would significantly aid in addressing this problem. However, it is challenging to gather diverse datasets in practice. Current methods focus on implicitly learning identity information from the original image or introducing additional auxiliary models, which are largely limited by the quality of the image and the performance of the additional model. To address these issues, inspired by prompt learning, we propose a novel multiple information prompt learning (MIPL) scheme for cloth-changing person ReID, which learns identity robust features through the common prompt guidance of multiple messages. Specifically, the clothing information stripping (CIS) module is designed to decouple the clothing information from the original RGB image features to counteract the influence of clothing appearance. The Bio-guided attention (BGA) module is proposed to increase the learning intensity of the model for key information. A dual-length hybrid patch (DHP) module is employed to make the features have diverse coverage to minimize the impact of feature bias. Extensive experiments demonstrate that the proposed method outperforms all state-of-the-art methods on the LTCC, Celeb-reID, Celeb-reID-light, and CSCC datasets, achieving rank-1 scores of 74.8%, 73.3%, 66.0%, and 88.1%, respectively. When compared to AIM (CVPR23), ACID (TIP23), and SCNet (MM23), MIPL achieves rank-1 improvements of 11.3%, 13.8%, and 7.9%, respectively, on the PRCC dataset.</li>
</ul>

<h3>Title: GAFusion: Adaptive Fusing LiDAR and Camera with Multiple Guidance for 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xiaotian Li, Baojie Fan, Jiandong Tian, Huijie Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00340">https://arxiv.org/abs/2411.00340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00340">https://arxiv.org/pdf/2411.00340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00340]] GAFusion: Adaptive Fusing LiDAR and Camera with Multiple Guidance for 3D Object Detection(https://arxiv.org/abs/2411.00340)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent years have witnessed the remarkable progress of 3D multi-modality object detection methods based on the Bird's-Eye-View (BEV) perspective. However, most of them overlook the complementary interaction and guidance between LiDAR and camera. In this work, we propose a novel multi-modality 3D objection detection method, named GAFusion, with LiDAR-guided global interaction and adaptive fusion. Specifically, we introduce sparse depth guidance (SDG) and LiDAR occupancy guidance (LOG) to generate 3D features with sufficient depth information. In the following, LiDAR-guided adaptive fusion transformer (LGAFT) is developed to adaptively enhance the interaction of different modal BEV features from a global perspective. Meanwhile, additional downsampling with sparse height compression and multi-scale dual-path transformer (MSDPT) are designed to enlarge the receptive fields of different modal features. Finally, a temporal fusion module is introduced to aggregate features from previous frames. GAFusion achieves state-of-the-art 3D object detection results with 73.6$\%$ mAP and 74.9$\%$ NDS on the nuScenes test set.</li>
</ul>

<h3>Title: Attention Tracker: Detecting Prompt Injection Attacks in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Kuo-Han Hung, Ching-Yun Ko, Ambrish Rawat, I-Hsin Chung, Winston H. Hsu, Pin-Yu Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00348">https://arxiv.org/abs/2411.00348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00348">https://arxiv.org/pdf/2411.00348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00348]] Attention Tracker: Detecting Prompt Injection Attacks in LLMs(https://arxiv.org/abs/2411.00348)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized various domains but remain vulnerable to prompt injection attacks, where malicious inputs manipulate the model into ignoring original instructions and executing designated action. In this paper, we investigate the underlying mechanisms of these attacks by analyzing the attention patterns within LLMs. We introduce the concept of the distraction effect, where specific attention heads, termed important heads, shift focus from the original instruction to the injected instruction. Building on this discovery, we propose Attention Tracker, a training-free detection method that tracks attention patterns on instruction to detect prompt injection attacks without the need for additional LLM inference. Our method generalizes effectively across diverse models, datasets, and attack types, showing an AUROC improvement of up to 10.0% over existing methods, and performs well even on small LLMs. We demonstrate the robustness of our approach through extensive evaluations and provide insights into safeguarding LLM-integrated systems from prompt injection vulnerabilities.</li>
</ul>

<h3>Title: Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review</h3>
<ul>
<li><strong>Authors: </strong>Dinitha Wijewardhana, Sugandima Vidanagamachchi, Nalin Arachchilage</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00349">https://arxiv.org/abs/2411.00349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00349">https://arxiv.org/pdf/2411.00349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00349]] Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review(https://arxiv.org/abs/2411.00349)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Cryptocurrencies have gained popularity due to their transparency, security, and accessibility compared to traditional financial systems, with Bitcoin, introduced in 2009, leading the market. Bitcoin's security relies on blockchain technology - a decentralized ledger consisting of a consensus and an incentive mechanism. The consensus mechanism, Proof of Work (PoW), requires miners to solve difficult cryptographic puzzles to add new blocks, while the incentive mechanism rewards them with newly minted bitcoins. However, as Bitcoin's acceptance grows, it faces increasing threats from attacks targeting these mechanisms, such as selfish mining, double-spending, and block withholding. These attacks compromise security, efficiency, and reward distribution. Recent research shows that these attacks can be combined with each other or with either malicious strategies, such as network-layer attacks, or non-malicious strategies, like honest mining. These combinations lead to more sophisticated attacks, increasing the attacker's success rates and profitability. Therefore, understanding and evaluating these attacks is essential for developing effective countermeasures and ensuring long-term security. This paper begins by examining individual attacks executed in isolation and their profitability. It then explores how combining these attacks with each other or with other malicious and non-malicious strategies can enhance their overall effectiveness and profitability. The analysis further explores how the deployment of attacks such as selfish mining and block withholding by multiple competing mining pools against each other impacts their economic returns. Lastly, a set of design guidelines is provided, outlining areas future work should focus on to prevent or mitigate the identified threats.</li>
</ul>

<h3>Title: Typosquatting 3.0: Characterizing Squatting in Blockchain Naming Systems</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Muzammil, Zhengyu Wu, Lalith Harisha, Brian Kondracki, Nick Nikiforakis</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00352">https://arxiv.org/abs/2411.00352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00352">https://arxiv.org/pdf/2411.00352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00352]] Typosquatting 3.0: Characterizing Squatting in Blockchain Naming Systems(https://arxiv.org/abs/2411.00352)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack</a></li>
<li><strong>Abstract: </strong>A Blockchain Name System (BNS) simplifies the process of sending cryptocurrencies by replacing complex cryptographic recipient addresses with human-readable names, making the transactions more convenient. Unfortunately, these names can be susceptible to typosquatting attacks, where attackers can take advantage of user typos by registering typographically similar BNS names. Unsuspecting users may accidentally mistype or misinterpret the intended name, resulting in an irreversible transfer of funds to an attacker's address instead of the intended recipient. In this work, we present the first large-scale, intra-BNS typosquatting study. To understand the prevalence of typosquatting within BNSs, we study three different services (Ethereum Name Service, Unstoppable Domains, and ADAHandles) spanning three blockchains (Ethereum, Polygon, and Cardano), collecting a total of 4.9M BNS names and 200M transactions-the largest dataset for BNSs to date. We describe the challenges involved in conducting name-squatting studies on these alternative naming systems, and then perform an in-depth quantitative analysis of our dataset. We find that typosquatters are indeed active on BNSs, registering more malicious domains with each passing year. Our analysis reveals that users have sent thousands of transactions to squatters and that squatters target both globally popular BNS domain names as well as the domains owned by popular Twitter/X users. Lastly, we document the complete lack of defenses against typosquatting in custodial and non-custodial wallets and propose straightforward countermeasures that can protect users without relying on third-party services.</li>
</ul>

<h3>Title: TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images</h3>
<ul>
<li><strong>Authors: </strong>Mengcheng Li, Mingbao Lin, Fei Chao, Chia-Wen Lin, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00355">https://arxiv.org/abs/2411.00355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00355">https://arxiv.org/pdf/2411.00355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00355]] TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images(https://arxiv.org/abs/2411.00355)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, diffusion</a></li>
<li><strong>Abstract: </strong>In this paper, we propose TextDestroyer, the first training- and annotation-free method for scene text destruction using a pre-trained diffusion model. Existing scene text removal models require complex annotation and retraining, and may leave faint yet recognizable text information, compromising privacy protection and content concealment. TextDestroyer addresses these issues by employing a three-stage hierarchical process to obtain accurate text masks. Our method scrambles text areas in the latent start code using a Gaussian distribution before reconstruction. During the diffusion denoising process, self-attention key and value are referenced from the original latent to restore the compromised background. Latent codes saved at each inversion step are used for replacement during reconstruction, ensuring perfect background restoration. The advantages of TextDestroyer include: (1) it eliminates labor-intensive data annotation and resource-intensive training; (2) it achieves more thorough text destruction, preventing recognizable traces; and (3) it demonstrates better generalization capabilities, performing well on both real-world scenes and generated images.</li>
</ul>

<h3>Title: Constrained Diffusion Implicit Models</h3>
<ul>
<li><strong>Authors: </strong>Vivek Jayaram, Ira Kemelmacher-Shlizerman, Steven M. Seitz, John Thickstun</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00359">https://arxiv.org/abs/2411.00359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00359">https://arxiv.org/pdf/2411.00359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00359]] Constrained Diffusion Implicit Models(https://arxiv.org/abs/2411.00359)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper describes an efficient algorithm for solving noisy linear inverse problems using pretrained diffusion models. Extending the paradigm of denoising diffusion implicit models (DDIM), we propose constrained diffusion implicit models (CDIM) that modify the diffusion updates to enforce a constraint upon the final output. For noiseless inverse problems, CDIM exactly satisfies the constraints; in the noisy case, we generalize CDIM to satisfy an exact constraint on the residual distribution of the noise. Experiments across a variety of tasks and metrics show strong performance of CDIM, with analogous inference acceleration to unconstrained DDIM: 10 to 50 times faster than previous conditional diffusion methods. We demonstrate the versatility of our approach on many problems including super-resolution, denoising, inpainting, deblurring, and 3D point cloud reconstruction.</li>
</ul>

<h3>Title: A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective</h3>
<ul>
<li><strong>Authors: </strong>Yeonsung Jung, Jaeyun Song, June Yong Yang, Jin-Hwa Kim, Sung-Yub Kim, Eunho Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00360">https://arxiv.org/abs/2411.00360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00360">https://arxiv.org/pdf/2411.00360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00360]] A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective(https://arxiv.org/abs/2411.00360)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Learning generalized models from biased data is an important undertaking toward fairness in deep learning. To address this issue, recent studies attempt to identify and leverage bias-conflicting samples free from spurious correlations without prior knowledge of bias or an unbiased set. However, spurious correlation remains an ongoing challenge, primarily due to the difficulty in precisely detecting these samples. In this paper, inspired by the similarities between mislabeled samples and bias-conflicting samples, we approach this challenge from a novel perspective of mislabeled sample detection. Specifically, we delve into Influence Function, one of the standard methods for mislabeled sample detection, for identifying bias-conflicting samples and propose a simple yet effective remedy for biased models by leveraging them. Through comprehensive analysis and experiments on diverse datasets, we demonstrate that our new perspective can boost the precision of detection and rectify biased models effectively. Furthermore, our approach is complementary to existing methods, showing performance improvement even when applied to models that have already undergone recent debiasing techniques.</li>
</ul>

<h3>Title: ROSS:RObust decentralized Stochastic learning based on Shapley values</h3>
<ul>
<li><strong>Authors: </strong>Lina Wang, Yunsheng Yuan, Feng Li, Lingjie Duan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00365">https://arxiv.org/abs/2411.00365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00365">https://arxiv.org/pdf/2411.00365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00365]] ROSS:RObust decentralized Stochastic learning based on Shapley values(https://arxiv.org/abs/2411.00365)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the paradigm of decentralized learning, a group of agents collaborate to learn a global model using a distributed dataset without a central server; nevertheless, it is severely challenged by the heterogeneity of the data distribution across the agents. For example, the data may be distributed non-independently and identically, and even be noised or poisoned. To address these data challenges, we propose ROSS, a novel robust decentralized stochastic learning algorithm based on Shapley values, in this paper. Specifically, in each round, each agent aggregates the cross-gradient information from its neighbors, i.e., the derivatives of its local model with respect to the datasets of its neighbors, to update its local model in a momentum like manner, while we innovate in weighting the derivatives according to their contributions measured by Shapley values. We perform solid theoretical analysis to reveal the linear convergence speedup of our ROSS algorithm. We also verify the efficacy of our algorithm through extensive experiments on public datasets. Our results demonstrate that, in face of the above variety of data challenges, our ROSS algorithm have oblivious advantages over existing state-of-the-art proposals in terms of both convergence and prediction accuracy.</li>
</ul>

<h3>Title: A Machine Learning Driven Website Platform and Browser Extension for Real-time Scoring and Fraud Detection for Website Legitimacy Verification and Consumer Protection</h3>
<ul>
<li><strong>Authors: </strong>Md Kamrul Hasan Chy, Obed Nana Buadi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00368">https://arxiv.org/abs/2411.00368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00368">https://arxiv.org/pdf/2411.00368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00368]] A Machine Learning Driven Website Platform and Browser Extension for Real-time Scoring and Fraud Detection for Website Legitimacy Verification and Consumer Protection(https://arxiv.org/abs/2411.00368)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>This paper introduces a Machine Learning-Driven website Platform and Browser Extension designed to quickly enhance online security by providing real-time risk scoring and fraud detection for website legitimacy verification and consumer protection. The platform works seamlessly in the background to analyze website behavior, network traffic, and user interactions, offering immediate feedback and alerts when potential threats are detected. By integrating this system into a user-friendly browser extension, the platform empowers individuals to navigate the web safely, reducing the risk of engaging with fraudulent websites. Its real-time functionality is crucial in e-commerce and everyday browsing, where quick, actionable insights can prevent financial losses, identity theft, and exposure to malicious sites. This paper explores how this solution offers a practical, fast-acting tool for enhancing online consumer protection, underscoring its potential to play a critical role in safeguarding users and maintaining trust in digital transactions. The platform's focus on speed and efficiency makes it an essential asset for preventing fraud in today's increasingly digital world.</li>
</ul>

<h3>Title: GRS-QA -- Graph Reasoning-Structured Question Answering Dataset</h3>
<ul>
<li><strong>Authors: </strong>Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00369">https://arxiv.org/abs/2411.00369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00369">https://arxiv.org/pdf/2411.00369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00369]] GRS-QA -- Graph Reasoning-Structured Question Answering Dataset(https://arxiv.org/abs/2411.00369)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have excelled in multi-hop question-answering (M-QA) due to their advanced reasoning abilities. However, the impact of the inherent reasoning structures on LLM M-QA performance remains unclear, largely due to the absence of QA datasets that provide fine-grained reasoning structures. To address this gap, we introduce the Graph Reasoning-Structured Question Answering Dataset (GRS-QA), which includes both semantic contexts and reasoning structures for QA pairs. Unlike existing M-QA datasets, where different reasoning structures are entangled together, GRS-QA explicitly captures intricate reasoning pathways by constructing reasoning graphs, where nodes represent textual contexts and edges denote logical flows. These reasoning graphs of different structures enable a fine-grained evaluation of LLM reasoning capabilities across various reasoning structures. Our empirical analysis reveals that LLMs perform differently when handling questions with varying reasoning structures. This finding facilitates the exploration of textual structures as compared with semantics.</li>
</ul>

<h3>Title: DeepCore: Simple Fingerprint Construction for Differentiating Homologous and Piracy Models</h3>
<ul>
<li><strong>Authors: </strong>Haifeng Sun, Lan Zhang, Xiang-Yang Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00380">https://arxiv.org/abs/2411.00380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00380">https://arxiv.org/pdf/2411.00380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00380]] DeepCore: Simple Fingerprint Construction for Differentiating Homologous and Piracy Models(https://arxiv.org/abs/2411.00380)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, watermark</a></li>
<li><strong>Abstract: </strong>As intellectual property rights, the copyright protection of deep models is becoming increasingly important. Existing work has made many attempts at model watermarking and fingerprinting, but they have ignored homologous models trained with similar structures or training datasets. We highlight challenges in efficiently querying black-box piracy models to protect model copyrights without misidentifying homologous models. To address these challenges, we propose a novel method called DeepCore, which discovers that the classification confidence of the model is positively correlated with the distance of the predicted sample from the model decision boundary and piracy models behave more similarly at high-confidence classified sample points. Then DeepCore constructs core points far away from the decision boundary by optimizing the predicted confidence of a few sample points and leverages behavioral discrepancies between piracy and homologous models to identify piracy models. Finally, we design different model identification methods, including two similarity-based methods and a clustering-based method to identify piracy models using models' predictions of core points. Extensive experiments show the effectiveness of DeepCore in identifying various piracy models, achieving lower missed and false identification rates, and outperforming state-of-the-art methods.</li>
</ul>

<h3>Title: Communication Learning in Multi-Agent Systems from Graph Modeling Perspective</h3>
<ul>
<li><strong>Authors: </strong>Shengchao Hu, Li Shen, Ya Zhang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00382">https://arxiv.org/abs/2411.00382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00382">https://arxiv.org/pdf/2411.00382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00382]] Communication Learning in Multi-Agent Systems from Graph Modeling Perspective(https://arxiv.org/abs/2411.00382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In numerous artificial intelligence applications, the collaborative efforts of multiple intelligent agents are imperative for the successful attainment of target objectives. To enhance coordination among these agents, a distributed communication framework is often employed. However, indiscriminate information sharing among all agents can be resource-intensive, and the adoption of manually pre-defined communication architectures imposes constraints on inter-agent communication, thus limiting the potential for effective collaboration. Moreover, the communication framework often remains static during inference, which may result in sustained high resource consumption, as in most cases, only key decisions necessitate information sharing among agents. In this study, we introduce a novel approach wherein we conceptualize the communication architecture among agents as a learnable graph. We formulate this problem as the task of determining the communication graph while enabling the architecture parameters to update normally, thus necessitating a bi-level optimization process. Utilizing continuous relaxation of the graph representation and incorporating attention units, our proposed approach, CommFormer, efficiently optimizes the communication graph and concurrently refines architectural parameters through gradient descent in an end-to-end manner. Additionally, we introduce a temporal gating mechanism for each agent, enabling dynamic decisions on whether to receive shared information at a given time, based on current observations, thus improving decision-making efficiency. Extensive experiments on a variety of cooperative tasks substantiate the robustness of our model across diverse cooperative scenarios, where agents are able to develop more coordinated and sophisticated strategies regardless of changes in the number of agents.</li>
</ul>

<h3>Title: STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing</h3>
<ul>
<li><strong>Authors: </strong>Jiaru Zou, Qing Wang, Pratyush Thakur, Nickvash Kani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00387">https://arxiv.org/abs/2411.00387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00387">https://arxiv.org/pdf/2411.00387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00387]] STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing(https://arxiv.org/abs/2411.00387)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Advances in large language models (LLMs) have spurred research into enhancing their reasoning capabilities, particularly in math-rich STEM documents. While LLMs can generate equations or solve math-related queries, their ability to fully understand and interpret abstract mathematical symbols in long, math-rich documents remains limited. In this paper, we introduce STEM-PoM, a comprehensive benchmark dataset designed to evaluate LLMs' reasoning abilities on math symbols within contextual scientific text. The dataset, sourced from real-world ArXiv documents, contains over 2K math symbols classified as main attributes of variables, constants, operators, and unit descriptors, with additional sub-attributes including scalar/vector/matrix for variables and local/global/discipline-specific labels for both constants and operators. Our extensive experiments show that state-of-the-art LLMs achieve an average of 20-60% accuracy under in-context learning and 50-60% accuracy with fine-tuning, revealing a significant gap in their mathematical reasoning capabilities. STEM-PoM fuels future research of developing advanced Math-AI models that can robustly handle math symbols.</li>
</ul>

<h3>Title: Preventing Dimensional Collapse in Self-Supervised Learning via Orthogonality Regularization</h3>
<ul>
<li><strong>Authors: </strong>Junlin He, Jinxiao Du, Wei Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00392">https://arxiv.org/abs/2411.00392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00392">https://arxiv.org/pdf/2411.00392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00392]] Preventing Dimensional Collapse in Self-Supervised Learning via Orthogonality Regularization(https://arxiv.org/abs/2411.00392)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Self-supervised learning (SSL) has rapidly advanced in recent years, approaching the performance of its supervised counterparts through the extraction of representations from unlabeled data. However, dimensional collapse, where a few large eigenvalues dominate the eigenspace, poses a significant obstacle for SSL. When dimensional collapse occurs on features (e.g. hidden features and representations), it prevents features from representing the full information of the data; when dimensional collapse occurs on weight matrices, their filters are self-related and redundant, limiting their expressive power. Existing studies have predominantly concentrated on the dimensional collapse of representations, neglecting whether this can sufficiently prevent the dimensional collapse of the weight matrices and hidden features. To this end, we first time propose a mitigation approach employing orthogonal regularization (OR) across the encoder, targeting both convolutional and linear layers during pretraining. OR promotes orthogonality within weight matrices, thus safeguarding against the dimensional collapse of weight matrices, hidden features, and representations. Our empirical investigations demonstrate that OR significantly enhances the performance of SSL methods across diverse benchmarks, yielding consistent gains with both CNNs and Transformer-based architectures.</li>
</ul>

<h3>Title: Advantages of Neural Population Coding for Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Heiko Hoffmann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00393">https://arxiv.org/abs/2411.00393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00393">https://arxiv.org/pdf/2411.00393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00393]] Advantages of Neural Population Coding for Deep Learning(https://arxiv.org/abs/2411.00393)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Scalar variables, e.g., the orientation of a shape in an image, are commonly predicted using a single output neuron in a neural network. In contrast, the mammalian cortex represents variables with a population of neurons. In this population code, each neuron is most active at its preferred value and shows partial activity for other values. Here, we investigate the benefit of using a population code for the output layer of a neural network. We compare population codes against single-neuron outputs and one-hot vectors. First, we show theoretically and in experiments with synthetic data that population codes improve robustness to input noise in networks of stacked linear layers. Second, we demonstrate the benefit of population codes to encode ambiguous outputs, as found for symmetric objects. Using the T-LESS dataset of feature-less real-world objects, we show that population codes improve the accuracy of predicting object orientation from RGB-image input.</li>
</ul>

<h3>Title: StyleTex: Style Image-Guided Texture Generation for 3D Models</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Xie, Yuqing Zhang, Xiangjun Tang, Yiqian Wu, Dehan Chen, Gongsheng Li, Xaogang Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00399">https://arxiv.org/abs/2411.00399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00399">https://arxiv.org/pdf/2411.00399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00399]] StyleTex: Style Image-Guided Texture Generation for 3D Models(https://arxiv.org/abs/2411.00399)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Style-guided texture generation aims to generate a texture that is harmonious with both the style of the reference image and the geometry of the input mesh, given a reference style image and a 3D mesh with its text description. Although diffusion-based 3D texture generation methods, such as distillation sampling, have numerous promising applications in stylized games and films, it requires addressing two challenges: 1) decouple style and content completely from the reference image for 3D models, and 2) align the generated texture with the color tone, style of the reference image, and the given text prompt. To this end, we introduce StyleTex, an innovative diffusion-model-based framework for creating stylized textures for 3D models. Our key insight is to decouple style information from the reference image while disregarding content in diffusion-based distillation sampling. Specifically, given a reference image, we first decompose its style feature from the image CLIP embedding by subtracting the embedding's orthogonal projection in the direction of the content feature, which is represented by a text CLIP embedding. Our novel approach to disentangling the reference image's style and content information allows us to generate distinct style and content features. We then inject the style feature into the cross-attention mechanism to incorporate it into the generation process, while utilizing the content feature as a negative prompt to further dissociate content information. Finally, we incorporate these strategies into StyleTex to obtain stylized textures. The resulting textures generated by StyleTex retain the style of the reference image, while also aligning with the text prompts and intrinsic details of the given 3D mesh. Quantitative and qualitative experiments show that our method outperforms existing baseline methods by a significant margin.</li>
</ul>

<h3>Title: Improving Viewpoint-Independent Object-Centric Representations through Active Viewpoint Selection</h3>
<ul>
<li><strong>Authors: </strong>Yinxuan Huang, Chengmin Gao, Bin Li, Xiangyang Xue</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00402">https://arxiv.org/abs/2411.00402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00402">https://arxiv.org/pdf/2411.00402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00402]] Improving Viewpoint-Independent Object-Centric Representations through Active Viewpoint Selection(https://arxiv.org/abs/2411.00402)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Given the complexities inherent in visual scenes, such as object occlusion, a comprehensive understanding often requires observation from multiple viewpoints. Existing multi-viewpoint object-centric learning methods typically employ random or sequential viewpoint selection strategies. While applicable across various scenes, these strategies may not always be ideal, as certain scenes could benefit more from specific viewpoints. To address this limitation, we propose a novel active viewpoint selection strategy. This strategy predicts images from unknown viewpoints based on information from observation images for each scene. It then compares the object-centric representations extracted from both viewpoints and selects the unknown viewpoint with the largest disparity, indicating the greatest gain in information, as the next observation viewpoint. Through experiments on various datasets, we demonstrate the effectiveness of our active viewpoint selection strategy, significantly enhancing segmentation and reconstruction performance compared to random viewpoint selection. Moreover, our method can accurately predict images from unknown viewpoints.</li>
</ul>

<h3>Title: Towards Building Secure UAV Navigation with FHE-aware Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Arjun Ramesh Kaushik, Charanjit Jutla, Nalini Ratha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00403">https://arxiv.org/abs/2411.00403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00403">https://arxiv.org/pdf/2411.00403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00403]] Towards Building Secure UAV Navigation with FHE-aware Knowledge Distillation(https://arxiv.org/abs/2411.00403)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>In safeguarding mission-critical systems, such as Unmanned Aerial Vehicles (UAVs), preserving the privacy of path trajectories during navigation is paramount. While the combination of Reinforcement Learning (RL) and Fully Homomorphic Encryption (FHE) holds promise, the computational overhead of FHE presents a significant challenge. This paper proposes an innovative approach that leverages Knowledge Distillation to enhance the practicality of secure UAV navigation. By integrating RL and FHE, our framework addresses vulnerabilities to adversarial attacks while enabling real-time processing of encrypted UAV camera feeds, ensuring data security. To mitigate FHE's latency, Knowledge Distillation is employed to compress the network, resulting in an impressive 18x speedup without compromising performance, as evidenced by an R-squared score of 0.9499 compared to the original model's score of 0.9631. Our methodology underscores the feasibility of processing encrypted data for UAV navigation tasks, emphasizing security alongside performance efficiency and timely processing. These findings pave the way for deploying autonomous UAVs in sensitive environments, bolstering their resilience against potential security threats.</li>
</ul>

<h3>Title: MoD: A Distribution-Based Approach for Merging Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Quy-Anh Dang, Chris Ngo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00406">https://arxiv.org/abs/2411.00406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00406">https://arxiv.org/pdf/2411.00406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00406]] MoD: A Distribution-Based Approach for Merging Large Language Models(https://arxiv.org/abs/2411.00406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have enabled the development of numerous specialized, task-specific variants. However, the maintenance and deployment of these individual models present substantial challenges in terms of resource utilization and operational efficiency. In this work, we propose the \textit{Mixture of Distributions (MoD)} framework, a novel approach for merging LLMs that operates directly on their output probability distributions, rather than on model weights. Unlike traditional weight-averaging methods, MoD effectively preserves the specialized capabilities of individual models while enabling efficient knowledge sharing across tasks. Through extensive experimentation on mathematical reasoning benchmarks using Qwen2.5 models, we demonstrate that MoD significantly outperforms existing model merging techniques across multiple benchmarks. All code, data, and experimental materials are published at this https URL.</li>
</ul>

<h3>Title: Enhancing Authorship Attribution through Embedding Fusion: A Novel Approach with Masked and Encoder-Decoder Language Models</h3>
<ul>
<li><strong>Authors: </strong>Arjun Ramesh Kaushik, Sunil Rufus R P, Nalini Ratha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00411">https://arxiv.org/abs/2411.00411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00411">https://arxiv.org/pdf/2411.00411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00411]] Enhancing Authorship Attribution through Embedding Fusion: A Novel Approach with Masked and Encoder-Decoder Language Models(https://arxiv.org/abs/2411.00411)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The increasing prevalence of AI-generated content alongside human-written text underscores the need for reliable discrimination methods. To address this challenge, we propose a novel framework with textual embeddings from Pre-trained Language Models (PLMs) to distinguish AI-generated and human-authored text. Our approach utilizes Embedding Fusion to integrate semantic information from multiple Language Models, harnessing their complementary strengths to enhance performance. Through extensive evaluation across publicly available diverse datasets, our proposed approach demonstrates strong performance, achieving classification accuracy greater than 96% and a Matthews Correlation Coefficient (MCC) greater than 0.93. This evaluation is conducted on a balanced dataset of texts generated from five well-known Large Language Models (LLMs), highlighting the effectiveness and robustness of our novel methodology.</li>
</ul>

<h3>Title: Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Bohan Lyu, Yadi Cao, Duncan Watson-Parris, Leon Bergen, Taylor Berg-Kirkpatrick, Rose Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00412">https://arxiv.org/abs/2411.00412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00412">https://arxiv.org/pdf/2411.00412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00412]] Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation(https://arxiv.org/abs/2411.00412)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate promising capabilities in solving simple scientific problems but often produce hallucinations for complex ones. While integrating LLMs with tools can increase reliability, this approach typically results in over-reliance on tools, diminishing the model's ability to solve simple problems through basic reasoning. In contrast, human experts first assess problem complexity using domain knowledge before choosing an appropriate solution approach. Inspired by this human problem-solving process, we propose a novel two-component fine-tuning method. In the first component World Knowledge Distillation (WKD), LLMs learn directly from solutions generated using tool's information to internalize domain knowledge. In the second component Tool Usage Adaptation (TUA), we partition problems into easy and hard categories based on the model's direct answering accuracy. While maintaining the same alignment target for easy problems as in WKD, we train the model to intelligently switch to tool usage for more challenging problems. We validate our method on six scientific benchmark datasets, spanning mathematics, climate science and epidemiology. On average, our models demonstrate a 28.18% improvement in answer accuracy and a 13.89% increase in tool usage precision across all datasets, surpassing state-of-the-art models including GPT-4o and Claude-3.5.</li>
</ul>

<h3>Title: Self-Evolved Reward Learning for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chenghua Huang, Zhizhen Fan, Lu Wang, Fangkai Yang, Pu Zhao, Zeqi Lin, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00418">https://arxiv.org/abs/2411.00418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00418">https://arxiv.org/pdf/2411.00418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00418]] Self-Evolved Reward Learning for LLMs(https://arxiv.org/abs/2411.00418)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for aligning language models with human preferences, playing a pivotal role in the success of conversational models like GPT-4, ChatGPT, and Llama 2. A core challenge in employing RLHF lies in training a reliable reward model (RM), which relies on high-quality labels typically provided by human experts or advanced AI system. These methods can be costly and may introduce biases that affect the language model's responses. As language models improve, human input may become less effective in further enhancing their performance. In this paper, we propose Self-Evolved Reward Learning (SER), a novel approach where the RM generates additional training data to iteratively improve itself. We conducted extensive experiments on multiple datasets such as HH-RLHF and UltraFeedback, using models like Mistral and Llama 3, and compare SER against various baselines. Our results demonstrate that even with limited human-annotated data, learning from self-feedback can robustly enhance RM performance, thereby boosting the capabilities of large language models (LLMs).</li>
</ul>

<h3>Title: Cityscape-Adverse: Benchmarking Robustness of Semantic Segmentation with Realistic Scene Modifications via Diffusion-Based Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Naufal Suryanto, Andro Aprila Adiputra, Ahmada Yusril Kadiptya, Thi-Thu-Huong Le, Derry Pratama, Yongsu Kim, Howon Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00425">https://arxiv.org/abs/2411.00425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00425">https://arxiv.org/pdf/2411.00425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00425]] Cityscape-Adverse: Benchmarking Robustness of Semantic Segmentation with Realistic Scene Modifications via Diffusion-Based Image Editing(https://arxiv.org/abs/2411.00425)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in generative AI, particularly diffusion-based image editing, have enabled the transformation of images into highly realistic scenes using only text instructions. This technology offers significant potential for generating diverse synthetic datasets to evaluate model robustness. In this paper, we introduce Cityscape-Adverse, a benchmark that employs diffusion-based image editing to simulate eight adverse conditions, including variations in weather, lighting, and seasons, while preserving the original semantic labels. We evaluate the reliability of diffusion-based models in generating realistic scene modifications and assess the performance of state-of-the-art CNN and Transformer-based semantic segmentation models under these challenging conditions. Additionally, we analyze which modifications have the greatest impact on model performance and explore how training on synthetic datasets can improve robustness in real-world adverse scenarios. Our results demonstrate that all tested models, particularly CNN-based architectures, experienced significant performance degradation under extreme conditions, while Transformer-based models exhibited greater resilience. We verify that models trained on Cityscape-Adverse show significantly enhanced resilience when applied to unseen domains. Code and datasets will be released at this https URL.</li>
</ul>

<h3>Title: A KAN-based Interpretable Framework for Process-Informed Prediction of Global Warming Potential</h3>
<ul>
<li><strong>Authors: </strong>Jaewook Lee, Xinyang Sun, Ethan Errington, Miao Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00426">https://arxiv.org/abs/2411.00426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00426">https://arxiv.org/pdf/2411.00426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00426]] A KAN-based Interpretable Framework for Process-Informed Prediction of Global Warming Potential(https://arxiv.org/abs/2411.00426)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurate prediction of Global Warming Potential (GWP) is essential for assessing the environmental impact of chemical processes and materials. Traditional GWP prediction models rely predominantly on molecular structure, overlooking critical process-related information. In this study, we present an integrative GWP prediction model that combines molecular descriptors (MACCS keys and Mordred descriptors) with process information (process title, description, and location) to improve predictive accuracy and interpretability. Using a deep neural network (DNN) model, we achieved an R-squared of 86% on test data with Mordred descriptors, process location, and description information, representing a 25% improvement over the previous benchmark of 61%; XAI analysis further highlighted the significant role of process title embeddings in enhancing model predictions. To enhance interpretability, we employed a Kolmogorov-Arnold Network (KAN) to derive a symbolic formula for GWP prediction, capturing key molecular and process features and providing a transparent, interpretable alternative to black-box models, enabling users to gain insights into the molecular and process factors influencing GWP. Error analysis showed that the model performs reliably in densely populated data ranges, with increased uncertainty for higher GWP values. This analysis allows users to manage prediction uncertainty effectively, supporting data-driven decision-making in chemical and process design. Our results suggest that integrating both molecular and process-level information in GWP prediction models yields substantial gains in accuracy and interpretability, offering a valuable tool for sustainability assessments. Future work may extend this approach to additional environmental impact categories and refine the model to further enhance its predictive reliability.</li>
</ul>

<h3>Title: DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems</h3>
<ul>
<li><strong>Authors: </strong>Aman Gupta, Anirudh Ravichandran, Ziji Zhang, Swair Shah, Anurag Beniwal, Narayanan Sadagopan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00427">https://arxiv.org/abs/2411.00427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00427">https://arxiv.org/pdf/2411.00427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00427]] DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems(https://arxiv.org/abs/2411.00427)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Task-oriented dialogue systems are essential for applications ranging from customer service to personal assistants and are widely used across various industries. However, developing effective multi-domain systems remains a significant challenge due to the complexity of handling diverse user intents, entity types, and domain-specific knowledge across several domains. In this work, we propose DARD (Domain Assigned Response Delegation), a multi-agent conversational system capable of successfully handling multi-domain dialogs. DARD leverages domain-specific agents, orchestrated by a central dialog manager agent. Our extensive experiments compare and utilize various agent modeling approaches, combining the strengths of smaller fine-tuned models (Flan-T5-large & Mistral-7B) with their larger counterparts, Large Language Models (LLMs) (Claude Sonnet 3.0). We provide insights into the strengths and limitations of each approach, highlighting the benefits of our multi-agent framework in terms of flexibility and composability. We evaluate DARD using the well-established MultiWOZ benchmark, achieving state-of-the-art performance by improving the dialogue inform rate by 6.6% and the success rate by 4.1% over the best-performing existing approaches. Additionally, we discuss various annotator discrepancies and issues within the MultiWOZ dataset and its evaluation system.</li>
</ul>

<h3>Title: Class Incremental Learning with Task-Specific Batch Normalization and Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Xuchen Xie, Yiqiao Qiu, Run Lin, Weishi Zheng, Ruixuan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00430">https://arxiv.org/abs/2411.00430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00430">https://arxiv.org/pdf/2411.00430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00430]] Class Incremental Learning with Task-Specific Batch Normalization and Out-of-Distribution Detection(https://arxiv.org/abs/2411.00430)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This study focuses on incremental learning for image classification, exploring how to reduce catastrophic forgetting of all learned knowledge when access to old data is restricted due to memory or privacy constraints. The challenge of incremental learning lies in achieving an optimal balance between plasticity, the ability to learn new knowledge, and stability, the ability to retain old knowledge. Based on whether the task identifier (task-ID) of an image can be obtained during the test stage, incremental learning for image classifcation is divided into two main paradigms, which are task incremental learning (TIL) and class incremental learning (CIL). The TIL paradigm has access to the task-ID, allowing it to use multiple task-specific classification heads selected based on the task-ID. Consequently, in CIL, where the task-ID is unavailable, TIL methods must predict the task-ID to extend their application to the CIL paradigm. Our previous method for TIL adds task-specific batch normalization and classification heads incrementally. This work extends the method by predicting task-ID through an "unknown" class added to each classification head. The head with the lowest "unknown" probability is selected, enabling task-ID prediction and making the method applicable to CIL. The task-specific batch normalization (BN) modules effectively adjust the distribution of output feature maps across different tasks, enhancing the model's this http URL, since BN has much fewer parameters compared to convolutional kernels, by only modifying the BN layers as new tasks arrive, the model can effectively manage parameter growth while ensuring stability across tasks. The innovation of this study lies in the first-time introduction of task-specific BN into CIL and verifying the feasibility of extending TIL methods to CIL through task-ID prediction with state-of-the-art performance on multiple datasets.</li>
</ul>

<h3>Title: E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00437">https://arxiv.org/abs/2411.00437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00437">https://arxiv.org/pdf/2411.00437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00437]] E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation(https://arxiv.org/abs/2411.00437)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation methods often neglect the quality of content retrieved from external knowledge bases, resulting in irrelevant information or potential misinformation that negatively affects the generation results of large language models. In this paper, we propose an end-to-end model with adaptive filtering for retrieval-augmented generation (E2E-AFG), which integrates answer existence judgment and text generation into a single end-to-end framework. This enables the model to focus more effectively on relevant content while reducing the influence of irrelevant information and generating accurate answers. We evaluate E2E-AFG on six representative knowledge-intensive language datasets, and the results show that it consistently outperforms baseline models across all tasks, demonstrating the effectiveness and robustness of the proposed approach.</li>
</ul>

<h3>Title: Pandora's Box in Your SSD: The Untold Dangers of NVMe</h3>
<ul>
<li><strong>Authors: </strong>Rick Wertenbroek, Alberto Dassatti</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00439">https://arxiv.org/abs/2411.00439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00439">https://arxiv.org/pdf/2411.00439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00439]] Pandora's Box in Your SSD: The Untold Dangers of NVMe(https://arxiv.org/abs/2411.00439)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Modern operating systems manage and abstract hardware resources, to ensure efficient execution of user workloads. The operating system must securely interface with often untrusted user code while relying on hardware that is assumed to be trustworthy. In this paper, we challenge this trust by introducing the eNVMe platform, a malicious NVMe storage device. The eNVMe platform features a novel, Linux-based, open-source NVMe firmware. It embeds hacking tools and it is compatible with a variety of PCI-enabled hardware. Using this platform, we uncover several attack vectors in Linux and Windows, highlighting the risks posed by malicious NVMe devices. We discuss available mitigation techniques and ponder about open-source firmware and open-hardware as a viable way forward for storage. While prior research has examined compromised existing hardware, our eNVMe platform provides a novel and unique tool for security researchers, enabling deeper exploration of vulnerabilities in operating system storage subsystems.</li>
</ul>

<h3>Title: An Empirical Study of Vulnerability Handling Times in CPython</h3>
<ul>
<li><strong>Authors: </strong>Jukka Ruohonen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00447">https://arxiv.org/abs/2411.00447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00447">https://arxiv.org/pdf/2411.00447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00447]] An Empirical Study of Vulnerability Handling Times in CPython(https://arxiv.org/abs/2411.00447)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The paper examines the handling times of software vulnerabilities in CPython, the reference implementation and interpreter for the today's likely most popular programming language, Python. The background comes from the so-called vulnerability life cycle analysis, the literature on bug fixing times, and the recent research on security of Python software. Based on regression analysis, the associated vulnerability fixing times can be explained very well merely by knowing who have reported the vulnerabilities. Severity, proof-of-concept code, commits made to a version control system, comments posted on a bug tracker, and references to other sources do not explain the vulnerability fixing times. With these results, the paper contributes to the recent effort to better understand security of the Python ecosystem.</li>
</ul>

<h3>Title: Improving Few-Shot Cross-Domain Named Entity Recognition by Instruction Tuning a Word-Embedding based Retrieval Augmented Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Subhadip Nandi, Neeraj Agrawal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00451">https://arxiv.org/abs/2411.00451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00451">https://arxiv.org/pdf/2411.00451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00451]] Improving Few-Shot Cross-Domain Named Entity Recognition by Instruction Tuning a Word-Embedding based Retrieval Augmented Large Language Model(https://arxiv.org/abs/2411.00451)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Few-Shot Cross-Domain NER is the process of leveraging knowledge from data-rich source domains to perform entity recognition on data scarce target domains. Most previous state-of-the-art (SOTA) approaches use pre-trained language models (PLMs) for cross-domain NER. However, these models are often domain specific. To successfully use these models for new target domains, we need to modify either the model architecture or perform model finetuning using data from the new domains. Both of these result in the creation of entirely new NER models for each target domain which is infeasible for practical scenarios. Recently,several works have attempted to use LLMs to solve Few-Shot Cross-Domain NER. However, most of these are either too expensive for practical purposes or struggle to follow LLM prompt instructions. In this paper, we propose IF-WRANER (Instruction Finetuned Word-embedding based Retrieval Augmented large language model for Named Entity Recognition), a retrieval augmented LLM, finetuned for the NER task. By virtue of the regularization techniques used during LLM finetuning and the adoption of word-level embedding over sentence-level embedding during the retrieval of in-prompt examples, IF-WRANER is able to outperform previous SOTA Few-Shot Cross-Domain NER approaches. We have demonstrated the effectiveness of our model by benchmarking its performance on the open source CrossNER dataset, on which it shows more than 2% F1 score improvement over the previous SOTA model. We have deployed the model for multiple customer care domains of an enterprise. Accurate entity prediction through IF-WRANER helps direct customers to automated workflows for the domains, thereby reducing escalations to human agents by almost 15% and leading to millions of dollars in yearly savings for the company.</li>
</ul>

<h3>Title: Diffusion Models as Network Optimizers: Explorations and Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ruihuai Liang, Bo Yang, Pengyu Chen, Xianjin Li, Yifan Xue, Zhiwen Yu, Xuelin Cao, Yan Zhang, Mérouane Debbah, H. Vincent Poor, Chau Yuen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00453">https://arxiv.org/abs/2411.00453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00453">https://arxiv.org/pdf/2411.00453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00453]] Diffusion Models as Network Optimizers: Explorations and Analysis(https://arxiv.org/abs/2411.00453)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Network optimization is a fundamental challenge in the Internet of Things (IoT) network, often characterized by complex features that make it difficult to solve these problems. Recently, generative diffusion models (GDMs) have emerged as a promising new approach to network optimization, with the potential to directly address these optimization problems. However, the application of GDMs in this field is still in its early stages, and there is a noticeable lack of theoretical research and empirical findings. In this study, we first explore the intrinsic characteristics of generative models. Next, we provide a concise theoretical proof and intuitive demonstration of the advantages of generative models over discriminative models in network optimization. Based on this exploration, we implement GDMs as optimizers aimed at learning high-quality solution distributions for given inputs, sampling from these distributions during inference to approximate or achieve optimal solutions. Specifically, we utilize denoising diffusion probabilistic models (DDPMs) and employ a classifier-free guidance mechanism to manage conditional guidance based on input parameters. We conduct extensive experiments across three challenging network optimization problems. By investigating various model configurations and the principles of GDMs as optimizers, we demonstrate the ability to overcome prediction errors and validate the convergence of generated solutions to optimal solutions.</li>
</ul>

<h3>Title: Defense Against Prompt Injection Attack by Leveraging Attack Techniques</h3>
<ul>
<li><strong>Authors: </strong>Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song, Dekai Wu, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00459">https://arxiv.org/abs/2411.00459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00459">https://arxiv.org/pdf/2411.00459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00459]] Defense Against Prompt Injection Attack by Leveraging Attack Techniques(https://arxiv.org/abs/2411.00459)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the advancement of technology, large language models (LLMs) have achieved remarkable performance across various natural language processing (NLP) tasks, powering LLM-integrated applications like Microsoft Copilot. However, as LLMs continue to evolve, new vulnerabilities, especially prompt injection attacks arise. These attacks trick LLMs into deviating from the original input instructions and executing the attacker's instructions injected in data content, such as retrieved results. Recent attack methods leverage LLMs' instruction-following abilities and their inabilities to distinguish instructions injected in the data content, and achieve a high attack success rate (ASR). When comparing the attack and defense methods, we interestingly find that they share similar design goals, of inducing the model to ignore unwanted instructions and instead to execute wanted instructions. Therefore, we raise an intuitive question: Could these attack techniques be utilized for defensive purposes? In this paper, we invert the intention of prompt injection methods to develop novel defense methods based on previous training-free attack methods, by repeating the attack process but with the original input instruction rather than the injected instruction. Our comprehensive experiments demonstrate that our defense techniques outperform existing training-free defense approaches, achieving state-of-the-art results.</li>
</ul>

<h3>Title: Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions</h3>
<ul>
<li><strong>Authors: </strong>Jie Wang, Tingfa Xu, Lihe Ding, Jianan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00462">https://arxiv.org/abs/2411.00462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00462">https://arxiv.org/pdf/2411.00462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00462]] Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions(https://arxiv.org/abs/2411.00462)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Achieving robust 3D perception in the face of corrupted data presents an challenging hurdle within 3D vision research. Contemporary transformer-based point cloud recognition models, albeit advanced, tend to overfit to specific patterns, consequently undermining their robustness against corruption. In this work, we introduce the Target-Guided Adversarial Point Cloud Transformer, termed APCT, a novel architecture designed to augment global structure capture through an adversarial feature erasing mechanism predicated on patterns discerned at each step during training. Specifically, APCT integrates an Adversarial Significance Identifier and a Target-guided Promptor. The Adversarial Significance Identifier, is tasked with discerning token significance by integrating global contextual analysis, utilizing a structural salience index algorithm alongside an auxiliary supervisory mechanism. The Target-guided Promptor, is responsible for accentuating the propensity for token discard within the self-attention mechanism, utilizing the value derived above, consequently directing the model attention towards alternative segments in subsequent stages. By iteratively applying this strategy in multiple steps during training, the network progressively identifies and integrates an expanded array of object-associated patterns. Extensive experiments demonstrate that our method achieves state-of-the-art results on multiple corruption benchmarks.</li>
</ul>

<h3>Title: Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions</h3>
<ul>
<li><strong>Authors: </strong>Rui Yang, Jie Wang, Guoping Wu, Bin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00465">https://arxiv.org/abs/2411.00465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00465">https://arxiv.org/pdf/2411.00465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00465]] Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions(https://arxiv.org/abs/2411.00465)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Real-world offline datasets are often subject to data corruptions (such as noise or adversarial attacks) due to sensor failures or malicious attacks. Despite advances in robust offline reinforcement learning (RL), existing methods struggle to learn robust agents under high uncertainty caused by the diverse corrupted data (i.e., corrupted states, actions, rewards, and dynamics), leading to performance degradation in clean environments. To tackle this problem, we propose a novel robust variational Bayesian inference for offline RL (TRACER). It introduces Bayesian inference for the first time to capture the uncertainty via offline data for robustness against all types of data corruptions. Specifically, TRACER first models all corruptions as the uncertainty in the action-value function. Then, to capture such uncertainty, it uses all offline data as the observations to approximate the posterior distribution of the action-value function under a Bayesian inference framework. An appealing feature of TRACER is that it can distinguish corrupted data from clean data using an entropy-based uncertainty measure, since corrupted data often induces higher uncertainty and entropy. Based on the aforementioned measure, TRACER can regulate the loss associated with corrupted data to reduce its influence, thereby enhancing robustness and performance in clean environments. Experiments demonstrate that TRACER significantly outperforms several state-of-the-art approaches across both individual and simultaneous data corruptions.</li>
</ul>

<h3>Title: MV-Adapter: Enhancing Underwater Instance Segmentation via Adaptive Channel Attention</h3>
<ul>
<li><strong>Authors: </strong>Lianjun Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00472">https://arxiv.org/abs/2411.00472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00472">https://arxiv.org/pdf/2411.00472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00472]] MV-Adapter: Enhancing Underwater Instance Segmentation via Adaptive Channel Attention(https://arxiv.org/abs/2411.00472)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Underwater instance segmentation is a fundamental and critical step in various underwater vision tasks. However, the decline in image quality caused by complex underwater environments presents significant challenges to existing segmentation models. While the state-of-the-art USIS-SAM model has demonstrated impressive performance, it struggles to effectively adapt to feature variations across different channels in addressing issues such as light attenuation, color distortion, and complex backgrounds. This limitation hampers its segmentation performance in challenging underwater scenarios. To address these issues, we propose the MarineVision Adapter (MV-Adapter). This module introduces an adaptive channel attention mechanism that enables the model to dynamically adjust the feature weights of each channel based on the characteristics of underwater images. By adaptively weighting features, the model can effectively handle challenges such as light attenuation, color shifts, and complex backgrounds. Experimental results show that integrating the MV-Adapter module into the USIS-SAM network architecture further improves the model's overall performance, especially in high-precision segmentation tasks. On the USIS10K dataset, the module achieves improvements in key metrics such as mAP, AP50, and AP75 compared to competitive baseline models.</li>
</ul>

<h3>Title: Computer Application Research based on Chinese Human Resources and Network Information Security Technology Management and Analysis In Chinese Universities</h3>
<ul>
<li><strong>Authors: </strong>Jun Cui</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00474">https://arxiv.org/abs/2411.00474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00474">https://arxiv.org/pdf/2411.00474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00474]] Computer Application Research based on Chinese Human Resources and Network Information Security Technology Management and Analysis In Chinese Universities(https://arxiv.org/abs/2411.00474)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>This study investigates the current state of computer network security and human resource management within Chinese universities, emphasizing the growing importance of safeguarding digital infrastructures. To support the analysis, interviews were conducted with managers from two leading Chinese cybersecurity firms and the qualitative data obtained was carefully analyzed to extract key insights and conclusions.</li>
</ul>

<h3>Title: Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Do Xuan Long, Duong Ngoc Yen, Anh Tuan Luu, Kenji Kawaguchi, Min-Yen Kan, Nancy F. Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00492">https://arxiv.org/abs/2411.00492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00492">https://arxiv.org/pdf/2411.00492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00492]] Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models(https://arxiv.org/abs/2411.00492)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple experts, aggregating their responses, and selecting the best among individual and aggregated responses. This process is performed in a single chain of thoughts through our seven carefully designed subtasks derived from the Nominal Group Technique (Ven and Delbecq, 1974), a well-established decision-making framework. Our evaluations demonstrate that Multi-expert Prompting significantly outperforms ExpertPrompting and comparable baselines in enhancing the truthfulness, factuality, informativeness, and usefulness of responses while reducing toxicity and hurtfulness. It further achieves state-of-the-art truthfulness by outperforming the best baseline by 8.69% with ChatGPT. Multi-expert Prompting is efficient, explainable, and highly adaptable to diverse scenarios, eliminating the need for manual prompt construction.</li>
</ul>

<h3>Title: Exploring the Precise Dynamics of Single-Layer GAN Models: Leveraging Multi-Feature Discriminators for High-Dimensional Subspace Learning</h3>
<ul>
<li><strong>Authors: </strong>Andrew Bond, Zafer Dogan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00498">https://arxiv.org/abs/2411.00498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00498">https://arxiv.org/pdf/2411.00498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00498]] Exploring the Precise Dynamics of Single-Layer GAN Models: Leveraging Multi-Feature Discriminators for High-Dimensional Subspace Learning(https://arxiv.org/abs/2411.00498)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Subspace learning is a critical endeavor in contemporary machine learning, particularly given the vast dimensions of modern datasets. In this study, we delve into the training dynamics of a single-layer GAN model from the perspective of subspace learning, framing these GANs as a novel approach to this fundamental task. Through a rigorous scaling limit analysis, we offer insights into the behavior of this model. Extending beyond prior research that primarily focused on sequential feature learning, we investigate the non-sequential scenario, emphasizing the pivotal role of inter-feature interactions in expediting training and enhancing performance, particularly with an uninformed initialization strategy. Our investigation encompasses both synthetic and real-world datasets, such as MNIST and Olivetti Faces, demonstrating the robustness and applicability of our findings to practical scenarios. By bridging our analysis to the realm of subspace learning, we systematically compare the efficacy of GAN-based methods against conventional approaches, both theoretically and empirically. Notably, our results unveil that while all methodologies successfully capture the underlying subspace, GANs exhibit a remarkable capability to acquire a more informative basis, owing to their intrinsic ability to generate new data samples. This elucidates the unique advantage of GAN-based approaches in subspace learning tasks.</li>
</ul>

<h3>Title: Cross-modal semantic segmentation for indoor environmental perception using single-chip millimeter-wave radar raw data</h3>
<ul>
<li><strong>Authors: </strong>Hairuo Hu, Haiyong Cong, Zhuyu Shao, Yubo Bi, Jinghao Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.ET, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00499">https://arxiv.org/abs/2411.00499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00499">https://arxiv.org/pdf/2411.00499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00499]] Cross-modal semantic segmentation for indoor environmental perception using single-chip millimeter-wave radar raw data(https://arxiv.org/abs/2411.00499)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In the context of firefighting and rescue operations, a cross-modal semantic segmentation model based on a single-chip millimeter-wave (mmWave) radar for indoor environmental perception is proposed and discussed. To efficiently obtain high-quality labels, an automatic label generation method utilizing LiDAR point clouds and occupancy grid maps is introduced. The proposed segmentation model is based on U-Net. A spatial attention module is incorporated, which enhanced the performance of the mode. The results demonstrate that cross-modal semantic segmentation provides a more intuitive and accurate representation of indoor environments. Unlike traditional methods, the model's segmentation performance is minimally affected by azimuth. Although performance declines with increasing distance, this can be mitigated by a well-designed model. Additionally, it was found that using raw ADC data as input is ineffective; compared to RA tensors, RD tensors are more suitable for the proposed model.</li>
</ul>

<h3>Title: Tactical Edge IoT in Defense and National Security</h3>
<ul>
<li><strong>Authors: </strong>Paula Fraga-Lamas, Tiago M. Fernandez-Carames</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00511">https://arxiv.org/abs/2411.00511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00511">https://arxiv.org/pdf/2411.00511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00511]] Tactical Edge IoT in Defense and National Security(https://arxiv.org/abs/2411.00511)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense</a></li>
<li><strong>Abstract: </strong>The deployment of Internet of Things (IoT) systems in Defense and National Security faces some limitations that can be addressed with Edge Computing approaches. The Edge Computing and IoT paradigms combined bring potential benefits, since they confront the limitations of traditional centralized cloud computing approaches, which enable easy scalability, real-time applications or mobility support, but whose use poses certain risks in aspects like cybersecurity. This chapter identifies scenarios in which Defense and National Security can leverage Commercial Off-The-Shelf (COTS) Edge IoT capabilities to deliver greater survivability to warfighters or first responders, while lowering costs and increasing operational efficiency and effectiveness. In addition, it presents the general design of a Tactical Edge IoT communications architecture, it identifies the open challenges for a widespread adoption and provides research guidelines and some recommendations for enabling cost-effective Edge IoT for Defense and National Security.</li>
</ul>

<h3>Title: Outlier-Oriented Poisoning Attack: A Grey-box Approach to Disturb Decision Boundaries by Perturbing Outliers in Multiclass Learning</h3>
<ul>
<li><strong>Authors: </strong>Anum Paracha, Junaid Arshad, Mohamed Ben Farah, Khalid Ismail</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00519">https://arxiv.org/abs/2411.00519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00519">https://arxiv.org/pdf/2411.00519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00519]] Outlier-Oriented Poisoning Attack: A Grey-box Approach to Disturb Decision Boundaries by Perturbing Outliers in Multiclass Learning(https://arxiv.org/abs/2411.00519)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Poisoning attacks are a primary threat to machine learning models, aiming to compromise their performance and reliability by manipulating training datasets. This paper introduces a novel attack - Outlier-Oriented Poisoning (OOP) attack, which manipulates labels of most distanced samples from the decision boundaries. The paper also investigates the adverse impact of such attacks on different machine learning algorithms within a multiclass classification scenario, analyzing their variance and correlation between different poisoning levels and performance degradation. To ascertain the severity of the OOP attack for different degrees (5% - 25%) of poisoning, we analyzed variance, accuracy, precision, recall, f1-score, and false positive rate for chosen ML this http URL our OOP attack, we have analyzed key characteristics of multiclass machine learning algorithms and their sensitivity to poisoning attacks. Our experimentation used three publicly available datasets: IRIS, MNIST, and ISIC. Our analysis shows that KNN and GNB are the most affected algorithms with a decrease in accuracy of 22.81% and 56.07% while increasing false positive rate to 17.14% and 40.45% for IRIS dataset with 15% poisoning. Further, Decision Trees and Random Forest are the most resilient algorithms with the least accuracy disruption of 12.28% and 17.52% with 15% poisoning of the IRIS dataset. We have also analyzed the correlation between number of dataset classes and the performance degradation of models. Our analysis highlighted that number of classes are inversely proportional to the performance degradation, specifically the decrease in accuracy of the models, which is normalized with increasing number of classes. Further, our analysis identified that imbalanced dataset distribution can aggravate the impact of poisoning for machine learning models</li>
</ul>

<h3>Title: Analyzing Multimodal Integration in the Variational Autoencoder from an Information-Theoretic Perspective</h3>
<ul>
<li><strong>Authors: </strong>Carlotta Langer, Yasmin Kim Georgie, Ilja Porohovoj, Verena Vanessa Hafner, Nihat Ay</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00522">https://arxiv.org/abs/2411.00522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00522">https://arxiv.org/pdf/2411.00522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00522]] Analyzing Multimodal Integration in the Variational Autoencoder from an Information-Theoretic Perspective(https://arxiv.org/abs/2411.00522)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Human perception is inherently multimodal. We integrate, for instance, visual, proprioceptive and tactile information into one experience. Hence, multimodal learning is of importance for building robotic systems that aim at robustly interacting with the real world. One potential model that has been proposed for multimodal integration is the multimodal variational autoencoder. A variational autoencoder (VAE) consists of two networks, an encoder that maps the data to a stochastic latent space and a decoder that reconstruct this data from an element of this latent space. The multimodal VAE integrates inputs from different modalities at two points in time in the latent space and can thereby be used as a controller for a robotic agent. Here we use this architecture and introduce information-theoretic measures in order to analyze how important the integration of the different modalities are for the reconstruction of the input data. Therefore we calculate two different types of measures, the first type is called single modality error and assesses how important the information from a single modality is for the reconstruction of this modality or all modalities. Secondly, the measures named loss of precision calculate the impact that missing information from only one modality has on the reconstruction of this modality or the whole vector. The VAE is trained via the evidence lower bound, which can be written as a sum of two different terms, namely the reconstruction and the latent loss. The impact of the latent loss can be weighted via an additional variable, which has been introduced to combat posterior collapse. Here we train networks with four different weighting schedules and analyze them with respect to their capabilities for multimodal integration.</li>
</ul>

<h3>Title: Active Preference-based Learning for Multi-dimensional Personalization</h3>
<ul>
<li><strong>Authors: </strong>Minhyeon Oh, Seungjoon Lee, Jungseul Ok</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00524">https://arxiv.org/abs/2411.00524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00524">https://arxiv.org/pdf/2411.00524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00524]] Active Preference-based Learning for Multi-dimensional Personalization(https://arxiv.org/abs/2411.00524)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable versatility across tasks, but aligning them with individual human preferences remains challenging due to the complexity and diversity of these preferences. Existing methods often overlook the fact that preferences are multi-objective, diverse, and hard to articulate, making full alignment difficult. In response, we propose an active preference learning framework that uses binary feedback to estimate user preferences across multiple objectives. Our approach leverages Bayesian inference to update preferences efficiently and reduces user feedback through an acquisition function that optimally selects queries. Additionally, we introduce a parameter to handle feedback noise and improve robustness. We validate our approach through theoretical analysis and experiments on language generation tasks, demonstrating its feedback efficiency and effectiveness in personalizing model responses.</li>
</ul>

<h3>Title: ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot Named Entity Recognition with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anbang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00533">https://arxiv.org/abs/2411.00533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00533">https://arxiv.org/pdf/2411.00533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00533]] ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot Named Entity Recognition with Large Language Models(https://arxiv.org/abs/2411.00533)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents ReverseNER, a framework aimed at overcoming the limitations of large language models (LLMs) in zero-shot Named Entity Recognition (NER) tasks, particularly in cases where certain entity types have ambiguous boundaries. ReverseNER tackles this challenge by constructing a reliable example library with the reversed process of NER. Rather than beginning with sentences, this method uses an LLM to generate entities based on their definitions and then expands them into full sentences. During sentence generation, the LLM is guided to replicate the structure of a specific 'feature sentence', extracted from the task sentences by clustering. This results in well-annotated sentences with clearly labeled entities, while preserving semantic and structural similarity to the task sentences. Once the example library is constructed, the method selects the most semantically similar example labels for each task sentence to support the LLM's inference. We also propose an entity-level self-consistency scoring mechanism to improve NER performance with LLMs. Experiments show that ReverseNER significantly outperforms traditional zero-shot NER with LLMs and surpasses several few-shot methods, marking a notable improvement in NER for domains with limited labeled data.</li>
</ul>

<h3>Title: 3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jongmin Lee, Minsu Cho</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00543">https://arxiv.org/abs/2411.00543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00543">https://arxiv.org/pdf/2411.00543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00543]] 3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction(https://arxiv.org/abs/2411.00543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Determining the 3D orientations of an object in an image, known as single-image pose estimation, is a crucial task in 3D vision applications. Existing methods typically learn 3D rotations parametrized in the spatial domain using Euler angles or quaternions, but these representations often introduce discontinuities and singularities. SO(3)-equivariant networks enable the structured capture of pose patterns with data-efficient learning, but the parametrizations in spatial domain are incompatible with their architecture, particularly spherical CNNs, which operate in the frequency domain to enhance computational efficiency. To overcome these issues, we propose a frequency-domain approach that directly predicts Wigner-D coefficients for 3D rotation regression, aligning with the operations of spherical CNNs. Our SO(3)-equivariant pose harmonics predictor overcomes the limitations of spatial parameterizations, ensuring consistent pose estimation under arbitrary rotations. Trained with a frequency-domain regression loss, our method achieves state-of-the-art results on benchmarks such as ModelNet10-SO(3) and PASCAL3D+, with significant improvements in accuracy, robustness, and data efficiency.</li>
</ul>

<h3>Title: Generative AI-based Pipeline Architecture for Increasing Training Efficiency in Intelligent Weed Control Systems</h3>
<ul>
<li><strong>Authors: </strong>Sourav Modak, Anthony Stein</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00548">https://arxiv.org/abs/2411.00548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00548">https://arxiv.org/pdf/2411.00548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00548]] Generative AI-based Pipeline Architecture for Increasing Training Efficiency in Intelligent Weed Control Systems(https://arxiv.org/abs/2411.00548)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In automated crop protection tasks such as weed control, disease diagnosis, and pest monitoring, deep learning has demonstrated significant potential. However, these advanced models rely heavily on high-quality, diverse datasets, often limited and costly in agricultural settings. Traditional data augmentation can increase dataset volume but usually lacks the real-world variability needed for robust training. This study presents a new approach for generating synthetic images to improve deep learning-based object detection models for intelligent weed control. Our GenAI-based image generation pipeline integrates the Segment Anything Model (SAM) for zero-shot domain adaptation with a text-to-image Stable Diffusion Model, enabling the creation of synthetic images that capture diverse real-world conditions. We evaluate these synthetic datasets using lightweight YOLO models, measuring data efficiency with mAP50 and mAP50-95 scores across varying proportions of real and synthetic data. Notably, YOLO models trained on datasets with 10% synthetic and 90% real images generally demonstrate superior mAP50 and mAP50-95 scores compared to those trained solely on real images. This approach not only reduces dependence on extensive real-world datasets but also enhances predictive performance. The integration of this approach opens opportunities for achieving continual self-improvement of perception modules in intelligent technical systems.</li>
</ul>

<h3>Title: Conditional Synthesis of 3D Molecules with Time Correction Sampler</h3>
<ul>
<li><strong>Authors: </strong>Hojung Jung, Youngrok Park, Laura Schmid, Jaehyeong Jo, Dongkyu Lee, Bongsang Kim, Se-Young Yun, Jinwoo Shin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00551">https://arxiv.org/abs/2411.00551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00551">https://arxiv.org/pdf/2411.00551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00551]] Conditional Synthesis of 3D Molecules with Time Correction Sampler(https://arxiv.org/abs/2411.00551)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated remarkable success in various domains, including molecular generation. However, conditional molecular generation remains a fundamental challenge due to an intrinsic trade-off between targeting specific chemical properties and generating meaningful samples from the data distribution. In this work, we present Time-Aware Conditional Synthesis (TACS), a novel approach to conditional generation on diffusion models. It integrates adaptively controlled plug-and-play "online" guidance into a diffusion model, driving samples toward the desired properties while maintaining validity and stability. A key component of our algorithm is our new type of diffusion sampler, Time Correction Sampler (TCS), which is used to control guidance and ensure that the generated molecules remain on the correct manifold at each reverse step of the diffusion process at the same time. Our proposed method demonstrates significant performance in conditional 3D molecular generation and offers a promising approach towards inverse molecular design, potentially facilitating advancements in drug discovery, materials science, and other related fields.</li>
</ul>

<h3>Title: Tracking one-in-a-million: Large-scale benchmark for microbial single-cell tracking with experiment-aware robustness metrics</h3>
<ul>
<li><strong>Authors: </strong>J. Seiffarth, L. Blöbaum, R. D. Paul, N. Friederich, A. J. Yamachui Sitcheu, R. Mikut, H. Scharr, A. Grünberger, K. Nöh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00552">https://arxiv.org/abs/2411.00552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00552">https://arxiv.org/pdf/2411.00552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00552]] Tracking one-in-a-million: Large-scale benchmark for microbial single-cell tracking with experiment-aware robustness metrics(https://arxiv.org/abs/2411.00552)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tracking the development of living cells in live-cell time-lapses reveals crucial insights into single-cell behavior and presents tremendous potential for biomedical and biotechnological applications. In microbial live-cell imaging (MLCI), a few to thousands of cells have to be detected and tracked within dozens of growing cell colonies. The challenge of tracking cells is heavily influenced by the experiment parameters, namely the imaging interval and maximal cell number. For now, tracking benchmarks are not widely available in MLCI and the effect of these parameters on the tracking performance are not yet known. Therefore, we present the largest publicly available and annotated dataset for MLCI, containing more than 1.4 million cell instances, 29k cell tracks, and 14k cell divisions. With this dataset at hand, we generalize existing tracking metrics to incorporate relevant imaging and experiment parameters into experiment-aware metrics. These metrics reveal that current cell tracking methods crucially depend on the choice of the experiment parameters, where their performance deteriorates at high imaging intervals and large cell colonies. Thus, our new benchmark quantifies the influence of experiment parameters on the tracking quality, and gives the opportunity to develop new data-driven methods that generalize across imaging and experiment parameters. The benchmark dataset is publicly available at this https URL.</li>
</ul>

<h3>Title: Is Multiple Object Tracking a Matter of Specialization?</h3>
<ul>
<li><strong>Authors: </strong>Gianluca Mancusi, Mattia Bernardi, Aniello Panariello, Angelo Porrello, Rita Cucchiara, Simone Calderara</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00553">https://arxiv.org/abs/2411.00553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00553">https://arxiv.org/pdf/2411.00553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00553]] Is Multiple Object Tracking a Matter of Specialization?(https://arxiv.org/abs/2411.00553)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>End-to-end transformer-based trackers have achieved remarkable performance on most human-related datasets. However, training these trackers in heterogeneous scenarios poses significant challenges, including negative interference - where the model learns conflicting scene-specific parameters - and limited domain generalization, which often necessitates expensive fine-tuning to adapt the models to new domains. In response to these challenges, we introduce Parameter-efficient Scenario-specific Tracking Architecture (PASTA), a novel framework that combines Parameter-Efficient Fine-Tuning (PEFT) and Modular Deep Learning (MDL). Specifically, we define key scenario attributes (e.g, camera-viewpoint, lighting condition) and train specialized PEFT modules for each attribute. These expert modules are combined in parameter space, enabling systematic generalization to new domains without increasing inference time. Extensive experiments on MOTSynth, along with zero-shot evaluations on MOT17 and PersonPath22 demonstrate that a neural tracker built from carefully selected modules surpasses its monolithic counterpart. We release models and code.</li>
</ul>

<h3>Title: Topology and Intersection-Union Constrained Loss Function for Multi-Region Anatomical Segmentation in Ocular Images</h3>
<ul>
<li><strong>Authors: </strong>Ruiyu Xia, Jianqiang Li, Xi Xu, Guanghui Fu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00560">https://arxiv.org/abs/2411.00560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00560">https://arxiv.org/pdf/2411.00560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00560]] Topology and Intersection-Union Constrained Loss Function for Multi-Region Anatomical Segmentation in Ocular Images(https://arxiv.org/abs/2411.00560)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Ocular Myasthenia Gravis (OMG) is a rare and challenging disease to detect in its early stages, but symptoms often first appear in the eye muscles, such as drooping eyelids and double vision. Ocular images can be used for early diagnosis by segmenting different regions, such as the sclera, iris, and pupil, which allows for the calculation of area ratios to support accurate medical assessments. However, no publicly available dataset and tools currently exist for this purpose. To address this, we propose a new topology and intersection-union constrained loss function (TIU loss) that improves performance using small training datasets. We conducted experiments on a public dataset consisting of 55 subjects and 2,197 images. Our proposed method outperformed two widely used loss functions across three deep learning networks, achieving a mean Dice score of 83.12% [82.47%, 83.81%] with a 95% bootstrap confidence interval. In a low-percentage training scenario (10% of the training data), our approach showed an 8.32% improvement in Dice score compared to the baseline. Additionally, we evaluated the method in a clinical setting with 47 subjects and 501 images, achieving a Dice score of 64.44% [63.22%, 65.62%]. We did observe some bias when applying the model in clinical settings. These results demonstrate that the proposed method is accurate, and our code along with the trained model is publicly available.</li>
</ul>

<h3>Title: Automated Classification of Cell Shapes: A Comparative Evaluation of Shape Descriptors</h3>
<ul>
<li><strong>Authors: </strong>Valentina Vadori, Antonella Peruffo, Jean-Marie Graïc, Livio Finos, Enrico Grisan</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00561">https://arxiv.org/abs/2411.00561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00561">https://arxiv.org/pdf/2411.00561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00561]] Automated Classification of Cell Shapes: A Comparative Evaluation of Shape Descriptors(https://arxiv.org/abs/2411.00561)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images. We assess the performance of various features for shape classification, including Elliptical Fourier Descriptors, curvature features, and lower dimensional representations. Using an annotated synthetic dataset of noisy contours, we identify the most suitable shape descriptors and apply them to a set of real images for qualitative analysis. Our aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization-critical tasks in both biological research and histopathological assessments.</li>
</ul>

<h3>Title: Handheld Video Document Scanning: A Robust On-Device Model for Multi-Page Document Scanning</h3>
<ul>
<li><strong>Authors: </strong>Curtis Wigington</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00576">https://arxiv.org/abs/2411.00576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00576">https://arxiv.org/pdf/2411.00576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00576]] Handheld Video Document Scanning: A Robust On-Device Model for Multi-Page Document Scanning(https://arxiv.org/abs/2411.00576)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Document capture applications on smartphones have emerged as popular tools for digitizing documents. For many individuals, capturing documents with their smartphones is more convenient than using dedicated photocopiers or scanners, even if the quality of digitization is lower. However, using a smartphone for digitization can become excessively time-consuming and tedious when a user needs to digitize a document with multiple pages. In this work, we propose a novel approach to automatically scan multi-page documents from a video stream as the user turns through the pages of the document. Unlike previous methods that required constrained settings such as mounting the phone on a tripod, our technique is designed to allow the user to hold the phone in their hand. Our technique is trained to be robust to the motion and instability inherent in handheld scanning. Our primary contributions in this work include: (1) an efficient, on-device deep learning model that is accurate and robust for handheld scanning, (2) a novel data collection and annotation technique for video document scanning, and (3) state-of-the-art results on the PUCIT page turn dataset.</li>
</ul>

<h3>Title: Federated Voxel Scene Graph for Intracranial Hemorrhage</h3>
<ul>
<li><strong>Authors: </strong>Antoine P. Sanner, Jonathan Stieber, Nils F. Grauhan, Suam Kim, Marc A. Brockmann, Ahmed E. Othman, Anirban Mukhopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.DC, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00578">https://arxiv.org/abs/2411.00578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00578">https://arxiv.org/pdf/2411.00578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00578]] Federated Voxel Scene Graph for Intracranial Hemorrhage(https://arxiv.org/abs/2411.00578)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across clinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain structures, but still struggle to generalize. While gathering more diverse data is the most natural approach, privacy regulations often limit the sharing of medical data. We propose the first application of Federated Scene Graph Generation. We show that our models can leverage the increased training data diversity. For Scene Graph Generation, they can recall up to 20% more clinically relevant relations across datasets compared to models trained on a single centralized dataset. Learning structured data representation in a federated setting can open the way to the development of new methods that can leverage this finer information to regularize across clients more effectively.</li>
</ul>

<h3>Title: Improving self-training under distribution shifts via anchored confidence with theoretical guarantees</h3>
<ul>
<li><strong>Authors: </strong>Taejong Joo, Diego Klabjan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00586">https://arxiv.org/abs/2411.00586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00586">https://arxiv.org/pdf/2411.00586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00586]] Improving self-training under distribution shifts via anchored confidence with theoretical guarantees(https://arxiv.org/abs/2411.00586)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Self-training often falls short under distribution shifts due to an increased discrepancy between prediction confidence and actual accuracy. This typically necessitates computationally demanding methods such as neighborhood or ensemble-based label corrections. Drawing inspiration from insights on early learning regularization, we develop a principled method to improve self-training under distribution shifts based on temporal consistency. Specifically, we build an uncertainty-aware temporal ensemble with a simple relative thresholding. Then, this ensemble smooths noisy pseudo labels to promote selective temporal consistency. We show that our temporal ensemble is asymptotically correct and our label smoothing technique can reduce the optimality gap of self-training. Our extensive experiments validate that our approach consistently improves self-training performances by 8% to 16% across diverse distribution shift scenarios without a computational overhead. Besides, our method exhibits attractive properties, such as improved calibration performance and robustness to different hyperparameter choices.</li>
</ul>

<h3>Title: $\alpha$-TCVAE: On the relationship between Disentanglement and Diversity</h3>
<ul>
<li><strong>Authors: </strong>Cristian Meo, Louis Mahon, Anirudh Goyal, Justin Dauwels</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00588">https://arxiv.org/abs/2411.00588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00588">https://arxiv.org/pdf/2411.00588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00588]] $\alpha$-TCVAE: On the relationship between Disentanglement and Diversity(https://arxiv.org/abs/2411.00588)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While disentangled representations have shown promise in generative modeling and representation learning, their downstream usefulness remains debated. Recent studies re-defined disentanglement through a formal connection to symmetries, emphasizing the ability to reduce latent domains and consequently enhance generative capabilities. However, from an information theory viewpoint, assigning a complex attribute to a specific latent variable may be infeasible, limiting the applicability of disentangled representations to simple datasets. In this work, we introduce $\alpha$-TCVAE, a variational autoencoder optimized using a novel total correlation (TC) lower bound that maximizes disentanglement and latent variables informativeness. The proposed TC bound is grounded in information theory constructs, generalizes the $\beta$-VAE lower bound, and can be reduced to a convex combination of the known variational information bottleneck (VIB) and conditional entropy bottleneck (CEB) terms. Moreover, we present quantitative analyses that support the idea that disentangled representations lead to better generative capabilities and diversity. Additionally, we perform downstream task experiments from both representation and RL domains to assess our questions from a broader ML perspective. Our results demonstrate that $\alpha$-TCVAE consistently learns more disentangled representations than baselines and generates more diverse observations without sacrificing visual fidelity. Notably, $\alpha$-TCVAE exhibits marked improvements on MPI3D-Real, the most realistic disentangled dataset in our study, confirming its ability to represent complex datasets when maximizing the informativeness of individual variables. Finally, testing the proposed model off-the-shelf on a state-of-the-art model-based RL agent, Director, significantly shows $\alpha$-TCVAE downstream usefulness on the loconav Ant Maze task.</li>
</ul>

<h3>Title: Adapting Language Models via Token Translation</h3>
<ul>
<li><strong>Authors: </strong>Zhili Feng, Tanya Marwah, Lester Mackey, David Alvarez-Melis, Nicolo Fusi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00593">https://arxiv.org/abs/2411.00593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00593">https://arxiv.org/pdf/2411.00593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00593]] Adapting Language Models via Token Translation(https://arxiv.org/abs/2411.00593)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern large language models use a fixed tokenizer to effectively compress text drawn from a source domain. However, applying the same tokenizer to a new target domain often leads to inferior compression, more costly inference, and reduced semantic alignment. To address this deficiency, we introduce Sparse Sinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the target domain and learns to translate between target and source tokens, enabling more effective reuse of the pre-trained next-source-token predictor. In our experiments with finetuned English language models, S2T2 improves both the perplexity and the compression of out-of-domain protein sequences, outperforming direct finetuning with either the source or target tokenizer. In addition, we find that token translations learned for smaller, less expensive models can be directly transferred to larger, more powerful models to reap the benefits of S2T2 at lower cost.</li>
</ul>

<h3>Title: On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR</h3>
<ul>
<li><strong>Authors: </strong>Li Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00600">https://arxiv.org/abs/2411.00600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00600">https://arxiv.org/pdf/2411.00600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00600]] On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR(https://arxiv.org/abs/2411.00600)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D LiDAR point cloud data is crucial for scene perception in computer vision, robotics, and autonomous driving. Geometric and semantic scene understanding, involving 3D point clouds, is essential for advancing autonomous driving technologies. However, significant challenges remain, particularly in improving the overall accuracy (e.g., segmentation accuracy, depth estimation accuracy, etc.) and efficiency of these systems. To address the challenge in terms of accuracy related to LiDAR-based tasks, we present DurLAR, the first high-fidelity 128-channel 3D LiDAR dataset featuring panoramic ambient (near infrared) and reflectivity imagery. To improve efficiency in 3D segmentation while ensuring the accuracy, we propose a novel pipeline that employs a smaller architecture, requiring fewer ground-truth annotations while achieving superior segmentation accuracy compared to contemporary approaches. To improve the segmentation accuracy, we introduce Range-Aware Pointwise Distance Distribution (RAPiD) features and the associated RAPiD-Seg architecture. All contributions have been accepted by peer-reviewed conferences, underscoring the advancements in both accuracy and efficiency in 3D LiDAR applications for autonomous driving. Full abstract: this https URL.</li>
</ul>

<h3>Title: Dual Low-Rank Adaptation for Continual Learning with Pre-Trained Models</h3>
<ul>
<li><strong>Authors: </strong>Huancheng Chen, Jingtao Li, Nidham Gazagnadou, Weiming Zhuang, Chen Chen, Lingjuan Lyu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00623">https://arxiv.org/abs/2411.00623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00623">https://arxiv.org/pdf/2411.00623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00623]] Dual Low-Rank Adaptation for Continual Learning with Pre-Trained Models(https://arxiv.org/abs/2411.00623)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In the era of foundation models, we revisit continual learning~(CL), which aims to enable vision transformers (ViTs) to learn new tasks over time. However, as the scale of these models increases, catastrophic forgetting remains a persistent challenge, particularly in the presence of significant domain shifts across tasks. Recent studies highlight a crossover between CL techniques and parameter-efficient fine-tuning (PEFT), which focuses on fine-tuning only a small set of trainable parameters to adapt to downstream tasks, such as low-rank adaptation (LoRA). While LoRA achieves faster convergence and requires fewer trainable parameters, it has seldom been explored in the context of continual learning. To address this gap, we propose a novel PEFT-CL method called Dual Low-Rank Adaptation (DualLoRA), which introduces both an orthogonal LoRA adapter and a residual LoRA adapter parallel to pre-trained weights in each layer. These components are orchestrated by a dynamic memory mechanism to strike a balance between stability and plasticity. The orthogonal LoRA adapter's parameters are updated in an orthogonal subspace of previous tasks to mitigate catastrophic forgetting, while the residual LoRA adapter's parameters are updated in the residual subspace spanned by task-specific bases without interaction across tasks, offering complementary capabilities for fine-tuning new tasks. On ViT-based models, we demonstrate that DualLoRA offers significant advantages in accuracy, inference speed, and memory efficiency over existing CL methods across multiple benchmarks.</li>
</ul>

<h3>Title: ZIM: Zero-Shot Image Matting for Anything</h3>
<ul>
<li><strong>Authors: </strong>Beomyoung Kim, Chanyong Shin, Joonhyun Jeong, Hyungsik Jung, Se-Yun Lee, Sewhan Chun, Dong-Hyun Hwang, Joonsang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00626">https://arxiv.org/abs/2411.00626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00626">https://arxiv.org/pdf/2411.00626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00626]] ZIM: Zero-Shot Image Matting for Anything(https://arxiv.org/abs/2411.00626)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The recent segmentation foundation model, Segment Anything Model (SAM), exhibits strong zero-shot segmentation capabilities, but it falls short in generating fine-grained precise masks. To address this limitation, we propose a novel zero-shot image matting model, called ZIM, with two key contributions: First, we develop a label converter that transforms segmentation labels into detailed matte labels, constructing the new SA1B-Matte dataset without costly manual annotations. Training SAM with this dataset enables it to generate precise matte masks while maintaining its zero-shot capability. Second, we design the zero-shot matting model equipped with a hierarchical pixel decoder to enhance mask representation, along with a prompt-aware masked attention mechanism to improve performance by enabling the model to focus on regions specified by visual prompts. We evaluate ZIM using the newly introduced MicroMat-3K test set, which contains high-quality micro-level matte labels. Experimental results show that ZIM outperforms existing methods in fine-grained mask generation and zero-shot generalization. Furthermore, we demonstrate the versatility of ZIM in various downstream tasks requiring precise masks, such as image inpainting and 3D NeRF. Our contributions provide a robust foundation for advancing zero-shot matting and its downstream applications across a wide range of computer vision tasks. The code is available at \url{this https URL}.</li>
</ul>

<h3>Title: STAA: Spatio-Temporal Attention Attribution for Real-Time Interpreting Transformer-based Video Models</h3>
<ul>
<li><strong>Authors: </strong>Zerui Wang, Yan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00630">https://arxiv.org/abs/2411.00630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00630">https://arxiv.org/pdf/2411.00630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00630]] STAA: Spatio-Temporal Attention Attribution for Real-Time Interpreting Transformer-based Video Models(https://arxiv.org/abs/2411.00630)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based models have achieved state-of-the-art performance in various computer vision tasks, including image and video analysis. However, Transformer's complex architecture and black-box nature pose challenges for explainability, a crucial aspect for real-world applications and scientific inquiry. Current Explainable AI (XAI) methods can only provide one-dimensional feature importance, either spatial or temporal explanation, with significant computational complexity. This paper introduces STAA (Spatio-Temporal Attention Attribution), an XAI method for interpreting video Transformer models. Differ from traditional methods that separately apply image XAI techniques for spatial features or segment contribution analysis for temporal aspects, STAA offers both spatial and temporal information simultaneously from attention values in Transformers. The study utilizes the Kinetics-400 dataset, a benchmark collection of 400 human action classes used for action recognition research. We introduce metrics to quantify explanations. We also apply optimization to enhance STAA's raw output. By implementing dynamic thresholding and attention focusing mechanisms, we improve the signal-to-noise ratio in our explanations, resulting in more precise visualizations and better evaluation results. In terms of computational overhead, our method requires less than 3\% of the computational resources of traditional XAI methods, making it suitable for real-time video XAI analysis applications. STAA contributes to the growing field of XAI by offering a method for researchers and practitioners to analyze Transformer models.</li>
</ul>

<h3>Title: Event-guided Low-light Video Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhen Yao, Mooi Choo Chuah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00639">https://arxiv.org/abs/2411.00639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00639">https://arxiv.org/pdf/2411.00639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00639]] Event-guided Low-light Video Semantic Segmentation(https://arxiv.org/abs/2411.00639)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Recent video semantic segmentation (VSS) methods have demonstrated promising results in well-lit environments. However, their performance significantly drops in low-light scenarios due to limited visibility and reduced contextual details. In addition, unfavorable low-light conditions make it harder to incorporate temporal consistency across video frames and thus, lead to video flickering effects. Compared with conventional cameras, event cameras can capture motion dynamics, filter out temporal-redundant information, and are robust to lighting conditions. To this end, we propose EVSNet, a lightweight framework that leverages event modality to guide the learning of a unified illumination-invariant representation. Specifically, we leverage a Motion Extraction Module to extract short-term and long-term temporal motions from event modality and a Motion Fusion Module to integrate image features and motion features adaptively. Furthermore, we use a Temporal Decoder to exploit video contexts and generate segmentation predictions. Such designs in EVSNet result in a lightweight architecture while achieving SOTA performance. Experimental results on 3 large-scale datasets demonstrate our proposed EVSNet outperforms SOTA methods with up to 11x higher parameter efficiency.</li>
</ul>

<h3>Title: Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction</h3>
<ul>
<li><strong>Authors: </strong>Houjing Wei, Hakaze Cho, Yuting Shi, Naoya Inoue</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00646">https://arxiv.org/abs/2411.00646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00646">https://arxiv.org/pdf/2411.00646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00646]] Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction(https://arxiv.org/abs/2411.00646)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Vision Large Language Models (VLLMs) usually take input as a concatenation of image token embeddings and text token embeddings and conduct causal modeling. However, their internal behaviors remain underexplored, raising the question of interaction among two types of tokens. To investigate such multimodal interaction during model inference, in this paper, we measure the contextualization among the hidden state vectors of tokens from different modalities. Our experiments uncover a four-phase inference dynamics of VLLMs against the depth of Transformer-based LMs, including (I) Alignment: In very early layers, contextualization emerges between modalities, suggesting a feature space alignment. (II) Intra-modal Encoding: In early layers, intra-modal contextualization is enhanced while inter-modal interaction is suppressed, suggesting a local encoding within modalities. (III) Inter-modal Encoding: In later layers, contextualization across modalities is enhanced, suggesting a deeper fusion across modalities. (IV) Output Preparation: In very late layers, contextualization is reduced globally, and hidden states are aligned towards the unembedding space.</li>
</ul>

<h3>Title: Towards High-fidelity Head Blending with Chroma Keying for Industrial Applications</h3>
<ul>
<li><strong>Authors: </strong>Hah Min Lew, Sahng-Min Yoo, Hyunwoo Kang, Gyeong-Moon Park</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00652">https://arxiv.org/abs/2411.00652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00652">https://arxiv.org/pdf/2411.00652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00652]] Towards High-fidelity Head Blending with Chroma Keying for Industrial Applications(https://arxiv.org/abs/2411.00652)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce an industrial Head Blending pipeline for the task of seamlessly integrating an actor's head onto a target body in digital content creation. The key challenge stems from discrepancies in head shape and hair structure, which lead to unnatural boundaries and blending artifacts. Existing methods treat foreground and background as a single task, resulting in suboptimal blending quality. To address this problem, we propose CHANGER, a novel pipeline that decouples background integration from foreground blending. By utilizing chroma keying for artifact-free background generation and introducing Head shape and long Hair augmentation ($H^2$ augmentation) to simulate a wide range of head shapes and hair styles, CHANGER improves generalization on innumerable various real-world cases. Furthermore, our Foreground Predictive Attention Transformer (FPAT) module enhances foreground blending by predicting and focusing on key head and body regions. Quantitative and qualitative evaluations on benchmark datasets demonstrate that our CHANGER outperforms state-of-the-art methods, delivering high-fidelity, industrial-grade results.</li>
</ul>

<h3>Title: Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Minki Kang, Sung Ju Hwang, Gibbeum Lee, Jaewoong Cho</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00686">https://arxiv.org/abs/2411.00686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00686">https://arxiv.org/pdf/2411.00686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00686]] Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection in Language Models(https://arxiv.org/abs/2411.00686)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) are increasingly deployed in specialized domains with continuously evolving knowledge, the need for timely and precise knowledge injection has become essential. Fine-tuning with paraphrased data is a common approach to enhance knowledge injection, yet it faces two significant challenges: high computational costs due to repetitive external model usage and limited sample diversity. To this end, we introduce LaPael, a latent-level paraphrasing method that applies input-dependent noise to early LLM layers. This approach enables diverse and semantically consistent augmentations directly within the model. Furthermore, it eliminates the recurring costs of paraphrase generation for each knowledge update. Our extensive experiments on question-answering benchmarks demonstrate that LaPael improves knowledge injection over standard fine-tuning and existing noise-based approaches. Additionally, combining LaPael with data-level paraphrasing further enhances performance.</li>
</ul>

<h3>Title: Towards Multi-Source Retrieval-Augmented Generation via Synergizing Reasoning and Preference-Driven Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Qingfei Zhao, Ruobing Wang, Xin Wang, Daren Zha, Nan Mu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00689">https://arxiv.org/abs/2411.00689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00689">https://arxiv.org/pdf/2411.00689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00689]] Towards Multi-Source Retrieval-Augmented Generation via Synergizing Reasoning and Preference-Driven Retrieval(https://arxiv.org/abs/2411.00689)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a reliable external knowledge augmentation technique to mitigate hallucination issues and parameterized knowledge limitations in Large Language Models (LLMs). Existing Adaptive RAG (ARAG) systems struggle to effectively explore multiple retrieval sources due to their inability to select the right source at the right time. To address this, we propose a multi-source ARAG framework, termed MSPR, which synergizes reasoning and preference-driven retrieval to adaptive decide "when and what to retrieve" and "which retrieval source to use". To better adapt to retrieval sources of differing characteristics, we also employ retrieval action adjustment and answer feedback strategy. They enable our framework to fully explore the high-quality primary source while supplementing it with secondary sources at the right time. Extensive and multi-dimensional experiments conducted on three datasets demonstrate the superiority and effectiveness of MSPR.</li>
</ul>

<h3>Title: Leveraging Large Language Models for Code-Mixed Data Augmentation in Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Linda Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00691">https://arxiv.org/abs/2411.00691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00691">https://arxiv.org/pdf/2411.00691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00691]] Leveraging Large Language Models for Code-Mixed Data Augmentation in Sentiment Analysis(https://arxiv.org/abs/2411.00691)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Code-mixing (CM), where speakers blend languages within a single expression, is prevalent in multilingual societies but poses challenges for natural language processing due to its complexity and limited data. We propose using a large language model to generate synthetic CM data, which is then used to enhance the performance of task-specific models for CM sentiment analysis. Our results show that in Spanish-English, synthetic data improved the F1 score by 9.32%, outperforming previous augmentation techniques. However, in Malayalam-English, synthetic data only helped when the baseline was low; with strong natural data, additional synthetic data offered little benefit. Human evaluation confirmed that this approach is a simple, cost-effective way to generate natural-sounding CM sentences, particularly beneficial for low baselines. Our findings suggest that few-shot prompting of large language models is a promising method for CM data augmentation and has significant impact on improving sentiment analysis, an important element in the development of social influence systems.</li>
</ul>

<h3>Title: Wasserstein Flow Matching: Generative modeling over families of distributions</h3>
<ul>
<li><strong>Authors: </strong>Doron Haviv, Aram-Alexandre Pooladian, Dana Pe'er, Brandon Amos</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00698">https://arxiv.org/abs/2411.00698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00698">https://arxiv.org/pdf/2411.00698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00698]] Wasserstein Flow Matching: Generative modeling over families of distributions(https://arxiv.org/abs/2411.00698)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative modeling typically concerns the transport of a single source distribution to a single target distribution by learning (i.e., regressing onto) simple probability flows. However, in modern data-driven fields such as computer graphics and single-cell genomics, samples (say, point-clouds) from datasets can themselves be viewed as distributions (as, say, discrete measures). In these settings, the standard generative modeling paradigm of flow matching would ignore the relevant geometry of the samples. To remedy this, we propose \emph{Wasserstein flow matching} (WFM), which appropriately lifts flow matching onto families of distributions by appealing to the Riemannian nature of the Wasserstein geometry. Our algorithm leverages theoretical and computational advances in (entropic) optimal transport, as well as the attention mechanism in our neural network architecture. We present two novel algorithmic contributions. First, we demonstrate how to perform generative modeling over Gaussian distributions, where we generate representations of granular cell states from single-cell genomics data. Secondly, we show that WFM can learn flows between high-dimensional and variable sized point-clouds and synthesize cellular microenvironments from spatial transcriptomics datasets. Code is available at [WassersteinFlowMatching](this https URL).</li>
</ul>

<h3>Title: Debiasify: Self-Distillation for Unsupervised Bias Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Nourhan Bayasi, Jamil Fayyad, Ghassan Hamarneh, Rafeef Garbi, Homayoun Najjaran</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00711">https://arxiv.org/abs/2411.00711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00711">https://arxiv.org/pdf/2411.00711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00711]] Debiasify: Self-Distillation for Unsupervised Bias Mitigation(https://arxiv.org/abs/2411.00711)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Simplicity bias poses a significant challenge in neural networks, often leading models to favor simpler solutions and inadvertently learn decision rules influenced by spurious correlations. This results in biased models with diminished generalizability. While many current approaches depend on human supervision, obtaining annotations for various bias attributes is often impractical. To address this, we introduce Debiasify, a novel self-distillation approach that requires no prior knowledge about the nature of biases. Our method leverages a new distillation loss to transfer knowledge within the network, from deeper layers containing complex, highly-predictive features to shallower layers with simpler, attribute-conditioned features in an unsupervised manner. This enables Debiasify to learn robust, debiased representations that generalize effectively across diverse biases and datasets, improving both worst-group performance and overall accuracy. Extensive experiments on computer vision and medical imaging benchmarks demonstrate the effectiveness of our approach, significantly outperforming previous unsupervised debiasing methods (e.g., a 10.13% improvement in worst-group accuracy for Wavy Hair classification in CelebA) and achieving comparable or superior performance to supervised approaches. Our code is publicly available at the following link: Debiasify.</li>
</ul>

<h3>Title: B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable</h3>
<ul>
<li><strong>Authors: </strong>Shreyash Arya, Sukrut Rao, Moritz Böhle, Bernt Schiele</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00715">https://arxiv.org/abs/2411.00715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00715">https://arxiv.org/pdf/2411.00715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00715]] B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable(https://arxiv.org/abs/2411.00715)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>B-cos Networks have been shown to be effective for obtaining highly human interpretable explanations of model decisions by architecturally enforcing stronger alignment between inputs and weight. B-cos variants of convolutional networks (CNNs) and vision transformers (ViTs), which primarily replace linear layers with B-cos transformations, perform competitively to their respective standard variants while also yielding explanations that are faithful by design. However, it has so far been necessary to train these models from scratch, which is increasingly infeasible in the era of large, pre-trained foundation models. In this work, inspired by the architectural similarities in standard DNNs and B-cos networks, we propose 'B-cosification', a novel approach to transform existing pre-trained models to become inherently interpretable. We perform a thorough study of design choices to perform this conversion, both for convolutional neural networks and vision transformers. We find that B-cosification can yield models that are on par with B-cos models trained from scratch in terms of interpretability, while often outperforming them in terms of classification performance at a fraction of the training cost. Subsequently, we apply B-cosification to a pretrained CLIP model, and show that, even with limited data and compute cost, we obtain a B-cosified version that is highly interpretable and competitive on zero shot performance across a variety of datasets. We release our code and pre-trained model weights at this https URL.</li>
</ul>

<h3>Title: PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals</h3>
<ul>
<li><strong>Authors: </strong>Saurav R. Pandey, Aaqib Saeed, Harlin Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00718">https://arxiv.org/abs/2411.00718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00718">https://arxiv.org/pdf/2411.00718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00718]] PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals(https://arxiv.org/abs/2411.00718)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Pediatric sleep is an important but often overlooked area in health informatics. We present PedSleepMAE, a generative model that fully leverages multimodal pediatric sleep signals including multichannel EEGs, respiratory signals, EOGs and EMG. This masked autoencoder-based model performs comparably to supervised learning models in sleep scoring and in the detection of apnea, hypopnea, EEG arousal and oxygen desaturation. Its embeddings are also shown to capture subtle differences in sleep signals coming from a rare genetic disorder. Furthermore, PedSleepMAE generates realistic signals that can be used for sleep segment retrieval, outlier detection, and missing channel imputation. This is the first general-purpose generative model trained on multiple types of pediatric sleep signals.</li>
</ul>

<h3>Title: Token-level Proximal Policy Optimization for Query Generation</h3>
<ul>
<li><strong>Authors: </strong>Yichen Ouyang, Lu Wang, Fangkai Yang, Pu Zhao, Chenghua Huang, Jianfeng Liu, Bochen Pang, Yaming Yang, Yuefeng Zhan, Hao Sun, Qingwei Lin, Saravan Rajmohan, Weiwei Deng, Dongmei Zhang, Feng Sun, Qi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00722">https://arxiv.org/abs/2411.00722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00722">https://arxiv.org/pdf/2411.00722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00722]] Token-level Proximal Policy Optimization for Query Generation(https://arxiv.org/abs/2411.00722)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Query generation is a critical task for web search engines (e.g. Google, Bing) and recommendation systems. Recently, state-of-the-art query generation methods leverage Large Language Models (LLMs) for their strong capabilities in context understanding and text generation. However, they still face challenges in generating high-quality queries in terms of inferring user intent based on their web search interaction history. In this paper, we propose Token-level Proximal Policy Optimization (TPPO), a noval approach designed to empower LLMs perform better in query generation through fine-tuning. TPPO is based on the Reinforcement Learning from AI Feedback (RLAIF) paradigm, consisting of a token-level reward model and a token-level proximal policy optimization module to address the sparse reward challenge in traditional RLAIF frameworks. To evaluate the effectiveness and robustness of TPPO, we conducted experiments on both open-source dataset and an industrial dataset that was collected from a globally-used search engine. The experimental results demonstrate that TPPO significantly improves the performance of query generation for LLMs and outperforms its existing competitors.</li>
</ul>

<h3>Title: Exploring Multi-Modality Dynamics: Insights and Challenges in Multimodal Fusion for Biomedical Tasks</h3>
<ul>
<li><strong>Authors: </strong>Laura Wenderoth</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00725">https://arxiv.org/abs/2411.00725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00725">https://arxiv.org/pdf/2411.00725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00725]] Exploring Multi-Modality Dynamics: Insights and Challenges in Multimodal Fusion for Biomedical Tasks(https://arxiv.org/abs/2411.00725)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>This paper investigates the MM dynamics approach proposed by Han et al. (2022) for multi-modal fusion in biomedical classification tasks. The MM dynamics algorithm integrates feature-level and modality-level informativeness to dynamically fuse modalities for improved classification performance. However, our analysis reveals several limitations and challenges in replicating and extending the results of MM dynamics. We found that feature informativeness improves performance and explainability, while modality informativeness does not provide significant advantages and can lead to performance degradation. Based on these results, we have extended feature informativeness to image data, resulting in the development of Image MM dynamics. Although this approach showed promising qualitative results, it did not outperform baseline methods quantitatively.</li>
</ul>

<h3>Title: SPRING Lab IITM's submission to Low Resource Indic Language Translation Shared Task</h3>
<ul>
<li><strong>Authors: </strong>Hamees Sayed, Advait Joglekar, Srinivasan Umesh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00727">https://arxiv.org/abs/2411.00727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00727">https://arxiv.org/pdf/2411.00727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00727]] SPRING Lab IITM's submission to Low Resource Indic Language Translation Shared Task(https://arxiv.org/abs/2411.00727)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We develop a robust translation model for four low-resource Indic languages: Khasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive pipeline from data collection and preprocessing to training and evaluation, leveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To address the scarcity of bilingual data, we use back-translation techniques on monolingual datasets for Mizo and Khasi, significantly expanding our training corpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and Manipuri, achieving improved performance over the baseline. For Khasi, which is not supported by the NLLB model, we introduce special tokens and train the model on our Khasi corpus. Our training involves masked language modelling, followed by fine-tuning for English-to-Indic and Indic-to-English translations.</li>
</ul>

<h3>Title: MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced Molecular Property Prediction</h3>
<ul>
<li><strong>Authors: </strong>Carl Edwards, Ziqing Lu, Ehsan Hajiramezanali, Tommaso Biancalani, Heng Ji, Gabriele Scalia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00737">https://arxiv.org/abs/2411.00737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00737">https://arxiv.org/pdf/2411.00737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00737]] MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced Molecular Property Prediction(https://arxiv.org/abs/2411.00737)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Bridging biomolecular modeling with natural language information, particularly through large language models (LLMs), has recently emerged as a promising interdisciplinary research area. LLMs, having been trained on large corpora of scientific documents, demonstrate significant potential in understanding and reasoning about biomolecules by providing enriched contextual and domain knowledge. However, the extent to which LLM-driven insights can improve performance on complex predictive tasks (e.g., toxicity) remains unclear. Further, the extent to which relevant knowledge can be extracted from LLMs also remains unknown. In this study, we present Molecule Caption Arena: the first comprehensive benchmark of LLM-augmented molecular property prediction. We evaluate over twenty LLMs, including both general-purpose and domain-specific molecule captioners, across diverse prediction tasks. To this goal, we introduce a novel, battle-based rating system. Our findings confirm the ability of LLM-extracted knowledge to enhance state-of-the-art molecular representations, with notable model-, prompt-, and dataset-specific variations. Code, resources, and data are available at this http URL.</li>
</ul>

<h3>Title: Decoding Dark Matter: Specialized Sparse Autoencoders for Interpreting Rare Concepts in Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Aashiq Muhamed, Mona Diab, Virginia Smith</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00743">https://arxiv.org/abs/2411.00743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00743">https://arxiv.org/pdf/2411.00743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00743]] Decoding Dark Matter: Specialized Sparse Autoencoders for Interpreting Rare Concepts in Foundation Models(https://arxiv.org/abs/2411.00743)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Understanding and mitigating the potential risks associated with foundation models (FMs) hinges on developing effective interpretability methods. Sparse Autoencoders (SAEs) have emerged as a promising tool for disentangling FM representations, but they struggle to capture rare, yet crucial concepts in the data. We introduce Specialized Sparse Autoencoders (SSAEs), designed to illuminate these elusive dark matter features by focusing on specific subdomains. We present a practical recipe for training SSAEs, demonstrating the efficacy of dense retrieval for data selection and the benefits of Tilted Empirical Risk Minimization as a training objective to improve concept recall. Our evaluation of SSAEs on standard metrics, such as downstream perplexity and $L_0$ sparsity, show that they effectively capture subdomain tail concepts, exceeding the capabilities of general-purpose SAEs. We showcase the practical utility of SSAEs in a case study on the Bias in Bios dataset, where SSAEs achieve a 12.5\% increase in worst-group classification accuracy when applied to remove spurious gender information. SSAEs provide a powerful new lens for peering into the inner workings of FMs in subdomains.</li>
</ul>

<h3>Title: Private, Augmentation-Robust and Task-Agnostic Data Valuation Approach for Data Marketplace</h3>
<ul>
<li><strong>Authors: </strong>Tayyebeh Jahani-Nezhad, Parsa Moradi, Mohammad Ali Maddah-Ali, Giuseppe Caire</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00745">https://arxiv.org/abs/2411.00745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00745">https://arxiv.org/pdf/2411.00745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00745]] Private, Augmentation-Robust and Task-Agnostic Data Valuation Approach for Data Marketplace(https://arxiv.org/abs/2411.00745)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Evaluating datasets in data marketplaces, where the buyer aim to purchase valuable data, is a critical challenge. In this paper, we introduce an innovative task-agnostic data valuation method called PriArTa which is an approach for computing the distance between the distribution of the buyer's existing dataset and the seller's dataset, allowing the buyer to determine how effectively the new data can enhance its dataset. PriArTa is communication-efficient, enabling the buyer to evaluate datasets without needing access to the entire dataset from each seller. Instead, the buyer requests that sellers perform specific preprocessing on their data and then send back the results. Using this information and a scoring metric, the buyer can evaluate the dataset. The preprocessing is designed to allow the buyer to compute the score while preserving the privacy of each seller's dataset, mitigating the risk of information leakage before the purchase. A key feature of PriArTa is its robustness to common data transformations, ensuring consistent value assessment and reducing the risk of purchasing redundant data. The effectiveness of PriArTa is demonstrated through experiments on real-world image datasets, showing its ability to perform privacy-preserving, augmentation-robust data valuation in data marketplaces.</li>
</ul>

<h3>Title: Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling</h3>
<ul>
<li><strong>Authors: </strong>Yiwen Ding, Zhiheng Xi, Wei He, Zhuoyuan Li, Yitao Zhai, Xiaowei Shi, Xunliang Cai, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00750">https://arxiv.org/abs/2411.00750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00750">https://arxiv.org/pdf/2411.00750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00750]] Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling(https://arxiv.org/abs/2411.00750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-improvement methods enable large language models (LLMs) to generate solutions themselves and iteratively train on filtered, high-quality rationales. This process proves effective and reduces the reliance on human supervision in LLMs' reasoning, but the performance soon plateaus. We delve into the process and find that models tend to over-sample on easy queries and under-sample on queries they have yet to master. As iterations proceed, this imbalance in sampling is exacerbated, leading to a long-tail distribution where solutions to difficult queries almost diminish. This phenomenon limits the performance gain of self-improving models. A straightforward solution is brute-force sampling to balance the distribution, which significantly raises computational costs. In this paper, we introduce Guided Self-Improvement (GSI), a strategy aimed at improving the efficiency of sampling challenging heavy-tailed data. It leverages Socratic-style guidance signals to help LLM reasoning with complex queries, reducing the exploration effort and minimizing computational overhead. Experiments on four models across diverse mathematical tasks show that GSI strikes a balance between performance and efficiency, while also being effective on held-out tasks.</li>
</ul>

<h3>Title: Hierarchical Transformer for Electrocardiogram Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Xiaoya Tang, Jake Berquist, Benjamin A. Steinberg, Tolga Tasdizen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00755">https://arxiv.org/abs/2411.00755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00755">https://arxiv.org/pdf/2411.00755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00755]] Hierarchical Transformer for Electrocardiogram Diagnosis(https://arxiv.org/abs/2411.00755)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformers, originally prominent in NLP and computer vision, are now being adapted for ECG signal analysis. This paper introduces a novel hierarchical transformer architecture that segments the model into multiple stages by assessing the spatial size of the embeddings, thus eliminating the need for additional downsampling strategies or complex attention designs. A classification token aggregates information across feature scales, facilitating interactions between different stages of the transformer. By utilizing depth-wise convolutions in a six-layer convolutional encoder, our approach preserves the relationships between different ECG leads. Moreover, an attention gate mechanism learns associations among the leads prior to classification. This model adapts flexibly to various embedding networks and input sizes while enhancing the interpretability of transformers in ECG signal analysis.</li>
</ul>

<h3>Title: Minibatch Optimal Transport and Perplexity Bound Estimation in Discrete Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Etrit Haxholli, Yeti Z. Gürbüz, Oğul Can, Eli Waxman</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00759">https://arxiv.org/abs/2411.00759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00759">https://arxiv.org/pdf/2411.00759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00759]] Minibatch Optimal Transport and Perplexity Bound Estimation in Discrete Flow Matching(https://arxiv.org/abs/2411.00759)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Outperforming autoregressive models on categorical data distributions, such as textual data, remains challenging for continuous diffusion and flow models. Discrete flow matching, a recent framework for modeling categorical data, has shown competitive performance with autoregressive models. Despite its similarities with continuous flow matching, the rectification strategy applied in the continuous version does not directly extend to the discrete one due to the inherent stochasticity of discrete paths. This limitation necessitates exploring alternative methods to minimize state transitions during generation. To address this, we propose a dynamic-optimal-transport-like minimization objective for discrete flows with convex interpolants and derive its equivalent Kantorovich formulation. The latter defines transport cost solely in terms of inter-state similarity and is optimized using a minibatch strategy. Another limitation we address in the discrete flow framework is model evaluation. Unlike continuous flows, wherein the instantaneous change of variables enables density estimation, discrete models lack a similar mechanism due to the inherent non-determinism and discontinuity of their paths. To alleviate this issue, we propose an upper bound on the perplexity of discrete flow models, enabling performance evaluation and comparison with other methods.</li>
</ul>

<h3>Title: Face Anonymization Made Simple</h3>
<ul>
<li><strong>Authors: </strong>Han-Wei Kung, Tuomas Varanka, Sanjay Saha, Terence Sim, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00762">https://arxiv.org/abs/2411.00762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00762">https://arxiv.org/pdf/2411.00762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00762]] Face Anonymization Made Simple(https://arxiv.org/abs/2411.00762)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Current face anonymization techniques often depend on identity loss calculated by face recognition models, which can be inaccurate and unreliable. Additionally, many methods require supplementary data such as facial landmarks and masks to guide the synthesis process. In contrast, our approach uses diffusion models with only a reconstruction loss, eliminating the need for facial landmarks or masks while still producing images with intricate, fine-grained details. We validated our results on two public benchmarks through both quantitative and qualitative evaluations. Our model achieves state-of-the-art performance in three key areas: identity anonymization, facial attribute preservation, and image quality. Beyond its primary function of anonymization, our model can also perform face swapping tasks by incorporating an additional facial image as input, demonstrating its versatility and potential for diverse applications. Our code and models are available at this https URL .</li>
</ul>

<h3>Title: GameGen-X: Interactive Open-world Game Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Haoxuan Che, Xuanhua He, Quande Liu, Cheng Jin, Hao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00769">https://arxiv.org/abs/2411.00769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00769">https://arxiv.org/pdf/2411.00769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00769]] GameGen-X: Interactive Open-world Game Video Generation(https://arxiv.org/abs/2411.00769)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce GameGen-X, the first diffusion transformer model specifically designed for both generating and interactively controlling open-world game videos. This model facilitates high-quality, open-domain generation by simulating an extensive array of game engine features, such as innovative characters, dynamic environments, complex actions, and diverse events. Additionally, it provides interactive controllability, predicting and altering future content based on the current clip, thus allowing for gameplay simulation. To realize this vision, we first collected and built an Open-World Video Game Dataset from scratch. It is the first and largest dataset for open-world game video generation and control, which comprises over a million diverse gameplay video clips sampling from over 150 games with informative captions from GPT-4o. GameGen-X undergoes a two-stage training process, consisting of foundation model pre-training and instruction tuning. Firstly, the model was pre-trained via text-to-video generation and video continuation, endowing it with the capability for long-sequence, high-quality open-domain game video generation. Further, to achieve interactive controllability, we designed InstructNet to incorporate game-related multi-modal control signal experts. This allows the model to adjust latent representations based on user inputs, unifying character interaction and scene content control for the first time in video generation. During instruction tuning, only the InstructNet is updated while the pre-trained foundation model is frozen, enabling the integration of interactive controllability without loss of diversity and quality of generated video content.</li>
</ul>

<h3>Title: Dimension-free Private Mean Estimation for Anisotropic Distributions</h3>
<ul>
<li><strong>Authors: </strong>Yuval Dagan, Michael I. Jordan, Xuelin Yang, Lydia Zakynthinou, Nikita Zhivotovskiy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00775">https://arxiv.org/abs/2411.00775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00775">https://arxiv.org/pdf/2411.00775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00775]] Dimension-free Private Mean Estimation for Anisotropic Distributions(https://arxiv.org/abs/2411.00775)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We present differentially private algorithms for high-dimensional mean estimation. Previous private estimators on distributions over $\mathbb{R}^d$ suffer from a curse of dimensionality, as they require $\Omega(d^{1/2})$ samples to achieve non-trivial error, even in cases where $O(1)$ samples suffice without privacy. This rate is unavoidable when the distribution is isotropic, namely, when the covariance is a multiple of the identity matrix, or when accuracy is measured with respect to the affine-invariant Mahalanobis distance. Yet, real-world data is often highly anisotropic, with signals concentrated on a small number of principal components. We develop estimators that are appropriate for such signals$\unicode{x2013}$our estimators are $(\varepsilon,\delta)$-differentially private and have sample complexity that is dimension-independent for anisotropic subgaussian distributions. Given $n$ samples from a distribution with known covariance-proxy $\Sigma$ and unknown mean $\mu$, we present an estimator $\hat{\mu}$ that achieves error $\|\hat{\mu}-\mu\|_2\leq \alpha$, as long as $n\gtrsim\mathrm{tr}(\Sigma)/\alpha^2+ \mathrm{tr}(\Sigma^{1/2})/(\alpha\varepsilon)$. In particular, when $\pmb{\sigma}^2=(\sigma_1^2, \ldots, \sigma_d^2)$ are the singular values of $\Sigma$, we have $\mathrm{tr}(\Sigma)=\|\pmb{\sigma}\|_2^2$ and $\mathrm{tr}(\Sigma^{1/2})=\|\pmb{\sigma}\|_1$, and hence our bound avoids dimension-dependence when the signal is concentrated in a few principal components. We show that this is the optimal sample complexity for this task up to logarithmic factors. Moreover, for the case of unknown covariance, we present an algorithm whose sample complexity has improved dependence on the dimension, from $d^{1/2}$ to $d^{1/4}$.</li>
</ul>

<h3>Title: Randomized Autoregressive Visual Generation</h3>
<ul>
<li><strong>Authors: </strong>Qihang Yu, Ju He, Xueqing Deng, Xiaohui Shen, Liang-Chieh Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00776">https://arxiv.org/abs/2411.00776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00776">https://arxiv.org/pdf/2411.00776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00776]] Randomized Autoregressive Visual Generation(https://arxiv.org/abs/2411.00776)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents Randomized AutoRegressive modeling (RAR) for visual generation, which sets a new state-of-the-art performance on the image generation task while maintaining full compatibility with language modeling frameworks. The proposed RAR is simple: during a standard autoregressive training process with a next-token prediction objective, the input sequence-typically ordered in raster form-is randomly permuted into different factorization orders with a probability r, where r starts at 1 and linearly decays to 0 over the course of training. This annealing training strategy enables the model to learn to maximize the expected likelihood over all factorization orders and thus effectively improve the model's capability of modeling bidirectional contexts. Importantly, RAR preserves the integrity of the autoregressive modeling framework, ensuring full compatibility with language modeling while significantly improving performance in image generation. On the ImageNet-256 benchmark, RAR achieves an FID score of 1.48, not only surpassing prior state-of-the-art autoregressive image generators but also outperforming leading diffusion-based and masked transformer-based methods. Code and models will be made available at this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
