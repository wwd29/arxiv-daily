<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces. (arXiv:2306.13091v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13091">http://arxiv.org/abs/2306.13091</a></li>
<li>Code URL: <a href="https://github.com/koushiksrivats/face_attribute_attack">https://github.com/koushiksrivats/face_attribute_attack</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13091] Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces](http://arxiv.org/abs/2306.13091) #security</code></li>
<li>Summary: <p>The ability of generative models to produce highly realistic synthetic face
images has raised security and ethical concerns. As a first line of defense
against such fake faces, deep learning based forensic classifiers have been
developed. While these forensic models can detect whether a face image is
synthetic or real with high accuracy, they are also vulnerable to adversarial
attacks. Although such attacks can be highly successful in evading detection by
forensic classifiers, they introduce visible noise patterns that are detectable
through careful human scrutiny. Additionally, these attacks assume access to
the target model(s) which may not always be true. Attempts have been made to
directly perturb the latent space of GANs to produce adversarial fake faces
that can circumvent forensic classifiers. In this work, we go one step further
and show that it is possible to successfully generate adversarial fake faces
with a specified set of attributes (e.g., hair color, eye size, race, gender,
etc.). To achieve this goal, we leverage the state-of-the-art generative model
StyleGAN with disentangled representations, which enables a range of
modifications without leaving the manifold of natural images. We propose a
framework to search for adversarial latent codes within the feature space of
StyleGAN, where the search can be guided either by a text prompt or a reference
image. We also propose a meta-learning based optimization strategy to achieve
transferable performance on unknown target models. Extensive experiments
demonstrate that the proposed approach can produce semantically manipulated
adversarial fake faces, which are true to the specified attribute set and can
successfully fool forensic face classifiers, while remaining undetectable by
humans. Code: https://github.com/koushiksrivats/face_attribute_attack.
</p></li>
</ul>

<h3>Title: On Evaluation of Document Classification using RVL-CDIP. (arXiv:2306.12550v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12550">http://arxiv.org/abs/2306.12550</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12550] On Evaluation of Document Classification using RVL-CDIP](http://arxiv.org/abs/2306.12550) #security</code></li>
<li>Summary: <p>The RVL-CDIP benchmark is widely used for measuring performance on the task
of document classification. Despite its widespread use, we reveal several
undesirable characteristics of the RVL-CDIP benchmark. These include (1)
substantial amounts of label noise, which we estimate to be 8.1% (ranging
between 1.6% to 16.9% per document category); (2) presence of many ambiguous or
multi-label documents; (3) a large overlap between test and train splits, which
can inflate model performance metrics; and (4) presence of sensitive
personally-identifiable information like US Social Security numbers (SSNs). We
argue that there is a risk in using RVL-CDIP for benchmarking document
classifiers, as its limited scope, presence of errors (state-of-the-art models
now achieve accuracy error rates that are within our estimated label error
rate), and lack of diversity make it less than ideal for benchmarking. We
further advocate for the creation of a new document classification benchmark,
and provide recommendations for what characteristics such a resource should
include.
</p></li>
</ul>

<h3>Title: On the Construction of Near-MDS Matrices. (arXiv:2306.12791v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12791">http://arxiv.org/abs/2306.12791</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12791] On the Construction of Near-MDS Matrices](http://arxiv.org/abs/2306.12791) #security</code></li>
<li>Summary: <p>The optimal branch number of MDS matrices makes them a preferred choice for
designing diffusion layers in many block ciphers and hash functions. However,
in lightweight cryptography, Near-MDS (NMDS) matrices with sub-optimal branch
numbers offer a better balance between security and efficiency as a diffusion
layer, compared to MDS matrices. In this paper, we study NMDS matrices,
exploring their construction in both recursive and nonrecursive settings. We
provide several theoretical results and explore the hardware efficiency of the
construction of NMDS matrices. Additionally, we make comparisons between the
results of NMDS and MDS matrices whenever possible. For the recursive approach,
we study the DLS matrices and provide some theoretical results on their use.
Some of the results are used to restrict the search space of the DLS matrices.
We also show that over a field of characteristic 2, any sparse matrix of order
$n\geq 4$ with fixed XOR value of 1 cannot be an NMDS when raised to a power of
$k\leq n$. Following that, we use the generalized DLS (GDLS) matrices to
provide some lightweight recursive NMDS matrices of several orders that perform
better than the existing matrices in terms of hardware cost or the number of
iterations. For the nonrecursive construction of NMDS matrices, we study
various structures, such as circulant and left-circulant matrices, and their
generalizations: Toeplitz and Hankel matrices. In addition, we prove that
Toeplitz matrices of order $n>4$ cannot be simultaneously NMDS and involutory
over a field of characteristic 2. Finally, we use GDLS matrices to provide some
lightweight NMDS matrices that can be computed in one clock cycle. The proposed
nonrecursive NMDS matrices of orders 4, 5, 6, 7, and 8 can be implemented with
24, 50, 65, 96, and 108 XORs over $\mathbb{F}_{2^4}$, respectively.
</p></li>
</ul>

<h3>Title: OptIForest: Optimal Isolation Forest for Anomaly Detection. (arXiv:2306.12703v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12703">http://arxiv.org/abs/2306.12703</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12703] OptIForest: Optimal Isolation Forest for Anomaly Detection](http://arxiv.org/abs/2306.12703) #security</code></li>
<li>Summary: <p>Anomaly detection plays an increasingly important role in various fields for
critical tasks such as intrusion detection in cybersecurity, financial risk
detection, and human health monitoring. A variety of anomaly detection methods
have been proposed, and a category based on the isolation forest mechanism
stands out due to its simplicity, effectiveness, and efficiency, e.g., iForest
is often employed as a state-of-the-art detector for real deployment. While the
majority of isolation forests use the binary structure, a framework LSHiForest
has demonstrated that the multi-fork isolation tree structure can lead to
better detection performance. However, there is no theoretical work answering
the fundamentally and practically important question on the optimal tree
structure for an isolation forest with respect to the branching factor. In this
paper, we establish a theory on isolation efficiency to answer the question and
determine the optimal branching factor for an isolation tree. Based on the
theoretical underpinning, we design a practical optimal isolation forest
OptIForest incorporating clustering based learning to hash which enables more
information to be learned from data for better isolation quality. The rationale
of our approach relies on a better bias-variance trade-off achieved by bias
reduction in OptIForest. Extensive experiments on a series of benchmarking
datasets for comparative and ablation studies demonstrate that our approach can
efficiently and robustly achieve better detection performance in general than
the state-of-the-arts including the deep learning based methods.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: DGC-GNN: Descriptor-free Geometric-Color Graph Neural Network for 2D-3D Matching. (arXiv:2306.12547v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12547">http://arxiv.org/abs/2306.12547</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12547] DGC-GNN: Descriptor-free Geometric-Color Graph Neural Network for 2D-3D Matching](http://arxiv.org/abs/2306.12547) #privacy</code></li>
<li>Summary: <p>Direct matching of 2D keypoints in an input image to a 3D point cloud of the
scene without requiring visual descriptors has garnered increased interest due
to its lower memory requirements, inherent privacy preservation, and reduced
need for expensive 3D model maintenance compared to visual descriptor-based
methods. However, existing algorithms often compromise on performance,
resulting in a significant deterioration compared to their descriptor-based
counterparts. In this paper, we introduce DGC-GNN, a novel algorithm that
employs a global-to-local Graph Neural Network (GNN) that progressively
exploits geometric and color cues to represent keypoints, thereby improving
matching robustness. Our global-to-local procedure encodes both Euclidean and
angular relations at a coarse level, forming the geometric embedding to guide
the local point matching. We evaluate DGC-GNN on both indoor and outdoor
datasets, demonstrating that it not only doubles the accuracy of the
state-of-the-art descriptor-free algorithm but, also, substantially narrows the
performance gap between descriptor-based and descriptor-free methods. The code
and trained models will be made publicly available.
</p></li>
</ul>

<h3>Title: Ladder Fine-tuning approach for SAM integrating complementary network. (arXiv:2306.12737v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12737">http://arxiv.org/abs/2306.12737</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12737] Ladder Fine-tuning approach for SAM integrating complementary network](http://arxiv.org/abs/2306.12737) #privacy</code></li>
<li>Summary: <p>Recently, foundation models have been introduced demonstrating various tasks
in the field of computer vision. These models such as Segment Anything Model
(SAM) are generalized models trained using huge datasets. Currently, ongoing
research focuses on exploring the effective utilization of these generalized
models for specific domains, such as medical imaging. However, in medical
imaging, the lack of training samples due to privacy concerns and other factors
presents a major challenge for applying these generalized models to medical
image segmentation task. To address this issue, the effective fine tuning of
these models is crucial to ensure their optimal utilization. In this study, we
propose to combine a complementary Convolutional Neural Network (CNN) along
with the standard SAM network for medical image segmentation. To reduce the
burden of fine tuning large foundation model and implement cost-efficient
trainnig scheme, we focus only on fine-tuning the additional CNN network and
SAM decoder part. This strategy significantly reduces trainnig time and
achieves competitive results on publicly available dataset. The code is
available at https://github.com/11yxk/SAM-LST.
</p></li>
</ul>

<h3>Title: Vec2Vec: A Compact Neural Network Approach for Transforming Text Embeddings with High Fidelity. (arXiv:2306.12689v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12689">http://arxiv.org/abs/2306.12689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12689] Vec2Vec: A Compact Neural Network Approach for Transforming Text Embeddings with High Fidelity](http://arxiv.org/abs/2306.12689) #privacy</code></li>
<li>Summary: <p>Vector embeddings have become ubiquitous tools for many language-related
tasks. A leading embedding model is OpenAI's text-ada-002 which can embed
approximately 6,000 words into a 1,536-dimensional vector. While powerful,
text-ada-002 is not open source and is only available via API. We trained a
simple neural network to convert open-source 768-dimensional MPNet embeddings
into text-ada-002 embeddings. We compiled a subset of 50,000 online food
reviews. We calculated MPNet and text-ada-002 embeddings for each review and
trained a simple neural network to for 75 epochs. The neural network was
designed to predict the corresponding text-ada-002 embedding for a given MPNET
embedding. Our model achieved an average cosine similarity of 0.932 on 10,000
unseen reviews in our held-out test dataset. We manually assessed the quality
of our predicted embeddings for vector search over text-ada-002-embedded
reviews. While not as good as real text-ada-002 embeddings, predicted
embeddings were able to retrieve highly relevant reviews. Our final model,
Vec2Vec, is lightweight (<80 MB) and fast. Future steps include training a
neural network with a more sophisticated architecture and a larger dataset of
paired embeddings to achieve greater performance. The ability to convert
between and align embedding spaces may be helpful for interoperability,
limiting dependence on proprietary models, protecting data privacy, reducing
costs, and offline operations.
</p></li>
</ul>

<h3>Title: XACML Extension for Graphs: Flexible Authorization Policy Specification and Datastore-independent Enforcement. (arXiv:2306.12819v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12819">http://arxiv.org/abs/2306.12819</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12819] XACML Extension for Graphs: Flexible Authorization Policy Specification and Datastore-independent Enforcement](http://arxiv.org/abs/2306.12819) #privacy</code></li>
<li>Summary: <p>The increasing use of graph-structured data for business- and
privacy-critical applications requires sophisticated, flexible and fine-grained
authorization and access control. Currently, role-based access control is
supported in graph databases, where access to objects is restricted via roles.
This does not take special properties of graphs into account such as vertices
and edges along the path between a given subject and resource. In previous
iterations of our research, we started to design an authorization policy
language and access control model, which considers the specification of graph
paths and enforces them in the multi-model database ArangoDB. Since this
approach is promising to consider graph characteristics in data protection, we
improve the language in this work to provide flexible path definitions and
specifying edges as protected resources. Furthermore, we introduce a method for
a datastore-independent policy enforcement. Besides discussing the latest work
in our XACML4G model, which is an extension to the Extensible Access Control
Markup Language (XACML), we demonstrate our prototypical implementation with a
real case and give an outlook on performance.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Auditing Predictive Models for Intersectional Biases. (arXiv:2306.13064v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13064">http://arxiv.org/abs/2306.13064</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13064] Auditing Predictive Models for Intersectional Biases](http://arxiv.org/abs/2306.13064) #protect</code></li>
<li>Summary: <p>Predictive models that satisfy group fairness criteria in aggregate for
members of a protected class, but do not guarantee subgroup fairness, could
produce biased predictions for individuals at the intersection of two or more
protected classes. To address this risk, we propose Conditional Bias Scan
(CBS), a flexible auditing framework for detecting intersectional biases in
classification models. CBS identifies the subgroup for which there is the most
significant bias against the protected class, as compared to the equivalent
subgroup in the non-protected class, and can incorporate multiple commonly used
fairness definitions for both probabilistic and binarized predictions. We show
that this methodology can detect previously unidentified intersectional and
contextual biases in the COMPAS pre-trial risk assessment tool and has higher
bias detection power compared to similar methods that audit for subgroup
fairness.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches. (arXiv:2306.12610v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12610">http://arxiv.org/abs/2306.12610</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12610] Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches](http://arxiv.org/abs/2306.12610) #defense</code></li>
<li>Summary: <p>Certifiably robust defenses against adversarial patches for image classifiers
ensure correct prediction against any changes to a constrained neighborhood of
pixels. PatchCleanser <a href="http://export.arxiv.org/abs/2108.09135">arXiv:2108.09135</a> [cs.CV], the state-of-the-art certified
defense, uses a double-masking strategy for robust classification. The success
of this strategy relies heavily on the model's invariance to image pixel
masking. In this paper, we take a closer look at model training schemes to
improve this invariance. Instead of using Random Cutout <a href="http://export.arxiv.org/abs/1708.04552">arXiv:1708.04552v2</a>
[cs.CV] augmentations like PatchCleanser, we introduce the notion of worst-case
masking, i.e., selecting masked images which maximize classification loss.
However, finding worst-case masks requires an exhaustive search, which might be
prohibitively expensive to do on-the-fly during training. To solve this
problem, we propose a two-round greedy masking strategy (Greedy Cutout) which
finds an approximate worst-case mask location with much less compute. We show
that the models trained with our Greedy Cutout improves certified robust
accuracy over Random Cutout in PatchCleanser across a range of datasets and
architectures. Certified robust accuracy on ImageNet with a ViT-B16-224 model
increases from 58.1\% to 62.3\% against a 3\% square patch applied anywhere on
the image.
</p></li>
</ul>

<h3>Title: Impacts and Risk of Generative AI Technology on Cyber Defense. (arXiv:2306.13033v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13033">http://arxiv.org/abs/2306.13033</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13033] Impacts and Risk of Generative AI Technology on Cyber Defense](http://arxiv.org/abs/2306.13033) #defense</code></li>
<li>Summary: <p>Generative Artificial Intelligence (GenAI) has emerged as a powerful
technology capable of autonomously producing highly realistic content in
various domains, such as text, images, audio, and videos. With its potential
for positive applications in creative arts, content generation, virtual
assistants, and data synthesis, GenAI has garnered significant attention and
adoption. However, the increasing adoption of GenAI raises concerns about its
potential misuse for crafting convincing phishing emails, generating
disinformation through deepfake videos, and spreading misinformation via
authentic-looking social media posts, posing a new set of challenges and risks
in the realm of cybersecurity. To combat the threats posed by GenAI, we propose
leveraging the Cyber Kill Chain (CKC) to understand the lifecycle of
cyberattacks, as a foundational model for cyber defense. This paper aims to
provide a comprehensive analysis of the risk areas introduced by the offensive
use of GenAI techniques in each phase of the CKC framework. We also analyze the
strategies employed by threat actors and examine their utilization throughout
different phases of the CKC, highlighting the implications for cyber defense.
Additionally, we propose GenAI-enabled defense strategies that are both
attack-aware and adaptive. These strategies encompass various techniques such
as detection, deception, and adversarial training, among others, aiming to
effectively mitigate the risks posed by GenAI-induced cyber threats.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Rethinking the Backward Propagation for Adversarial Transferability. (arXiv:2306.12685v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12685">http://arxiv.org/abs/2306.12685</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12685] Rethinking the Backward Propagation for Adversarial Transferability](http://arxiv.org/abs/2306.12685) #attack</code></li>
<li>Summary: <p>Transfer-based attacks generate adversarial examples on the surrogate model,
which can mislead other black-box models without any access, making it
promising to attack real-world applications. Recently, several works have been
proposed to boost adversarial transferability, in which the surrogate model is
usually overlooked. In this work, we identify that non-linear layers (e.g.,
ReLU, max-pooling, etc.) truncate the gradient during backward propagation,
making the gradient w.r.t.input image imprecise to the loss function. We
hypothesize and empirically validate that such truncation undermines the
transferability of adversarial examples. Based on these findings, we propose a
novel method called Backward Propagation Attack (BPA) to increase the relevance
between the gradient w.r.t. input image and loss function so as to generate
adversarial examples with higher transferability. Specifically, BPA adopts a
non-monotonic function as the derivative of ReLU and incorporates softmax with
temperature to smooth the derivative of max-pooling, thereby mitigating the
information loss during the backward propagation of gradients. Empirical
results on the ImageNet dataset demonstrate that not only does our method
substantially boost the adversarial transferability, but it also is general to
existing transfer-based attacks.
</p></li>
</ul>

<h3>Title: Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models. (arXiv:2306.12941v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12941">http://arxiv.org/abs/2306.12941</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12941] Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models](http://arxiv.org/abs/2306.12941) #attack</code></li>
<li>Summary: <p>While a large amount of work has focused on designing adversarial attacks
against image classifiers, only a few methods exist to attack semantic
segmentation models. We show that attacking segmentation models presents
task-specific challenges, for which we propose novel solutions. Our final
evaluation protocol outperforms existing methods, and shows that those can
overestimate the robustness of the models. Additionally, so far adversarial
training, the most successful way for obtaining robust image classifiers, could
not be successfully applied to semantic segmentation. We argue that this is
because the task to be learned is more challenging, and requires significantly
higher computational effort than for image classification. As a remedy, we show
that by taking advantage of recent advances in robust ImageNet classifiers, one
can train adversarially robust segmentation models at limited computational
cost by fine-tuning robust backbones.
</p></li>
</ul>

<h3>Title: Towards More Realistic Membership Inference Attacks on Large Diffusion Models. (arXiv:2306.12983v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12983">http://arxiv.org/abs/2306.12983</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12983] Towards More Realistic Membership Inference Attacks on Large Diffusion Models](http://arxiv.org/abs/2306.12983) #attack</code></li>
<li>Summary: <p>Generative diffusion models, including Stable Diffusion and Midjourney, can
generate visually appealing, diverse, and high-resolution images for various
applications. These models are trained on billions of internet-sourced images,
raising significant concerns about the potential unauthorized use of
copyright-protected images. In this paper, we examine whether it is possible to
determine if a specific image was used in the training set, a problem known in
the cybersecurity community and referred to as a membership inference attack.
Our focus is on Stable Diffusion, and we address the challenge of designing a
fair evaluation framework to answer this membership question. We propose a
methodology to establish a fair evaluation setup and apply it to Stable
Diffusion, enabling potential extensions to other generative models. Utilizing
this evaluation setup, we execute membership attacks (both known and newly
introduced). Our research reveals that previously proposed evaluation setups do
not provide a full understanding of the effectiveness of membership inference
attacks. We conclude that the membership inference attack remains a significant
challenge for large diffusion models (often deployed as black-box systems),
indicating that related privacy and copyright issues will persist in the
foreseeable future.
</p></li>
</ul>

<h3>Title: Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation. (arXiv:2306.12916v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12916">http://arxiv.org/abs/2306.12916</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12916] Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation](http://arxiv.org/abs/2306.12916) #attack</code></li>
<li>Summary: <p>While summarization has been extensively researched in natural language
processing (NLP), cross-lingual cross-temporal summarization (CLCTS) is a
largely unexplored area that has the potential to improve cross-cultural
accessibility, information sharing, and understanding. This paper
comprehensively addresses the CLCTS task, including dataset creation, modeling,
and evaluation. We build the first CLCTS corpus, leveraging historical fictive
texts and Wikipedia summaries in English and German, and examine the
effectiveness of popular transformer end-to-end models with different
intermediate task finetuning tasks. Additionally, we explore the potential of
ChatGPT for CLCTS as a summarizer and an evaluator. Overall, we report
evaluations from humans, ChatGPT, and several recent automatic evaluation
metrics where we find our intermediate task finetuned end-to-end models
generate bad to moderate quality summaries; ChatGPT as a summarizer (without
any finetuning) provides moderate to good quality outputs and as an evaluator
correlates moderately with human evaluations though it is prone to giving lower
scores. ChatGPT also seems to be very adept at normalizing historical text. We
finally test ChatGPT in a scenario with adversarially attacked and unseen
source documents and find that ChatGPT is better at omission and entity swap
than negating against its prior knowledge.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Neural Spectro-polarimetric Fields. (arXiv:2306.12562v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12562">http://arxiv.org/abs/2306.12562</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12562] Neural Spectro-polarimetric Fields](http://arxiv.org/abs/2306.12562) #robust</code></li>
<li>Summary: <p>Modeling the spatial radiance distribution of light rays in a scene has been
extensively explored for applications, including view synthesis. Spectrum and
polarization, the wave properties of light, are often neglected due to their
integration into three RGB spectral bands and their non-perceptibility to human
vision. Despite this, these properties encompass substantial material and
geometric information about a scene. In this work, we propose to model
spectro-polarimetric fields, the spatial Stokes-vector distribution of any
light ray at an arbitrary wavelength. We present Neural Spectro-polarimetric
Fields (NeSpoF), a neural representation that models the physically-valid
Stokes vector at given continuous variables of position, direction, and
wavelength. NeSpoF manages inherently noisy raw measurements, showcases memory
efficiency, and preserves physically vital signals, factors that are crucial
for representing the high-dimensional signal of a spectro-polarimetric field.
To validate NeSpoF, we introduce the first multi-view
hyperspectral-polarimetric image dataset, comprised of both synthetic and
real-world scenes. These were captured using our compact
hyperspectral-polarimetric imaging system, which has been calibrated for
robustness against system imperfections. We demonstrate the capabilities of
NeSpoF on diverse scenes.
</p></li>
</ul>

<h3>Title: 1st Place Solution to MultiEarth 2023 Challenge on Multimodal SAR-to-EO Image Translation. (arXiv:2306.12626v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12626">http://arxiv.org/abs/2306.12626</a></li>
<li>Code URL: <a href="https://github.com/cjf8899/MultiEarth2023_SAR2EO_1st_Place_Solution">https://github.com/cjf8899/MultiEarth2023_SAR2EO_1st_Place_Solution</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12626] 1st Place Solution to MultiEarth 2023 Challenge on Multimodal SAR-to-EO Image Translation](http://arxiv.org/abs/2306.12626) #robust</code></li>
<li>Summary: <p>The Multimodal Learning for Earth and Environment Workshop (MultiEarth 2023)
aims to harness the substantial amount of remote sensing data gathered over
extensive periods for the monitoring and analysis of Earth's ecosystems'health.
The subtask, Multimodal SAR-to-EO Image Translation, involves the use of robust
SAR data, even under adverse weather and lighting conditions, transforming it
into high-quality, clear, and visually appealing EO data. In the context of the
SAR2EO task, the presence of clouds or obstructions in EO data can potentially
pose a challenge. To address this issue, we propose the Clean Collector
Algorithm (CCA), designed to take full advantage of this cloudless SAR data and
eliminate factors that may hinder the data learning process. Subsequently, we
applied pix2pixHD for the SAR-to-EO translation and Restormer for image
enhancement. In the final evaluation, the team 'CDRL' achieved an MAE of
0.07313, securing the top rank on the leaderboard.
</p></li>
</ul>

<h3>Title: Hand Pose Estimation with Mems-Ultrasonic Sensors. (arXiv:2306.12652v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12652">http://arxiv.org/abs/2306.12652</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12652] Hand Pose Estimation with Mems-Ultrasonic Sensors](http://arxiv.org/abs/2306.12652) #robust</code></li>
<li>Summary: <p>Hand tracking is an important aspect of human-computer interaction and has a
wide range of applications in extended reality devices. However, current hand
motion capture methods suffer from various limitations. For instance,
visual-based hand pose estimation is susceptible to self-occlusion and changes
in lighting conditions, while IMU-based tracking gloves experience significant
drift and are not resistant to external magnetic field interference. To address
these issues, we propose a novel and low-cost hand-tracking glove that utilizes
several MEMS-ultrasonic sensors attached to the fingers, to measure the
distance matrix among the sensors. Our lightweight deep network then
reconstructs the hand pose from the distance matrix. Our experimental results
demonstrate that this approach is both accurate, size-agnostic, and robust to
external interference. We also show the design logic for the sensor selection,
sensor configurations, circuit diagram, as well as model architecture.
</p></li>
</ul>

<h3>Title: Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields. (arXiv:2306.12760v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12760">http://arxiv.org/abs/2306.12760</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12760] Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields](http://arxiv.org/abs/2306.12760) #robust</code></li>
<li>Summary: <p>Editing a local region or a specific object in a 3D scene represented by a
NeRF is challenging, mainly due to the implicit nature of the scene
representation. Consistently blending a new realistic object into the scene
adds an additional level of difficulty. We present Blended-NeRF, a robust and
flexible framework for editing a specific region of interest in an existing
NeRF scene, based on text prompts or image patches, along with a 3D ROI box.
Our method leverages a pretrained language-image model to steer the synthesis
towards a user-provided text prompt or image patch, along with a 3D MLP model
initialized on an existing NeRF scene to generate the object and blend it into
a specified region in the original scene. We allow local editing by localizing
a 3D ROI box in the input scene, and seamlessly blend the content synthesized
inside the ROI with the existing scene using a novel volumetric blending
technique. To obtain natural looking and view-consistent results, we leverage
existing and new geometric priors and 3D augmentations for improving the visual
fidelity of the final result.
</p></li>
</ul>

<p>We test our framework both qualitatively and quantitatively on a variety of
real 3D scenes and text prompts, demonstrating realistic multi-view consistent
results with much flexibility and diversity compared to the baselines. Finally,
we show the applicability of our framework for several 3D editing applications,
including adding new objects to a scene, removing/replacing/altering existing
objects, and texture conversion.
</p>

<h3>Title: Affine Correspondences between Multi-Camera Systems for Relative Pose Estimation. (arXiv:2306.12996v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12996">http://arxiv.org/abs/2306.12996</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12996] Affine Correspondences between Multi-Camera Systems for Relative Pose Estimation](http://arxiv.org/abs/2306.12996) #robust</code></li>
<li>Summary: <p>We present a novel method to compute the relative pose of multi-camera
systems using two affine correspondences (ACs). Existing solutions to the
multi-camera relative pose estimation are either restricted to special cases of
motion, have too high computational complexity, or require too many point
correspondences (PCs). Thus, these solvers impede an efficient or accurate
relative pose estimation when applying RANSAC as a robust estimator. This paper
shows that the 6DOF relative pose estimation problem using ACs permits a
feasible minimal solution, when exploiting the geometric constraints between
ACs and multi-camera systems using a special parameterization. We present a
problem formulation based on two ACs that encompass two common types of ACs
across two views, i.e., inter-camera and intra-camera. Moreover, the framework
for generating the minimal solvers can be extended to solve various relative
pose estimation problems, e.g., 5DOF relative pose estimation with known
rotation angle prior. Experiments on both virtual and real multi-camera systems
prove that the proposed solvers are more efficient than the state-of-the-art
algorithms, while resulting in a better relative pose accuracy. Source code is
available at https://github.com/jizhaox/relpose-mcs-depth.
</p></li>
</ul>

<h3>Title: Iterative Scale-Up ExpansionIoU and Deep Features Association for Multi-Object Tracking in Sports. (arXiv:2306.13074v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13074">http://arxiv.org/abs/2306.13074</a></li>
<li>Code URL: <a href="https://github.com/hsiangwei0903/Deep-EIoU">https://github.com/hsiangwei0903/Deep-EIoU</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13074] Iterative Scale-Up ExpansionIoU and Deep Features Association for Multi-Object Tracking in Sports](http://arxiv.org/abs/2306.13074) #robust</code></li>
<li>Summary: <p>Multi-object tracking algorithms have made significant advancements due to
the recent developments in object detection. However, most existing methods
primarily focus on tracking pedestrians or vehicles, which exhibit relatively
simple and regular motion patterns. Consequently, there is a scarcity of
algorithms that address the tracking of targets with irregular or non-linear
motion, such as multi-athlete tracking. Furthermore, popular tracking
algorithms often rely on the Kalman filter for object motion modeling, which
fails to track objects when their motion contradicts the linear motion
assumption of the Kalman filter. Due to this reason, we proposed a novel online
and robust multi-object tracking approach, named Iterative Scale-Up
ExpansionIoU and Deep Features for multi-object tracking. Unlike conventional
methods, we abandon the use of the Kalman filter and propose utilizing the
iterative scale-up expansion IoU. This approach achieves superior tracking
performance without requiring additional training data or adopting a more
robust detector, all while maintaining a lower computational cost compared to
other appearance-based methods. Our proposed method demonstrates remarkable
effectiveness in tracking irregular motion objects, achieving a score of 75.3%
in HOTA. It outperforms all state-of-the-art online tracking algorithms on the
SportsMOT dataset, covering various kinds of sport scenarios.
</p></li>
</ul>

<h3>Title: From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought. (arXiv:2306.12672v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12672">http://arxiv.org/abs/2306.12672</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12672] From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought](http://arxiv.org/abs/2306.12672) #robust</code></li>
<li>Summary: <p>How does language inform our downstream thinking? In particular, how do
humans make meaning from language -- and how can we leverage a theory of
linguistic meaning to build machines that think in more human-like ways? In
this paper, we propose \textit{rational meaning construction}, a computational
framework for language-informed thinking that combines neural models of
language with probabilistic models for rational inference. We frame linguistic
meaning as a context-sensitive mapping from natural language into a
\textit{probabilistic language of thought} (PLoT) -- a general-purpose symbolic
substrate for probabilistic, generative world modeling. Our architecture
integrates two powerful computational tools that have not previously come
together: we model thinking with \textit{probabilistic programs}, an expressive
representation for flexible commonsense reasoning; and we model meaning
construction with \textit{large language models} (LLMs), which support
broad-coverage translation from natural language utterances to code expressions
in a probabilistic programming language. We illustrate our framework in action
through examples covering four core domains from cognitive science:
probabilistic reasoning, logical and relational reasoning, visual and physical
reasoning, and social reasoning about agents and their plans. In each, we show
that LLMs can generate context-sensitive translations that capture
pragmatically-appropriate linguistic meanings, while Bayesian inference with
the generated programs supports coherent and robust commonsense reasoning. We
extend our framework to integrate cognitively-motivated symbolic modules to
provide a unified commonsense thinking interface from language. Finally, we
explore how language can drive the construction of world models themselves.
</p></li>
</ul>

<h3>Title: Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4. (arXiv:2306.12794v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12794">http://arxiv.org/abs/2306.12794</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12794] Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4](http://arxiv.org/abs/2306.12794) #robust</code></li>
<li>Summary: <p>The advent and fast development of neural networks have revolutionized the
research on dialogue systems and subsequently have triggered various challenges
regarding their automatic evaluation. Automatic evaluation of open-domain
dialogue systems as an open challenge has been the center of the attention of
many researchers. Despite the consistent efforts to improve automatic metrics'
correlations with human evaluation, there have been very few attempts to assess
their robustness over multiple domains and dimensions. Also, their focus is
mainly on the English language. All of these challenges prompt the development
of automatic evaluation metrics that are reliable in various domains,
dimensions, and languages. This track in the 11th Dialogue System Technology
Challenge (DSTC11) is part of the ongoing effort to promote robust and
multilingual automatic evaluation metrics. This article describes the datasets
and baselines provided to participants and discusses the submission and result
details of the two proposed subtasks.
</p></li>
</ul>

<h3>Title: DP-BREM: Differentially-Private and Byzantine-Robust Federated Learning with Client Momentum. (arXiv:2306.12608v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12608">http://arxiv.org/abs/2306.12608</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12608] DP-BREM: Differentially-Private and Byzantine-Robust Federated Learning with Client Momentum](http://arxiv.org/abs/2306.12608) #robust</code></li>
<li>Summary: <p>Federated Learning (FL) allows multiple participating clients to train
machine learning models collaboratively by keeping their datasets local and
only exchanging the gradient or model updates with a coordinating server.
Existing FL protocols were shown to be vulnerable to attacks that aim to
compromise data privacy and/or model robustness. Recently proposed defenses
focused on ensuring either privacy or robustness, but not both. In this paper,
we focus on simultaneously achieving differential privacy (DP) and Byzantine
robustness for cross-silo FL, based on the idea of learning from history. The
robustness is achieved via client momentum, which averages the updates of each
client over time, thus reduces the variance of the honest clients and exposes
the small malicious perturbations of Byzantine clients that are undetectable in
a single round but accumulate over time. In our initial solution DP-BREM, the
DP property is achieved via adding noise to the aggregated momentum, and we
account for the privacy cost from the momentum, which is different from the
conventional DP-SGD that accounts for the privacy cost from gradient. Since
DP-BREM assumes a trusted server (who can obtain clients' local models or
updates), we further develop the final solution called DP-BREM+, which achieves
the same DP and robustness properties as DP-BREM without a trusted server by
utilizing secure aggregation techniques, where DP noise is securely and jointly
generated by the clients. Our theoretical analysis on the convergence rate and
experimental results under different DP guarantees and attack settings
demonstrate that our proposed protocols achieve better privacy-utility tradeoff
and stronger Byzantine robustness than several baseline methods.
</p></li>
</ul>

<h3>Title: Verifying Global Neural Network Specifications using Hyperproperties. (arXiv:2306.12495v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12495">http://arxiv.org/abs/2306.12495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12495] Verifying Global Neural Network Specifications using Hyperproperties](http://arxiv.org/abs/2306.12495) #robust</code></li>
<li>Summary: <p>Current approaches to neural network verification focus on specifications
that target small regions around known input data points, such as local
robustness. Thus, using these approaches, we can not obtain guarantees for
inputs that are not close to known inputs. Yet, it is highly likely that a
neural network will encounter such truly unseen inputs during its application.
We study global specifications that - when satisfied - provide guarantees for
all potential inputs. We introduce a hyperproperty formalism that allows for
expressing global specifications such as monotonicity, Lipschitz continuity,
global robustness, and dependency fairness. Our formalism enables verifying
global specifications using existing neural network verification approaches by
leveraging capabilities for verifying general computational graphs. Thereby, we
extend the scope of guarantees that can be provided using existing methods.
Recent success in verifying specific global specifications shows that attaining
strong guarantees for all potential data points is feasible.
</p></li>
</ul>

<h3>Title: Density Uncertainty Layers for Reliable Uncertainty Estimation. (arXiv:2306.12497v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12497">http://arxiv.org/abs/2306.12497</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12497] Density Uncertainty Layers for Reliable Uncertainty Estimation](http://arxiv.org/abs/2306.12497) #robust</code></li>
<li>Summary: <p>Assessing the predictive uncertainty of deep neural networks is crucial for
safety-related applications of deep learning. Although Bayesian deep learning
offers a principled framework for estimating model uncertainty, the approaches
that are commonly used to approximate the posterior often fail to deliver
reliable estimates of predictive uncertainty. In this paper we propose a novel
criterion for predictive uncertainty, that a model's predictive variance should
be grounded in the empirical density of the input. It should produce higher
uncertainty for inputs that are improbable in the training data and lower
uncertainty for those inputs that are more probable. To operationalize this
criterion, we develop the density uncertainty layer, an architectural element
for a stochastic neural network that guarantees that the density uncertain
criterion is satisfied. We study neural networks with density uncertainty
layers on the CIFAR-10 and CIFAR-100 uncertainty benchmarks. Compared to
existing approaches, we find that density uncertainty layers provide reliable
uncertainty estimates and robust out-of-distribution detection performance.
</p></li>
</ul>

<h3>Title: RobustNeuralNetworks.jl: a Package for Machine Learning and Data-Driven Control with Certified Robustness. (arXiv:2306.12612v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12612">http://arxiv.org/abs/2306.12612</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12612] RobustNeuralNetworks](http://arxiv.org/abs/2306.12612) #robust</code></li>
<li>Summary: <p>Neural networks are typically sensitive to small input perturbations, leading
to unexpected or brittle behaviour. We present RobustNeuralNetworks.jl: a Julia
package for neural network models that are constructed to naturally satisfy a
set of user-defined robustness constraints. The package is based on the
recently proposed Recurrent Equilibrium Network (REN) and Lipschitz-Bounded
Deep Network (LBDN) model classes, and is designed to interface directly with
Julia's most widely-used machine learning package, Flux.jl. We discuss the
theory behind our model parameterization, give an overview of the package, and
provide a tutorial demonstrating its use in image classification, reinforcement
learning, and nonlinear state-observer design.
</p></li>
</ul>

<h3>Title: Outlier-robust Estimation of a Sparse Linear Model Using Invexity. (arXiv:2306.12678v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12678">http://arxiv.org/abs/2306.12678</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12678] Outlier-robust Estimation of a Sparse Linear Model Using Invexity](http://arxiv.org/abs/2306.12678) #robust</code></li>
<li>Summary: <p>In this paper, we study problem of estimating a sparse regression vector with
correct support in the presence of outlier samples. The inconsistency of
lasso-type methods is well known in this scenario. We propose a combinatorial
version of outlier-robust lasso which also identifies clean samples.
Subsequently, we use these clean samples to make a good estimation. We also
provide a novel invex relaxation for the combinatorial problem and provide
provable theoretical guarantees for this relaxation. Finally, we conduct
experiments to validate our theory and compare our results against standard
lasso.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Semi-automated extraction of research topics and trends from NCI funding in radiological sciences from 2000-2020. (arXiv:2306.13075v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13075">http://arxiv.org/abs/2306.13075</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13075] Semi-automated extraction of research topics and trends from NCI funding in radiological sciences from 2000-2020](http://arxiv.org/abs/2306.13075) #extraction</code></li>
<li>Summary: <p>Investigators, funders, and the public desire knowledge on topics and trends
in publicly funded research but current efforts in manual categorization are
limited in scale and understanding. We developed a semi-automated approach to
extract and name research topics, and applied this to \$1.9B of NCI funding
over 21 years in the radiological sciences to determine micro- and macro-scale
research topics and funding trends. Our method relies on sequential clustering
of existing biomedical-based word embeddings, naming using subject matter
experts, and visualization to discover trends at a macroscopic scale above
individual topics. We present results using 15 and 60 cluster topics, where we
found that 2D projection of grant embeddings reveals two dominant axes:
physics-biology and therapeutic-diagnostic. For our dataset, we found that
funding for therapeutics- and physics-based research have outpaced diagnostics-
and biology-based research, respectively. We hope these results may (1) give
insight to funders on the appropriateness of their funding allocation, (2)
assist investigators in contextualizing their work and explore neighboring
research domains, and (3) allow the public to review where their tax dollars
are being allocated.
</p></li>
</ul>

<h3>Title: Natural Language Processing in Electronic Health Records in Relation to Healthcare Decision-making: A Systematic Review. (arXiv:2306.12834v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12834">http://arxiv.org/abs/2306.12834</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12834] Natural Language Processing in Electronic Health Records in Relation to Healthcare Decision-making: A Systematic Review](http://arxiv.org/abs/2306.12834) #extraction</code></li>
<li>Summary: <p>Background: Natural Language Processing (NLP) is widely used to extract
clinical insights from Electronic Health Records (EHRs). However, the lack of
annotated data, automated tools, and other challenges hinder the full
utilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)
and NLP techniques are studied and compared to understand the limitations and
opportunities in this space comprehensively.
</p></li>
</ul>

<p>Methodology: After screening 261 articles from 11 databases, we included 127
papers for full-text review covering seven categories of articles: 1) medical
note classification, 2) clinical entity recognition, 3) text summarisation, 4)
deep learning (DL) and transfer learning architecture, 5) information
extraction, 6) Medical language translation and 7) other NLP applications. This
study follows the Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines.
</p>
<p>Result and Discussion: EHR was the most commonly used data type among the
selected articles, and the datasets were primarily unstructured. Various ML and
DL methods were used, with prediction or classification being the most common
application of ML or DL. The most common use cases were: the International
Classification of Diseases, Ninth Revision (ICD-9) classification, clinical
note analysis, and named entity recognition (NER) for clinical descriptions and
research on psychiatric disorders.
</p>
<p>Conclusion: We find that the adopted ML models were not adequately assessed.
In addition, the data imbalance problem is quite important, yet we must find
techniques to address this underlining problem. Future studies should address
key limitations in studies, primarily identifying Lupus Nephritis, Suicide
Attempts, perinatal self-harmed and ICD-9 classification.
</p>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Decentralized Online Federated G-Network Learning for Lightweight Intrusion Detection. (arXiv:2306.13029v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13029">http://arxiv.org/abs/2306.13029</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13029] Decentralized Online Federated G-Network Learning for Lightweight Intrusion Detection](http://arxiv.org/abs/2306.13029) #federate</code></li>
<li>Summary: <p>Cyberattacks are increasingly threatening networked systems, often with the
emergence of new types of unknown (zero-day) attacks and the rise of vulnerable
devices. While Machine Learning (ML)-based Intrusion Detection Systems (IDSs)
have been shown to be extremely promising in detecting these attacks, the need
to learn large amounts of labelled data often limits the applicability of
ML-based IDSs to cybersystems that only have access to private local data. To
address this issue, this paper proposes a novel Decentralized and Online
Federated Learning Intrusion Detection (DOF-ID) architecture. DOF-ID is a
collaborative learning system that allows each IDS used for a cybersystem to
learn from experience gained in other cybersystems in addition to its own local
data without violating the data privacy of other systems. As the performance
evaluation results using public Kitsune and Bot-IoT datasets show, DOF-ID
significantly improves the intrusion detection performance in all collaborating
nodes simultaneously with acceptable computation time for online learning.
</p></li>
</ul>

<h3>Title: Communication-Efficient Federated Learning through Importance Sampling. (arXiv:2306.12625v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12625">http://arxiv.org/abs/2306.12625</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12625] Communication-Efficient Federated Learning through Importance Sampling](http://arxiv.org/abs/2306.12625) #federate</code></li>
<li>Summary: <p>The high communication cost of sending model updates from the clients to the
server is a significant bottleneck for scalable federated learning (FL). Among
existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been
achieved using stochastic compression methods -- in which the client $n$ sends
a sample from a client-only probability distribution $q_{\phi^{(n)}}$, and the
server estimates the mean of the clients' distributions using these samples.
However, such methods do not take full advantage of the FL setup where the
server, throughout the training process, has side information in the form of a
pre-data distribution $p_{\theta}$ that is close to the client's distribution
$q_{\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit
this closeness between the clients' distributions $q_{\phi^{(n)}}$'s and the
side information $p_{\theta}$ at the server, and propose a framework that
requires approximately $D_{KL}(q_{\phi^{(n)}}|| p_{\theta})$ bits of
communication. We show that our method can be integrated into many existing
stochastic compression frameworks such as FedPM, Federated SGLD, and QSGD to
attain the same (and often higher) test accuracy with up to $50$ times
reduction in the bitrate.
</p></li>
</ul>

<h3>Title: Reinforcement Federated Learning Method Based on Adaptive OPTICS Clustering. (arXiv:2306.12859v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12859">http://arxiv.org/abs/2306.12859</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12859] Reinforcement Federated Learning Method Based on Adaptive OPTICS Clustering](http://arxiv.org/abs/2306.12859) #federate</code></li>
<li>Summary: <p>Federated learning is a distributed machine learning technology, which
realizes the balance between data privacy protection and data sharing
computing. To protect data privacy, feder-ated learning learns shared models by
locally executing distributed training on participating devices and aggregating
local models into global models. There is a problem in federated learning, that
is, the negative impact caused by the non-independent and identical
distribu-tion of data across different user terminals. In order to alleviate
this problem, this paper pro-poses a strengthened federation aggregation method
based on adaptive OPTICS clustering. Specifically, this method perceives the
clustering environment as a Markov decision process, and models the adjustment
process of parameter search direction, so as to find the best clus-tering
parameters to achieve the best federated aggregation method. The core
contribution of this paper is to propose an adaptive OPTICS clustering
algorithm for federated learning. The algorithm combines OPTICS clustering and
adaptive learning technology, and can effective-ly deal with the problem of
non-independent and identically distributed data across different user
terminals. By perceiving the clustering environment as a Markov decision
process, the goal is to find the best parameters of the OPTICS cluster without
artificial assistance, so as to obtain the best federated aggregation method
and achieve better performance. The reliability and practicability of this
method have been verified on the experimental data, and its effec-tiveness and
superiority have been proved.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: Investigating Poor Performance Regions of Black Boxes: LIME-based Exploration in Sepsis Detection. (arXiv:2306.12507v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12507">http://arxiv.org/abs/2306.12507</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12507] Investigating Poor Performance Regions of Black Boxes: LIME-based Exploration in Sepsis Detection](http://arxiv.org/abs/2306.12507) #interpretability</code></li>
<li>Summary: <p>Interpreting machine learning models remains a challenge, hindering their
adoption in clinical settings. This paper proposes leveraging Local
Interpretable Model-Agnostic Explanations (LIME) to provide interpretable
descriptions of black box classification models in high-stakes sepsis
detection. By analyzing misclassified instances, significant features
contributing to suboptimal performance are identified. The analysis reveals
regions where the classifier performs poorly, allowing the calculation of error
rates within these regions. This knowledge is crucial for cautious
decision-making in sepsis detection and other critical applications. The
proposed approach is demonstrated using the eICU dataset, effectively
identifying and visualizing regions where the classifier underperforms. By
enhancing interpretability, our method promotes the adoption of machine
learning models in clinical practice, empowering informed decision-making and
mitigating risks in critical scenarios.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Towards Explainable Evaluation Metrics for Machine Translation. (arXiv:2306.13041v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13041">http://arxiv.org/abs/2306.13041</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13041] Towards Explainable Evaluation Metrics for Machine Translation](http://arxiv.org/abs/2306.13041) #explainability</code></li>
<li>Summary: <p>Unlike classical lexical overlap metrics such as BLEU, most current
evaluation metrics for machine translation (for example, COMET or BERTScore)
are based on black-box large language models. They often achieve strong
correlations with human judgments, but recent research indicates that the
lower-quality classical metrics remain dominant, one of the potential reasons
being that their decision processes are more transparent. To foster more
widespread acceptance of novel high-quality metrics, explainability thus
becomes crucial. In this concept paper, we identify key properties as well as
key goals of explainable machine translation metrics and provide a
comprehensive synthesis of recent techniques, relating them to our established
goals and properties. In this context, we also discuss the latest
state-of-the-art approaches to explainable metrics based on generative models
such as ChatGPT and GPT4. Finally, we contribute a vision of next-generation
approaches, including natural language explanations. We hope that our work can
help catalyze and guide future research on explainable evaluation metrics and,
mediately, also contribute to better and more transparent machine translation
systems.
</p></li>
</ul>

<h3>Title: Explainable Representations for Relation Prediction in Knowledge Graphs. (arXiv:2306.12687v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12687">http://arxiv.org/abs/2306.12687</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12687] Explainable Representations for Relation Prediction in Knowledge Graphs](http://arxiv.org/abs/2306.12687) #explainability</code></li>
<li>Summary: <p>Knowledge graphs represent real-world entities and their relations in a
semantically-rich structure supported by ontologies. Exploring this data with
machine learning methods often relies on knowledge graph embeddings, which
produce latent representations of entities that preserve structural and local
graph neighbourhood properties, but sacrifice explainability. However, in tasks
such as link or relation prediction, understanding which specific features
better explain a relation is crucial to support complex or critical
applications.
</p></li>
</ul>

<p>We propose SEEK, a novel approach for explainable representations to support
relation prediction in knowledge graphs. It is based on identifying relevant
shared semantic aspects (i.e., subgraphs) between entities and learning
representations for each subgraph, producing a multi-faceted and explainable
representation.
</p>
<p>We evaluate SEEK on two real-world highly complex relation prediction tasks:
protein-protein interaction prediction and gene-disease association prediction.
Our extensive analysis using established benchmarks demonstrates that SEEK
achieves significantly better performance than standard learning representation
methods while identifying both sufficient and necessary explanations based on
shared semantic aspects.
</p>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Semi-Implicit Denoising Diffusion Models (SIDDMs). (arXiv:2306.12511v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12511">http://arxiv.org/abs/2306.12511</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12511] Semi-Implicit Denoising Diffusion Models (SIDDMs)](http://arxiv.org/abs/2306.12511) #diffusion</code></li>
<li>Summary: <p>Despite the proliferation of generative models, achieving fast sampling
during inference without compromising sample diversity and quality remains
challenging. Existing models such as Denoising Diffusion Probabilistic Models
(DDPM) deliver high-quality, diverse samples but are slowed by an inherently
high number of iterative steps. The Denoising Diffusion Generative Adversarial
Networks (DDGAN) attempted to circumvent this limitation by integrating a GAN
model for larger jumps in the diffusion process. However, DDGAN encountered
scalability limitations when applied to large datasets. To address these
limitations, we introduce a novel approach that tackles the problem by matching
implicit and explicit factors. More specifically, our approach involves
utilizing an implicit model to match the marginal distributions of noisy data
and the explicit conditional distribution of the forward diffusion. This
combination allows us to effectively match the joint denoising distributions.
Unlike DDPM but similar to DDGAN, we do not enforce a parametric distribution
for the reverse step, enabling us to take large steps during inference. Similar
to the DDPM but unlike DDGAN, we take advantage of the exact form of the
diffusion process. We demonstrate that our proposed method obtains comparable
generative performance to diffusion-based models and vastly superior results to
models with a small number of sampling steps.
</p></li>
</ul>

<h3>Title: One at A Time: Multi-step Volumetric Probability Distribution Diffusion for Depth Estimation. (arXiv:2306.12681v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12681">http://arxiv.org/abs/2306.12681</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12681] One at A Time: Multi-step Volumetric Probability Distribution Diffusion for Depth Estimation](http://arxiv.org/abs/2306.12681) #diffusion</code></li>
<li>Summary: <p>Recent works have explored the fundamental role of depth estimation in
multi-view stereo (MVS) and semantic scene completion (SSC). They generally
construct 3D cost volumes to explore geometric correspondence in depth, and
estimate such volumes in a single step relying directly on the ground truth
approximation. However, such problem cannot be thoroughly handled in one step
due to complex empirical distributions, especially in challenging regions like
occlusions, reflections, etc. In this paper, we formulate the depth estimation
task as a multi-step distribution approximation process, and introduce a new
paradigm of modeling the Volumetric Probability Distribution progressively
(step-by-step) following a Markov chain with Diffusion models (VPDD).
Specifically, to constrain the multi-step generation of volume in VPDD, we
construct a meta volume guidance and a confidence-aware contextual guidance as
conditional geometry priors to facilitate the distribution approximation. For
the sampling process, we further investigate an online filtering strategy to
maintain consistency in volume representations for stable training. Experiments
demonstrate that our plug-and-play VPDD outperforms the state-of-the-arts for
tasks of MVS and SSC, and can also be easily extended to different baselines to
get improvement. It is worth mentioning that we are the first camera-based work
that surpasses LiDAR-based methods on the SemanticKITTI dataset.
</p></li>
</ul>

<h3>Title: Continuous Layout Editing of Single Images with Diffusion Models. (arXiv:2306.13078v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13078">http://arxiv.org/abs/2306.13078</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13078] Continuous Layout Editing of Single Images with Diffusion Models](http://arxiv.org/abs/2306.13078) #diffusion</code></li>
<li>Summary: <p>Recent advancements in large-scale text-to-image diffusion models have
enabled many applications in image editing. However, none of these methods have
been able to edit the layout of single existing images. To address this gap, we
propose the first framework for layout editing of a single image while
preserving its visual properties, thus allowing for continuous editing on a
single image. Our approach is achieved through two key modules. First, to
preserve the characteristics of multiple objects within an image, we
disentangle the concepts of different objects and embed them into separate
textual tokens using a novel method called masked textual inversion. Next, we
propose a training-free optimization method to perform layout control for a
pre-trained diffusion model, which allows us to regenerate images with learned
concepts and align them with user-specified layouts. As the first framework to
edit the layout of existing images, we demonstrate that our method is effective
and outperforms other baselines that were modified to support this task. Our
code will be freely available for public use upon acceptance.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h3>Title: Data-Free Backbone Fine-Tuning for Pruned Neural Networks. (arXiv:2306.12881v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12881">http://arxiv.org/abs/2306.12881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12881] Data-Free Backbone Fine-Tuning for Pruned Neural Networks](http://arxiv.org/abs/2306.12881) #data-free</code></li>
<li>Summary: <p>Model compression techniques reduce the computational load and memory
consumption of deep neural networks. After the compression operation, e.g.
parameter pruning, the model is normally fine-tuned on the original training
dataset to recover from the performance drop caused by compression. However,
the training data is not always available due to privacy issues or other
factors. In this work, we present a data-free fine-tuning approach for pruning
the backbone of deep neural networks. In particular, the pruned network
backbone is trained with synthetically generated images, and our proposed
intermediate supervision to mimic the unpruned backbone's output feature map.
Afterwards, the pruned backbone can be combined with the original network head
to make predictions. We generate synthetic images by back-propagating gradients
to noise images while relying on L1-pruning for the backbone pruning. In our
experiments, we show that our approach is task-independent due to pruning only
the backbone. By evaluating our approach on 2D human pose estimation, object
detection, and image classification, we demonstrate promising performance
compared to the unpruned model. Our code is available at
https://github.com/holzbock/dfbf.
</p></li>
</ul>

<h2>transformer</h2>
<h3>Title: LPFormer: LiDAR Pose Estimation Transformer with Multi-Task Network. (arXiv:2306.12525v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12525">http://arxiv.org/abs/2306.12525</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12525] LPFormer: LiDAR Pose Estimation Transformer with Multi-Task Network](http://arxiv.org/abs/2306.12525) #transformer</code></li>
<li>Summary: <p>In this technical report, we present the 1st place solution for the 2023
Waymo Open Dataset Pose Estimation challenge. Due to the difficulty of
acquiring large-scale 3D human keypoint annotation, previous methods have
commonly relied on 2D image features and 2D sequential annotations for 3D human
pose estimation. In contrast, our proposed method, named LPFormer, uses only
LiDAR as its input along with its corresponding 3D annotations. LPFormer
consists of two stages: the first stage detects the human bounding box and
extracts multi-level feature representations, while the second stage employs a
transformer-based network to regress the human keypoints using these features.
Experimental results on the Waymo Open Dataset demonstrate the top performance,
and improvements even compared to previous multi-modal solutions.
</p></li>
</ul>

<h3>Title: Learning from Visual Observation via Offline Pretrained State-to-Go Transformer. (arXiv:2306.12860v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12860">http://arxiv.org/abs/2306.12860</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12860] Learning from Visual Observation via Offline Pretrained State-to-Go Transformer](http://arxiv.org/abs/2306.12860) #transformer</code></li>
<li>Summary: <p>Learning from visual observation (LfVO), aiming at recovering policies from
only visual observation data, is promising yet a challenging problem. Existing
LfVO approaches either only adopt inefficient online learning schemes or
require additional task-specific information like goal states, making them not
suited for open-ended tasks. To address these issues, we propose a two-stage
framework for learning from visual observation. In the first stage, we
introduce and pretrain State-to-Go (STG) Transformer offline to predict and
differentiate latent transitions of demonstrations. Subsequently, in the second
stage, the STG Transformer provides intrinsic rewards for downstream
reinforcement learning tasks where an agent learns merely from intrinsic
rewards. Empirical results on Atari and Minecraft show that our proposed method
outperforms baselines and in some tasks even achieves performance comparable to
the policy learned from environmental rewards. These results shed light on the
potential of utilizing video-only data to solve difficult visual reinforcement
learning tasks rather than relying on complete offline datasets containing
states, actions, and rewards. The project's website and code can be found at
https://sites.google.com/view/stgtransformer.
</p></li>
</ul>

<h3>Title: Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing. (arXiv:2306.12929v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12929">http://arxiv.org/abs/2306.12929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12929] Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing](http://arxiv.org/abs/2306.12929) #transformer</code></li>
<li>Summary: <p>Transformer models have been widely adopted in various domains over the last
years, and especially large language models have advanced the field of AI
significantly. Due to their size, the capability of these networks has
increased tremendously, but this has come at the cost of a significant increase
in necessary compute. Quantization is one of the most effective ways to reduce
the computational time and memory consumption of neural networks. Many studies
have shown, however, that modern transformer models tend to learn strong
outliers in their activations, making them difficult to quantize. To retain
acceptable performance, the existence of these outliers requires activations to
be in higher bitwidth or the use of different numeric formats, extra
fine-tuning, or other workarounds. We show that strong outliers are related to
very specific behavior of attention heads that try to learn a "no-op" or just a
partial update of the residual. To achieve the exact zeros needed in the
attention matrix for a no-update, the input to the softmax is pushed to be
larger and larger during training, causing outliers in other parts of the
network. Based on these observations, we propose two simple (independent)
modifications to the attention mechanism - clipped softmax and gated attention.
We empirically show that models pre-trained using our methods learn
significantly smaller outliers while maintaining and sometimes even improving
the floating-point task performance. This enables us to quantize transformers
to full INT8 quantization of the activations without any additional effort. We
demonstrate the effectiveness of our methods on both language models (BERT,
OPT) and vision transformers.
</p></li>
</ul>

<h3>Title: Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers. (arXiv:2306.12992v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12992">http://arxiv.org/abs/2306.12992</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12992] Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers](http://arxiv.org/abs/2306.12992) #transformer</code></li>
<li>Summary: <p>High-quality panoramic images with a Field of View (FoV) of 360-degree are
essential for contemporary panoramic computer vision tasks. However,
conventional imaging systems come with sophisticated lens designs and heavy
optical components. This disqualifies their usage in many mobile and wearable
applications where thin and portable, minimalist imaging systems are desired.
In this paper, we propose a Panoramic Computational Imaging Engine (PCIE) to
address minimalist and high-quality panoramic imaging. With less than three
spherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) is
constructed based on the design of the Panoramic Annular Lens (PAL), but with
low-quality imaging results due to aberrations and small image plane size. We
propose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution and
Aberration Correction (SR&amp;AC), to solve the image quality problems of MPIP,
with imaging sensors of small and large pixel size, respectively. To provide a
universal network for the two pipelines, we leverage the information from the
Point Spread Function (PSF) of the optical system and design a PSF-aware
Aberration-image Recovery Transformer (PART), in which the self-attention
calculation and feature extraction are guided via PSF-aware mechanisms. We
train PART on synthetic image pairs from simulation and put forward the PALHQ
dataset to fill the gap of real-world high-quality PAL images for low-level
vision. A comprehensive variety of experiments on synthetic and real-world
benchmarks demonstrates the impressive imaging results of PCIE and the
effectiveness of plug-and-play PSF-aware mechanisms. We further deliver
heuristic experimental findings for minimalist and high-quality panoramic
imaging. Our dataset and code will be available at
https://github.com/zju-jiangqi/PCIE-PART.
</p></li>
</ul>

<h3>Title: Deep Metric Learning with Soft Orthogonal Proxies. (arXiv:2306.13055v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13055">http://arxiv.org/abs/2306.13055</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13055] Deep Metric Learning with Soft Orthogonal Proxies](http://arxiv.org/abs/2306.13055) #transformer</code></li>
<li>Summary: <p>Deep Metric Learning (DML) models rely on strong representations and
similarity-based measures with specific loss functions. Proxy-based losses have
shown great performance compared to pair-based losses in terms of convergence
speed. However, proxies that are assigned to different classes may end up being
closely located in the embedding space and hence having a hard time to
distinguish between positive and negative items. Alternatively, they may become
highly correlated and hence provide redundant information with the model. To
address these issues, we propose a novel approach that introduces Soft
Orthogonality (SO) constraint on proxies. The constraint ensures the proxies to
be as orthogonal as possible and hence control their positions in the embedding
space. Our approach leverages Data-Efficient Image Transformer (DeiT) as an
encoder to extract contextual features from images along with a DML objective.
The objective is made of the Proxy Anchor loss along with the SO
regularization. We evaluate our method on four public benchmarks for
category-level image retrieval and demonstrate its effectiveness with
comprehensive experimental results and ablation studies. Our evaluations
demonstrate the superiority of our proposed approach over state-of-the-art
methods by a significant margin.
</p></li>
</ul>

<h3>Title: Named entity recognition in resumes. (arXiv:2306.13062v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13062">http://arxiv.org/abs/2306.13062</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13062] Named entity recognition in resumes](http://arxiv.org/abs/2306.13062) #transformer</code></li>
<li>Summary: <p>Named entity recognition (NER) is used to extract information from various
documents and texts such as names and dates. It is important to extract
education and work experience information from resumes in order to filter them.
Considering the fact that all information in a resume has to be entered to the
companys system manually, automatizing this process will save time of the
companies. In this study, a deep learning-based semi-automatic named entity
recognition system has been implemented with a focus on resumes in the field of
IT. Firstly, resumes of employees from five different IT related fields has
been annotated. Six transformer based pre-trained models have been adapted to
named entity recognition problem using the annotated data. These models have
been selected among popular models in the natural language processing field.
The obtained system can recognize eight different entity types which are city,
date, degree, diploma major, job title, language, country and skill. Models
used in the experiments are compared using micro, macro and weighted F1 scores
and the performance of the methods was evaluated. Taking these scores into
account for test set the best micro and weighted F1 score is obtained by
RoBERTa and the best macro F1 score is obtained by Electra model.
</p></li>
</ul>

<h3>Title: Improving Long-Horizon Imitation Through Instruction Prediction. (arXiv:2306.12554v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12554">http://arxiv.org/abs/2306.12554</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12554] Improving Long-Horizon Imitation Through Instruction Prediction](http://arxiv.org/abs/2306.12554) #transformer</code></li>
<li>Summary: <p>Complex, long-horizon planning and its combinatorial nature pose steep
challenges for learning-based agents. Difficulties in such settings are
exacerbated in low data regimes where over-fitting stifles generalization and
compounding errors hurt accuracy. In this work, we explore the use of an often
unused source of auxiliary supervision: language. Inspired by recent advances
in transformer-based models, we train agents with an instruction prediction
loss that encourages learning temporally extended representations that operate
at a high level of abstraction. Concretely, we demonstrate that instruction
modeling significantly improves performance in planning environments when
training with a limited number of demonstrations on the BabyAI and Crafter
benchmarks. In further analysis we find that instruction modeling is most
important for tasks that require complex reasoning, while understandably
offering smaller gains in environments that require simple plans. More details
and code can be found at https://github.com/jhejna/instruction-prediction.
</p></li>
</ul>

<h3>Title: A Comparison of Time-based Models for Multimodal Emotion Recognition. (arXiv:2306.13076v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13076">http://arxiv.org/abs/2306.13076</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13076] A Comparison of Time-based Models for Multimodal Emotion Recognition](http://arxiv.org/abs/2306.13076) #transformer</code></li>
<li>Summary: <p>Emotion recognition has become an important research topic in the field of
human-computer interaction. Studies on sound and videos to understand emotions
focused mainly on analyzing facial expressions and classified 6 basic emotions.
In this study, the performance of different sequence models in multi-modal
emotion recognition was compared. The sound and images were first processed by
multi-layered CNN models, and the outputs of these models were fed into various
sequence models. The sequence model is GRU, Transformer, LSTM and Max Pooling.
Accuracy, precision, and F1 Score values of all models were calculated. The
multi-modal CREMA-D dataset was used in the experiments. As a result of the
comparison of the CREMA-D dataset, GRU-based architecture with 0.640 showed the
best result in F1 score, LSTM-based architecture with 0.699 in precision
metric, while sensitivity showed the best results over time with Max
Pooling-based architecture with 0.620. As a result, it has been observed that
the sequence models compare performances close to each other.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: SituatedGen: Incorporating Geographical and Temporal Contexts into Generative Commonsense Reasoning. (arXiv:2306.12552v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12552">http://arxiv.org/abs/2306.12552</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12552] SituatedGen: Incorporating Geographical and Temporal Contexts into Generative Commonsense Reasoning](http://arxiv.org/abs/2306.12552) #generative</code></li>
<li>Summary: <p>Recently, commonsense reasoning in text generation has attracted much
attention. Generative commonsense reasoning is the task that requires machines,
given a group of keywords, to compose a single coherent sentence with
commonsense plausibility. While existing datasets targeting generative
commonsense reasoning focus on everyday scenarios, it is unclear how well
machines reason under specific geographical and temporal contexts. We formalize
this challenging task as SituatedGen, where machines with commonsense should
generate a pair of contrastive sentences given a group of keywords including
geographical or temporal entities. We introduce a corresponding English dataset
consisting of 8,268 contrastive sentence pairs, which are built upon several
existing commonsense reasoning benchmarks with minimal manual labor.
Experiments show that state-of-the-art generative language models struggle to
generate sentences with commonsense plausibility and still lag far behind human
performance. Our dataset is publicly available at
https://github.com/yunx-z/situated_gen.
</p></li>
</ul>

<h3>Title: Generative Multimodal Entity Linking. (arXiv:2306.12725v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12725">http://arxiv.org/abs/2306.12725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12725] Generative Multimodal Entity Linking](http://arxiv.org/abs/2306.12725) #generative</code></li>
<li>Summary: <p>Multimodal Entity Linking (MEL) is the task of mapping mentions with
multimodal contexts to the referent entities from a knowledge base (e.g.,
Wikipedia). Prior MEL methods mainly focus on designing complex multimodal
interaction mechanisms and require fine-tuning all model parameters, which can
be prohibitively costly and difficult to scale in the era of Large Language
Models (LLMs). In this work, we propose GEMEL, a simple yet effective
Generative Multimodal Entity Linking method, which leverages the capabilities
of LLMs from large-scale pre-training to directly generate target entity names.
We keep the vision and language model frozen and only train a linear layer to
enable cross-modality interactions. To adapt LLMs to the MEL task, we take
advantage of the emerging in-context learning (ICL) capability of LLMs by
retrieving multimodal instances as demonstrations. Extensive experiments show
that with only ~0.3% of the model parameters fine-tuned, GEMEL achieves
state-of-the-art results on two well-established MEL datasets (4.1% accuracy
gains on WikiDiverse and 15.4% accuracy gains on WikiMEL). Our approach is
compatible with any off-the-shelf language model, paving the way towards an
efficient and general solution for utilizing LLMs in the MEL task.
</p></li>
</ul>

<h3>Title: Mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation. (arXiv:2306.12766v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12766">http://arxiv.org/abs/2306.12766</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12766] Mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation](http://arxiv.org/abs/2306.12766) #generative</code></li>
<li>Summary: <p>Structured knowledge bases (KBs) are the backbone of many
know-ledge-intensive applications, and their automated construction has
received considerable attention. In particular, open information extraction
(OpenIE) is often used to induce structure from a text. However, although it
allows high recall, the extracted knowledge tends to inherit noise from the
sources and the OpenIE algorithm. Besides, OpenIE tuples contain an open-ended,
non-canonicalized set of relations, making the extracted knowledge's downstream
exploitation harder. In this paper, we study the problem of mapping an open KB
into the fixed schema of an existing KB, specifically for the case of
commonsense knowledge. We propose approaching the problem by generative
translation, i.e., by training a language model to generate fixed-schema
assertions from open ones. Experiments show that this approach occupies a sweet
spot between traditional manual, rule-based, or classification-based
canonicalization and purely generative KB construction like COMET. Moreover, it
produces higher mapping accuracy than the former while avoiding the
association-based noise of the latter.
</p></li>
</ul>

<h3>Title: FLAG: Finding Line Anomalies (in code) with Generative AI. (arXiv:2306.12643v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12643">http://arxiv.org/abs/2306.12643</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12643] FLAG: Finding Line Anomalies (in code) with Generative AI](http://arxiv.org/abs/2306.12643) #generative</code></li>
<li>Summary: <p>Code contains security and functional bugs. The process of identifying and
localizing them is difficult and relies on human labor. In this work, we
present a novel approach (FLAG) to assist human debuggers. FLAG is based on the
lexical capabilities of generative AI, specifically, Large Language Models
(LLMs). Here, we input a code file then extract and regenerate each line within
that file for self-comparison. By comparing the original code with an
LLM-generated alternative, we can flag notable differences as anomalies for
further inspection, with features such as distance from comments and LLM
confidence also aiding this classification. This reduces the inspection search
space for the designer. Unlike other automated approaches in this area, FLAG is
language-agnostic, can work on incomplete (and even non-compiling) code and
requires no creation of security properties, functional tests or definition of
rules. In this work, we explore the features that help LLMs in this
classification and evaluate the performance of FLAG on known bugs. We use 121
benchmarks across C, Python and Verilog; with each benchmark containing a known
security or functional weakness. We conduct the experiments using two state of
the art LLMs in OpenAI's code-davinci-002 and gpt-3.5-turbo, but our approach
may be used by other models. FLAG can identify 101 of the defects and helps
reduce the search space to 12-17% of source code.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference. (arXiv:2306.12509v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12509">http://arxiv.org/abs/2306.12509</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12509] Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference](http://arxiv.org/abs/2306.12509) #large language model</code></li>
<li>Summary: <p>We view large language models (LLMs) as stochastic \emph{language layers} in
a network, where the learnable parameters are the natural language
\emph{prompts} at each layer. We stack two such layers, feeding the output of
one layer to the next. We call the stacked architecture a \emph{Deep Language
Network} (DLN). We first show how to effectively perform prompt optimization
for a 1-Layer language network (DLN-1). We then show how to train 2-layer DLNs
(DLN-2), where two prompts must be learnt. We consider the output of the first
layer as a latent variable to marginalize, and devise a variational inference
algorithm for joint prompt training. A DLN-2 reaches higher performance than a
single layer, sometimes comparable to few-shot GPT-4 even when each LLM in the
network is smaller and less powerful. The DLN code is open source:
https://github.com/microsoft/deep-language-networks .
</p></li>
</ul>

<h3>Title: Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning Ability and Human-like Biases. (arXiv:2306.12567v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12567">http://arxiv.org/abs/2306.12567</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12567] Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning Ability and Human-like Biases](http://arxiv.org/abs/2306.12567) #large language model</code></li>
<li>Summary: <p>This paper investigates whether current large language models exhibit biases
in logical reasoning, similar to humans. Specifically, we focus on syllogistic
reasoning, a well-studied form of inference in the cognitive science of human
deduction. To facilitate our analysis, we introduce a dataset called NeuBAROCO,
originally designed for psychological experiments that assess human logical
abilities in syllogistic reasoning. The dataset consists of syllogistic
inferences in both English and Japanese. We examine three types of biases
observed in human syllogistic reasoning: belief biases, conversion errors, and
atmosphere effects. Our findings demonstrate that current large language models
struggle more with problems involving these three types of biases.
</p></li>
</ul>

<h3>Title: ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews. (arXiv:2306.12587v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12587">http://arxiv.org/abs/2306.12587</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12587] ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews](http://arxiv.org/abs/2306.12587) #large language model</code></li>
<li>Summary: <p>Revising scientific papers based on peer feedback is a challenging task that
requires not only deep scientific knowledge and reasoning, but also the ability
to recognize the implicit requests in high-level feedback and to choose the
best of many possible ways to update the manuscript in response. We introduce
this task for large language models and release ARIES, a dataset of review
comments and their corresponding paper edits, to enable training and evaluating
models. We study two versions of the task: comment-edit alignment and edit
generation, and evaluate several baselines, including GPT-4. We find that
models struggle even to identify the edits that correspond to a comment,
especially in cases where the comment is phrased in an indirect way or where
the edit addresses the spirit of a comment but not the precise request. When
tasked with generating edits, GPT-4 often succeeds in addressing comments on a
surface level, but it rigidly follows the wording of the feedback rather than
the underlying intent, and includes fewer technical details than human-written
edits. We hope that our formalization, dataset, and analysis will form a
foundation for future work in this area.
</p></li>
</ul>

<h3>Title: Identifying and Extracting Rare Disease Phenotypes with Large Language Models. (arXiv:2306.12656v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12656">http://arxiv.org/abs/2306.12656</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12656] Identifying and Extracting Rare Disease Phenotypes with Large Language Models](http://arxiv.org/abs/2306.12656) #large language model</code></li>
<li>Summary: <p>Rare diseases (RDs) are collectively common and affect 300 million people
worldwide. Accurate phenotyping is critical for informing diagnosis and
treatment, but RD phenotypes are often embedded in unstructured text and
time-consuming to extract manually. While natural language processing (NLP)
models can perform named entity recognition (NER) to automate extraction, a
major bottleneck is the development of a large, annotated corpus for model
training. Recently, prompt learning emerged as an NLP paradigm that can lead to
more generalizable results without any (zero-shot) or few labeled samples
(few-shot). Despite growing interest in ChatGPT, a revolutionary large language
model capable of following complex human prompts and generating high-quality
responses, none have studied its NER performance for RDs in the zero- and
few-shot settings. To this end, we engineered novel prompts aimed at extracting
RD phenotypes and, to the best of our knowledge, are the first the establish a
benchmark for evaluating ChatGPT's performance in these settings. We compared
its performance to the traditional fine-tuning approach and conducted an
in-depth error analysis. Overall, fine-tuning BioClinicalBERT resulted in
higher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.591 in the
zero- and few-shot settings, respectively). Despite this, ChatGPT achieved
similar or higher accuracy for certain entities (i.e., rare diseases and signs)
in the one-shot setting (F1 of 0.776 and 0.725). This suggests that with
appropriate prompt engineering, ChatGPT has the potential to match or
outperform fine-tuned language models for certain entity types with just one
labeled sample. While the proliferation of large language models may provide
opportunities for supporting RD diagnosis and treatment, researchers and
clinicians should critically evaluate model outputs and be well-informed of
their limitations.
</p></li>
</ul>

<h3>Title: Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models. (arXiv:2306.12659v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12659">http://arxiv.org/abs/2306.12659</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12659] Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models](http://arxiv.org/abs/2306.12659) #large language model</code></li>
<li>Summary: <p>Sentiment analysis is a vital tool for uncovering insights from financial
articles, news, and social media, shaping our understanding of market
movements. Despite the impressive capabilities of large language models (LLMs)
in financial natural language processing (NLP), they still struggle with
accurately interpreting numerical values and grasping financial context,
limiting their effectiveness in predicting financial sentiment. In this paper,
we introduce a simple yet effective instruction tuning approach to address
these issues. By transforming a small portion of supervised financial sentiment
analysis data into instruction data and fine-tuning a general-purpose LLM with
this method, we achieve remarkable advancements in financial sentiment
analysis. In the experiment, our approach outperforms state-of-the-art
supervised sentiment analysis models, as well as widely used LLMs like ChatGPT
and LLaMAs, particularly in scenarios where numerical understanding and
contextual comprehension are vital.
</p></li>
</ul>

<h3>Title: AudioPaLM: A Large Language Model That Can Speak and Listen. (arXiv:2306.12925v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12925">http://arxiv.org/abs/2306.12925</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12925] AudioPaLM: A Large Language Model That Can Speak and Listen](http://arxiv.org/abs/2306.12925) #large language model</code></li>
<li>Summary: <p>We introduce AudioPaLM, a large language model for speech understanding and
generation. AudioPaLM fuses text-based and speech-based language models, PaLM-2
[Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified
multimodal architecture that can process and generate text and speech with
applications including speech recognition and speech-to-speech translation.
AudioPaLM inherits the capability to preserve paralinguistic information such
as speaker identity and intonation from AudioLM and the linguistic knowledge
present only in text large language models such as PaLM-2. We demonstrate that
initializing AudioPaLM with the weights of a text-only large language model
improves speech processing, successfully leveraging the larger quantity of text
training data used in pretraining to assist with the speech tasks. The
resulting model significantly outperforms existing systems for speech
translation tasks and has the ability to perform zero-shot speech-to-text
translation for many languages for which input/target language combinations
were not seen in training. AudioPaLM also demonstrates features of audio
language models, such as transferring a voice across languages based on a short
spoken prompt. We release examples of our method at
https://google-research.github.io/seanet/audiopalm/examples
</p></li>
</ul>

<h3>Title: Tracking public attitudes toward ChatGPT on Twitter using sentiment analysis and topic modeling. (arXiv:2306.12951v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12951">http://arxiv.org/abs/2306.12951</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12951] Tracking public attitudes toward ChatGPT on Twitter using sentiment analysis and topic modeling](http://arxiv.org/abs/2306.12951) #large language model</code></li>
<li>Summary: <p>ChatGPT sets a new record with the fastest-growing user base, as a chatbot
powered by a large language model (LLM). While it demonstrates state-of-the-art
capabilities in a variety of language-generating tasks, it also raises
widespread public concerns regarding its societal impact. In this paper, we
utilize natural language processing approaches to investigate the public
attitudes towards ChatGPT by applying sentiment analysis and topic modeling
techniques to Twitter data. Our result shows that the overall sentiment is
largely neutral to positive, which also holds true across different occupation
groups. Among a wide range of topics mentioned in tweets, the most popular
topics are Artificial Intelligence, Search Engines, Education, Writing, and
Question Answering.
</p></li>
</ul>

<h3>Title: Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs. (arXiv:2306.13063v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13063">http://arxiv.org/abs/2306.13063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13063] Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs](http://arxiv.org/abs/2306.13063) #large language model</code></li>
<li>Summary: <p>The task of empowering large language models (LLMs) to accurately express
their confidence, referred to as confidence elicitation, is essential in
ensuring reliable and trustworthy decision-making processes. Previous methods,
which primarily rely on model logits, have become less suitable for LLMs and
even infeasible with the rise of closed-source LLMs (e.g., commercialized LLM
APIs). This leads to a growing need to explore the untapped area of
\emph{non-logit-based} approaches to estimate the uncertainty of LLMs. Hence,
in this study, we investigate approaches for confidence elicitation that do not
require model fine-tuning or access to proprietary information. We introduce
three categories of methods: verbalize-based, consistency-based, and their
hybrid methods for benchmarking, and evaluate their performance across five
types of datasets and four widely-used LLMs. Our analysis of these methods
uncovers several key insights: 1) LLMs often exhibit a high degree of
overconfidence when verbalizing their confidence; 2) Prompting strategies such
as CoT, Top-K and Multi-step confidences improve calibration of verbalized
confidence; 3) Consistency-based methods outperform the verbalized confidences
in most cases, with particularly notable improvements on the arithmetic
reasoning task; 4) Hybrid methods consistently deliver the best performance
over their baselines, thereby emerging as a promising state-of-the-art
approach; 5) Despite these advancements, all investigated methods continue to
struggle with challenging tasks, such as those requiring professional
knowledge, leaving significant scope for improvement of confidence elicitation.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Curriculum Knowledge Switching for Pancreas Segmentation. (arXiv:2306.12651v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.12651">http://arxiv.org/abs/2306.12651</a></li>
<li>Code URL: <a href="https://github.com/kunzhan/cks_pancreas">https://github.com/kunzhan/cks_pancreas</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.12651] Curriculum Knowledge Switching for Pancreas Segmentation](http://arxiv.org/abs/2306.12651) #segmentation</code></li>
<li>Summary: <p>Pancreas segmentation is challenging due to the small proportion and highly
changeable anatomical structure. It motivates us to propose a novel
segmentation framework, namely Curriculum Knowledge Switching (CKS) framework,
which decomposes detecting pancreas into three phases with different difficulty
extent: straightforward, difficult, and challenging. The framework switches
from straightforward to challenging phases and thereby gradually learns to
detect pancreas. In addition, we adopt the momentum update parameter updating
mechanism during switching, ensuring the loss converges gradually when the
input dataset changes. Experimental results show that different neural network
backbones with the CKS framework achieved state-of-the-art performance on the
NIH dataset as measured by the DSC metric.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
