<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: UNICORN: A Unified Backdoor Trigger Inversion Framework. (arXiv:2304.02786v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02786">http://arxiv.org/abs/2304.02786</a></li>
<li>Code URL: <a href="https://github.com/ru-system-software-and-security/unicorn">https://github.com/ru-system-software-and-security/unicorn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02786] UNICORN: A Unified Backdoor Trigger Inversion Framework](http://arxiv.org/abs/2304.02786) #security</code></li>
<li>Summary: <p>The backdoor attack, where the adversary uses inputs stamped with triggers
(e.g., a patch) to activate pre-planted malicious behaviors, is a severe threat
to Deep Neural Network (DNN) models. Trigger inversion is an effective way of
identifying backdoor models and understanding embedded adversarial behaviors. A
challenge of trigger inversion is that there are many ways of constructing the
trigger. Existing methods cannot generalize to various types of triggers by
making certain assumptions or attack-specific constraints. The fundamental
reason is that existing work does not consider the trigger's design space in
their formulation of the inversion problem. This work formally defines and
analyzes the triggers injected in different spaces and the inversion problem.
Then, it proposes a unified framework to invert backdoor triggers based on the
formalization of triggers and the identified inner behaviors of backdoor models
from our analysis. Our prototype UNICORN is general and effective in inverting
backdoor triggers in DNNs. The code can be found at
https://github.com/RU-System-Software-and-Security/UNICORN.
</p></li>
</ul>

<h3>Title: On the Limits of Cross-Authentication Checks for GNSS Signals. (arXiv:2304.02977v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02977">http://arxiv.org/abs/2304.02977</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02977] On the Limits of Cross-Authentication Checks for GNSS Signals](http://arxiv.org/abs/2304.02977) #security</code></li>
<li>Summary: <p>Global navigation satellite systems (GNSSs) are implementing security
mechanisms: examples are Galileo open service navigation message authentication
(OS-NMA) and GPS chips-message robust authentication (CHIMERA). Each of these
mechanisms operates in a single band. However, nowadays, even commercial GNSS
receivers typically compute the position, velocity, and time (PVT) solution
using multiple constellations and signals from multiple bands at once,
significantly improving both accuracy and availability. Hence,
cross-authentication checks have been proposed, based on the PVT obtained from
the mixture of authenticated and non-authenticated signals.
</p></li>
</ul>

<p>In this paper, first, we formalize the models for the cross-authentication
checks. Next, we describe, for each check, a spoofing attack to generate a fake
signal leading the victim to a target PVT without notice. We analytically
relate the degrees of the freedom of the attacker in manipulating the victim's
solution to both the employed security checks and the number of open signals
that can be tampered with by the attacker. We test the performance of the
considered attack strategies on an experimental dataset. Lastly, we show the
limits of the PVT-based GNSS cross-authentication checks, where both
authenticated and non-authenticated signals are used.
</p>

<h3>Title: Smart Contract and DeFi Security: Insights from Tool Evaluations and Practitioner Surveys. (arXiv:2304.02981v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02981">http://arxiv.org/abs/2304.02981</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02981] Smart Contract and DeFi Security: Insights from Tool Evaluations and Practitioner Surveys](http://arxiv.org/abs/2304.02981) #security</code></li>
<li>Summary: <p>The growth of the decentralized finance (DeFi) ecosystem built on blockchain
technology and smart contracts has led to an increased demand for secure and
reliable smart contract development. However, attacks targeting smart contracts
are increasing, causing an estimated \$6.45 billion in financial losses.
Researchers have proposed various automated security tools to detect
vulnerabilities, but their real-world impact remains uncertain.
</p></li>
</ul>

<p>In this paper, we aim to shed light on the effectiveness of automated
security tools in identifying vulnerabilities that can lead to high-profile
attacks, and their overall usage within the industry. Our comprehensive study
encompasses an evaluation of five SoTA automated security tools, an analysis of
127 high-impact real-world attacks resulting in \$2.3 billion in losses, and a
survey of 49 developers and auditors working in leading DeFi protocols. Our
findings reveal a stark reality: the tools could have prevented a mere 8% of
the attacks in our dataset, amounting to \$149 million out of the \$2.3 billion
in losses. Notably, all preventable attacks were related to reentrancy
vulnerabilities. Furthermore, practitioners distinguish logic-related bugs and
protocol layer vulnerabilities as significant threats that are not adequately
addressed by existing security tools. Our results emphasize the need to develop
specialized tools catering to the distinct demands and expectations of
developers and auditors. Further, our study highlights the necessity for
continuous advancements in security tools to effectively tackle the
ever-evolving challenges confronting the DeFi ecosystem.
</p>

<h3>Title: Hierarchical Graph Neural Network with Cross-Attention for Cross-Device User Matching. (arXiv:2304.03215v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03215">http://arxiv.org/abs/2304.03215</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03215] Hierarchical Graph Neural Network with Cross-Attention for Cross-Device User Matching](http://arxiv.org/abs/2304.03215) #security</code></li>
<li>Summary: <p>Cross-device user matching is a critical problem in numerous domains,
including advertising, recommender systems, and cybersecurity. It involves
identifying and linking different devices belonging to the same person,
utilizing sequence logs. Previous data mining techniques have struggled to
address the long-range dependencies and higher-order connections between the
logs. Recently, researchers have modeled this problem as a graph problem and
proposed a two-tier graph contextual embedding (TGCE) neural network
architecture, which outperforms previous methods. In this paper, we propose a
novel hierarchical graph neural network architecture (HGNN), which has a more
computationally efficient second level design than TGCE. Furthermore, we
introduce a cross-attention (Cross-Att) mechanism in our model, which improves
performance by 5% compared to the state-of-the-art TGCE method.
</p></li>
</ul>

<h3>Title: GIF: A General Graph Unlearning Strategy via Influence Function. (arXiv:2304.02835v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02835">http://arxiv.org/abs/2304.02835</a></li>
<li>Code URL: <a href="https://github.com/wujcan/gif-torch">https://github.com/wujcan/gif-torch</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02835] GIF: A General Graph Unlearning Strategy via Influence Function](http://arxiv.org/abs/2304.02835) #security</code></li>
<li>Summary: <p>With the greater emphasis on privacy and security in our society, the problem
of graph unlearning -- revoking the influence of specific data on the trained
GNN model, is drawing increasing attention. However, ranging from machine
unlearning to recently emerged graph unlearning methods, existing efforts
either resort to retraining paradigm, or perform approximate erasure that fails
to consider the inter-dependency between connected neighbors or imposes
constraints on GNN structure, therefore hard to achieve satisfying
performance-complexity trade-offs.
</p></li>
</ul>

<p>In this work, we explore the influence function tailored for graph
unlearning, so as to improve the unlearning efficacy and efficiency for graph
unlearning. We first present a unified problem formulation of diverse graph
unlearning tasks \wrt node, edge, and feature. Then, we recognize the crux to
the inability of traditional influence function for graph unlearning, and
devise Graph Influence Function (GIF), a model-agnostic unlearning method that
can efficiently and accurately estimate parameter changes in response to a
$\epsilon$-mass perturbation in deleted data. The idea is to supplement the
objective of the traditional influence function with an additional loss term of
the influenced neighbors due to the structural dependency. Further deductions
on the closed-form solution of parameter changes provide a better understanding
of the unlearning mechanism. We conduct extensive experiments on four
representative GNN models and three benchmark datasets to justify the
superiority of GIF for diverse graph unlearning tasks in terms of unlearning
efficacy, model utility, and unlearning efficiency. Our implementations are
available at \url{https://github.com/wujcan/GIF-torch/}.
</p>

<h2>privacy</h2>
<h3>Title: Source-free Domain Adaptation Requires Penalized Diversity. (arXiv:2304.02798v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02798">http://arxiv.org/abs/2304.02798</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02798] Source-free Domain Adaptation Requires Penalized Diversity](http://arxiv.org/abs/2304.02798) #privacy</code></li>
<li>Summary: <p>While neural networks are capable of achieving human-like performance in many
tasks such as image classification, the impressive performance of each model is
limited to its own dataset. Source-free domain adaptation (SFDA) was introduced
to address knowledge transfer between different domains in the absence of
source data, thus, increasing data privacy. Diversity in representation space
can be vital to a model`s adaptability in varied and difficult domains. In
unsupervised SFDA, the diversity is limited to learning a single hypothesis on
the source or learning multiple hypotheses with a shared feature extractor.
Motivated by the improved predictive performance of ensembles, we propose a
novel unsupervised SFDA algorithm that promotes representational diversity
through the use of separate feature extractors with Distinct Backbone
Architectures (DBA). Although diversity in feature space is increased, the
unconstrained mutual information (MI) maximization may potentially introduce
amplification of weak hypotheses. Thus we introduce the Weak Hypothesis
Penalization (WHP) regularizer as a mitigation strategy. Our work proposes
Penalized Diversity (PD) where the synergy of DBA and WHP is applied to
unsupervised source-free domain adaptation for covariate shift. In addition, PD
is augmented with a weighted MI maximization objective for label distribution
shift. Empirical results on natural, synthetic, and medical domains demonstrate
the effectiveness of PD under different distributional shifts.
</p></li>
</ul>

<h3>Title: The Saudi Privacy Policy Dataset. (arXiv:2304.02757v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02757">http://arxiv.org/abs/2304.02757</a></li>
<li>Code URL: <a href="https://github.com/iwan-rg/saudi_privacy_policy">https://github.com/iwan-rg/saudi_privacy_policy</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02757] The Saudi Privacy Policy Dataset](http://arxiv.org/abs/2304.02757) #privacy</code></li>
<li>Summary: <p>This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation
of Arabic privacy policies from various sectors in Saudi Arabia, annotated
according to the 10 principles of the Personal Data Protection Law (PDPL); the
PDPL was established to be compatible with General Data Protection Regulation
(GDPR); one of the most comprehensive data regulations worldwide. Data were
collected from multiple sources, including the Saudi Central Bank, the Saudi
Arabia National United Platform, the Council of Health Insurance, and general
websites using Google and Wikipedia. The final dataset includes 1,000 websites
belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size
of 8,353 KB. The annotated dataset offers significant reuse potential for
assessing privacy policy compliance, benchmarking privacy practices across
industries, and developing automated tools for monitoring adherence to data
protection regulations. By providing a comprehensive and annotated dataset of
privacy policies, this paper aims to facilitate further research and
development in the areas of privacy policy analysis, natural language
processing, and machine learning applications related to privacy and data
protection, while also serving as an essential resource for researchers,
policymakers, and industry professionals interested in understanding and
promoting compliance with privacy regulations in Saudi Arabia.
</p></li>
</ul>

<h3>Title: ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model. (arXiv:2304.03086v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03086">http://arxiv.org/abs/2304.03086</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03086] ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model](http://arxiv.org/abs/2304.03086) #privacy</code></li>
<li>Summary: <p>The ChatGPT, as a lite and conversational variant of Generative Pretrained
Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large
Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred
up a lot of interest among researchers and practitioners by their impressive
skills in natural language processing tasks, which have a profound impact on a
wide range of fields. This paper mainly discusses the future applications of
LLMs in dentistry. We introduce two primary LLM deployment methods in
dentistry, including automated dental diagnosis and cross-modal dental
diagnosis, and examine their potential applications. Especially, equipped with
a cross-modal encoder, a single LLM can manage multi-source data and conduct
advanced natural language reasoning to perform complex clinical operations. A
use case is presented to demonstrate the potential of a fully automatic
Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer
significant potential benefits, the challenges, such as data privacy, data
quality, and model bias, need further study. Overall, LLMs have the potential
to revolutionize dental diagnosis and treatment, which indicates a promising
avenue for clinical application and research in dentistry.
</p></li>
</ul>

<h3>Title: FedBot: Enhancing Privacy in Chatbots with Federated Learning. (arXiv:2304.03228v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03228">http://arxiv.org/abs/2304.03228</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03228] FedBot: Enhancing Privacy in Chatbots with Federated Learning](http://arxiv.org/abs/2304.03228) #privacy</code></li>
<li>Summary: <p>Chatbots are mainly data-driven and usually based on utterances that might be
sensitive. However, training deep learning models on shared data can violate
user privacy. Such issues have commonly existed in chatbots since their
inception. In the literature, there have been many approaches to deal with
privacy, such as differential privacy and secure multi-party computation, but
most of them need to have access to users' data. In this context, Federated
Learning (FL) aims to protect data privacy through distributed learning methods
that keep the data in its location. This paper presents Fedbot, a
proof-of-concept (POC) privacy-preserving chatbot that leverages large-scale
customer support data. The POC combines Deep Bidirectional Transformer models
and federated learning algorithms to protect customer data privacy during
collaborative model training. The results of the proof-of-concept showcase the
potential for privacy-preserving chatbots to transform the customer support
industry by delivering personalized and efficient customer service that meets
data privacy regulations and legal requirements. Furthermore, the system is
specifically designed to improve its performance and accuracy over time by
leveraging its ability to learn from previous interactions.
</p></li>
</ul>

<h3>Title: Robust, privacy-preserving, transparent, and auditable on-device blocklisting. (arXiv:2304.02810v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02810">http://arxiv.org/abs/2304.02810</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02810] Robust, privacy-preserving, transparent, and auditable on-device blocklisting](http://arxiv.org/abs/2304.02810) #privacy</code></li>
<li>Summary: <p>With the accelerated adoption of end-to-end encryption, there is an
opportunity to re-architect security and anti-abuse primitives in a manner that
preserves new privacy expectations. In this paper, we consider two novel
protocols for on-device blocklisting that allow a client to determine whether
an object (e.g., URL, document, image, etc.) is harmful based on threat
information possessed by a so-called remote enforcer in a way that is both
privacy-preserving and trustworthy. Our protocols leverage a unique combination
of private set intersection to promote privacy, cryptographic hashes to ensure
resilience to false positives, cryptographic signatures to improve
transparency, and Merkle inclusion proofs to ensure consistency and
auditability. We benchmark our protocols -- one that is time-efficient, and the
other space-efficient -- to demonstrate their practical use for applications
such as email, messaging, storage, and other applications. We also highlight
remaining challenges, such as privacy and censorship tensions that exist with
logging or reporting. We consider our work to be a critical first step towards
enabling complex, multi-stakeholder discussions on how best to provide
on-device protections.
</p></li>
</ul>

<h3>Title: Protecting User Privacy in Online Settings via Supervised Learning. (arXiv:2304.02870v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02870">http://arxiv.org/abs/2304.02870</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02870] Protecting User Privacy in Online Settings via Supervised Learning](http://arxiv.org/abs/2304.02870) #privacy</code></li>
<li>Summary: <p>Companies that have an online presence-in particular, companies that are
exclusively digital-often subscribe to this business model: collect data from
the user base, then expose the data to advertisement agencies in order to turn
a profit. Such companies routinely market a service as "free", while
obfuscating the fact that they tend to "charge" users in the currency of
personal information rather than money. However, online companies also gather
user data for more principled purposes, such as improving the user experience
and aggregating statistics. The problem is the sale of user data to third
parties. In this work, we design an intelligent approach to online privacy
protection that leverages supervised learning. By detecting and blocking data
collection that might infringe on a user's privacy, we can restore a degree of
digital privacy to the user. In our evaluation, we collect a dataset of network
requests and measure the performance of several classifiers that adhere to the
supervised learning paradigm. The results of our evaluation demonstrate the
feasibility and potential of our approach.
</p></li>
</ul>

<h3>Title: Quantifying and Defending against Privacy Threats on Federated Knowledge Graph Embedding. (arXiv:2304.02932v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02932">http://arxiv.org/abs/2304.02932</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02932] Quantifying and Defending against Privacy Threats on Federated Knowledge Graph Embedding](http://arxiv.org/abs/2304.02932) #privacy</code></li>
<li>Summary: <p>Knowledge Graph Embedding (KGE) is a fundamental technique that extracts
expressive representation from knowledge graph (KG) to facilitate diverse
downstream tasks. The emerging federated KGE (FKGE) collaboratively trains from
distributed KGs held among clients while avoiding exchanging clients' sensitive
raw KGs, which can still suffer from privacy threats as evidenced in other
federated model trainings (e.g., neural networks). However, quantifying and
defending against such privacy threats remain unexplored for FKGE which
possesses unique properties not shared by previously studied models. In this
paper, we conduct the first holistic study of the privacy threat on FKGE from
both attack and defense perspectives. For the attack, we quantify the privacy
threat by proposing three new inference attacks, which reveal substantial
privacy risk by successfully inferring the existence of the KG triple from
victim clients. For the defense, we propose DP-Flames, a novel differentially
private FKGE with private selection, which offers a better privacy-utility
tradeoff by exploiting the entity-binding sparse gradient property of FKGE and
comes with a tight privacy accountant by incorporating the state-of-the-art
private selection technique. We further propose an adaptive privacy budget
allocation policy to dynamically adjust defense magnitude across the training
procedure. Comprehensive evaluations demonstrate that the proposed defense can
successfully mitigate the privacy threat by effectively reducing the success
rate of inference attacks from $83.1\%$ to $59.4\%$ on average with only a
modest utility decrease.
</p></li>
</ul>

<h3>Title: When approximate design for fast homomorphic computation provides differential privacy guarantees. (arXiv:2304.02959v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02959">http://arxiv.org/abs/2304.02959</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02959] When approximate design for fast homomorphic computation provides differential privacy guarantees](http://arxiv.org/abs/2304.02959) #privacy</code></li>
<li>Summary: <p>While machine learning has become pervasive in as diversified fields as
industry, healthcare, social networks, privacy concerns regarding the training
data have gained a critical importance. In settings where several parties wish
to collaboratively train a common model without jeopardizing their sensitive
data, the need for a private training protocol is particularly stringent and
implies to protect the data against both the model's end-users and the actors
of the training phase. Differential privacy (DP) and cryptographic primitives
are complementary popular countermeasures against privacy attacks. Among these
cryptographic primitives, fully homomorphic encryption (FHE) offers ciphertext
malleability at the cost of time-consuming operations in the homomorphic
domain. In this paper, we design SHIELD, a probabilistic approximation
algorithm for the argmax operator which is both fast when homomorphically
executed and whose inaccuracy is used as a feature to ensure DP guarantees.
Even if SHIELD could have other applications, we here focus on one setting and
seamlessly integrate it in the SPEED collaborative training framework from
"SPEED: Secure, PrivatE, and Efficient Deep learning" (Grivet S\'ebert et al.,
2021) to improve its computational efficiency. After thoroughly describing the
FHE implementation of our algorithm and its DP analysis, we present
experimental results. To the best of our knowledge, it is the first work in
which relaxing the accuracy of an homomorphic calculation is constructively
usable as a degree of freedom to achieve better FHE performances.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models. (arXiv:2304.03218v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03218">http://arxiv.org/abs/2304.03218</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03218] Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models](http://arxiv.org/abs/2304.03218) #protect</code></li>
<li>Summary: <p>To safely deploy deep learning-based computer vision models for
computer-aided detection and diagnosis, we must ensure that they are robust and
reliable. Towards that goal, algorithmic auditing has received substantial
attention. To guide their audit procedures, existing methods rely on heuristic
approaches or high-level objectives (e.g., non-discrimination in regards to
protected attributes, such as sex, gender, or race). However, algorithms may
show bias with respect to various attributes beyond the more obvious ones, and
integrity issues related to these more subtle attributes can have serious
consequences. To enable the generation of actionable, data-driven hypotheses
which identify specific dataset attributes likely to induce model bias, we
contribute a first technique for the rigorous, quantitative screening of
medical image datasets. Drawing from literature in the causal inference and
information theory domains, our procedure decomposes the risks associated with
dataset attributes in terms of their detectability and utility (defined as the
amount of information knowing the attribute gives about a task label). To
demonstrate the effectiveness and sensitivity of our method, we develop a
variety of datasets with synthetically inserted artifacts with different
degrees of association to the target label that allow evaluation of inherited
model biases via comparison of performance against true counterfactual
examples. Using these datasets and results from hundreds of trained models, we
show our screening method reliably identifies nearly imperceptible
bias-inducing artifacts. Lastly, we apply our method to the natural attributes
of a popular skin-lesion dataset and demonstrate its success. Our approach
provides a means to perform more systematic algorithmic audits and guide future
data collection efforts in pursuit of safer and more reliable models.
</p></li>
</ul>

<h3>Title: Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks. (arXiv:2304.02739v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02739">http://arxiv.org/abs/2304.02739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02739] Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks](http://arxiv.org/abs/2304.02739) #protect</code></li>
<li>Summary: <p>This paper investigates the potential of semi-supervised Generative
Adversarial Networks (GANs) to fine-tune pretrained language models in order to
classify Bengali fake reviews from real reviews with a few annotated data. With
the rise of social media and e-commerce, the ability to detect fake or
deceptive reviews is becoming increasingly important in order to protect
consumers from being misled by false information. Any machine learning model
will have trouble identifying a fake review, especially for a low resource
language like Bengali. We have demonstrated that the proposed semi-supervised
GAN-LM architecture (generative adversarial network on top of a pretrained
language model) is a viable solution in classifying Bengali fake reviews as the
experimental results suggest that even with only 1024 annotated samples,
BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and
a f1-score of 84.89% outperforming other pretrained language models -
BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and
10% respectively in terms of accuracy. The experiments were conducted on a
manually labeled food review dataset consisting of total 6014 real and fake
reviews collected from various social media groups. Researchers that are
experiencing difficulty recognizing not just fake reviews but other
classification issues owing to a lack of labeled data may find a solution in
our proposed methodology.
</p></li>
</ul>

<h3>Title: Protected or Porous: A Comparative Analysis of Threat Detection Capability of IoT Safeguards. (arXiv:2304.03045v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03045">http://arxiv.org/abs/2304.03045</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03045] Protected or Porous: A Comparative Analysis of Threat Detection Capability of IoT Safeguards](http://arxiv.org/abs/2304.03045) #protect</code></li>
<li>Summary: <p>Consumer Internet of Things (IoT) devices are increasingly common, from smart
speakers to security cameras, in homes. Along with their benefits come
potential privacy and security threats. To limit these threats a number of
commercial services have become available (IoT safeguards). The safeguards
claim to provide protection against IoT privacy risks and security threats.
However, the effectiveness and the associated privacy risks of these safeguards
remains a key open question. In this paper, we investigate the threat detection
capabilities of IoT safeguards for the first time. We develop and release an
approach for automated safeguards experimentation to reveal their response to
common security threats and privacy risks. We perform thousands of automated
experiments using popular commercial IoT safeguards when deployed in a large
IoT testbed. Our results indicate not only that these devices may be
ineffective in preventing risks, but also their cloud interactions and data
collection operations may introduce privacy risks for the households that adopt
them.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability. (arXiv:2304.02688v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02688">http://arxiv.org/abs/2304.02688</a></li>
<li>Code URL: <a href="https://github.com/framartin/rfn-flatness-transferability">https://github.com/framartin/rfn-flatness-transferability</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02688] Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability](http://arxiv.org/abs/2304.02688) #attack</code></li>
<li>Summary: <p>Transferability is the property of adversarial examples to be misclassified
by other models than the surrogate model for which they were crafted. Previous
research has shown that transferability is substantially increased when the
training of the surrogate model has been early stopped. A common hypothesis to
explain this is that the later training epochs are when models learn the
non-robust features that adversarial attacks exploit. Hence, an early stopped
model is more robust (hence, a better surrogate) than fully trained models. We
demonstrate that the reasons why early stopping improves transferability lie in
the side effects it has on the learning dynamics of the model. We first show
that early stopping benefits transferability even on models learning from data
with non-robust features. We then establish links between transferability and
the exploration of the loss landscape in the parameter space, on which early
stopping has an inherent effect. More precisely, we observe that
transferability peaks when the learning rate decays, which is also the time at
which the sharpness of the loss significantly drops. This leads us to propose
RFN, a new approach for transferability that minimizes loss sharpness during
training in order to maximize transferability. We show that by searching for
large flat neighborhoods, RFN always improves over early stopping (by up to 47
points of transferability rate) and is competitive to (if not better than)
strong state-of-the-art baselines.
</p></li>
</ul>

<h3>Title: A Certified Radius-Guided Attack Framework to Image Segmentation Models. (arXiv:2304.02693v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02693">http://arxiv.org/abs/2304.02693</a></li>
<li>Code URL: <a href="https://github.com/randomizedheap/cr_attack">https://github.com/randomizedheap/cr_attack</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02693] A Certified Radius-Guided Attack Framework to Image Segmentation Models](http://arxiv.org/abs/2304.02693) #attack</code></li>
<li>Summary: <p>Image segmentation is an important problem in many safety-critical
applications. Recent studies show that modern image segmentation models are
vulnerable to adversarial perturbations, while existing attack methods mainly
follow the idea of attacking image classification models. We argue that image
segmentation and classification have inherent differences, and design an attack
framework specially for image segmentation models. Our attack framework is
inspired by certified radius, which was originally used by defenders to defend
against adversarial perturbations to classification models. We are the first,
from the attacker perspective, to leverage the properties of certified radius
and propose a certified radius guided attack framework against image
segmentation models. Specifically, we first adapt randomized smoothing, the
state-of-the-art certification method for classification models, to derive the
pixel's certified radius. We then focus more on disrupting pixels with
relatively smaller certified radii and design a pixel-wise certified radius
guided loss, when plugged into any existing white-box attack, yields our
certified radius-guided white-box attack. Next, we propose the first black-box
attack to image segmentation models via bandit. We design a novel gradient
estimator, based on bandit feedback, which is query-efficient and provably
unbiased and stable. We use this gradient estimator to design a projected
bandit gradient descent (PBGD) attack, as well as a certified radius-guided
PBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieve
asymptotically optimal attack performance with an optimal rate. We evaluate our
certified-radius guided white-box and black-box attacks on multiple modern
image segmentation models and datasets. Our results validate the effectiveness
of our certified radius-guided attack framework.
</p></li>
</ul>

<h3>Title: FACE-AUDITOR: Data Auditing in Facial Recognition Systems. (arXiv:2304.02782v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02782">http://arxiv.org/abs/2304.02782</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02782] FACE-AUDITOR: Data Auditing in Facial Recognition Systems](http://arxiv.org/abs/2304.02782) #attack</code></li>
<li>Summary: <p>Few-shot-based facial recognition systems have gained increasing attention
due to their scalability and ability to work with a few face images during the
model deployment phase. However, the power of facial recognition systems
enables entities with moderate resources to canvas the Internet and build
well-performed facial recognition models without people's awareness and
consent. To prevent the face images from being misused, one straightforward
approach is to modify the raw face images before sharing them, which inevitably
destroys the semantic information, increases the difficulty of retroactivity,
and is still prone to adaptive attacks. Therefore, an auditing method that does
not interfere with the facial recognition model's utility and cannot be quickly
bypassed is urgently needed.
</p></li>
</ul>

<p>In this paper, we formulate the auditing process as a user-level membership
inference problem and propose a complete toolkit FACE-AUDITOR that can
carefully choose the probing set to query the few-shot-based facial recognition
model and determine whether any of a user's face images is used in training the
model. We further propose to use the similarity scores between the original
face images as reference information to improve the auditing performance.
Extensive experiments on multiple real-world face image datasets show that
FACE-AUDITOR can achieve auditing accuracy of up to $99\%$. Finally, we show
that FACE-AUDITOR is robust in the presence of several perturbation mechanisms
to the training images or the target models. The source code of our experiments
can be found at \url{https://github.com/MinChen00/Face-Auditor}.
</p>

<h3>Title: TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph. (arXiv:2304.02838v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02838">http://arxiv.org/abs/2304.02838</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02838] TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph](http://arxiv.org/abs/2304.02838) #attack</code></li>
<li>Summary: <p>APT detection is difficult to detect due to the long-term latency, covert and
slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle
these issues, we propose TBDetector, a transformer-based advanced persistent
threat detection method for APT attack detection. Considering that provenance
graphs provide rich historical information and have the powerful attacks
historic correlation ability to identify anomalous activities, TBDetector
employs provenance analysis for APT detection, which summarizes long-running
system execution with space efficiency and utilizes transformer with
self-attention based encoder-decoder to extract long-term contextual features
of system states to detect slow-acting attacks. Furthermore, we further
introduce anomaly scores to investigate the anomaly of different system states,
where each state is calculated with an anomaly score corresponding to its
similarity score and isolation score. To evaluate the effectiveness of the
proposed method, we have conducted experiments on five public datasets, i.e.,
streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimental
results and comparisons with state-of-the-art methods have exhibited better
performance of our proposed method.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Real-Time Dense 3D Mapping of Underwater Environments. (arXiv:2304.02704v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02704">http://arxiv.org/abs/2304.02704</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02704] Real-Time Dense 3D Mapping of Underwater Environments](http://arxiv.org/abs/2304.02704) #robust</code></li>
<li>Summary: <p>This paper addresses real-time dense 3D reconstruction for a
resource-constrained Autonomous Underwater Vehicle (AUV). Underwater
vision-guided operations are among the most challenging as they combine 3D
motion in the presence of external forces, limited visibility, and absence of
global positioning. Obstacle avoidance and effective path planning require
online dense reconstructions of the environment. Autonomous operation is
central to environmental monitoring, marine archaeology, resource utilization,
and underwater cave exploration. To address this problem, we propose to use
SVIn2, a robust VIO method, together with a real-time 3D reconstruction
pipeline. We provide extensive evaluation on four challenging underwater
datasets. Our pipeline produces comparable reconstruction with that of COLMAP,
the state-of-the-art offline 3D reconstruction method, at high frame rates on a
single CPU.
</p></li>
</ul>

<h3>Title: Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets. (arXiv:2304.02847v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02847">http://arxiv.org/abs/2304.02847</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02847] Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets](http://arxiv.org/abs/2304.02847) #robust</code></li>
<li>Summary: <p>Deep networks have achieved impressive results on a range of well-curated
benchmark datasets. Surprisingly, their performance remains sensitive to
perturbations that have little effect on human performance. In this work, we
propose a novel extension of Mixup called Robustmix that regularizes networks
to classify based on lower-frequency spatial features. We show that this type
of regularization improves robustness on a range of benchmarks such as
Imagenet-C and Stylized Imagenet. It adds little computational overhead and,
furthermore, does not require a priori knowledge of a large set of image
transformations. We find that this approach further complements recent advances
in model architecture and data augmentation, attaining a state-of-the-art mCE
of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of
16 mCE compared to the baseline.
</p></li>
</ul>

<h3>Title: Patch-aware Batch Normalization for Improving Cross-domain Robustness. (arXiv:2304.02848v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02848">http://arxiv.org/abs/2304.02848</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02848] Patch-aware Batch Normalization for Improving Cross-domain Robustness](http://arxiv.org/abs/2304.02848) #robust</code></li>
<li>Summary: <p>Despite the significant success of deep learning in computer vision tasks,
cross-domain tasks still present a challenge in which the model's performance
will degrade when the training set and the test set follow different
distributions. Most existing methods employ adversarial learning or instance
normalization for achieving data augmentation to solve this task. In contrast,
considering that the batch normalization (BN) layer may not be robust for
unseen domains and there exist the differences between local patches of an
image, we propose a novel method called patch-aware batch normalization (PBN).
To be specific, we first split feature maps of a batch into non-overlapping
patches along the spatial dimension, and then independently normalize each
patch to jointly optimize the shared BN parameter at each iteration. By
exploiting the differences between local patches of an image, our proposed PBN
can effectively enhance the robustness of the model's parameters. Besides,
considering the statistics from each patch may be inaccurate due to their
smaller size compared to the global feature maps, we incorporate the globally
accumulated statistics with the statistics from each batch to obtain the final
statistics for normalizing each patch. Since the proposed PBN can replace the
typical BN, it can be integrated into most existing state-of-the-art methods.
Extensive experiments and analysis demonstrate the effectiveness of our PBN in
multiple computer vision tasks, including classification, object detection,
instance retrieval, and semantic segmentation.
</p></li>
</ul>

<h3>Title: Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification. (arXiv:2304.02849v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02849">http://arxiv.org/abs/2304.02849</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02849] Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification](http://arxiv.org/abs/2304.02849) #robust</code></li>
<li>Summary: <p>A natural way of estimating heteroscedastic label noise in regression is to
model the observed (potentially noisy) target as a sample from a normal
distribution, whose parameters can be learned by minimizing the negative
log-likelihood. This loss has desirable loss attenuation properties, as it can
reduce the contribution of high-error examples. Intuitively, this behavior can
improve robustness against label noise by reducing overfitting. We propose an
extension of this simple and probabilistic approach to classification that has
the same desirable loss attenuation properties. We evaluate the effectiveness
of the method by measuring its robustness against label noise in
classification. We perform enlightening experiments exploring the inner
workings of the method, including sensitivity to hyperparameters, ablation
studies, and more.
</p></li>
</ul>

<h3>Title: Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce. (arXiv:2304.02853v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02853">http://arxiv.org/abs/2304.02853</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02853] Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce](http://arxiv.org/abs/2304.02853) #robust</code></li>
<li>Summary: <p>This paper aims to establish a generic multi-modal foundation model that has
the scalable capability to massive downstream applications in E-commerce.
Recently, large-scale vision-language pretraining approaches have achieved
remarkable advances in the general domain. However, due to the significant
differences between natural and product images, directly applying these
frameworks for modeling image-level representations to E-commerce will be
inevitably sub-optimal. To this end, we propose an instance-centric multi-modal
pretraining paradigm called ECLIP in this work. In detail, we craft a decoder
architecture that introduces a set of learnable instance queries to explicitly
aggregate instance-level semantics. Moreover, to enable the model to focus on
the desired product instance without reliance on expensive manual annotations,
two specially configured pretext tasks are further proposed. Pretrained on the
100 million E-commerce-related data, ECLIP successfully extracts more generic,
semantic-rich, and robust representations. Extensive experimental results show
that, without further fine-tuning, ECLIP surpasses existing methods by a large
margin on a broad range of downstream tasks, demonstrating the strong
transferability to real-world E-commerce applications.
</p></li>
</ul>

<h3>Title: VPFusion: Towards Robust Vertical Representation Learning for 3D Object Detection. (arXiv:2304.02867v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02867">http://arxiv.org/abs/2304.02867</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02867] VPFusion: Towards Robust Vertical Representation Learning for 3D Object Detection](http://arxiv.org/abs/2304.02867) #robust</code></li>
<li>Summary: <p>Efficient point cloud representation is a fundamental element of Lidar-based
3D object detection. Recent grid-based detectors usually divide point clouds
into voxels or pillars and construct single-stream networks in Bird's Eye View.
However, these point cloud encoding paradigms underestimate the point
representation in the vertical direction, which cause the loss of semantic or
fine-grained information, especially for vertical sensitive objects like
pedestrian and cyclists. In this paper, we propose an explicit vertical
multi-scale representation learning framework, VPFusion, to combine the
complementary information from both voxel and pillar streams. Specifically,
VPFusion first builds upon a sparse voxel-pillar-based backbone. The backbone
divides point clouds into voxels and pillars, then encodes features with 3D and
2D sparse convolution simultaneously. Next, we introduce the Sparse Fusion
Layer (SFL), which establishes a bidirectional pathway for sparse voxel and
pillar features to enable the interaction between them. Additionally, we
present the Dense Fusion Neck (DFN) to effectively combine the dense feature
maps from voxel and pillar branches with multi-scale. Extensive experiments on
the large-scale Waymo Open Dataset and nuScenes Dataset demonstrate that
VPFusion surpasses the single-stream baselines by a large margin and achieves
state-of-the-art performance with real-time inference speed.
</p></li>
</ul>

<h3>Title: Benchmarking Robustness to Text-Guided Corruptions. (arXiv:2304.02963v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02963">http://arxiv.org/abs/2304.02963</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02963] Benchmarking Robustness to Text-Guided Corruptions](http://arxiv.org/abs/2304.02963) #robust</code></li>
<li>Summary: <p>This study investigates the robustness of image classifiers to text-guided
corruptions. We utilize diffusion models to edit images to different domains.
Unlike other works that use synthetic or hand-picked data for benchmarking, we
use diffusion models as they are generative models capable of learning to edit
images while preserving their semantic content. Thus, the corruptions will be
more realistic and the comparison will be more informative. Also, there is no
need for manual labeling and we can create large-scale benchmarks with less
effort. We define a prompt hierarchy based on the original ImageNet hierarchy
to apply edits in different domains. As well as introducing a new benchmark we
try to investigate the robustness of different vision models. The results of
this study demonstrate that the performance of image classifiers decreases
significantly in different language-based corruptions and edit domains. We also
observe that convolutional models are more robust than transformer
architectures. Additionally, we see that common data augmentation techniques
can improve the performance on both the original data and the edited images.
The findings of this research can help improve the design of image classifiers
and contribute to the development of more robust machine learning systems. The
code for generating the benchmark will be made available online upon
publication.
</p></li>
</ul>

<h3>Title: Exploiting the Complementarity of 2D and 3D Networks to Address Domain-Shift in 3D Semantic Segmentation. (arXiv:2304.02991v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02991">http://arxiv.org/abs/2304.02991</a></li>
<li>Code URL: <a href="https://github.com/cvlab-unibo/mm2d3d">https://github.com/cvlab-unibo/mm2d3d</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02991] Exploiting the Complementarity of 2D and 3D Networks to Address Domain-Shift in 3D Semantic Segmentation](http://arxiv.org/abs/2304.02991) #robust</code></li>
<li>Summary: <p>3D semantic segmentation is a critical task in many real-world applications,
such as autonomous driving, robotics, and mixed reality. However, the task is
extremely challenging due to ambiguities coming from the unstructured, sparse,
and uncolored nature of the 3D point clouds. A possible solution is to combine
the 3D information with others coming from sensors featuring a different
modality, such as RGB cameras. Recent multi-modal 3D semantic segmentation
networks exploit these modalities relying on two branches that process the 2D
and 3D information independently, striving to maintain the strength of each
modality. In this work, we first explain why this design choice is effective
and then show how it can be improved to make the multi-modal semantic
segmentation more robust to domain shift. Our surprisingly simple contribution
achieves state-of-the-art performances on four popular multi-modal unsupervised
domain adaptation benchmarks, as well as better results in a domain
generalization scenario.
</p></li>
</ul>

<h3>Title: ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments. (arXiv:2304.03047v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03047">http://arxiv.org/abs/2304.03047</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03047] ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments](http://arxiv.org/abs/2304.03047) #robust</code></li>
<li>Summary: <p>Vision-language navigation is a task that requires an agent to follow
instructions to navigate in environments. It becomes increasingly crucial in
the field of embodied AI, with potential applications in autonomous navigation,
search and rescue, and human-robot interaction. In this paper, we propose to
address a more practical yet challenging counterpart setting - vision-language
navigation in continuous environments (VLN-CE). To develop a robust VLN-CE
agent, we propose a new navigation framework, ETPNav, which focuses on two
critical skills: 1) the capability to abstract environments and generate
long-range navigation plans, and 2) the ability of obstacle-avoiding control in
continuous environments. ETPNav performs online topological mapping of
environments by self-organizing predicted waypoints along a traversed path,
without prior environmental experience. It privileges the agent to break down
the navigation procedure into high-level planning and low-level control.
Concurrently, ETPNav utilizes a transformer-based cross-modal planner to
generate navigation plans based on topological maps and instructions. The plan
is then performed through an obstacle-avoiding controller that leverages a
trial-and-error heuristic to prevent navigation from getting stuck in
obstacles. Experimental results demonstrate the effectiveness of the proposed
method. ETPNav yields more than 10% and 20% improvements over prior
state-of-the-art on R2R-CE and RxR-CE datasets, respectively. Our code is
available at https://github.com/MarSaKi/ETPNav.
</p></li>
</ul>

<h3>Title: Improving Visual Question Answering Models through Robustness Analysis and In-Context Learning with a Chain of Basic Questions. (arXiv:2304.03147v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03147">http://arxiv.org/abs/2304.03147</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03147] Improving Visual Question Answering Models through Robustness Analysis and In-Context Learning with a Chain of Basic Questions](http://arxiv.org/abs/2304.03147) #robust</code></li>
<li>Summary: <p>Deep neural networks have been critical in the task of Visual Question
Answering (VQA), with research traditionally focused on improving model
accuracy. Recently, however, there has been a trend towards evaluating the
robustness of these models against adversarial attacks. This involves assessing
the accuracy of VQA models under increasing levels of noise in the input, which
can target either the image or the proposed query question, dubbed the main
question. However, there is currently a lack of proper analysis of this aspect
of VQA. This work proposes a new method that utilizes semantically related
questions, referred to as basic questions, acting as noise to evaluate the
robustness of VQA models. It is hypothesized that as the similarity of a basic
question to the main question decreases, the level of noise increases. To
generate a reasonable noise level for a given main question, a pool of basic
questions is ranked based on their similarity to the main question, and this
ranking problem is cast as a LASSO optimization problem. Additionally, this
work proposes a novel robustness measure, R_score, and two basic question
datasets to standardize the analysis of VQA model robustness. The experimental
results demonstrate that the proposed evaluation method effectively analyzes
the robustness of VQA models. Moreover, the experiments show that in-context
learning with a chain of basic questions can enhance model accuracy.
</p></li>
</ul>

<h3>Title: Instant-NVR: Instant Neural Volumetric Rendering for Human-object Interactions from Monocular RGBD Stream. (arXiv:2304.03184v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03184">http://arxiv.org/abs/2304.03184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03184] Instant-NVR: Instant Neural Volumetric Rendering for Human-object Interactions from Monocular RGBD Stream](http://arxiv.org/abs/2304.03184) #robust</code></li>
<li>Summary: <p>Convenient 4D modeling of human-object interactions is essential for numerous
applications. However, monocular tracking and rendering of complex interaction
scenarios remain challenging. In this paper, we propose Instant-NVR, a neural
approach for instant volumetric human-object tracking and rendering using a
single RGBD camera. It bridges traditional non-rigid tracking with recent
instant radiance field techniques via a multi-thread tracking-rendering
mechanism. In the tracking front-end, we adopt a robust human-object capture
scheme to provide sufficient motion priors. We further introduce a separated
instant neural representation with a novel hybrid deformation module for the
interacting scene. We also provide an on-the-fly reconstruction scheme of the
dynamic/static radiance fields via efficient motion-prior searching. Moreover,
we introduce an online key frame selection scheme and a rendering-aware
refinement strategy to significantly improve the appearance details for online
novel-view synthesis. Extensive experiments demonstrate the effectiveness and
efficiency of our approach for the instant generation of human-object radiance
fields on the fly, notably achieving real-time photo-realistic novel view
synthesis under complex human-object interactions.
</p></li>
</ul>

<h3>Title: GPT detectors are biased against non-native English writers. (arXiv:2304.02819v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02819">http://arxiv.org/abs/2304.02819</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02819] GPT detectors are biased against non-native English writers](http://arxiv.org/abs/2304.02819) #robust</code></li>
<li>Summary: <p>The rapid adoption of generative language models has brought about
substantial advancements in digital communication, while simultaneously raising
concerns regarding the potential misuse of AI-generated content. Although
numerous detection methods have been proposed to differentiate between AI and
human-generated content, the fairness and robustness of these detectors remain
underexplored. In this study, we evaluate the performance of several
widely-used GPT detectors using writing samples from native and non-native
English writers. Our findings reveal that these detectors consistently
misclassify non-native English writing samples as AI-generated, whereas native
writing samples are accurately identified. Furthermore, we demonstrate that
simple prompting strategies can not only mitigate this bias but also
effectively bypass GPT detectors, suggesting that GPT detectors may
unintentionally penalize writers with constrained linguistic expressions. Our
results call for a broader conversation about the ethical implications of
deploying ChatGPT content detectors and caution against their use in evaluative
or educational settings, particularly when they may inadvertently penalize or
exclude non-native English speakers from the global discourse.
</p></li>
</ul>

<h3>Title: Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming. (arXiv:2304.03145v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03145">http://arxiv.org/abs/2304.03145</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03145] Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming](http://arxiv.org/abs/2304.03145) #robust</code></li>
<li>Summary: <p>Question answering (QA) models have shown compelling results in the task of
Machine Reading Comprehension (MRC). Recently these systems have proved to
perform better than humans on held-out test sets of datasets e.g. SQuAD, but
their robustness is not guaranteed. The QA model's brittleness is exposed when
evaluated on adversarial generated examples by a performance drop. In this
study, we explore the robustness of MRC models to entity renaming, with
entities from low-resource regions such as Africa. We propose EntSwap, a method
for test-time perturbations, to create a test set whose entities have been
renamed. In particular, we rename entities of type: country, person,
nationality, location, organization, and city, to create AfriSQuAD2. Using the
perturbed test set, we evaluate the robustness of three popular MRC models. We
find that compared to base models, large models perform well comparatively on
novel entities. Furthermore, our analysis indicates that entity type person
highly challenges the MRC models' performance.
</p></li>
</ul>

<h3>Title: CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval. (arXiv:2304.03158v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03158">http://arxiv.org/abs/2304.03158</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03158] CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval](http://arxiv.org/abs/2304.03158) #robust</code></li>
<li>Summary: <p>Growing techniques have been emerging to improve the performance of passage
retrieval. As an effective representation bottleneck pretraining technique, the
contextual masked auto-encoder utilizes contextual embedding to assist in the
reconstruction of passages. However, it only uses a single auto-encoding
pre-task for dense representation pre-training. This study brings multi-view
modeling to the contextual masked auto-encoder. Firstly, multi-view
representation utilizes both dense and sparse vectors as multi-view
representations, aiming to capture sentence semantics from different aspects.
Moreover, multiview decoding paradigm utilizes both autoencoding and
auto-regressive decoders in representation bottleneck pre-training, aiming to
provide both reconstructive and generative signals for better contextual
representation pretraining. We refer to this multi-view pretraining method as
CoT-MAE v2. Through extensive experiments, we show that CoT-MAE v2 is effective
and robust on large-scale passage retrieval benchmarks and out-of-domain
zero-shot benchmarks.
</p></li>
</ul>

<h3>Title: Selective Data Augmentation for Robust Speech Translation. (arXiv:2304.03169v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03169">http://arxiv.org/abs/2304.03169</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03169] Selective Data Augmentation for Robust Speech Translation](http://arxiv.org/abs/2304.03169) #robust</code></li>
<li>Summary: <p>Speech translation (ST) systems translate speech in one language to text in
another language. End-to-end ST systems (e2e-ST) have gained popularity over
cascade systems because of their enhanced performance due to reduced latency
and computational cost. Though resource intensive, e2e-ST systems have the
inherent ability to retain para and non-linguistic characteristics of the
speech unlike cascade systems. In this paper, we propose to use an e2e
architecture for English-Hindi (en-hi) ST. We use two imperfect machine
translation (MT) services to translate Libri-trans en text into hi text. While
each service gives MT data individually to generate parallel ST data, we
propose a data augmentation strategy of noisy MT data to aid robust ST. The
main contribution of this paper is the proposal of a data augmentation
strategy. We show that this results in better ST (BLEU score) compared to brute
force augmentation of MT data. We observed an absolute improvement of 1.59 BLEU
score with our approach.
</p></li>
</ul>

<h3>Title: On the Pareto Front of Multilingual Neural Machine Translation. (arXiv:2304.03216v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03216">http://arxiv.org/abs/2304.03216</a></li>
<li>Code URL: <a href="https://github.com/chenllliang/paretomnmt">https://github.com/chenllliang/paretomnmt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03216] On the Pareto Front of Multilingual Neural Machine Translation](http://arxiv.org/abs/2304.03216) #robust</code></li>
<li>Summary: <p>In this work, we study how the generalization performance of a given
direction changes with its sampling ratio in Multilingual Neural Machine
Translation (MNMT). By training over 200 multilingual models with various model
sizes, directions, and total numbers of tasks, we find that scalarization leads
to a multitask trade-off front that deviates from the traditional Pareto front
when there exists data imbalance in the training corpus. That is, the
performance of certain translation directions does not improve with the
increase of its weight in the multi-task optimization objective, which poses
greater challenge to improve the overall performance of all directions. Based
on our observations, we propose the Double Power Law to predict the unique
performance trade-off front in MNMT, which is robust across various languages,
data adequacy and number of tasks. Finally, we formulate sample ratio selection
in MNMT as an optimization problem based on the Double Power Law, which
achieves better performance than temperature searching and gradient
manipulation methods using up to half of the total training budget in our
experiments.
</p></li>
</ul>

<h3>Title: Robust Neural Architecture Search. (arXiv:2304.02845v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02845">http://arxiv.org/abs/2304.02845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02845] Robust Neural Architecture Search](http://arxiv.org/abs/2304.02845) #robust</code></li>
<li>Summary: <p>Neural Architectures Search (NAS) becomes more and more popular over these
years. However, NAS-generated models tends to suffer greater vulnerability to
various malicious attacks. Lots of robust NAS methods leverage adversarial
training to enhance the robustness of NAS-generated models, however, they
neglected the nature accuracy of NAS-generated models. In our paper, we propose
a novel NAS method, Robust Neural Architecture Search (RNAS). To design a
regularization term to balance accuracy and robustness, RNAS generates
architectures with both high accuracy and good robustness. To reduce search
cost, we further propose to use noise examples instead adversarial examples as
input to search architectures. Extensive experiments show that RNAS achieves
state-of-the-art (SOTA) performance on both image classification and
adversarial attacks, which illustrates the proposed RNAS achieves a good
tradeoff between robustness and accuracy.
</p></li>
</ul>

<h3>Title: Hybrid Zonotopes Exactly Represent ReLU Neural Networks. (arXiv:2304.02755v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02755">http://arxiv.org/abs/2304.02755</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02755] Hybrid Zonotopes Exactly Represent ReLU Neural Networks](http://arxiv.org/abs/2304.02755) #robust</code></li>
<li>Summary: <p>We show that hybrid zonotopes offer an equivalent representation of
feed-forward fully connected neural networks with ReLU activation functions.
Our approach demonstrates that the complexity of binary variables is equal to
the total number of neurons in the network and hence grows linearly in the size
of the network. We demonstrate the utility of the hybrid zonotope formulation
through three case studies including nonlinear function approximation, MPC
closed-loop reachability and verification, and robustness of classification on
the MNIST dataset.
</p></li>
</ul>

<h3>Title: A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation. (arXiv:2304.02858v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02858">http://arxiv.org/abs/2304.02858</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02858] A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation](http://arxiv.org/abs/2304.02858) #robust</code></li>
<li>Summary: <p>Class imbalance (CI) in classification problems arises when the number of
observations belonging to one class is lower than the other classes. Ensemble
learning that combines multiple models to obtain a robust model has been
prominently used with data augmentation methods to address class imbalance
problems. In the last decade, a number of strategies have been added to enhance
ensemble learning and data augmentation methods, along with new methods such as
generative adversarial networks (GANs). A combination of these has been applied
in many studies, but the true rank of different combinations would require a
computational review. In this paper, we present a computational review to
evaluate data augmentation and ensemble learning methods used to address
prominent benchmark CI problems. We propose a general framework that evaluates
10 data augmentation and 10 ensemble learning methods for CI problems. Our
objective was to identify the most effective combination for improving
classification performance on imbalanced datasets. The results indicate that
combinations of data augmentation methods with ensemble learning can
significantly improve classification performance on imbalanced datasets. These
findings have important implications for the development of more effective
approaches for handling imbalanced datasets in machine learning applications.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Learning Stage-wise GANs for Whistle Extraction in Time-Frequency Spectrograms. (arXiv:2304.02714v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02714">http://arxiv.org/abs/2304.02714</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02714] Learning Stage-wise GANs for Whistle Extraction in Time-Frequency Spectrograms](http://arxiv.org/abs/2304.02714) #extraction</code></li>
<li>Summary: <p>Whistle contour extraction aims to derive animal whistles from time-frequency
spectrograms as polylines. For toothed whales, whistle extraction results can
serve as the basis for analyzing animal abundance, species identity, and social
activities. During the last few decades, as long-term recording systems have
become affordable, automated whistle extraction algorithms were proposed to
process large volumes of recording data. Recently, a deep learning-based method
demonstrated superior performance in extracting whistles under varying noise
conditions. However, training such networks requires a large amount of
labor-intensive annotation, which is not available for many species. To
overcome this limitation, we present a framework of stage-wise generative
adversarial networks (GANs), which compile new whistle data suitable for deep
model training via three stages: generation of background noise in the
spectrogram, generation of whistle contours, and generation of whistle signals.
By separating the generation of different components in the samples, our
framework composes visually promising whistle data and labels even when few
expert annotated data are available. Regardless of the amount of
human-annotated data, the proposed data augmentation framework leads to a
consistent improvement in performance of the whistle extraction model, with a
maximum increase of 1.69 in the whistle extraction mean F1-score. Our
stage-wise GAN also surpasses one single GAN in improving whistle extraction
models with augmented data. The data and code will be available at
https://github.com/Paul-LiPu/CompositeGAN_WhistleAugment.
</p></li>
</ul>

<h3>Title: A Fast and Lightweight Network for Low-Light Image Enhancement. (arXiv:2304.02978v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02978">http://arxiv.org/abs/2304.02978</a></li>
<li>Code URL: <a href="https://github.com/hitzhangyu/FLW-Net">https://github.com/hitzhangyu/FLW-Net</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02978] A Fast and Lightweight Network for Low-Light Image Enhancement](http://arxiv.org/abs/2304.02978) #extraction</code></li>
<li>Summary: <p>Low-light images often suffer from severe noise, low brightness, low
contrast, and color deviation. While several low-light image enhancement
methods have been proposed, there remains a lack of efficient methods that can
simultaneously solve all of these problems. In this paper, we introduce
FLW-Net, a Fast and LightWeight Network for low-light image enhancement that
significantly improves processing speed and overall effect. To achieve
efficient low-light image enhancement, we recognize the challenges of the lack
of an absolute reference and the need for a large receptive field to obtain
global contrast. Therefore, we propose an efficient global feature information
extraction component and design loss functions based on relative information to
overcome these challenges. Finally, we conduct comparative experiments to
demonstrate the effectiveness of the proposed method, and the results confirm
that FLW-Net can significantly reduce the complexity of supervised low-light
image enhancement networks while improving processing effect. Code is available
at https://github.com/hitzhangyu/FLW-Net
</p></li>
</ul>

<h3>Title: Geometric-aware Pretraining for Vision-centric 3D Object Detection. (arXiv:2304.03105v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03105">http://arxiv.org/abs/2304.03105</a></li>
<li>Code URL: <a href="https://github.com/opendrivelab/bevperception-survey-recipe">https://github.com/opendrivelab/bevperception-survey-recipe</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03105] Geometric-aware Pretraining for Vision-centric 3D Object Detection](http://arxiv.org/abs/2304.03105) #extraction</code></li>
<li>Summary: <p>Multi-camera 3D object detection for autonomous driving is a challenging
problem that has garnered notable attention from both academia and industry. An
obstacle encountered in vision-based techniques involves the precise extraction
of geometry-conscious features from RGB images. Recent approaches have utilized
geometric-aware image backbones pretrained on depth-relevant tasks to acquire
spatial information. However, these approaches overlook the critical aspect of
view transformation, resulting in inadequate performance due to the
misalignment of spatial knowledge between the image backbone and view
transformation. To address this issue, we propose a novel geometric-aware
pretraining framework called GAPretrain. Our approach incorporates spatial and
structural cues to camera networks by employing the geometric-rich modality as
guidance during the pretraining phase. The transference of modal-specific
attributes across different modalities is non-trivial, but we bridge this gap
by using a unified bird's-eye-view (BEV) representation and structural hints
derived from LiDAR point clouds to facilitate the pretraining process.
GAPretrain serves as a plug-and-play solution that can be flexibly applied to
multiple state-of-the-art detectors. Our experiments demonstrate the
effectiveness and generalization ability of the proposed method. We achieve
46.2 mAP and 55.5 NDS on the nuScenes val set using the BEVFormer method, with
a gain of 2.7 and 2.1 points, respectively. We also conduct experiments on
various image backbones and view transformations to validate the efficacy of
our approach. Code will be released at
https://github.com/OpenDriveLab/BEVPerception-Survey-Recipe.
</p></li>
</ul>

<h3>Title: Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP dalam bahasa Indonesia. (arXiv:2304.02746v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02746">http://arxiv.org/abs/2304.02746</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02746] Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP dalam bahasa Indonesia](http://arxiv.org/abs/2304.02746) #extraction</code></li>
<li>Summary: <p>This study provides an overview of the history of the development of Natural
Language Processing (NLP) in the context of the Indonesian language, with a
focus on the basic technologies, methods, and practical applications that have
been developed. This review covers developments in basic NLP technologies such
as stemming, part-of-speech tagging, and related methods; practical
applications in cross-language information retrieval systems, information
extraction, and sentiment analysis; and methods and techniques used in
Indonesian language NLP research, such as machine learning, statistics-based
machine translation, and conflict-based approaches. This study also explores
the application of NLP in Indonesian language industry and research and
identifies challenges and opportunities in Indonesian language NLP research and
development. Recommendations for future Indonesian language NLP research and
development include developing more efficient methods and technologies,
expanding NLP applications, increasing sustainability, further research into
the potential of NLP, and promoting interdisciplinary collaboration. It is
hoped that this review will help researchers, practitioners, and the government
to understand the development of Indonesian language NLP and identify
opportunities for further research and development.
</p></li>
</ul>

<h3>Title: SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention. (arXiv:2304.02901v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02901">http://arxiv.org/abs/2304.02901</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02901] SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention](http://arxiv.org/abs/2304.02901) #extraction</code></li>
<li>Summary: <p>Extracting entities and relations is an essential task of information
extraction. Triplets extracted from a sentence might overlap with each other.
Previous methods either did not address the overlapping issues or solved
overlapping issues partially. To tackle triplet overlapping problems
completely, firstly we extract candidate subjects with a standard span
mechanism. Then we present a labeled span mechanism to extract the objects and
relations simultaneously, we use the labeled span mechanism to generate labeled
spans whose start and end positions indicate the objects, and whose labels
correspond to relations of subject and objects. Besides, we design an entity
attention mechanism to enhance the information fusion between subject and
sentence during extracting objects and relations. We test our method on two
public datasets, our method achieves the best performances on these two
datasets.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: IoT Federated Blockchain Learning at the Edge. (arXiv:2304.03006v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03006">http://arxiv.org/abs/2304.03006</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03006] IoT Federated Blockchain Learning at the Edge](http://arxiv.org/abs/2304.03006) #federate</code></li>
<li>Summary: <p>IoT devices are sorely underutilized in the medical field, especially within
machine learning for medicine, yet they offer unrivaled benefits. IoT devices
are low-cost, energy-efficient, small and intelligent devices. In this paper,
we propose a distributed federated learning framework for IoT devices, more
specifically for IoMT (Internet of Medical Things), using blockchain to allow
for a decentralized scheme improving privacy and efficiency over a centralized
system; this allows us to move from the cloud-based architectures, that are
prevalent, to the edge. The system is designed for three paradigms: 1) Training
neural networks on IoT devices to allow for collaborative training of a shared
model whilst decoupling the learning from the dataset to ensure privacy.
Training is performed in an online manner simultaneously amongst all
participants, allowing for the training of actual data that may not have been
present in a dataset collected in the traditional way and dynamically adapt the
system whilst it is being trained. 2) Training of an IoMT system in a fully
private manner such as to mitigate the issue with confidentiality of medical
data and to build robust, and potentially bespoke, models where not much, if
any, data exists. 3) Distribution of the actual network training, something
federated learning itself does not do, to allow hospitals, for example, to
utilize their spare computing resources to train network models.
</p></li>
</ul>

<h3>Title: Deep Reinforcement Learning Based Vehicle Selection for Asynchronous Federated Learning Enabled Vehicular Edge Computing. (arXiv:2304.02832v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02832">http://arxiv.org/abs/2304.02832</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02832] Deep Reinforcement Learning Based Vehicle Selection for Asynchronous Federated Learning Enabled Vehicular Edge Computing](http://arxiv.org/abs/2304.02832) #federate</code></li>
<li>Summary: <p>In the traditional vehicular network, computing tasks generated by the
vehicles are usually uploaded to the cloud for processing. However, since task
offloading toward the cloud will cause a large delay, vehicular edge computing
(VEC) is introduced to avoid such a problem and improve the whole system
performance, where a roadside unit (RSU) with certain computing capability is
used to process the data of vehicles as an edge entity. Owing to the privacy
and security issues, vehicles are reluctant to upload local data directly to
the RSU, and thus federated learning (FL) becomes a promising technology for
some machine learning tasks in VEC, where vehicles only need to upload the
local model hyperparameters instead of transferring their local data to the
nearby RSU. Furthermore, as vehicles have different local training time due to
various sizes of local data and their different computing capabilities,
asynchronous federated learning (AFL) is employed to facilitate the RSU to
update the global model immediately after receiving a local model to reduce the
aggregation delay. However, in AFL of VEC, different vehicles may have
different impact on the global model updating because of their various local
training delay, transmission delay and local data sizes. Also, if there are bad
nodes among the vehicles, it will affect the global aggregation quality at the
RSU. To solve the above problem, we shall propose a deep reinforcement learning
(DRL) based vehicle selection scheme to improve the accuracy of the global
model in AFL of vehicular network. In the scheme, we present the model
including the state, action and reward in the DRL based to the specific
problem. Simulation results demonstrate our scheme can effectively remove the
bad nodes and improve the aggregation accuracy of the global model.
</p></li>
</ul>

<h3>Title: Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients. (arXiv:2304.02892v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02892">http://arxiv.org/abs/2304.02892</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02892] Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients](http://arxiv.org/abs/2304.02892) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is a distributed framework for collaboratively
training with privacy guarantees. In real-world scenarios, clients may have
Non-IID data (local class imbalance) with poor annotation quality (label
noise). The co-existence of label noise and class imbalance in FL's small local
datasets renders conventional FL methods and noisy-label learning methods both
ineffective. To address the challenges, we propose FedCNI without using an
additional clean proxy dataset. It includes a noise-resilient local solver and
a robust global aggregator. For the local solver, we design a more robust
prototypical noise detector to distinguish noisy samples. Further to reduce the
negative impact brought by the noisy samples, we devise a curriculum pseudo
labeling method and a denoise Mixup training strategy. For the global
aggregator, we propose a switching re-weighted aggregation method tailored to
different learning periods. Extensive experiments demonstrate our method can
substantially outperform state-of-the-art solutions in mix-heterogeneous FL
environments.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Uncurated Image-Text Datasets: Shedding Light on Demographic Bias. (arXiv:2304.02828v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02828">http://arxiv.org/abs/2304.02828</a></li>
<li>Code URL: <a href="https://github.com/noagarcia/phase">https://github.com/noagarcia/phase</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02828] Uncurated Image-Text Datasets: Shedding Light on Demographic Bias](http://arxiv.org/abs/2304.02828) #fair</code></li>
<li>Summary: <p>The increasing tendency to collect large and uncurated datasets to train
vision-and-language models has raised concerns about fair representations. It
is known that even small but manually annotated datasets, such as MSCOCO, are
affected by societal bias. This problem, far from being solved, may be getting
worse with data crawled from the Internet without much control. In addition,
the lack of tools to analyze societal bias in big collections of images makes
addressing the problem extremely challenging. Our first contribution is to
annotate part of the Google Conceptual Captions dataset, widely used for
training vision-and-language models, with four demographic and two contextual
attributes. Our second contribution is to conduct a comprehensive analysis of
the annotations, focusing on how different demographic groups are represented.
Our last contribution lies in evaluating three prevailing vision-and-language
tasks: image captioning, text-image CLIP embeddings, and text-to-image
generation, showing that societal bias is a persistent problem in all of them.
</p></li>
</ul>

<h3>Title: Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts. (arXiv:2304.02886v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02886">http://arxiv.org/abs/2304.02886</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02886] Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts](http://arxiv.org/abs/2304.02886) #fair</code></li>
<li>Summary: <p>Automatically associating ICD codes with electronic health data is a
well-known NLP task in medical research. NLP has evolved significantly in
recent years with the emergence of pre-trained language models based on
Transformers architecture, mainly in the English language. This paper adapts
these models to automatically associate the ICD codes. Several neural network
architectures have been experimented with to address the challenges of dealing
with a large set of both input tokens and labels to be guessed. In this paper,
we propose a model that combines the latest advances in NLP and multi-label
classification for ICD-10 code association. Fair experiments on a Clinical
dataset in the French language show that our approach increases the $F_1$-score
metric by more than 55\% compared to state-of-the-art results.
</p></li>
</ul>

<h3>Title: Fair Ordering via Social Choice Theory. (arXiv:2304.02730v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02730">http://arxiv.org/abs/2304.02730</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02730] Fair Ordering via Social Choice Theory](http://arxiv.org/abs/2304.02730) #fair</code></li>
<li>Summary: <p>Control of the ordering of transactions in modern blockchains can be
extremely profitable. Rather than allow one central actor to control this
revenue source, recent research has studied mechanisms for decentralizing the
process of computing an ordering among multiple, distributed replicas. This
problem is akin to the classic problem from social choice theory of aggregating
ordinal votes, applied to a streaming setting. Prior work proposes a
``$\gamma$-batch-order-fairness'' requirement on the aggregate ordering. Under
this requirement, the ordering should be divisible into contiguous batches, and
when a $\gamma$ fraction of replicas receive $tx$ before $tx^\prime$, then
$tx^\prime$ cannot be in an earlier batch than $tx$.
</p></li>
</ul>

<p>We extend this definition to formalize the notion that these batches should
have minimal size, thereby giving the first notion of order fairness that
cannot be vacuously satisfied (by arbitrarily large batches) and that can be
satisfied in the presence of faulty replicas. We then show that the Ranked
Pairs aggregation method produces an ordering that satisfies our fairness
definition for every choice of parameter $\gamma$ simultaneously and for any
number of faulty replicas (where fairness guarantees linearly degrade as the
fraction of faulty replicas increases).
</p>
<p>We then instantiate our protocol in the streaming setting. Careful analysis
of the interactions between ordering dependencies enables our protocol to
simulate Ranked Pairs voting in this setting, and adjustments to ordering
algorithm give a protocol that (under synchronous network assumptions) always
appends a transaction to the output ordering after a bounded amount of time.
</p>

<h3>Title: Inductive Graph Unlearning. (arXiv:2304.03093v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03093">http://arxiv.org/abs/2304.03093</a></li>
<li>Code URL: <a href="https://github.com/happy2git/guide">https://github.com/happy2git/guide</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03093] Inductive Graph Unlearning](http://arxiv.org/abs/2304.03093) #fair</code></li>
<li>Summary: <p>As a way to implement the "right to be forgotten" in machine learning,
\textit{machine unlearning} aims to completely remove the contributions and
information of the samples to be deleted from a trained model without affecting
the contributions of other samples. Recently, many frameworks for machine
unlearning have been proposed, and most of them focus on image and text data.
To extend machine unlearning to graph data, \textit{GraphEraser} has been
proposed. However, a critical issue is that \textit{GraphEraser} is
specifically designed for the transductive graph setting, where the graph is
static and attributes and edges of test nodes are visible during training. It
is unsuitable for the inductive setting, where the graph could be dynamic and
the test graph information is invisible in advance. Such inductive capability
is essential for production machine learning systems with evolving graphs like
social media and transaction networks. To fill this gap, we propose the
\underline{{\bf G}}\underline{{\bf U}}ided \underline{{\bf I}}n\underline{{\bf
D}}uctiv\underline{{\bf E}} Graph Unlearning framework (GUIDE). GUIDE consists
of three components: guided graph partitioning with fairness and balance,
efficient subgraph repair, and similarity-based aggregation. Empirically, we
evaluate our method on several inductive benchmarks and evolving transaction
graphs. Generally speaking, GUIDE can be efficiently implemented on the
inductive graph learning tasks for its low graph partition cost, no matter on
computation or structure information. The code will be available here:
https://github.com/Happy2Git/GUIDE.
</p></li>
</ul>

<h3>Title: A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors. (arXiv:2304.02780v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02780">http://arxiv.org/abs/2304.02780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02780] A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors](http://arxiv.org/abs/2304.02780) #fair</code></li>
<li>Summary: <p>Liver transplantation is a life-saving procedure for patients with end-stage
liver disease. There are two main challenges in liver transplant: finding the
best matching patient for a donor and ensuring transplant equity among
different subpopulations. The current MELD scoring system evaluates a patient's
mortality risk if not receiving an organ within 90 days. However, the
donor-patient matching should also take into consideration post-transplant risk
factors, such as cardiovascular disease, chronic rejection, etc., which are all
common complications after transplant. Accurate prediction of these risk scores
remains a significant challenge. In this study, we will use predictive models
to solve the above challenge. We propose a deep learning framework model to
predict multiple risk factors after a liver transplant. By formulating it as a
multi-task learning problem, the proposed deep neural network was trained on
this data to simultaneously predict the five post-transplant risks and achieve
equally good performance by leveraging task balancing techniques. We also
propose a novel fairness achieving algorithm and to ensure prediction fairness
across different subpopulations. We used electronic health records of 160,360
liver transplant patients, including demographic information, clinical
variables, and laboratory values, collected from the liver transplant records
of the United States from 1987 to 2018. The performance of the model was
evaluated using various performance metrics such as AUROC, AURPC, and accuracy.
The results of our experiments demonstrate that the proposed multitask
prediction model achieved high accuracy and good balance in predicting all five
post-transplant risk factors, with a maximum accuracy discrepancy of only 2.7%.
The fairness-achieving algorithm significantly reduced the fairness disparity
compared to the baseline model.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: SLM: End-to-end Feature Selection via Sparse Learnable Masks. (arXiv:2304.03202v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03202">http://arxiv.org/abs/2304.03202</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03202] SLM: End-to-end Feature Selection via Sparse Learnable Masks](http://arxiv.org/abs/2304.03202) #interpretability</code></li>
<li>Summary: <p>Feature selection has been widely used to alleviate compute requirements
during training, elucidate model interpretability, and improve model
generalizability. We propose SLM -- Sparse Learnable Masks -- a canonical
approach for end-to-end feature selection that scales well with respect to both
the feature dimension and the number of samples. At the heart of SLM lies a
simple but effective learnable sparse mask, which learns which features to
select, and gives rise to a novel objective that provably maximizes the mutual
information (MI) between the selected features and the labels, which can be
derived from a quadratic relaxation of mutual information from first
principles. In addition, we derive a scaling mechanism that allows SLM to
precisely control the number of features selected, through a novel use of
sparsemax. This allows for more effective learning as demonstrated in ablation
studies. Empirically, SLM achieves state-of-the-art results against a variety
of competitive baselines on eight benchmark datasets, often by a significant
margin, especially on those with real-world challenges such as class imbalance.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model. (arXiv:2304.02827v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.02827">http://arxiv.org/abs/2304.02827</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.02827] DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model](http://arxiv.org/abs/2304.02827) #diffusion</code></li>
<li>Summary: <p>The increasing demand for high-quality 3D content creation has motivated the
development of automated methods for creating 3D object models from a single
image and/or from a text prompt. However, the reconstructed 3D objects using
state-of-the-art image-to-3D methods still exhibit low correspondence to the
given image and low multi-view consistency. Recent state-of-the-art text-to-3D
methods are also limited, yielding 3D samples with low diversity per prompt
with long synthesis time. To address these challenges, we propose DITTO-NeRF, a
novel pipeline to generate a high-quality 3D NeRF model from a text prompt or a
single image. Our DITTO-NeRF consists of constructing high-quality partial 3D
object for limited in-boundary (IB) angles using the given or text-generated 2D
image from the frontal view and then iteratively reconstructing the remaining
3D NeRF using inpainting latent diffusion model. We propose progressive 3D
object reconstruction schemes in terms of scales (low to high resolution),
angles (IB angles initially to outer-boundary (OB) later), and masks (object to
background boundary) in our DITTO-NeRF so that high-quality information on IB
can be propagated into OB. Our DITTO-NeRF outperforms state-of-the-art methods
in terms of fidelity and diversity qualitatively and quantitatively with much
faster training times than prior arts on image/text-to-3D such as DreamFusion,
and NeuralLift-360.
</p></li>
</ul>

<h3>Title: Zero-shot Generative Model Adaptation via Image-specific Prompt Learning. (arXiv:2304.03119v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03119">http://arxiv.org/abs/2304.03119</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03119] Zero-shot Generative Model Adaptation via Image-specific Prompt Learning](http://arxiv.org/abs/2304.03119) #diffusion</code></li>
<li>Summary: <p>Recently, CLIP-guided image synthesis has shown appealing performance on
adapting a pre-trained source-domain generator to an unseen target domain. It
does not require any target-domain samples but only the textual domain labels.
The training is highly efficient, e.g., a few minutes. However, existing
methods still have some limitations in the quality of generated images and may
suffer from the mode collapse issue. A key reason is that a fixed adaptation
direction is applied for all cross-domain image pairs, which leads to identical
supervision signals. To address this issue, we propose an Image-specific Prompt
Learning (IPL) method, which learns specific prompt vectors for each
source-domain image. This produces a more precise adaptation direction for
every cross-domain image pair, endowing the target-domain generator with
greatly enhanced flexibility. Qualitative and quantitative evaluations on
various domains demonstrate that IPL effectively improves the quality and
diversity of synthesized images and alleviates the mode collapse. Moreover, IPL
is independent of the structure of the generative model, such as generative
adversarial networks or diffusion models. Code is available at
https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation.
</p></li>
</ul>

<h3>Title: SketchFFusion: Sketch-guided image editing with diffusion model. (arXiv:2304.03174v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03174">http://arxiv.org/abs/2304.03174</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03174] SketchFFusion: Sketch-guided image editing with diffusion model](http://arxiv.org/abs/2304.03174) #diffusion</code></li>
<li>Summary: <p>Sketch-guided image editing aims to achieve local fine-tuning of the image
based on the sketch information provided by the user, while maintaining the
original status of the unedited areas. Due to the high cost of acquiring human
sketches, previous works mostly relied on edge maps as a substitute for
sketches, but sketches possess more rich structural information. In this paper,
we propose a sketch generation scheme that can preserve the main contours of an
image and closely adhere to the actual sketch style drawn by the user.
Simultaneously, current image editing methods often face challenges such as
image distortion, training cost, and loss of fine details in the sketch. To
address these limitations, We propose a conditional diffusion model
(SketchFFusion) based on the sketch structure vector. We evaluate the
generative performance of our model and demonstrate that it outperforms
existing methods.
</p></li>
</ul>

<h3>Title: Face Animation with an Attribute-Guided Diffusion Model. (arXiv:2304.03199v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03199">http://arxiv.org/abs/2304.03199</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03199] Face Animation with an Attribute-Guided Diffusion Model](http://arxiv.org/abs/2304.03199) #diffusion</code></li>
<li>Summary: <p>Face animation has achieved much progress in computer vision. However,
prevailing GAN-based methods suffer from unnatural distortions and artifacts
due to sophisticated motion deformation. In this paper, we propose a Face
Animation framework with an attribute-guided Diffusion Model (FADM), which is
the first work to exploit the superior modeling capacity of diffusion models
for photo-realistic talking-head generation. To mitigate the uncontrollable
synthesis effect of the diffusion model, we design an Attribute-Guided
Conditioning Network (AGCN) to adaptively combine the coarse animation features
and 3D face reconstruction results, which can incorporate appearance and motion
conditions into the diffusion process. These specific designs help FADM rectify
unnatural artifacts and distortions, and also enrich high-fidelity facial
details through iterative diffusion refinements with accurate animation
attributes. FADM can flexibly and effectively improve existing animation
videos. Extensive experiments on widely used talking-head benchmarks validate
the effectiveness of FADM over prior arts.
</p></li>
</ul>

<h3>Title: Inst-Inpaint: Instructing to Remove Objects with Diffusion Models. (arXiv:2304.03246v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03246">http://arxiv.org/abs/2304.03246</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03246] Inst-Inpaint: Instructing to Remove Objects with Diffusion Models](http://arxiv.org/abs/2304.03246) #diffusion</code></li>
<li>Summary: <p>Image inpainting task refers to erasing unwanted pixels from images and
filling them in a semantically consistent and realistic way. Traditionally, the
pixels that are wished to be erased are defined with binary masks. From the
application point of view, a user needs to generate the masks for the objects
they would like to remove which can be time-consuming and prone to errors. In
this work, we are interested in an image inpainting algorithm that estimates
which object to be removed based on natural language input and also removes it,
simultaneously. For this purpose, first, we construct a dataset named
GQA-Inpaint for this task which will be released soon. Second, we present a
novel inpainting framework, Inst-Inpaint, that can remove objects from images
based on the instructions given as text prompts. We set various GAN and
diffusion-based baselines and run experiments on synthetic and real image
datasets. We compare methods with different evaluation metrics that measure the
quality and accuracy of the models and show significant quantitative and
qualitative improvements.
</p></li>
</ul>

<h3>Title: Diffusion Models as Masked Autoencoders. (arXiv:2304.03283v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.03283">http://arxiv.org/abs/2304.03283</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.03283] Diffusion Models as Masked Autoencoders](http://arxiv.org/abs/2304.03283) #diffusion</code></li>
<li>Summary: <p>There has been a longstanding belief that generation can facilitate a true
understanding of visual data. In line with this, we revisit generatively
pre-training visual representations in light of recent interest in denoising
diffusion models. While directly pre-training with diffusion models does not
produce strong representations, we condition diffusion models on masked input
and formulate diffusion models as masked autoencoders (DiffMAE). Our approach
is capable of (i) serving as a strong initialization for downstream recognition
tasks, (ii) conducting high-quality image inpainting, and (iii) being
effortlessly extended to video where it produces state-of-the-art
classification accuracy. We further perform a comprehensive study on the pros
and cons of design choices and build connections between diffusion models and
masked autoencoders.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
