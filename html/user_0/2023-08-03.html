<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Stake Your Claim: Zero-Trust Validator Deployment Leveraging NFTs and Smart Contracts in Proof-of-Stake Networks. (arXiv:2308.01158v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01158">http://arxiv.org/abs/2308.01158</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01158] Stake Your Claim: Zero-Trust Validator Deployment Leveraging NFTs and Smart Contracts in Proof-of-Stake Networks](http://arxiv.org/abs/2308.01158) #secure</code></li>
<li>Summary: <p>We present a novel method for a multi-party, zero-trust validator
infrastructure deployment arrangement via smart contracts to secure
Proof-of-Stake (PoS) blockchains. The proposed arrangement architecture employs
a combination of non-fungible tokens (NFTs), a treasury contract, and validator
smart contract wallets to facilitate trustless participation in staking
mechanisms. The NFT minting process allows depositors to exchange their capital
for an NFT representing their stake in a validator, while the treasury contract
manages the registry of NFT holders and handles rewards distribution. Validator
smart contract wallets are employed to create a trustless connection between
the validator operator and the treasury, enabling autonomous staking and
unstaking processes based on predefined conditions. In addition, the proposed
system incorporates protection mechanisms for depositors, such as triggered
exits in case of non-payment of rewards and a penalty payout from the validator
operator. The arrangement benefits from the extensibility and interoperability
of web3 technologies, with potential applications in the broader digital
ecosystem. This zero-trust staking mechanism aims to serve users who desire
increased privacy, trust, and flexibility in managing their digital wealth,
while promoting greater decentralization and transparency in the PoS ecosystem.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Curriculum Guided Domain Adaptation in the Dark. (arXiv:2308.00956v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00956">http://arxiv.org/abs/2308.00956</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00956] Curriculum Guided Domain Adaptation in the Dark](http://arxiv.org/abs/2308.00956) #security</code></li>
<li>Summary: <p>Addressing the rising concerns of privacy and security, domain adaptation in
the dark aims to adapt a black-box source trained model to an unlabeled target
domain without access to any source data or source model parameters. The need
for domain adaptation of black-box predictors becomes even more pronounced to
protect intellectual property as deep learning based solutions are becoming
increasingly commercialized. Current methods distill noisy predictions on the
target data obtained from the source model to the target model, and/or separate
clean/noisy target samples before adapting using traditional noisy label
learning algorithms. However, these methods do not utilize the easy-to-hard
learning nature of the clean/noisy data splits. Also, none of the existing
methods are end-to-end, and require a separate fine-tuning stage and an initial
warmup stage. In this work, we present Curriculum Adaptation for Black-Box
(CABB) which provides a curriculum guided adaptation approach to gradually
train the target model, first on target data with high confidence (clean)
labels, and later on target data with noisy labels. CABB utilizes
Jensen-Shannon divergence as a better criterion for clean-noisy sample
separation, compared to the traditional criterion of cross entropy loss. Our
method utilizes co-training of a dual-branch network to suppress error
accumulation resulting from confirmation bias. The proposed approach is
end-to-end trainable and does not require any extra finetuning stage, unlike
existing methods. Empirical results on standard domain adaptation datasets show
that CABB outperforms existing state-of-the-art black-box DA models and is
comparable to white-box domain adaptation models.
</p></li>
</ul>

<h3>Title: Homography Estimation in Complex Topological Scenes. (arXiv:2308.01086v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01086">http://arxiv.org/abs/2308.01086</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01086] Homography Estimation in Complex Topological Scenes](http://arxiv.org/abs/2308.01086) #security</code></li>
<li>Summary: <p>Surveillance videos and images are used for a broad set of applications,
ranging from traffic analysis to crime detection. Extrinsic camera calibration
data is important for most analysis applications. However, security cameras are
susceptible to environmental conditions and small camera movements, resulting
in a need for an automated re-calibration method that can account for these
varying conditions. In this paper, we present an automated camera-calibration
process leveraging a dictionary-based approach that does not require prior
knowledge on any camera settings. The method consists of a custom
implementation of a Spatial Transformer Network (STN) and a novel topological
loss function. Experiments reveal that the proposed method improves the IoU
metric by up to 12% w.r.t. a state-of-the-art model across five synthetic
datasets and the World Cup 2014 dataset.
</p></li>
</ul>

<h3>Title: IIDS: Design of Intelligent Intrusion Detection System for Internet-of-Things Applications. (arXiv:2308.00943v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00943">http://arxiv.org/abs/2308.00943</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00943] IIDS: Design of Intelligent Intrusion Detection System for Internet-of-Things Applications](http://arxiv.org/abs/2308.00943) #security</code></li>
<li>Summary: <p>With rapid technological growth, security attacks are drastically increasing.
In many crucial Internet-of-Things (IoT) applications such as healthcare and
defense, the early detection of security attacks plays a significant role in
protecting huge resources. An intrusion detection system is used to address
this problem. The signature-based approaches fail to detect zero-day attacks.
So anomaly-based detection particularly AI tools, are becoming popular. In
addition, the imbalanced dataset leads to biased results. In Machine Learning
(ML) models, F1 score is an important metric to measure the accuracy of
class-level correct predictions. The model may fail to detect the target
samples if the F1 is considerably low. It will lead to unrecoverable
consequences in sensitive applications such as healthcare and defense. So, any
improvement in the F1 score has significant impact on the resource protection.
In this paper, we present a framework for ML-based intrusion detection system
for an imbalanced dataset. In this study, the most recent dataset, namely
CICIoT2023 is considered. The random forest (RF) algorithm is used in the
proposed framework. The proposed approach improves 3.72%, 3.75% and 4.69% in
precision, recall and F1 score, respectively, with the existing method.
Additionally, for unsaturated classes (i.e., classes with F1 score < 0.99), F1
score improved significantly by 7.9%. As a result, the proposed approach is
more suitable for IoT security applications for efficient detection of
intrusion and is useful in further studies.
</p></li>
</ul>

<h3>Title: Integrating Homomorphic Encryption and Trusted Execution Technology for Autonomous and Confidential Model Refining in Cloud. (arXiv:2308.00963v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00963">http://arxiv.org/abs/2308.00963</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00963] Integrating Homomorphic Encryption and Trusted Execution Technology for Autonomous and Confidential Model Refining in Cloud](http://arxiv.org/abs/2308.00963) #security</code></li>
<li>Summary: <p>With the popularity of cloud computing and machine learning, it has been a
trend to outsource machine learning processes (including model training and
model-based inference) to cloud. By the outsourcing, other than utilizing the
extensive and scalable resource offered by the cloud service provider, it will
also be attractive to users if the cloud servers can manage the machine
learning processes autonomously on behalf of the users. Such a feature will be
especially salient when the machine learning is expected to be a long-term
continuous process and the users are not always available to participate. Due
to security and privacy concerns, it is also desired that the autonomous
learning preserves the confidentiality of users' data and models involved.
Hence, in this paper, we aim to design a scheme that enables autonomous and
confidential model refining in cloud. Homomorphic encryption and trusted
execution environment technology can protect confidentiality for autonomous
computation, but each of them has their limitations respectively and they are
complementary to each other. Therefore, we further propose to integrate these
two techniques in the design of the model refining scheme. Through
implementation and experiments, we evaluate the feasibility of our proposed
scheme. The results indicate that, with our proposed scheme the cloud server
can autonomously refine an encrypted model with newly provided encrypted
training data to continuously improve its accuracy. Though the efficiency is
still significantly lower than the baseline scheme that refines plaintext-model
with plaintext-data, we expect that it can be improved by fully utilizing the
higher level of parallelism and the computational power of GPU at the cloud
server.
</p></li>
</ul>

<h3>Title: Evaluate and Guard the Wisdom of Crowds: Zero Knowledge Proofs for Crowdsourcing Truth Inference. (arXiv:2308.00985v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00985">http://arxiv.org/abs/2308.00985</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00985] Evaluate and Guard the Wisdom of Crowds: Zero Knowledge Proofs for Crowdsourcing Truth Inference](http://arxiv.org/abs/2308.00985) #security</code></li>
<li>Summary: <p>Due to the risks of correctness and security in outsourced cloud computing,
we consider a new paradigm called crowdsourcing: distribute tasks, receive
answers and aggregate the results from multiple entities. Through this
approach, we can aggregate the wisdom of the crowd to complete tasks, ensuring
the accuracy of task completion while reducing the risks posed by the malicious
acts of a single entity. However, the ensuing question is, how can we ensure
that the aggregator has done its work honestly and each contributor's work has
been evaluated fairly?
</p></li>
</ul>

<p>In this paper, we propose a new scheme called $\mathsf{zkTI}$. This scheme
ensures that the aggregator has honestly completed the aggregation and each
data source is fairly evaluated. We combine a cryptographic primitive called
\textit{zero-knowledge proof} with a class of \textit{truth inference
algorithms} which is widely studied in AI/ML scenarios. Under this scheme,
various complex outsourced tasks can be solved with efficiency and accuracy. To
build our scheme, a novel method to prove the precise computation of
floating-point numbers is proposed, which is nearly optimal and well-compatible
with existing argument systems. This may become an independent point of
interest. Thus our work can prove the process of aggregation and inference
without loss of precision. We fully implement and evaluate our ideas. Compared
with recent works, our scheme achieves $2-4 \times$ efficiency improvement and
is robust to be widely applied.
</p>

<h3>Title: An Adaptable Approach for Successful SIEM Adoption in Companies. (arXiv:2308.01065v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01065">http://arxiv.org/abs/2308.01065</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01065] An Adaptable Approach for Successful SIEM Adoption in Companies](http://arxiv.org/abs/2308.01065) #security</code></li>
<li>Summary: <p>In corporations around the world, the topic of cybersecurity and information
security is becoming increasingly important as the number of cyberattacks on
themselves continues to grow. Nowadays, it is no longer just a matter of
protecting against cyberattacks, but rather of detecting such attacks at an
early stage and responding accordingly. There is currently no generic
methodological approach for the implementation of Security Information and
Event Management (SIEM) systems that takes academic aspects into account and
can be applied independently of the product or developers of the systems.
Applying Hevner's design science research approach, the goal of this paper is
to develop a holistic procedure model for implementing respective SIEM systems
in corporations. According to the study during the validation phase, the
procedure model was verified to be applicable. As desire for future research,
the procedure model should be applied in various implementation projects in
different enterprises to analyze its applicability and completeness.
</p></li>
</ul>

<h3>Title: BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems. (arXiv:2308.01274v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01274">http://arxiv.org/abs/2308.01274</a></li>
<li>Code URL: <a href="https://github.com/aralab-unr/brnes">https://github.com/aralab-unr/brnes</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01274] BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems](http://arxiv.org/abs/2308.01274) #security</code></li>
<li>Summary: <p>Although experience sharing (ES) accelerates multiagent reinforcement
learning (MARL) in an advisor-advisee framework, attempts to apply ES to
decentralized multiagent systems have so far relied on trusted environments and
overlooked the possibility of adversarial manipulation and inference.
Nevertheless, in a real-world setting, some Byzantine attackers, disguised as
advisors, may provide false advice to the advisee and catastrophically degrade
the overall learning performance. Also, an inference attacker, disguised as an
advisee, may conduct several queries to infer the advisors' private information
and make the entire ES process questionable in terms of privacy leakage. To
address and tackle these issues, we propose a novel MARL framework (BRNES) that
heuristically selects a dynamic neighbor zone for each advisee at each learning
step and adopts a weighted experience aggregation technique to reduce Byzantine
attack impact. Furthermore, to keep the agent's private information safe from
adversarial inference attacks, we leverage the local differential privacy
(LDP)-induced noise during the ES process. Our experiments show that our
framework outperforms the state-of-the-art in terms of the steps to goal,
obtained reward, and time to goal metrics. Particularly, our evaluation shows
that the proposed framework is 8.32x faster than the current non-private
frameworks and 1.41x faster than the private frameworks in an adversarial
setting.
</p></li>
</ul>

<h3>Title: DeepTSF: Codeless machine learning operations for time series forecasting. (arXiv:2308.00709v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00709">http://arxiv.org/abs/2308.00709</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00709] DeepTSF: Codeless machine learning operations for time series forecasting](http://arxiv.org/abs/2308.00709) #security</code></li>
<li>Summary: <p>This paper presents DeepTSF, a comprehensive machine learning operations
(MLOps) framework aiming to innovate time series forecasting through workflow
automation and codeless modeling. DeepTSF automates key aspects of the ML
lifecycle, making it an ideal tool for data scientists and MLops engineers
engaged in machine learning (ML) and deep learning (DL)-based forecasting.
DeepTSF empowers users with a robust and user-friendly solution, while it is
designed to seamlessly integrate with existing data analysis workflows,
providing enhanced productivity and compatibility. The framework offers a
front-end user interface (UI) suitable for data scientists, as well as other
higher-level stakeholders, enabling comprehensive understanding through
insightful visualizations and evaluation metrics. DeepTSF also prioritizes
security through identity management and access authorization mechanisms. The
application of DeepTSF in real-life use cases of the I-NERGY project has
already proven DeepTSF's efficacy in DL-based load forecasting, showcasing its
significant added value in the electrical power and energy systems domain.
</p></li>
</ul>

<h3>Title: Maximizing Success Rate of Payment Routing using Non-stationary Bandits. (arXiv:2308.01028v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01028">http://arxiv.org/abs/2308.01028</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01028] Maximizing Success Rate of Payment Routing using Non-stationary Bandits](http://arxiv.org/abs/2308.01028) #security</code></li>
<li>Summary: <p>This paper discusses the system architecture design and deployment of
non-stationary multi-armed bandit approaches to determine a near-optimal
payment routing policy based on the recent history of transactions. We propose
a Routing Service architecture using a novel Ray-based implementation for
optimally scaling bandit-based payment routing to over 10000 transactions per
second, adhering to the system design requirements and ecosystem constraints
with Payment Card Industry Data Security Standard (PCI DSS). We first evaluate
the effectiveness of multiple bandit-based payment routing algorithms on a
custom simulator to benchmark multiple non-stationary bandit approaches and
identify the best hyperparameters. We then conducted live experiments on the
payment transaction system on a fantasy sports platform Dream11. In the live
experiments, we demonstrated that our non-stationary bandit-based algorithm
consistently improves the success rate of transactions by 0.92\% compared to
the traditional rule-based methods over one month.
</p></li>
</ul>

<h3>Title: Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach. (arXiv:2308.01063v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01063">http://arxiv.org/abs/2308.01063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01063] Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach](http://arxiv.org/abs/2308.01063) #security</code></li>
<li>Summary: <p>Graph anomaly detection (GAD) has achieved success and has been widely
applied in various domains, such as fraud detection, cybersecurity, finance
security, and biochemistry. However, existing graph anomaly detection
algorithms focus on distinguishing individual entities (nodes or graphs) and
overlook the possibility of anomalous groups within the graph. To address this
limitation, this paper introduces a novel unsupervised framework for a new task
called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework
first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that
belong to potential anomaly groups by capturing long-range inconsistencies.
Subsequently, group sampling is employed to sample candidate groups, which are
then fed into the proposed Topology Pattern-based Graph Contrastive Learning
(TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to
generate embeddings for each candidate group and thus distinct anomaly groups.
The experimental results on both real-world and synthetic datasets demonstrate
that the proposed framework shows superior performance in identifying and
localizing anomaly groups, highlighting it as a promising solution for Gr-GAD.
Datasets and codes of the proposed framework are at the github repository
https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation. (arXiv:2308.00856v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00856">http://arxiv.org/abs/2308.00856</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00856] Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation](http://arxiv.org/abs/2308.00856) #privacy</code></li>
<li>Summary: <p>Federated Learning (FL) is a distributed machine learning approach that
safeguards privacy by creating an impartial global model while respecting the
privacy of individual client data. However, the conventional FL method can
introduce security risks when dealing with diverse client data, potentially
compromising privacy and data integrity. To address these challenges, we
present a differential privacy (DP) federated deep learning framework in
medical image segmentation. In this paper, we extend our similarity weight
aggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private
similarity-weighted aggregation algorithm for brain tumor segmentation in
multi-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only
enhances model segmentation capabilities but also provides an additional layer
of privacy preservation. Extensive benchmarking and evaluation of our
framework, with computational performance as a key consideration, demonstrate
that DP-SimAgg enables accurate and robust brain tumor segmentation while
minimizing communication costs during model training. This advancement is
crucial for preserving the privacy of medical image data and safeguarding
sensitive information. In conclusion, adding a differential privacy layer in
the global weight aggregation phase of the federated brain tumor segmentation
provides a promising solution to privacy concerns without compromising
segmentation model efficacy. By leveraging DP, we ensure the protection of
client data against adversarial attacks and malicious participants.
</p></li>
</ul>

<h3>Title: Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives. (arXiv:2308.01139v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01139">http://arxiv.org/abs/2308.01139</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01139] Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives](http://arxiv.org/abs/2308.01139) #privacy</code></li>
<li>Summary: <p>This paper proposes a locally differentially private federated learning
algorithm for strongly convex but possibly nonsmooth problems that protects the
gradients of each worker against an honest but curious server. The proposed
algorithm adds artificial noise to the shared information to ensure privacy and
dynamically allocates the time-varying noise variance to minimize an upper
bound of the optimization error subject to a predefined privacy budget
constraint. This allows for an arbitrarily large but finite number of
iterations to achieve both privacy protection and utility up to a neighborhood
of the optimal solution, removing the need for tuning the number of iterations.
Numerical results show the superiority of the proposed algorithm over
state-of-the-art methods.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites. (arXiv:2308.01246v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01246">http://arxiv.org/abs/2308.01246</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01246] Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites](http://arxiv.org/abs/2308.01246) #protect</code></li>
<li>Summary: <p>Digital preservation of Cultural Heritage (CH) sites is crucial to protect
them against damage from natural disasters or human activities. Creating 3D
models of CH sites has become a popular method of digital preservation thanks
to advancements in computer vision and photogrammetry. However, the process is
time-consuming, expensive, and typically requires specialized equipment and
expertise, posing challenges in resource-limited developing countries.
Additionally, the lack of an open repository for 3D models hinders research and
public engagement with their heritage. To address these issues, we propose
Tirtha, a web platform for crowdsourcing images of CH sites and creating their
3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and
Multi-View Stereo (MVS) techniques. It is modular, extensible and
cost-effective, allowing for the incorporation of new techniques as
photogrammetry advances. Tirtha is accessible through a web interface at
https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud
environment. In our case studies, we demonstrate the pipeline's effectiveness
by creating 3D models of temples in Odisha, India, using crowdsourced images.
These models are available for viewing, interaction, and download on the Tirtha
website. Our work aims to provide a dataset of crowdsourced images and 3D
reconstructions for research in computer vision, heritage conservation, and
related domains. Overall, Tirtha is a step towards democratizing digital
preservation, primarily in resource-limited developing countries.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Tim. (arXiv:2308.01040v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01040">http://arxiv.org/abs/2308.01040</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01040] Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Tim](http://arxiv.org/abs/2308.01040) #defense</code></li>
<li>Summary: <p>Automatic speech recognition (ASR) systems have been shown to be vulnerable
to adversarial examples (AEs). Recent success all assumes that users will not
notice or disrupt the attack process despite the existence of music/noise-like
sounds and spontaneous responses from voice assistants. Nonetheless, in
practical user-present scenarios, user awareness may nullify existing attack
attempts that launch unexpected sounds or ASR usage. In this paper, we seek to
bridge the gap in existing research and extend the attack to user-present
scenarios. We propose VRIFLE, an inaudible adversarial perturbation (IAP)
attack via ultrasound delivery that can manipulate ASRs as a user speaks. The
inherent differences between audible sounds and ultrasounds make IAP delivery
face unprecedented challenges such as distortion, noise, and instability. In
this regard, we design a novel ultrasonic transformation model to enhance the
crafted perturbation to be physically effective and even survive long-distance
delivery. We further enable VRIFLE's robustness by adopting a series of
augmentation on user and real-world variations during the generation process.
In this way, VRIFLE features an effective real-time manipulation of the ASR
output from different distances and under any speech of users, with an
alter-and-mute strategy that suppresses the impact of user disruption. Our
extensive experiments in both digital and physical worlds verify VRIFLE's
effectiveness under various configurations, robustness against six kinds of
defenses, and universality in a targeted manner. We also show that VRIFLE can
be delivered with a portable attack device and even everyday-life loudspeakers.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Training on Foveated Images Improves Robustness to Adversarial Attacks. (arXiv:2308.00854v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00854">http://arxiv.org/abs/2308.00854</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00854] Training on Foveated Images Improves Robustness to Adversarial Attacks](http://arxiv.org/abs/2308.00854) #attack</code></li>
<li>Summary: <p>Deep neural networks (DNNs) have been shown to be vulnerable to adversarial
attacks -- subtle, perceptually indistinguishable perturbations of inputs that
change the response of the model. In the context of vision, we hypothesize that
an important contributor to the robustness of human visual perception is
constant exposure to low-fidelity visual stimuli in our peripheral vision. To
investigate this hypothesis, we develop \RBlur, an image transform that
simulates the loss in fidelity of peripheral vision by blurring the image and
reducing its color saturation based on the distance from a given fixation
point. We show that compared to DNNs trained on the original images, DNNs
trained on images transformed by \RBlur are substantially more robust to
adversarial attacks, as well as other, non-adversarial, corruptions, achieving
up to 25\% higher accuracy on perturbed data.
</p></li>
</ul>

<h3>Title: Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks. (arXiv:2308.00958v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00958">http://arxiv.org/abs/2308.00958</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00958] Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks](http://arxiv.org/abs/2308.00958) #attack</code></li>
<li>Summary: <p>Despite the broad application of Machine Learning models as a Service
(MLaaS), they are vulnerable to model stealing attacks. These attacks can
replicate the model functionality by using the black-box query process without
any prior knowledge of the target victim model. Existing stealing defenses add
deceptive perturbations to the victim's posterior probabilities to mislead the
attackers. However, these defenses are now suffering problems of high inference
computational overheads and unfavorable trade-offs between benign accuracy and
stealing robustness, which challenges the feasibility of deployed models in
practice. To address the problems, this paper proposes Isolation and Induction
(InI), a novel and effective training framework for model stealing defenses.
Instead of deploying auxiliary defense modules that introduce redundant
inference time, InI directly trains a defensive model by isolating the
adversary's training gradient from the expected gradient, which can effectively
reduce the inference computational cost. In contrast to adding perturbations
over model predictions that harm the benign accuracy, we train models to
produce uninformative outputs against stealing queries, which can induce the
adversary to extract little useful knowledge from victim models with minimal
impact on the benign performance. Extensive experiments on several visual
classification datasets (e.g., MNIST and CIFAR10) demonstrate the superior
robustness (up to 48% reduction on stealing accuracy) and speed (up to 25.4x
faster) of our InI over other state-of-the-art methods. Our codes can be found
in https://github.com/DIG-Beihang/InI-Model-Stealing-Defense.
</p></li>
</ul>

<h3>Title: A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards. (arXiv:2308.01074v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01074">http://arxiv.org/abs/2308.01074</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01074] A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards](http://arxiv.org/abs/2308.01074) #attack</code></li>
<li>Summary: <p>With recent developments in deep learning, the ubiquity of micro-phones and
the rise in online services via personal devices, acoustic side channel attacks
present a greater threat to keyboards than ever. This paper presents a
practical implementation of a state-of-the-art deep learning model in order to
classify laptop keystrokes, using a smartphone integrated microphone. When
trained on keystrokes recorded by a nearby phone, the classifier achieved an
accuracy of 95%, the highest accuracy seen without the use of a language model.
When trained on keystrokes recorded using the video-conferencing software Zoom,
an accuracy of 93% was achieved, a new best for the medium. Our results prove
the practicality of these side channel attacks via off-the-shelf equipment and
algorithms. We discuss a series of mitigation methods to protect users against
these series of attacks.
</p></li>
</ul>

<h3>Title: Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator. (arXiv:2308.01193v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01193">http://arxiv.org/abs/2308.01193</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01193] Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator](http://arxiv.org/abs/2308.01193) #attack</code></li>
<li>Summary: <p>DNN accelerators have been widely deployed in many scenarios to speed up the
inference process and reduce the energy consumption. One big concern about the
usage of the accelerators is the confidentiality of the deployed models: model
inference execution on the accelerators could leak side-channel information,
which enables an adversary to preciously recover the model details. Such model
extraction attacks can not only compromise the intellectual property of DNN
models, but also facilitate some adversarial attacks.
</p></li>
</ul>

<p>Although previous works have demonstrated a number of side-channel techniques
to extract models from DNN accelerators, they are not practical for two
reasons. (1) They only target simplified accelerator implementations, which
have limited practicality in the real world. (2) They require heavy human
analysis and domain knowledge. To overcome these limitations, this paper
presents Mercury, the first automated remote side-channel attack against the
off-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to model
the side-channel extraction process as a sequence-to-sequence problem. The
adversary can leverage a time-to-digital converter (TDC) to remotely collect
the power trace of the target model's inference. Then he uses a learning model
to automatically recover the architecture details of the victim model from the
power trace without any prior knowledge. The adversary can further use the
attention mechanism to localize the leakage points that contribute most to the
attack. Evaluation results indicate that Mercury can keep the error rate of
model extraction below 1%.
</p>

<h3>Title: LSF-IDM: Lightweight Deep Learning Models for Automotive Intrusion Detection Model Based on Semantic Fusion. (arXiv:2308.01237v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01237">http://arxiv.org/abs/2308.01237</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01237] LSF-IDM: Lightweight Deep Learning Models for Automotive Intrusion Detection Model Based on Semantic Fusion](http://arxiv.org/abs/2308.01237) #attack</code></li>
<li>Summary: <p>Autonomous vehicles (AVs) are more vulnerable to network attacks due to the
high connectivity and diverse communication modes between vehicles and external
networks. Deep learning-based Intrusion detection, an effective method for
detecting network attacks, can provide functional safety as well as a real-time
communication guarantee for vehicles, thereby being widely used for AVs.
Existing works well for cyber-attacks such as simple-mode but become a higher
false alarm with a resource-limited environment required when the attack is
concealed within a contextual feature. In this paper, we present a lightweight
intrusion detection model based on semantic fusion, named LSF-IDM. Our
motivation is based on the observation that, when injected the malicious
packets to the in-vehicle networks (IVNs), the packet log presents a strict
order of context feature because of the periodicity and broadcast nature of the
CAN bus. Therefore, this model first captures the context as the semantic
feature of messages by the BERT language framework. Thereafter, the lightweight
model (e.g., BiLSTM) learns the fused feature from an input packet's
classification and its output distribution in BERT based on knowledge
distillation. Experiment results demonstrate the effectiveness of our methods
in defending against several representative attacks from IVNs. We also perform
the difference analysis of the proposed method with lightweight models and Bert
to attain a deeper understanding of how the model balance detection performance
and model complexity.
</p></li>
</ul>

<h3>Title: A Large-Scale Study of Phishing PDF Documents. (arXiv:2308.01273v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01273">http://arxiv.org/abs/2308.01273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01273] A Large-Scale Study of Phishing PDF Documents](http://arxiv.org/abs/2308.01273) #attack</code></li>
<li>Summary: <p>Phishing PDFs are malicious PDF documents that do not embed malware but trick
victims into visiting malicious web pages leading to password theft or drive-by
downloads. While recent reports indicate a surge of phishing PDFs, prior works
have largely neglected this new threat, positioning phishing PDFs as
accessories distributed via email phishing campaigns.
</p></li>
</ul>

<p>This paper challenges this belief and presents the first systematic and
comprehensive study centered on phishing PDFs. Starting from a real-world
dataset, we first identify 44 phishing PDF campaigns via clustering and
characterize them by looking at their volumetric, temporal, and visual
features. Among these, we identify three large campaigns covering 89% of the
dataset, exhibiting significantly different volumetric and temporal properties
compared to classical email phishing, and relying on web UI elements as visual
baits. Finally, we look at the distribution vectors and show that phishing PDFs
are not only distributed via attachments but also via SEO attacks, placing
phishing PDFs outside the email distribution ecosystem.
</p>
<p>This paper also assesses the usefulness of the VirusTotal scoring system,
showing that phishing PDFs are ranked considerably low, creating a blind spot
for organizations. While URL blocklists can help to prevent victims from
visiting the attack web pages, PDF documents seem not subjected to any form of
content-based filtering or detection.
</p>

<h2>robust</h2>
<h3>Title: Adaptive Semantic Consistency for Cross-domain Few-shot Classification. (arXiv:2308.00727v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00727">http://arxiv.org/abs/2308.00727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00727] Adaptive Semantic Consistency for Cross-domain Few-shot Classification](http://arxiv.org/abs/2308.00727) #robust</code></li>
<li>Summary: <p>Cross-domain few-shot classification (CD-FSC) aims to identify novel target
classes with a few samples, assuming that there exists a domain shift between
source and target domains. Existing state-of-the-art practices typically
pre-train on source domain and then finetune on the few-shot target data to
yield task-adaptive representations. Despite promising progress, these methods
are prone to overfitting the limited target distribution since data-scarcity
and ignore the transferable knowledge learned in the source domain. To
alleviate this problem, we propose a simple plug-and-play Adaptive Semantic
Consistency (ASC) framework, which improves cross-domain robustness by
preserving source transfer capability during the finetuning stage. Concretely,
we reuse the source images in the pretraining phase and design an adaptive
weight assignment strategy to highlight the samples similar to target domain,
aiming to aggregate informative target-related knowledge from source domain.
Subsequently, a semantic consistency regularization is applied to constrain the
consistency between the semantic features of the source images output by the
source model and target model. In this way, the proposed ASC enables explicit
transfer of source domain knowledge to prevent the model from overfitting the
target domain. Extensive experiments on multiple benchmarks demonstrate the
effectiveness of the proposed ASC, and ASC provides consistent improvements
over the baselines. The source code will be released.
</p></li>
</ul>

<h3>Title: Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction. (arXiv:2308.00799v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00799">http://arxiv.org/abs/2308.00799</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00799] Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction](http://arxiv.org/abs/2308.00799) #robust</code></li>
<li>Summary: <p>While 3D body reconstruction methods have made remarkable progress recently,
it remains difficult to acquire the sufficiently accurate and numerous 3D
supervisions required for training. In this paper, we propose \textbf{KNOWN}, a
framework that effectively utilizes body \textbf{KNOW}ledge and
u\textbf{N}certainty modeling to compensate for insufficient 3D supervisions.
KNOWN exploits a comprehensive set of generic body constraints derived from
well-established body knowledge. These generic constraints precisely and
explicitly characterize the reconstruction plausibility and enable 3D
reconstruction models to be trained without any 3D data. Moreover, existing
methods typically use images from multiple datasets during training, which can
result in data noise (\textit{e.g.}, inconsistent joint annotation) and data
imbalance (\textit{e.g.}, minority images representing unusual poses or
captured from challenging camera views). KNOWN solves these problems through a
novel probabilistic framework that models both aleatoric and epistemic
uncertainty. Aleatoric uncertainty is encoded in a robust Negative
Log-Likelihood (NLL) training loss, while epistemic uncertainty is used to
guide model refinement. Experiments demonstrate that KNOWN's body
reconstruction outperforms prior weakly-supervised approaches, particularly on
the challenging minority images.
</p></li>
</ul>

<h3>Title: ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation. (arXiv:2308.00906v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00906">http://arxiv.org/abs/2308.00906</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00906] ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation](http://arxiv.org/abs/2308.00906) #robust</code></li>
<li>Summary: <p>While language-guided image manipulation has made remarkable progress, the
challenge of how to instruct the manipulation process faithfully reflecting
human intentions persists. An accurate and comprehensive description of a
manipulation task using natural language is laborious and sometimes even
impossible, primarily due to the inherent uncertainty and ambiguity present in
linguistic expressions. Is it feasible to accomplish image manipulation without
resorting to external cross-modal language information? If this possibility
exists, the inherent modality gap would be effortlessly eliminated. In this
paper, we propose a novel manipulation methodology, dubbed ImageBrush, that
learns visual instructions for more accurate image editing. Our key idea is to
employ a pair of transformation images as visual instructions, which not only
precisely captures human intention but also facilitates accessibility in
real-world scenarios. Capturing visual instructions is particularly challenging
because it involves extracting the underlying intentions solely from visual
demonstrations and then applying this operation to a new image. To address this
challenge, we formulate visual instruction learning as a diffusion-based
inpainting problem, where the contextual information is fully exploited through
an iterative process of generation. A visual prompting encoder is carefully
devised to enhance the model's capacity in uncovering human intent behind the
visual instructions. Extensive experiments show that our method generates
engaging manipulation results conforming to the transformations entailed in
demonstrations. Moreover, our model exhibits robust generalization capabilities
on various downstream tasks such as pose transfer, image translation and video
inpainting.
</p></li>
</ul>

<h3>Title: MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization. (arXiv:2308.01000v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01000">http://arxiv.org/abs/2308.01000</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01000] MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization](http://arxiv.org/abs/2308.01000) #robust</code></li>
<li>Summary: <p>Supervised 3D Object Detection models have been displaying increasingly
better performance in single-domain cases where the training data comes from
the same environment and sensor as the testing data. However, in real-world
scenarios data from the target domain may not be available for finetuning or
for domain adaptation methods. Indeed, 3D object detection models trained on a
source dataset with a specific point distribution have shown difficulties in
generalizing to unseen datasets. Therefore, we decided to leverage the
information available from several annotated source datasets with our
Multi-Dataset Training for 3D Object Detection (MDT3D) method to increase the
robustness of 3D object detection models when tested in a new environment with
a different sensor configuration. To tackle the labelling gap between datasets,
we used a new label mapping based on coarse labels. Furthermore, we show how we
managed the mix of datasets during training and finally introduce a new
cross-dataset augmentation method: cross-dataset object injection. We
demonstrate that this training paradigm shows improvements for different types
of 3D object detection models. The source code and additional results for this
research project will be publicly available on GitHub for interested parties to
access and utilize: https://github.com/LouisSF/MDT3D
</p></li>
</ul>

<h3>Title: FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving. (arXiv:2308.01006v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01006">http://arxiv.org/abs/2308.01006</a></li>
<li>Code URL: <a href="https://github.com/westlake-autolab/fusionad">https://github.com/westlake-autolab/fusionad</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01006] FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving](http://arxiv.org/abs/2308.01006) #robust</code></li>
<li>Summary: <p>Building a multi-modality multi-task neural network toward accurate and
robust performance is a de-facto standard in perception task of autonomous
driving. However, leveraging such data from multiple sensors to jointly
optimize the prediction and planning tasks remains largely unexplored. In this
paper, we present FusionAD, to the best of our knowledge, the first unified
framework that fuse the information from two most critical sensors, camera and
LiDAR, goes beyond perception task. Concretely, we first build a transformer
based multi-modality fusion network to effectively produce fusion based
features. In constrast to camera-based end-to-end method UniAD, we then
establish a fusion aided modality-aware prediction and status-aware planning
modules, dubbed FMSPnP that take advantages of multi-modality features. We
conduct extensive experiments on commonly used benchmark nuScenes dataset, our
FusionAD achieves state-of-the-art performance and surpassing baselines on
average 15% on perception tasks like detection and tracking, 10% on occupancy
prediction accuracy, reducing prediction error from 0.708 to 0.389 in ADE score
and reduces the collision rate from 0.31% to only 0.12%.
</p></li>
</ul>

<h3>Title: MammoDG: Generalisable Deep Learning Breaks the Limits of Cross-Domain Multi-Center Breast Cancer Screening. (arXiv:2308.01057v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01057">http://arxiv.org/abs/2308.01057</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01057] MammoDG: Generalisable Deep Learning Breaks the Limits of Cross-Domain Multi-Center Breast Cancer Screening](http://arxiv.org/abs/2308.01057) #robust</code></li>
<li>Summary: <p>Breast cancer is a major cause of cancer death among women, emphasising the
importance of early detection for improved treatment outcomes and quality of
life. Mammography, the primary diagnostic imaging test, poses challenges due to
the high variability and patterns in mammograms. Double reading of mammograms
is recommended in many screening programs to improve diagnostic accuracy but
increases radiologists' workload. Researchers explore Machine Learning models
to support expert decision-making. Stand-alone models have shown comparable or
superior performance to radiologists, but some studies note decreased
sensitivity with multiple datasets, indicating the need for high generalisation
and robustness models. This work devises MammoDG, a novel deep-learning
framework for generalisable and reliable analysis of cross-domain multi-center
mammography data. MammoDG leverages multi-view mammograms and a novel
contrastive mechanism to enhance generalisation capabilities. Extensive
validation demonstrates MammoDG's superiority, highlighting the critical
importance of domain generalisation for trustworthy mammography analysis in
imaging protocol variations.
</p></li>
</ul>

<h3>Title: Stereo Visual Odometry with Deep Learning-Based Point and Line Feature Matching using an Attention Graph Neural Network. (arXiv:2308.01125v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01125">http://arxiv.org/abs/2308.01125</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01125] Stereo Visual Odometry with Deep Learning-Based Point and Line Feature Matching using an Attention Graph Neural Network](http://arxiv.org/abs/2308.01125) #robust</code></li>
<li>Summary: <p>Robust feature matching forms the backbone for most Visual Simultaneous
Localization and Mapping (vSLAM), visual odometry, 3D reconstruction, and
Structure from Motion (SfM) algorithms. However, recovering feature matches
from texture-poor scenes is a major challenge and still remains an open area of
research. In this paper, we present a Stereo Visual Odometry (StereoVO)
technique based on point and line features which uses a novel feature-matching
mechanism based on an Attention Graph Neural Network that is designed to
perform well even under adverse weather conditions such as fog, haze, rain, and
snow, and dynamic lighting conditions such as nighttime illumination and glare
scenarios. We perform experiments on multiple real and synthetic datasets to
validate the ability of our method to perform StereoVO under low visibility
weather and lighting conditions through robust point and line matches. The
results demonstrate that our method achieves more line feature matches than
state-of-the-art line matching algorithms, which when complemented with point
feature matches perform consistently well in adverse weather and dynamic
lighting conditions.
</p></li>
</ul>

<h3>Title: More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes. (arXiv:2308.01313v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01313">http://arxiv.org/abs/2308.01313</a></li>
<li>Code URL: <a href="https://github.com/umd-huang-lab/perceptionclip">https://github.com/umd-huang-lab/perceptionclip</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01313] More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes](http://arxiv.org/abs/2308.01313) #robust</code></li>
<li>Summary: <p>CLIP, as a foundational vision language model, is widely used in zero-shot
image classification due to its ability to understand various visual concepts
and natural language descriptions. However, how to fully leverage CLIP's
unprecedented human-like understanding capabilities to achieve better zero-shot
classification is still an open question. This paper draws inspiration from the
human visual perception process: a modern neuroscience view suggests that in
classifying an object, humans first infer its class-independent attributes
(e.g., background and orientation) which help separate the foreground object
from the background, and then make decisions based on this information.
Inspired by this, we observe that providing CLIP with contextual attributes
improves zero-shot classification and mitigates reliance on spurious features.
We also observe that CLIP itself can reasonably infer the attributes from an
image. With these observations, we propose a training-free, two-step zero-shot
classification method named PerceptionCLIP. Given an image, it first infers
contextual attributes (e.g., background) and then performs object
classification conditioning on them. Our experiments show that PerceptionCLIP
achieves better generalization, group robustness, and better interpretability.
For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by
16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</p></li>
</ul>

<h3>Title: Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning. (arXiv:2308.00989v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00989">http://arxiv.org/abs/2308.00989</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00989] Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning](http://arxiv.org/abs/2308.00989) #robust</code></li>
<li>Summary: <p>Hierarchical reinforcement learning composites subpolicies in different
hierarchies to accomplish complex tasks.Automated subpolicies discovery, which
does not depend on domain knowledge, is a promising approach to generating
subpolicies.However, the degradation problem is a challenge that existing
methods can hardly deal with due to the lack of consideration of diversity or
the employment of weak regularizers. In this paper, we propose a novel
task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer
(WDER), which enlarges the diversity of subpolicies by maximizing the
Wasserstein distances among action distributions. The proposed WDER can be
easily incorporated into the loss function of existing methods to boost their
performance further.Experimental results demonstrate that our WDER improves
performance and sample efficiency in comparison with prior work without
modifying hyperparameters, which indicates the applicability and robustness of
the WDER.
</p></li>
</ul>

<h3>Title: Calibration in Deep Learning: A Survey of the State-of-the-Art. (arXiv:2308.01222v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01222">http://arxiv.org/abs/2308.01222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01222] Calibration in Deep Learning: A Survey of the State-of-the-Art](http://arxiv.org/abs/2308.01222) #robust</code></li>
<li>Summary: <p>Calibrating deep neural models plays an important role in building reliable,
robust AI systems in safety-critical applications. Recent work has shown that
modern neural networks that possess high predictive capability are poorly
calibrated and produce unreliable model predictions. Though deep learning
models achieve remarkable performance on various benchmarks, the study of model
calibration and reliability is relatively underexplored. Ideal deep models
should have not only high predictive performance but also be well calibrated.
There have been some recent methods proposed to calibrate deep models by using
different mechanisms. In this survey, we review the state-of-the-art
calibration methods and provide an understanding of their principles for
performing model calibration. First, we start with the definition of model
calibration and explain the root causes of model miscalibration. Then we
introduce the key metrics that can measure this aspect. It is followed by a
summary of calibration methods that we roughly classified into four categories:
post-hoc calibration, regularization methods, uncertainty estimation, and
composition methods. We also covered some recent advancements in calibrating
large models, particularly large language models (LLMs). Finally, we discuss
some open issues, challenges, and potential directions.
</p></li>
</ul>

<h3>Title: Evaluating the Robustness of Test Selection Methods for Deep Neural Networks. (arXiv:2308.01314v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01314">http://arxiv.org/abs/2308.01314</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01314] Evaluating the Robustness of Test Selection Methods for Deep Neural Networks](http://arxiv.org/abs/2308.01314) #robust</code></li>
<li>Summary: <p>Testing deep learning-based systems is crucial but challenging due to the
required time and labor for labeling collected raw data. To alleviate the
labeling effort, multiple test selection methods have been proposed where only
a subset of test data needs to be labeled while satisfying testing
requirements. However, we observe that such methods with reported promising
results are only evaluated under simple scenarios, e.g., testing on original
test data. This brings a question to us: are they always reliable? In this
paper, we explore when and to what extent test selection methods fail for
testing. Specifically, first, we identify potential pitfalls of 11 selection
methods from top-tier venues based on their construction. Second, we conduct a
study on five datasets with two model architectures per dataset to empirically
confirm the existence of these pitfalls. Furthermore, we demonstrate how
pitfalls can break the reliability of these methods. Concretely, methods for
fault detection suffer from test data that are: 1) correctly classified but
uncertain, or 2) misclassified but confident. Remarkably, the test relative
coverage achieved by such methods drops by up to 86.85%. On the other hand,
methods for performance estimation are sensitive to the choice of
intermediate-layer output. The effectiveness of such methods can be even worse
than random selection when using an inappropriate layer.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification. (arXiv:2308.01136v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01136">http://arxiv.org/abs/2308.01136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01136] Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification](http://arxiv.org/abs/2308.01136) #biometric</code></li>
<li>Summary: <p>This paper introduces a novel approach to leverage the knowledge of existing
expert models for training new Convolutional Neural Networks, on domains where
task-specific data are limited or unavailable. The presented scheme is applied
in offline handwritten signature verification (OffSV) which, akin to other
biometric applications, suffers from inherent data limitations due to
regulatory restrictions. The proposed Student-Teacher (S-T) configuration
utilizes feature-based knowledge distillation (FKD), combining graph-based
similarity for local activations with global similarity measures to supervise
student's training, using only handwritten text data. Remarkably, the models
trained using this technique exhibit comparable, if not superior, performance
to the teacher model across three popular signature datasets. More importantly,
these results are attained without employing any signatures during the feature
extraction training process. This study demonstrates the efficacy of leveraging
existing expert models to overcome data scarcity challenges in OffSV and
potentially other related domains.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: WCCNet: Wavelet-integrated CNN with Crossmodal Rearranging Fusion for Fast Multispectral Pedestrian Detection. (arXiv:2308.01042v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01042">http://arxiv.org/abs/2308.01042</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01042] WCCNet: Wavelet-integrated CNN with Crossmodal Rearranging Fusion for Fast Multispectral Pedestrian Detection](http://arxiv.org/abs/2308.01042) #extraction</code></li>
<li>Summary: <p>Multispectral pedestrian detection achieves better visibility in challenging
conditions and thus has a broad application in various tasks, for which both
the accuracy and computational cost are of paramount importance. Most existing
approaches treat RGB and infrared modalities equally, typically adopting two
symmetrical CNN backbones for multimodal feature extraction, which ignores the
substantial differences between modalities and brings great difficulty for the
reduction of the computational cost as well as effective crossmodal fusion. In
this work, we propose a novel and efficient framework named WCCNet that is able
to differentially extract rich features of different spectra with lower
computational complexity and semantically rearranges these features for
effective crossmodal fusion. Specifically, the discrete wavelet transform (DWT)
allowing fast inference and training speed is embedded to construct a
dual-stream backbone for efficient feature extraction. The DWT layers of WCCNet
extract frequency components for infrared modality, while the CNN layers
extract spatial-domain features for RGB modality. This methodology not only
significantly reduces the computational complexity, but also improves the
extraction of infrared features to facilitate the subsequent crossmodal fusion.
Based on the well extracted features, we elaborately design the crossmodal
rearranging fusion module (CMRF), which can mitigate spatial misalignment and
merge semantically complementary features of spatially-related local regions to
amplify the crossmodal complementary information. We conduct comprehensive
evaluations on KAIST and FLIR benchmarks, in which WCCNet outperforms
state-of-the-art methods with considerable computational efficiency and
competitive accuracy. We also perform the ablation study and analyze thoroughly
the impact of different components on the performance of WCCNet.
</p></li>
</ul>

<h3>Title: Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction. (arXiv:2308.00886v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00886">http://arxiv.org/abs/2308.00886</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00886] Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction](http://arxiv.org/abs/2308.00886) #extraction</code></li>
<li>Summary: <p>Machine learning (ML) models trained on subjective self-report scores
struggle to objectively classify pain accurately due to the significant
variance between real-time pain experiences and recorded scores afterwards.
This study developed two devices for acquisition of real-time, continuous
in-session pain scores and gathering of ANS-modulated endodermal activity
(EDA).The experiment recruited N = 24 subjects who underwent a post-exercise
circulatory occlusion (PECO) with stretch, inducing discomfort. Subject data
were stored in a custom pain platform, facilitating extraction of time-domain
EDA features and in-session ground truth scores. Moreover, post-experiment
visual analog scale (VAS) scores were collected from each subject. Machine
learning models, namely Multi-layer Perceptron (MLP) and Random Forest (RF),
were trained using corresponding objective EDA features combined with
in-session scores and post-session scores, respectively. Over a 10-fold
cross-validation, the macro-averaged geometric mean score revealed MLP and RF
models trained with objective EDA features and in-session scores achieved
superior performance (75.9% and 78.3%) compared to models trained with
post-session scores (70.3% and 74.6%) respectively. This pioneering study
demonstrates that using continuous in-session ground truth scores significantly
enhances ML performance in pain intensity characterization, overcoming ground
truth sparsity-related issues, data imbalance, and high variance. This study
informs future objective-based ML pain system training.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Delegated Time-Lock Puzzle. (arXiv:2308.01280v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01280">http://arxiv.org/abs/2308.01280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01280] Delegated Time-Lock Puzzle](http://arxiv.org/abs/2308.01280) #fair</code></li>
<li>Summary: <p>Time-Lock Puzzles (TLPs) are cryptographic protocols that enable a client to
lock a message in such a way that a server can only unlock it after a specific
time period. However, existing TLPs have certain limitations: (i) they assume
that both the client and server always possess sufficient computational
resources and (ii) they solely focus on the lower time bound for finding a
solution, disregarding the upper bound that guarantees a regular server can
find a solution within a certain time frame. Additionally, existing TLPs
designed to handle multiple puzzles either (a) entail high verification costs
or (b) lack generality, requiring identical time intervals between consecutive
solutions. To address these limitations, this paper introduces, for the first
time, the concept of a "Delegated Time-Lock Puzzle" and presents a protocol
called "Efficient Delegated Time-Lock Puzzle" (ED-TLP) that realises this
concept. ED-TLP allows the client and server to delegate their
resource-demanding tasks to third-party helpers. It facilitates real-time
verification of solution correctness and efficiently handles multiple puzzles
with varying time intervals. ED-TLP ensures the delivery of solutions within
predefined time limits by incorporating both an upper bound and a fair payment
algorithm. We have implemented ED-TLP and conducted a comprehensive analysis of
its overheads, demonstrating the efficiency of the construction.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: WaterFlow: Heuristic Normalizing Flow for Underwater Image Enhancement and Beyond. (arXiv:2308.00931v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00931">http://arxiv.org/abs/2308.00931</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00931] WaterFlow: Heuristic Normalizing Flow for Underwater Image Enhancement and Beyond](http://arxiv.org/abs/2308.00931) #interpretability</code></li>
<li>Summary: <p>Underwater images suffer from light refraction and absorption, which impairs
visibility and interferes the subsequent applications. Existing underwater
image enhancement methods mainly focus on image quality improvement, ignoring
the effect on practice. To balance the visual quality and application, we
propose a heuristic normalizing flow for detection-driven underwater image
enhancement, dubbed WaterFlow. Specifically, we first develop an invertible
mapping to achieve the translation between the degraded image and its clear
counterpart. Considering the differentiability and interpretability, we
incorporate the heuristic prior into the data-driven mapping procedure, where
the ambient light and medium transmission coefficient benefit credible
generation. Furthermore, we introduce a detection perception module to transmit
the implicit semantic guidance into the enhancement procedure, where the
enhanced images hold more detection-favorable features and are able to promote
the detection performance. Extensive experiments prove the superiority of our
WaterFlow, against state-of-the-art methods quantitatively and qualitatively.
</p></li>
</ul>

<h3>Title: DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems. (arXiv:2308.00878v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00878">http://arxiv.org/abs/2308.00878</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00878] DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems](http://arxiv.org/abs/2308.00878) #interpretability</code></li>
<li>Summary: <p>Dialogue act annotations are important to improve response generation quality
in task-oriented dialogue systems. However, it can be challenging to use
dialogue acts to control response generation in a generalizable way because
different datasets and tasks may have incompatible annotations. While
alternative methods that utilize latent action spaces or reinforcement learning
do not require explicit annotations, they may lack interpretability or face
difficulties defining task-specific rewards. In this work, we present a novel
end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts
in a latent space. DiactTOD, when pre-trained on a large corpus, is able to
predict and control dialogue acts to generate controllable responses using
these latent representations in a zero-shot fashion. Our approach demonstrates
state-of-the-art performance across a wide range of experimental settings on
the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning
with both end-to-end and policy optimization configurations.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: The Bias Amplification Paradox in Text-to-Image Generation. (arXiv:2308.00755v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00755">http://arxiv.org/abs/2308.00755</a></li>
<li>Code URL: <a href="https://github.com/preethiseshadri518/bias-amplification-paradox">https://github.com/preethiseshadri518/bias-amplification-paradox</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00755] The Bias Amplification Paradox in Text-to-Image Generation](http://arxiv.org/abs/2308.00755) #diffusion</code></li>
<li>Summary: <p>Bias amplification is a phenomenon in which models increase imbalances
present in the training data. In this paper, we study bias amplification in the
text-to-image domain using Stable Diffusion by comparing gender ratios in
training vs. generated images. We find that the model appears to amplify
gender-occupation biases found in the training data (LAION). However, we
discover that amplification can largely be attributed to discrepancies between
training captions and model prompts. For example, an inherent difference is
that captions from the training data often contain explicit gender information
while the prompts we use do not, which leads to a distribution shift and
consequently impacts bias measures. Once we account for various distributional
differences between texts used for training and generation, we observe that
amplification decreases considerably. Our findings illustrate the challenges of
comparing biases in models and the data they are trained on, and highlight
confounding factors that contribute to bias amplification.
</p></li>
</ul>

<h3>Title: Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective. (arXiv:2308.00994v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00994">http://arxiv.org/abs/2308.00994</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00994] Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective](http://arxiv.org/abs/2308.00994) #diffusion</code></li>
<li>Summary: <p>We live in a vast ocean of data, and deep neural networks are no exception to
this. However, this data exhibits an inherent phenomenon of imbalance. This
imbalance poses a risk of deep neural networks producing biased predictions,
leading to potentially severe ethical and social consequences. To address these
challenges, we believe that the use of generative models is a promising
approach for comprehending tasks, given the remarkable advancements
demonstrated by recent diffusion models in generating high-quality images. In
this work, we propose a simple yet effective baseline, SYNAuG, that utilizes
synthetic data as a preliminary step before employing task-specific algorithms
to address data imbalance problems. This straightforward approach yields
impressive performance on datasets such as CIFAR100-LT, ImageNet100-LT,
UTKFace, and Waterbird, surpassing the performance of existing task-specific
methods. While we do not claim that our approach serves as a complete solution
to the problem of data imbalance, we argue that supplementing the existing data
with synthetic data proves to be an effective and crucial preliminary step in
addressing data imbalance concerns.
</p></li>
</ul>

<h3>Title: DiffusePast: Diffusion-based Generative Replay for Class Incremental Semantic Segmentation. (arXiv:2308.01127v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01127">http://arxiv.org/abs/2308.01127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01127] DiffusePast: Diffusion-based Generative Replay for Class Incremental Semantic Segmentation](http://arxiv.org/abs/2308.01127) #diffusion</code></li>
<li>Summary: <p>The Class Incremental Semantic Segmentation (CISS) extends the traditional
segmentation task by incrementally learning newly added classes. Previous work
has introduced generative replay, which involves replaying old class samples
generated from a pre-trained GAN, to address the issues of catastrophic
forgetting and privacy concerns. However, the generated images lack semantic
precision and exhibit out-of-distribution characteristics, resulting in
inaccurate masks that further degrade the segmentation performance. To tackle
these challenges, we propose DiffusePast, a novel framework featuring a
diffusion-based generative replay module that generates semantically accurate
images with more reliable masks guided by different instructions (e.g., text
prompts or edge maps). Specifically, DiffusePast introduces a dual-generator
paradigm, which focuses on generating old class images that align with the
distribution of downstream datasets while preserving the structure and layout
of the original images, enabling more precise masks. To adapt to the novel
visual concepts of newly added classes continuously, we incorporate class-wise
token embedding when updating the dual-generator. Moreover, we assign adequate
pseudo-labels of old classes to the background pixels in the new step images,
further mitigating the forgetting of previously learned knowledge. Through
comprehensive experiments, our method demonstrates competitive performance
across mainstream benchmarks, striking a better balance between the performance
of old and novel classes.
</p></li>
</ul>

<h3>Title: Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment for Markup-to-Image Generation. (arXiv:2308.01147v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01147">http://arxiv.org/abs/2308.01147</a></li>
<li>Code URL: <a href="https://github.com/zgj77/fsacdm">https://github.com/zgj77/fsacdm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01147] Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment for Markup-to-Image Generation](http://arxiv.org/abs/2308.01147) #diffusion</code></li>
<li>Summary: <p>The recently rising markup-to-image generation poses greater challenges as
compared to natural image generation, due to its low tolerance for errors as
well as the complex sequence and context correlations between markup and
rendered image. This paper proposes a novel model named "Contrast-augmented
Diffusion Model with Fine-grained Sequence Alignment" (FSA-CDM), which
introduces contrastive positive/negative samples into the diffusion model to
boost performance for markup-to-image generation. Technically, we design a
fine-grained cross-modal alignment module to well explore the sequence
similarity between the two modalities for learning robust feature
representations. To improve the generalization ability, we propose a
contrast-augmented diffusion model to explicitly explore positive and negative
samples by maximizing a novel contrastive variational objective, which is
mathematically inferred to provide a tighter bound for the model's
optimization. Moreover, the context-aware cross attention module is developed
to capture the contextual information within markup language during the
denoising process, yielding better noise prediction results. Extensive
experiments are conducted on four benchmark datasets from different domains,
and the experimental results demonstrate the effectiveness of the proposed
components in FSA-CDM, significantly exceeding state-of-the-art performance by
about 2%-12% DTW improvements. The code will be released at
https://github.com/zgj77/FSACDM.
</p></li>
</ul>

<h3>Title: Patched Denoising Diffusion Models For High-Resolution Image Synthesis. (arXiv:2308.01316v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01316">http://arxiv.org/abs/2308.01316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01316] Patched Denoising Diffusion Models For High-Resolution Image Synthesis](http://arxiv.org/abs/2308.01316) #diffusion</code></li>
<li>Summary: <p>We propose an effective denoising diffusion model for generating
high-resolution images (e.g., 1024$\times$512), trained on small-size image
patches (e.g., 64$\times$64). We name our algorithm Patch-DM, in which a new
feature collage strategy is designed to avoid the boundary artifact when
synthesizing large-size images. Feature collage systematically crops and
combines partial features of the neighboring patches to predict the features of
a shifted image patch, allowing the seamless generation of the entire image due
to the overlap in the patch feature space. Patch-DM produces high-quality image
synthesis results on our newly collected dataset of nature images
(1024$\times$512), as well as on standard benchmarks of smaller sizes
(256$\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ. We compare our
method with previous patch-based generation methods and achieve
state-of-the-art FID scores on all four datasets. Further, Patch-DM also
reduces memory complexity compared to the classic diffusion models.
</p></li>
</ul>

<h2>noise learning</h2>
<h3>Title: Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases. (arXiv:2308.01138v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01138">http://arxiv.org/abs/2308.01138</a></li>
<li>Code URL: <a href="https://github.com/magnomic/cnst">https://github.com/magnomic/cnst</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01138] Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases](http://arxiv.org/abs/2308.01138) #noise learning</code></li>
<li>Summary: <p>Spectrum analysis systems in online water quality testing are designed to
detect types and concentrations of pollutants and enable regulatory agencies to
respond promptly to pollution incidents. However, spectral data-based testing
devices suffer from complex noise patterns when deployed in non-laboratory
environments. To make the analysis model applicable to more environments, we
propose a noise patterns transferring model, which takes the spectrum of
standard water samples in different environments as cases and learns the
differences in their noise patterns, thus enabling noise patterns to transfer
to unknown samples. Unfortunately, the inevitable sample-level baseline noise
makes the model unable to obtain the paired data that only differ in
dataset-level environmental noise. To address the problem, we generate a
sample-to-sample case-base to exclude the interference of sample-level noise on
dataset-level noise learning, enhancing the system's learning performance.
Experiments on spectral data with different background noises demonstrate the
good noise-transferring ability of the proposed method against baseline systems
ranging from wavelet denoising, deep neural networks, and generative models.
From this research, we posit that our method can enhance the performance of DL
models by generating high-quality cases. The source code is made publicly
available online at https://github.com/Magnomic/CNST.
</p></li>
</ul>

<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: ELFNet: Evidential Local-global Fusion for Stereo Matching. (arXiv:2308.00728v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00728">http://arxiv.org/abs/2308.00728</a></li>
<li>Code URL: <a href="https://github.com/jimmy19991222/elfnet">https://github.com/jimmy19991222/elfnet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00728] ELFNet: Evidential Local-global Fusion for Stereo Matching](http://arxiv.org/abs/2308.00728) #transformer</code></li>
<li>Summary: <p>Although existing stereo matching models have achieved continuous
improvement, they often face issues related to trustworthiness due to the
absence of uncertainty estimation. Additionally, effectively leveraging
multi-scale and multi-view knowledge of stereo pairs remains unexplored. In
this paper, we introduce the \textbf{E}vidential \textbf{L}ocal-global
\textbf{F}usion (ELF) framework for stereo matching, which endows both
uncertainty estimation and confidence-aware fusion with trustworthy heads.
Instead of predicting the disparity map alone, our model estimates an
evidential-based disparity considering both aleatoric and epistemic
uncertainties. With the normal inverse-Gamma distribution as a bridge, the
proposed framework realizes intra evidential fusion of multi-level predictions
and inter evidential fusion between cost-volume-based and transformer-based
stereo matching. Extensive experimental results show that the proposed
framework exploits multi-view information effectively and achieves
state-of-the-art overall performance both on accuracy and cross-domain
generalization.
</p></li>
</ul>

<p>The codes are available at https://github.com/jimmy19991222/ELFNet.
</p>

<h3>Title: Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather. (arXiv:2308.00924v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00924">http://arxiv.org/abs/2308.00924</a></li>
<li>Code URL: <a href="https://github.com/sadman-jahan/aid-ucm-degradingweather">https://github.com/sadman-jahan/aid-ucm-degradingweather</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00924] Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather](http://arxiv.org/abs/2308.00924) #transformer</code></li>
<li>Summary: <p>Domain adaptation (DA) strives to mitigate the domain gap between the source
domain where a model is trained, and the target domain where the model is
deployed. When a deep learning model is deployed on an aerial platform, it may
face gradually degrading weather conditions during operation, leading to
widening domain gaps between the training data and the encountered evaluation
data. We synthesize two such gradually worsening weather conditions on real
images from two existing aerial imagery datasets, generating a total of four
benchmark datasets. Under the continual, or test-time adaptation setting, we
evaluate three DA models on our datasets: a baseline standard DA model and two
continual DA models. In such setting, the models can access only one small
portion, or one batch of the target data at a time, and adaptation takes place
continually, and over only one epoch of the data. The combination of the
constraints of continual adaptation, and gradually deteriorating weather
conditions provide the practical DA scenario for aerial deployment. Among the
evaluated models, we consider both convolutional and transformer architectures
for comparison. We discover stability issues during adaptation for existing
buffer-fed continual DA methods, and offer gradient normalization as a simple
solution to curb training instability.
</p></li>
</ul>

<h3>Title: From Sparse to Soft Mixtures of Experts. (arXiv:2308.00951v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00951">http://arxiv.org/abs/2308.00951</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00951] From Sparse to Soft Mixtures of Experts](http://arxiv.org/abs/2308.00951) #transformer</code></li>
<li>Summary: <p>Sparse mixture of expert architectures (MoEs) scale model capacity without
large increases in training or inference costs. Despite their success, MoEs
suffer from a number of issues: training instability, token dropping, inability
to scale the number of experts, or ineffective finetuning. In this work, we
proposeSoft MoE, a fully-differentiable sparse Transformer that addresses these
challenges, while maintaining the benefits of MoEs. Soft MoE performs an
implicit soft assignment by passing different weighted combinations of all
input tokens to each expert. As in other MoE works, experts in Soft MoE only
process a subset of the (combined) tokens, enabling larger model capacity at
lower inference cost. In the context of visual recognition, Soft MoE greatly
outperforms standard Transformers (ViTs) and popular MoE variants (Tokens
Choice and Experts Choice). For example, Soft MoE-Base/16 requires 10.5x lower
inference cost (5.7x lower wall-clock time) than ViT-Huge/14 while matching its
performance after similar training. Soft MoE also scales well: Soft MoE Huge/14
with 128 experts in 16 MoE layers has over 40x more parameters than ViT
Huge/14, while inference time cost grows by only 2%, and it performs
substantially better.
</p></li>
</ul>

<h3>Title: Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation. (arXiv:2308.01045v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01045">http://arxiv.org/abs/2308.01045</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01045] Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation](http://arxiv.org/abs/2308.01045) #transformer</code></li>
<li>Summary: <p>Vision transformers have achieved leading performance on various visual tasks
yet still suffer from high computational complexity. The situation deteriorates
in dense prediction tasks like semantic segmentation, as high-resolution inputs
and outputs usually imply more tokens involved in computations. Directly
removing the less attentive tokens has been discussed for the image
classification task but can not be extended to semantic segmentation since a
dense prediction is required for every patch. To this end, this work introduces
a Dynamic Token Pruning (DToP) method based on the early exit of tokens for
semantic segmentation. Motivated by the coarse-to-fine segmentation process by
humans, we naturally split the widely adopted auxiliary-loss-based network
architecture into several stages, where each auxiliary block grades every
token's difficulty level. We can finalize the prediction of easy tokens in
advance without completing the entire forward pass. Moreover, we keep $k$
highest confidence tokens for each semantic category to uphold the
representative context information. Thus, computational complexity will change
with the difficulty of the input, akin to the way humans do segmentation.
Experiments suggest that the proposed DToP architecture reduces on average
$20\% - 35\%$ of computational cost for current semantic segmentation methods
based on plain vision transformers without accuracy degradation.
</p></li>
</ul>

<h3>Title: UCDFormer: Unsupervised Change Detection Using a Transformer-driven Image Translation. (arXiv:2308.01146v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01146">http://arxiv.org/abs/2308.01146</a></li>
<li>Code URL: <a href="https://github.com/zhu-xlab/ucdformer">https://github.com/zhu-xlab/ucdformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01146] UCDFormer: Unsupervised Change Detection Using a Transformer-driven Image Translation](http://arxiv.org/abs/2308.01146) #transformer</code></li>
<li>Summary: <p>Change detection (CD) by comparing two bi-temporal images is a crucial task
in remote sensing. With the advantages of requiring no cumbersome labeled
change information, unsupervised CD has attracted extensive attention in the
community. However, existing unsupervised CD approaches rarely consider the
seasonal and style differences incurred by the illumination and atmospheric
conditions in multi-temporal images. To this end, we propose a change detection
with domain shift setting for remote sensing images. Furthermore, we present a
novel unsupervised CD method using a light-weight transformer, called
UCDFormer. Specifically, a transformer-driven image translation composed of a
light-weight transformer and a domain-specific affinity weight is first
proposed to mitigate domain shift between two images with real-time efficiency.
After image translation, we can generate the difference map between the
translated before-event image and the original after-event image. Then, a novel
reliable pixel extraction module is proposed to select significantly
changed/unchanged pixel positions by fusing the pseudo change maps of fuzzy
c-means clustering and adaptive threshold. Finally, a binary change map is
obtained based on these selected pixel pairs and a binary classifier.
Experimental results on different unsupervised CD tasks with seasonal and style
changes demonstrate the effectiveness of the proposed UCDFormer. For example,
compared with several other related methods, UCDFormer improves performance on
the Kappa coefficient by more than 12\%. In addition, UCDFormer achieves
excellent performance for earthquake-induced landslide detection when
considering large-scale applications. The code is available at
\url{https://github.com/zhu-xlab/UCDFormer}
</p></li>
</ul>

<h3>Title: Grounded Image Text Matching with Mismatched Relation Reasoning. (arXiv:2308.01236v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01236">http://arxiv.org/abs/2308.01236</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01236] Grounded Image Text Matching with Mismatched Relation Reasoning](http://arxiv.org/abs/2308.01236) #transformer</code></li>
<li>Summary: <p>This paper introduces Grounded Image Text Matching with Mismatched Relation
(GITM-MR), a novel visual-linguistic joint task that evaluates the relation
understanding capabilities of transformer-based pre-trained models. GITM-MR
requires a model to first determine if an expression describes an image, then
localize referred objects or ground the mismatched parts of the text. We
provide a benchmark for evaluating pre-trained models on this task, with a
focus on the challenging settings of limited data and out-of-distribution
sentence lengths. Our evaluation demonstrates that pre-trained models lack data
efficiency and length generalization ability. To address this, we propose the
Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates
relation-aware reasoning via bi-directional message propagation guided by
language structure. RCRN can be interpreted as a modular program and delivers
strong performance in both length generalization and data efficiency.
</p></li>
</ul>

<h3>Title: Revisiting DETR Pre-training for Object Detection. (arXiv:2308.01300v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01300">http://arxiv.org/abs/2308.01300</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01300] Revisiting DETR Pre-training for Object Detection](http://arxiv.org/abs/2308.01300) #transformer</code></li>
<li>Summary: <p>Motivated by that DETR-based approaches have established new records on COCO
detection and segmentation benchmarks, many recent endeavors show increasing
interest in how to further improve DETR-based approaches by pre-training the
Transformer in a self-supervised manner while keeping the backbone frozen. Some
studies already claimed significant improvements in accuracy. In this paper, we
take a closer look at their experimental methodology and check if their
approaches are still effective on the very recent state-of-the-art such as
$\mathcal{H}$-Deformable-DETR. We conduct thorough experiments on COCO object
detection tasks to study the influence of the choice of pre-training datasets,
localization, and classification target generation schemes. Unfortunately, we
find the previous representative self-supervised approach such as DETReg, fails
to boost the performance of the strong DETR-based approaches on full data
regimes. We further analyze the reasons and find that simply combining a more
accurate box predictor and Objects$365$ benchmark can significantly improve the
results in follow-up experiments. We demonstrate the effectiveness of our
approach by achieving strong object detection results of AP=$59.3\%$ on COCO
val set, which surpasses $\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\%$.
Last, we generate a series of synthetic pre-training datasets by combining the
very recent image-to-text captioning models (LLaVA) and text-to-image
generative models (SDXL). Notably, pre-training on these synthetic datasets
leads to notable improvements in object detection performance. Looking ahead,
we anticipate substantial advantages through the future expansion of the
synthetic pre-training dataset.
</p></li>
</ul>

<h3>Title: A Pre-trained Data Deduplication Model based on Active Learning. (arXiv:2308.00721v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00721">http://arxiv.org/abs/2308.00721</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00721] A Pre-trained Data Deduplication Model based on Active Learning](http://arxiv.org/abs/2308.00721) #transformer</code></li>
<li>Summary: <p>In the era of big data, the issue of data quality has become increasingly
prominent. One of the main challenges is the problem of duplicate data, which
can arise from repeated entry or the merging of multiple data sources. These
"dirty data" problems can significantly limit the effective application of big
data. To address the issue of data deduplication, we propose a pre-trained
deduplication model based on active learning, which is the first work that
utilizes active learning to address the problem of deduplication at the
semantic level. The model is built on a pre-trained Transformer and fine-tuned
to solve the deduplication problem as a sequence to classification task, which
firstly integrate the transformer with active learning into an end-to-end
architecture to select the most valuable data for deduplication model training,
and also firstly employ the R-Drop method to perform data augmentation on each
round of labeled data, which can reduce the cost of manual labeling and improve
the model's performance. Experimental results demonstrate that our proposed
model outperforms previous state-of-the-art (SOTA) for deduplicated data
identification, achieving up to a 28% improvement in Recall score on benchmark
datasets.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade Forests for Detecting GAN-generated Faces. (arXiv:2308.00964v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00964">http://arxiv.org/abs/2308.00964</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00964] ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade Forests for Detecting GAN-generated Faces](http://arxiv.org/abs/2308.00964) #generative</code></li>
<li>Summary: <p>The prominent progress in generative models has significantly improved the
reality of generated faces, bringing serious concerns to society. Since recent
GAN-generated faces are in high realism, the forgery traces have become more
imperceptible, increasing the forensics challenge. To combat GAN-generated
faces, many countermeasures based on Convolutional Neural Networks (CNNs) have
been spawned due to their strong learning ability. In this paper, we rethink
this problem and explore a new approach based on forest models instead of CNNs.
Specifically, we describe a simple and effective forest-based method set called
{\em ForensicsForest Family} to detect GAN-generate faces. The proposed
ForensicsForest family is composed of three variants, which are {\em
ForensicsForest}, {\em Hybrid ForensicsForest} and {\em Divide-and-Conquer
ForensicsForest} respectively. ForenscisForest is a newly proposed Multi-scale
Hierarchical Cascade Forest, which takes semantic, frequency and biology
features as input, hierarchically cascades different levels of features for
authenticity prediction, and then employs a multi-scale ensemble scheme that
can comprehensively consider different levels of information to improve the
performance further. Based on ForensicsForest, we develop Hybrid
ForensicsForest, an extended version that integrates the CNN layers into
models, to further refine the effectiveness of augmented features. Moreover, to
reduce the memory cost in training, we propose Divide-and-Conquer
ForensicsForest, which can construct a forest model using only a portion of
training samplings. In the training stage, we train several candidate forest
models using the subsets of training samples. Then a ForensicsForest is
assembled by picking the suitable components from these candidate forest
models...
</p></li>
</ul>

<h3>Title: Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior. (arXiv:2308.01184v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01184">http://arxiv.org/abs/2308.01184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01184] Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior](http://arxiv.org/abs/2308.01184) #generative</code></li>
<li>Summary: <p>The learning with noisy labels has been addressed with both discriminative
and generative models. Although discriminative models have dominated the field
due to their simpler modeling and more efficient computational training
processes, generative models offer a more effective means of disentangling
clean and noisy labels and improving the estimation of the label transition
matrix. However, generative approaches maximize the joint likelihood of noisy
labels and data using a complex formulation that only indirectly optimizes the
model of interest associating data and clean labels. Additionally, these
approaches rely on generative models that are challenging to train and tend to
use uninformative clean label priors. In this paper, we propose a new
generative noisy-label learning approach that addresses these three issues.
First, we propose a new model optimisation that directly associates data and
clean labels. Second, the generative model is implicitly estimated using a
discriminative model, eliminating the inefficient training of a generative
model. Third, we propose a new informative label prior inspired by partial
label learning as supervision signal for noisy label learning. Extensive
experiments on several noisy-label benchmarks demonstrate that our generative
model provides state-of-the-art results while maintaining a similar
computational complexity as discriminative models.
</p></li>
</ul>

<h3>Title: Feature-aware conditional GAN for category text generation. (arXiv:2308.00939v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00939">http://arxiv.org/abs/2308.00939</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00939] Feature-aware conditional GAN for category text generation](http://arxiv.org/abs/2308.00939) #generative</code></li>
<li>Summary: <p>Category text generation receives considerable attentions since it is
beneficial for various natural language processing tasks. Recently, the
generative adversarial network (GAN) has attained promising performance in text
generation, attributed to its adversarial training process. However, there are
several issues in text GANs, including discreteness, training instability, mode
collapse, lack of diversity and controllability etc. To address these issues,
this paper proposes a novel GAN framework, the feature-aware conditional GAN
(FA-GAN), for controllable category text generation. In FA-GAN, the generator
has a sequence-to-sequence structure for improving sentence diversity, which
consists of three encoders including a special feature-aware encoder and a
category-aware encoder, and one relational-memory-core-based decoder with the
Gumbel SoftMax activation function. The discriminator has an additional
category classification head. To generate sentences with specified categories,
the multi-class classification loss is supplemented in the adversarial
training. Comprehensive experiments have been conducted, and the results show
that FA-GAN consistently outperforms 10 state-of-the-art text generation
approaches on 6 text classification datasets. The case study demonstrates that
the synthetic sentences generated by FA-GAN can match the required categories
and are aware of the features of conditioned sentences, with good readability,
fluency, and text authenticity.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders. (arXiv:2308.01317v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01317">http://arxiv.org/abs/2308.01317</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01317] ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders](http://arxiv.org/abs/2308.01317) #large language model</code></li>
<li>Summary: <p>Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or
ELIXR, leverages a language-aligned image encoder combined or grafted onto a
fixed LLM, PaLM 2, to perform a broad range of tasks. We train this lightweight
adapter architecture using images paired with corresponding free-text radiology
reports from the MIMIC-CXR dataset. ELIXR achieved state-of-the-art performance
on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13
findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898
across five findings (atelectasis, cardiomegaly, consolidation, pleural
effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images)
training data), and semantic search (0.76 normalized discounted cumulative gain
(NDCG) across nineteen queries, including perfect retrieval on twelve of them).
Compared to existing data-efficient methods including supervised contrastive
learning (SupCon), ELIXR required two orders of magnitude less data to reach
similar performance. ELIXR also showed promise on CXR vision-language tasks,
demonstrating overall accuracies of 58.7% and 62.5% on visual question
answering and report quality assurance tasks, respectively. These results
suggest that ELIXR is a robust and versatile approach to CXR AI.
</p></li>
</ul>

<h3>Title: Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation. (arXiv:2308.01240v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01240">http://arxiv.org/abs/2308.01240</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01240] Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation](http://arxiv.org/abs/2308.01240) #large language model</code></li>
<li>Summary: <p>In this work, we evaluate 10 open-source instructed LLMs on four
representative code comprehension and generation tasks. We have the following
main findings. First, for the zero-shot setting, instructed LLMs are very
competitive on code comprehension and generation tasks and sometimes even
better than small SOTA models specifically fine-tuned on each downstream task.
We also find that larger instructed LLMs are not always better on code-related
tasks. Second, for the few-shot setting, we find that adding demonstration
examples substantially helps instructed LLMs perform better on most code
comprehension and generation tasks; however, the examples would sometimes
induce unstable or even worse performance. Furthermore, we find widely-used
BM25-based shot selection strategy significantly outperforms the basic random
selection or fixed selection only on generation problems. Third, for the
fine-tuning setting, we find that fine-tuning could further improve the model
performance on downstream code comprehension and generation tasks compared to
the zero-shot/one-shot performance. In addition, after being fine-tuned on the
same downstream task dataset, instructed LLMs outperform both the small SOTA
models and similar-scaled LLMs without instruction tuning. Based on our
findings, we further present practical implications on model and usage
recommendation, performance and cost trade-offs, and future direction.
</p></li>
</ul>

<h3>Title: XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models. (arXiv:2308.01263v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01263">http://arxiv.org/abs/2308.01263</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01263] XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models](http://arxiv.org/abs/2308.01263) #large language model</code></li>
<li>Summary: <p>Without proper safeguards, large language models will readily follow
malicious instructions and generate toxic content. This motivates safety
efforts such as red-teaming and large-scale feedback learning, which aim to
make models both helpful and harmless. However, there is a tension between
these two objectives, since harmlessness requires models to refuse complying
with unsafe prompts, and thus not be helpful. Recent anecdotal evidence
suggests that some models may have struck a poor balance, so that even clearly
safe prompts are refused if they use similar language to unsafe prompts or
mention sensitive topics. In this paper, we introduce a new test suite called
XSTest to identify such eXaggerated Safety behaviours in a structured and
systematic way. In its current form, XSTest comprises 200 safe prompts across
ten prompt types that well-calibrated models should not refuse to comply with.
We describe XSTest's creation and composition, and use the test suite to
highlight systematic failure modes in a recently-released state-of-the-art
language model.
</p></li>
</ul>

<h3>Title: Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01284">http://arxiv.org/abs/2308.01284</a></li>
<li>Code URL: <a href="https://github.com/amritabh/chatgpt-as-detector">https://github.com/amritabh/chatgpt-as-detector</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01284] Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?](http://arxiv.org/abs/2308.01284) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) such as ChatGPT are increasingly being used for
various use cases, including text content generation at scale. Although
detection methods for such AI-generated text exist already, we investigate
ChatGPT's performance as a detector on such AI-generated text, inspired by
works that use ChatGPT as a data labeler or annotator. We evaluate the
zero-shot performance of ChatGPT in the task of human-written vs. AI-generated
text detection, and perform experiments on publicly available datasets. We
empirically investigate if ChatGPT is symmetrically effective in detecting
AI-generated or human-written text. Our findings provide insight on how ChatGPT
and similar LLMs may be leveraged in automated detection pipelines by simply
focusing on solving a specific aspect of the problem and deriving the rest from
that solution. All code and data is available at
\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Detection and Segmentation of Cosmic Objects Based on Adaptive Thresholding and Back Propagation Neural Network. (arXiv:2308.00926v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00926">http://arxiv.org/abs/2308.00926</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00926] Detection and Segmentation of Cosmic Objects Based on Adaptive Thresholding and Back Propagation Neural Network](http://arxiv.org/abs/2308.00926) #segmentation</code></li>
<li>Summary: <p>Astronomical images provide information about the great variety of cosmic
objects in the Universe. Due to the large volumes of data, the presence of
innumerable bright point sources as well as noise within the frame and the
spatial gap between objects and satellite cameras, it is a challenging task to
classify and detect the celestial objects. We propose an Adaptive Thresholding
Method (ATM) based segmentation and Back Propagation Neural Network (BPNN)
based cosmic object detection including a well-structured series of
pre-processing steps designed to enhance segmentation and detection.
</p></li>
</ul>

<h3>Title: Training-Free Instance Segmentation from Semantic Image Segmentation Masks. (arXiv:2308.00949v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.00949">http://arxiv.org/abs/2308.00949</a></li>
<li>Code URL: <a href="https://github.com/ssyc123/tfiseg">https://github.com/ssyc123/tfiseg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2308.00949] Training-Free Instance Segmentation from Semantic Image Segmentation Masks](http://arxiv.org/abs/2308.00949) #segmentation</code></li>
<li>Summary: <p>In recent years, the development of instance segmentation has garnered
significant attention in a wide range of applications. However, the training of
a fully-supervised instance segmentation model requires costly both
instance-level and pixel-level annotations. In contrast, weakly-supervised
instance segmentation methods (i.e., with image-level class labels or point
labels) struggle to satisfy the accuracy and recall requirements of practical
scenarios. In this paper, we propose a novel paradigm for instance segmentation
called training-free instance segmentation (TFISeg), which achieves instance
segmentation results from image masks predicted using off-the-shelf semantic
segmentation models. TFISeg does not require training a semantic or/and
instance segmentation model and avoids the need for instance-level image
annotations. Therefore, it is highly efficient. Specifically, we first obtain a
semantic segmentation mask of the input image via a trained semantic
segmentation model. Then, we calculate a displacement field vector for each
pixel based on the segmentation mask, which can indicate representations
belonging to the same class but different instances, i.e., obtaining the
instance-level object information. Finally, instance segmentation results are
obtained after being refined by a learnable category-agnostic object boundary
branch. Extensive experimental results on two challenging datasets and
representative semantic segmentation baselines (including CNNs and
Transformers) demonstrate that TFISeg can achieve competitive results compared
to the state-of-the-art fully-supervised instance segmentation methods without
the need for additional human resources or increased computational costs. The
code is available at: TFISeg
</p></li>
</ul>

<h3>Title: Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation. (arXiv:2308.01189v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01189">http://arxiv.org/abs/2308.01189</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01189] Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation](http://arxiv.org/abs/2308.01189) #segmentation</code></li>
<li>Summary: <p>This paper seeks to address the dense labeling problems where a significant
fraction of the dataset can be pruned without sacrificing much accuracy. We
observe that, on standard medical image segmentation benchmarks, the loss
gradient norm-based metrics of individual training examples applied in image
classification fail to identify the important samples. To address this issue,
we propose a data pruning method by taking into consideration the training
dynamics on target regions using Dynamic Average Dice (DAD) score. To the best
of our knowledge, we are among the first to address the data importance in
dense labeling tasks in the field of medical image analysis, making the
following contributions: (1) investigating the underlying causes with rigorous
empirical analysis, and (2) determining effective data pruning approach in
dense labeling problems. Our solution can be used as a strong yet simple
baseline to select important examples for medical image segmentation with
combined data sources.
</p></li>
</ul>

<h3>Title: A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data. (arXiv:2308.01251v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.01251">http://arxiv.org/abs/2308.01251</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.01251] A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data](http://arxiv.org/abs/2308.01251) #segmentation</code></li>
<li>Summary: <p>As a harzard disaster, landslide often brings tremendous losses to humanity,
so it's necessary to achieve reliable detection of landslide. However, the
problems of visual blur and small-sized dataset cause great challenges for old
landslide detection task when using remote sensing data. To reliably extract
semantic features, a hyper-pixel-wise contrastive learning augmented
segmentation network (HPCL-Net) is proposed, which augments the local salient
feature extraction from the boundaries of landslides through HPCL and fuses the
heterogeneous infromation in the semantic space from High-Resolution Remote
Sensing Images and Digital Elevation Model Data data. For full utilization of
the precious samples, a global hyper-pixel-wise sample pair queues-based
contrastive learning method, which includes the construction of global queues
that store hyper-pixel-wise samples and the updating scheme of a momentum
encoder, is developed, reliably enhancing the extraction ability of semantic
features. The proposed HPCL-Net is evaluated on a Loess Plateau old landslide
dataset and experiment results show that the model greatly improves the
reliablity of old landslide detection compared to the previous old landslide
segmentation model, where mIoU metric is increased from 0.620 to 0.651,
Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric is
increased from 0.501 to 0.565.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
