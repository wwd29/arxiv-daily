<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Hardware Trojan Threats to Cache Coherence in Modern 2.5D Chiplet Systems. (arXiv:2210.00058v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00058">http://arxiv.org/abs/2210.00058</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00058] Hardware Trojan Threats to Cache Coherence in Modern 2](http://arxiv.org/abs/2210.00058)</code></li>
<li>Summary: <p>As industry moves toward chiplet-based designs, the insertion of hardware
Trojans poses a significant threat to the security of these systems. These
systems rely heavily on cache coherence for coherent data communication, making
coherence an attractive target. Critically, unlike prior work, which focuses
only on malicious packet modifications, a Trojan attack that exploits coherence
can modify data in memory that was never touched and is not owned by the
chiplet which contains the Trojan. Further, the Trojan need not even be
physically between the victim and the memory controller to attack the victim's
memory transactions. Here, we explore the fundamental attack vectors possible
in chiplet-based systems and provide an example Trojan implementation capable
of directly modifying victim data in memory. This work aims to highlight the
need for developing mechanisms that can protect and secure the coherence scheme
from these forms of attacks.
</p></li>
</ul>

<h3>Title: Technical Report-IoT Devices Proximity Authentication In Ad Hoc Network Environment. (arXiv:2210.00175v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00175">http://arxiv.org/abs/2210.00175</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00175] Technical Report-IoT Devices Proximity Authentication In Ad Hoc Network Environment](http://arxiv.org/abs/2210.00175)</code></li>
<li>Summary: <p>Internet of Things (IoT) is a distributed communication technology system
that offers the possibility for physical devices (e.g. vehicles home appliances
sensors actuators etc.) known as Things to connect and exchange data more
importantly without human interaction. Since IoT plays a significant role in
our daily lives we must secure the IoT environment to work effectively. Among
the various security requirements authentication to the IoT devices is
essential as it is the first step in preventing any negative impact of possible
attackers. Using the current IEEE 802.11 infrastructure this paper implements
an IoT devices authentication scheme based on something that is in the IoT
devices environment (i.e. ambient access points). Data from the broadcast
messages (i.e. beacon frame characteristics) are utilized to implement the
authentication factor that confirms proximity between two devices in an ad hoc
IoT network.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Evaluation of Pre-Trained CNN Models for Geographic Fake Image Detection. (arXiv:2210.00361v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00361">http://arxiv.org/abs/2210.00361</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00361] Evaluation of Pre-Trained CNN Models for Geographic Fake Image Detection](http://arxiv.org/abs/2210.00361)</code></li>
<li>Summary: <p>Thanks to the remarkable advances in generative adversarial networks (GANs),
it is becoming increasingly easy to generate/manipulate images. The existing
works have mainly focused on deepfake in face images and videos. However, we
are currently witnessing the emergence of fake satellite images, which can be
misleading or even threatening to national security. Consequently, there is an
urgent need to develop detection methods capable of distinguishing between real
and fake satellite images. To advance the field, in this paper, we explore the
suitability of several convolutional neural network (CNN) architectures for
fake satellite image detection. Specifically, we benchmark four CNN models by
conducting extensive experiments to evaluate their performance and robustness
against various image distortions. This work allows the establishment of new
baselines and may be useful for the development of CNN-based methods for fake
satellite image detection.
</p></li>
</ul>

<h3>Title: ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks. (arXiv:2210.00108v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00108">http://arxiv.org/abs/2210.00108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00108] ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks](http://arxiv.org/abs/2210.00108)</code></li>
<li>Summary: <p>Early backdoor attacks against machine learning set off an arms race in
attack and defence development. Defences have since appeared demonstrating some
ability to detect backdoors in models or even remove them. These defences work
by inspecting the training data, the model, or the integrity of the training
procedure. In this work, we show that backdoors can be added during
compilation, circumventing any safeguards in the data preparation and model
training stages. As an illustration, the attacker can insert weight-based
backdoors during the hardware compilation step that will not be detected by any
training or data-preparation process. Next, we demonstrate that some backdoors,
such as ImpNet, can only be reliably detected at the stage where they are
inserted and removing them anywhere else presents a significant challenge. We
conclude that machine-learning model security requires assurance of provenance
along the entire technical pipeline, including the data, model architecture,
compiler, and hardware specification.
</p></li>
</ul>

<h3>Title: zkBridge: Trustless Cross-chain Bridges Made Practical. (arXiv:2210.00264v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00264">http://arxiv.org/abs/2210.00264</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00264] zkBridge: Trustless Cross-chain Bridges Made Practical](http://arxiv.org/abs/2210.00264)</code></li>
<li>Summary: <p>Blockchains have seen growing traction with cryptocurrencies reaching a
market cap of over 1 trillion dollars, major institution investors taking
interests, and global impacts on governments, businesses, and individuals. Also
growing significantly is the heterogeneity of the ecosystem where a variety of
blockchains co-exist. Cross-chain bridge is a necessary building block in this
multi-chain ecosystem. Existing solutions, however, either suffer from
performance issues or rely on trust assumptions of committees that
significantly lower the security. Recurring attacks against bridges have cost
users more than 1.5 billion USD. In this paper, we introduce zkBridge, an
efficient cross-chain bridge that guarantees strong security without external
trust assumptions. With succinct proofs, zkBridge not only guarantees
correctness, but also significantly reduces on-chain verification cost. We
propose novel succinct proof protocols that are orders-of-magnitude faster than
existing solutions for workload in zkBridge. With a modular design, zkBridge
enables a broad spectrum of use cases and capabilities, including message
passing, token transferring, and other computational logic operating on state
changes from different chains. To demonstrate the practicality of zkBridge, we
implemented a prototype bridge from Cosmos to Ethereum, a particularly
challenging direction that involves large proof circuits that existing systems
cannot efficiently handle. Our evaluation shows that zkBridge achieves
practical performance: proof generation takes less than 20 seconds, while
verifying proofs on-chain costs less than 230K gas. For completeness, we also
implemented and evaluated the direction from Ethereum to other EVM-compatible
chains (such as BSC) which involves smaller circuits and incurs much less
overhead.
</p></li>
</ul>

<h3>Title: Artificial Replay: A Meta-Algorithm for Harnessing Historical Data in Bandits. (arXiv:2210.00025v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00025">http://arxiv.org/abs/2210.00025</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00025] Artificial Replay: A Meta-Algorithm for Harnessing Historical Data in Bandits](http://arxiv.org/abs/2210.00025)</code></li>
<li>Summary: <p>While standard bandit algorithms sometimes incur high regret, their
performance can be greatly improved by "warm starting" with historical data.
Unfortunately, how best to incorporate historical data is unclear: naively
initializing reward estimates using all historical samples can suffer from
spurious data and imbalanced data coverage, leading to computational and
storage issues - particularly in continuous action spaces. We address these two
challenges by proposing Artificial Replay, a meta-algorithm for incorporating
historical data into any arbitrary base bandit algorithm. Artificial Replay
uses only a subset of the historical data as needed to reduce computation and
storage. We show that for a broad class of base algorithms that satisfy
independence of irrelevant data (IIData), a novel property that we introduce,
our method achieves equal regret as a full warm-start approach while
potentially using only a fraction of the historical data. We complement these
theoretical results with a case study of $K$-armed and continuous combinatorial
bandit algorithms, including on a green security domain using real poaching
data, to show the practical benefits of Artificial Replay in achieving optimal
regret alongside low computational and storage costs.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Differentially Private Bias-Term only Fine-tuning of Foundation Models. (arXiv:2210.00036v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00036">http://arxiv.org/abs/2210.00036</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00036] Differentially Private Bias-Term only Fine-tuning of Foundation Models](http://arxiv.org/abs/2210.00036)</code></li>
<li>Summary: <p>We study the problem of differentially private (DP) fine-tuning of large
pre-trained models -- a recent privacy-preserving approach suitable for solving
downstream tasks with sensitive data. Existing work has demonstrated that high
accuracy is possible under strong privacy constraint, yet requires significant
computational overhead or modifications to the network architecture.
</p></li>
</ul>

<p>We propose differentially private bias-term fine-tuning (DP-BiTFiT), which
matches the state-of-the-art accuracy for DP algorithms and the efficiency of
the standard BiTFiT. DP-BiTFiT is model agnostic (not modifying the network
architecture), parameter efficient (only training about $0.1\%$ of the
parameters), and computation efficient (almost removing the overhead caused by
DP, in both the time and space complexity). On a wide range of tasks, DP-BiTFiT
is $2\sim 30\times$ faster and uses $2\sim 8\times$ less memory than DP full
fine-tuning, even faster than the standard full fine-tuning. This amazing
efficiency enables us to conduct DP fine-tuning on language and vision tasks
with long-sequence texts and high-resolution images, which were computationally
difficult using existing methods.
</p>

<h3>Title: Differentially Private Optimization on Large Model at Small Cost. (arXiv:2210.00038v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00038">http://arxiv.org/abs/2210.00038</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00038] Differentially Private Optimization on Large Model at Small Cost](http://arxiv.org/abs/2210.00038)</code></li>
<li>Summary: <p>Differentially private (DP) optimization is the standard paradigm to learn
large neural networks that are accurate and privacy-preserving. The
computational cost for DP deep learning, however, is notoriously heavy due to
the per-sample gradient clipping. Existing DP implementations are
$2-1000\times$ more costly in time and space complexity than the standard
(non-private) training. In this work, we develop a novel Book-Keeping (BK)
technique that implements existing DP optimizers (thus achieving the same
accuracy), with a substantial improvement on the computational cost.
Specifically, BK enables DP training on large models and high dimensional data
to be roughly as efficient as the standard training, whereas previous DP
algorithms can be inefficient or incapable of training due to memory error. The
computational advantage of BK is supported by the complexity analysis as well
as extensive experiments on vision and language tasks. Our implementation
achieves state-of-the-art (SOTA) accuracy with very small extra cost: on GPT2
and at the same memory cost, BK has 1.0$\times$ the time complexity of the
standard training (0.75$\times$ training speed in practice), and 0.6$\times$
the time complexity of the most efficient DP implementation (1.24$\times$
training speed in practice). We will open-source the codebase for the BK
algorithm.
</p></li>
</ul>

<h3>Title: Kernel Normalized Convolutional Networks for Privacy-Preserving Machine Learning. (arXiv:2210.00053v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00053">http://arxiv.org/abs/2210.00053</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00053] Kernel Normalized Convolutional Networks for Privacy-Preserving Machine Learning](http://arxiv.org/abs/2210.00053)</code></li>
<li>Summary: <p>Normalization is an important but understudied challenge in privacy-related
application domains such as federated learning (FL) and differential privacy
(DP). While the unsuitability of batch normalization for FL and DP has already
been shown, the impact of the other normalization methods on the performance of
federated or differentially private models is not well-known. To address this,
we draw a performance comparison among layer normalization (LayerNorm), group
normalization (GroupNorm), and the recently proposed kernel normalization
(KernelNorm) in FL and DP settings. Our results indicate LayerNorm and
GroupNorm provide no performance gain compared to the baseline (i.e. no
normalization) for shallow models, but they considerably enhance performance of
deeper models. KernelNorm, on the other hand, significantly outperforms its
competitors in terms of accuracy and convergence rate (or communication
efficiency) for both shallow and deeper models. Given these key observations,
we propose a kernel normalized ResNet architecture called KNResNet-13 for
differentially private learning environments. Using the proposed architecture,
we provide new state-of-the-art accuracy values on the CIFAR-10 and Imagenette
datasets.
</p></li>
</ul>

<h3>Title: Frequency Estimation of Evolving Data Under Local Differential Privacy. (arXiv:2210.00262v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00262">http://arxiv.org/abs/2210.00262</a></li>
<li>Code URL: <a href="https://github.com/hharcolezi/LOLOHA">https://github.com/hharcolezi/LOLOHA</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00262] Frequency Estimation of Evolving Data Under Local Differential Privacy](http://arxiv.org/abs/2210.00262)</code></li>
<li>Summary: <p>Collecting and analyzing evolving longitudinal data has become a common
practice. One possible approach to protect the users' privacy in this context
is to use local differential privacy (LDP) protocols, which ensure the privacy
protection of all users even in the case of a breach or data misuse. Existing
LDP data collection protocols such as Google's RAPPOR and Microsoft's
dBitFlipPM have longitudinal privacy linear to the domain size k, which can be
excessive for large domains, such as Internet domains. To solve this issue, in
this paper we introduce a new LDP data collection protocol for longitudinal
frequency monitoring named LOngitudinal LOcal HAshing (LOLOHA) with formal
privacy guarantees. In addition, the privacy-utility trade-off of our protocol
is only linear with respect to a reduced domain size 2<=g<<k. LOLOHA combines a
domain reduction approach via local hashing with double randomization to
minimize the privacy leakage incurred by data updates. As demonstrated by our
theoretical analysis as well as our experimental evaluation, LOLOHA achieves a
utility competitive to current state-of-the-art protocols, while substantially
minimizing the longitudinal privacy budget consumption by up to k/g orders of
magnitude.
</p></li>
</ul>

<h3>Title: Privacy-preserving Decentralized Federated Learning over Time-varying Communication Graph. (arXiv:2210.00325v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00325">http://arxiv.org/abs/2210.00325</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00325] Privacy-preserving Decentralized Federated Learning over Time-varying Communication Graph](http://arxiv.org/abs/2210.00325)</code></li>
<li>Summary: <p>Establishing how a set of learners can provide privacy-preserving federated
learning in a fully decentralized (peer-to-peer, no coordinator) manner is an
open problem. We propose the first privacy-preserving consensus-based algorithm
for the distributed learners to achieve decentralized global model aggregation
in an environment of high mobility, where the communication graph between the
learners may vary between successive rounds of model aggregation. In
particular, in each round of global model aggregation, the Metropolis-Hastings
method is applied to update the weighted adjacency matrix based on the current
communication topology. In addition, the Shamir's secret sharing scheme is
integrated to facilitate privacy in reaching consensus of the global model. The
paper establishes the correctness and privacy properties of the proposed
algorithm. The computational efficiency is evaluated by a simulation built on a
federated learning framework with a real-word dataset.
</p></li>
</ul>

<h3>Title: Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation. (arXiv:2210.00538v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00538">http://arxiv.org/abs/2210.00538</a></li>
<li>Code URL: <a href="https://github.com/aixwinnie/hetedp">https://github.com/aixwinnie/hetedp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00538] Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation](http://arxiv.org/abs/2210.00538)</code></li>
<li>Summary: <p>Social networks are considered to be heterogeneous graph neural networks
(HGNNs) with deep learning technological advances. HGNNs, compared to
homogeneous data, absorb various aspects of information about individuals in
the training stage. That means more information has been covered in the
learning result, especially sensitive information. However, the
privacy-preserving methods on homogeneous graphs only preserve the same type of
node attributes or relationships, which cannot effectively work on
heterogeneous graphs due to the complexity. To address this issue, we propose a
novel heterogeneous graph neural network privacy-preserving method based on a
differential privacy mechanism named HeteDP, which provides a double guarantee
on graph features and topology. In particular, we first define a new attack
scheme to reveal privacy leakage in the heterogeneous graphs. Specifically, we
design a two-stage pipeline framework, which includes the privacy-preserving
feature encoder and the heterogeneous link reconstructor with gradients
perturbation based on differential privacy to tolerate data diversity and
against the attack. To better control the noise and promote model performance,
we utilize a bi-level optimization pattern to allocate a suitable privacy
budget for the above two modules. Our experiments on four public benchmarks
show that the HeteDP method is equipped to resist heterogeneous graph privacy
leakage with admirable model generalization.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Assessing the impact of contextual information in hate speech detection. (arXiv:2210.00465v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00465">http://arxiv.org/abs/2210.00465</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00465] Assessing the impact of contextual information in hate speech detection](http://arxiv.org/abs/2210.00465)</code></li>
<li>Summary: <p>In recent years, hate speech has gained great relevance in social networks
and other virtual media because of its intensity and its relationship with
violent acts against members of protected groups. Due to the great amount of
content generated by users, great effort has been made in the research and
development of automatic tools to aid the analysis and moderation of this
speech, at least in its most threatening forms. One of the limitations of
current approaches to automatic hate speech detection is the lack of context.
Most studies and resources are performed on data without context; that is,
isolated messages without any type of conversational context or the topic being
discussed. This restricts the available information to define if a post on a
social network is hateful or not. In this work, we provide a novel corpus for
contextualized hate speech detection based on user responses to news posts from
media outlets on Twitter. This corpus was collected in the Rioplatense
dialectal variety of Spanish and focuses on hate speech associated with the
COVID-19 pandemic. Classification experiments using state-of-the-art techniques
show evidence that adding contextual information improves hate speech detection
performance for two proposed tasks (binary and multi-label prediction). We make
our code, models, and corpus available for further research.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Adversarial Attacks on Transformers-Based Malware Detectors. (arXiv:2210.00008v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00008">http://arxiv.org/abs/2210.00008</a></li>
<li>Code URL: <a href="https://github.com/yashjakhotiya/adversarial-attacks-on-transformers">https://github.com/yashjakhotiya/adversarial-attacks-on-transformers</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00008] Adversarial Attacks on Transformers-Based Malware Detectors](http://arxiv.org/abs/2210.00008)</code></li>
<li>Summary: <p>Signature-based malware detectors have proven to be insufficient as even a
small change in malignant executable code can bypass these signature-based
detectors. Many machine learning-based models have been proposed to efficiently
detect a wide variety of malware. Many of these models are found to be
susceptible to adversarial attacks - attacks that work by generating
intentionally designed inputs that can force these models to misclassify. Our
work aims to explore vulnerabilities in the current state of the art malware
detectors to adversarial attacks. We train a Transformers-based malware
detector, carry out adversarial attacks resulting in a misclassification rate
of 23.9% and propose defenses that reduce this misclassification rate to half.
An implementation of our work can be found at
https://github.com/yashjakhotiya/Adversarial-Attacks-On-Transformers.
</p></li>
</ul>

<h3>Title: DeltaBound Attack: Efficient decision-based attack in low queries regime. (arXiv:2210.00292v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00292">http://arxiv.org/abs/2210.00292</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00292] DeltaBound Attack: Efficient decision-based attack in low queries regime](http://arxiv.org/abs/2210.00292)</code></li>
<li>Summary: <p>Deep neural networks and other machine learning systems, despite being
extremely powerful and able to make predictions with high accuracy, are
vulnerable to adversarial attacks. We proposed the DeltaBound attack: a novel,
powerful attack in the hard-label setting with $\ell_2$ norm bounded
perturbations. In this scenario, the attacker has only access to the top-1
predicted label of the model and can be therefore applied to real-world
settings such as remote API. This is a complex problem since the attacker has
very little information about the model. Consequently, most of the other
techniques present in the literature require a massive amount of queries for
attacking a single example. Oppositely, this work mainly focuses on the
evaluation of attack's power in the low queries regime $\leq 1000$ queries)
with $\ell_2$ norm in the hard-label settings. We find that the DeltaBound
attack performs as well and sometimes better than current state-of-the-art
attacks while remaining competitive across different kinds of models. Moreover,
we evaluate our method against not only deep neural networks, but also non-deep
learning models, such as Gradient Boosting Decision Trees and Multinomial Naive
Bayes.
</p></li>
</ul>

<h3>Title: Adaptive Smoothness-weighted Adversarial Training for Multiple Perturbations with Its Stability Analysis. (arXiv:2210.00557v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00557">http://arxiv.org/abs/2210.00557</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00557] Adaptive Smoothness-weighted Adversarial Training for Multiple Perturbations with Its Stability Analysis](http://arxiv.org/abs/2210.00557)</code></li>
<li>Summary: <p>Adversarial Training (AT) has been demonstrated as one of the most effective
methods against adversarial examples. While most existing works focus on AT
with a single type of perturbation e.g., the $\ell_\infty$ attacks), DNNs are
facing threats from different types of adversarial examples. Therefore,
adversarial training for multiple perturbations (ATMP) is proposed to
generalize the adversarial robustness over different perturbation types (in
$\ell_1$, $\ell_2$, and $\ell_\infty$ norm-bounded perturbations). However, the
resulting model exhibits trade-off between different attacks. Meanwhile, there
is no theoretical analysis of ATMP, limiting its further development. In this
paper, we first provide the smoothness analysis of ATMP and show that $\ell_1$,
$\ell_2$, and $\ell_\infty$ adversaries give different contributions to the
smoothness of the loss function of ATMP. Based on this, we develop the
stability-based excess risk bounds and propose adaptive smoothness-weighted
adversarial training for multiple perturbations. Theoretically, our algorithm
yields better bounds. Empirically, our experiments on CIFAR10 and CIFAR100
achieve the state-of-the-art performance against the mixture of multiple
perturbations attacks.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Adaptive Weight Decay: On The Fly Weight Decay Tuning for Improving Robustness. (arXiv:2210.00094v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00094">http://arxiv.org/abs/2210.00094</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00094] Adaptive Weight Decay: On The Fly Weight Decay Tuning for Improving Robustness](http://arxiv.org/abs/2210.00094)</code></li>
<li>Summary: <p>We introduce adaptive weight decay, which automatically tunes the
hyper-parameter for weight decay during each training iteration. For
classification problems, we propose changing the value of the weight decay
hyper-parameter on the fly based on the strength of updates from the
classification loss (i.e., gradient of cross-entropy), and the regularization
loss (i.e., $\ell_2$-norm of the weights). We show that this simple
modification can result in large improvements in adversarial robustness -- an
area which suffers from robust overfitting -- without requiring extra data.
Specifically, our reformulation results in 20% relative robustness improvement
for CIFAR-100, and 10% relative robustness improvement on CIFAR-10 comparing to
traditional weight decay. In addition, this method has other desirable
properties, such as less sensitivity to learning rate, and smaller weight
norms, which the latter contributes to robustness to overfitting to label
noise, and pruning.
</p></li>
</ul>

<h3>Title: Robust Person Identification: A WiFi Vision-based Approach. (arXiv:2210.00127v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00127">http://arxiv.org/abs/2210.00127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00127] Robust Person Identification: A WiFi Vision-based Approach](http://arxiv.org/abs/2210.00127)</code></li>
<li>Summary: <p>Person re-identification (Re-ID) has become increasingly important as it
supports a wide range of security applications. Traditional person Re-ID mainly
relies on optical camera-based systems, which incur several limitations due to
the changes in the appearance of people, occlusions, and human poses. In this
work, we propose a WiFi vision-based system, 3D-ID, for person Re-ID in 3D
space. Our system leverages the advances of WiFi and deep learning to help WiFi
devices see, identify, and recognize people. In particular, we leverage
multiple antennas on next-generation WiFi devices and 2D AoA estimation of the
signal reflections to enable WiFi to visualize a person in the physical
environment. We then leverage deep learning to digitize the visualization of
the person into 3D body representation and extract both the static body shape
and dynamic walking patterns for person Re-ID. Our evaluation results under
various indoor environments show that the 3D-ID system achieves an overall
rank-1 accuracy of 85.3%. Results also show that our system is resistant to
various attacks. The proposed 3D-ID is thus very promising as it could augment
or complement camera-based systems.
</p></li>
</ul>

<h3>Title: DARE: A large-scale handwritten date recognition system. (arXiv:2210.00503v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00503">http://arxiv.org/abs/2210.00503</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00503] DARE: A large-scale handwritten date recognition system](http://arxiv.org/abs/2210.00503)</code></li>
<li>Summary: <p>Handwritten text recognition for historical documents is an important task
but it remains difficult due to a lack of sufficient training data in
combination with a large variability of writing styles and degradation of
historical documents. While recurrent neural network architectures are commonly
used for handwritten text recognition, they are often computationally expensive
to train and the benefit of recurrence drastically differs by task. For these
reasons, it is important to consider non-recurrent architectures. In the
context of handwritten date recognition, we propose an architecture based on
the EfficientNetV2 class of models that is fast to train, robust to parameter
choices, and accurately transcribes handwritten dates from a number of sources.
For training, we introduce a database containing almost 10 million tokens,
originating from more than 2.2 million handwritten dates which are segmented
from different historical documents. As dates are some of the most common
information on historical documents, and with historical archives containing
millions of such documents, the efficient and automatic transcription of dates
has the potential to lead to significant cost-savings over manual
transcription. We show that training on handwritten text with high variability
in writing styles result in robust models for general handwritten text
recognition and that transfer learning from the DARE system increases
transcription accuracy substantially, allowing one to obtain high accuracy even
when using a relatively small training sample.
</p></li>
</ul>

<h3>Title: Fast and Robust Video-Based Exercise Classification via Body Pose Tracking and Scalable Multivariate Time Series Classifiers. (arXiv:2210.00507v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00507">http://arxiv.org/abs/2210.00507</a></li>
<li>Code URL: <a href="https://github.com/mlgig/bodymts_2021">https://github.com/mlgig/bodymts_2021</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00507] Fast and Robust Video-Based Exercise Classification via Body Pose Tracking and Scalable Multivariate Time Series Classifiers](http://arxiv.org/abs/2210.00507)</code></li>
<li>Summary: <p>Technological advancements have spurred the usage of machine learning based
applications in sports science. Physiotherapists, sports coaches and athletes
actively look to incorporate the latest technologies in order to further
improve performance and avoid injuries. While wearable sensors are very
popular, their use is hindered by constraints on battery power and sensor
calibration, especially for use cases which require multiple sensors to be
placed on the body. Hence, there is renewed interest in video-based data
capture and analysis for sports science. In this paper, we present the
application of classifying S\&amp;C exercises using video. We focus on the popular
Military Press exercise, where the execution is captured with a video-camera
using a mobile device, such as a mobile phone, and the goal is to classify the
execution into different types. Since video recordings need a lot of storage
and computation, this use case requires data reduction, while preserving the
classification accuracy and enabling fast prediction. To this end, we propose
an approach named BodyMTS to turn video into time series by employing body pose
tracking, followed by training and prediction using multivariate time series
classifiers. We analyze the accuracy and robustness of BodyMTS and show that it
is robust to different types of noise caused by either video quality or pose
estimation factors. We compare BodyMTS to state-of-the-art deep learning
methods which classify human activity directly from videos and show that
BodyMTS achieves similar accuracy, but with reduced running time and model
engineering effort. Finally, we discuss some of the practical aspects of
employing BodyMTS in this application in terms of accuracy and robustness under
reduced data quality and size. We show that BodyMTS achieves an average
accuracy of 87\%, which is significantly higher than the accuracy of human
domain experts.
</p></li>
</ul>

<h3>Title: Institutional Foundations of Adaptive Planning: Exploration of Flood Planning in the Lower Rio Grande Valley, Texas, USA. (arXiv:2210.00113v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00113">http://arxiv.org/abs/2210.00113</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00113] Institutional Foundations of Adaptive Planning: Exploration of Flood Planning in the Lower Rio Grande Valley, Texas, USA](http://arxiv.org/abs/2210.00113)</code></li>
<li>Summary: <p>Adaptive planning is ideally suited for the deep uncertainties presented by
climate change. While there is a robust scholarship on the theory and methods
of adaptive planning, this has largely neglected how adaptive planning is
affected by existing planning institutions and how to move forward within the
constraints of traditional planning organizations. This study asks: How do
existing traditional planning institutions support adaptive planning? We
explore this for flood planning in the Lower Rio Grande Valley of Texas, United
States. We draw on county hazard plan and regional flood plan documents as well
as transcripts of regional flood planning meetings to explore the emergent
topics of these institutional outputs. Using Natural Language Processing to
analyze this large amount of text, we find that hazard plans and discussions
developing these plans are largely lacking an adaptive approach.
</p></li>
</ul>

<h3>Title: Adversarial Robustness of Representation Learning for Knowledge Graphs. (arXiv:2210.00122v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00122">http://arxiv.org/abs/2210.00122</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00122] Adversarial Robustness of Representation Learning for Knowledge Graphs](http://arxiv.org/abs/2210.00122)</code></li>
<li>Summary: <p>Knowledge graphs represent factual knowledge about the world as relationships
between concepts and are critical for intelligent decision making in enterprise
applications. New knowledge is inferred from the existing facts in the
knowledge graphs by encoding the concepts and relations into low-dimensional
feature vector representations. The most effective representations for this
task, called Knowledge Graph Embeddings (KGE), are learned through neural
network architectures. Due to their impressive predictive performance, they are
increasingly used in high-impact domains like healthcare, finance and
education. However, are the black-box KGE models adversarially robust for use
in domains with high stakes? This thesis argues that state-of-the-art KGE
models are vulnerable to data poisoning attacks, that is, their predictive
performance can be degraded by systematically crafted perturbations to the
training knowledge graph. To support this argument, two novel data poisoning
attacks are proposed that craft input deletions or additions at training time
to subvert the learned model's performance at inference time. These adversarial
attacks target the task of predicting the missing facts in knowledge graphs
using KGE models, and the evaluation shows that the simpler attacks are
competitive with or outperform the computationally expensive ones. The thesis
contributions not only highlight and provide an opportunity to fix the security
vulnerabilities of KGE models, but also help to understand the black-box
predictive behaviour of KGE models.
</p></li>
</ul>

<h3>Title: Understanding Adversarial Robustness Against On-manifold Adversarial Examples. (arXiv:2210.00430v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00430">http://arxiv.org/abs/2210.00430</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00430] Understanding Adversarial Robustness Against On-manifold Adversarial Examples](http://arxiv.org/abs/2210.00430)</code></li>
<li>Summary: <p>Deep neural networks (DNNs) are shown to be vulnerable to adversarial
examples. A well-trained model can be easily attacked by adding small
perturbations to the original data. One of the hypotheses of the existence of
the adversarial examples is the off-manifold assumption: adversarial examples
lie off the data manifold. However, recent research showed that on-manifold
adversarial examples also exist. In this paper, we revisit the off-manifold
assumption and want to study a question: at what level is the poor performance
of neural networks against adversarial attacks due to on-manifold adversarial
examples? Since the true data manifold is unknown in practice, we consider two
approximated on-manifold adversarial examples on both real and synthesis
datasets. On real datasets, we show that on-manifold adversarial examples have
greater attack rates than off-manifold adversarial examples on both
standard-trained and adversarially-trained models. On synthetic datasets,
theoretically, We prove that on-manifold adversarial examples are powerful, yet
adversarial training focuses on off-manifold directions and ignores the
on-manifold adversarial examples. Furthermore, we provide analysis to show that
the properties derived theoretically can also be observed in practice. Our
analysis suggests that on-manifold adversarial examples are important, and we
should pay more attention to on-manifold adversarial examples for training
robust models.
</p></li>
</ul>

<h3>Title: pMPL: A Robust Multi-Party Learning Framework with a Privileged Party. (arXiv:2210.00486v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00486">http://arxiv.org/abs/2210.00486</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00486] pMPL: A Robust Multi-Party Learning Framework with a Privileged Party](http://arxiv.org/abs/2210.00486)</code></li>
<li>Summary: <p>In order to perform machine learning among multiple parties while protecting
the privacy of raw data, privacy-preserving machine learning based on secure
multi-party computation (MPL for short) has been a hot spot in recent. The
configuration of MPL usually follows the peer-to-peer architecture, where each
party has the same chance to reveal the output result. However, typical
business scenarios often follow a hierarchical architecture where a powerful,
usually \textit{privileged party}, leads the tasks of machine learning. Only
the \textit{privileged party} can reveal the final model even if other
\textit{assistant parties} collude with each other. It is even required to
avoid the abort of machine learning to ensure the scheduled deadlines and/or
save used computing resources when part of \textit{assistant parties} drop out.
</p></li>
</ul>

<p>Motivated by the above scenarios, we propose \pmpl, a robust MPL framework
with a \textit{privileged party}. \pmpl supports three-party training in the
semi-honest setting. By setting alternate shares for the \textit{privileged
party}, \pmpl is robust to tolerate one of the rest two parties dropping out
during the training. With the above settings, we design a series of efficient
protocols based on vector space secret sharing for \pmpl to bridge the gap
between vector space secret sharing and machine learning. Finally, the
experimental results show that the performance of \pmpl is promising when we
compare it with the state-of-the-art MPL frameworks. Especially, in the LAN
setting, \pmpl is around $16\times$ and $5\times$ faster than
\texttt{TF-encrypted} (with \texttt{ABY3} as the back-end framework) for the
linear regression, and logistic regression, respectively. Besides, the accuracy
of trained models of linear regression, logistic regression, and BP neural
networks can reach around 97\%, 99\%, and 96\% on MNIST dataset respectively.
</p>

<h3>Title: Learning Robust Kernel Ensembles with Kernel Average Pooling. (arXiv:2210.00062v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00062">http://arxiv.org/abs/2210.00062</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00062] Learning Robust Kernel Ensembles with Kernel Average Pooling](http://arxiv.org/abs/2210.00062)</code></li>
<li>Summary: <p>Model ensembles have long been used in machine learning to reduce the
variance in individual model predictions, making them more robust to input
perturbations. Pseudo-ensemble methods like dropout have also been commonly
used in deep learning models to improve generalization. However, the
application of these techniques to improve neural networks' robustness against
input perturbations remains underexplored. We introduce Kernel Average Pool
(KAP), a new neural network building block that applies the mean filter along
the kernel dimension of the layer activation tensor. We show that ensembles of
kernels with similar functionality naturally emerge in convolutional neural
networks equipped with KAP and trained with backpropagation. Moreover, we show
that when combined with activation noise, KAP models are remarkably robust
against various forms of adversarial attacks. Empirical evaluations on CIFAR10,
CIFAR100, TinyImagenet, and Imagenet datasets show substantial improvements in
robustness against strong adversarial attacks such as AutoAttack that are on
par with adversarially trained networks but are importantly obtained without
training on any adversarial examples.
</p></li>
</ul>

<h3>Title: Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00116">http://arxiv.org/abs/2210.00116</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00116] Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information](http://arxiv.org/abs/2210.00116)</code></li>
<li>Summary: <p>Predicting the responses of a cell under perturbations may bring important
benefits to drug discovery and personalized therapeutics. In this work, we
propose a novel graph variational Bayesian causal inference framework to
predict a cell's gene expressions under counterfactual perturbations
(perturbations that this cell did not factually receive), leveraging
information representing biological knowledge in the form of gene regulatory
networks (GRNs) to aid individualized cellular response predictions. Aiming at
a data-adaptive GRN, we also developed an adjacency matrix updating technique
for graph convolutional networks and used it to refine GRNs during
pre-training, which generated more insights on gene relations and enhanced
model performance. Additionally, we propose a robust estimator within our
framework for the asymptotically efficient estimation of marginal perturbation
effect, which is yet to be carried out in previous works. With extensive
experiments, we exhibited the advantage of our approach over state-of-the-art
deep learning models for individual response prediction.
</p></li>
</ul>

<h3>Title: Robust Bayesian optimization with reinforcement learned acquisition functions. (arXiv:2210.00476v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00476">http://arxiv.org/abs/2210.00476</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00476] Robust Bayesian optimization with reinforcement learned acquisition functions](http://arxiv.org/abs/2210.00476)</code></li>
<li>Summary: <p>In Bayesian optimization (BO) for expensive black-box optimization tasks,
acquisition function (AF) guides sequential sampling and plays a pivotal role
for efficient convergence to better optima. Prevailing AFs usually rely on
artificial experiences in terms of preferences for exploration or exploitation,
which runs a risk of a computational waste or traps in local optima and
resultant re-optimization. To address the crux, the idea of data-driven AF
selection is proposed, and the sequential AF selection task is further
formalized as a Markov decision process (MDP) and resort to powerful
reinforcement learning (RL) technologies. Appropriate selection policy for AFs
is learned from superior BO trajectories to balance between exploration and
exploitation in real time, which is called reinforcement-learning-assisted
Bayesian optimization (RLABO). Competitive and robust BO evaluations on five
benchmark problems demonstrate RL's recognition of the implicit AF selection
pattern and imply the proposal's potential practicality for intelligent AF
selection as well as efficient optimization in expensive black-box problems.
</p></li>
</ul>

<h3>Title: Task Formulation Matters When Learning Continually: A Case Study in Visual Question Answering. (arXiv:2210.00044v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00044">http://arxiv.org/abs/2210.00044</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00044] Task Formulation Matters When Learning Continually: A Case Study in Visual Question Answering](http://arxiv.org/abs/2210.00044)</code></li>
<li>Summary: <p>Continual learning aims to train a model incrementally on a sequence of tasks
without forgetting previous knowledge. Although continual learning has been
widely studied in computer vision, its application to Vision+Language tasks is
not that straightforward, as settings can be parameterized in multiple ways
according to their input modalities. In this paper, we present a detailed study
of how different settings affect performance for Visual Question Answering. We
first propose three plausible task formulations and demonstrate their impact on
the performance of continual learning algorithms. We break down several factors
of task similarity, showing that performance and sensitivity to task order
highly depend on the shift of the output distribution. We also investigate the
potential of pretrained models and compare the robustness of transformer models
with different visual embeddings. Finally, we provide an analysis interpreting
model representations and their impact on forgetting. Our results highlight the
importance of stabilizing visual representations in deeper layers.
</p></li>
</ul>

<h3>Title: On the tightness of linear relaxation based robustness certification methods. (arXiv:2210.00178v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00178">http://arxiv.org/abs/2210.00178</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00178] On the tightness of linear relaxation based robustness certification methods](http://arxiv.org/abs/2210.00178)</code></li>
<li>Summary: <p>There has been a rapid development and interest in adversarial training and
defenses in the machine learning community in the recent years. One line of
research focuses on improving the performance and efficiency of adversarial
robustness certificates for neural networks \cite{gowal:19, wong_zico:18,
raghunathan:18, WengTowardsFC:18, wong:scalable:18, singh:convex_barrier:19,
Huang_etal:19, single-neuron-relax:20, Zhang2020TowardsSA}. While each
providing a certification to lower (or upper) bound the true distortion under
adversarial attacks via relaxation, less studied was the tightness of
relaxation. In this paper, we analyze a family of linear outer approximation
based certificate methods via a meta algorithm, IBP-Lin. The aforementioned
works often lack quantitative analysis to answer questions such as how does the
performance of the certificate method depend on the network configuration and
the choice of approximation parameters. Under our framework, we make a first
attempt at answering these questions, which reveals that the tightness of
linear approximation based certification can depend heavily on the
configuration of the trained networks.
</p></li>
</ul>

<h3>Title: Solving practical multi-body dynamics problems using a single neural operator. (arXiv:2210.00222v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00222">http://arxiv.org/abs/2210.00222</a></li>
<li>Code URL: <a href="https://github.com/Hedawl/PINO-MBD">https://github.com/Hedawl/PINO-MBD</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00222] Solving practical multi-body dynamics problems using a single neural operator](http://arxiv.org/abs/2210.00222)</code></li>
<li>Summary: <p>As a fundamental design tool in many engineering disciplines, multi-body
dynamics (MBD) models a complex structure with a differential equation group
containing multiple physical quantities. Engineers must constantly adjust
structures at the design stage, which requires a highly efficient solver. The
rise of deep learning technologies has offered new perspectives on MBD.
Unfortunately, existing black-box models suffer from poor accuracy and
robustness, while the advanced methodologies of single-output operator
regression cannot deal with multiple quantities simultaneously. To address
these challenges, we propose PINO-MBD, a deep learning framework for solving
practical MBD problems based on the theory of physics-informed neural operator
(PINO). PINO-MBD uses a single network for all quantities in a multi-body
system, instead of training dozens, or even hundreds of networks as in the
existing literature. We demonstrate the flexibility and feasibility of PINO-MBD
for one toy example and two practical applications: vehicle-track coupled
dynamics (VTCD) and reliability analysis of a four-storey building. The
performance of VTCD indicates that our framework outperforms existing software
and machine learning-based methods in terms of efficiency and precision,
respectively. For the reliability analysis, PINO-MBD can provide
higher-resolution results in less than a quarter of the time incurred when
using the probability density evolution method (PDEM). This framework
integrates mechanics and deep learning technologies and may reveal a new
concept for MBD and probabilistic engineering.
</p></li>
</ul>

<h3>Title: Subspace Learning for Feature Selection via Rank Revealing QR Factorization: Unsupervised and Hybrid Approaches with Non-negative Matrix Factorization and Evolutionary Algorithm. (arXiv:2210.00418v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00418">http://arxiv.org/abs/2210.00418</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00418] Subspace Learning for Feature Selection via Rank Revealing QR Factorization: Unsupervised and Hybrid Approaches with Non-negative Matrix Factorization and Evolutionary Algorithm](http://arxiv.org/abs/2210.00418)</code></li>
<li>Summary: <p>The selection of most informative and discriminative features from
high-dimensional data has been noticed as an important topic in machine
learning and data engineering. Using matrix factorization-based techniques such
as nonnegative matrix factorization for feature selection has emerged as a hot
topic in feature selection. The main goal of feature selection using matrix
factorization is to extract a subspace which approximates the original space
but in a lower dimension. In this study, rank revealing QR (RRQR)
factorization, which is computationally cheaper than singular value
decomposition (SVD), is leveraged in obtaining the most informative features as
a novel unsupervised feature selection technique. This technique uses the
permutation matrix of QR for feature selection which is a unique property to
this factorization method. Moreover, QR factorization is embedded into
non-negative matrix factorization (NMF) objective function as a new
unsupervised feature selection method. Lastly, a hybrid feature selection
algorithm is proposed by coupling RRQR, as a filter-based technique, and a
Genetic algorithm as a wrapper-based technique. In this method, redundant
features are removed using RRQR factorization and the most discriminative
subset of features are selected using the Genetic algorithm. The proposed
algorithm shows to be dependable and robust when compared against
state-of-the-art feature selection algorithms in supervised, unsupervised, and
semi-supervised settings. All methods are tested on seven available microarray
datasets using KNN, SVM and C4.5 classifiers. In terms of evaluation metrics,
the experimental results shows that the proposed method is comparable with the
state-of-the-art feature selection.
</p></li>
</ul>

<h3>Title: Comparison of Data Representations and Machine Learning Architectures for User Identification on Arbitrary Motion Sequences. (arXiv:2210.00527v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00527">http://arxiv.org/abs/2210.00527</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00527] Comparison of Data Representations and Machine Learning Architectures for User Identification on Arbitrary Motion Sequences](http://arxiv.org/abs/2210.00527)</code></li>
<li>Summary: <p>Reliable and robust user identification and authentication are important and
often necessary requirements for many digital services. It becomes paramount in
social virtual reality (VR) to ensure trust, specifically in digital encounters
with lifelike realistic-looking avatars as faithful replications of real
persons. Recent research has shown great interest in providing new solutions
that verify the identity of extended reality (XR) systems. This paper compares
different machine learning approaches to identify users based on arbitrary
sequences of head and hand movements, a data stream provided by the majority of
today's XR systems. We compare three different potential representations of the
motion data from heads and hands (scene-relative, body-relative, and
body-relative velocities), and by comparing the performances of five different
machine learning architectures (random forest, multilayer perceptron, fully
recurrent neural network, long-short term memory, gated recurrent unit). We use
the publicly available dataset "Talking with Hands" and publish all our code to
allow reproducibility and to provide baselines for future work. After
hyperparameter optimization, the combination of a long-short term memory
architecture and body-relative data outperformed competing combinations: the
model correctly identifies any of the 34 subjects with an accuracy of 100\%
within 150 seconds. The code for models, training and evaluation is made
publicly available. Altogether, our approach provides an effective foundation
for behaviometric-based identification and authentication to guide researchers
and practitioners.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Alignment-guided Temporal Attention for Video Action Recognition. (arXiv:2210.00132v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00132">http://arxiv.org/abs/2210.00132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00132] Alignment-guided Temporal Attention for Video Action Recognition](http://arxiv.org/abs/2210.00132)</code></li>
<li>Summary: <p>Temporal modeling is crucial for various video learning tasks. Most recent
approaches employ either factorized (2D+1D) or joint (3D) spatial-temporal
operations to extract temporal contexts from the input frames. While the former
is more efficient in computation, the latter often obtains better performance.
In this paper, we attribute this to a dilemma between the sufficiency and the
efficiency of interactions among various positions in different frames. These
interactions affect the extraction of task-relevant information shared among
frames. To resolve this issue, we prove that frame-by-frame alignments have the
potential to increase the mutual information between frame representations,
thereby including more task-relevant information to boost effectiveness. Then
we propose Alignment-guided Temporal Attention (ATA) to extend 1-dimensional
temporal attention with parameter-free patch-level alignments between
neighboring frames. It can act as a general plug-in for image backbones to
conduct the action recognition task without any model-specific design.
Extensive experiments on multiple benchmarks demonstrate the superiority and
generality of our module.
</p></li>
</ul>

<h3>Title: Structure-Aware NeRF without Posed Camera via Epipolar Constraint. (arXiv:2210.00183v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00183">http://arxiv.org/abs/2210.00183</a></li>
<li>Code URL: <a href="https://github.com/xtu-pr-lab/sanerf">https://github.com/xtu-pr-lab/sanerf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00183] Structure-Aware NeRF without Posed Camera via Epipolar Constraint](http://arxiv.org/abs/2210.00183)</code></li>
<li>Summary: <p>The neural radiance field (NeRF) for realistic novel view synthesis requires
camera poses to be pre-acquired by a structure-from-motion (SfM) approach. This
two-stage strategy is not convenient to use and degrades the performance
because the error in the pose extraction can propagate to the view synthesis.
We integrate the pose extraction and view synthesis into a single end-to-end
procedure so they can benefit from each other. For training NeRF models, only
RGB images are given, without pre-known camera poses. The camera poses are
obtained by the epipolar constraint in which the identical feature in different
views has the same world coordinates transformed from the local camera
coordinates according to the extracted poses. The epipolar constraint is
jointly optimized with pixel color constraint. The poses are represented by a
CNN-based deep network, whose input is the related frames. This joint
optimization enables NeRF to be aware of the scene's structure that has an
improved generalization performance. Extensive experiments on a variety of
scenes demonstrate the effectiveness of the proposed approach. Code is
available at https://github.com/XTU-PR-LAB/SaNerf.
</p></li>
</ul>

<h3>Title: A Dual-Attention Learning Network with Word and Sentence Embedding for Medical Visual Question Answering. (arXiv:2210.00220v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00220">http://arxiv.org/abs/2210.00220</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00220] A Dual-Attention Learning Network with Word and Sentence Embedding for Medical Visual Question Answering](http://arxiv.org/abs/2210.00220)</code></li>
<li>Summary: <p>Research in medical visual question answering (MVQA) can contribute to the
development of computeraided diagnosis. MVQA is a task that aims to predict
accurate and convincing answers based on given medical images and associated
natural language questions. This task requires extracting medical
knowledge-rich feature content and making fine-grained understandings of them.
Therefore, constructing an effective feature extraction and understanding
scheme are keys to modeling. Existing MVQA question extraction schemes mainly
focus on word information, ignoring medical information in the text. Meanwhile,
some visual and textual feature understanding schemes cannot effectively
capture the correlation between regions and keywords for reasonable visual
reasoning. In this study, a dual-attention learning network with word and
sentence embedding (WSDAN) is proposed. We design a module, transformer with
sentence embedding (TSE), to extract a double embedding representation of
questions containing keywords and medical information. A dualattention learning
(DAL) module consisting of self-attention and guided attention is proposed to
model intensive intramodal and intermodal interactions. With multiple DAL
modules (DALs), learning visual and textual co-attention can increase the
granularity of understanding and improve visual reasoning. Experimental results
on the ImageCLEF 2019 VQA-MED (VQA-MED 2019) and VQA-RAD datasets demonstrate
that our proposed method outperforms previous state-of-the-art methods.
According to the ablation studies and Grad-CAM maps, WSDAN can extract rich
textual information and has strong visual reasoning ability.
</p></li>
</ul>

<h3>Title: Gait-based Age Group Classification with Adaptive Graph Neural Network. (arXiv:2210.00294v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00294">http://arxiv.org/abs/2210.00294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00294] Gait-based Age Group Classification with Adaptive Graph Neural Network](http://arxiv.org/abs/2210.00294)</code></li>
<li>Summary: <p>Deep learning techniques have recently been utilized for model-free
age-associated gait feature extraction. However, acquiring model-free gait
demands accurate pre-processing such as background subtraction, which is
non-trivial in unconstrained environments. On the other hand, model-based gait
can be obtained without background subtraction and is less affected by
covariates. For model-based gait-based age group classification problems,
present works rely solely on handcrafted features, where feature extraction is
tedious and requires domain expertise. This paper proposes a deep learning
approach to extract age-associated features from model-based gait for age group
classification. Specifically, we first develop an unconstrained gait dataset
called Multimedia University Gait Age and Gender dataset (MMU GAG). Next, the
body joint coordinates are determined via pose estimation algorithms and
represented as compact gait graphs via a novel part aggregation scheme. Then, a
Part-AdaptIve Residual Graph Convolutional Neural Network (PairGCN) is designed
for age-associated feature learning. Experiments suggest that PairGCN features
are far more informative than handcrafted features, yielding up to 99% accuracy
for classifying subjects as a child, adult, or senior in the MMU GAG dataset.
</p></li>
</ul>

<h3>Title: Seeing Through The Noisy Dark: Toward Real-world Low-Light Image Enhancement and Denoising. (arXiv:2210.00545v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00545">http://arxiv.org/abs/2210.00545</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00545] Seeing Through The Noisy Dark: Toward Real-world Low-Light Image Enhancement and Denoising](http://arxiv.org/abs/2210.00545)</code></li>
<li>Summary: <p>Images collected in real-world low-light environment usually suffer from
lower visibility and heavier noise, due to the insufficient light or hardware
limitation. While existing low-light image enhancement (LLIE) methods basically
ignored the noise interference and mainly focus on refining the illumination of
the low-light images based on benchmarked noise-negligible datasets. Such
operations will make them inept for the real-world LLIE (RLLIE) with heavy
noise, and result in speckle noise and blur in the enhanced images. Although
several LLIE methods considered the noise in low-light image, they are trained
on the raw data and hence cannot be used for sRGB images, since the domains of
data are different and lack of expertise or unknown protocols. In this paper,
we clearly consider the task of seeing through the noisy dark in sRGB color
space, and propose a novel end-to-end method termed Real-world Low-light
Enhancement &amp; Denoising Network (RLED-Net). Since natural images can usually be
characterized by low-rank subspaces in which the redundant information and
noise can be removed, we design a Latent Subspace Reconstruction Block (LSRB)
for feature extraction and denoising. To reduce the loss of global feature
(e.g., color/shape information) and extract more accurate local features (e.g.,
edge/texture information), we also present a basic layer with two branches,
called Cross-channel &amp; Shift-window Transformer (CST). Based on the CST, we
further present a new backbone to design a U-structure Network (CSTNet) for
deep feature recovery, and also design a Feature Refine Block (FRB) to refine
the final features. Extensive experiments on real noisy images and public
databases verified the effectiveness of our RLED-Net for both RLLIE and
denoising.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Training of Dual Encoding Models on Small Non-IID Client Datasets. (arXiv:2210.00092v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00092">http://arxiv.org/abs/2210.00092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00092] Federated Training of Dual Encoding Models on Small Non-IID Client Datasets](http://arxiv.org/abs/2210.00092)</code></li>
<li>Summary: <p>Dual encoding models that encode a pair of inputs are widely used for
representation learning. Many approaches train dual encoding models by
maximizing agreement between pairs of encodings on centralized training data.
However, in many scenarios, datasets are inherently decentralized across many
clients (user devices or organizations) due to privacy concerns, motivating
federated learning. In this work, we focus on federated training of dual
encoding models on decentralized data composed of many small, non-IID
(independent and identically distributed) client datasets. We show that
existing approaches that work well in centralized settings perform poorly when
naively adapted to this setting using federated averaging. We observe that, we
can simulate large-batch loss computation on individual clients for loss
functions that are based on encoding statistics. Based on this insight, we
propose a novel federated training approach, Distributed Cross Correlation
Optimization (DCCO), which trains dual encoding models using encoding
statistics aggregated across clients, without sharing individual data samples.
Our experimental results on two datasets demonstrate that the proposed DCCO
approach outperforms federated variants of existing approaches by a large
margin.
</p></li>
</ul>

<h3>Title: FedTrees: A Novel Computation-Communication Efficient Federated Learning Framework Investigated in Smart Grids. (arXiv:2210.00060v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00060">http://arxiv.org/abs/2210.00060</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00060] FedTrees: A Novel Computation-Communication Efficient Federated Learning Framework Investigated in Smart Grids](http://arxiv.org/abs/2210.00060)</code></li>
<li>Summary: <p>Smart energy performance monitoring and optimisation at the supplier and
consumer levels is essential to realising smart cities. In order to implement a
more sustainable energy management plan, it is crucial to conduct a better
energy forecast. The next-generation smart meters can also be used to measure,
record, and report energy consumption data, which can be used to train machine
learning (ML) models for predicting energy needs. However, sharing fine-grained
energy data and performing centralised learning may compromise users' privacy
and leave them vulnerable to several attacks. This study addresses this issue
by utilising federated learning (FL), an emerging technique that performs ML
model training at the user level, where data resides. We introduce FedTrees, a
new, lightweight FL framework that benefits from the outstanding features of
ensemble learning. Furthermore, we developed a delta-based early stopping
algorithm to monitor FL training and stop it when it does not need to continue.
The simulation results demonstrate that FedTrees outperforms the most popular
federated averaging (FedAvg) framework and the baseline Persistence model for
providing accurate energy forecasting patterns while taking only 2% of the
computation time and 13% of the communication rounds compared to FedAvg, saving
considerable amounts of computation and communication resources.
</p></li>
</ul>

<h3>Title: Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning. (arXiv:2210.00226v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00226">http://arxiv.org/abs/2210.00226</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00226] Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning](http://arxiv.org/abs/2210.00226)</code></li>
<li>Summary: <p>Federated learning aims to train models collaboratively across different
clients without the sharing of data for privacy considerations. However, one
major challenge for this learning paradigm is the {\em data heterogeneity}
problem, which refers to the discrepancies between the local data distributions
among various clients. To tackle this problem, we first study how data
heterogeneity affects the representations of the globally aggregated models.
Interestingly, we find that heterogeneous data results in the global model
suffering from severe {\em dimensional collapse}, in which representations tend
to reside in a lower-dimensional space instead of the ambient space. Moreover,
we observe a similar phenomenon on models locally trained on each client and
deduce that the dimensional collapse on the global model is inherited from
local models. In addition, we theoretically analyze the gradient flow dynamics
to shed light on how data heterogeneity result in dimensional collapse for
local models. To remedy this problem caused by the data heterogeneity, we
propose {\sc FedDecorr}, a novel method that can effectively mitigate
dimensional collapse in federated learning. Specifically, {\sc FedDecorr}
applies a regularization term during local training that encourages different
dimensions of representations to be uncorrelated. {\sc FedDecorr}, which is
implementation-friendly and computationally-efficient, yields consistent
improvements over baselines on standard benchmark datasets. Code will be
released.
</p></li>
</ul>

<h3>Title: Federated Representation Learning via Maximal Coding Rate Reduction. (arXiv:2210.00299v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00299">http://arxiv.org/abs/2210.00299</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00299] Federated Representation Learning via Maximal Coding Rate Reduction](http://arxiv.org/abs/2210.00299)</code></li>
<li>Summary: <p>We propose a federated methodology to learn low-dimensional representations
from a dataset that is distributed among several clients. In particular, we
move away from the commonly-used cross-entropy loss in federated learning, and
seek to learn shared low-dimensional representations of the data in a
decentralized manner via the principle of maximal coding rate reduction (MCR2).
Our proposed method, which we refer to as FLOW, utilizes MCR2 as the objective
of choice, hence resulting in representations that are both between-class
discriminative and within-class compressible. We theoretically show that our
distributed algorithm achieves a first-order stationary point. Moreover, we
demonstrate, via numerical experiments, the utility of the learned
low-dimensional representations.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Multi-Task Option Learning and Discovery for Stochastic Path Planning. (arXiv:2210.00068v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00068">http://arxiv.org/abs/2210.00068</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00068] Multi-Task Option Learning and Discovery for Stochastic Path Planning](http://arxiv.org/abs/2210.00068)</code></li>
<li>Summary: <p>This paper addresses the problem of reliably and efficiently solving broad
classes of long-horizon stochastic path planning problems. Starting with a
vanilla RL formulation with a stochastic dynamics simulator and an occupancy
matrix of the environment, our approach computes useful options with policies
as well as high-level paths that compose the discovered options.
</p></li>
</ul>

<p>Our main contributions are (1) data-driven methods for creating abstract
states that serve as endpoints for helpful options, (2) methods for computing
option policies using auto-generated option guides in the form of dense
pseudo-reward functions, and (3) an overarching algorithm for composing the
computed options. We show that this approach yields strong guarantees of
executability and solvability: under fairly general conditions, the computed
option guides lead to composable option policies and consequently ensure
downward refinability. Empirical evaluation on a range of robots, environments,
and tasks shows that this approach effectively transfers knowledge across
related tasks and that it outperforms existing approaches by a significant
margin.
</p>

<h3>Title: Neural Causal Models for Counterfactual Identification and Estimation. (arXiv:2210.00035v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00035">http://arxiv.org/abs/2210.00035</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00035] Neural Causal Models for Counterfactual Identification and Estimation](http://arxiv.org/abs/2210.00035)</code></li>
<li>Summary: <p>Evaluating hypothetical statements about how the world would be had a
different course of action been taken is arguably one key capability expected
from modern AI systems. Counterfactual reasoning underpins discussions in
fairness, the determination of blame and responsibility, credit assignment, and
regret. In this paper, we study the evaluation of counterfactual statements
through neural models. Specifically, we tackle two causal problems required to
make such evaluations, i.e., counterfactual identification and estimation from
an arbitrary combination of observational and experimental data. First, we show
that neural causal models (NCMs) are expressive enough and encode the
structural constraints necessary for performing counterfactual reasoning.
Second, we develop an algorithm for simultaneously identifying and estimating
counterfactual distributions. We show that this algorithm is sound and complete
for deciding counterfactual identification in general settings. Third,
considering the practical implications of these results, we introduce a new
strategy for modeling NCMs using generative adversarial networks. Simulations
corroborate with the proposed methodology.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Data-driven discovery of non-Newtonian astronomy via learning non-Euclidean Hamiltonian. (arXiv:2210.00090v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.00090">http://arxiv.org/abs/2210.00090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.00090] Data-driven discovery of non-Newtonian astronomy via learning non-Euclidean Hamiltonian](http://arxiv.org/abs/2210.00090)</code></li>
<li>Summary: <p>Incorporating the Hamiltonian structure of physical dynamics into deep
learning models provides a powerful way to improve the interpretability and
prediction accuracy. While previous works are mostly limited to the Euclidean
spaces, their extension to the Lie group manifold is needed when rotations form
a key component of the dynamics, such as the higher-order physics beyond simple
point-mass dynamics for N-body celestial interactions. Moreover, the multiscale
nature of these processes presents a challenge to existing methods as a long
time horizon is required. By leveraging a symplectic Lie-group manifold
preserving integrator, we present a method for data-driven discovery of
non-Newtonian astronomy. Preliminary results show the importance of both these
properties in training stability and prediction accuracy.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
