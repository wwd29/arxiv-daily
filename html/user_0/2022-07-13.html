<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Time synchronization protocol for the KLJN secure key exchange scheme. (arXiv:2207.05675v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05675">http://arxiv.org/abs/2207.05675</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The information theoretically secure Kirchhoff-law-Johnson-noise (KLJN) key
exchange scheme, similarly to quantum key distribution (QKD), is also
potentially vulnerable against clock attacks, where Eve takes over the control
of clock synchronization in the channel. This short note aims to introduce a
time synchronization protocol scheme for Alice and Bob, which is resistant
against arbitrary time delay attacks, both symmetric and asymmetric ones. We
propose and explore various ways of clock synchronization for the KLJN system
and propose an ultimate protocol that preserves time and hardware integrity
under arbitrary attacks.
</p></li>
</ul>

<h3>Title: Design and Implementation of a Secure RISC-V Microprocessor. (arXiv:2205.05095v2 [cs.CR] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2205.05095">http://arxiv.org/abs/2205.05095</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Secret keys can be extracted from the power consumption or electromagnetic
emanations of unprotected devices. Traditional counter-measures have limited
scope of protection, and impose several restrictions on how sensitive data must
be manipulated. We demonstrate a bit-serial RISC-V microprocessor
implementation with no plain-text data. All values are protected using Boolean
masking. Software can run with little to no counter-measures, reducing code
size and performance overheads. Unlike previous literature, our methodology is
fully automated and can be applied to designs of arbitrary size or complexity.
We also provide details on other key components such as clock randomizer,
memory protection, and random number generator. The microprocessor was
implemented in 65 nm CMOS technology. Its implementation was evaluated using
NIST tests as well as side channel attacks. Random numbers generated with our
RNG pass on all NIST tests. Side-channel analysis on the baseline
implementation extracted the AES key using only 375 traces, while our secure
microprocessor was able to withstand attacks using 20 M traces.
</p></li>
</ul>

<h3>Title: Toward Timed-Release Encryption in Web3 An Efficient Dual-Purpose Proof-of-Work Consensus. (arXiv:2205.09020v3 [cs.CR] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2205.09020">http://arxiv.org/abs/2205.09020</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Many existing timed-release encryption schemes uses time-lock puzzles to
avoid relying on a trusted timeserver or a key holder which could be a weak
spot in data security. However, it is unavoidable to consume massive computing
power for solving time-lock puzzles and it is difficult for encryptors to
predict the amount of time to solve a puzzle by decryptors. In this study, an
efficient dual-purpose proof-of-work consensus allows users to release a
time-locked content, which is encrypted by an asymmetric key encryption scheme
on a blockchain, without trust in any third-party agents. The release time is
predictable as the block time in a proof-of-work blockchain is adaptively
controlled. The mining work is reproposed so that once a new block was mined on
the blockchain network, time-lock puzzles were also solved immediately. No
additional work is required to reveal the time-locked contents and the
encryption is secured by monetary incentive mechanisms since it would be very
costly to arrange an attack attempt, which must overtake the total hash rate of
the whole blockchain network.
</p></li>
</ul>

<h3>Title: Horizontal Federated Learning and Secure Distributed Training for Recommendation System with Intel SGX. (arXiv:2207.05079v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05079">http://arxiv.org/abs/2207.05079</a></li>
<li>Code URL: null</li>
<li>Summary: <p>With the advent of big data era and the development of artificial
intelligence and other technologies, data security and privacy protection have
become more important. Recommendation systems have many applications in our
society, but the model construction of recommendation systems is often
inseparable from users' data. Especially for deep learning-based recommendation
systems, due to the complexity of the model and the characteristics of deep
learning itself, its training process not only requires long training time and
abundant computational resources but also needs to use a large amount of user
data, which poses a considerable challenge in terms of data security and
privacy protection. How to train a distributed recommendation system while
ensuring data security has become an urgent problem to be solved. In this
paper, we implement two schemes, Horizontal Federated Learning and Secure
Distributed Training, based on Intel SGX(Software Guard Extensions), an
implementation of a trusted execution environment, and TensorFlow framework, to
achieve secure, distributed recommendation system-based learning schemes in
different scenarios. We experiment on the classical Deep Learning
Recommendation Model (DLRM), which is a neural network-based machine learning
model designed for personalization and recommendation, and the results show
that our implementation introduces approximately no loss in model performance.
The training speed is within acceptable limits.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: A novel conservative chaos driven dynamic DNA coding for image encryption. (arXiv:2207.05475v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05475">http://arxiv.org/abs/2207.05475</a></li>
<li>Code URL: null</li>
<li>Summary: <p>In this paper, we propose a novel conservative chaotic standard map-driven
dynamic DNA coding (encoding, addition, subtraction and decoding) for the image
encryption. The proposed image encryption algorithm is a dynamic DNA coding
algorithm i.e., for the encryption of each pixel different rules for encoding,
addition/subtraction, decoding etc. are randomly selected based on the
pseudorandom sequences generated with the help of the conservative chaotic
standard map. We propose a novel way to generate pseudo-random sequences
through the conservative chaotic standard map and also test them rigorously
through the most stringent test suite of pseudo-randomness, the NIST test
suite, before using them in the proposed image encryption algorithm. Our image
encryption algorithm incorporates a unique feed-forward and feedback mechanisms
to generate and modify the dynamic one-time pixels that are further used for
the encryption of each pixel of the plain image, therefore, bringing in the
desired sensitivity on plaintext as well as ciphertext. All the controlling
pseudorandom sequences used in the algorithm are generated for a different
value of the parameter (part of the secret key) with inter-dependency through
the iterates of the chaotic map (in the generation process) and therefore
possess extreme key sensitivity too. The performance and security analysis has
been executed extensively through histogram analysis, correlation analysis,
information entropy analysis, DNA sequence-based analysis, perceptual quality
analysis, key sensitivity analysis, plaintext sensitivity analysis, etc., The
results are promising and prove the robustness of the algorithm against various
common cryptanalytic attacks.
</p></li>
</ul>

<h3>Title: "Why do so?" -- A Practical Perspective on Machine Learning Security. (arXiv:2207.05164v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05164">http://arxiv.org/abs/2207.05164</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Despite the large body of academic work on machine learning security, little
is known about the occurrence of attacks on machine learning systems in the
wild. In this paper, we report on a quantitative study with 139 industrial
practitioners. We analyze attack occurrence and concern and evaluate
statistical hypotheses on factors influencing threat perception and exposure.
Our results shed light on real-world attacks on deployed machine learning. On
the organizational level, while we find no predictors for threat exposure in
our sample, the amount of implement defenses depends on exposure to threats or
expected likelihood to become a target. We also provide a detailed analysis of
practitioners' replies on the relevance of individual machine learning attacks,
unveiling complex concerns like unreliable decision making, business
information leakage, and bias introduction into models. Finally, we find that
on the individual level, prior knowledge about machine learning security
influences threat perception. Our work paves the way for more research about
adversarial machine learning in practice, but yields also insights for
regulation and auditing.
</p></li>
</ul>

<h3>Title: From Bitcoin to Solana -- Innovating Blockchain towards Enterprise Applications. (arXiv:2207.05240v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05240">http://arxiv.org/abs/2207.05240</a></li>
<li>Code URL: null</li>
<li>Summary: <p>This survey presents a comprehensive study of recent advances in block-chain
technologies, focusing on how issues that affecting the enterprise adoption
were progressively addressed from the original Bitcoin system to Ethereum, to
Solana etc. Key issues preventing the wide adoption are scala-bility and
performance, while recent advances in Solana has clearly demon-strated that it
is possible to significantly improve on those issues by innovat-ing on data
structure, processes and algorithms by consolidating various time-consuming
algorithms and security enforcements, and differentiate and balance users and
their responsibilities and rights, while maintaining the re-quired security and
integrity that blockchain systems inherently offer.
</p></li>
</ul>

<h3>Title: Security Methods in Internet of vehicles. (arXiv:2207.05269v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05269">http://arxiv.org/abs/2207.05269</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The emerging wireless communication technology known as vehicle ad hoc
networks (VANETs) has the potential to both lower the risk of auto accidents
caused by drivers and offer a wide range of entertainment amenities. The
messages broadcast by a vehicle may be impacted by security threats due to the
open-access nature of VANETs. Because of this, VANET is susceptible to security
and privacy problems. In order to go beyond the obstacle, we investigate and
review some existing researches to secure communication in VANET. Additionally,
we provide overview, components in VANET in details.
</p></li>
</ul>

<h3>Title: A Security-aware and LUT-based CAD Flow for the Physical Synthesis of eASICs. (arXiv:2207.05413v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05413">http://arxiv.org/abs/2207.05413</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Numerous threats are associated with the globalized integrated circuit (IC)
supply chain, such as piracy, reverse engineering, overproduction, and
malicious logic insertion. Many obfuscation approaches have been proposed to
mitigate these threats by preventing an adversary from fully understanding the
IC (or parts of it). The use of reconfigurable elements inside an IC is a known
obfuscation technique, either as a coarse grain reconfigurable block (i.e.,
eFPGA) or as a fine grain element (i.e., FPGA-like look-up tables). This paper
presents a security-aware CAD flow that is LUT-based yet still compatible with
the standard cell based physical synthesis flow. More precisely, our CAD flow
explores the FPGA-ASIC design space and produces heavily obfuscated designs
where only small portions of the logic resemble an ASIC. Therefore, we term
this specialized solution an "embedded ASIC" (eASIC). Nevertheless, even for
heavily LUT-dominated designs, our proposed decomposition and pin swapping
algorithms allow for performance gains that enable performance levels that only
ASICs would otherwise achieve. On the security side, we have developed novel
template-based attacks and also applied existing attacks, both oracle-free and
oracle-based. Our security analysis revealed that the obfuscation rate for an
SHA-256 study case should be at least 45% for withstanding traditional attacks
and at least 80% for withstanding template-based attacks. When the 80\%
obfuscated SHA-256 design is physically implemented, it achieves a remarkable
frequency of 368MHz in a 65nm commercial technology, whereas its FPGA
implementation (in a superior technology) achieves only 77MHz.
</p></li>
</ul>

<h3>Title: Representation learning with function call graph transformations for malware open set recognition. (arXiv:2205.06918v3 [cs.CR] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2205.06918">http://arxiv.org/abs/2205.06918</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Open set recognition (OSR) problem has been a challenge in many machine
learning (ML) applications, such as security. As new/unknown malware families
occur regularly, it is difficult to exhaust samples that cover all the classes
for the training process in ML systems. An advanced malware classification
system should classify the known classes correctly while sensitive to the
unknown class. In this paper, we introduce a self-supervised pre-training
approach for the OSR problem in malware classification. We propose two
transformations for the function call graph (FCG) based malware representations
to facilitate the pretext task. Also, we present a statistical thresholding
approach to find the optimal threshold for the unknown class. Moreover, the
experiment results indicate that our proposed pre-training process can improve
different performances of different downstream loss functions for the OSR
problem.
</p></li>
</ul>

<h3>Title: Offline Equilibrium Finding. (arXiv:2207.05285v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05285">http://arxiv.org/abs/2207.05285</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Offline reinforcement learning (Offline RL) is an emerging field that has
recently begun gaining attention across various application domains due to its
ability to learn behavior from earlier collected datasets. Using logged data is
imperative when further interaction with the environment is expensive
(computationally or otherwise), unsafe, or entirely unfeasible. Offline RL
proved very successful, paving a path to solving previously intractable
real-world problems, and we aim to generalize this paradigm to a multi-agent or
multiplayer-game setting. Very little research has been done in this area, as
the progress is hindered by the lack of standardized datasets and meaningful
benchmarks. In this work, we coin the term offline equilibrium finding (OEF) to
describe this area and construct multiple datasets consisting of strategies
collected across a wide range of games using several established methods. We
also propose a benchmark method -- an amalgamation of a behavior-cloning and a
model-based algorithm. Our two model-based algorithms -- OEF-PSRO and OEF-CFR
-- are adaptations of the widely-used equilibrium finding algorithms Deep CFR
and PSRO in the context of offline learning. In the empirical part, we evaluate
the performance of the benchmark algorithms on the constructed datasets. We
hope that our efforts may help to accelerate research in large-scale
equilibrium finding. Datasets and code are available at
https://github.com/SecurityGames/oef.
</p></li>
</ul>

<h3>Title: Fast Yet Effective Machine Unlearning. (arXiv:2111.08947v4 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2111.08947">http://arxiv.org/abs/2111.08947</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Unlearning the data observed during the training of a machine learning (ML)
model is an important task that can play a pivotal role in fortifying the
privacy and security of ML-based applications. This paper raises the following
questions: (i) can we unlearn a single or multiple classes of data from an ML
model without looking at the full training data even once? (ii) can we make the
process of unlearning fast and scalable to large datasets, and generalize it to
different deep networks? We introduce a novel machine unlearning framework with
error-maximizing noise generation and impair-repair based weight manipulation
that offers an efficient solution to the above questions. An error-maximizing
noise matrix is learned for the class to be unlearned using the original model.
The noise matrix is used to manipulate the model weights to unlearn the
targeted class of data. We introduce impair and repair steps for a controlled
manipulation of the network weights. In the impair step, the noise matrix along
with a very high learning rate is used to induce sharp unlearning in the model.
Thereafter, the repair step is used to regain the overall performance. With
very few update steps, we show excellent unlearning while substantially
retaining the overall model accuracy. Unlearning multiple classes requires a
similar number of update steps as for the single class, making our approach
scalable to large problems. Our method is quite efficient in comparison to the
existing methods, works for multi-class unlearning, doesn't put any constraints
on the original optimization mechanism or network design, and works well in
both small and large-scale vision tasks. This work is an important step towards
fast and easy implementation of unlearning in deep networks. We will make the
source code publicly available.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: PeopleSansPeople: A Synthetic Data Generator for Human-Centric Computer Vision. (arXiv:2112.09290v2 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2112.09290">http://arxiv.org/abs/2112.09290</a></li>
<li>Code URL: <a href="https://github.com/unity-technologies/peoplesanspeople">https://github.com/unity-technologies/peoplesanspeople</a></li>
<li>Summary: <p>In recent years, person detection and human pose estimation have made great
strides, helped by large-scale labeled datasets. However, these datasets had no
guarantees or analysis of human activities, poses, or context diversity.
Additionally, privacy, legal, safety, and ethical concerns may limit the
ability to collect more human data. An emerging alternative to real-world data
that alleviates some of these issues is synthetic data. However, creation of
synthetic data generators is incredibly challenging and prevents researchers
from exploring their usefulness. Therefore, we release a human-centric
synthetic data generator PeopleSansPeople which contains simulation-ready 3D
human assets, a parameterized lighting and camera system, and generates 2D and
3D bounding box, instance and semantic segmentation, and COCO pose labels.
Using PeopleSansPeople, we performed benchmark synthetic data training using a
Detectron2 Keypoint R-CNN variant [1]. We found that pre-training a network
using synthetic data and fine-tuning on various sizes of real-world data
resulted in a keypoint AP increase of $+38.03$ ($44.43 \pm 0.17$ vs. $6.40$)
for few-shot transfer (limited subsets of COCO-person train [2]), and an
increase of $+1.47$ ($63.47 \pm 0.19$ vs. $62.00$) for abundant real data
regimes, outperforming models trained with the same real data alone. We also
found that our models outperformed those pre-trained with ImageNet with a
keypoint AP increase of $+22.53$ ($44.43 \pm 0.17$ vs. $21.90$) for few-shot
transfer and $+1.07$ ($63.47 \pm 0.19$ vs. $62.40$) for abundant real data
regimes. This freely-available data generator should enable a wide range of
research into the emerging field of simulation to real transfer learning in the
critical area of human-centric computer vision.
</p></li>
</ul>

<h3>Title: Efficient and Privacy Preserving Group Signature for Federated Learning. (arXiv:2207.05297v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05297">http://arxiv.org/abs/2207.05297</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Federated Learning (FL) is a Machine Learning (ML) technique that aims to
reduce the threats to user data privacy. Training is done using the raw data on
the users' device, called clients, and only the training results, called
gradients, are sent to the server to be aggregated and generate an updated
model. However, we cannot assume that the server can be trusted with private
information, such as metadata related to the owner or source of the data. So,
hiding the client information from the server helps reduce privacy-related
attacks. Therefore, the privacy of the client's identity, along with the
privacy of the client's data, is necessary to make such attacks more difficult.
This paper proposes an efficient and privacy-preserving protocol for FL based
on group signature. A new group signature for federated learning, called GSFL,
is designed to not only protect the privacy of the client's data and identity
but also significantly reduce the computation and communication costs
considering the iterative process of federated learning. We show that GSFL
outperforms existing approaches in terms of computation, communication, and
signaling costs. Also, we show that the proposed protocol can handle various
security attacks in the federated learning environment.
</p></li>
</ul>

<h3>Title: End-to-end speech recognition modeling from de-identified data. (arXiv:2207.05469v1 [eess.AS])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05469">http://arxiv.org/abs/2207.05469</a></li>
<li>Code URL: null</li>
<li>Summary: <p>De-identification of data used for automatic speech recognition modeling is a
critical component in protecting privacy, especially in the medical domain.
However, simply removing all personally identifiable information (PII) from
end-to-end model training data leads to a significant performance degradation
in particular for the recognition of names, dates, locations, and words from
similar categories. We propose and evaluate a two-step method for partially
recovering this loss. First, PII is identified, and each occurrence is replaced
with a random word sequence of the same category. Then, corresponding audio is
produced via text-to-speech or by splicing together matching audio fragments
extracted from the corpus. These artificial audio/label pairs, together with
speaker turns from the original data without PII, are used to train models. We
evaluate the performance of this method on in-house data of medical
conversations and observe a recovery of almost the entire performance
degradation in the general word error rate while still maintaining a strong
diarization performance. Our main focus is the improvement of recall and
precision in the recognition of PII-related words. Depending on the PII
category, between $50\% - 90\%$ of the performance degradation can be recovered
using our proposed method.
</p></li>
</ul>

<h3>Title: Improved Rates for Differentially Private Stochastic Convex Optimization with Heavy-Tailed Data. (arXiv:2106.01336v5 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2106.01336">http://arxiv.org/abs/2106.01336</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We study stochastic convex optimization with heavy-tailed data under the
constraint of differential privacy (DP). Most prior work on this problem is
restricted to the case where the loss function is Lipschitz. Instead, as
introduced by Wang, Xiao, Devadas, and Xu \cite{WangXDX20}, we study general
convex loss functions with the assumption that the distribution of gradients
has bounded $k$-th moments. We provide improved upper bounds on the excess
population risk under concentrated DP for convex and strongly convex loss
functions. Along the way, we derive new algorithms for private mean estimation
of heavy-tailed distributions, under both pure and concentrated DP. Finally, we
prove nearly-matching lower bounds for private stochastic convex optimization
with strongly convex losses and mean estimation, showing new separations
between pure and concentrated DP.
</p></li>
</ul>

<h3>Title: Zero-Shot Machine Unlearning. (arXiv:2201.05629v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2201.05629">http://arxiv.org/abs/2201.05629</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Modern privacy regulations grant citizens the right to be forgotten by
products, services and companies. In case of machine learning (ML)
applications, this necessitates deletion of data not only from storage archives
but also from ML models. Due to an increasing need for regulatory compliance
required for ML applications, machine unlearning is becoming an emerging
research problem. The right to be forgotten requests come in the form of
removal of a certain set or class of data from the already trained ML model.
Practical considerations preclude retraining of the model from scratch minus
the deleted data. The few existing studies use either the whole training data,
or a subset of training data, or some metadata stored during training to update
the model weights for unlearning. However, strict regulatory compliance
requires time-bound deletion of data. Thus, in many cases, no data related to
the training process or training samples may be accessible even for the
unlearning purpose. We therefore ask the question: is it possible to achieve
unlearning with zero training samples? In this paper, we introduce the novel
problem of zero-shot machine unlearning that caters for the extreme but
practical scenario where zero original data samples are available for use. We
then propose two novel solutions for zero-shot machine unlearning based on (a)
error minimizing-maximizing noise and (b) gated knowledge transfer. These
methods remove the information of the forget data from the model while
maintaining the model efficacy on the retain data. The zero-shot approach
offers good protection against the model inversion attacks and membership
inference attacks. We introduce a new evaluation metric, Anamnesis Index (AIN)
to effectively measure the quality of the unlearning method. The experiments
show promising results for unlearning in deep learning models on benchmark
vision data-sets.
</p></li>
</ul>

<h3>Title: Efficient NLP Inference at the Edge via Elastic Pipelining. (arXiv:2207.05022v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05022">http://arxiv.org/abs/2207.05022</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Natural Language Processing (NLP) inference is seeing increasing adoption by
mobile applications, where on-device inference is desirable for crucially
preserving user data privacy and avoiding network roundtrips. Yet, the
unprecedented size of an NLP model stresses both latency and memory, the two
key resources of a mobile device. To meet a target latency, holding the whole
model in memory launches execution as soon as possible but increases one app's
memory footprints by several times, limiting its benefits to only a few
inferences before being recycled by mobile memory management. On the other
hand, loading the model from storage on demand incurs a few seconds long IO,
far exceeding the delay range satisfying to a user; pipelining layerwise model
loading and execution does not hide IO either, due to the large skewness
between IO and computation delays.
</p></li>
</ul>

<p>To this end, we propose WRX. Built on the key idea of maximizing IO/compute
resource utilization on the most important parts of a model, WRX reconciles the
latency/memory tension via two novel techniques. First, model sharding. WRX
manages model parameters as independently tunable shards and profiles their
importance to accuracy. Second, elastic pipeline planning with a preload
buffer. WRX instantiates an IO/computation pipeline and uses a small buffer for
preload shards to bootstrap execution without stalling in early stages; it
judiciously selects, tunes, and assembles shards per their importance for
resource-elastic execution, which maximizes inference accuracy.
</p>
<p>Atop two commodity SoCs, we build WRX and evaluate it against a wide range of
NLP tasks, under a practical range of target latencies, and on both CPU and
GPU. We demonstrate that, WRX delivers high accuracies with 1--2 orders of
magnitude lower memory, outperforming competitive baselines.
</p>

<h2>protect</h2>
<h3>Title: Image and Model Transformation with Secret Key for Vision Transformer. (arXiv:2207.05366v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05366">http://arxiv.org/abs/2207.05366</a></li>
<li>Code URL: null</li>
<li>Summary: <p>In this paper, we propose a combined use of transformed images and vision
transformer (ViT) models transformed with a secret key. We show for the first
time that models trained with plain images can be directly transformed to
models trained with encrypted images on the basis of the ViT architecture, and
the performance of the transformed models is the same as models trained with
plain images when using test images encrypted with the key. In addition, the
proposed scheme does not require any specially prepared data for training
models or network modification, so it also allows us to easily update the
secret key. In an experiment, the effectiveness of the proposed scheme is
evaluated in terms of performance degradation and model protection performance
in an image classification task on the CIFAR-10 dataset.
</p></li>
</ul>

<h3>Title: HyperDbg: Reinventing Hardware-Assisted Debugging. (arXiv:2207.05676v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05676">http://arxiv.org/abs/2207.05676</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Software analysis, debugging, and reverse engineering have a crucial impact
in today's software industry. Efficient and stealthy debuggers are especially
relevant for malware analysis. However, existing debugging platforms fail to
address a transparent, effective, and high-performance low-level debugger due
to their detectable fingerprints, complexity, and implementation restrictions.
In this paper, we present HyperDbg, a new hypervisor-assisted debugger for
high-performance and stealthy debugging of user and kernel applications. To
accomplish this, HyperDbg relies on state-of-the-art hardware features
available in today's CPUs, such as VT-x and extended page tables. In contrast
to other widely used existing debuggers, we design HyperDbg using a custom
hypervisor, making it independent of OS functionality or API. We propose
hardware-based instruction-level emulation and OS-level API hooking via
extended page tables to increase the stealthiness. Our results of the dynamic
analysis of 10,853 malware samples show that HyperDbg's stealthiness allows
debugging on average 22% and 26% more samples than WinDbg and x64dbg,
respectively. Moreover, in contrast to existing debuggers, HyperDbg is not
detected by any of the 13 tested packers and protectors. We improve the
performance over other debuggers by deploying a VMX-compatible script engine,
eliminating unnecessary context switches. Our experiment on three concrete
debugging scenarios shows that compared to WinDbg as the only kernel debugger,
HyperDbg performs step-in, conditional breaks, and syscall recording, 2.98x,
1319x, and 2018x faster, respectively. We finally show real-world applications,
such as a 0-day analysis, structure reconstruction for reverse engineering,
software performance analysis, and code-coverage analysis.
</p></li>
</ul>

<h3>Title: CAN-MM: Multiplexed Message Authentication Code for Controller Area Network message authentication in road vehicles. (arXiv:2206.02603v2 [cs.CR] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2206.02603">http://arxiv.org/abs/2206.02603</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The automotive market is increasingly profitable for cyberattacks with the
constant shift toward fully interconnected vehicles. Electronic Control Units
(ECUs) installed on cars often operate in a critical and hostile environment.
Hence, both carmakers and governments have decided to support a series of
initiatives to mitigate risks and threats belonging to the automotive domain.
The Controller Area Network (CAN) is the primary communication protocol in the
automotive field, and the integrity of the communication over this network is
assured through Message Authentication Codes (MAC). However, limitations in
throughput and frame size limit the application of this technique to specific
versions of the CAN protocol, leaving several vehicles still unprotected. This
paper presents CAN Multiplexed MAC (CAN-MM), a new approach exploiting
frequency modulation to multiplex MAC data with standard CAN communication.
CAN-MM allows transmitting MAC payloads maintaining full-back compatibility
with all versions of the standard CAN protocol. Moreover, multiplexing allows
sending DATA and MAC simultaneously.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Markov Decision Process For Automatic Cyber Defense. (arXiv:2207.05436v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05436">http://arxiv.org/abs/2207.05436</a></li>
<li>Code URL: null</li>
<li>Summary: <p>It is challenging for a security analyst to detect or defend against
cyber-attacks. Moreover, traditional defense deployment methods require the
security analyst to manually enforce the defenses in the presence of
uncertainties about the defense to deploy. As a result, it is essential to
develop an automated and resilient defense deployment mechanism to thwart the
new generation of attacks. In this paper, we propose a framework based on
Markov Decision Process (MDP) and Q-learning to automatically generate optimal
defense solutions for networked system states. The framework consists of four
phases namely; the model initialization phase, model generation phase,
Q-learning phase, and the conclusion phase. The proposed model collects real
network information as inputs and then builds them into structural data. We
implement a Q-learning process in the model to learn the quality of a defense
action in a particular state. To investigate the feasibility of the proposed
model, we perform simulation experiments and the result reveals that the model
can reduce the risk of network systems from cyber attacks. Furthermore, the
experiment shows that the model has shown a certain level of flexibility when
different parameters are used for Q-learning.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Towards Effective Multi-Label Recognition Attacks via Knowledge Graph Consistency. (arXiv:2207.05137v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05137">http://arxiv.org/abs/2207.05137</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Many real-world applications of image recognition require multi-label
learning, whose goal is to find all labels in an image. Thus, robustness of
such systems to adversarial image perturbations is extremely important.
However, despite a large body of recent research on adversarial attacks, the
scope of the existing works is mainly limited to the multi-class setting, where
each image contains a single label. We show that the naive extensions of
multi-class attacks to the multi-label setting lead to violating label
relationships, modeled by a knowledge graph, and can be detected using a
consistency verification scheme. Therefore, we propose a graph-consistent
multi-label attack framework, which searches for small image perturbations that
lead to misclassifying a desired target set while respecting label hierarchies.
By extensive experiments on two datasets and using several multi-label
recognition models, we show that our method generates extremely successful
attacks that, unlike naive multi-label perturbations, can produce model
predictions consistent with the knowledge graph.
</p></li>
</ul>

<h3>Title: Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05225">http://arxiv.org/abs/2207.05225</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The recent advances in continual (incremental or lifelong) learning have
concentrated on the prevention of forgetting that can lead to catastrophic
consequences, but there are two outstanding challenges that must be addressed.
The first is the evaluation of the robustness of the proposed methods. The
second is ensuring the security of learned tasks remains largely unexplored.
This paper presents a comprehensive study of the susceptibility of the
continually learned tasks (including both current and previously learned tasks)
that are vulnerable to forgetting. Such vulnerability of tasks against
adversarial attacks raises profound issues in data integrity and privacy. We
consider the task incremental learning (Task-IL) scenario and explore three
regularization-based experiments, three replay-based experiments, and one
hybrid technique based on the reply and exemplar approach. We examine the
robustness of these methods. In particular, we consider cases where we
demonstrate that any class belonging to the current or previously learned tasks
is prone to misclassification. Our observations highlight the potential
limitations of existing Task-IL approaches. Our empirical study recommends that
the research community consider the robustness of the proposed continual
learning approaches and invest extensive efforts in mitigating catastrophic
forgetting.
</p></li>
</ul>

<h3>Title: Frequency Domain Model Augmentation for Adversarial Attack. (arXiv:2207.05382v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05382">http://arxiv.org/abs/2207.05382</a></li>
<li>Code URL: <a href="https://github.com/yuyang-long/ssa">https://github.com/yuyang-long/ssa</a></li>
<li>Summary: <p>For black-box attacks, the gap between the substitute model and the victim
model is usually large, which manifests as a weak attack performance. Motivated
by the observation that the transferability of adversarial examples can be
improved by attacking diverse models simultaneously, model augmentation methods
which simulate different models by using transformed images are proposed.
However, existing transformations for spatial domain do not translate to
significantly diverse augmented models. To tackle this issue, we propose a
novel spectrum simulation attack to craft more transferable adversarial
examples against both normally trained and defense models. Specifically, we
apply a spectrum transformation to the input and thus perform the model
augmentation in the frequency domain. We theoretically prove that the
transformation derived from frequency domain leads to a diverse spectrum
saliency map, an indicator we proposed to reflect the diversity of substitute
models. Notably, our method can be generally combined with existing attacks.
Extensive experiments on the ImageNet dataset demonstrate the effectiveness of
our method, \textit{e.g.}, attacking nine state-of-the-art defense models with
an average success rate of \textbf{95.4\%}. Our code is available in
\url{https://github.com/yuyang-long/SSA}.
</p></li>
</ul>

<h3>Title: Backdoor Attacks on Crowd Counting. (arXiv:2207.05641v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05641">http://arxiv.org/abs/2207.05641</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Crowd counting is a regression task that estimates the number of people in a
scene image, which plays a vital role in a range of safety-critical
applications, such as video surveillance, traffic monitoring and flow control.
In this paper, we investigate the vulnerability of deep learning based crowd
counting models to backdoor attacks, a major security threat to deep learning.
A backdoor attack implants a backdoor trigger into a target model via data
poisoning so as to control the model's predictions at test time. Different from
image classification models on which most of existing backdoor attacks have
been developed and tested, crowd counting models are regression models that
output multi-dimensional density maps, thus requiring different techniques to
manipulate.
</p></li>
</ul>

<p>In this paper, we propose two novel Density Manipulation Backdoor Attacks
(DMBA$^{-}$ and DMBA$^{+}$) to attack the model to produce arbitrarily large or
small density estimations. Experimental results demonstrate the effectiveness
of our DMBA attacks on five classic crowd counting models and four types of
datasets. We also provide an in-depth analysis of the unique challenges of
backdooring crowd counting models and reveal two key elements of effective
attacks: 1) full and dense triggers and 2) manipulation of the ground truth
counts or density maps. Our work could help evaluate the vulnerability of crowd
counting models to potential backdoor attacks.
</p>

<h3>Title: Physical Passive Patch Adversarial Attacks on Visual Odometry Systems. (arXiv:2207.05729v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05729">http://arxiv.org/abs/2207.05729</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Deep neural networks are known to be susceptible to adversarial perturbations
-- small perturbations that alter the output of the network and exist under
strict norm limitations. While such perturbations are usually discussed as
tailored to a specific input, a universal perturbation can be constructed to
alter the model's output on a set of inputs. Universal perturbations present a
more realistic case of adversarial attacks, as awareness of the model's exact
input is not required. In addition, the universal attack setting raises the
subject of generalization to unseen data, where given a set of inputs, the
universal perturbations aim to alter the model's output on out-of-sample data.
In this work, we study physical passive patch adversarial attacks on visual
odometry-based autonomous navigation systems. A visual odometry system aims to
infer the relative camera motion between two corresponding viewpoints, and is
frequently used by vision-based autonomous navigation systems to estimate their
state. For such navigation systems, a patch adversarial perturbation poses a
severe security issue, as it can be used to mislead a system onto some
collision course. To the best of our knowledge, we show for the first time that
the error margin of a visual odometry model can be significantly increased by
deploying patch adversarial attacks in the scene. We provide evaluation on
synthetic closed-loop drone navigation data and demonstrate that a comparable
vulnerability exists in real data. A reference implementation of the proposed
method and the reported experiments is provided at
https://github.com/patchadversarialattacks/patchadversarialattacks.
</p></li>
</ul>

<h3>Title: Opportunistic Wiretapping/Jamming: A New Attack Model in Millimeter-Wave Wireless Networks. (arXiv:2207.05383v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05383">http://arxiv.org/abs/2207.05383</a></li>
<li>Code URL: null</li>
<li>Summary: <p>While the millimeter-wave (mmWave) communication is robust against the
conventional wiretapping attack due to its short transmission range and
directivity, this paper proposes a new opportunistic wiretapping and jamming
(OWJ) attack model in mmWave wireless networks. With OWJ, an eavesdropper can
opportunistically conduct wiretapping or jamming to initiate a more hazardous
attack based on the instantaneous costs of wiretapping and jamming. We also
provide three realizations of the OWJ attack, which are mainly determined by
the cost models relevant to distance, path loss and received power,
respectively. To understand the impact of the new attack on mmWave network
security, we first develop novel approximation techniques to characterize the
irregular distributions of wiretappers, jammers and interferers under three OWJ
realizations. With the help of the results of node distributions, we then
derive analytical expressions for the secrecy transmission capacity to depict
the network security performance under OWJ. Finally, we provide extensive
numerical results to illustrate the effect of OWJ and to demonstrate that the
new attack can more significantly degrade the network security performance than
the pure wiretapping or jamming attack.
</p></li>
</ul>

<h3>Title: Practical Attacks on Machine Learning: A Case Study on Adversarial Windows Malware. (arXiv:2207.05548v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05548">http://arxiv.org/abs/2207.05548</a></li>
<li>Code URL: null</li>
<li>Summary: <p>While machine learning is vulnerable to adversarial examples, it still lacks
systematic procedures and tools for evaluating its security in different
application contexts. In this article, we discuss how to develop automated and
scalable security evaluations of machine learning using practical attacks,
reporting a use case on Windows malware detection.
</p></li>
</ul>

<h3>Title: Attacking (and defending) the Maritime Radar System. (arXiv:2207.05623v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05623">http://arxiv.org/abs/2207.05623</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Operation of radar equipment is one of the key facilities used by navigators
to gather situational awareness about their surroundings. With an ever
increasing need for always-running logistics and tighter shipping schedules,
operators are relying more and more on computerized instruments and their
indications. As a result, modern ships have become a complex cyber-physical
system in which sensors and computers constantly communicate and coordinate. In
this work, we discuss novel threats related to the radar system, which is one
of the most security-sensitive component on a ship. In detail, we first discuss
some new attacks capable of compromising the integrity of data displayed on a
radar system, with potentially catastrophic impacts on the crew' situational
awareness or even safety itself. Then, we present a detection system aimed at
highlighting anomalies in the radar video feed, requiring no modifications to
the target ship configuration. Finally, we stimulate our detection system by
performing the attacks inside of a simulated environment. The experimental
results clearly indicate that the attacks are feasible, rather easy to carry
out, and hard-to-detect. Moreover, they prove that the proposed detection
technique is effective.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: RUSH: Robust Contrastive Learning via Randomized Smoothing. (arXiv:2207.05127v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05127">http://arxiv.org/abs/2207.05127</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Recently, adversarial training has been incorporated in self-supervised
contrastive pre-training to augment label efficiency with exciting adversarial
robustness. However, the robustness came at a cost of expensive adversarial
training. In this paper, we show a surprising fact that contrastive
pre-training has an interesting yet implicit connection with robustness, and
such natural robustness in the pre trained representation enables us to design
a powerful robust algorithm against adversarial attacks, RUSH, that combines
the standard contrastive pre-training and randomized smoothing. It boosts both
standard accuracy and robust accuracy, and significantly reduces training costs
as compared with adversarial training. We use extensive empirical studies to
show that the proposed RUSH outperforms robust classifiers from adversarial
training, by a significant margin on common benchmarks (CIFAR-10, CIFAR-100,
and STL-10) under first-order attacks. In particular, under
$\ell_{\infty}$-norm perturbations of size 8/255 PGD attack on CIFAR-10, our
model using ResNet-18 as backbone reached 77.8% robust accuracy and 87.9%
standard accuracy. Our work has an improvement of over 15% in robust accuracy
and a slight improvement in standard accuracy, compared to the
state-of-the-arts.
</p></li>
</ul>

<h3>Title: Patch-level instance-group discrimination with pretext-invariant learning for colitis scoring. (arXiv:2207.05192v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05192">http://arxiv.org/abs/2207.05192</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Inflammatory bowel disease (IBD), in particular ulcerative colitis (UC), is
graded by endoscopists and this assessment is the basis for risk stratification
and therapy monitoring. Presently, endoscopic characterisation is largely
operator dependant leading to sometimes undesirable clinical outcomes for
patients with IBD. We focus on the Mayo Endoscopic Scoring (MES) system which
is widely used but requires the reliable identification of subtle changes in
mucosal inflammation. Most existing deep learning classification methods cannot
detect these fine-grained changes which make UC grading such a challenging
task. In this work, we introduce a novel patch-level instance-group
discrimination with pretext-invariant representation learning (PLD-PIRL) for
self-supervised learning (SSL). Our experiments demonstrate both improved
accuracy and robustness compared to the baseline supervised network and several
state-of-the-art SSL methods. Compared to the baseline (ResNet50) supervised
classification our proposed PLD-PIRL obtained an improvement of 4.75% on
hold-out test data and 6.64% on unseen center test data for top-1 accuracy.
</p></li>
</ul>

<h3>Title: Real-Time And Robust 3D Object Detection with Roadside LiDARs. (arXiv:2207.05200v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05200">http://arxiv.org/abs/2207.05200</a></li>
<li>Code URL: null</li>
<li>Summary: <p>This work aims to address the challenges in autonomous driving by focusing on
the 3D perception of the environment using roadside LiDARs. We design a 3D
object detection model that can detect traffic participants in roadside LiDARs
in real-time. Our model uses an existing 3D detector as a baseline and improves
its accuracy. To prove the effectiveness of our proposed modules, we train and
evaluate the model on three different vehicle and infrastructure datasets. To
show the domain adaptation ability of our detector, we train it on an
infrastructure dataset from China and perform transfer learning on a different
dataset recorded in Germany. We do several sets of experiments and ablation
studies for each module in the detector that show that our model outperforms
the baseline by a significant margin, while the inference speed is at 45 Hz (22
ms). We make a significant contribution with our LiDAR-based 3D detector that
can be used for smart city applications to provide connected and automated
vehicles with a far-reaching view. Vehicles that are connected to the roadside
sensors can get information about other vehicles around the corner to improve
their path and maneuver planning and to increase road traffic safety.
</p></li>
</ul>

<h3>Title: Accelerating Certifiable Estimation with Preconditioned Eigensolvers. (arXiv:2207.05257v1 [cs.RO])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05257">http://arxiv.org/abs/2207.05257</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Convex (specifically semidefinite) relaxation provides a powerful approach to
constructing robust machine perception systems, enabling the recovery of
certifiably globally optimal solutions of challenging estimation problems in
many practical settings. However, solving the large-scale semidefinite
relaxations underpinning this approach remains a formidable computational
challenge. A dominant cost in many state-of-the-art (Burer-Monteiro
factorization-based) certifiable estimation methods is solution verification
(testing the global optimality of a given candidate solution), which entails
computing a minimum eigenpair of a certain symmetric certificate matrix. In
this paper, we show how to significantly accelerate this verification step, and
thereby the overall speed of certifiable estimation methods. First, we show
that the certificate matrices arising in the Burer-Monteiro approach
generically possess spectra that make the verification problem expensive to
solve using standard iterative eigenvalue methods. We then show how to address
this challenge using preconditioned eigensolvers; specifically, we design a
specialized solution verification algorithm based upon the locally optimal
block preconditioned conjugate gradient (LOBPCG) method together with a simple
yet highly effective algebraic preconditioner. Experimental evaluation on a
variety of simulated and real-world examples shows that our proposed
verification scheme is very effective in practice, accelerating solution
verification by up to 280x, and the overall Burer-Monteiro method by up to 16x,
versus the standard Lanczos method when applied to relaxations derived from
large-scale SLAM benchmarks.
</p></li>
</ul>

<h3>Title: Cross-Architecture Knowledge Distillation. (arXiv:2207.05273v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05273">http://arxiv.org/abs/2207.05273</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Transformer attracts much attention because of its ability to learn global
relations and superior performance. In order to achieve higher performance, it
is natural to distill complementary knowledge from Transformer to convolutional
neural network (CNN). However, most existing knowledge distillation methods
only consider homologous-architecture distillation, such as distilling
knowledge from CNN to CNN. They may not be suitable when applying to
cross-architecture scenarios, such as from Transformer to CNN. To deal with
this problem, a novel cross-architecture knowledge distillation method is
proposed. Specifically, instead of directly mimicking output/intermediate
features of the teacher, a partially cross attention projector and a group-wise
linear projector are introduced to align the student features with the
teacher's in two projected feature spaces. And a multi-view robust training
scheme is further presented to improve the robustness and stability of the
framework. Extensive experiments show that the proposed method outperforms 14
state-of-the-arts on both small-scale and large-scale datasets.
</p></li>
</ul>

<h3>Title: Towards Hard-Positive Query Mining for DETR-based Human-Object Interaction Detection. (arXiv:2207.05293v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05293">http://arxiv.org/abs/2207.05293</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Human-Object Interaction (HOI) detection is a core task for high-level image
understanding. Recently, Detection Transformer (DETR)-based HOI detectors have
become popular due to their superior performance and efficient structure.
However, these approaches typically adopt fixed HOI queries for all testing
images, which is vulnerable to the location change of objects in one specific
image. Accordingly, in this paper, we propose to enhance DETR's robustness by
mining hard-positive queries, which are forced to make correct predictions
using partial visual cues. First, we explicitly compose hard-positive queries
according to the ground-truth (GT) position of labeled human-object pairs for
each training image. Specifically, we shift the GT bounding boxes of each
labeled human-object pair so that the shifted boxes cover only a certain
portion of the GT ones. We encode the coordinates of the shifted boxes for each
labeled human-object pair into an HOI query. Second, we implicitly construct
another set of hard-positive queries by masking the top scores in
cross-attention maps of the decoder layers. The masked attention maps then only
cover partial important cues for HOI predictions. Finally, an alternate
strategy is proposed that efficiently combines both types of hard queries. In
each iteration, both DETR's learnable queries and one selected type of
hard-positive queries are adopted for loss computation. Experimental results
show that our proposed approach can be widely applied to existing DETR-based
HOI detectors. Moreover, we consistently achieve state-of-the-art performance
on three benchmarks: HICO-DET, V-COCO, and HOI-A. Code is available at
https://github.com/MuchHair/HQM.
</p></li>
</ul>

<h3>Title: CPO: Change Robust Panorama to Point Cloud Localization. (arXiv:2207.05317v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05317">http://arxiv.org/abs/2207.05317</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We present CPO, a fast and robust algorithm that localizes a 2D panorama with
respect to a 3D point cloud of a scene possibly containing changes. To robustly
handle scene changes, our approach deviates from conventional feature point
matching, and focuses on the spatial context provided from panorama images.
Specifically, we propose efficient color histogram generation and subsequent
robust localization using score maps. By utilizing the unique equivariance of
spherical projections, we propose very fast color histogram generation for a
large number of camera poses without explicitly rendering images for all
candidate poses. We accumulate the regional consistency of the panorama and
point cloud as 2D/3D score maps, and use them to weigh the input color values
to further increase robustness. The weighted color distribution quickly finds
good initial poses and achieves stable convergence for gradient-based
optimization. CPO is lightweight and achieves effective localization in all
tested scenarios, showing stable performance despite scene changes, repetitive
structures, or featureless regions, which are typical challenges for visual
localization with perspective cameras.
</p></li>
</ul>

<h3>Title: Certified Adversarial Robustness via Anisotropic Randomized Smoothing. (arXiv:2207.05327v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05327">http://arxiv.org/abs/2207.05327</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Randomized smoothing has achieved great success for certified robustness
against adversarial perturbations. Given any arbitrary classifier, randomized
smoothing can guarantee the classifier's prediction over the perturbed input
with provable robustness bound by injecting noise into the classifier. However,
all of the existing methods rely on fixed i.i.d. probability distribution to
generate noise for all dimensions of the data (e.g., all the pixels in an
image), which ignores the heterogeneity of inputs and data dimensions. Thus,
existing randomized smoothing methods cannot provide optimal protection for all
the inputs. To address this limitation, we propose the first anisotropic
randomized smoothing method which ensures provable robustness guarantee based
on pixel-wise noise distributions. Also, we design a novel CNN-based noise
generator to efficiently fine-tune the pixel-wise noise distributions for all
the pixels in each input. Experimental results demonstrate that our method
significantly outperforms the state-of-the-art randomized smoothing methods.
</p></li>
</ul>

<h3>Title: Cycle Self-Training for Semi-Supervised Object Detection with Distribution Consistency Reweighting. (arXiv:2207.05334v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05334">http://arxiv.org/abs/2207.05334</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Recently, many semi-supervised object detection (SSOD) methods adopt
teacher-student framework and have achieved state-of-the-art results. However,
the teacher network is tightly coupled with the student network since the
teacher is an exponential moving average (EMA) of the student, which causes a
performance bottleneck. To address the coupling problem, we propose a Cycle
Self-Training (CST) framework for SSOD, which consists of two teachers T1 and
T2, two students S1 and S2. Based on these networks, a cycle self-training
mechanism is built, i.e.,
S1${\rightarrow}$T1${\rightarrow}$S2${\rightarrow}$T2${\rightarrow}$S1. For
S${\rightarrow}$T, we also utilize the EMA weights of the students to update
the teachers. For T${\rightarrow}$S, instead of providing supervision for its
own student S1(S2) directly, the teacher T1(T2) generates pseudo-labels for the
student S2(S1), which looses the coupling effect. Moreover, owing to the
property of EMA, the teacher is most likely to accumulate the biases from the
student and make the mistakes irreversible. To mitigate the problem, we also
propose a distribution consistency reweighting strategy, where pseudo-labels
are reweighted based on distribution consistency across the teachers T1 and T2.
With the strategy, the two students S2 and S1 can be trained robustly with
noisy pseudo labels to avoid confirmation biases. Extensive experiments prove
the superiority of CST by consistently improving the AP over the baseline and
outperforming state-of-the-art methods by 2.1% absolute AP improvements with
scarce labeled data.
</p></li>
</ul>

<h3>Title: eX-ViT: A Novel eXplainable Vision Transformer for Weakly Supervised Semantic Segmentation. (arXiv:2207.05358v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05358">http://arxiv.org/abs/2207.05358</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Recently vision transformer models have become prominent models for a range
of vision tasks. These models, however, are usually opaque with weak feature
interpretability. Moreover, there is no method currently built for an
intrinsically interpretable transformer, which is able to explain its reasoning
process and provide a faithful explanation. To close these crucial gaps, we
propose a novel vision transformer dubbed the eXplainable Vision Transformer
(eX-ViT), an intrinsically interpretable transformer model that is able to
jointly discover robust interpretable features and perform the prediction.
Specifically, eX-ViT is composed of the Explainable Multi-Head Attention
(E-MHA) module, the Attribute-guided Explainer (AttE) module and the
self-supervised attribute-guided loss. The E-MHA tailors explainable attention
weights that are able to learn semantically interpretable representations from
local patches in terms of model decisions with noise robustness. Meanwhile,
AttE is proposed to encode discriminative attribute features for the target
object through diverse attribute discovery, which constitutes faithful evidence
for the model's predictions. In addition, a self-supervised attribute-guided
loss is developed for our eX-ViT, which aims at learning enhanced
representations through the attribute discriminability mechanism and attribute
diversity mechanism, to localize diverse and discriminative attributes and
generate more robust explanations. As a result, we can uncover faithful and
robust interpretations with diverse attributes through the proposed eX-ViT.
</p></li>
</ul>

<h3>Title: CP3: Unifying Point Cloud Completion by Pretrain-Prompt-Predict Paradigm. (arXiv:2207.05359v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05359">http://arxiv.org/abs/2207.05359</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Point cloud completion aims to predict complete shape from its partial
observation. Current approaches mainly consist of generation and refinement
stages in a coarse-to-fine style. However, the generation stage often lacks
robustness to tackle different incomplete variations, while the refinement
stage blindly recovers point clouds without the semantic awareness. To tackle
these challenges, we unify point cloud Completion by a generic
Pretrain-Prompt-Predict paradigm, namely CP3. Inspired by prompting approaches
from NLP, we creatively reinterpret point cloud generation and refinement as
the prompting and predicting stages, respectively. Then, we introduce a concise
self-supervised pretraining stage before prompting. It can effectively increase
robustness of point cloud generation, by an Incompletion-Of-Incompletion (IOI)
pretext task. Moreover, we develop a novel Semantic Conditional Refinement
(SCR) network at the predicting stage. It can discriminatively modulate
multi-scale refinement with the guidance of semantics. Finally, extensive
experiments demonstrate that our CP3 outperforms the state-of-the-art methods
with a large margin.
</p></li>
</ul>

<h3>Title: Occluded Human Body Capture with Self-Supervised Spatial-Temporal Motion Prior. (arXiv:2207.05375v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05375">http://arxiv.org/abs/2207.05375</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Although significant progress has been achieved on monocular maker-less human
motion capture in recent years, it is still hard for state-of-the-art methods
to obtain satisfactory results in occlusion scenarios. There are two main
reasons: the one is that the occluded motion capture is inherently ambiguous as
various 3D poses can map to the same 2D observations, which always results in
an unreliable estimation. The other is that no sufficient occluded human data
can be used for training a robust model. To address the obstacles, our key-idea
is to employ non-occluded human data to learn a joint-level spatial-temporal
motion prior for occluded human with a self-supervised strategy. To further
reduce the gap between synthetic and real occlusion data, we build the first 3D
occluded motion dataset~(OcMotion), which can be used for both training and
testing. We encode the motions in 2D maps and synthesize occlusions on
non-occluded data for the self-supervised training. A spatial-temporal layer is
then designed to learn joint-level correlations. The learned prior reduces the
ambiguities of occlusions and is robust to diverse occlusion types, which is
then adopted to assist the occluded human motion capture. Experimental results
show that our method can generate accurate and coherent human motions from
occluded videos with good generalization ability and runtime efficiency. The
dataset and code are publicly available at
\url{https://github.com/boycehbz/CHOMP}.
</p></li>
</ul>

<h3>Title: Wound Segmentation with Dynamic Illumination Correction and Dual-view Semantic Fusion. (arXiv:2207.05388v1 [eess.IV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05388">http://arxiv.org/abs/2207.05388</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Wound image segmentation is a critical component for the clinical diagnosis
and in-time treatment of wounds. Recently, deep learning has become the
mainstream methodology for wound image segmentation. However, the
pre-processing of the wound image, such as the illumination correction, is
required before the training phase as the performance can be greatly improved.
The correction procedure and the training of deep models are independent of
each other, which leads to sub-optimal segmentation performance as the fixed
illumination correction may not be suitable for all images. To address
aforementioned issues, an end-to-end dual-view segmentation approach was
proposed in this paper, by incorporating a learn-able illumination correction
module into the deep segmentation models. The parameters of the module can be
learned and updated during the training stage automatically, while the
dual-view fusion can fully employ the features from both the raw images and the
enhanced ones. To demonstrate the effectiveness and robustness of the proposed
framework, the extensive experiments are conducted on the benchmark datasets.
The encouraging results suggest that our framework can significantly improve
the segmentation performance, compared to the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Improving Domain Generalization by Learning without Forgetting: Application in Retail Checkout. (arXiv:2207.05422v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05422">http://arxiv.org/abs/2207.05422</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Designing an automatic checkout system for retail stores at the human level
accuracy is challenging due to similar appearance products and their various
poses. This paper addresses the problem by proposing a method with a two-stage
pipeline. The first stage detects class-agnostic items, and the second one is
dedicated to classify product categories. We also track the objects across
video frames to avoid duplicated counting. One major challenge is the domain
gap because the models are trained on synthetic data but tested on the real
images. To reduce the error gap, we adopt domain generalization methods for the
first-stage detector. In addition, model ensemble is used to enhance the
robustness of the 2nd-stage classifier. The method is evaluated on the AI City
challenge 2022 -- Track 4 and gets the F1 score $40\%$ on the test A set. Code
is released at the link https://github.com/cybercore-co-ltd/aicity22-track4.
</p></li>
</ul>

<h3>Title: On the Effects of Image Quality Degradation on Minutiae- and Ridge-Based Automatic Fingerprint Recognition. (arXiv:2207.05447v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05447">http://arxiv.org/abs/2207.05447</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The effect of image quality degradation on the verification performance of
automatic fingerprint recognition is investigated. We study the performance of
two fingerprint matchers based on minutiae and ridge information under varying
fingerprint image quality. The ridge-based system is found to be more robust to
image quality degradation than the minutiae-based system for a number of
different image quality criteria.
</p></li>
</ul>

<h3>Title: Transferability-Guided Cross-Domain Cross-Task Transfer Learning. (arXiv:2207.05510v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05510">http://arxiv.org/abs/2207.05510</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We propose two novel transferability metrics F-OTCE (Fast Optimal Transport
based Conditional Entropy) and JC-OTCE (Joint Correspondence OTCE) to evaluate
how much the source model (task) can benefit the learning of the target task
and to learn more transferable representations for cross-domain cross-task
transfer learning. Unlike the existing metric that requires evaluating the
empirical transferability on auxiliary tasks, our metrics are auxiliary-free
such that they can be computed much more efficiently. Specifically, F-OTCE
estimates transferability by first solving an Optimal Transport (OT) problem
between source and target distributions, and then uses the optimal coupling to
compute the Negative Conditional Entropy between source and target labels. It
can also serve as a loss function to maximize the transferability of the source
model before finetuning on the target task. Meanwhile, JC-OTCE improves the
transferability robustness of F-OTCE by including label distances in the OT
problem, though it may incur additional computation cost. Extensive experiments
demonstrate that F-OTCE and JC-OTCE outperform state-of-the-art auxiliary-free
metrics by 18.85% and 28.88%, respectively in correlation coefficient with the
ground-truth transfer accuracy. By eliminating the training cost of auxiliary
tasks, the two metrics reduces the total computation time of the previous
method from 43 minutes to 9.32s and 10.78s, respectively, for a pair of tasks.
When used as a loss function, F-OTCE shows consistent improvements on the
transfer accuracy of the source model in few-shot classification experiments,
with up to 4.41% accuracy gain.
</p></li>
</ul>

<h3>Title: Online Video Instance Segmentation via Robust Context Fusion. (arXiv:2207.05580v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05580">http://arxiv.org/abs/2207.05580</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Video instance segmentation (VIS) aims at classifying, segmenting and
tracking object instances in video sequences. Recent transformer-based neural
networks have demonstrated their powerful capability of modeling
spatio-temporal correlations for the VIS task. Relying on video- or clip-level
input, they suffer from high latency and computational cost. We propose a
robust context fusion network to tackle VIS in an online fashion, which
predicts instance segmentation frame-by-frame with a few preceding frames. To
acquire the precise and temporal-consistent prediction for each frame
efficiently, the key idea is to fuse effective and compact context from
reference frames into the target frame. Considering the different effects of
reference and target frames on the target prediction, we first summarize
contextual features through importance-aware compression. A transformer encoder
is adopted to fuse the compressed context. Then, we leverage an
order-preserving instance embedding to convey the identity-aware information
and correspond the identities to predicted instance masks. We demonstrate that
our robust fusion network achieves the best performance among existing online
VIS methods and is even better than previously published clip-level methods on
the Youtube-VIS 2019 and 2021 benchmarks. In addition, visual objects often
have acoustic signatures that are naturally synchronized with them in
audio-bearing video recordings. By leveraging the flexibility of our context
fusion network on multi-modal data, we further investigate the influence of
audios on the video-dense prediction task, which has never been discussed in
existing works. We build up an Audio-Visual Instance Segmentation dataset, and
demonstrate that acoustic signals in the wild scenarios could benefit the VIS
task.
</p></li>
</ul>

<h3>Title: PC$^2$-PU: Patch Correlation and Point Correlation for Effective Point Cloud Upsampling. (arXiv:2109.09337v3 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2109.09337">http://arxiv.org/abs/2109.09337</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Point cloud upsampling is to densify a sparse point set acquired from 3D
sensors, providing a denser representation for the underlying surface. Existing
methods divide the input points into small patches and upsample each patch
separately, however, ignoring the global spatial consistency between patches.
In this paper, we present a novel method PC$^2$-PU, which explores
patch-to-patch and point-to-point correlations for more effective and robust
point cloud upsampling. Specifically, our network has two appealing designs:
(i) We take adjacent patches as supplementary inputs to compensate the loss
structure information within a single patch and introduce a Patch Correlation
Module to capture the difference and similarity between patches. (ii) After
augmenting each patch's geometry, we further introduce a Point Correlation
Module to reveal the relationship of points inside each patch to maintain the
local spatial consistency. Extensive experiments on both synthetic and real
scanned datasets demonstrate that our method surpasses previous upsampling
methods, particularly with the noisy inputs. The code and data are at
\url{https://github.com/chenlongwhu/PC2-PU.git}.
</p></li>
</ul>

<h3>Title: diffConv: Analyzing Irregular Point Clouds with an Irregular View. (arXiv:2111.14658v3 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2111.14658">http://arxiv.org/abs/2111.14658</a></li>
<li>Code URL: <a href="https://github.com/mmmmimic/diffconvnet">https://github.com/mmmmimic/diffconvnet</a></li>
<li>Summary: <p>Standard spatial convolutions assume input data with a regular neighborhood
structure. Existing methods typically generalize convolution to the irregular
point cloud domain by fixing a regular "view" through e.g. a fixed neighborhood
size, where the convolution kernel size remains the same for each point.
However, since point clouds are not as structured as images, the fixed neighbor
number gives an unfortunate inductive bias. We present a novel graph
convolution named Difference Graph Convolution (diffConv), which does not rely
on a regular view. diffConv operates on spatially-varying and density-dilated
neighborhoods, which are further adapted by a learned masked attention
mechanism. Experiments show that our model is very robust to the noise,
obtaining state-of-the-art performance in 3D shape classification and scene
understanding tasks, along with a faster inference speed.
</p></li>
</ul>

<h3>Title: Transform your Smartphone into a DSLR Camera: Learning the ISP in the Wild. (arXiv:2203.10636v4 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2203.10636">http://arxiv.org/abs/2203.10636</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We propose a trainable Image Signal Processing (ISP) framework that produces
DSLR quality images given RAW images captured by a smartphone. To address the
color misalignments between training image pairs, we employ a color-conditional
ISP network and optimize a novel parametric color mapping between each input
RAW and reference DSLR image. During inference, we predict the target color
image by designing a color prediction network with efficient Global Context
Transformer modules. The latter effectively leverage global information to
learn consistent color and tone mappings. We further propose a robust masked
aligned loss to identify and discard regions with inaccurate motion estimation
during training. Lastly, we introduce the ISP in the Wild (ISPW) dataset,
consisting of weakly paired phone RAW and DSLR sRGB images. We extensively
evaluate our method, setting a new state-of-the-art on two datasets.
</p></li>
</ul>

<h3>Title: Improving the Robustness and Generalization of Deep Neural Network with Confidence Threshold Reduction. (arXiv:2206.00913v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2206.00913">http://arxiv.org/abs/2206.00913</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Deep neural networks are easily attacked by imperceptible perturbation.
Presently, adversarial training (AT) is the most effective method to enhance
the robustness of the model against adversarial examples. However, because
adversarial training solved a min-max value problem, in comparison with natural
training, the robustness and generalization are contradictory, i.e., the
robustness improvement of the model will decrease the generalization of the
model. To address this issue, in this paper, a new concept, namely confidence
threshold (CT), is introduced and the reducing of the confidence threshold,
known as confidence threshold reduction (CTR), is proven to improve both the
generalization and robustness of the model. Specifically, to reduce the CT for
natural training (i.e., for natural training with CTR), we propose a
mask-guided divergence loss function (MDL) consisting of a cross-entropy loss
term and an orthogonal term. The empirical and theoretical analysis
demonstrates that the MDL loss improves the robustness and generalization of
the model simultaneously for natural training. However, the model robustness
improvement of natural training with CTR is not comparable to that of
adversarial training. Therefore, for adversarial training, we propose a
standard deviation loss function (STD), which minimizes the difference in the
probabilities of the wrong categories, to reduce the CT by being integrated
into the loss function of adversarial training. The empirical and theoretical
analysis demonstrates that the STD based loss function can further improve the
robustness of the adversarially trained model on basis of guaranteeing the
changeless or slight improvement of the natural accuracy.
</p></li>
</ul>

<h3>Title: Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment. (arXiv:2203.15937v3 [eess.AS] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2203.15937">http://arxiv.org/abs/2203.15937</a></li>
<li>Code URL: <a href="https://github.com/mu-y/mpl-mdd">https://github.com/mu-y/mpl-mdd</a></li>
<li>Summary: <p>Current leading mispronunciation detection and diagnosis (MDD) systems
achieve promising performance via end-to-end phoneme recognition. One challenge
of such end-to-end solutions is the scarcity of human-annotated phonemes on
natural L2 speech. In this work, we leverage unlabeled L2 speech via a
pseudo-labeling (PL) procedure and extend the fine-tuning approach based on
pre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec
2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples
plus the created pseudo-labeled L2 speech samples. Our pseudo labels are
dynamic and are produced by an ensemble of the online model on-the-fly, which
ensures that our model is robust to pseudo label noise. We show that
fine-tuning with pseudo labels achieves a 5.35% phoneme error rate reduction
and 2.48% MDD F1 score improvement over a labeled-samples-only fine-tuning
baseline. The proposed PL method is also shown to outperform conventional
offline PL methods. Compared to the state-of-the-art MDD systems, our MDD
solution produces a more accurate and consistent phonetic error diagnosis. In
addition, we conduct an open test on a separate UTD-4Accents dataset, where our
system recognition outputs show a strong correlation with human perception,
based on accentedness and intelligibility.
</p></li>
</ul>

<h3>Title: Grounding Aleatoric Uncertainty in Unsupervised Environment Design. (arXiv:2207.05219v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05219">http://arxiv.org/abs/2207.05219</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Adaptive curricula in reinforcement learning (RL) have proven effective for
producing policies robust to discrepancies between the train and test
environment. Recently, the Unsupervised Environment Design (UED) framework
generalized RL curricula to generating sequences of entire environments,
leading to new methods with robust minimax regret properties. Problematically,
in partially-observable or stochastic settings, optimal policies may depend on
the ground-truth distribution over aleatoric parameters of the environment in
the intended deployment setting, while curriculum learning necessarily shifts
the training distribution. We formalize this phenomenon as curriculum-induced
covariate shift (CICS), and describe how its occurrence in aleatoric parameters
can lead to suboptimal policies. Directly sampling these parameters from the
ground-truth distribution avoids the issue, but thwarts curriculum learning. We
propose SAMPLR, a minimax regret UED method that optimizes the ground-truth
utility function, even when the underlying training data is biased due to CICS.
We prove, and validate on challenging domains, that our approach preserves
optimality under the ground-truth distribution, while promoting robustness
across the full range of environment settings.
</p></li>
</ul>

<h3>Title: Adversarial Robustness Assessment of NeuroEvolution Approaches. (arXiv:2207.05451v1 [cs.NE])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05451">http://arxiv.org/abs/2207.05451</a></li>
<li>Code URL: null</li>
<li>Summary: <p>NeuroEvolution automates the generation of Artificial Neural Networks through
the application of techniques from Evolutionary Computation. The main goal of
these approaches is to build models that maximize predictive performance,
sometimes with an additional objective of minimizing computational complexity.
Although the evolved models achieve competitive results performance-wise, their
robustness to adversarial examples, which becomes a concern in
security-critical scenarios, has received limited attention. In this paper, we
evaluate the adversarial robustness of models found by two prominent
NeuroEvolution approaches on the CIFAR-10 image classification task: DENSER and
NSGA-Net. Since the models are publicly available, we consider white-box
untargeted attacks, where the perturbations are bounded by either the L2 or the
Linfinity-norm. Similarly to manually-designed networks, our results show that
when the evolved models are attacked with iterative methods, their accuracy
usually drops to, or close to, zero under both distance metrics. The DENSER
model is an exception to this trend, showing some resistance under the L2
threat model, where its accuracy only drops from 93.70% to 18.10% even with
iterative attacks. Additionally, we analyzed the impact of pre-processing
applied to the data before the first layer of the network. Our observations
suggest that some of these techniques can exacerbate the perturbations added to
the original inputs, potentially harming robustness. Thus, this choice should
not be neglected when automatically designing networks for applications where
adversarial attacks are prone to occur.
</p></li>
</ul>

<h3>Title: Brain-inspired Graph Spiking Neural Networks for Commonsense Knowledge Representation and Reasoning. (arXiv:2207.05561v1 [cs.NE])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05561">http://arxiv.org/abs/2207.05561</a></li>
<li>Code URL: null</li>
<li>Summary: <p>How neural networks in the human brain represent commonsense knowledge, and
complete related reasoning tasks is an important research topic in
neuroscience, cognitive science, psychology, and artificial intelligence.
Although the traditional artificial neural network using fixed-length vectors
to represent symbols has gained good performance in some specific tasks, it is
still a black box that lacks interpretability, far from how humans perceive the
world. Inspired by the grandmother-cell hypothesis in neuroscience, this work
investigates how population encoding and spiking timing-dependent plasticity
(STDP) mechanisms can be integrated into the learning of spiking neural
networks, and how a population of neurons can represent a symbol via guiding
the completion of sequential firing between different neuron populations. The
neuron populations of different communities together constitute the entire
commonsense knowledge graph, forming a giant graph spiking neural network.
Moreover, we introduced the Reward-modulated spiking timing-dependent
plasticity (R-STDP) mechanism to simulate the biological reinforcement learning
process and completed the related reasoning tasks accordingly, achieving
comparable accuracy and faster convergence speed than the graph convolutional
artificial neural networks. For the fields of neuroscience and cognitive
science, the work in this paper provided the foundation of computational
modeling for further exploration of the way the human brain represents
commonsense knowledge. For the field of artificial intelligence, this paper
indicated the exploration direction for realizing a more robust and
interpretable neural network by constructing a commonsense knowledge
representation and reasoning spiking neural networks with solid biological
plausibility.
</p></li>
</ul>

<h3>Title: Long Short-Term Memory to predict 3D Amino acids Positions in GPCR Molecular Dynamics. (arXiv:2207.05682v1 [q-bio.BM])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05682">http://arxiv.org/abs/2207.05682</a></li>
<li>Code URL: null</li>
<li>Summary: <p>G-Protein Coupled Receptors (GPCRs) are a big family of eukaryotic cell
transmembrane proteins, responsible for numerous biological processes. From a
practical viewpoint around 34\% of the drugs approved by the US Food and Drug
Administration target these receptors. They can be analyzed from their
simulated molecular dynamics, including the prediction of their behavior in the
presence of drugs. In this paper, the capability of Long Short-Term Memory
Networks (LSTMs) are evaluated to learn and predict the molecular dynamic
trajectories of a receptor. Several models were trained with the 3D position of
the amino acids of the receptor considering different transformations on the
position of the amino acid, such as their centers of mass, the geometric
centers and the position of the $\alpha$--carbon for each amino acid. The error
of the prediction of the position was evaluated by the mean average error (MAE)
and root-mean-square deviation (RMSD). The LSTM models show a robust
performance, with results comparable to the state-of-the-art in non-dynamic 3D
predictions. The best MAE and RMSD values were found for the mass center of the
amino acids with 0.078 {\AA} and 0.156 {\AA} respectively. This work shows the
potential of LSTM to predict the molecular dynamics of GPRCs.
</p></li>
</ul>

<h3>Title: Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL. (arXiv:2207.05683v1 [cs.MA])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05683">http://arxiv.org/abs/2207.05683</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Cooperative multi-agent reinforcement learning (MARL) is making rapid
progress for solving tasks in a grid world and real-world scenarios, in which
agents are given different attributes and goals, resulting in different
behavior through the whole multi-agent task. In this study, we quantify the
agent's behavior difference and build its relationship with the policy
performance via {\bf Role Diversity}, a metric to measure the characteristics
of MARL tasks. We define role diversity from three perspectives: action-based,
trajectory-based, and contribution-based to fully measure a multi-agent task.
Through theoretical analysis, we find that the error bound in MARL can be
decomposed into three parts that have a strong relation to the role diversity.
The decomposed factors can significantly impact policy optimization on three
popular directions including parameter sharing, communication mechanism, and
credit assignment. The main experimental platforms are based on {\bf Multiagent
Particle Environment (MPE)} and {\bf The StarCraft Multi-Agent Challenge
(SMAC). Extensive experiments} clearly show that role diversity can serve as a
robust measurement for the characteristics of a multi-agent cooperation task
and help diagnose whether the policy fits the current multi-agent system for a
better policy performance.
</p></li>
</ul>

<h3>Title: Benchmarking of eight recurrent neural network variants for breath phase and adventitious sound detection on a self-developed open-access lung sound database-HF_Lung_V1. (arXiv:2102.03049v3 [cs.SD] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2102.03049">http://arxiv.org/abs/2102.03049</a></li>
<li>Code URL: null</li>
<li>Summary: <p>A reliable, remote, and continuous real-time respiratory sound monitor with
automated respiratory sound analysis ability is urgently required in many
clinical scenarios-such as in monitoring disease progression of coronavirus
disease 2019-to replace conventional auscultation with a handheld stethoscope.
However, a robust computerized respiratory sound analysis algorithm has not yet
been validated in practical applications. In this study, we developed a lung
sound database (HF_Lung_V1) comprising 9,765 audio files of lung sounds
(duration of 15 s each), 34,095 inhalation labels, 18,349 exhalation labels,
13,883 continuous adventitious sound (CAS) labels (comprising 8,457 wheeze
labels, 686 stridor labels, and 4,740 rhonchi labels), and 15,606 discontinuous
adventitious sound labels (all crackles). We conducted benchmark tests for long
short-term memory (LSTM), gated recurrent unit (GRU), bidirectional LSTM
(BiLSTM), bidirectional GRU (BiGRU), convolutional neural network (CNN)-LSTM,
CNN-GRU, CNN-BiLSTM, and CNN-BiGRU models for breath phase detection and
adventitious sound detection. We also conducted a performance comparison
between the LSTM-based and GRU-based models, between unidirectional and
bidirectional models, and between models with and without a CNN. The results
revealed that these models exhibited adequate performance in lung sound
analysis. The GRU-based models outperformed, in terms of F1 scores and areas
under the receiver operating characteristic curves, the LSTM-based models in
most of the defined tasks. Furthermore, all bidirectional models outperformed
their unidirectional counterparts. Finally, the addition of a CNN improved the
accuracy of lung sound analysis, especially in the CAS detection tasks.
</p></li>
</ul>

<h3>Title: Risk-averse autonomous systems: A brief history and recent developments from the perspective of optimal control. (arXiv:2109.08947v3 [cs.AI] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2109.08947">http://arxiv.org/abs/2109.08947</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We present an historical overview about the connections between the analysis
of risk and the control of autonomous systems. We offer two main contributions.
Our first contribution is to propose three overlapping paradigms to classify
the vast body of literature: the worst-case, risk-neutral, and risk-averse
paradigms. We consider an appropriate assessment for the risk of an autonomous
system to depend on the application at hand. In contrast, it is typical to
assess risk using an expectation, variance, or probability alone. Our second
contribution is to unify the concepts of risk and autonomous systems. We
achieve this by connecting approaches for quantifying and optimizing the risk
that arises from a system's behaviour across academic fields. The survey is
highly multidisciplinary. We include research from the communities of
reinforcement learning, stochastic and robust control theory, operations
research, and formal verification. We describe both model-based and model-free
methods, with emphasis on the former. Lastly, we highlight fruitful areas for
further research. A key direction is to blend risk-averse model-based and
model-free methods to enhance the real-time adaptive capabilities of systems to
improve human and environmental welfare.
</p></li>
</ul>

<h3>Title: Learning with Noisy Labels by Efficient Transition Matrix Estimation to Combat Label Miscorrection. (arXiv:2111.14932v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2111.14932">http://arxiv.org/abs/2111.14932</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Recent studies on learning with noisy labels have shown remarkable
performance by exploiting a small clean dataset. In particular, model agnostic
meta-learning-based label correction methods further improve performance by
correcting noisy labels on the fly. However, there is no safeguard on the label
miscorrection, resulting in unavoidable performance degradation. Moreover,
every training step requires at least three back-propagations, significantly
slowing down the training speed. To mitigate these issues, we propose a robust
and efficient method that learns a label transition matrix on the fly.
Employing the transition matrix makes the classifier skeptical about all the
corrected samples, which alleviates the miscorrection issue. We also introduce
a two-head architecture to efficiently estimate the label transition matrix
every iteration within a single back-propagation, so that the estimated matrix
closely follows the shifting noise distribution induced by label correction.
Extensive experiments demonstrate that our approach shows the best performance
in training efficiency while having comparable or better accuracy than existing
methods.
</p></li>
</ul>

<h3>Title: Integrated multimodal artificial intelligence framework for healthcare applications. (arXiv:2202.12998v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2202.12998">http://arxiv.org/abs/2202.12998</a></li>
<li>Code URL: <a href="https://github.com/lrsoenksen/haim">https://github.com/lrsoenksen/haim</a></li>
<li>Summary: <p>Artificial intelligence (AI) systems hold great promise to improve healthcare
over the next decades. Specifically, AI systems leveraging multiple data
sources and input modalities are poised to become a viable method to deliver
more accurate results and deployable pipelines across a wide range of
applications. In this work, we propose and evaluate a unified Holistic AI in
Medicine (HAIM) framework to facilitate the generation and testing of AI
systems that leverage multimodal inputs. Our approach uses generalizable data
pre-processing and machine learning modeling stages that can be readily adapted
for research and deployment in healthcare environments. We evaluate our HAIM
framework by training and characterizing 14,324 independent models based on
MIMIC-IV-MM, a multimodal clinical database (N=34,537 samples) containing 7,279
unique hospitalizations and 6,485 patients, spanning all possible input
combinations of 4 data modalities (i.e., tabular, time-series, text and
images), 11 unique data sources and 12 predictive tasks. We show that this
framework can consistently and robustly produce models that outperform similar
single-source approaches across various healthcare demonstrations (by 6-33%),
including 10 distinct chest pathology diagnoses, along with length-of-stay and
48-hour mortality predictions. We also quantify the contribution of each
modality and data source using Shapley values, which demonstrates the
heterogeneity in data type importance and the necessity of multimodal inputs
across different healthcare-relevant tasks. The generalizable properties and
flexibility of our Holistic AI in Medicine (HAIM) framework could offer a
promising pathway for future multimodal predictive systems in clinical and
operational healthcare settings.
</p></li>
</ul>

<h3>Title: TabSynDex: A Universal Metric for Robust Evaluation of Synthetic Tabular Data. (arXiv:2207.05295v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05295">http://arxiv.org/abs/2207.05295</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Synthetic tabular data generation becomes crucial when real data is limited,
expensive to collect, or simply cannot be used due to privacy concerns.
However, producing good quality synthetic data is challenging. Several
probabilistic, statistical, and generative adversarial networks (GANs) based
approaches have been presented for synthetic tabular data generation. Once
generated, evaluating the quality of the synthetic data is quite challenging.
Some of the traditional metrics have been used in the literature but there is
lack of a common, robust, and single metric. This makes it difficult to
properly compare the effectiveness of different synthetic tabular data
generation methods. In this paper we propose a new universal metric, TabSynDex,
for robust evaluation of synthetic data. TabSynDex assesses the similarity of
synthetic data with real data through different component scores which evaluate
the characteristics that are desirable for "high quality" synthetic data. Being
a single score metric, TabSynDex can also be used to observe and evaluate the
training of neural network based approaches. This would help in obtaining
insights that was not possible earlier. Further, we present several baseline
models for comparative analysis of the proposed evaluation metric with existing
generative models.
</p></li>
</ul>

<h3>Title: Bi-fidelity Evolutionary Multiobjective Search for Adversarially Robust Deep Neural Architectures. (arXiv:2207.05321v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05321">http://arxiv.org/abs/2207.05321</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Deep neural networks have been found vulnerable to adversarial attacks, thus
raising potentially concerns in security-sensitive contexts. To address this
problem, recent research has investigated the adversarial robustness of deep
neural networks from the architectural point of view. However, searching for
architectures of deep neural networks is computationally expensive,
particularly when coupled with adversarial training process. To meet the above
challenge, this paper proposes a bi-fidelity multiobjective neural architecture
search approach. First, we formulate the NAS problem for enhancing adversarial
robustness of deep neural networks into a multiobjective optimization problem.
Specifically, in addition to a low-fidelity performance predictor as the first
objective, we leverage an auxiliary-objective -- the value of which is the
output of a surrogate model trained with high-fidelity evaluations. Secondly,
we reduce the computational cost by combining three performance estimation
methods, i.e., parameter sharing, low-fidelity evaluation, and surrogate-based
predictor. The effectiveness of the proposed approach is confirmed by extensive
experiments conducted on CIFAR-10, CIFAR-100 and SVHN datasets.
</p></li>
</ul>

<h3>Title: Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning. (arXiv:2207.05480v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05480">http://arxiv.org/abs/2207.05480</a></li>
<li>Code URL: null</li>
<li>Summary: <p>In real-world robotics applications, Reinforcement Learning (RL) agents are
often unable to generalise to environment variations that were not observed
during training. This issue is intensified for image-based RL where a change in
one variable, such as the background colour, can change many pixels in the
image, and in turn can change all values in the agent's internal representation
of the image. To learn more robust representations, we introduce TEmporal
Disentanglement (TED), a self-supervised auxiliary task that leads to
disentangled representations using the sequential nature of RL observations. We
find empirically that RL algorithms with TED as an auxiliary task adapt more
quickly to changes in environment variables with continued training compared to
state-of-the-art representation learning methods. Due to the disentangled
structure of the representation, we also find that policies trained with TED
generalise better to unseen values of variables irrelevant to the task (e.g.
background colour) as well as unseen values of variables that affect the
optimal policy (e.g. goal positions).
</p></li>
</ul>

<h3>Title: Label-Efficient Self-Supervised Speaker Verification With Information Maximization and Contrastive Learning. (arXiv:2207.05506v1 [eess.AS])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05506">http://arxiv.org/abs/2207.05506</a></li>
<li>Code URL: null</li>
<li>Summary: <p>State-of-the-art speaker verification systems are inherently dependent on
some kind of human supervision as they are trained on massive amounts of
labeled data. However, manually annotating utterances is slow, expensive and
not scalable to the amount of data available today. In this study, we explore
self-supervised learning for speaker verification by learning representations
directly from raw audio. The objective is to produce robust speaker embeddings
that have small intra-speaker and large inter-speaker variance. Our approach is
based on recent information maximization learning frameworks and an intensive
data augmentation pre-processing step. We evaluate the ability of these methods
to work without contrastive samples before showing that they achieve better
performance when combined with a contrastive loss. Furthermore, we conduct
experiments to show that our method reaches competitive results compared to
existing techniques and can get better performances compared to a supervised
baseline when fine-tuned with a small portion of labeled data.
</p></li>
</ul>

<h3>Title: Hybrid Physical-Neural ODEs for Fast N-body Simulations. (arXiv:2207.05509v1 [astro-ph.CO])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05509">http://arxiv.org/abs/2207.05509</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We present a new scheme to compensate for the small-scales approximations
resulting from Particle-Mesh (PM) schemes for cosmological N-body simulations.
This kind of simulations are fast and low computational cost realizations of
the large scale structures, but lack resolution on small scales. To improve
their accuracy, we introduce an additional effective force within the
differential equations of the simulation, parameterized by a Fourier-space
Neural Network acting on the PM-estimated gravitational potential. We compare
the results for the matter power spectrum obtained to the ones obtained by the
PGD scheme (Potential gradient descent scheme). We notice a similar improvement
in term of power spectrum, but we find that our approach outperforms PGD for
the cross-correlation coefficients, and is more robust to changes in simulation
settings (different resolutions, different cosmologies).
</p></li>
</ul>

<h3>Title: Robustness and Personalization in Federated Learning: A Unified Approach via Regularization. (arXiv:2009.06303v3 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2009.06303">http://arxiv.org/abs/2009.06303</a></li>
<li>Code URL: null</li>
<li>Summary: <p>We present a class of methods for robust, personalized federated learning,
called Fed+, that unifies many federated learning algorithms. The principal
advantage of this class of methods is to better accommodate the real-world
characteristics found in federated training, such as the lack of IID data
across parties, the need for robustness to outliers or stragglers, and the
requirement to perform well on party-specific datasets. We achieve this through
a problem formulation that allows the central server to employ robust ways of
aggregating the local models while keeping the structure of local computation
intact. Without making any statistical assumption on the degree of
heterogeneity of local data across parties, we provide convergence guarantees
for Fed+ for convex and non-convex loss functions under different (robust)
aggregation methods. The Fed+ theory is also equipped to handle heterogeneous
computing environments including stragglers without additional assumptions;
specifically, the convergence results cover the general setting where the
number of local update steps across parties can vary. We demonstrate the
benefits of Fed+ through extensive experiments across standard benchmark
datasets.
</p></li>
</ul>

<h3>Title: Remote sensing and AI for building climate adaptation applications. (arXiv:2107.02693v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2107.02693">http://arxiv.org/abs/2107.02693</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Urban areas are not only one of the biggest contributors to climate change,
but also they are one of the most vulnerable areas with high populations who
would together experience the negative impacts. In this paper, we address some
of the opportunities brought by satellite remote sensing imaging and artificial
intelligence (AI) in order to measure climate adaptation of cities
automatically. We propose a framework combining AI and simulation which may be
useful for extracting indicators from remote-sensing images and may help with
predictive estimation of future states of these climate-adaptation-related
indicators. When such models become more robust and used in real life
applications, they may help decision makers and early responders to choose the
best actions to sustain the well-being of society, natural resources and
biodiversity. We underline that this is an open field and an on-going area of
research for many scientists, therefore we offer an in-depth discussion on the
challenges and limitations of data-driven methods and the predictive estimation
models in general.
</p></li>
</ul>

<h3>Title: High-dimensional Inference for Dynamic Treatment Effects. (arXiv:2110.04924v3 [stat.ME] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2110.04924">http://arxiv.org/abs/2110.04924</a></li>
<li>Code URL: null</li>
<li>Summary: <p>This paper proposes a confidence interval construction for heterogeneous
treatment effects in the context of multi-stage experiments with $N$ samples
and high-dimensional, $d$, confounders. Our focus is on the case of $d\gg N$,
but the results obtained also apply to low-dimensional cases. We showcase that
the bias of regularized estimation, unavoidable in high-dimensional covariate
spaces, is mitigated with a simple double-robust score. In this way, no
additional bias removal is necessary, and we obtain root-$N$ inference results
while allowing multi-stage interdependency of the treatments and covariates.
Memoryless property is also not assumed; treatment can possibly depend on all
previous treatment assignments and all previous multi-stage confounders. Our
results rely on certain sparsity assumptions of the underlying dependencies. We
discover new product rate conditions necessary for robust inference with
dynamic treatments.
</p></li>
</ul>

<h3>Title: On robust risk-based active-learning algorithms for enhanced decision support. (arXiv:2201.02555v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2201.02555">http://arxiv.org/abs/2201.02555</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Classification models are a fundamental component of physical-asset
management technologies such as structural health monitoring (SHM) systems and
digital twins. Previous work introduced risk-based active learning, an online
approach for the development of statistical classifiers that takes into account
the decision-support context in which they are applied. Decision-making is
considered by preferentially querying data labels according to expected value
of perfect information (EVPI). Although several benefits are gained by adopting
a risk-based active learning approach, including improved decision-making
performance, the algorithms suffer from issues relating to sampling bias as a
result of the guided querying process. This sampling bias ultimately manifests
as a decline in decision-making performance during the later stages of active
learning, which in turn corresponds to lost resource/utility.
</p></li>
</ul>

<p>The current paper proposes two novel approaches to counteract the effects of
sampling bias: semi-supervised learning, and discriminative classification
models. These approaches are first visualised using a synthetic dataset, then
subsequently applied to an experimental case study, specifically, the Z24
Bridge dataset. The semi-supervised learning approach is shown to have variable
performance; with robustness to sampling bias dependent on the suitability of
the generative distributions selected for the model with respect to each
dataset. In contrast, the discriminative classifiers are shown to have
excellent robustness to the effects of sampling bias. Moreover, it was found
that the number of inspections made during a monitoring campaign, and therefore
resource expenditure, could be reduced with the careful selection of the
statistical classifiers used within a decision-supporting monitoring system.
</p>

<h3>Title: A Robust and Flexible EM Algorithm for Mixtures of Elliptical Distributions with Missing Data. (arXiv:2201.12020v3 [stat.ML] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2201.12020">http://arxiv.org/abs/2201.12020</a></li>
<li>Code URL: <a href="https://github.com/fmouret/flexible_em_imputation">https://github.com/fmouret/flexible_em_imputation</a></li>
<li>Summary: <p>This paper tackles the problem of missing data imputation for noisy and
non-Gaussian data. A classical imputation method, the Expectation Maximization
(EM) algorithm for Gaussian mixture models, has shown interesting properties
when compared to other popular approaches such as those based on k-nearest
neighbors or on multiple imputations by chained equations. However, Gaussian
mixture models are known to be non-robust to heterogeneous data, which can lead
to poor estimation performance when the data is contaminated by outliers or
follows non-Gaussian distributions. To overcome this issue, a new EM algorithm
is investigated for mixtures of elliptical distributions with the property of
handling potential missing data. This paper shows that this problem reduces to
the estimation of a mixture of Angular Gaussian distributions under generic
assumptions (i.e., each sample is drawn from a mixture of elliptical
distributions, which is possibly different for one sample to another). In that
case, the complete-data likelihood associated with mixtures of elliptical
distributions is well adapted to the EM framework with missing data thanks to
its conditional distribution, which is shown to be a multivariate
$t$-distribution. Experimental results on synthetic data demonstrate that the
proposed algorithm is robust to outliers and can be used with non-Gaussian
data. Furthermore, experiments conducted on real-world datasets show that this
algorithm is very competitive when compared to other classical imputation
methods.
</p></li>
</ul>

<h3>Title: Uniform Manifold Approximation with Two-phase Optimization. (arXiv:2205.00420v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2205.00420">http://arxiv.org/abs/2205.00420</a></li>
<li>Code URL: <a href="https://github.com/hyungkwonko/umato">https://github.com/hyungkwonko/umato</a></li>
<li>Summary: <p>We introduce Uniform Manifold Approximation with Two-phase Optimization
(UMATO), a dimensionality reduction (DR) technique that improves UMAP to
capture the global structure of high-dimensional data more accurately. In
UMATO, optimization is divided into two phases so that the resulting embeddings
can depict the global structure reliably while preserving the local structure
with sufficient accuracy. In the first phase, hub points are identified and
projected to construct a skeletal layout for the global structure. In the
second phase, the remaining points are added to the embedding preserving the
regional characteristics of local areas. Through quantitative experiments, we
found that UMATO (1) outperformed widely used DR techniques in preserving the
global structure while (2) producing competitive accuracy in representing the
local structure. We also verified that UMATO is preferable in terms of
robustness over diverse initialization methods, number of epochs, and
subsampling techniques.
</p></li>
</ul>

<h3>Title: How Robust is your Fair Model? Exploring the Robustness of Diverse Fairness Strategies. (arXiv:2207.04581v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.04581">http://arxiv.org/abs/2207.04581</a></li>
<li>Code URL: <a href="https://github.com/Teddyzander/FairR">https://github.com/Teddyzander/FairR</a></li>
<li>Summary: <p>With the introduction of machine learning in high-stakes decision making,
ensuring algorithmic fairness has become an increasingly important problem to
solve. In response to this, many mathematical definitions of fairness have been
proposed, and a variety of optimisation techniques have been developed, all
designed to maximise a defined notion of fairness. However, fair solutions are
reliant on the quality of the training data, and can be highly sensitive to
noise. Recent studies have shown that robustness (the ability for a model to
perform well on unseen data) plays a significant role in the type of strategy
that should be used when approaching a new problem and, hence, measuring the
robustness of these strategies has become a fundamental problem. In this work,
we therefore propose a new criterion to measure the robustness of various
fairness optimisation strategies - the robustness ratio. We conduct multiple
extensive experiments on five bench mark fairness data sets using three of the
most popular fairness strategies with respect to four of the most popular
definitions of fairness. Our experiments empirically show that fairness methods
that rely on threshold optimisation are very sensitive to noise in all the
evaluated data sets, despite mostly outperforming other methods. This is in
contrast to the other two methods, which are less fair for low noise scenarios
but fairer for high noise ones. To the best of our knowledge, we are the first
to quantitatively evaluate the robustness of fairness optimisation strategies.
This can potentially can serve as a guideline in choosing the most suitable
fairness strategy for various data sets.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Biometrics in the Era of COVID-19: Challenges and Opportunities. (arXiv:2102.09258v2 [cs.CY] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2102.09258">http://arxiv.org/abs/2102.09258</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Since early 2020 the COVID-19 pandemic has had a considerable impact on many
aspects of daily life. A range of different measures have been implemented
worldwide to reduce the rate of new infections and to manage the pressure on
national health services. A primary strategy has been to reduce gatherings and
the potential for transmission through the prioritisation of remote working and
education. Enhanced hand hygiene and the use of facial masks have decreased the
spread of pathogens when gatherings are unavoidable. These particular measures
present challenges for reliable biometric recognition, e.g. for facial-, voice-
and hand-based biometrics. At the same time, new challenges create new
opportunities and research directions, e.g. renewed interest in non-constrained
iris or periocular recognition, touch-less fingerprint- and vein-based
authentication and the use of biometric characteristics for disease detection.
This article presents an overview of the research carried out to address those
challenges and emerging opportunities.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Weakly-supervised Part-Attention and Mentored Networks for Vehicle Re-Identification. (arXiv:2107.08228v2 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2107.08228">http://arxiv.org/abs/2107.08228</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Vehicle re-identification (Re-ID) aims to retrieve images with the same
vehicle ID across different cameras. Current part-level feature learning
methods typically detect vehicle parts via uniform division, outside tools, or
attention modeling. However, such part features often require expensive
additional annotations and cause sub-optimal performance in case of unreliable
part mask predictions. In this paper, we propose a weakly-supervised
Part-Attention Network (PANet) and Part-Mentored Network (PMNet) for Vehicle
Re-ID. Firstly, PANet localizes vehicle parts via part-relevant channel
recalibration and cluster-based mask generation without vehicle part
supervisory information. Secondly, PMNet leverages teacher-student guided
learning to distill vehicle part-specific features from PANet and performs
multi-scale global-part feature extraction. During inference, PMNet can
adaptively extract discriminative part features without part localization by
PANet, preventing unstable part mask predictions. We address this Re-ID issue
as a multi-task problem and adopt Homoscedastic Uncertainty to learn the
optimal weighing of ID losses. Experiments are conducted on two public
benchmarks, showing that our approach outperforms recent methods, which require
no extra annotations by an average increase of 3.0% in CMC@5 on VehicleID and
over 1.4% in mAP on VeRi776. Moreover, our method can extend to the occluded
vehicle Re-ID task and exhibits good generalization ability.
</p></li>
</ul>

<h3>Title: Dual Vision Transformer. (arXiv:2207.04976v2 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.04976">http://arxiv.org/abs/2207.04976</a></li>
<li>Code URL: <a href="https://github.com/yehli/imagenetmodel">https://github.com/yehli/imagenetmodel</a></li>
<li>Summary: <p>Prior works have proposed several strategies to reduce the computational cost
of self-attention mechanism. Many of these works consider decomposing the
self-attention procedure into regional and local feature extraction procedures
that each incurs a much smaller computational complexity. However, regional
information is typically only achieved at the expense of undesirable
information lost owing to down-sampling. In this paper, we propose a novel
Transformer architecture that aims to mitigate the cost issue, named Dual
Vision Transformer (Dual-ViT). The new architecture incorporates a critical
semantic pathway that can more efficiently compress token vectors into global
semantics with reduced order of complexity. Such compressed global semantics
then serve as useful prior information in learning finer pixel level details,
through another constructed pixel pathway. The semantic pathway and pixel
pathway are then integrated together and are jointly trained, spreading the
enhanced self-attention information in parallel through both of the pathways.
Dual-ViT is henceforth able to reduce the computational complexity without
compromising much accuracy. We empirically demonstrate that Dual-ViT provides
superior accuracy than SOTA Transformer architectures with reduced training
complexity. Source code is available at
\url{https://github.com/YehLi/ImageNetModel}.
</p></li>
</ul>

<h3>Title: Effective Few-Shot Named Entity Linking by Meta-Learning. (arXiv:2207.05280v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05280">http://arxiv.org/abs/2207.05280</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Entity linking aims to link ambiguous mentions to their corresponding
entities in a knowledge base, which is significant and fundamental for various
downstream applications, e.g., knowledge base completion, question answering,
and information extraction. While great efforts have been devoted to this task,
most of these studies follow the assumption that large-scale labeled data is
available. However, when the labeled data is insufficient for specific domains
due to labor-intensive annotation work, the performance of existing algorithms
will suffer an intolerable decline. In this paper, we endeavor to solve the
problem of few-shot entity linking, which only requires a minimal amount of
in-domain labeled data and is more practical in real situations. Specifically,
we firstly propose a novel weak supervision strategy to generate non-trivial
synthetic entity-mention pairs based on mention rewriting. Since the quality of
the synthetic data has a critical impact on effective model training, we
further design a meta-learning mechanism to assign different weights to each
synthetic entity-mention pair automatically. Through this way, we can
profoundly exploit rich and precious semantic information to derive a
well-trained entity linking model under the few-shot setting. The experiments
on real-world datasets show that the proposed method can extensively improve
the state-of-the-art few-shot entity linking model and achieve impressive
performance when only a small amount of labeled data is available. Moreover, we
also demonstrate the outstanding ability of the model's transferability.
</p></li>
</ul>

<h3>Title: Similarity and Content-based Phonetic Self Attention for Speech Recognition. (arXiv:2203.10252v3 [cs.CL] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2203.10252">http://arxiv.org/abs/2203.10252</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Transformer-based speech recognition models have achieved great success due
to the self-attention (SA) mechanism that utilizes every frame in the feature
extraction process. Especially, SA heads in lower layers capture various
phonetic characteristics by the query-key dot product, which is designed to
compute the pairwise relationship between frames. In this paper, we propose a
variant of SA to extract more representative phonetic features. The proposed
phonetic self-attention (phSA) is composed of two different types of phonetic
attention; one is similarity-based and the other is content-based. In short,
similarity-based attention captures the correlation between frames while
content-based attention only considers each frame without being affected by
other frames. We identify which parts of the original dot product equation are
related to two different attention patterns and improve each part with simple
modifications. Our experiments on phoneme classification and speech recognition
show that replacing SA with phSA for lower layers improves the recognition
performance without increasing the latency and the parameter size.
</p></li>
</ul>

<h3>Title: Multi-level Fusion of Wav2vec 2.0 and BERT for Multimodal Emotion Recognition. (arXiv:2207.04697v2 [cs.CL] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.04697">http://arxiv.org/abs/2207.04697</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The research and applications of multimodal emotion recognition have become
increasingly popular recently. However, multimodal emotion recognition faces
the challenge of lack of data. To solve this problem, we propose to use
transfer learning which leverages state-of-the-art pre-trained models including
wav2vec 2.0 and BERT for this task. Multi-level fusion approaches including
coattention-based early fusion and late fusion with the models trained on both
embeddings are explored. Also, a multi-granularity framework which extracts not
only frame-level speech embeddings but also segment-level embeddings including
phone, syllable and word-level speech embeddings is proposed to further boost
the performance. By combining our coattention-based early fusion model and late
fusion model with the multi-granularity feature extraction framework, we obtain
result that outperforms best baseline approaches by 1.3% unweighted accuracy
(UA) on the IEMOCAP dataset.
</p></li>
</ul>

<h3>Title: Modern Views of Machine Learning for Precision Psychiatry. (arXiv:2204.01607v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2204.01607">http://arxiv.org/abs/2204.01607</a></li>
<li>Code URL: null</li>
<li>Summary: <p>In light of the NIMH's Research Domain Criteria (RDoC), the advent of
functional neuroimaging, novel technologies and methods provide new
opportunities to develop precise and personalized prognosis and diagnosis of
mental disorders. Machine learning (ML) and artificial intelligence (AI)
technologies are playing an increasingly critical role in the new era of
precision psychiatry. Combining ML/AI with neuromodulation technologies can
potentially provide explainable solutions in clinical practice and effective
therapeutic treatment. Advanced wearable and mobile technologies also call for
the new role of ML/AI for digital phenotyping in mobile mental health. In this
review, we provide a comprehensive review of the ML methodologies and
applications by combining neuroimaging, neuromodulation, and advanced mobile
technologies in psychiatry practice. Additionally, we review the role of ML in
molecular phenotyping and cross-species biomarker identification in precision
psychiatry. We further discuss explainable AI (XAI) and causality testing in a
closed-human-in-the-loop manner, and highlight the ML potential in multimedia
information extraction and multimodal data fusion. Finally, we discuss
conceptual and practical challenges in precision psychiatry and highlight ML
opportunities in future research.
</p></li>
</ul>

<h3>Title: Insights into Deep Non-linear Filters for Improved Multi-channel Speech Enhancement. (arXiv:2206.13310v2 [eess.AS] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2206.13310">http://arxiv.org/abs/2206.13310</a></li>
<li>Code URL: <a href="https://github.com/sp-uhh/deep-non-linear-filter">https://github.com/sp-uhh/deep-non-linear-filter</a></li>
<li>Summary: <p>The key advantage of using multiple microphones for speech enhancement is
that spatial filtering can be used to complement the tempo-spectral processing.
In a traditional setting, linear spatial filtering (beamforming) and
single-channel post-filtering are commonly performed separately. In contrast,
there is a trend towards employing deep neural networks (DNNs) to learn a joint
spatial and tempo-spectral non-linear filter, which means that the restriction
of a linear processing model and that of a separate processing of spatial and
tempo-spectral information can potentially be overcome. However, the internal
mechanisms that lead to good performance of such data-driven filters for
multi-channel speech enhancement are not well understood. Therefore, in this
work, we analyse the properties of a non-linear spatial filter realized by a
DNN as well as its interdependency with temporal and spectral processing by
carefully controlling the information sources (spatial, spectral, and temporal)
available to the network. We confirm the superiority of a non-linear spatial
processing model, which outperforms an oracle linear spatial filter in a
challenging speaker extraction scenario for a low number of microphones by 0.24
POLQA score. Our analyses reveal that in particular spectral information should
be processed jointly with spatial information as this increases the spatial
selectivity of the filter. Our systematic evaluation then leads to a simple
network architecture, that outperforms state-of-the-art network architectures
on a speaker extraction task by 0.22 POLQA score and by 0.32 POLQA score on the
CHiME3 data.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Unlearning: How to Efficiently Erase a Client in FL?. (arXiv:2207.05521v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05521">http://arxiv.org/abs/2207.05521</a></li>
<li>Code URL: null</li>
<li>Summary: <p>With privacy legislation empowering users with the right to be forgotten, it
has become essential to make a model forget about some of its training data. We
explore the problem of removing any client's contribution in federated learning
(FL). During FL rounds, each client performs local training to learn a model
that minimizes the empirical loss on their private data. We propose to perform
unlearning at the client (to be erased) by reversing the learning process,
i.e., training a model to \emph{maximize} the local empirical loss. In
particular, we formulate the unlearning problem as a constrained maximization
problem by restricting to an $\ell_2$-norm ball around a suitably chosen
reference model to help retain some knowledge learnt from the other clients'
data. This allows the client to use projected gradient descent to perform
unlearning. The method does neither require global access to the data used for
training nor the history of the parameter updates to be stored by the
aggregator (server) or any of the clients. Experiments on the MNIST dataset
show that the proposed unlearning method is efficient and effective.
</p></li>
</ul>

<h3>Title: A Cross-City Federated Transfer Learning Framework: A Case Study on Urban Region Profiling. (arXiv:2206.00007v3 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2206.00007">http://arxiv.org/abs/2206.00007</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Data insufficiency problems (i.e., data missing and label scarcity) caused by
inadequate services and infrastructures or imbalanced development levels of
cities have seriously affected the urban computing tasks in real scenarios.
Prior transfer learning methods inspire an elegant solution to the data
insufficiency, but are only concerned with one kind of insufficiency issue and
fail to give consideration to both sides. In addition, most previous cross-city
transfer methods overlook inter-city data privacy which is a public concern in
practical applications. To address the above challenging problems, we propose a
novel Cross-city Federated Transfer Learning framework (CcFTL) to cope with the
data insufficiency and privacy problems. Concretely, CcFTL transfers the
relational knowledge from multiple rich-data source cities to the target city.
Besides, the model parameters specific to the target task are firstly trained
on the source data and then fine-tuned to the target city by parameter
transfer. With our adaptation of federated training and homomorphic encryption
settings, CcFTL can effectively deal with the data privacy problem among
cities. We take the urban region profiling as an application of smart cities
and evaluate the proposed method with a real-world study. The experiments
demonstrate the notable superiority of our framework over several competitive
state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Towards the Practical Utility of Federated Learning in the Medical Domain. (arXiv:2207.03075v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.03075">http://arxiv.org/abs/2207.03075</a></li>
<li>Code URL: <a href="https://github.com/wns823/medical_federated">https://github.com/wns823/medical_federated</a></li>
<li>Summary: <p>Federated learning (FL) is an active area of research. One of the most
suitable areas for adopting FL is the medical domain, where patient privacy
must be respected. Previous research, however, does not fully consider who will
most likely use FL in the medical domain. It is not the hospitals who are eager
to adopt FL, but the service providers such as IT companies who want to develop
machine learning models with real patient records. Moreover, service providers
would prefer to focus on maximizing the performance of the models at the lowest
cost possible. In this work, we propose empirical benchmarks of FL methods
considering both performance and monetary cost with three real-world datasets:
electronic health records, skin cancer images, and electrocardiogram datasets.
We also propose Federated learning with Proximal regularization eXcept local
Normalization (FedPxN), which, using a simple combination of FedProx and FedBN,
outperforms all other FL algorithms while consuming only slightly more power
than the most power efficient method.
</p></li>
</ul>

<h3>Title: FedPseudo: Pseudo value-based Deep Learning Models for Federated Survival Analysis. (arXiv:2207.05247v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05247">http://arxiv.org/abs/2207.05247</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Survival analysis, time-to-event analysis, is an important problem in
healthcare since it has a wide-ranging impact on patients and palliative care.
Many survival analysis methods have assumed that the survival data is centrally
available either from one medical center or by data sharing from multi-centers.
However, the sensitivity of the patient attributes and the strict privacy laws
have increasingly forbidden sharing of healthcare data. To address this
challenge, the research community has looked at the solution of decentralized
training and sharing of model parameters using the Federated Learning (FL)
paradigm. In this paper, we study the utilization of FL for performing survival
analysis on distributed healthcare datasets. Recently, the popular Cox
proportional hazard (CPH) models have been adapted for FL settings; however,
due to its linearity and proportional hazards assumptions, CPH models result in
suboptimal performance, especially for non-linear, non-iid, and heavily
censored survival datasets. To overcome the challenges of existing federated
survival analysis methods, we leverage the predictive accuracy of the deep
learning models and the power of pseudo values to propose a first-of-its-kind,
pseudo value-based deep learning model for federated survival analysis (FSA)
called FedPseudo. Furthermore, we introduce a novel approach of deriving pseudo
values for survival probability in the FL settings that speeds up the
computation of pseudo values. Extensive experiments on synthetic and real-world
datasets show that our pseudo valued-based FL framework achieves similar
performance as the best centrally trained deep survival analysis model.
Moreover, our proposed FL approach obtains the best results for various
censoring settings.
</p></li>
</ul>

<h3>Title: Multi-Model Federated Learning with Provable Guarantees. (arXiv:2207.04330v2 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.04330">http://arxiv.org/abs/2207.04330</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Federated Learning (FL) is a variant of distributed learning where edge
devices collaborate to learn a model without sharing their data with the
central server or each other. We refer to the process of training multiple
independent models simultaneously in a federated setting using a common pool of
clients as multi-model FL. In this work, we propose two variants of the popular
FedAvg algorithm for multi-model FL, with provable convergence guarantees. We
further show that for the same amount of computation, multi-model FL can have
better performance than training each model separately. We supplement our
theoretical results with experiments in strongly convex, convex, and non-convex
settings.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Enhancing Fairness of Visual Attribute Predictors. (arXiv:2207.05727v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05727">http://arxiv.org/abs/2207.05727</a></li>
<li>Code URL: null</li>
<li>Summary: <p>The performance of deep neural networks for image recognition tasks such as
predicting a smiling face is known to degrade with under-represented classes of
sensitive attributes. We address this problem by introducing fairness-aware
regularization losses based on batch estimates of Demographic Parity, Equalized
Odds, and a novel Intersection-over-Union measure. The experiments performed on
facial and medical images from CelebA, UTKFace, and the SIIM-ISIC melanoma
classification challenge show the effectiveness of our proposed fairness losses
for bias mitigation as they improve model fairness while maintaining high
classification performance. To the best of our knowledge, our work is the first
attempt to incorporate these types of losses in an end-to-end training scheme
for mitigating biases of visual attribute predictors.
</p></li>
</ul>

<h3>Title: Counterfactually Measuring and Eliminating Social Bias in Vision-Language Pre-training Models. (arXiv:2207.01056v2 [cs.CV] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.01056">http://arxiv.org/abs/2207.01056</a></li>
<li>Code URL: <a href="https://github.com/vl-bias/vl-bias">https://github.com/vl-bias/vl-bias</a></li>
<li>Summary: <p>Vision-Language Pre-training (VLP) models have achieved state-of-the-art
performance in numerous cross-modal tasks. Since they are optimized to capture
the statistical properties of intra- and inter-modality, there remains risk to
learn social biases presented in the data as well. In this work, we (1)
introduce a counterfactual-based bias measurement \emph{CounterBias} to
quantify the social bias in VLP models by comparing the [MASK]ed prediction
probabilities of factual and counterfactual samples; (2) construct a novel
VL-Bias dataset including 24K image-text pairs for measuring gender bias in VLP
models, from which we observed that significant gender bias is prevalent in VLP
models; and (3) propose a VLP debiasing method \emph{FairVLP} to minimize the
difference in the [MASK]ed prediction probabilities between factual and
counterfactual image-text pairs for VLP debiasing. Although CounterBias and
FairVLP focus on social bias, they are generalizable to serve as tools and
provide new insights to probe and regularize more knowledge in VLP models.
</p></li>
</ul>

<h3>Title: Causal Conceptions of Fairness and their Consequences. (arXiv:2207.05302v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05302">http://arxiv.org/abs/2207.05302</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Recent work highlights the role of causality in designing equitable
decision-making algorithms. It is not immediately clear, however, how existing
causal conceptions of fairness relate to one another, or what the consequences
are of using these definitions as design principles. Here, we first assemble
and categorize popular causal definitions of algorithmic fairness into two
broad families: (1) those that constrain the effects of decisions on
counterfactual disparities; and (2) those that constrain the effects of legally
protected characteristics, like race and gender, on decisions. We then show,
analytically and empirically, that both families of definitions \emph{almost
always} -- in a measure theoretic sense -- result in strongly Pareto dominated
decision policies, meaning there is an alternative, unconstrained policy
favored by every stakeholder with preferences drawn from a large, natural
class. For example, in the case of college admissions decisions, policies
constrained to satisfy causal fairness definitions would be disfavored by every
stakeholder with neutral or positive preferences for both academic preparedness
and diversity. Indeed, under a prominent definition of causal fairness, we
prove the resulting policies require admitting all students with the same
probability, regardless of academic qualifications or group membership. Our
results highlight formal limitations and potential adverse consequences of
common mathematical notions of causal fairness.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Regression Metric Loss: Learning a Semantic Representation Space for Medical Images. (arXiv:2207.05231v1 [eess.IV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05231">http://arxiv.org/abs/2207.05231</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Regression plays an essential role in many medical imaging applications for
estimating various clinical risk or measurement scores. While training
strategies and loss functions have been studied for the deep neural networks in
medical image classification tasks, options for regression tasks are very
limited. One of the key challenges is that the high-dimensional feature
representation learned by existing popular loss functions like Mean Squared
Error or L1 loss is hard to interpret. In this paper, we propose a novel
Regression Metric Loss (RM-Loss), which endows the representation space with
the semantic meaning of the label space by finding a representation manifold
that is isometric to the label space. Experiments on two regression tasks, i.e.
coronary artery calcium score estimation and bone age assessment, show that
RM-Loss is superior to the existing popular regression losses on both
performance and interpretability. Code is available at
https://github.com/DIAL-RPI/Regression-Metric-Loss.
</p></li>
</ul>

<h3>Title: Rethinking gradient weights' influence over saliency map estimation. (arXiv:2207.05374v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05374">http://arxiv.org/abs/2207.05374</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Class activation map (CAM) helps to formulate saliency maps that aid in
interpreting the deep neural network's prediction. Gradient-based methods are
generally faster than other branches of vision interpretability and independent
of human guidance. The performance of CAM-like studies depends on the governing
model's layer response, and the influences of the gradients. Typical
gradient-oriented CAM studies rely on weighted aggregation for saliency map
estimation by projecting the gradient maps into single weight values, which may
lead to over generalized saliency map. To address this issue, we use a global
guidance map to rectify the weighted aggregation operation during saliency
estimation, where resultant interpretations are comparatively clean er and
instance-specific. We obtain the global guidance map by performing elementwise
multiplication between the feature maps and their corresponding gradient maps.
To validate our study, we compare the proposed study with eight different
saliency visualizers. In addition, we use seven commonly used evaluation
metrics for quantitative comparison. The proposed scheme achieves significant
improvement over the test images from the ImageNet, MS-COCO 14, and PASCAL VOC
2012 datasets.
</p></li>
</ul>

<h3>Title: Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05543">http://arxiv.org/abs/2207.05543</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Deep generative models are widely used for modelling high-dimensional time
series, such as video animations, audio and climate data. Sequential
variational autoencoders have been successfully considered for many
applications, with many variant models relying on discrete-time methods and
recurrent neural networks (RNNs). On the other hand, continuous-time methods
have recently gained attraction, especially in the context of
irregularly-sampled time series, where they can better handle the data than
discrete-time methods. One such class are Gaussian process variational
autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GPs),
allowing inductive biases to be explicitly encoded via the kernel function and
interpretability of the latent space. However, a major limitation of GPVAEs is
that it inherits the same cubic computational cost as GPs. In this work, we
leverage the equivalent discrete state space representation of Markovian GPs to
enable a linear-time GP solver via Kalman filtering and smoothing. We show via
corrupt and missing frames tasks that our method performs favourably,
especially on the latter where it outperforms RNN-based models.
</p></li>
</ul>

<h3>Title: Tell Me the Evidence? Dual Visual-Linguistic Interaction for Answer Grounding. (arXiv:2207.05703v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05703">http://arxiv.org/abs/2207.05703</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Answer grounding aims to reveal the visual evidence for visual question
answering (VQA), which entails highlighting relevant positions in the image
when answering questions about images. Previous attempts typically tackle this
problem using pretrained object detectors, but without the flexibility for
objects not in the predefined vocabulary. However, these black-box methods
solely concentrate on the linguistic generation, ignoring the visual
interpretability. In this paper, we propose Dual Visual-Linguistic Interaction
(DaVI), a novel unified end-to-end framework with the capability for both
linguistic answering and visual grounding. DaVI innovatively introduces two
visual-linguistic interaction mechanisms: 1) visual-based linguistic encoder
that understands questions incorporated with visual features and produces
linguistic-oriented evidence for further answer decoding, and 2)
linguistic-based visual decoder that focuses visual features on the
evidence-related regions for answer grounding. This way, our approach ranked
the 1st place in the answer grounding track of 2022 VizWiz Grand Challenge.
</p></li>
</ul>

<h3>Title: Interpretable Deep Causal Learning for Moderation Effects. (arXiv:2206.10261v3 [cs.LG] UPDATED)</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2206.10261">http://arxiv.org/abs/2206.10261</a></li>
<li>Code URL: null</li>
<li>Summary: <p>In this extended abstract paper, we address the problem of interpretability
and targeted regularization in causal machine learning models. In particular,
we focus on the problem of estimating individual causal/treatment effects under
observed confounders, which can be controlled for and moderate the effect of
the treatment on the outcome of interest. Black-box ML models adjusted for the
causal setting perform generally well in this task, but they lack interpretable
output identifying the main drivers of treatment heterogeneity and their
functional relationship. We propose a novel deep counterfactual learning
architecture for estimating individual treatment effects that can
simultaneously: i) convey targeted regularization on, and produce quantify
uncertainty around the quantity of interest (i.e., the Conditional Average
Treatment Effect); ii) disentangle baseline prognostic and moderating effects
of the covariates and output interpretable score functions describing their
relationship with the outcome. Finally, we demonstrate the use of the method
via a simple simulated experiment.
</p></li>
</ul>

<h3>Title: Using Interpretable Machine Learning to Predict Maternal and Fetal Outcomes. (arXiv:2207.05322v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.05322">http://arxiv.org/abs/2207.05322</a></li>
<li>Code URL: null</li>
<li>Summary: <p>Most pregnancies and births result in a good outcome, but complications are
not uncommon and when they do occur, they can be associated with serious
implications for mothers and babies. Predictive modeling has the potential to
improve outcomes through better understanding of risk factors, heightened
surveillance, and more timely and appropriate interventions, thereby helping
obstetricians deliver better care. For three types of complications we identify
and study the most important risk factors using Explainable Boosting Machine
(EBM), a glass box model, in order to gain intelligibility: (i) Severe Maternal
Morbidity (SMM), (ii) shoulder dystocia, and (iii) preterm preeclampsia. While
using the interpretability of EBM's to reveal surprising insights into the
features contributing to risk, our experiments show EBMs match the accuracy of
other black-box ML methods such as deep neural nets and random forests.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
