<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Probabilistic Sampling-Enhanced Temporal-Spatial GCN: A Scalable Framework for Transaction Anomaly Detection in Ethereum Networks. (arXiv:2310.00144v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00144">http://arxiv.org/abs/2310.00144</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00144]] Probabilistic Sampling-Enhanced Temporal-Spatial GCN: A Scalable Framework for Transaction Anomaly Detection in Ethereum Networks(http://arxiv.org/abs/2310.00144)</code></li>
<li>Summary: <p>The rapid evolution of the Ethereum network necessitates sophisticated
techniques to ensure its robustness against potential threats and to maintain
transparency. While Graph Neural Networks (GNNs) have pioneered anomaly
detection in such platforms, capturing the intricacies of both spatial and
temporal transactional patterns has remained a challenge. This study presents a
fusion of Graph Convolutional Networks (GCNs) with Temporal Random Walks (TRW)
enhanced by probabilistic sampling to bridge this gap. Our approach, unlike
traditional GCNs, leverages the strengths of TRW to discern complex temporal
sequences in Ethereum transactions, thereby providing a more nuanced
transaction anomaly detection mechanism. Preliminary evaluations demonstrate
that our TRW-GCN framework substantially advances the performance metrics over
conventional GCNs in detecting anomalies and transaction bursts. This research
not only underscores the potential of temporal cues in Ethereum transactional
data but also offers a scalable and effective methodology for ensuring the
security and transparency of decentralized platforms. By harnessing both
spatial relationships and time-based transactional sequences as node features,
our model introduces an additional layer of granularity, making the detection
process more robust and less prone to false positives. This work lays the
foundation for future research aimed at optimizing and enhancing the
transparency of blockchain technologies, and serves as a testament to the
significance of considering both time and space dimensions in the ever-evolving
landscape of the decentralized platforms.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Federated Learning with Differential Privacy for End-to-End Speech Recognition. (arXiv:2310.00098v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00098">http://arxiv.org/abs/2310.00098</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00098]] Federated Learning with Differential Privacy for End-to-End Speech Recognition(http://arxiv.org/abs/2310.00098)</code></li>
<li>Summary: <p>While federated learning (FL) has recently emerged as a promising approach to
train machine learning models, it is limited to only preliminary explorations
in the domain of automatic speech recognition (ASR). Moreover, FL does not
inherently guarantee user privacy and requires the use of differential privacy
(DP) for robust privacy guarantees. However, we are not aware of prior work on
applying DP to FL for ASR. In this paper, we aim to bridge this research gap by
formulating an ASR benchmark for FL with DP and establishing the first
baselines. First, we extend the existing research on FL for ASR by exploring
different aspects of recent $\textit{large end-to-end transformer models}$:
architecture design, seed models, data heterogeneity, domain shift, and impact
of cohort size. With a $\textit{practical}$ number of central aggregations we
are able to train $\textbf{FL models}$ that are \textbf{nearly optimal} even
with heterogeneous data, a seed model from another domain, or no pre-trained
seed model. Second, we apply DP to FL for ASR, which is non-trivial since DP
noise severely affects model training, especially for large transformer models,
due to highly imbalanced gradients in the attention block. We counteract the
adverse effect of DP noise by reviving per-layer clipping and explaining why
its effect is more apparent in our case than in the prior work. Remarkably, we
achieve user-level ($7.2$, $10^{-9}$)-$\textbf{DP}$ (resp. ($4.5$,
$10^{-9}$)-$\textbf{DP}$) with a 1.3% (resp. 4.6%) absolute drop in the word
error rate for extrapolation to high (resp. low) population scale for
$\textbf{FL with DP in ASR}$.
</p></li>
</ul>

<h3>Title: Beyond Random Noise: Insights on Anonymization Strategies from a Latent Bandit Study. (arXiv:2310.00221v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00221">http://arxiv.org/abs/2310.00221</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00221]] Beyond Random Noise: Insights on Anonymization Strategies from a Latent Bandit Study(http://arxiv.org/abs/2310.00221)</code></li>
<li>Summary: <p>This paper investigates the issue of privacy in a learning scenario where
users share knowledge for a recommendation task. Our study contributes to the
growing body of research on privacy-preserving machine learning and underscores
the need for tailored privacy techniques that address specific attack patterns
rather than relying on one-size-fits-all solutions. We use the latent bandit
setting to evaluate the trade-off between privacy and recommender performance
by employing various aggregation strategies, such as averaging, nearest
neighbor, and clustering combined with noise injection. More specifically, we
simulate a linkage attack scenario leveraging publicly available auxiliary
information acquired by the adversary. Our results on three open real-world
datasets reveal that adding noise using the Laplace mechanism to an individual
user's data record is a poor choice. It provides the highest regret for any
noise level, relative to de-anonymization probability and the ADS metric.
Instead, one should combine noise with appropriate aggregation strategies. For
example, using averages from clusters of different sizes provides flexibility
not achievable by varying the amount of noise alone. Generally, no single
aggregation strategy can consistently achieve the optimum regret for a given
desired level of privacy.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks. (arXiv:2310.00076v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00076">http://arxiv.org/abs/2310.00076</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00076]] Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks(http://arxiv.org/abs/2310.00076)</code></li>
<li>Summary: <p>In light of recent advancements in generative AI models, it has become
essential to distinguish genuine content from AI-generated one to prevent the
malicious usage of fake materials as authentic ones and vice versa. Various
techniques have been introduced for identifying AI-generated images, with
watermarking emerging as a promising approach. In this paper, we analyze the
robustness of various AI-image detectors including watermarking and
classifier-based deepfake detectors. For watermarking methods that introduce
subtle image perturbations (i.e., low perturbation budget methods), we reveal a
fundamental trade-off between the evasion error rate (i.e., the fraction of
watermarked images detected as non-watermarked ones) and the spoofing error
rate (i.e., the fraction of non-watermarked images detected as watermarked
ones) upon an application of a diffusion purification attack. In this regime,
we also empirically show that diffusion purification effectively removes
watermarks with minimal changes to images. For high perturbation watermarking
methods where notable changes are applied to images, the diffusion purification
attack is not effective. In this case, we develop a model substitution
adversarial attack that can successfully remove watermarks. Moreover, we show
that watermarking methods are vulnerable to spoofing attacks where the attacker
aims to have real images (potentially obscene) identified as watermarked ones,
damaging the reputation of the developers. In particular, by just having
black-box access to the watermarking method, we show that one can generate a
watermarked noise image which can be added to the real images to have them
falsely flagged as watermarked ones. Finally, we extend our theory to
characterize a fundamental trade-off between the robustness and reliability of
classifier-based deep fake detectors and demonstrate it through experiments.
</p></li>
</ul>

<h3>Title: Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study. (arXiv:2310.00108v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00108">http://arxiv.org/abs/2310.00108</a></li>
<li>Code URL: https://github.com/ruoxi-jia-group/clip-mia</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00108]] Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study(http://arxiv.org/abs/2310.00108)</code></li>
<li>Summary: <p>Membership inference attacks (MIAs) aim to infer whether a data point has
been used to train a machine learning model. These attacks can be employed to
identify potential privacy vulnerabilities and detect unauthorized use of
personal data. While MIAs have been traditionally studied for simple
classification models, recent advancements in multi-modal pre-training, such as
CLIP, have demonstrated remarkable zero-shot performance across a range of
computer vision tasks. However, the sheer scale of data and models presents
significant computational challenges for performing the attacks.
</p>
<p>This paper takes a first step towards developing practical MIAs against
large-scale multi-modal models. We introduce a simple baseline strategy by
thresholding the cosine similarity between text and image features of a target
point and propose further enhancing the baseline by aggregating cosine
similarity across transformations of the target. We also present a new weakly
supervised attack method that leverages ground-truth non-members (e.g.,
obtained by using the publication date of a target model and the timestamps of
the open data) to further enhance the attack. Our evaluation shows that CLIP
models are susceptible to our attack strategies, with our simple baseline
achieving over $75\%$ membership identification accuracy. Furthermore, our
enhanced attacks outperform the baseline across multiple models and datasets,
with the weakly supervised attack demonstrating an average-case performance
improvement of $17\%$ and being at least $7$X more effective at low
false-positive rates. These findings highlight the importance of protecting the
privacy of multi-modal foundational models, which were previously assumed to be
less susceptible to MIAs due to less overfitting. Our code is available at
https://github.com/ruoxi-jia-group/CLIP-MIA.
</p></li>
</ul>

<h3>Title: Source Inference Attacks: Beyond Membership Inference Attacks in Federated Learning. (arXiv:2310.00222v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00222">http://arxiv.org/abs/2310.00222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00222]] Source Inference Attacks: Beyond Membership Inference Attacks in Federated Learning(http://arxiv.org/abs/2310.00222)</code></li>
<li>Summary: <p>Federated learning (FL) is a popular approach to facilitate privacy-aware
machine learning since it allows multiple clients to collaboratively train a
global model without granting others access to their private data. It is,
however, known that FL can be vulnerable to membership inference attacks
(MIAs), where the training records of the global model can be distinguished
from the testing records. Surprisingly, research focusing on the investigation
of the source inference problem appears to be lacking. We also observe that
identifying a training record's source client can result in privacy breaches
extending beyond MIAs. For example, consider an FL application where multiple
hospitals jointly train a COVID-19 diagnosis model, membership inference
attackers can identify the medical records that have been used for training,
and any additional identification of the source hospital can result the patient
from the particular hospital more prone to discrimination. Seeking to
contribute to the literature gap, we take the first step to investigate source
privacy in FL. Specifically, we propose a new inference attack (hereafter
referred to as source inference attack -- SIA), designed to facilitate an
honest-but-curious server to identify the training record's source client. The
proposed SIAs leverage the Bayesian theorem to allow the server to implement
the attack in a non-intrusive manner without deviating from the defined FL
protocol. We then evaluate SIAs in three different FL frameworks to show that
in existing FL frameworks, the clients sharing gradients, model parameters, or
predictions on a public dataset will leak such source information to the
server. We also conduct extensive experiments on various datasets to
investigate the key factors in an SIA. The experimental results validate the
efficacy of the proposed SIAs.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Prior Mismatch and Adaptation in PnP-ADMM with a Nonconvex Convergence Analysis. (arXiv:2310.00133v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00133">http://arxiv.org/abs/2310.00133</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00133]] Prior Mismatch and Adaptation in PnP-ADMM with a Nonconvex Convergence Analysis(http://arxiv.org/abs/2310.00133)</code></li>
<li>Summary: <p>Plug-and-Play (PnP) priors is a widely-used family of methods for solving
imaging inverse problems by integrating physical measurement models with image
priors specified using image denoisers. PnP methods have been shown to achieve
state-of-the-art performance when the prior is obtained using powerful deep
denoisers. Despite extensive work on PnP, the topic of distribution mismatch
between the training and testing data has often been overlooked in the PnP
literature. This paper presents a set of new theoretical and numerical results
on the topic of prior distribution mismatch and domain adaptation for
alternating direction method of multipliers (ADMM) variant of PnP. Our
theoretical result provides an explicit error bound for PnP-ADMM due to the
mismatch between the desired denoiser and the one used for inference. Our
analysis contributes to the work in the area by considering the mismatch under
nonconvex data-fidelity terms and expansive denoisers. Our first set of
numerical results quantifies the impact of the prior distribution mismatch on
the performance of PnP-ADMM on the problem of image super-resolution. Our
second set of numerical results considers a simple and effective domain
adaption strategy that closes the performance gap due to the use of mismatched
denoisers. Our results suggest the relative robustness of PnP-ADMM to prior
distribution mismatch, while also showing that the performance gap can be
significantly reduced with few training samples from the desired distribution.
</p></li>
</ul>

<h3>Title: Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection. (arXiv:2310.00161v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00161">http://arxiv.org/abs/2310.00161</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00161]] Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection(http://arxiv.org/abs/2310.00161)</code></li>
<li>Summary: <p>We present a new open-vocabulary detection approach based on
detection-oriented image-text pretraining to bridge the gap between image-level
pretraining and open-vocabulary object detection. At the pretraining phase, we
replace the commonly used classification architecture with the detector
architecture, which better serves the region-level recognition needs of
detection by enabling the detector heads to learn from noisy image-text pairs.
Using only standard contrastive loss and no pseudo-labeling, our approach is a
simple yet effective extension of the contrastive learning method to learn
emergent object-semantic cues. In addition, we propose a shifted-window
learning approach upon window attention to make the backbone representation
more robust, translation-invariant, and less biased by the window pattern. On
the popular LVIS open-vocabulary detection benchmark, our approach sets a new
state of the art of 40.4 mask AP$_r$ using the common ViT-L backbone,
significantly outperforming the best existing approach by +6.5 mask AP$_r$ at
system level. On the COCO benchmark, we achieve very competitive 40.8 novel AP
without pseudo labeling or weak supervision. In addition, we evaluate our
approach on the transfer detection setup, where ours outperforms the baseline
significantly. Visualization reveals emerging object locality from the
pretraining recipes compared to the baseline. Code and models will be publicly
released.
</p></li>
</ul>

<h3>Title: Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization. (arXiv:2310.00116v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00116">http://arxiv.org/abs/2310.00116</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00116]] Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization(http://arxiv.org/abs/2310.00116)</code></li>
<li>Summary: <p>To improve the robustness of deep classifiers against adversarial
perturbations, many approaches have been proposed, such as designing new
architectures with better robustness properties (e.g., Lipschitz-capped
networks), or modifying the training process itself (e.g., min-max
optimization, constrained learning, or regularization). These approaches,
however, might not be effective at increasing the margin in the input (feature)
space. As a result, there has been an increasing interest in developing
training procedures that can directly manipulate the decision boundary in the
input space. In this paper, we build upon recent developments in this category
by developing a robust training algorithm whose objective is to increase the
margin in the output (logit) space while regularizing the Lipschitz constant of
the model along vulnerable directions. We show that these two objectives can
directly promote larger margins in the input space. To this end, we develop a
scalable method for calculating guaranteed differentiable upper bounds on the
Lipschitz constant of neural networks accurately and efficiently. The relative
accuracy of the bounds prevents excessive regularization and allows for more
direct manipulation of the decision boundary. Furthermore, our Lipschitz
bounding algorithm exploits the monotonicity and Lipschitz continuity of the
activation layers, and the resulting bounds can be used to design new layers
with controllable bounds on their Lipschitz constant. Experiments on the MNIST,
CIFAR-10, and Tiny-ImageNet data sets verify that our proposed algorithm
obtains competitively improved results compared to the state-of-the-art.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h3>Title: Towards Few-Call Model Stealing via Active Self-Paced Knowledge Distillation and Diffusion-Based Image Generation. (arXiv:2310.00096v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00096">http://arxiv.org/abs/2310.00096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00096]] Towards Few-Call Model Stealing via Active Self-Paced Knowledge Distillation and Diffusion-Based Image Generation(http://arxiv.org/abs/2310.00096)</code></li>
<li>Summary: <p>Diffusion models showcased strong capabilities in image synthesis, being used
in many computer vision tasks with great success. To this end, we propose to
explore a new use case, namely to copy black-box classification models without
having access to the original training data, the architecture, and the weights
of the model, \ie~the model is only exposed through an inference API. More
specifically, we can only observe the (soft or hard) labels for some image
samples passed as input to the model. Furthermore, we consider an additional
constraint limiting the number of model calls, mostly focusing our research on
few-call model stealing. In order to solve the model extraction task given the
applied restrictions, we propose the following framework. As training data, we
create a synthetic data set (called proxy data set) by leveraging the ability
of diffusion models to generate realistic and diverse images. Given a maximum
number of allowed API calls, we pass the respective number of samples through
the black-box model to collect labels. Finally, we distill the knowledge of the
black-box teacher (attacked model) into a student model (copy of the attacked
model), harnessing both labeled and unlabeled data generated by the diffusion
model. We employ a novel active self-paced learning framework to make the most
of the proxy data during distillation. Our empirical results on two data sets
confirm the superiority of our framework over two state-of-the-art methods in
the few-call model extraction scenario.
</p></li>
</ul>

<h2>extraction</h2>
<h3>Title: PRIME: Prioritizing Interpretability in Failure Mode Extraction. (arXiv:2310.00164v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00164">http://arxiv.org/abs/2310.00164</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00164]] PRIME: Prioritizing Interpretability in Failure Mode Extraction(http://arxiv.org/abs/2310.00164)</code></li>
<li>Summary: <p>In this work, we study the challenge of providing human-understandable
descriptions for failure modes in trained image classification models. Existing
works address this problem by first identifying clusters (or directions) of
incorrectly classified samples in a latent space and then aiming to provide
human-understandable text descriptions for them. We observe that in some cases,
describing text does not match well with identified failure modes, partially
owing to the fact that shared interpretable attributes of failure modes may not
be captured using clustering in the feature space. To improve on these
shortcomings, we propose a novel approach that prioritizes interpretability in
this problem: we start by obtaining human-understandable concepts (tags) of
images in the dataset and then analyze the model's behavior based on the
presence or absence of combinations of these tags. Our method also ensures that
the tags describing a failure mode form a minimal set, avoiding redundant and
noisy descriptions. Through several experiments on different datasets, we show
that our method successfully identifies failure modes and generates
high-quality text descriptions associated with them. These results highlight
the importance of prioritizing interpretability in understanding model
failures.
</p></li>
</ul>

<h3>Title: Voice2Action: Language Models as Agent for Efficient Real-Time Interaction in Virtual Reality. (arXiv:2310.00092v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00092">http://arxiv.org/abs/2310.00092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00092]] Voice2Action: Language Models as Agent for Efficient Real-Time Interaction in Virtual Reality(http://arxiv.org/abs/2310.00092)</code></li>
<li>Summary: <p>Large Language Models (LLMs) are trained and aligned to follow natural
language instructions with only a handful of examples, and they are prompted as
task-driven autonomous agents to adapt to various sources of execution
environments. However, deploying agent LLMs in virtual reality (VR) has been
challenging due to the lack of efficiency in online interactions and the
complex manipulation categories in 3D environments. In this work, we propose
Voice2Action, a framework that hierarchically analyzes customized voice signals
and textual commands through action and entity extraction and divides the
execution tasks into canonical interaction subsets in real-time with error
prevention from environment feedback. Experiment results in an urban
engineering VR environment with synthetic instruction data show that
Voice2Action can perform more efficiently and accurately than approaches
without optimizations.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning. (arXiv:2310.00141v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00141">http://arxiv.org/abs/2310.00141</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00141]] The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning(http://arxiv.org/abs/2310.00141)</code></li>
<li>Summary: <p>Automatic speech recognition (ASR) models are typically trained on large
datasets of transcribed speech. As language evolves and new terms come into
use, these models can become outdated and stale. In the context of models
trained on the server but deployed on edge devices, errors may result from the
mismatch between server training data and actual on-device usage. In this work,
we seek to continually learn from on-device user corrections through Federated
Learning (FL) to address this issue. We explore techniques to target fresh
terms that the model has not previously encountered, learn long-tail words, and
mitigate catastrophic forgetting. In experimental evaluations, we find that the
proposed techniques improve model recognition of fresh terms, while preserving
quality on the overall language distribution.
</p></li>
</ul>

<h3>Title: FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things. (arXiv:2310.00109v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00109">http://arxiv.org/abs/2310.00109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00109]] FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things(http://arxiv.org/abs/2310.00109)</code></li>
<li>Summary: <p>There is a significant relevance of federated learning (FL) in the realm of
Artificial Intelligence of Things (AIoT). However, most existing FL works are
not conducted on datasets collected from authentic IoT devices that capture
unique modalities and inherent challenges of IoT data. In this work, we
introduce FedAIoT, an FL benchmark for AIoT to fill this critical gap. FedAIoT
includes eight datatsets collected from a wide range of IoT devices. These
datasets cover unique IoT modalities and target representative applications of
AIoT. FedAIoT also includes a unified end-to-end FL framework for AIoT that
simplifies benchmarking the performance of the datasets. Our benchmark results
shed light on the opportunities and challenges of FL for AIoT. We hope FedAIoT
could serve as an invaluable resource to foster advancements in the important
field of FL for AIoT. The repository of FedAIoT is maintained at
https://github.com/AIoT-MLSys-Lab/FedAIoT.
</p></li>
</ul>

<h3>Title: Accelerating Non-IID Federated Learning via Heterogeneity-Guided Client Sampling. (arXiv:2310.00198v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00198">http://arxiv.org/abs/2310.00198</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00198]] Accelerating Non-IID Federated Learning via Heterogeneity-Guided Client Sampling(http://arxiv.org/abs/2310.00198)</code></li>
<li>Summary: <p>Statistical heterogeneity of data present at client devices in a federated
learning (FL) system renders the training of a global model in such systems
difficult. Particularly challenging are the settings where due to resource
constraints only a small fraction of clients can participate in any given round
of FL. Recent approaches to training a global model in FL systems with non-IID
data have focused on developing client selection methods that aim to sample
clients with more informative updates of the model. However, existing client
selection techniques either introduce significant computation overhead or
perform well only in the scenarios where clients have data with similar
heterogeneity profiles. In this paper, we propose HiCS-FL (Federated Learning
via Hierarchical Clustered Sampling), a novel client selection method in which
the server estimates statistical heterogeneity of a client's data using the
client's update of the network's output layer and relies on this information to
cluster and sample the clients. We analyze the ability of the proposed
techniques to compare heterogeneity of different datasets, and characterize
convergence of the training process that deploys the introduced client
selection method. Extensive experimental results demonstrate that in non-IID
settings HiCS-FL achieves faster convergence and lower training variance than
state-of-the-art FL client selection schemes. Notably, HiCS-FL drastically
reduces computation cost compared to existing selection schemes and is
adaptable to different heterogeneity scenarios.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: The Sem-Lex Benchmark: Modeling ASL Signs and Their Phonemes. (arXiv:2310.00196v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00196">http://arxiv.org/abs/2310.00196</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00196]] The Sem-Lex Benchmark: Modeling ASL Signs and Their Phonemes(http://arxiv.org/abs/2310.00196)</code></li>
<li>Summary: <p>Sign language recognition and translation technologies have the potential to
increase access and inclusion of deaf signing communities, but research
progress is bottlenecked by a lack of representative data. We introduce a new
resource for American Sign Language (ASL) modeling, the Sem-Lex Benchmark. The
Benchmark is the current largest of its kind, consisting of over 84k videos of
isolated sign productions from deaf ASL signers who gave informed consent and
received compensation. Human experts aligned these videos with other sign
language resources including ASL-LEX, SignBank, and ASL Citizen, enabling
useful expansions for sign and phonological feature recognition. We present a
suite of experiments which make use of the linguistic information in ASL-LEX,
evaluating the practicality and fairness of the Sem-Lex Benchmark for isolated
sign recognition (ISR). We use an SL-GCN model to show that the phonological
features are recognizable with 85% accuracy, and that they are effective as an
auxiliary target to ISR. Learning to recognize phonological features alongside
gloss results in a 6% improvement for few-shot ISR accuracy and a 2%
improvement for ISR accuracy overall. Instructions for downloading the data can
be found at https://github.com/leekezar/SemLex.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: LSOR: Longitudinally-Consistent Self-Organized Representation Learning. (arXiv:2310.00213v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00213">http://arxiv.org/abs/2310.00213</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00213]] LSOR: Longitudinally-Consistent Self-Organized Representation Learning(http://arxiv.org/abs/2310.00213)</code></li>
<li>Summary: <p>Interpretability is a key issue when applying deep learning models to
longitudinal brain MRIs. One way to address this issue is by visualizing the
high-dimensional latent spaces generated by deep learning via self-organizing
maps (SOM). SOM separates the latent space into clusters and then maps the
cluster centers to a discrete (typically 2D) grid preserving the
high-dimensional relationship between clusters. However, learning SOM in a
high-dimensional latent space tends to be unstable, especially in a
self-supervision setting. Furthermore, the learned SOM grid does not
necessarily capture clinically interesting information, such as brain age. To
resolve these issues, we propose the first self-supervised SOM approach that
derives a high-dimensional, interpretable representation stratified by brain
age solely based on longitudinal brain MRIs (i.e., without demographic or
cognitive information). Called Longitudinally-consistent Self-Organized
Representation learning (LSOR), the method is stable during training as it
relies on soft clustering (vs. the hard cluster assignments used by existing
SOM). Furthermore, our approach generates a latent space stratified according
to brain age by aligning trajectories inferred from longitudinal MRIs to the
reference vector associated with the corresponding SOM cluster. When applied to
longitudinal MRIs of the Alzheimer's Disease Neuroimaging Initiative (ADNI,
N=632), LSOR generates an interpretable latent space and achieves comparable or
higher accuracy than the state-of-the-art representations with respect to the
downstream tasks of classification (static vs. progressive mild cognitive
impairment) and regression (determining ADAS-Cog score of all subjects). The
code is available at
https://github.com/ouyangjiahong/longitudinal-som-single-modality.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Adversarial Explainability: Utilizing Explainable Machine Learning in Bypassing IoT Botnet Detection Systems. (arXiv:2310.00070v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00070">http://arxiv.org/abs/2310.00070</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00070]] Adversarial Explainability: Utilizing Explainable Machine Learning in Bypassing IoT Botnet Detection Systems(http://arxiv.org/abs/2310.00070)</code></li>
<li>Summary: <p>Botnet detection based on machine learning have witnessed significant leaps
in recent years, with the availability of large and reliable datasets that are
extracted from real-life scenarios. Consequently, adversarial attacks on
machine learning-based cybersecurity systems are posing a significant threat to
the practicality of these solutions. In this paper, we introduce a novel attack
that utilizes machine learning model's explainability in evading detection by
botnet detection systems. The proposed attack utilizes information obtained
from model's explainability to build adversarial samples that can evade
detection in a blackbox setting. The proposed attack was tested on a trained
IoT botnet detection systems and was capable of bypassing the botnet detection
with 0% detection by altering one feature only to generate the adversarial
samples.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Text-image Alignment for Diffusion-based Perception. (arXiv:2310.00031v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00031">http://arxiv.org/abs/2310.00031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00031]] Text-image Alignment for Diffusion-based Perception(http://arxiv.org/abs/2310.00031)</code></li>
<li>Summary: <p>Diffusion models are generative models with impressive text-to-image
synthesis capabilities and have spurred a new wave of creative methods for
classical machine learning tasks. However, the best way to harness the
perceptual knowledge of these generative models for visual tasks is still an
open question. Specifically, it is unclear how to use the prompting interface
when applying diffusion backbones to vision tasks. We find that automatically
generated captions can improve text-image alignment and significantly enhance a
model's cross-attention maps, leading to better perceptual performance. Our
approach improves upon the current SOTA in diffusion-based semantic
segmentation on ADE20K and the current overall SOTA in depth estimation on
NYUv2. Furthermore, our method generalizes to the cross-domain setting; we use
model personalization and caption modifications to align our model to the
target domain and find improvements over unaligned baselines. Our object
detection model, trained on Pascal VOC, achieves SOTA results on Watercolor2K.
Our segmentation method, trained on Cityscapes, achieves SOTA results on Dark
Zurich-val and Nighttime Driving.
</p></li>
</ul>

<h3>Title: FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery. (arXiv:2310.00106v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00106">http://arxiv.org/abs/2310.00106</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00106]] FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery(http://arxiv.org/abs/2310.00106)</code></li>
<li>Summary: <p>Our study introduces a new image-to-video generator called FashionFlow. By
utilising a diffusion model, we are able to create short videos from still
images. Our approach involves developing and connecting relevant components
with the diffusion model, which sets our work apart. The components include the
use of pseudo-3D convolutional layers to generate videos efficiently. VAE and
CLIP encoders capture vital characteristics from still images to influence the
diffusion model. Our research demonstrates a successful synthesis of fashion
videos featuring models posing from various angles, showcasing the fit and
appearance of the garment. Our findings hold great promise for improving and
enhancing the shopping experience for the online fashion industry.
</p></li>
</ul>

<h3>Title: Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional Image Synthesis. (arXiv:2310.00224v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00224">http://arxiv.org/abs/2310.00224</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00224]] Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional Image Synthesis(http://arxiv.org/abs/2310.00224)</code></li>
<li>Summary: <p>Conditional generative models typically demand large annotated training sets
to achieve high-quality synthesis. As a result, there has been significant
interest in designing models that perform plug-and-play generation, i.e., to
use a predefined or pretrained model, which is not explicitly trained on the
generative task, to guide the generative process (e.g., using language).
However, such guidance is typically useful only towards synthesizing high-level
semantics rather than editing fine-grained details as in image-to-image
translation tasks. To this end, and capitalizing on the powerful fine-grained
generative control offered by the recent diffusion-based generative models, we
introduce Steered Diffusion, a generalized framework for photorealistic
zero-shot conditional image generation using a diffusion model trained for
unconditional generation. The key idea is to steer the image generation of the
diffusion model at inference time via designing a loss using a pre-trained
inverse model that characterizes the conditional task. This loss modulates the
sampling trajectory of the diffusion process. Our framework allows for easy
incorporation of multiple conditions during inference. We present experiments
using steered diffusion on several tasks including inpainting, colorization,
text-guided semantic editing, and image super-resolution. Our results
demonstrate clear qualitative and quantitative improvements over
state-of-the-art diffusion-based plug-and-play models while adding negligible
additional computational cost.
</p></li>
</ul>

<h3>Title: On the Counting of Involutory MDS Matrices. (arXiv:2310.00090v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00090">http://arxiv.org/abs/2310.00090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00090]] On the Counting of Involutory MDS Matrices(http://arxiv.org/abs/2310.00090)</code></li>
<li>Summary: <p>The optimal branch number of MDS matrices has established their prominence in
the design of diffusion layers for various block ciphers and hash functions.
Consequently, several matrix structures have been proposed for designing MDS
matrices, including Hadamard and circulant matrices. In this paper, we first
provide the count of Hadamard MDS matrices of order $4$ over the field
$\mathbb{F}_{2^r}$. Subsequently, we present the counts of order $2$ MDS
matrices and order $2$ involutory MDS matrices over the field
$\mathbb{F}_{2^r}$. Finally, leveraging these counts of order $2$ matrices, we
derive an upper bound for the number of all involutory MDS matrices of order
$4$ over $\mathbb{F}_{2^r}$.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00100">http://arxiv.org/abs/2310.00100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00100]] Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!(http://arxiv.org/abs/2310.00100)</code></li>
<li>Summary: <p>The impression section of a radiology report summarizes important radiology
findings and plays a critical role in communicating these findings to
physicians. However, the preparation of these summaries is time-consuming and
error-prone for radiologists. Recently, numerous models for radiology report
summarization have been developed. Nevertheless, there is currently no model
that can summarize these reports in multiple languages. Such a model could
greatly improve future research and the development of Deep Learning models
that incorporate data from patients with different ethnic backgrounds. In this
study, the generation of radiology impressions in different languages was
automated by fine-tuning a model, publicly available, based on a multilingual
text-to-text Transformer to summarize findings available in English,
Portuguese, and German radiology reports. In a blind test, two board-certified
radiologists indicated that for at least 70% of the system-generated summaries,
the quality matched or exceeded the corresponding human-written summaries,
suggesting substantial clinical reliability. Furthermore, this study showed
that the multilingual model outperformed other models that specialized in
summarizing radiology reports in only one language, as well as models that were
not specifically designed for summarizing radiology reports, such as ChatGPT.
</p></li>
</ul>

<h3>Title: De-SaTE: Denoising Self-attention Transformer Encoders for Li-ion Battery Health Prognostics. (arXiv:2310.00023v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00023">http://arxiv.org/abs/2310.00023</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00023]] De-SaTE: Denoising Self-attention Transformer Encoders for Li-ion Battery Health Prognostics(http://arxiv.org/abs/2310.00023)</code></li>
<li>Summary: <p>Lithium Ion (Li-ion) batteries have gained widespread popularity across
various industries, from powering portable electronic devices to propelling
electric vehicles and supporting energy storage systems. A central challenge in
managing Li-ion batteries effectively is accurately predicting their Remaining
Useful Life (RUL), which is a critical measure for proactive maintenance and
predictive analytics. This study presents a novel approach that harnesses the
power of multiple denoising modules, each trained to address specific types of
noise commonly encountered in battery data. Specifically we use a denoising
auto-encoder and a wavelet denoiser to generate encoded/decomposed
representations, which are subsequently processed through dedicated
self-attention transformer encoders. After extensive experimentation on the
NASA and CALCE datasets, we are able to characterize a broad spectrum of health
indicator estimations under a set of diverse noise patterns. We find that our
reported error metrics on these datasets are on par or better with the best
reported in recent literature.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Prompt-Enhanced Self-supervised Representation Learning for Remote Sensing Image Understanding. (arXiv:2310.00022v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00022">http://arxiv.org/abs/2310.00022</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00022]] Prompt-Enhanced Self-supervised Representation Learning for Remote Sensing Image Understanding(http://arxiv.org/abs/2310.00022)</code></li>
<li>Summary: <p>Learning representations through self-supervision on a large-scale, unlabeled
dataset has proven to be highly effective for understanding diverse images,
such as those used in remote sensing image analysis. However, remote sensing
images often have complex and densely populated scenes, with multiple land
objects and no clear foreground objects. This intrinsic property can lead to
false positive pairs in contrastive learning, or missing contextual information
in reconstructive learning, which can limit the effectiveness of existing
self-supervised learning methods. To address these problems, we propose a
prompt-enhanced self-supervised representation learning method that uses a
simple yet efficient pre-training pipeline. Our approach involves utilizing
original image patches as a reconstructive prompt template, and designing a
prompt-enhanced generative branch that provides contextual information through
semantic consistency constraints. We collected a dataset of over 1.28 million
remote sensing images that is comparable to the popular ImageNet dataset, but
without specific temporal or geographical constraints. Our experiments show
that our method outperforms fully supervised learning models and
state-of-the-art self-supervised learning methods on various downstream tasks,
including land cover classification, semantic segmentation, object detection,
and instance segmentation. These results demonstrate that our approach learns
impressive remote sensing representations with high generalization and
transferability.
</p></li>
</ul>

<h3>Title: Feedback-guided Data Synthesis for Imbalanced Classification. (arXiv:2310.00158v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00158">http://arxiv.org/abs/2310.00158</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00158]] Feedback-guided Data Synthesis for Imbalanced Classification(http://arxiv.org/abs/2310.00158)</code></li>
<li>Summary: <p>Current status quo in machine learning is to use static datasets of real
images for training, which often come from long-tailed distributions. With the
recent advances in generative models, researchers have started augmenting these
static datasets with synthetic data, reporting moderate performance
improvements on classification tasks. We hypothesize that these performance
gains are limited by the lack of feedback from the classifier to the generative
model, which would promote the usefulness of the generated samples to improve
the classifier's performance. In this work, we introduce a framework for
augmenting static datasets with useful synthetic samples, which leverages
one-shot feedback from the classifier to drive the sampling of the generative
model. In order for the framework to be effective, we find that the samples
must be close to the support of the real data of the task at hand, and be
sufficiently diverse. We validate three feedback criteria on a long-tailed
dataset (ImageNet-LT) as well as a group-imbalanced dataset (NICO++). On
ImageNet-LT, we achieve state-of-the-art results, with over 4 percent
improvement on underrepresented classes while being twice efficient in terms of
the number of generated synthetic samples. NICO++ also enjoys marked boosts of
over 5 percent in worst group accuracy. With these results, our framework paves
the path towards effectively leveraging state-of-the-art text-to-image models
as data sources that can be queried to improve downstream applications.
</p></li>
</ul>

<h3>Title: Latent Space Symmetry Discovery. (arXiv:2310.00105v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00105">http://arxiv.org/abs/2310.00105</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00105]] Latent Space Symmetry Discovery(http://arxiv.org/abs/2310.00105)</code></li>
<li>Summary: <p>Equivariant neural networks require explicit knowledge of the symmetry group.
Automatic symmetry discovery methods aim to relax this constraint and learn
invariance and equivariance from data. However, existing symmetry discovery
methods are limited to linear symmetries in their search space and cannot
handle the complexity of symmetries in real-world, often high-dimensional data.
We propose a novel generative model, Latent LieGAN (LaLiGAN), which can
discover nonlinear symmetries from data. It learns a mapping from data to a
latent space where the symmetries become linear and simultaneously discovers
symmetries in the latent space. Theoretically, we show that our method can
express any nonlinear symmetry under certain conditions. Experimentally, our
method can capture the intrinsic symmetry in high-dimensional observations,
which results in a well-structured latent space that is useful for other
downstream tasks. We demonstrate the use cases for LaLiGAN in improving
equation discovery and long-term forecasting for various dynamical systems.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: PB-LLM: Partially Binarized Large Language Models. (arXiv:2310.00034v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00034">http://arxiv.org/abs/2310.00034</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00034]] PB-LLM: Partially Binarized Large Language Models(http://arxiv.org/abs/2310.00034)</code></li>
<li>Summary: <p>This paper explores network binarization, a radical form of quantization,
compressing model weights to a single bit, specifically for Large Language
Models (LLMs) compression. Due to previous binarization methods collapsing
LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can
achieve extreme low-bit quantization while maintaining the linguistic reasoning
capacity of quantized LLMs. Specifically, our exploration first uncovers the
ineffectiveness of naive applications of existing binarization algorithms and
highlights the imperative role of salient weights in achieving low-bit
quantization. Thus, PB-LLM filters a small ratio of salient weights during
binarization, allocating them to higher-bit storage, i.e.,
partially-binarization. PB-LLM is extended to recover the capacities of
quantized LMMs, by analyzing from the perspective of post-training quantization
(PTQ) and quantization-aware training (QAT). Under PTQ, combining the concepts
from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian
matrix and successfully recover the reasoning capacity of PB-LLM in low-bit.
Under QAT, we freeze the salient weights during training, explore the
derivation of optimal scaling factors crucial for minimizing the quantization
error, and propose a scaling mechanism based on this derived scaling strategy
for residual binarized weights. Those explorations and the developed
methodologies significantly contribute to rejuvenating the performance of
low-bit quantized LLMs and present substantial advancements in the field of
network binarization for LLMs.The code is available at
https://github.com/hahnyuan/BinaryLLM.
</p></li>
</ul>

<h3>Title: SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation. (arXiv:2310.00074v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00074">http://arxiv.org/abs/2310.00074</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00074]] SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation(http://arxiv.org/abs/2310.00074)</code></li>
<li>Summary: <p>To comprehensively assess the capacity of current models for complex
reasoning, it is crucial to assess their step-by-step reasoning in a scalable
manner. Established reference-based evaluation metrics rely on human-annotated
reasoning chains to assess the model-derived chains. However, such
``gold-standard'' human-written reasoning chains may not be unique and their
acquisition is often labor-intensive. Existing reference-free reasoning metrics
eliminate the need for human-crafted reasoning chains as references, but they
typically require fine-tuning on datasets with human-derived reasoning chains,
which complicates the process and raises concerns regarding generalizability
across diverse datasets. To address these challenges, we harness GPT-4 to
automatically evaluate reasoning chain quality, obviating the need for
human-crafted references. Leveraging the Socratic method, we devise tailored
prompts to enhance reference-free reasoning evaluation, which we term SocREval
(Socratic method for Reasoning Evaluation). Empirical results from four human
annotated datasets reveal that SocREval significantly improves GPT-4's
performance, surpassing existing reference-free and reference-based reasoning
evaluation metrics. Beyond its demonstrated efficacy, our proposed framework,
large language models (LLMs) with the Socratic method, proves to be both
cost-efficient and robust to prompt writing and example selection, as
substantiated by our in-depth analysis.
</p></li>
</ul>

<h3>Title: Automatic Prompt Rewriting for Personalized Text Generation. (arXiv:2310.00152v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00152">http://arxiv.org/abs/2310.00152</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00152]] Automatic Prompt Rewriting for Personalized Text Generation(http://arxiv.org/abs/2310.00152)</code></li>
<li>Summary: <p>Facilitated by large language models (LLMs), personalized text generation has
become a rapidly growing research direction. Most existing studies focus on
designing specialized models for a particular domain, or they require
fine-tuning the LLMs to generate personalized text. We consider a typical
scenario in which the large language model, which generates personalized
output, is frozen and can only be accessed through APIs. Under this constraint,
all one can do is to improve the input text (i.e., text prompts) sent to the
LLM, a procedure that is usually done manually. In this paper, we propose a
novel method to automatically revise prompts for personalized text generation.
The proposed method takes the initial prompts generated by a state-of-the-art,
multistage framework for personalized generation and rewrites a few critical
components that summarize and synthesize the personal context. The prompt
rewriter employs a training paradigm that chains together supervised learning
(SL) and reinforcement learning (RL), where SL reduces the search space of RL
and RL facilitates end-to-end training of the rewriter. Using datasets from
three representative domains, we demonstrate that the rewritten prompts
outperform both the original prompts and the prompts optimized via supervised
learning or reinforcement learning alone. In-depth analysis of the rewritten
prompts shows that they are not only human readable, but also able to guide
manual revision of prompts when there is limited resource to employ
reinforcement learning to train the prompt rewriter, or when it is costly to
deploy an automatic prompt rewriter for inference.
</p></li>
</ul>

<h3>Title: Self-Specialization: Uncovering Latent Expertise within Large Language Models. (arXiv:2310.00160v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00160">http://arxiv.org/abs/2310.00160</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00160]] Self-Specialization: Uncovering Latent Expertise within Large Language Models(http://arxiv.org/abs/2310.00160)</code></li>
<li>Summary: <p>Recent works have demonstrated the effectiveness of self-alignment in which a
large language model is, by itself, aligned to follow general instructions
through the automatic generation of instructional data using a handful of
human-written seeds. Instead of general alignment, in this work, we focus on
self-alignment for expert domain specialization (e.g., biomedicine),
discovering it to be very effective for improving zero-shot and few-shot
performance in target domains of interest. As a preliminary, we first present
the benchmark results of existing aligned models within a specialized domain,
which reveals the marginal effect that "generic" instruction-following training
has on downstream expert domains' performance. To remedy this, we explore
self-specialization that leverages domain-specific unlabelled data and a few
labeled seeds for the self-alignment process. When augmented with retrieval to
reduce hallucination and enhance concurrency of the alignment,
self-specialization offers an effective (and efficient) way of "carving out" an
expert model out of a "generalist", pre-trained LLM where different domains of
expertise are originally combined in a form of "superposition". Our
experimental results on a biomedical domain show that our self-specialized
model (30B) outperforms its base model, MPT-30B by a large margin and even
surpasses larger popular models based on LLaMA-65B, highlighting its potential
and practicality for specialization, especially considering its efficiency in
terms of data and parameters.
</p></li>
</ul>

<h3>Title: Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. (arXiv:2310.00212v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00212">http://arxiv.org/abs/2310.00212</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00212]] Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment(http://arxiv.org/abs/2310.00212)</code></li>
<li>Summary: <p>Large Language Models (LLMs) can acquire extensive world knowledge through
pre-training on large corpora. However, due to exposure to low-quality data,
LLMs may exhibit harmful behavior without aligning with human values. The
dominant approach for steering LLMs towards beneficial behavior involves
Reinforcement Learning with Human Feedback (RLHF), with Proximal Policy
Optimization (PPO) serving as the default RL optimizer. Despite its
effectiveness, PPO has limitations when optimizing rewards trained from
comparison-based loss. Primarily, PPO is not invariant to equivalent reward
functions containing identical preference information due to the need to
calibrate the reward scale. Additionally, PPO's necessity for token-wise
updates introduces complexity in both function approximation and algorithm
design compared to trajectory-wise optimization. This paper proposes a new
framework, reinforcement learning with relative feedback, and a novel
trajectory-wise policy gradient algorithm, Pairwise Proximal Policy
Optimization (P3O) that operates directly on comparative rewards. We show
theoretically that P3O is invariant to equivalent rewards and avoids the
complexity of PPO. Empirical evaluations demonstrate that P3O outperforms PPO
in the KL-Reward trade-off and can align with human preferences as well as or
better than prior methods. In summary, this work introduces a simpler yet
effective approach for aligning LLMs to human preferences through relative
feedback.
</p></li>
</ul>

<h3>Title: LoRA ensembles for large language model fine-tuning. (arXiv:2310.00035v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00035">http://arxiv.org/abs/2310.00035</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00035]] LoRA ensembles for large language model fine-tuning(http://arxiv.org/abs/2310.00035)</code></li>
<li>Summary: <p>Finetuned LLMs often exhibit poor uncertainty quantification, manifesting as
overconfidence, poor calibration, and unreliable prediction results on test
data or out-of-distribution samples. One approach commonly used in vision for
alleviating this issue is a deep ensemble, which constructs an ensemble by
training the same model multiple times using different random initializations.
However, there is a huge challenge to ensembling LLMs: the most effective LLMs
are very, very large. Keeping a single LLM in memory is already challenging
enough: keeping an ensemble of e.g. 5 LLMs in memory is impossible in many
settings. To address these issues, we propose an ensemble approach using
Low-Rank Adapters (LoRA), a parameter-efficient fine-tuning technique.
Critically, these low-rank adapters represent a very small number of
parameters, orders of magnitude less than the underlying pre-trained model.
Thus, it is possible to construct large ensembles of LoRA adapters with almost
the same computational overhead as using the original model. We find that LoRA
ensembles, applied on its own or on top of pre-existing regularization
techniques, gives consistent improvements in predictive accuracy and
uncertainty quantification.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Joint Self-supervised Depth and Optical Flow Estimation towards Dynamic Objects. (arXiv:2310.00011v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00011">http://arxiv.org/abs/2310.00011</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00011]] Joint Self-supervised Depth and Optical Flow Estimation towards Dynamic Objects(http://arxiv.org/abs/2310.00011)</code></li>
<li>Summary: <p>Significant attention has been attracted to deep learning-based depth
estimates. Dynamic objects become the most hard problems in
inter-frame-supervised depth estimates due to the uncertainty in adjacent
frames. Thus, integrating optical flow information with depth estimation is a
feasible solution, as the optical flow is an essential motion representation.
In this work, we construct a joint inter-frame-supervised depth and optical
flow estimation framework, which predicts depths in various motions by
minimizing pixel wrap errors in bilateral photometric re-projections and
optical vectors. For motion segmentation, we adaptively segment the preliminary
estimated optical flow map with large areas of connectivity. In self-supervised
depth estimation, different motion regions are predicted independently and then
composite into a complete depth. Further, the pose and depth estimations
re-synthesize the optical flow maps, serving to compute reconstruction errors
with the preliminary predictions. Our proposed joint depth and optical flow
estimation outperforms existing depth estimators on the KITTI Depth dataset,
both with and without Cityscapes pretraining. Additionally, our optical flow
results demonstrate competitive performance on the KITTI Flow 2015 dataset.
</p></li>
</ul>

<h3>Title: Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition. (arXiv:2310.00132v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00132">http://arxiv.org/abs/2310.00132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00132]] Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition(http://arxiv.org/abs/2310.00132)</code></li>
<li>Summary: <p>Audiovisual segmentation (AVS) is a challenging task that aims to segment
visual objects in videos based on their associated acoustic cues. With multiple
sound sources involved, establishing robust correspondences between audio and
visual contents poses unique challenges due to its (1) intricate entanglement
across sound sources and (2) frequent shift among sound events. Assuming sound
events occur independently, the multi-source semantic space (which encompasses
all possible semantic categories) can be viewed as the Cartesian product of
single-source sub-spaces. This motivates us to decompose the multi-source audio
semantics into single-source semantics, allowing for more effective interaction
with visual content. Specifically, we propose a semantic decomposition method
based on product quantization, where the multi-source semantics can be
decomposed and represented by several quantized single-source semantics.
Furthermore, we introduce a global-to-local quantization mechanism that
distills knowledge from stable global (clip-level) features into local
(frame-level) ones to handle the constant shift of audio semantics. Extensive
experiments demonstrate that semantically quantized and decomposed audio
representation significantly improves AVS performance, e.g., +21.2% mIoU on the
most challenging AVS-Semantic benchmark.
</p></li>
</ul>

<h3>Title: DeformUX-Net: Exploring a 3D Foundation Backbone for Medical Image Segmentation with Depthwise Deformable Convolution. (arXiv:2310.00199v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.00199">http://arxiv.org/abs/2310.00199</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.00199]] DeformUX-Net: Exploring a 3D Foundation Backbone for Medical Image Segmentation with Depthwise Deformable Convolution(http://arxiv.org/abs/2310.00199)</code></li>
<li>Summary: <p>The application of 3D ViTs to medical image segmentation has seen remarkable
strides, somewhat overshadowing the budding advancements in Convolutional
Neural Network (CNN)-based models. Large kernel depthwise convolution has
emerged as a promising technique, showcasing capabilities akin to hierarchical
transformers and facilitating an expansive effective receptive field (ERF)
vital for dense predictions. Despite this, existing core operators, ranging
from global-local attention to large kernel convolution, exhibit inherent
trade-offs and limitations (e.g., global-local range trade-off, aggregating
attentional features). We hypothesize that deformable convolution can be an
exploratory alternative to combine all advantages from the previous operators,
providing long-range dependency, adaptive spatial aggregation and computational
efficiency as a foundation backbone. In this work, we introduce 3D
DeformUX-Net, a pioneering volumetric CNN model that adeptly navigates the
shortcomings traditionally associated with ViTs and large kernel convolution.
Specifically, we revisit volumetric deformable convolution in depth-wise
setting to adapt long-range dependency with computational efficiency. Inspired
by the concepts of structural re-parameterization for convolution kernel
weights, we further generate the deformable tri-planar offsets by adapting a
parallel branch (starting from $1\times1\times1$ convolution), providing
adaptive spatial aggregation across all channels. Our empirical evaluations
reveal that the 3D DeformUX-Net consistently outperforms existing
state-of-the-art ViTs and large kernel convolution models across four
challenging public datasets, spanning various scales from organs (KiTS: 0.680
to 0.720, MSD Pancreas: 0.676 to 0.717, AMOS: 0.871 to 0.902) to vessels (e.g.,
MSD hepatic vessels: 0.635 to 0.671) in mean Dice.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
