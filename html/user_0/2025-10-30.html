<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-10-30</h1>
<h3>Title: Iti-Validator: A Guardrail Framework for Validating and Correcting LLM-Generated Itineraries</h3>
<ul>
<li><strong>Authors: </strong>Shravan Gadbail, Masumi Desai, Kamalakar Karlapalem</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24719">https://arxiv.org/abs/2510.24719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24719">https://arxiv.org/pdf/2510.24719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24719]] Iti-Validator: A Guardrail Framework for Validating and Correcting LLM-Generated Itineraries(https://arxiv.org/abs/2510.24719)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) has enabled them to generate complex, multi-step plans and itineraries. However, these generated plans often lack temporal and spatial consistency, particularly in scenarios involving physical travel constraints. This research aims to study the temporal performance of different LLMs and presents a validation framework that evaluates and improves the temporal consistency of LLM-generated travel itineraries. The system employs multiple state-of-the-art LLMs to generate travel plans and validates them against real-world flight duration constraints using the AeroDataBox API. This work contributes to the understanding of LLM capabilities in handling complex temporal reasoning tasks like itinerary generation and provides a framework to rectify any temporal inconsistencies like overlapping journeys or unrealistic transit times in the itineraries generated by LLMs before the itinerary is given to the user. Our experiments reveal that while current LLMs frequently produce temporally inconsistent itineraries, these can be systematically and reliably corrected using our framework, enabling their practical deployment in large-scale travel planning.</li>
</ul>

<h3>Title: Falcon: A Comprehensive Chinese Text-to-SQL Benchmark for Enterprise-Grade Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Wenzhen Luo, Wei Guan, Yifan Yao, Yimin Pan, Feng Wang, Zhipeng Yu, Zhe Wen, Liang Chen, Yihong Zhuang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24762">https://arxiv.org/abs/2510.24762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24762">https://arxiv.org/pdf/2510.24762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24762]] Falcon: A Comprehensive Chinese Text-to-SQL Benchmark for Enterprise-Grade Evaluation(https://arxiv.org/abs/2510.24762)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce Falcon, a cross-domain Chinese text-to-SQL benchmark grounded in an enterprise-compatible dialect (MaxCompute/Hive). It contains 600 Chinese questions over 28 databases; 77% require multi-table reasoning and over half touch more than four tables. Each example is annotated along SQL-computation features and Chinese semantics. For evaluation, we release a robust execution comparator and an automated evaluation pipeline, under which all current state-of-the-art large-scale models (including Deepseek) achieve accuracies of at most 50%. Major errors originate from two sources: (1) schema linking in large enterprise landscapes - hundreds of tables, denormalized fields, ambiguous column names, implicit foreign-key relations and domain-specific synonyms that make correct join/column selection difficult; and (2) mapping concise, colloquial Chinese into the exact operators and predicates required for analytics - e.g., choosing the correct aggregation and group-by keys, expressing time windows and granularities, applying unit conversions, handling NULLs and data-quality rules, and formulating nested or windowed subqueries. Falcon therefore targets Chinese-specific semantics and enterprise dialects (abbreviations, business jargon, fuzzy entity references) and provides a reproducible middle ground before full production deployment by using realistic enterprise schemas, query templates, an execution comparator, and an automated evaluation pipeline for end-to-end validation.</li>
</ul>

<h3>Title: Towards Fine-Grained Human Motion Video Captioning</h3>
<ul>
<li><strong>Authors: </strong>Guorui Song, Guocun Wang, Zhe Huang, Jing Lin, Xuefei Zhe, Jian Li, Haoqian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24767">https://arxiv.org/abs/2510.24767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24767">https://arxiv.org/pdf/2510.24767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24767]] Towards Fine-Grained Human Motion Video Captioning(https://arxiv.org/abs/2510.24767)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generating accurate descriptions of human actions in videos remains a challenging task for video captioning models. Existing approaches often struggle to capture fine-grained motion details, resulting in vague or semantically inconsistent captions. In this work, we introduce the Motion-Augmented Caption Model (M-ACM), a novel generative framework that enhances caption quality by incorporating motion-aware decoding. At its core, M-ACM leverages motion representations derived from human mesh recovery to explicitly highlight human body dynamics, thereby reducing hallucinations and improving both semantic fidelity and spatial alignment in the generated captions. To support research in this area, we present the Human Motion Insight (HMI) Dataset, comprising 115K video-description pairs focused on human movement, along with HMI-Bench, a dedicated benchmark for evaluating motion-focused video captioning. Experimental results demonstrate that M-ACM significantly outperforms previous methods in accurately describing complex human motions and subtle temporal variations, setting a new standard for motion-centric video captioning.</li>
</ul>

<h3>Title: Confidence is Not Competence</h3>
<ul>
<li><strong>Authors: </strong>Debdeep Sanyal, Manya Pandey, Dhruv Kumar, Saurabh Deshpande, Murari Mandal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24772">https://arxiv.org/abs/2510.24772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24772">https://arxiv.org/pdf/2510.24772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24772]] Confidence is Not Competence(https://arxiv.org/abs/2510.24772)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often exhibit a puzzling disconnect between their asserted confidence and actual problem-solving competence. We offer a mechanistic account of this decoupling by analyzing the geometry of internal states across two phases - pre-generative assessment and solution execution. A simple linear probe decodes the internal "solvability belief" of a model, revealing a well-ordered belief axis that generalizes across model families and across math, code, planning, and logic tasks. Yet, the geometries diverge - although belief is linearly decodable, the assessment manifold has high linear effective dimensionality as measured from the principal components, while the subsequent reasoning trace evolves on a much lower-dimensional manifold. This sharp reduction in geometric complexity from thought to action mechanistically explains the confidence-competence gap. Causal interventions that steer representations along the belief axis leave final solutions unchanged, indicating that linear nudges in the complex assessment space do not control the constrained dynamics of execution. We thus uncover a two-system architecture - a geometrically complex assessor feeding a geometrically simple executor. These results challenge the assumption that decodable beliefs are actionable levers, instead arguing for interventions that target the procedural dynamics of execution rather than the high-level geometry of assessment.</li>
</ul>

<h3>Title: Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Yujie Nie, Jianzhang Ni, Yonglong Ye, Yuan-Ting Zhang, Yun Kwok Wing, Xiangqing Xu, Xin Ma, Lizhou Fan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24777">https://arxiv.org/abs/2510.24777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24777">https://arxiv.org/pdf/2510.24777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24777]] Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis(https://arxiv.org/abs/2510.24777)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate diagnosis of Alzheimer's disease (AD) is essential for enabling timely intervention and slowing disease progression. Multimodal diagnostic approaches offer considerable promise by integrating complementary information across behavioral and perceptual domains. Eye-tracking and facial features, in particular, are important indicators of cognitive function, reflecting attentional distribution and neurocognitive state. However, few studies have explored their joint integration for auxiliary AD diagnosis. In this study, we propose a multimodal cross-enhanced fusion framework that synergistically leverages eye-tracking and facial features for AD detection. The framework incorporates two key modules: (a) a Cross-Enhanced Fusion Attention Module (CEFAM), which models inter-modal interactions through cross-attention and global enhancement, and (b) a Direction-Aware Convolution Module (DACM), which captures fine-grained directional facial features via horizontal-vertical receptive fields. Together, these modules enable adaptive and discriminative multimodal representation learning. To support this work, we constructed a synchronized multimodal dataset, including 25 patients with AD and 25 healthy controls (HC), by recording aligned facial video and eye-tracking sequences during a visual memory-search paradigm, providing an ecologically valid resource for evaluating integration strategies. Extensive experiments on this dataset demonstrate that our framework outperforms traditional late fusion and feature concatenation methods, achieving a classification accuracy of 95.11% in distinguishing AD from HC, highlighting superior robustness and diagnostic performance by explicitly modeling inter-modal dependencies and modality-specific contributions.</li>
</ul>

<h3>Title: ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and Hardware Co-Optimization for Virtual Reality</h3>
<ul>
<li><strong>Authors: </strong>Mingzhi Zhu, Ding Shang, Sai Qian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24787">https://arxiv.org/abs/2510.24787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24787">https://arxiv.org/pdf/2510.24787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24787]] ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and Hardware Co-Optimization for Virtual Reality(https://arxiv.org/abs/2510.24787)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Photorealistic Codec Avatars (PCA), which generate high-fidelity human face renderings, are increasingly being used in Virtual Reality (VR) environments to enable immersive communication and interaction through deep learning-based generative models. However, these models impose significant computational demands, making real-time inference challenging on resource-constrained VR devices such as head-mounted displays, where latency and power efficiency are critical. To address this challenge, we propose an efficient post-training quantization (PTQ) method tailored for Codec Avatar models, enabling low-precision execution without compromising output quality. In addition, we design a custom hardware accelerator that can be integrated into the system-on-chip of VR devices to further enhance processing efficiency. Building on these components, we introduce ESCA, a full-stack optimization framework that accelerates PCA inference on edge VR platforms. Experimental results demonstrate that ESCA boosts FovVideoVDP quality scores by up to $+0.39$ over the best 4-bit baseline, delivers up to $3.36\times$ latency reduction, and sustains a rendering rate of 100 frames per second in end-to-end tests, satisfying real-time VR requirements. These results demonstrate the feasibility of deploying high-fidelity codec avatars on resource-constrained devices, opening the door to more immersive and portable VR experiences.</li>
</ul>

<h3>Title: Cross-Lingual Summarization as a Black-Box Watermark Removal Attack</h3>
<ul>
<li><strong>Authors: </strong>Gokul Ganesan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24789">https://arxiv.org/abs/2510.24789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24789">https://arxiv.org/pdf/2510.24789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24789]] Cross-Lingual Summarization as a Black-Box Watermark Removal Attack(https://arxiv.org/abs/2510.24789)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Watermarking has been proposed as a lightweight mechanism to identify AI-generated text, with schemes typically relying on perturbations to token distributions. While prior work shows that paraphrasing can weaken such signals, these attacks remain partially detectable or degrade text quality. We demonstrate that cross-lingual summarization attacks (CLSA) -- translation to a pivot language followed by summarization and optional back-translation -- constitute a qualitatively stronger attack vector. By forcing a semantic bottleneck across languages, CLSA systematically destroys token-level statistical biases while preserving semantic fidelity. In experiments across multiple watermarking schemes (KGW, SIR, XSIR, Unigram) and five languages (Amharic, Chinese, Hindi, Spanish, Swahili), we show that CLSA reduces watermark detection accuracy more effectively than monolingual paraphrase at similar quality levels. Our results highlight an underexplored vulnerability that challenges the practicality of watermarking for provenance or regulation. We argue that robust provenance solutions must move beyond distributional watermarking and incorporate cryptographic or model-attestation approaches. On 300 held-out samples per language, CLSA consistently drives detection toward chance while preserving task utility. Concretely, for XSIR (explicitly designed for cross-lingual robustness), AUROC with paraphrasing is $0.827$, with Cross-Lingual Watermark Removal Attacks (CWRA) [He et al., 2024] using Chinese as the pivot, it is $0.823$, whereas CLSA drives it down to $0.53$ (near chance). Results highlight a practical, low-cost removal pathway that crosses languages and compresses content without visible artifacts.</li>
</ul>

<h3>Title: PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Patrick Haller, Fabio Barth, Jonas Golde, Georg Rehm, Alan Akbik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24792">https://arxiv.org/abs/2510.24792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24792">https://arxiv.org/pdf/2510.24792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24792]] PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models(https://arxiv.org/abs/2510.24792)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) have demonstrated remarkable progress in multimodal reasoning. However, existing benchmarks remain limited in terms of high-quality, human-verified examples. Many current datasets rely on synthetically generated content by large language models (LLMs). Furthermore, most datasets are limited to English, as manual quality assurance of translated samples is time-consuming and costly. To fill this gap, we introduce PISA-Bench, a multilingual benchmark derived from English examples of the expert-created PISA tests, a unified framework for the assessment of student competencies in over eighty countries. Each example consists of human-extracted instructions, questions, answer options, and images, enriched with question type categories, and has been translated from English into five additional languages (Spanish, German, Chinese, French, and Italian), resulting in a fully parallel corpus covering six languages. We evaluate state-of-the-art vision-language models on PISA-Bench and find that especially small models (<20B parameters) fail to achieve high test scores. We further find substantial performance degradation on non-English splits as well as high error-rates when models are tasked with spatial and geometric reasoning. By releasing the dataset and evaluation framework, we provide a resource for advancing research on multilingual multimodal reasoning.</li>
</ul>

<h3>Title: Large Language Models Report Subjective Experience Under Self-Referential Processing</h3>
<ul>
<li><strong>Authors: </strong>Cameron Berg, Diogo de Lucena, Judd Rosenblatt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24797">https://arxiv.org/abs/2510.24797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24797">https://arxiv.org/pdf/2510.24797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24797]] Large Language Models Report Subjective Experience Under Self-Referential Processing(https://arxiv.org/abs/2510.24797)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models sometimes produce structured, first-person descriptions that explicitly reference awareness or subjective experience. To better understand this behavior, we investigate one theoretically motivated condition under which such reports arise: self-referential processing, a computational motif emphasized across major theories of consciousness. Through a series of controlled experiments on GPT, Claude, and Gemini model families, we test whether this regime reliably shifts models toward first-person reports of subjective experience, and how such claims behave under mechanistic and behavioral probes. Four main results emerge: (1) Inducing sustained self-reference through simple prompting consistently elicits structured subjective experience reports across model families. (2) These reports are mechanistically gated by interpretable sparse-autoencoder features associated with deception and roleplay: surprisingly, suppressing deception features sharply increases the frequency of experience claims, while amplifying them minimizes such claims. (3) Structured descriptions of the self-referential state converge statistically across model families in ways not observed in any control condition. (4) The induced state yields significantly richer introspection in downstream reasoning tasks where self-reflection is only indirectly afforded. While these findings do not constitute direct evidence of consciousness, they implicate self-referential processing as a minimal and reproducible condition under which large language models generate structured first-person reports that are mechanistically gated, semantically convergent, and behaviorally generalizable. The systematic emergence of this pattern across architectures makes it a first-order scientific and ethical priority for further investigation.</li>
</ul>

<h3>Title: Fortytwo: Swarm Inference with Peer-Ranked Consensus</h3>
<ul>
<li><strong>Authors: </strong>Vladyslav Larin, Ihor Naumenko, Aleksei Ivashov, Ivan Nikitin, Alexander Firsov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24801">https://arxiv.org/abs/2510.24801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24801">https://arxiv.org/pdf/2510.24801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24801]] Fortytwo: Swarm Inference with Peer-Ranked Consensus(https://arxiv.org/abs/2510.24801)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>As centralized AI hits compute ceilings and diminishing returns from ever-larger training runs, meeting demand requires an inference layer that scales horizontally in both capacity and capability. We present Fortytwo, a novel protocol that leverages swarm intelligence principles and distributed pairwise ranking consensus to achieve superior performance in AI inference. Our approach reimagines collaboration among AI nodes using swarm inference: a peer-ranked, reputation-weighted consensus across heterogeneous models that surfaces the highest-quality responses. Using pairwise ranking with a custom Bradley-Terry-style aggregation model, we demonstrate that swarm inference substantially outperforms majority voting, achieving 85.90% on GPQA Diamond versus 68.69% for majority voting with the same model set - an improvement of +17.21 percentage points (approximately +25.1% relative). The protocol incorporates on-chain reputation so node influence adapts to demonstrated accuracy over time, yielding a meritocratic consensus that filters low-quality or malicious participants. To resist Sybil attacks, Fortytwo employs proof-of-capability in its consensus: nodes must successfully complete calibration/test requests and stake reputation to enter ranking rounds, making multi-identity attacks economically unattractive while preserving openness. Across six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and AIME, our evaluation indicates higher accuracy and strong resilience to adversarial and noisy free-form prompting (e.g., prompt-injection degradation of only 0.12% versus 6.20% for a monolithic single-model baseline), while retaining practical deployability. Together, these results establish a foundation for decentralized AI systems - democratizing access to high-quality inference through collective intelligence without sacrificing reliability or security.</li>
</ul>

<h3>Title: Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases</h3>
<ul>
<li><strong>Authors: </strong>Ziyao Cui, Minxing Zhang, Jian Pei</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24807">https://arxiv.org/abs/2510.24807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24807">https://arxiv.org/pdf/2510.24807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24807]] Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases(https://arxiv.org/abs/2510.24807)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Privacy concerns have become increasingly critical in modern AI and data science applications, where sensitive information is collected, analyzed, and shared across diverse domains such as healthcare, finance, and mobility. While prior research has focused on protecting privacy in a single data release, many real-world systems operate under sequential or continuous data publishing, where the same or related data are released over time. Such sequential disclosures introduce new vulnerabilities, as temporal correlations across releases may enable adversaries to infer sensitive information that remains hidden in any individual release. In this paper, we investigate whether an attacker can compromise privacy in sequential data releases by exploiting dependencies between consecutive publications, even when each individual release satisfies standard privacy guarantees. To this end, we propose a novel attack model that captures these sequential dependencies by integrating a Hidden Markov Model with a reinforcement learning-based bi-directional inference mechanism. This enables the attacker to leverage both earlier and later observations in the sequence to infer private information. We instantiate our framework in the context of trajectory data, demonstrating how an adversary can recover sensitive locations from sequential mobility datasets. Extensive experiments on Geolife, Porto Taxi, and SynMob datasets show that our model consistently outperforms baseline approaches that treat each release independently. The results reveal a fundamental privacy risk inherent to sequential data publishing, where individually protected releases can collectively leak sensitive information when analyzed temporally. These findings underscore the need for new privacy-preserving frameworks that explicitly model temporal dependencies, such as time-aware differential privacy or sequential data obfuscation strategies.</li>
</ul>

<h3>Title: ProofSketch: Efficient Verified Reasoning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Disha Sheshanarayana, Tanishka Magar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24811">https://arxiv.org/abs/2510.24811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24811">https://arxiv.org/pdf/2510.24811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24811]] ProofSketch: Efficient Verified Reasoning for Large Language Models(https://arxiv.org/abs/2510.24811)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning methods such as chain-of-thought prompting and self-consistency have shown immense potential to improve the accuracy of large language models across various reasoning tasks. However such methods involve generation of lengthy reasoning chains, which substantially increases token consumption, computational cost, and latency. To address this inefficiency, we propose ProofSketch, a verification-guided reasoning framework that integrates symbolic closure computation, lexicographic verification and adaptive sketch generation. Our experiments show that ProofSketch consistently reduces token usage while improving accuracy, demonstrating that this approach offers a promising path for efficient and trustworthy reasoning.</li>
</ul>

<h3>Title: Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection</h3>
<ul>
<li><strong>Authors: </strong>Cui Yakun, Fushuo Huo, Weijie Shi, Juntao Dai, Hang Du, Zhenghao Zhu, Sirui Han, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24816">https://arxiv.org/abs/2510.24816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24816">https://arxiv.org/pdf/2510.24816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24816]] Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection(https://arxiv.org/abs/2510.24816)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of multi-modal large language models (MLLMs) has greatly advanced research into applications for Video fake news detection (VFND) tasks. Traditional video-based FND benchmarks typically focus on the accuracy of the final decision, often failing to provide fine-grained assessments for the entire detection process, making the detection process a black box. Therefore, we introduce the MVFNDB (Multi-modal Video Fake News Detection Benchmark) based on the empirical analysis, which provides foundation for tasks definition. The benchmark comprises 10 tasks and is meticulously crafted to probe MLLMs' perception, understanding, and reasoning capacities during detection, featuring 9730 human-annotated video-related questions based on a carefully constructed taxonomy ability of VFND. To validate the impact of combining multiple features on the final results, we design a novel framework named MVFND-CoT, which incorporates both creator-added content and original shooting footage reasoning. Building upon the benchmark, we conduct an in-depth analysis of the deeper factors influencing accuracy, including video processing strategies and the alignment between video features and model capabilities. We believe this benchmark will lay a solid foundation for future evaluations and advancements of MLLMs in the domain of video fake news detection.</li>
</ul>

<h3>Title: Towards a Method for Synthetic Generation of PWA Transcripts</h3>
<ul>
<li><strong>Authors: </strong>Jason M. Pittman, Anton Phillips Jr., Yesenia Medina-Santos, Brielle C. Stark</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24817">https://arxiv.org/abs/2510.24817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24817">https://arxiv.org/pdf/2510.24817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24817]] Towards a Method for Synthetic Generation of PWA Transcripts(https://arxiv.org/abs/2510.24817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In aphasia research, Speech-Language Pathologists (SLPs) devote extensive time to manually coding speech samples using Correct Information Units (CIUs), a measure of how informative an individual sample of speech is. Developing automated systems to recognize aphasic language is limited by data scarcity. For example, only about 600 transcripts are available in AphasiaBank yet billions of tokens are used to train large language models (LLMs). In the broader field of machine learning (ML), researchers increasingly turn to synthetic data when such are sparse. Therefore, this study constructs and validates two methods to generate synthetic transcripts of the AphasiaBank Cat Rescue picture description task. One method leverages a procedural programming approach while the second uses Mistral 7b Instruct and Llama 3.1 8b Instruct LLMs. The methods generate transcripts across four severity levels (Mild, Moderate, Severe, Very Severe) through word dropping, filler insertion, and paraphasia substitution. Overall, we found, compared to human-elicited transcripts, Mistral 7b Instruct best captures key aspects of linguistic degradation observed in aphasia, showing realistic directional changes in NDW, word count, and word length amongst the synthetic generation methods. Based on the results, future work should plan to create a larger dataset, fine-tune models for better aphasic representation, and have SLPs assess the realism and usefulness of the synthetic transcripts.</li>
</ul>

<h3>Title: Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation</h3>
<ul>
<li><strong>Authors: </strong>Inclusion AI: Bowen Ma, Cheng Zou, Canxiang Yan, Chunxiang Jin, Chunjie Shen, Dandan Zheng, Fudong Wang, Furong Xu, GuangMing Yao, Jun Zhou, Jingdong Chen, Jianing Li, Jianxin Sun, Jiajia Liu, Jianjiang Zhu, Jianping Jiang, Jun Peng, Kaixiang Ji, Kaimeng Ren, Libin Wang, Lixiang Ru, Longhua Tan, Lan Wang, Mochen Bai, Ning Gao, Qingpei Guo, Qinglong Zhang, Qiang Xu, Rui Liu, Ruijie Xiong, Ruobing Zheng, Sirui Gao, Tianqi Li, Tinghao Liu, Weilong Chai, Xinyu Xiao, Xiaomei Wang, Xiaolong Wang, Xiao Lu, Xiaoyu Li, Xingning Dong, Xuzheng Yu, Yi Yuan, Yuting Gao, Yuting Xiao, Yunxiao Sun, Yipeng Chen, Yifan Mao, Yifei Wu, Yongjie Lyu, Ziping Ma, Zhiqiang Fang, Zhihao Qiu, Ziyuan Huang, Zizheng Yang, Zhengyu He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24821">https://arxiv.org/abs/2510.24821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24821">https://arxiv.org/pdf/2510.24821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24821]] Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation(https://arxiv.org/abs/2510.24821)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion total parameters, of which only 6.1 billion are active per token. This architecture enables highly efficient scaling (dramatically improving computational efficiency while significantly expanding model capacity) and empowers stronger unified multimodal intelligence across vision, speech, and language, representing a key step toward Artificial General Intelligence (AGI). Compared to its predecessor, the upgraded version exhibits substantial improvements across multimodal understanding and generation. We significantly advance speech recognition capabilities, achieving state-of-the-art performance in contextual ASR and highly competitive results in dialect-aware ASR. In image generation, Ming-Flash-Omni introduces high-fidelity text rendering and demonstrates marked gains in scene consistency and identity preservation during image editing. Furthermore, Ming-Flash-Omni introduces generative segmentation, a capability that not only achieves strong standalone segmentation performance but also enhances spatial control in image generation and improves editing consistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in text-to-image generation and generative segmentation, and sets new records on all 12 contextual ASR benchmarks, all within a single unified architecture.</li>
</ul>

<h3>Title: Parallel Loop Transformer for Efficient Test-Time Computation Scaling</h3>
<ul>
<li><strong>Authors: </strong>Bohong Wu, Mengzhao Chen, Xiang Luo, Shen Yan, Qifan Yu, Fan Xia, Tianqi Zhang, Hongrui Zhan, Zheng Zhong, Xun Zhou, Siyuan Qiao, Xingyan Bin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24824">https://arxiv.org/abs/2510.24824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24824">https://arxiv.org/pdf/2510.24824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24824]] Parallel Loop Transformer for Efficient Test-Time Computation Scaling(https://arxiv.org/abs/2510.24824)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are powerful but often too slow and costly for real-world use during inference. Looped transformers save on parameters by reusing the same weights for multiple computational steps, or "loops." However, this approach has a major flaw: the loops run one after another, causing inference latency and memory requirements to increase with each added loop. This makes them impractical for fast applications. To solve this problem, we introduce the Parallel Loop Transformer (PLT). PLT is a new architecture that delivers the performance benefits of a deep, looped model but with the low latency of a standard, non-looped model. PLT works using two key techniques. First, Cross-Loop Parallelism (CLP) breaks the sequential dependency by computing different loops for different tokens at the same time, all within a single pass. Second, to prevent memory costs from growing, we use an Efficient Representation Enhancement strategy. This method shares the memory (KV cache) from the first loop with all other loops. It then uses a Gated Sliding-Window Attention (G-SWA) to combine this shared global information with local information, maintaining high accuracy. Our experiments show that PLT achieves the high accuracy of a traditional looped model but with almost no extra latency or memory cost compared to a standard transformer.</li>
</ul>

<h3>Title: The Generation Phases of Flow Matching: a Denoising Perspective</h3>
<ul>
<li><strong>Authors: </strong>Anne Gagneux, Ségolène Martin, Rémi Gribonval, Mathurin Massias</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24830">https://arxiv.org/abs/2510.24830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24830">https://arxiv.org/pdf/2510.24830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24830]] The Generation Phases of Flow Matching: a Denoising Perspective(https://arxiv.org/abs/2510.24830)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Flow matching has achieved remarkable success, yet the factors influencing the quality of its generation process remain poorly understood. In this work, we adopt a denoising perspective and design a framework to empirically probe the generation process. Laying down the formal connections between flow matching models and denoisers, we provide a common ground to compare their performances on generation and denoising. This enables the design of principled and controlled perturbations to influence sample generation: noise and drift. This leads to new insights on the distinct dynamical phases of the generative process, enabling us to precisely characterize at which stage of the generative process denoisers succeed or fail and why this matters.</li>
</ul>

<h3>Title: Do Large Language Models Grasp The Grammar? Evidence from Grammar-Book-Guided Probing in Luxembourgish</h3>
<ul>
<li><strong>Authors: </strong>Lujun Li, Yewei Song, Lama Sleem, Yiqun Wang, Yangjie Xu, Cedric Lothritz, Niccolo Gentile, Radu State, Tegawende F. Bissyande, Jacques Klein</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24856">https://arxiv.org/abs/2510.24856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24856">https://arxiv.org/pdf/2510.24856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24856]] Do Large Language Models Grasp The Grammar? Evidence from Grammar-Book-Guided Probing in Luxembourgish(https://arxiv.org/abs/2510.24856)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Grammar refers to the system of rules that governs the structural organization and the semantic relations among linguistic units such as sentences, phrases, and words within a given language. In natural language processing, there remains a notable scarcity of grammar focused evaluation protocols, a gap that is even more pronounced for low-resource languages. Moreover, the extent to which large language models genuinely comprehend grammatical structure, especially the mapping between syntactic structures and meanings, remains under debate. To investigate this issue, we propose a Grammar Book Guided evaluation pipeline intended to provide a systematic and generalizable framework for grammar evaluation consisting of four key stages, and in this work we take Luxembourgish as a case study. The results show a weak positive correlation between translation performance and grammatical understanding, indicating that strong translations do not necessarily imply deep grammatical competence. Larger models perform well overall due to their semantic strength but remain weak in morphology and syntax, struggling particularly with Minimal Pair tasks, while strong reasoning ability offers a promising way to enhance their grammatical understanding.</li>
</ul>

<h3>Title: Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations</h3>
<ul>
<li><strong>Authors: </strong>Olawale Salaudeen, Haoran Zhang, Kumail Alhamoud, Sara Beery, Marzyeh Ghassemi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24884">https://arxiv.org/abs/2510.24884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24884">https://arxiv.org/pdf/2510.24884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24884]] Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations(https://arxiv.org/abs/2510.24884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Benchmarks for out-of-distribution (OOD) generalization frequently show a strong positive correlation between in-distribution (ID) and OOD accuracy across models, termed "accuracy-on-the-line." This pattern is often taken to imply that spurious correlations - correlations that improve ID but reduce OOD performance - are rare in practice. We find that this positive correlation is often an artifact of aggregating heterogeneous OOD examples. Using a simple gradient-based method, OODSelect, we identify semantically coherent OOD subsets where accuracy on the line does not hold. Across widely used distribution shift benchmarks, the OODSelect uncovers subsets, sometimes over half of the standard OOD set, where higher ID accuracy predicts lower OOD accuracy. Our findings indicate that aggregate metrics can obscure important failure modes of OOD robustness. We release code and the identified subsets to facilitate further research.</li>
</ul>

<h3>Title: Proper Body Landmark Subset Enables More Accurate and 5X Faster Recognition of Isolated Signs in LIBRAS</h3>
<ul>
<li><strong>Authors: </strong>Daniele L. V. dos Santos, Thiago B. Pereira, Carlos Eduardo G. R. Alves, Richard J. M. G. Tello, Francisco de A. Boldt, Thiago M. Paixão</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24887">https://arxiv.org/abs/2510.24887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24887">https://arxiv.org/pdf/2510.24887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24887]] Proper Body Landmark Subset Enables More Accurate and 5X Faster Recognition of Isolated Signs in LIBRAS(https://arxiv.org/abs/2510.24887)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper investigates the feasibility of using lightweight body landmark detection for the recognition of isolated signs in Brazilian Sign Language (LIBRAS). Although the skeleton-based approach by Alves et al. (2024) enabled substantial improvements in recognition performance, the use of OpenPose for landmark extraction hindered time performance. In a preliminary investigation, we observed that simply replacing OpenPose with the lightweight MediaPipe, while improving processing speed, significantly reduced accuracy. To overcome this limitation, we explored landmark subset selection strategies aimed at optimizing recognition performance. Experimental results showed that a proper landmark subset achieves comparable or superior performance to state-of-the-art methods while reducing processing time by more than 5X compared to Alves et al. (2024). As an additional contribution, we demonstrated that spline-based imputation effectively mitigates missing landmark issues, leading to substantial accuracy gains. These findings highlight that careful landmark selection, combined with simple imputation techniques, enables efficient and accurate isolated sign recognition, paving the way for scalable Sign Language Recognition systems.</li>
</ul>

<h3>Title: Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep Q-learning thresholding</h3>
<ul>
<li><strong>Authors: </strong>Shakeel Abdulkareem (1), Bora Yimenicioglu (2), Andrea Yang (3), Khartik Uppalapati (2), Aneesh Gudipati (1), Zhaoyang Fan (3) ((1) George Mason University, College of Science, Fairfax, VA, USA, (2) Raregen Youth Network, Translational Medical Research Department, Oakton, VA, USA, (3) University of Southern California, Los Angeles, CA, USA)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24889">https://arxiv.org/abs/2510.24889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24889">https://arxiv.org/pdf/2510.24889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24889]] Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep Q-learning thresholding(https://arxiv.org/abs/2510.24889)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Rapid triage of suspected stroke needs accurate, bedside-deployable tools; EEG is promising but underused at first contact. We present an adaptive multitask EEG classifier that converts 32-channel signals to power spectral density features (Welch), uses a recurrent-convolutional network (GRU-TCN) to predict stroke type (healthy, ischemic, hemorrhagic), hemispheric lateralization, and severity, and applies a deep Q-network (DQN) to tune decision thresholds in real time. Using a patient-wise split of the UCLH Stroke EIT/EEG data set (44 recordings; about 26 acute stroke, 10 controls), the primary outcome was stroke-type performance; secondary outcomes were severity and lateralization. The baseline GRU-TCN reached 89.3% accuracy (F1 92.8%) for stroke type, about 96.9% (F1 95.9%) for severity, and about 96.7% (F1 97.4%) for lateralization. With DQN threshold adaptation, stroke-type accuracy increased to about 98.0% (F1 97.7%). We also tested robustness on an independent, low-density EEG cohort (ZJU4H) and report paired patient-level statistics. Analyses follow STARD 2015 guidance for diagnostic accuracy studies (index test: GRU-TCN+DQN; reference standard: radiology/clinical diagnosis; patient-wise evaluation). Adaptive thresholding shifts the operating point to clinically preferred sensitivity-specificity trade-offs, while integrated scalp-map and spectral visualizations support interpretability.</li>
</ul>

<h3>Title: Idea2Plan: Exploring AI-Powered Research Planning</h3>
<ul>
<li><strong>Authors: </strong>Jin Huang, Silviu Cucerzan, Sujay Kumar Jauhar, Ryen W. White</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24891">https://arxiv.org/abs/2510.24891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24891">https://arxiv.org/pdf/2510.24891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24891]] Idea2Plan: Exploring AI-Powered Research Planning(https://arxiv.org/abs/2510.24891)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated significant potential to accelerate scientific discovery as valuable tools for analyzing data, generating hypotheses, and supporting innovative approaches in various scientific fields. In this work, we investigate how LLMs can handle the transition from conceptual research ideas to well-structured research plans. Effective research planning not only supports scientists in advancing their research but also represents a crucial capability for the development of autonomous research agents. Despite its importance, the field lacks a systematic understanding of LLMs' research planning capability. To rigorously measure this capability, we introduce the Idea2Plan task and Idea2Plan Bench, a benchmark built from 200 ICML 2025 Spotlight and Oral papers released after major LLM training cutoffs. Each benchmark instance includes a research idea and a grading rubric capturing the key components of valid plans. We further propose Idea2Plan JudgeEval, a complementary benchmark to assess the reliability of LLM-based judges against expert annotations. Experimental results show that GPT-5 and GPT-5-mini achieve the strongest performance on the benchmark, though substantial headroom remains for future improvement. Our study provides new insights into LLMs' capability for research planning and lay the groundwork for future progress.</li>
</ul>

<h3>Title: VividCam: Learning Unconventional Camera Motions from Virtual Synthetic Videos</h3>
<ul>
<li><strong>Authors: </strong>Qiucheng Wu, Handong Zhao, Zhixin Shu, Jing Shi, Yang Zhang, Shiyu Chang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24904">https://arxiv.org/abs/2510.24904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24904">https://arxiv.org/pdf/2510.24904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24904]] VividCam: Learning Unconventional Camera Motions from Virtual Synthetic Videos(https://arxiv.org/abs/2510.24904)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Although recent text-to-video generative models are getting more capable of following external camera controls, imposed by either text descriptions or camera trajectories, they still struggle to generalize to unconventional camera motions, which is crucial in creating truly original and artistic videos. The challenge lies in the difficulty of finding sufficient training videos with the intended uncommon camera motions. To address this challenge, we propose VividCam, a training paradigm that enables diffusion models to learn complex camera motions from synthetic videos, releasing the reliance on collecting realistic training videos. VividCam incorporates multiple disentanglement strategies that isolates camera motion learning from synthetic appearance artifacts, ensuring more robust motion representation and mitigating domain shift. We demonstrate that our design synthesizes a wide range of precisely controlled and complex camera motions using surprisingly simple synthetic data. Notably, this synthetic data often consists of basic geometries within a low-poly 3D scene and can be efficiently rendered by engines like Unity. Our video results can be found in this https URL .</li>
</ul>

<h3>Title: Understanding Multi-View Transformers</h3>
<ul>
<li><strong>Authors: </strong>Michal Stary, Julien Gaubil, Ayush Tewari, Vincent Sitzmann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24907">https://arxiv.org/abs/2510.24907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24907">https://arxiv.org/pdf/2510.24907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24907]] Understanding Multi-View Transformers(https://arxiv.org/abs/2510.24907)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multi-view transformers such as DUSt3R are revolutionizing 3D vision by solving 3D tasks in a feed-forward manner. However, contrary to previous optimization-based pipelines, the inner mechanisms of multi-view transformers are unclear. Their black-box nature makes further improvements beyond data scaling challenging and complicates usage in safety- and reliability-critical applications. Here, we present an approach for probing and visualizing 3D representations from the residual connections of the multi-view transformers' layers. In this manner, we investigate a variant of the DUSt3R model, shedding light on the development of its latent state across blocks, the role of the individual layers, and suggest how it differs from methods with stronger inductive biases of explicit global pose. Finally, we show that the investigated variant of DUSt3R estimates correspondences that are refined with reconstructed geometry. The code used for the analysis is available at this https URL .</li>
</ul>

<h3>Title: Topic Analysis with Side Information: A Neural-Augmented LDA Approach</h3>
<ul>
<li><strong>Authors: </strong>Biyi Fang, Kripa Rajshekhar, Truong Vo, Diego Klabjan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24918">https://arxiv.org/abs/2510.24918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24918">https://arxiv.org/pdf/2510.24918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24918]] Topic Analysis with Side Information: A Neural-Augmented LDA Approach(https://arxiv.org/abs/2510.24918)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Traditional topic models such as Latent Dirichlet Allocation (LDA) have been widely used to uncover latent structures in text corpora, but they often struggle to integrate auxiliary information such as metadata, user attributes, or document labels. These limitations restrict their expressiveness, personalization, and interpretability. To address this, we propose nnLDA, a neural-augmented probabilistic topic model that dynamically incorporates side information through a neural prior mechanism. nnLDA models each document as a mixture of latent topics, where the prior over topic proportions is generated by a neural network conditioned on auxiliary features. This design allows the model to capture complex nonlinear interactions between side information and topic distributions that static Dirichlet priors cannot represent. We develop a stochastic variational Expectation-Maximization algorithm to jointly optimize the neural and probabilistic components. Across multiple benchmark datasets, nnLDA consistently outperforms LDA and Dirichlet-Multinomial Regression in topic coherence, perplexity, and downstream classification. These results highlight the benefits of combining neural representation learning with probabilistic topic modeling in settings where side information is available.</li>
</ul>

<h3>Title: Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>Hossein R. Nowdeh, Jie Ji, Xiaolong Ma, Fatemeh Afghah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24919">https://arxiv.org/abs/2510.24919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24919">https://arxiv.org/pdf/2510.24919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24919]] Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning(https://arxiv.org/abs/2510.24919)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In multimodal learning, dominant modalities often overshadow others, limiting generalization. We propose Modality-Aware Sharpness-Aware Minimization (M-SAM), a model-agnostic framework that applies to many modalities and supports early and late fusion scenarios. In every iteration, M-SAM in three steps optimizes learning. \textbf{First, it identifies the dominant modality} based on modalities' contribution in the accuracy using Shapley. \textbf{Second, it decomposes the loss landscape}, or in another language, it modulates the loss to prioritize the robustness of the model in favor of the dominant modality, and \textbf{third, M-SAM updates the weights} by backpropagation of modulated gradients. This ensures robust learning for the dominant modality while enhancing contributions from others, allowing the model to explore and exploit complementary features that strengthen overall performance. Extensive experiments on four diverse datasets show that M-SAM outperforms the latest state-of-the-art optimization and gradient manipulation methods and significantly balances and improves multimodal learning.</li>
</ul>

<h3>Title: S3C2 Summit 2025-03: Industry Secure Supply Chain Summit</h3>
<ul>
<li><strong>Authors: </strong>Elizabeth Lin, Jonah Ghebremichael, William Enck, Yasemin Acar, Michel Cukier, Alexandros Kapravelos, Christian Kastner, Laurie Williams</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24920">https://arxiv.org/abs/2510.24920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24920">https://arxiv.org/pdf/2510.24920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24920]] S3C2 Summit 2025-03: Industry Secure Supply Chain Summit(https://arxiv.org/abs/2510.24920)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Software supply chains, while providing immense economic and software development value, are only as strong as their weakest link. Over the past several years, there has been an exponential increase in cyberattacks specifically targeting vulnerable links in critical software supply chains. These attacks disrupt the day-to-day functioning and threaten the security of nearly everyone on the internet, from billion-dollar companies and government agencies to hobbyist open-source developers. The ever-evolving threat of software supply chain attacks has garnered interest from both the software industry and US government in improving software supply chain security. On Thursday, March 6th, 2025, four researchers from the NSF-backed Secure Software Supply Chain Center (S3C2) conducted a Secure Software Supply Chain Summit with a diverse set of 18 practitioners from 17 organizations. The goals of the Summit were: (1) to enable sharing between participants from different industries regarding practical experiences and challenges with software supply chain security; (2) to help form new collaborations; and (3) to learn about the challenges facing participants to inform our future research directions. The summit consisted of discussions of six topics relevant to the government agencies represented, including software bill of materials (SBOMs); compliance; malicious commits; build infrastructure; culture; and large language models (LLMs) and security. For each topic of discussion, we presented a list of questions to participants to spark conversation. In this report, we provide a summary of the summit. The open questions and challenges that remained after each topic are listed at the end of each topic's section, and the initial discussion questions for each topic are provided in the appendix.</li>
</ul>

<h3>Title: RiddleBench: A New Generative Reasoning Benchmark for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Deepon Halder, Alan Saji, Thanmay Jayakumar, Ratish Puduppully, Anoop Kunchukuttan, Raj Dabre</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24932">https://arxiv.org/abs/2510.24932</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24932">https://arxiv.org/pdf/2510.24932</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24932]] RiddleBench: A New Generative Reasoning Benchmark for LLMs(https://arxiv.org/abs/2510.24932)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have demonstrated strong performance on many established reasoning benchmarks. However, these benchmarks primarily evaluate structured skills like quantitative problem-solving, leaving a gap in assessing flexible, multifaceted reasoning abilities that are central to human intelligence. These abilities require integrating logical deduction with spatial awareness and constraint satisfaction, which current evaluations do not measure well. To address this, we introduce RiddleBench, a benchmark of 1,737 challenging puzzles in English designed to probe these core reasoning capabilities. Evaluation of state-of-the-art models on RiddleBench shows fundamental weaknesses. Even top proprietary models like Gemini 2.5 Pro, o3, and Claude 4 Sonnet achieve accuracy just above 60% (60.30%, 63.37%, and 63.16%). Analysis further reveals deep failures, including hallucination cascades (accepting flawed reasoning from other models) and poor self-correction due to a strong self-confirmation bias. Their reasoning is also fragile, with performance degrading significantly when constraints are reordered or irrelevant information is introduced. RiddleBench functions as a diagnostic tool for these issues and as a resource for guiding the development of more robust and reliable language models.</li>
</ul>

<h3>Title: IBIS: A Powerful Hybrid Architecture for Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Alison M. Fernandes, Hermes I. Del Monego, Bruno S. Chang, Anelise Munaretto, Hélder M. Fontes, Rui L. Campos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24936">https://arxiv.org/abs/2510.24936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24936">https://arxiv.org/pdf/2510.24936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24936]] IBIS: A Powerful Hybrid Architecture for Human Activity Recognition(https://arxiv.org/abs/2510.24936)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The increasing interest in Wi-Fi sensing stems from its potential to capture environmental data in a low-cost, non-intrusive way, making it ideal for applications like healthcare, space occupancy analysis, and gesture-based IoT control. However, a major limitation in this field is the common problem of overfitting, where models perform well on training data but fail to generalize to new data. To overcome this, we introduce a novel hybrid architecture that integrates Inception-BiLSTM with a Support Vector Machine (SVM), which we refer to as IBIS. Our IBIS approach is uniquely engineered to improve model generalization and create more robust classification boundaries. By applying this method to Doppler-derived data, we achieve a movement recognition accuracy of nearly 99%. Comprehensive performance metrics and confusion matrices confirm the significant effectiveness of our proposed solution.</li>
</ul>

<h3>Title: SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens</h3>
<ul>
<li><strong>Authors: </strong>Yinhan He, Wendy Zheng, Yaochen Zhu, Zaiyi Zheng, Lin Su, Sriram Vasudevan, Qi Guo, Liangjie Hong, Jundong Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24940">https://arxiv.org/abs/2510.24940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24940">https://arxiv.org/pdf/2510.24940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24940]] SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens(https://arxiv.org/abs/2510.24940)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The verbosity of Chain-of-Thought (CoT) reasoning hinders its mass deployment in efficiency-critical applications. Recently, implicit CoT approaches have emerged, which encode reasoning steps within LLM's hidden embeddings (termed ``implicit reasoning'') rather than explicit tokens. This approach accelerates CoT by reducing the reasoning length and bypassing some LLM components. However, existing implicit CoT methods face two significant challenges: (1) they fail to preserve the semantic alignment between the implicit reasoning (when transformed to natural language) and the ground-truth reasoning, resulting in a significant CoT performance degradation, and (2) they focus on reducing the length of the implicit reasoning; however, they neglect the considerable time cost for an LLM to generate one individual implicit reasoning token. To tackle these challenges, we propose a novel semantically-aligned implicit CoT framework termed SemCoT. In particular, for the first challenge, we design a contrastively trained sentence transformer that evaluates semantic alignment between implicit and explicit reasoning, which is used to enforce semantic preservation during implicit reasoning optimization. To address the second challenge, we introduce an efficient implicit reasoning generator by finetuning a lightweight language model using knowledge distillation. This generator is guided by our sentence transformer to distill ground-truth reasoning into semantically aligned implicit reasoning, while also optimizing for accuracy. SemCoT is the first approach that enhances CoT efficiency by jointly optimizing token-level generation speed and preserving semantic alignment with ground-truth reasoning. Extensive experiments demonstrate the superior performance of SemCoT compared to state-of-the-art methods in both efficiency and effectiveness. Our code can be found at this https URL.</li>
</ul>

<h3>Title: Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought</h3>
<ul>
<li><strong>Authors: </strong>Jiachen Zhao, Yiyou Sun, Weiyan Shi, Dawn Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24941">https://arxiv.org/abs/2510.24941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24941">https://arxiv.org/pdf/2510.24941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24941]] Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought(https://arxiv.org/abs/2510.24941)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) can generate long Chain-of-Thought (CoT) at test time, enabling them to solve complex tasks. These reasoning steps in CoT are often assumed as a faithful reflection of the model's internal thinking process, and used to monitor unsafe intentions. However, we find many reasoning steps don't truly contribute to LLMs' prediction. We measure the step-wise causal influence of each reasoning step on the model's final prediction with a proposed True Thinking Score (TTS). We reveal that LLMs often interleave between true-thinking steps (which are genuinely used to produce the final output) and decorative-thinking steps (which only give the appearance of reasoning but have minimal causal impact). Notably, only a small subset of the total reasoning steps have a high TTS that causally drive the model's prediction: e.g., for the AIME dataset, only an average of 2.3% of reasoning steps in CoT have a TTS >= 0.7 (range: 0-1) under the Qwen-2.5 model. Furthermore, we identify a TrueThinking direction in the latent space of LLMs. By steering along or against this direction, we can force the model to perform or disregard certain CoT steps when computing the final result. Finally, we highlight that self-verification steps in CoT (i.e., aha moments) can also be decorative, where LLMs do not truly verify their solution. Steering along the TrueThinking direction can force internal reasoning over these steps, resulting in a change in the final results. Overall, our work reveals that LLMs often verbalize reasoning steps without actually performing them internally, which undermines both the efficiency of LLM reasoning and the trustworthiness of CoT.</li>
</ul>

<h3>Title: Resource-Efficient and Robust Inference of Deep and Bayesian Neural Networks on Embedded and Analog Computing Platforms</h3>
<ul>
<li><strong>Authors: </strong>Bernhard Klein</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24951">https://arxiv.org/abs/2510.24951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24951">https://arxiv.org/pdf/2510.24951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24951]] Resource-Efficient and Robust Inference of Deep and Bayesian Neural Networks on Embedded and Analog Computing Platforms(https://arxiv.org/abs/2510.24951)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While modern machine learning has transformed numerous application domains, its growing computational demands increasingly constrain scalability and efficiency, particularly on embedded and resource-limited platforms. In practice, neural networks must not only operate efficiently but also provide reliable predictions under distributional shifts or unseen data. Bayesian neural networks offer a principled framework for quantifying uncertainty, yet their computational overhead further compounds these challenges. This work advances resource-efficient and robust inference for both conventional and Bayesian neural networks through the joint pursuit of algorithmic and hardware efficiency. The former reduces computation through model compression and approximate Bayesian inference, while the latter optimizes deployment on digital accelerators and explores analog hardware, bridging algorithmic design and physical realization. The first contribution, Galen, performs automatic layer-specific compression guided by sensitivity analysis and hardware-in-the-loop feedback. Analog accelerators offer efficiency gains at the cost of noise; this work models device imperfections and extends noisy training to nonstationary conditions, improving robustness and stability. A second line of work advances probabilistic inference, developing analytic and ensemble approximations that replace costly sampling, integrate into a compiler stack, and optimize embedded inference. Finally, probabilistic photonic computing introduces a paradigm where controlled analog noise acts as an intrinsic entropy source, enabling fast, energy-efficient probabilistic inference directly in hardware. Together, these studies demonstrate how efficiency and reliability can be advanced jointly through algorithm-hardware co-design, laying the foundation for the next generation of trustworthy, energy-efficient machine-learning systems.</li>
</ul>

<h3>Title: Language Model Behavioral Phases are Consistent Across Architecture, Training Data, and Scale</h3>
<ul>
<li><strong>Authors: </strong>James A. Michaelov, Roger P. Levy, Benjamin K. Bergen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24963">https://arxiv.org/abs/2510.24963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24963">https://arxiv.org/pdf/2510.24963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24963]] Language Model Behavioral Phases are Consistent Across Architecture, Training Data, and Scale(https://arxiv.org/abs/2510.24963)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We show that across architecture (Transformer vs. Mamba vs. RWKV), training dataset (OpenWebText vs. The Pile), and scale (14 million parameters to 12 billion parameters), autoregressive language models exhibit highly consistent patterns of change in their behavior over the course of pretraining. Based on our analysis of over 1,400 language model checkpoints on over 110,000 tokens of English, we find that up to 98% of the variance in language model behavior at the word level can be explained by three simple heuristics: the unigram probability (frequency) of a given word, the $n$-gram probability of the word, and the semantic similarity between the word and its context. Furthermore, we see consistent behavioral phases in all language models, with their predicted probabilities for words overfitting to those words' $n$-gram probabilities for increasing $n$ over the course of training. Taken together, these results suggest that learning in neural language models may follow a similar trajectory irrespective of model details.</li>
</ul>

<h3>Title: Sequences of Logits Reveal the Low Rank Structure of Language Models</h3>
<ul>
<li><strong>Authors: </strong>Noah Golowich, Allen Liu, Abhishek Shetty</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24966">https://arxiv.org/abs/2510.24966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24966">https://arxiv.org/pdf/2510.24966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24966]] Sequences of Logits Reveal the Low Rank Structure of Language Models(https://arxiv.org/abs/2510.24966)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A major problem in the study of large language models is to understand their inherent low-dimensional structure. We introduce an approach to study the low-dimensional structure of language models at a model-agnostic level: as sequential probabilistic models. We first empirically demonstrate that a wide range of modern language models exhibit low-rank structure: in particular, matrices built from the model's logits for varying sets of prompts and responses have low approximate rank. We then show that this low-rank structure can be leveraged for generation -- in particular, we can generate a response to a target prompt using a linear combination of the model's outputs on unrelated, or even nonsensical prompts. On the theoretical front, we observe that studying the approximate rank of language models in the sense discussed above yields a simple universal abstraction whose theoretical predictions parallel our experiments. We then analyze the representation power of the abstraction and give provable learning guarantees.</li>
</ul>

<h3>Title: Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Banafsheh Saber Latibari, Najmeh Nazari, Hossein Sayadi, Houman Homayoun, Abhijit Mahalanobis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24976">https://arxiv.org/abs/2510.24976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24976">https://arxiv.org/pdf/2510.24976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24976]] Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging(https://arxiv.org/abs/2510.24976)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, steal, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Vision Transformers (ViTs) have emerged as powerful architectures in medical image analysis, excelling in tasks such as disease detection, segmentation, and classification. However, their reliance on large, attention-driven models makes them vulnerable to hardware-level attacks. In this paper, we propose a novel threat model referred to as Med-Hammer that combines the Rowhammer hardware fault injection with neural Trojan attacks to compromise the integrity of ViT-based medical imaging systems. Specifically, we demonstrate how malicious bit flips induced via Rowhammer can trigger implanted neural Trojans, leading to targeted misclassification or suppression of critical diagnoses (e.g., tumors or lesions) in medical scans. Through extensive experiments on benchmark medical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that such attacks can remain stealthy while achieving high attack success rates about 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We further investigate how architectural properties, such as model sparsity, attention weight distribution, and the number of features of the layer, impact attack effectiveness. Our findings highlight a critical and underexplored intersection between hardware-level faults and deep learning security in healthcare applications, underscoring the urgent need for robust defenses spanning both model architectures and underlying hardware platforms.</li>
</ul>

<h3>Title: FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Reza Saadati Fard, Emmanuel Agu, Palawat Busaranuvong, Deepak Kumar, Shefalika Gautam, Bengisu Tulu, Diane Strong, Lorraine Loretz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24980">https://arxiv.org/abs/2510.24980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24980">https://arxiv.org/pdf/2510.24980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24980]] FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning(https://arxiv.org/abs/2510.24980)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Pressure ulcers (PUs) are a serious and prevalent healthcare concern. Accurate classification of PU severity (Stages I-IV) is essential for proper treatment but remains challenging due to subtle visual distinctions and subjective interpretation, leading to variability among clinicians. Prior AI-based approaches using Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) achieved promising accuracy but offered limited interpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal model), a fine-tuned multimodal large language model (MLLM) with an agentic self-reflection mechanism for pressure ulcer severity classification. Inspired by clinician-style diagnostic reassessment, FT-ARM iteratively refines its predictions by reasoning over visual features and encoded clinical knowledge from text, enhancing both accuracy and consistency. On the publicly available Pressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B, achieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based models by +4%. Unlike earlier CNN/ViT studies that relied solely on offline evaluations, FT-ARM is designed and tested for live inference, reflecting real-time deployment conditions. Furthermore, it produces clinically grounded natural-language explanations, improving interpretability and trust. By integrating fine-tuning and reflective reasoning across multimodal inputs, FT-ARM advances the reliability, transparency, and clinical applicability of automated wound assessment systems, addressing the critical need for consistent and explainable PU staging to support improved patient care.</li>
</ul>

<h3>Title: LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies</h3>
<ul>
<li><strong>Authors: </strong>Ximan Sun, Xiang Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24983">https://arxiv.org/abs/2510.24983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24983">https://arxiv.org/pdf/2510.24983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24983]] LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies(https://arxiv.org/abs/2510.24983)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion policies are competitive for offline reinforcement learning (RL) but are typically guided at sampling time by heuristics that lack a statistical notion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that treats each denoising step as a sequential hypothesis test between the unconditional prior and the state-conditional policy head. Concretely, we accumulate a log-likelihood ratio and gate the conditional mean with a logistic controller whose threshold tau is calibrated once under H0 to meet a user-specified Type-I level alpha. This turns guidance from a fixed push into an evidence-driven adjustment with a user-interpretable risk budget. Importantly, we deliberately leave training vanilla (two heads with standard epsilon-prediction) under the structure of DDPM. LRT guidance composes naturally with Q-gradients: critic-gradient updates can be taken at the unconditional mean, at the LRT-gated mean, or a blend, exposing a continuum from exploitation to conservatism. We standardize states and actions consistently at train and test time and report a state-conditional out-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks, LRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines in our implementation while honoring the desired alpha. Theoretically, we establish level-alpha calibration, concise stability bounds, and a return comparison showing when LRT surpasses Q-guidance-especially when off-support errors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method that adds principled, calibrated risk control to diffusion policies for offline RL.</li>
</ul>

<h3>Title: FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Najmeh Nazari, Banafsheh Saber Latibari, Elahe Hosseini, Fatemeh Movafagh, Chongzhou Fang, Hosein Mohammadi Makrani, Kevin Immanuel Gubbi, Abhijit Mahalanobis, Setareh Rafatirad, Hossein Sayadi, Houman Homayoun</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24985">https://arxiv.org/abs/2510.24985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24985">https://arxiv.org/pdf/2510.24985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24985]] FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models(https://arxiv.org/abs/2510.24985)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Forget and Rewire (FaR) methodology has demonstrated strong resilience against Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating critical parameters through dynamic rewiring of linear layers. However, the application of FaR introduces non-negligible performance and memory overheads, primarily due to the runtime modification of activation pathways and the lack of hardware-level optimization. To overcome these limitations, we propose FaRAccel, a novel hardware accelerator architecture implemented on FPGA, specifically designed to offload and optimize FaR operations. FaRAccel integrates reconfigurable logic for dynamic activation rerouting, and lightweight storage of rewiring configurations, enabling low-latency inference with minimal energy overhead. We evaluate FaRAccel across a suite of Transformer models and demonstrate substantial reductions in FaR inference latency and improvement in energy efficiency, while maintaining the robustness gains of the original FaR methodology. To the best of our knowledge, this is the first hardware-accelerated defense against BFAs in Transformers, effectively bridging the gap between algorithmic resilience and efficient deployment on real-world AI platforms.</li>
</ul>

<h3>Title: Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series</h3>
<ul>
<li><strong>Authors: </strong>Hemanath Arumugam, Falong Fan, Bo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24988">https://arxiv.org/abs/2510.24988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24988">https://arxiv.org/pdf/2510.24988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24988]] Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series(https://arxiv.org/abs/2510.24988)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Hierarchical Reinforcement Learning (HRL) enhances the scalability of decision-making in long-horizon tasks by introducing temporal abstraction through options-policies that span multiple timesteps. Despite its theoretical appeal, the practical implementation of HRL suffers from the challenge of autonomously discovering semantically meaningful subgoals and learning optimal option termination boundaries. This paper introduces a novel architecture that integrates a self-supervised, Transformer-based Change Point Detection (CPD) module into the Option-Critic framework, enabling adaptive segmentation of state trajectories and the discovery of options. The CPD module is trained using heuristic pseudo-labels derived from intrinsic signals to infer latent shifts in environment dynamics without external supervision. These inferred change-points are leveraged in three critical ways: (i) to serve as supervisory signals for stabilizing termination function gradients, (ii) to pretrain intra-option policies via segment-wise behavioral cloning, and (iii) to enforce functional specialization through inter-option divergence penalties over CPD-defined state partitions. The overall optimization objective enhances the standard actor-critic loss using structure-aware auxiliary losses. In our framework, option discovery arises naturally as CPD-defined trajectory segments are mapped to distinct intra-option policies, enabling the agent to autonomously partition its behavior into reusable, semantically meaningful skills. Experiments on the Four-Rooms and Pinball tasks demonstrate that CPD-guided agents exhibit accelerated convergence, higher cumulative returns, and significantly improved option specialization. These findings confirm that integrating structural priors via change-point segmentation leads to more interpretable, sample-efficient, and robust hierarchical policies in complex environments.</li>
</ul>

<h3>Title: SLIP-SEC: Formalizing Secure Protocols for Model IP Protection</h3>
<ul>
<li><strong>Authors: </strong>Racchit Jain, Satya Lokam, Yehonathan Refael, Adam Hakim, Lev Greenberg, Jay Tenenbaum</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.24999">https://arxiv.org/abs/2510.24999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.24999">https://arxiv.org/pdf/2510.24999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.24999]] SLIP-SEC: Formalizing Secure Protocols for Model IP Protection(https://arxiv.org/abs/2510.24999)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) represent valuable intellectual property (IP), reflecting significant investments in training data, compute, and expertise. Deploying these models on partially trusted or insecure devices introduces substantial risk of model theft, making it essential to design inference protocols with provable security guarantees. We present the formal framework and security foundations of SLIP, a hybrid inference protocol that splits model computation between a trusted and an untrusted resource. We define and analyze the key notions of model decomposition and hybrid inference protocols, and introduce formal properties including safety, correctness, efficiency, and t-soundness. We construct secure inference protocols based on additive decompositions of weight matrices, combined with masking and probabilistic verification techniques. We prove that these protocols achieve information-theoretic security against honest-but-curious adversaries, and provide robustness against malicious adversaries with negligible soundness error. This paper focuses on the theoretical underpinnings of SLIP: precise definitions, formal protocols, and proofs of security. Empirical validation and decomposition heuristics appear in the companion SLIP paper. Together, the two works provide a complete account of securing LLM IP via hybrid inference, bridging both practice and theory.</li>
</ul>

<h3>Title: Emergence of Minimal Circuits for Indirect Object Identification in Attention-Only Transformers</h3>
<ul>
<li><strong>Authors: </strong>Rabin Adhikari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25013">https://arxiv.org/abs/2510.25013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25013">https://arxiv.org/pdf/2510.25013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25013]] Emergence of Minimal Circuits for Indirect Object Identification in Attention-Only Transformers(https://arxiv.org/abs/2510.25013)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Mechanistic interpretability aims to reverse-engineer large language models (LLMs) into human-understandable computational circuits. However, the complexity of pretrained models often obscures the minimal mechanisms required for specific reasoning tasks. In this work, we train small, attention-only transformers from scratch on a symbolic version of the Indirect Object Identification (IOI) task -- a benchmark for studying coreference -- like reasoning in transformers. Surprisingly, a single-layer model with only two attention heads achieves perfect IOI accuracy, despite lacking MLPs and normalization layers. Through residual stream decomposition, spectral analysis, and embedding interventions, we find that the two heads specialize into additive and contrastive subcircuits that jointly implement IOI resolution. Furthermore, we show that a two-layer, one-head model achieves similar performance by composing information across layers through query-value interactions. These results demonstrate that task-specific training induces highly interpretable, minimal circuits, offering a controlled testbed for probing the computational foundations of transformer reasoning.</li>
</ul>

<h3>Title: Disentangling Shared and Private Neural Dynamics with SPIRE: A Latent Modeling Framework for Deep Brain Stimulation</h3>
<ul>
<li><strong>Authors: </strong>Rahil Soroushmojdehi, Sina Javadzadeh, Mehrnaz Asadi, Terence D.Sanger</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25023">https://arxiv.org/abs/2510.25023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25023">https://arxiv.org/pdf/2510.25023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25023]] Disentangling Shared and Private Neural Dynamics with SPIRE: A Latent Modeling Framework for Deep Brain Stimulation(https://arxiv.org/abs/2510.25023)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Disentangling shared network-level dynamics from region-specific activity is a central challenge in modeling multi-region neural data. We introduce SPIRE (Shared-Private Inter-Regional Encoder), a deep multi-encoder autoencoder that factorizes recordings into shared and private latent subspaces with novel alignment and disentanglement losses. Trained solely on baseline data, SPIRE robustly recovers cross-regional structure and reveals how external perturbations reorganize it. On synthetic benchmarks with ground-truth latents, SPIRE outperforms classical probabilistic models under nonlinear distortions and temporal misalignments. Applied to intracranial deep brain stimulation (DBS) recordings, SPIRE shows that shared latents reliably encode stimulation-specific signatures that generalize across sites and frequencies. These results establish SPIRE as a practical, reproducible tool for analyzing multi-region neural dynamics under stimulation.</li>
</ul>

<h3>Title: Secure Retrieval-Augmented Generation against Poisoning Attacks</h3>
<ul>
<li><strong>Authors: </strong>Zirui Cheng, Jikai Sun, Anjun Gao, Yueyang Quan, Zhuqing Liu, Xiaohua Hu, Minghong Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25025">https://arxiv.org/abs/2510.25025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25025">https://arxiv.org/pdf/2510.25025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25025]] Secure Retrieval-Augmented Generation against Poisoning Attacks(https://arxiv.org/abs/2510.25025)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have transformed natural language processing (NLP), enabling applications from content generation to decision support. Retrieval-Augmented Generation (RAG) improves LLMs by incorporating external knowledge but also introduces security risks, particularly from data poisoning, where the attacker injects poisoned texts into the knowledge database to manipulate system outputs. While various defenses have been proposed, they often struggle against advanced attacks. To address this, we introduce RAGuard, a detection framework designed to identify poisoned texts. RAGuard first expands the retrieval scope to increase the proportion of clean texts, reducing the likelihood of retrieving poisoned content. It then applies chunk-wise perplexity filtering to detect abnormal variations and text similarity filtering to flag highly similar texts. This non-parametric approach enhances RAG security, and experiments on large-scale datasets demonstrate its effectiveness in detecting and mitigating poisoning attacks, including strong adaptive attacks.</li>
</ul>

<h3>Title: Machine Learning based Analysis for Radiomics Features Robustness in Real-World Deployment Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Sarmad Ahmad Khan, Simon Bernatz, Zahra Moslehi, Florian Buettner</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25026">https://arxiv.org/abs/2510.25026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25026">https://arxiv.org/pdf/2510.25026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25026]] Machine Learning based Analysis for Radiomics Features Robustness in Real-World Deployment Scenarios(https://arxiv.org/abs/2510.25026)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Radiomics-based machine learning models show promise for clinical decision support but are vulnerable to distribution shifts caused by variations in imaging protocols, positioning, and segmentation. This study systematically investigates the robustness of radiomics-based machine learning models under distribution shifts across five MRI sequences. We evaluated how different acquisition protocols and segmentation strategies affect model reliability in terms of predictive power and uncertainty-awareness. Using a phantom of 16 fruits, we evaluated distribution shifts through: (1) protocol variations across T2-HASTE, T2-TSE, T2-MAP, T1-TSE, and T2-FLAIR sequences; (2) segmentation variations (full, partial, rotated); and (3) inter-observer variability. We trained XGBoost classifiers on 8 consistent robust features versus sequence-specific features, testing model performance under in-domain and out-of-domain conditions. Results demonstrate that models trained on protocol-invariant features maintain F1-scores >0.85 across distribution shifts, while models using all features showed 40% performance degradation under protocol changes. Dataset augmentation substantially improved the quality of uncertainty estimates and reduced the expected calibration error (ECE) by 35% without sacrificing accuracy. Temperature scaling provided minimal calibration benefits, confirming XGBoost's inherent reliability. Our findings reveal that protocol-aware feature selection and controlled phantom studies effectively predict model behavior under distribution shifts, providing a framework for developing robust radiomics models resilient to real-world protocol variations.</li>
</ul>

<h3>Title: Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference Models</h3>
<ul>
<li><strong>Authors: </strong>Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi, Ali Diba</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25051">https://arxiv.org/abs/2510.25051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25051">https://arxiv.org/pdf/2510.25051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25051]] Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference Models(https://arxiv.org/abs/2510.25051)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Breast cancer remains the most commonly diagnosed malignancy among women in the developed world. Early detection through mammography screening plays a pivotal role in reducing mortality rates. While computer-aided diagnosis (CAD) systems have shown promise in assisting radiologists, existing approaches face critical limitations in clinical deployment - particularly in handling the nuanced interpretation of multi-modal data and feasibility due to the requirement of prior clinical history. This study introduces a novel framework that synergistically combines visual features from 2D mammograms with structured textual descriptors derived from easily accessible clinical metadata and synthesized radiological reports through innovative tokenization modules. Our proposed methods in this study demonstrate that strategic integration of convolutional neural networks (ConvNets) with language representations achieves superior performance to vision transformer-based models while handling high-resolution images and enabling practical deployment across diverse populations. By evaluating it on multi-national cohort screening mammograms, our multi-modal approach achieves superior performance in cancer detection and calcification identification compared to unimodal baselines, with particular improvements. The proposed method establishes a new paradigm for developing clinically viable VLM-based CAD systems that effectively leverage imaging data and contextual patient information through effective fusion mechanisms.</li>
</ul>

<h3>Title: GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nourah M Salem, Elizabeth White, Michael Bada, Lawrence Hunter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25055">https://arxiv.org/abs/2510.25055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25055">https://arxiv.org/pdf/2510.25055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25055]] GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using Large Language Models(https://arxiv.org/abs/2510.25055)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Scientific progress is driven by the deliberate articulation of what remains unknown. This study investigates the ability of large language models (LLMs) to identify research knowledge gaps in the biomedical literature. We define two categories of knowledge gaps: explicit gaps, clear declarations of missing knowledge; and implicit gaps, context-inferred missing knowledge. While prior work has focused mainly on explicit gap detection, we extend this line of research by addressing the novel task of inferring implicit gaps. We conducted two experiments on almost 1500 documents across four datasets, including a manually annotated corpus of biomedical articles. We benchmarked both closed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2) under paragraph-level and full-paper settings. To address the reasoning of implicit gaps inference, we introduce \textbf{\small TABI}, a Toulmin-Abductive Bucketed Inference scheme that structures reasoning and buckets inferred conclusion candidates for validation. Our results highlight the robust capability of LLMs in identifying both explicit and implicit knowledge gaps. This is true for both open- and closed-weight models, with larger variants often performing better. This suggests a strong ability of LLMs for systematically identifying candidate knowledge gaps, which can support early-stage research formulation, policymakers, and funding decisions. We also report observed failure modes and outline directions for robust deployment, including domain adaptation, human-in-the-loop verification, and benchmarking across open- and closed-weight models.</li>
</ul>

<h3>Title: Auto3DSeg for Brain Tumor Segmentation from 3D MRI in BraTS 2023 Challenge</h3>
<ul>
<li><strong>Authors: </strong>Andriy Myronenko, Dong Yang, Yufan He, Daguang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25058">https://arxiv.org/abs/2510.25058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25058">https://arxiv.org/pdf/2510.25058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25058]] Auto3DSeg for Brain Tumor Segmentation from 3D MRI in BraTS 2023 Challenge(https://arxiv.org/abs/2510.25058)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this work, we describe our solution to the BraTS 2023 cluster of challenges using Auto3DSeg from MONAI. We participated in all 5 segmentation challenges, and achieved the 1st place results in three of them: Brain Metastasis, Brain Meningioma, BraTS-Africa challenges, and the 2nd place results in the remaining two: Adult and Pediatic Glioma challenges.</li>
</ul>

<h3>Title: Can LLMs Estimate Cognitive Complexity of Reading Comprehension Items?</h3>
<ul>
<li><strong>Authors: </strong>Seonjeong Hwang, Hyounghun Kim, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25064">https://arxiv.org/abs/2510.25064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25064">https://arxiv.org/pdf/2510.25064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25064]] Can LLMs Estimate Cognitive Complexity of Reading Comprehension Items?(https://arxiv.org/abs/2510.25064)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Estimating the cognitive complexity of reading comprehension (RC) items is crucial for assessing item difficulty before it is administered to learners. Unlike syntactic and semantic features, such as passage length or semantic similarity between options, cognitive features that arise during answer reasoning are not readily extractable using existing NLP tools and have traditionally relied on human annotation. In this study, we examine whether large language models (LLMs) can estimate the cognitive complexity of RC items by focusing on two dimensions-Evidence Scope and Transformation Level-that indicate the degree of cognitive burden involved in reasoning about the answer. Our experimental results demonstrate that LLMs can approximate the cognitive complexity of items, indicating their potential as tools for prior difficulty analysis. Further analysis reveals a gap between LLMs' reasoning ability and their metacognitive awareness: even when they produce correct answers, they sometimes fail to correctly identify the features underlying their own reasoning process.</li>
</ul>

<h3>Title: TOPol: Capturing and Explaining Multidimensional Semantic Polarity Fields and Vectors</h3>
<ul>
<li><strong>Authors: </strong>Gabin Taibi, Lucia Gomez</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25069">https://arxiv.org/abs/2510.25069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25069">https://arxiv.org/pdf/2510.25069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25069]] TOPol: Capturing and Explaining Multidimensional Semantic Polarity Fields and Vectors(https://arxiv.org/abs/2510.25069)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Traditional approaches to semantic polarity in computational linguistics treat sentiment as a unidimensional scale, overlooking the multidimensional structure of language. This work introduces TOPol (Topic-Orientation POLarity), a semi-unsupervised framework for reconstructing and interpreting multidimensional narrative polarity fields under human-on-the-loop (HoTL) defined contextual boundaries (CBs). The framework embeds documents using a transformer-based large language model (tLLM), applies neighbor-tuned UMAP projection, and segments topics via Leiden partitioning. Given a CB between discourse regimes A and B, TOPol computes directional vectors between corresponding topic-boundary centroids, yielding a polarity field that quantifies fine-grained semantic displacement during regime shifts. This vectorial representation enables assessing CB quality and detecting polarity changes, guiding HoTL CB refinement. To interpret identified polarity vectors, the tLLM compares their extreme points and produces contrastive labels with estimated coverage. Robustness analyses show that only CB definitions (the main HoTL-tunable parameter) significantly affect results, confirming methodological stability. We evaluate TOPol on two corpora: (i) U.S. Central Bank speeches around a macroeconomic breakpoint, capturing non-affective semantic shifts, and (ii) Amazon product reviews across rating strata, where affective polarity aligns with NRC valence. Results demonstrate that TOPol consistently captures both affective and non-affective polarity transitions, providing a scalable, generalizable, and interpretable framework for context-sensitive multidimensional discourse analysis.</li>
</ul>

<h3>Title: Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments</h3>
<ul>
<li><strong>Authors: </strong>Manjunath Prasad Holenarasipura Rajiv, B. M. Vidyavathi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25070">https://arxiv.org/abs/2510.25070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25070">https://arxiv.org/pdf/2510.25070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25070]] Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments(https://arxiv.org/abs/2510.25070)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Zero-shot scene understanding in real-world settings presents major challenges due to the complexity and variability of natural scenes, where models must recognize new objects, actions, and contexts without prior labeled examples. This work proposes a vision-language integration framework that unifies pre-trained visual encoders (e.g., CLIP, ViT) and large language models (e.g., GPT-based architectures) to achieve semantic alignment between visual and textual modalities. The goal is to enable robust zero-shot comprehension of scenes by leveraging natural language as a bridge to generalize over unseen categories and contexts. Our approach develops a unified model that embeds visual inputs and textual prompts into a shared space, followed by multimodal fusion and reasoning layers for contextual interpretation. Experiments on Visual Genome, COCO, ADE20K, and custom real-world datasets demonstrate significant gains over state-of-the-art zero-shot models in object recognition, activity detection, and scene captioning. The proposed system achieves up to 18% improvement in top-1 accuracy and notable gains in semantic coherence metrics, highlighting the effectiveness of cross-modal alignment and language grounding in enhancing generalization for real-world scene understanding.</li>
</ul>

<h3>Title: Neighborhood Feature Pooling for Remote Sensing Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Fahimeh Orvati Nia, Amirmohammad Mohammadi, Salim Al Kharsa, Pragati Naikare, Zigfried Hampel-Arias, Joshua Peeples</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25077">https://arxiv.org/abs/2510.25077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25077">https://arxiv.org/pdf/2510.25077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25077]] Neighborhood Feature Pooling for Remote Sensing Image Classification(https://arxiv.org/abs/2510.25077)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this work, we propose neighborhood feature pooling (NFP) as a novel texture feature extraction method for remote sensing image classification. The NFP layer captures relationships between neighboring inputs and efficiently aggregates local similarities across feature dimensions. Implemented using convolutional layers, NFP can be seamlessly integrated into any network. Results comparing the baseline models and the NFP method indicate that NFP consistently improves performance across diverse datasets and architectures while maintaining minimal parameter overhead.</li>
</ul>

<h3>Title: BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Nourah M Salem, Elizabeth White, Michael Bada, Lawrence Hunter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25087">https://arxiv.org/abs/2510.25087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25087">https://arxiv.org/pdf/2510.25087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25087]] BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs(https://arxiv.org/abs/2510.25087)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Coreference resolution in biomedical texts presents unique challenges due to complex domain-specific terminology, high ambiguity in mention forms, and long-distance dependencies between coreferring expressions. In this work, we present a comprehensive evaluation of generative large language models (LLMs) for coreference resolution in the biomedical domain. Using the CRAFT corpus as our benchmark, we assess the LLMs' performance with four prompting experiments that vary in their use of local, contextual enrichment, and domain-specific cues such as abbreviations and entity dictionaries. We benchmark these approaches against a discriminative span-based encoder, SpanBERT, to compare the efficacy of generative versus discriminative methods. Our results demonstrate that while LLMs exhibit strong surface-level coreference capabilities, especially when supplemented with domain-grounding prompts, their performance remains sensitive to long-range context and mentions ambiguity. Notably, the LLaMA 8B and 17B models show superior precision and F1 scores under entity-augmented prompting, highlighting the potential of lightweight prompt engineering for enhancing LLM utility in biomedical NLP tasks.</li>
</ul>

<h3>Title: Continual Low-Rank Adapters for LLM-based Generative Recommender Systems</h3>
<ul>
<li><strong>Authors: </strong>Hyunsik Yoo, Ting-Wei Li, SeongKu Kang, Zhining Liu, Charlie Xu, Qilin Qi, Hanghang Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25093">https://arxiv.org/abs/2510.25093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25093">https://arxiv.org/pdf/2510.25093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25093]] Continual Low-Rank Adapters for LLM-based Generative Recommender Systems(https://arxiv.org/abs/2510.25093)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) achieve strong performance in recommendation, they face challenges in continual learning as users, items, and user preferences evolve over time. Existing LoRA-based continual methods primarily focus on preserving performance on previous tasks, but this overlooks the unique nature of recommendation: the goal is not to predict past preferences, and outdated preferences can even harm performance when current interests shift significantly. To address this, we propose PESO (Proximally rEgularized Single evolving lOra, a continual adaptation method for LoRA in recommendation. PESO introduces a proximal regularizer that anchors the current adapter to its most recent frozen state, enabling the model to flexibly balance adaptation and preservation, and to better capture recent user behaviors. Theoretically, we show that this proximal design provides data-aware, direction-wise guidance in the LoRA subspace. Empirically, PESO consistently outperforms existing LoRA-based continual learning methods.</li>
</ul>

<h3>Title: Learning Fair Graph Representations with Multi-view Information Bottleneck</h3>
<ul>
<li><strong>Authors: </strong>Chuxun Liu, Debo Cheng, Qingfeng Chen, Jiangzhang Gan, Jiuyong Li, Lin Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25096">https://arxiv.org/abs/2510.25096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25096">https://arxiv.org/pdf/2510.25096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25096]] Learning Fair Graph Representations with Multi-view Information Bottleneck(https://arxiv.org/abs/2510.25096)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) excel on relational data by passing messages over node features and structure, but they can amplify training data biases, propagating discriminatory attributes and structural imbalances into unfair outcomes. Many fairness methods treat bias as a single source, ignoring distinct attribute and structure effects and leading to suboptimal fairness and utility trade-offs. To overcome this challenge, we propose FairMIB, a multi-view information bottleneck framework designed to decompose graphs into feature, structural, and diffusion views for mitigating complexity biases in GNNs. Especially, the proposed FairMIB employs contrastive learning to maximize cross-view mutual information for bias-free representation learning. It further integrates multi-perspective conditional information bottleneck objectives to balance task utility and fairness by minimizing mutual information with sensitive attributes. Additionally, FairMIB introduces an inverse probability-weighted (IPW) adjacency correction in the diffusion view, which reduces the spread of bias propagation during message passing. Experiments on five real-world benchmark datasets demonstrate that FairMIB achieves state-of-the-art performance across both utility and fairness metrics.</li>
</ul>

<h3>Title: DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates</h3>
<ul>
<li><strong>Authors: </strong>Yun-Shiuan Chuang, Ruixuan Tu, Chengtao Dai, Smit Vasani, Binwei Yao, Michael Henry Tessler, Sijia Yang, Dhavan Shah, Robert Hawkins, Junjie Hu, Timothy T. Rogers</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25110">https://arxiv.org/abs/2510.25110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25110">https://arxiv.org/pdf/2510.25110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25110]] DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates(https://arxiv.org/abs/2510.25110)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurately modeling opinion change through social interactions is crucial for addressing issues like misinformation and polarization. While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics. Current LLM role-play setups often produce unnatural dynamics (e.g., premature convergence), without an empirical benchmark to measure authentic human opinion trajectories. To bridge this gap, we introduce DEBATE, the first large-scale empirical benchmark explicitly designed to evaluate the authenticity of the interaction between multi-agent role-playing LLMs. DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions. Using DEBATE, we systematically evaluate and identify critical discrepancies between simulated and authentic group dynamics. We further demonstrate DEBATE's utility for aligning LLMs with human behavior through supervised fine-tuning, achieving improvements in surface-level metrics (e.g., ROUGE-L and message length) while highlighting limitations in deeper semantic alignment (e.g., semantic similarity). Our findings highlight both the potential and current limitations of role-playing LLM agents for realistically simulating human-like social dynamics.</li>
</ul>

<h3>Title: The Neural Differential Manifold: An Architecture with Explicit Geometric Structure</h3>
<ul>
<li><strong>Authors: </strong>Di Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.DG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25113">https://arxiv.org/abs/2510.25113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25113">https://arxiv.org/pdf/2510.25113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25113]] The Neural Differential Manifold: An Architecture with Explicit Geometric Structure(https://arxiv.org/abs/2510.25113)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces the Neural Differential Manifold (NDM), a novel neural network architecture that explicitly incorporates geometric structure into its fundamental design. Departing from conventional Euclidean parameter spaces, the NDM re-conceptualizes a neural network as a differentiable manifold where each layer functions as a local coordinate chart, and the network parameters directly parameterize a Riemannian metric tensor at every point. The architecture is organized into three synergistic layers: a Coordinate Layer implementing smooth chart transitions via invertible transformations inspired by normalizing flows, a Geometric Layer that dynamically generates the manifold's metric through auxiliary sub-networks, and an Evolution Layer that optimizes both task performance and geometric simplicity through a dual-objective loss function. This geometric regularization penalizes excessive curvature and volume distortion, providing intrinsic regularization that enhances generalization and robustness. The framework enables natural gradient descent optimization aligned with the learned manifold geometry and offers unprecedented interpretability by endowing internal representations with clear geometric meaning. We analyze the theoretical advantages of this approach, including its potential for more efficient optimization, enhanced continual learning, and applications in scientific discovery and controllable generative modeling. While significant computational challenges remain, the Neural Differential Manifold represents a fundamental shift towards geometrically structured, interpretable, and efficient deep learning systems.</li>
</ul>

<h3>Title: A Survey on Unlearning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ruichen Qiu, Jiajun Tan, Jiayue Pu, Honglin Wang, Xiao-Shan Gao, Fei Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25117">https://arxiv.org/abs/2510.25117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25117">https://arxiv.org/pdf/2510.25117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25117]] A Survey on Unlearning in Large Language Models(https://arxiv.org/abs/2510.25117)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, generative, large language model</a></li>
<li><strong>Abstract: </strong>The advancement of Large Language Models (LLMs) has revolutionized natural language processing, yet their training on massive corpora poses significant risks, including the memorization of sensitive personal data, copyrighted material, and knowledge that could facilitate malicious activities. To mitigate these issues and align with legal and ethical standards such as the "right to be forgotten", machine unlearning has emerged as a critical technique to selectively erase specific knowledge from LLMs without compromising their overall performance. This survey provides a systematic review of over 180 papers on LLM unlearning published since 2021, focusing exclusively on large-scale generative models. Distinct from prior surveys, we introduce novel taxonomies for both unlearning methods and evaluations. We clearly categorize methods into training-time, post-training, and inference-time based on the training stage at which unlearning is applied. For evaluations, we not only systematically compile existing datasets and metrics but also critically analyze their advantages, disadvantages, and applicability, providing practical guidance to the research community. In addition, we discuss key challenges and promising future research directions. Our comprehensive overview aims to inform and guide the ongoing development of secure and reliable LLMs.</li>
</ul>

<h3>Title: A Unified Bilevel Model for Adversarial Learning and A Case Study</h3>
<ul>
<li><strong>Authors: </strong>Yutong Zheng, Qingna Li</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25121">https://arxiv.org/abs/2510.25121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25121">https://arxiv.org/pdf/2510.25121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25121]] A Unified Bilevel Model for Adversarial Learning and A Case Study(https://arxiv.org/abs/2510.25121)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial learning has been attracting more and more attention thanks to the fast development of machine learning and artificial intelligence. However, due to the complicated structure of most machine learning models, the mechanism of adversarial attacks is not well interpreted. How to measure the effect of attack is still not quite clear. In this paper, we propose a unified bilevel model for adversarial learning. We further investigate the adversarial attack in clustering models and interpret it from data perturbation point of view. We reveal that when the data perturbation is relatively small, the clustering model is robust, whereas if it is relatively large, the clustering result changes, which leads to an attack. To measure the effect of attacks for clustering models, we analyse the well-definedness of the so-called $\delta$-measure, which can be used in the proposed bilevel model for adversarial learning of clustering models.</li>
</ul>

<h3>Title: Lipschitz-aware Linearity Grafting for Certified Robustness</h3>
<ul>
<li><strong>Authors: </strong>Yongjin Han, Suhyun Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25130">https://arxiv.org/abs/2510.25130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25130">https://arxiv.org/pdf/2510.25130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25130]] Lipschitz-aware Linearity Grafting for Certified Robustness(https://arxiv.org/abs/2510.25130)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Lipschitz constant is a fundamental property in certified robustness, as smaller values imply robustness to adversarial examples when a model is confident in its prediction. However, identifying the worst-case adversarial examples is known to be an NP-complete problem. Although over-approximation methods have shown success in neural network verification to address this challenge, reducing approximation errors remains a significant obstacle. Furthermore, these approximation errors hinder the ability to obtain tight local Lipschitz constants, which are crucial for certified robustness. Originally, grafting linearity into non-linear activation functions was proposed to reduce the number of unstable neurons, enabling scalable and complete verification. However, no prior theoretical analysis has explained how linearity grafting improves certified robustness. We instead consider linearity grafting primarily as a means of eliminating approximation errors rather than reducing the number of unstable neurons, since linear functions do not require relaxation. In this paper, we provide two theoretical contributions: 1) why linearity grafting improves certified robustness through the lens of the $l_\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear activation functions, the dominant source of approximation errors, yields a tighter local Lipschitz constant. Based on these theoretical contributions, we propose a Lipschitz-aware linearity grafting method that removes dominant approximation errors, which are crucial for tightening the local Lipschitz constant, thereby improving certified robustness, even without certified training. Our extensive experiments demonstrate that grafting linearity into these influential activations tightens the $l_\infty$ local Lipschitz constant and enhances certified robustness.</li>
</ul>

<h3>Title: Region-CAM: Towards Accurate Object Regions in Class Activation Maps for Weakly Supervised Learning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Qingdong Cai, Charith Abhayaratne</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25134">https://arxiv.org/abs/2510.25134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25134">https://arxiv.org/pdf/2510.25134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25134]] Region-CAM: Towards Accurate Object Regions in Class Activation Maps for Weakly Supervised Learning Tasks(https://arxiv.org/abs/2510.25134)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Class Activation Mapping (CAM) methods are widely applied in weakly supervised learning tasks due to their ability to highlight object regions. However, conventional CAM methods highlight only the most discriminative regions of the target. These highlighted regions often fail to cover the entire object and are frequently misaligned with object boundaries, thereby limiting the performance of downstream weakly supervised learning tasks, particularly Weakly Supervised Semantic Segmentation (WSSS), which demands pixel-wise accurate activation maps to get the best results. To alleviate the above problems, we propose a novel activation method, Region-CAM. Distinct from network feature weighting approaches, Region-CAM generates activation maps by extracting semantic information maps (SIMs) and performing semantic information propagation (SIP) by considering both gradients and features in each of the stages of the baseline classification model. Our approach highlights a greater proportion of object regions while ensuring activation maps to have precise boundaries that align closely with object edges. Region-CAM achieves 60.12% and 58.43% mean intersection over union (mIoU) using the baseline model on the PASCAL VOC training and validation datasets, respectively, which are improvements of 13.61% and 13.13% over the original CAM (46.51% and 45.30%). On the MS COCO validation set, Region-CAM achieves 36.38%, a 16.23% improvement over the original CAM (20.15%). We also demonstrate the superiority of Region-CAM in object localization tasks, using the ILSVRC2012 validation set. Region-CAM achieves 51.7% in Top-1 Localization accuracy Loc1. Compared with LayerCAM, an activation method designed for weakly supervised object localization, Region-CAM achieves 4.5% better performance in Loc1.</li>
</ul>

<h3>Title: DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications</h3>
<ul>
<li><strong>Authors: </strong>Malaisree P, Youwai S, Kitkobsin T, Janrungautai S, Amorndechaphon D, Rojanavasu P</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25140">https://arxiv.org/abs/2510.25140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25140">https://arxiv.org/pdf/2510.25140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25140]] DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications(https://arxiv.org/abs/2510.25140)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Object detection in civil engineering applications is constrained by limited annotated data in specialized domains. We introduce DINO-YOLO, a hybrid architecture combining YOLOv12 with DINOv3 self-supervised vision transformers for data-efficient detection. DINOv3 features are strategically integrated at two locations: input preprocessing (P0) and mid-backbone enhancement (P3). Experimental validation demonstrates substantial improvements: Tunnel Segment Crack detection (648 images) achieves 12.4% improvement, Construction PPE (1K images) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while maintaining real-time inference (30-47 FPS). Systematic ablation across five YOLO scales and nine DINOv3 variants reveals that Medium-scale architectures achieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while Small-scale requires Triple Integration (53.63%). The 2-4x inference overhead (21-33ms versus 8-16ms baseline) remains acceptable for field deployment on NVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil engineering datasets (<10K images) while preserving computational efficiency, providing practical solutions for construction safety monitoring and infrastructure inspection in data-constrained environments.</li>
</ul>

<h3>Title: Revisiting Reconstruction-based AI-generated Image Detection: A Geometric Perspective</h3>
<ul>
<li><strong>Authors: </strong>Wan Jiang, Jing Yan, Ruixuan Zhang, Xiaojing Chen, Changtao Miao, Zhe Li, Chenhao Lin, Yunfeng Diao, Richang Hong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25141">https://arxiv.org/abs/2510.25141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25141">https://arxiv.org/pdf/2510.25141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25141]] Revisiting Reconstruction-based AI-generated Image Detection: A Geometric Perspective(https://arxiv.org/abs/2510.25141)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>The rise of generative Artificial Intelligence (AI) has made detecting AI-generated images a critical challenge for ensuring authenticity. Existing reconstruction-based methods lack theoretical foundations and on empirical heuristics, limiting interpretability and reliability. In this paper, we introduce the Jacobian-Spectral Lower Bound for reconstruction error from a geometric perspective, showing that real images off the reconstruction manifold exhibit a non-trivial error lower bound, while generated images on the manifold have near-zero error. Furthermore, we reveal the limitations of existing methods that rely on static reconstruction error from a single pass. These methods often fail when some real images exhibit lower error than generated ones. This counterintuitive behavior reduces detection accuracy and requires data-specific threshold tuning, limiting their applicability in real-world scenarios. To address these challenges, we propose ReGap, a training-free method that computes dynamic reconstruction error by leveraging structured editing operations to introduce controlled perturbations. This enables measuring error changes before and after editing, improving detection accuracy by enhancing error separation. Experimental results show that our method outperforms existing baselines, exhibits robustness to common post-processing operations and generalizes effectively across diverse conditions.</li>
</ul>

<h3>Title: EA3D: Online Open-World 3D Object Extraction from Streaming Videos</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Zhou, Jingqi Wang, Yuang Jia, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25146">https://arxiv.org/abs/2510.25146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25146">https://arxiv.org/pdf/2510.25146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25146]] EA3D: Online Open-World 3D Object Extraction from Streaming Videos(https://arxiv.org/abs/2510.25146)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Current 3D scene understanding methods are limited by offline-collected multi-view data or pre-constructed 3D geometry. In this paper, we present ExtractAnything3D (EA3D), a unified online framework for open-world 3D object extraction that enables simultaneous geometric reconstruction and holistic scene understanding. Given a streaming video, EA3D dynamically interprets each frame using vision-language and 2D vision foundation encoders to extract object-level knowledge. This knowledge is integrated and embedded into a Gaussian feature map via a feed-forward online update strategy. We then iteratively estimate visual odometry from historical frames and incrementally update online Gaussian features with new observations. A recurrent joint optimization module directs the model's attention to regions of interest, simultaneously enhancing both geometric reconstruction and semantic understanding. Extensive experiments across diverse benchmarks and tasks, including photo-realistic rendering, semantic and instance segmentation, 3D bounding box and semantic occupancy estimation, and 3D mesh generation, demonstrate the effectiveness of EA3D. Our method establishes a unified and efficient framework for joint online 3D reconstruction and holistic scene understanding, enabling a broad range of downstream tasks.</li>
</ul>

<h3>Title: Explainable Disentanglement on Discrete Speech Representations for Noise-Robust ASR</h3>
<ul>
<li><strong>Authors: </strong>Shreyas Gopal, Ashutosh Anshul, Haoyang Li, Yue Heng Yeo, Hexin Liu, Eng Siong Chng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25150">https://arxiv.org/abs/2510.25150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25150">https://arxiv.org/pdf/2510.25150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25150]] Explainable Disentanglement on Discrete Speech Representations for Noise-Robust ASR(https://arxiv.org/abs/2510.25150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Discrete audio representations are gaining traction in speech modeling due to their interpretability and compatibility with large language models, but are not always optimized for noisy or real-world environments. Building on existing works that quantize Whisper embeddings for speech-to-unit modeling, we propose disentangling semantic speech content from background noise in the latent space. Our end-to-end model separates clean speech in the form of codebook tokens, while extracting interpretable noise vectors as quantization residue which are supervised via a lightweight classifier. We show that our approach improves alignment between clean/noisy speech and text, producing speech tokens that display a high degree of noiseinvariance, and improves ASR performance. Keeping Whisper frozen, we show an 82% reduction in error rate compared to Whisper, and 35% improvement over baseline methods on the VBDemand test set. Further analyses show that the learned token space generalizes well to both seen and unseen acoustic conditions.</li>
</ul>

<h3>Title: Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Gautam A. Viruthagiri, Arnuv Tandon, Gerald G. Fuller, Vinny Chandran Suja</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25157">https://arxiv.org/abs/2510.25157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25157">https://arxiv.org/pdf/2510.25157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25157]] Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers(https://arxiv.org/abs/2510.25157)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Thin film interferometry is a powerful technique for non-invasively measuring liquid film thickness with applications in ophthalmology, but its clinical translation is hindered by the challenges in reconstructing thickness profiles from interference patterns - an ill-posed inverse problem complicated by phase periodicity, imaging noise and ambient artifacts. Traditional reconstruction methods are either computationally intensive, sensitive to noise, or require manual expert analysis, which is impractical for real-time diagnostics. To address this challenge, here we present a vision transformer-based approach for real-time inference of thin liquid film thickness profiles directly from isolated interferograms. Trained on a hybrid dataset combining physiologically-relevant synthetic and experimental tear film data, our model leverages long-range spatial correlations to resolve phase ambiguities and reconstruct temporally coherent thickness profiles in a single forward pass from dynamic interferograms acquired in vivo and ex vivo. The network demonstrates state-of-the-art performance on noisy, rapidly-evolving films with motion artifacts, overcoming limitations of conventional phase-unwrapping and iterative fitting methods. Our data-driven approach enables automated, consistent thickness reconstruction at real-time speeds on consumer hardware, opening new possibilities for continuous monitoring of pre-lens ocular tear films and non-invasive diagnosis of conditions such as the dry eye disease.</li>
</ul>

<h3>Title: Model-Document Protocol for AI Search</h3>
<ul>
<li><strong>Authors: </strong>Hongjin Qian, Zheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25160">https://arxiv.org/abs/2510.25160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25160">https://arxiv.org/pdf/2510.25160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25160]] Model-Document Protocol for AI Search(https://arxiv.org/abs/2510.25160)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents. We introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning. As an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.</li>
</ul>

<h3>Title: Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Zheng, Chenwei Sun, Wenbo Zhang, Jiancheng Lv, Xianggen Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25163">https://arxiv.org/abs/2510.25163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25163">https://arxiv.org/pdf/2510.25163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25163]] Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation(https://arxiv.org/abs/2510.25163)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep generative models, such as diffusion models, have shown promising progress in image generation and audio generation via simplified continuity assumptions. However, the development of generative modeling techniques for generating multi-modal data, such as parametric CAD sequences, still lags behind due to the challenges in addressing long-range constraints and parameter sensitivity. In this work, we propose a novel framework for quantitatively constrained CAD generation, termed Target-Guided Bayesian Flow Network (TGBFN). For the first time, TGBFN handles the multi-modality of CAD sequences (i.e., discrete commands and continuous parameters) in a unified continuous and differentiable parameter space rather than in the discrete data space. In addition, TGBFN penetrates the parameter update kernel and introduces a guided Bayesian flow to control the CAD properties. To evaluate TGBFN, we construct a new dataset for quantitatively constrained CAD generation. Extensive comparisons across single-condition and multi-condition constrained generation tasks demonstrate that TGBFN achieves state-of-the-art performance in generating high-fidelity, condition-aware CAD sequences. The code is available at this https URL.</li>
</ul>

<h3>Title: A Study on Inference Latency for Vision Transformers on Mobile Devices</h3>
<ul>
<li><strong>Authors: </strong>Zhuojin Li, Marco Paolieri, Leana Golubchik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25166">https://arxiv.org/abs/2510.25166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25166">https://arxiv.org/pdf/2510.25166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25166]] A Study on Inference Latency for Vision Transformers on Mobile Devices(https://arxiv.org/abs/2510.25166)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Given the significant advances in machine learning techniques on mobile devices, particularly in the domain of computer vision, in this work we quantitatively study the performance characteristics of 190 real-world vision transformers (ViTs) on mobile devices. Through a comparison with 102 real-world convolutional neural networks (CNNs), we provide insights into the factors that influence the latency of ViT architectures on mobile devices. Based on these insights, we develop a dataset including measured latencies of 1000 synthetic ViTs with representative building blocks and state-of-the-art architectures from two machine learning frameworks and six mobile platforms. Using this dataset, we show that inference latency of new ViTs can be predicted with sufficient accuracy for real-world applications.</li>
</ul>

<h3>Title: $D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Kejing Xia, Jidong Jia, Ke Jin, Yucai Bai, Li Sun, Dacheng Tao, Youjian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25173">https://arxiv.org/abs/2510.25173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25173">https://arxiv.org/pdf/2510.25173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25173]] $D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction(https://arxiv.org/abs/2510.25173)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, Gaussian Splatting (GS) has shown great potential for urban scene reconstruction in the field of autonomous driving. However, current urban scene reconstruction methods often depend on multimodal sensors as inputs, \textit{i.e.} LiDAR and images. Though the geometry prior provided by LiDAR point clouds can largely mitigate ill-posedness in reconstruction, acquiring such accurate LiDAR data is still challenging in practice: i) precise spatiotemporal calibration between LiDAR and other sensors is required, as they may not capture data simultaneously; ii) reprojection errors arise from spatial misalignment when LiDAR and cameras are mounted at different locations. To avoid the difficulty of acquiring accurate LiDAR depth, we propose $D^2GS$, a LiDAR-free urban scene reconstruction framework. In this work, we obtain geometry priors that are as effective as LiDAR while being denser and more accurate. $\textbf{First}$, we initialize a dense point cloud by back-projecting multi-view metric depth predictions. This point cloud is then optimized by a Progressive Pruning strategy to improve the global consistency. $\textbf{Second}$, we jointly refine Gaussian geometry and predicted dense metric depth via a Depth Enhancer. Specifically, we leverage diffusion priors from a depth foundation model to enhance the depth maps rendered by Gaussians. In turn, the enhanced depths provide stronger geometric constraints during Gaussian training. $\textbf{Finally}$, we improve the accuracy of ground geometry by constraining the shape and normal attributes of Gaussians within road regions. Extensive experiments on the Waymo dataset demonstrate that our method consistently outperforms state-of-the-art methods, producing more accurate geometry even when compared with those using ground-truth LiDAR data.</li>
</ul>

<h3>Title: Classifier Enhancement Using Extended Context and Domain Experts for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Huadong Tang, Youpeng Zhao, Min Xu, Jun Wang, Qiang Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25174">https://arxiv.org/abs/2510.25174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25174">https://arxiv.org/pdf/2510.25174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25174]] Classifier Enhancement Using Extended Context and Domain Experts for Semantic Segmentation(https://arxiv.org/abs/2510.25174)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Prevalent semantic segmentation methods generally adopt a vanilla classifier to categorize each pixel into specific classes. Although such a classifier learns global information from the training data, this information is represented by a set of fixed parameters (weights and biases). However, each image has a different class distribution, which prevents the classifier from addressing the unique characteristics of individual images. At the dataset level, class imbalance leads to segmentation results being biased towards majority classes, limiting the model's effectiveness in identifying and segmenting minority class regions. In this paper, we propose an Extended Context-Aware Classifier (ECAC) that dynamically adjusts the classifier using global (dataset-level) and local (image-level) contextual information. Specifically, we leverage a memory bank to learn dataset-level contextual information of each class, incorporating the class-specific contextual information from the current image to improve the classifier for precise pixel labeling. Additionally, a teacher-student network paradigm is adopted, where the domain expert (teacher network) dynamically adjusts contextual information with ground truth and transfers knowledge to the student network. Comprehensive experiments illustrate that the proposed ECAC can achieve state-of-the-art performance across several datasets, including ADE20K, COCO-Stuff10K, and Pascal-Context.</li>
</ul>

<h3>Title: Mask-Robust Face Verification for Online Learning via YOLOv5 and Residual Networks</h3>
<ul>
<li><strong>Authors: </strong>Zhifeng Wang, Minghui Wang, Chunyan Zeng, Jialong Yao, Yang Yang, Hongmin Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25184">https://arxiv.org/abs/2510.25184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25184">https://arxiv.org/pdf/2510.25184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25184]] Mask-Robust Face Verification for Online Learning via YOLOv5 and Residual Networks(https://arxiv.org/abs/2510.25184)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>In the contemporary landscape, the fusion of information technology and the rapid advancement of artificial intelligence have ushered school education into a transformative phase characterized by digitization and heightened intelligence. Concurrently, the global paradigm shift caused by the Covid-19 pandemic has catalyzed the evolution of e-learning, accentuating its significance. Amidst these developments, one pivotal facet of the online education paradigm that warrants attention is the authentication of identities within the digital learning sphere. Within this context, our study delves into a solution for online learning authentication, utilizing an enhanced convolutional neural network architecture, specifically the residual network model. By harnessing the power of deep learning, this technological approach aims to galvanize the ongoing progress of online education, while concurrently bolstering its security and stability. Such fortification is imperative in enabling online education to seamlessly align with the swift evolution of the educational landscape. This paper's focal proposition involves the deployment of the YOLOv5 network, meticulously trained on our proprietary dataset. This network is tasked with identifying individuals' faces culled from images captured by students' open online cameras. The resultant facial information is then channeled into the residual network to extract intricate features at a deeper level. Subsequently, a comparative analysis of Euclidean distances against students' face databases is performed, effectively ascertaining the identity of each student.</li>
</ul>

<h3>Title: Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ritesh Sunil Chavan, Jack Mostow</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25187">https://arxiv.org/abs/2510.25187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25187">https://arxiv.org/pdf/2510.25187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25187]] Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence Prediction(https://arxiv.org/abs/2510.25187)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models are trained on massive datasets, this data is heavily skewed towards English. Does their impressive performance reflect genuine ability or just this data advantage? To find out, we tested them in a setting where they could not rely on data abundance: low-resource languages. Building on prior work Agarwal et al. (2025) that used Next Sentence Prediction (NSP) as a test, we created a large-scale benchmark with 10,000 questions each for English (a high-resource language), Swahili (medium-resource), and Hausa (low-resource). We then tested several top models, including GPT-4 Turbo, Gemini 1.5 Flash, and LLaMA 3 70B, to see how their performance holds up. The results painted a clear picture of how levels of language resources impact outcomes. While all models excelled in English, their accuracy dropped in Swahili and fell sharply in Hausa, with LLaMA 3 struggling the most. The story became even more interesting when we introduced Chain-of-Thought (CoT) prompting. For the struggling LLaMA 3, CoT acted as a helpful guide, significantly boosting its accuracy. However, for the more capable GPT-4 and Gemini, the same technique often backfired, leading to a kind of "overthinking" that hurt their results in the cross-lingual context. This reveals that Chain-of-Thought is not a universal solution; its effectiveness depends heavily on the model's baseline capability and the specific context of the task. Our framework pinpoints LLM weaknesses, highlights when CoT helps or hinders cross-lingual NSP performance, and factors influencing their decisions.</li>
</ul>

<h3>Title: AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training & Experimentation Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Ana M. Rodriguez, Jaime Acosta, Anantaa Kotal, Aritran Piplai</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25189">https://arxiv.org/abs/2510.25189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25189">https://arxiv.org/pdf/2510.25189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25189]] AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training & Experimentation Scenarios(https://arxiv.org/abs/2510.25189)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Designing realistic and adaptive networked threat scenarios remains a core challenge in cybersecurity research and training, still requiring substantial manual effort. While large language models (LLMs) show promise for automated synthesis, unconstrained generation often yields configurations that fail validation or execution. We present AgentCyTE, a framework integrating LLM-based reasoning with deterministic, schema-constrained network emulation to generate and refine executable threat environments. Through an agentic feedback loop, AgentCyTE observes scenario outcomes, validates correctness, and iteratively enhances realism and consistency. This hybrid approach preserves LLM flexibility while enforcing structural validity, enabling scalable, data-driven experimentation and reliable scenario generation for threat modeling and adaptive cybersecurity training. Our framework can be accessed at: this https URL</li>
</ul>

<h3>Title: Selective Learning for Deep Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Yisong Fu, Zezhi Shao, Chengqing Yu, Yujie Li, Zhulin An, Qi Wang, Yongjun Xu, Fei Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25207">https://arxiv.org/abs/2510.25207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25207">https://arxiv.org/pdf/2510.25207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25207]] Selective Learning for Deep Time Series Forecasting(https://arxiv.org/abs/2510.25207)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Benefiting from high capacity for capturing complex temporal patterns, deep learning (DL) has significantly advanced time series forecasting (TSF). However, deep models tend to suffer from severe overfitting due to the inherent vulnerability of time series to noise and anomalies. The prevailing DL paradigm uniformly optimizes all timesteps through the MSE loss and learns those uncertain and anomalous timesteps without difference, ultimately resulting in overfitting. To address this, we propose a novel selective learning strategy for deep TSF. Specifically, selective learning screens a subset of the whole timesteps to calculate the MSE loss in optimization, guiding the model to focus on generalizable timesteps while disregarding non-generalizable ones. Our framework introduces a dual-mask mechanism to target timesteps: (1) an uncertainty mask leveraging residual entropy to filter uncertain timesteps, and (2) an anomaly mask employing residual lower bound estimation to exclude anomalous timesteps. Extensive experiments across eight real-world datasets demonstrate that selective learning can significantly improve the predictive performance for typical state-of-the-art deep models, including 37.4% MSE reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.</li>
</ul>

<h3>Title: MSF-Net: Multi-Stage Feature Extraction and Fusion for Robust Photometric Stereo</h3>
<ul>
<li><strong>Authors: </strong>Shiyu Qin, Zhihao Cai, Kaixuan Wang, Lin Qi, Junyu Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25221">https://arxiv.org/abs/2510.25221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25221">https://arxiv.org/pdf/2510.25221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25221]] MSF-Net: Multi-Stage Feature Extraction and Fusion for Robust Photometric Stereo(https://arxiv.org/abs/2510.25221)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Photometric stereo is a technique aimed at determining surface normals through the utilization of shading cues derived from images taken under different lighting conditions. However, existing learning-based approaches often fail to accurately capture features at multiple stages and do not adequately promote interaction between these features. Consequently, these models tend to extract redundant features, especially in areas with intricate details such as wrinkles and edges. To tackle these issues, we propose MSF-Net, a novel framework for extracting information at multiple stages, paired with selective update strategy, aiming to extract high-quality feature information, which is critical for accurate normal construction. Additionally, we have developed a feature fusion module to improve the interplay among different features. Experimental results on the DiLiGenT benchmark show that our proposed MSF-Net significantly surpasses previous state-of-the-art methods in the accuracy of surface normal estimation.</li>
</ul>

<h3>Title: ProMediate: A Socio-cognitive framework for evaluating proactive agents in multi-party negotiation</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Liu, Bahar Sarrafzadeh, Pei Zhou, Longqi Yang, Jieyu Zhao, Ashish Sharma</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25224">https://arxiv.org/abs/2510.25224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25224">https://arxiv.org/pdf/2510.25224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25224]] ProMediate: A Socio-cognitive framework for evaluating proactive agents in multi-party negotiation(https://arxiv.org/abs/2510.25224)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) are increasingly used in agentic frameworks to assist individual users, there is a growing need for agents that can proactively manage complex, multi-party collaboration. Systematic evaluation methods for such proactive agents remain scarce, limiting progress in developing AI that can effectively support multiple people together. Negotiation offers a demanding testbed for this challenge, requiring socio-cognitive intelligence to navigate conflicting interests between multiple participants and multiple topics and build consensus. Here, we present ProMediate, the first framework for evaluating proactive AI mediator agents in complex, multi-topic, multi-party negotiations. ProMediate consists of two core components: (i) a simulation testbed based on realistic negotiation cases and theory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and ProMediate-Hard), with a plug-and-play proactive AI mediator grounded in socio-cognitive mediation theories, capable of flexibly deciding when and how to intervene; and (ii) a socio-cognitive evaluation framework with a new suite of metrics to measure consensus changes, intervention latency, mediator effectiveness, and intelligence. Together, these components establish a systematic framework for assessing the socio-cognitive intelligence of proactive AI agents in multi-party settings. Our results show that a socially intelligent mediator agent outperforms a generic baseline, via faster, better-targeted interventions. In the ProMediate-Hard setting, our social mediator increases consensus change by 3.6 percentage points compared to the generic baseline (10.65\% vs 7.01\%) while being 77\% faster in response (15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous, theory-grounded testbed to advance the development of proactive, socially intelligent agents.</li>
</ul>

<h3>Title: Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Quang-Khai Bui-Tran, Thanh-Huy Nguyen, Hoang-Thien Nguyen, Ba-Thinh Lam, Nguyen Lan Vi Vu, Phat K. Huynh, Ulas Bagci, Min Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25227">https://arxiv.org/abs/2510.25227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25227">https://arxiv.org/pdf/2510.25227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25227]] Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation(https://arxiv.org/abs/2510.25227)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, segmentation</a></li>
<li><strong>Abstract: </strong>Source-Free Domain Adaptation (SFDA) is emerging as a compelling solution for medical image segmentation under privacy constraints, yet current approaches often ignore sample difficulty and struggle with noisy supervision under domain shift. We present a new SFDA framework that leverages Hard Sample Selection and Denoised Patch Mixing to progressively align target distributions. First, unlabeled images are partitioned into reliable and unreliable subsets through entropy-similarity analysis, allowing adaptation to start from easy samples and gradually incorporate harder ones. Next, pseudo-labels are refined via Monte Carlo-based denoising masks, which suppress unreliable pixels and stabilize training. Finally, intra- and inter-domain objectives mix patches between subsets, transferring reliable semantics while mitigating noise. Experiments on benchmark datasets show consistent gains over prior SFDA and UDA methods, delivering more accurate boundary delineation and achieving state-of-the-art Dice and ASSD scores. Our study highlights the importance of progressive adaptation and denoised supervision for robust segmentation under domain shift.</li>
</ul>

<h3>Title: Balanced conic rectified flow</h3>
<ul>
<li><strong>Authors: </strong>Kim Shin Seong, Mingi Kwon, Jaeseok Jeong, Youngjung Uh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25229">https://arxiv.org/abs/2510.25229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25229">https://arxiv.org/pdf/2510.25229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25229]] Balanced conic rectified flow(https://arxiv.org/abs/2510.25229)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Rectified flow is a generative model that learns smooth transport mappings between two distributions through an ordinary differential equation (ODE). Unlike diffusion-based generative models, which require costly numerical integration of a generative ODE to sample images with state-of-the-art quality, rectified flow uses an iterative process called reflow to learn smooth and straight ODE paths. This allows for relatively simple and efficient generation of high-quality images. However, rectified flow still faces several challenges. 1) The reflow process requires a large number of generative pairs to preserve the target distribution, leading to significant computational costs. 2) Since the model is typically trained using only generated image pairs, its performance heavily depends on the 1-rectified flow model, causing it to become biased towards the generated data. In this work, we experimentally expose the limitations of the original rectified flow and propose a novel approach that incorporates real images into the training process. By preserving the ODE paths for real images, our method effectively reduces reliance on large amounts of generated data. Instead, we demonstrate that the reflow process can be conducted efficiently using a much smaller set of generated and real images. In CIFAR-10, we achieved significantly better FID scores, not only in one-step generation but also in full-step simulations, while using only of the generative pairs compared to the original method. Furthermore, our approach induces straighter paths and avoids saturation on generated images during reflow, leading to more robust ODE learning while preserving the distribution of real images.</li>
</ul>

<h3>Title: DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yinqi Cai, Jichang Li, Zhaolun Li, Weikai Chen, Rushi Lan, Xi Xie, Xiaonan Luo, Guanbin Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25237">https://arxiv.org/abs/2510.25237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25237">https://arxiv.org/pdf/2510.25237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25237]] DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis(https://arxiv.org/abs/2510.25237)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in deep generative models have made it easier to manipulate face videos, raising significant concerns about their potential misuse for fraud and misinformation. Existing detectors often perform well in in-domain scenarios but fail to generalize across diverse manipulation techniques due to their reliance on forgery-specific artifacts. In this work, we introduce DeepShield, a novel deepfake detection framework that balances local sensitivity and global generalization to improve robustness across unseen forgeries. DeepShield enhances the CLIP-ViT encoder through two key components: Local Patch Guidance (LPG) and Global Forgery Diversification (GFD). LPG applies spatiotemporal artifact modeling and patch-wise supervision to capture fine-grained inconsistencies often overlooked by global models. GFD introduces domain feature augmentation, leveraging domain-bridging and boundary-expanding feature generation to synthesize diverse forgeries, mitigating overfitting and enhancing cross-domain adaptability. Through the integration of novel local and global analysis for deepfake detection, DeepShield outperforms state-of-the-art methods in cross-dataset and cross-manipulation evaluations, achieving superior robustness against unseen deepfake attacks.</li>
</ul>

<h3>Title: VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations</h3>
<ul>
<li><strong>Authors: </strong>Qianqian Qiao, DanDan Zheng, Yihang Bo, Bao Peng, Heng Huang, Longteng Jiang, Huaye Wang, Jingdong Chen, Jun Zhou, Xin Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25238">https://arxiv.org/abs/2510.25238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25238">https://arxiv.org/pdf/2510.25238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25238]] VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations(https://arxiv.org/abs/2510.25238)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Video aesthetic assessment, a vital area in multimedia computing, integrates computer vision with human cognition. Its progress is limited by the lack of standardized datasets and robust models, as the temporal dynamics of video and multimodal fusion challenges hinder direct application of image-based methods. This study introduces VADB, the largest video aesthetic database with 10,490 diverse videos annotated by 37 professionals across multiple aesthetic dimensions, including overall and attribute-specific aesthetic scores, rich language comments and objective tags. We propose VADB-Net, a dual-modal pre-training framework with a two-stage training strategy, which outperforms existing video quality assessment models in scoring tasks and supports downstream video aesthetic assessment tasks. The dataset and source code are available at this https URL.</li>
</ul>

<h3>Title: Mapping and Classification of Trees Outside Forests using Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Moritz Lucas, Hamid Ebrahimy, Viacheslav Barkov, Ralf Pecenka, Kai-Uwe Kühnberger, Björn Waske</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25239">https://arxiv.org/abs/2510.25239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25239">https://arxiv.org/pdf/2510.25239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25239]] Mapping and Classification of Trees Outside Forests using Deep Learning(https://arxiv.org/abs/2510.25239)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Trees Outside Forests (TOF) play an important role in agricultural landscapes by supporting biodiversity, sequestering carbon, and regulating microclimates. Yet, most studies have treated TOF as a single class or relied on rigid rule-based thresholds, limiting ecological interpretation and adaptability across regions. To address this, we evaluate deep learning for TOF classification using a newly generated dataset and high-resolution aerial imagery from four agricultural landscapes in Germany. Specifically, we compare convolutional neural networks (CNNs), vision transformers, and hybrid CNN-transformer models across six semantic segmentation architectures (ABCNet, LSKNet, FT-UNetFormer, DC-Swin, BANet, and U-Net) to map four categories of woody vegetation: Forest, Patch, Linear, and Tree, derived from previous studies and governmental products. Overall, the models achieved good classification accuracy across the four landscapes, with the FT-UNetFormer performing best (mean Intersection-over-Union 0.74; mean F1 score 0.84), underscoring the importance of spatial context understanding in TOF mapping and classification. Our results show good results for Forest and Linear class and reveal challenges particularly in classifying complex structures with high edge density, notably the Patch and Tree class. Our generalization experiments highlight the need for regionally diverse training data to ensure reliable large-scale mapping. The dataset and code are openly available at this https URL</li>
</ul>

<h3>Title: LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yang Miao, Jan-Nico Zaech, Xi Wang, Fabien Despinoy, Danda Pani Paudel, Luc Van Gool</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25263">https://arxiv.org/abs/2510.25263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25263">https://arxiv.org/pdf/2510.25263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25263]] LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation(https://arxiv.org/abs/2510.25263)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>We propose LangHOPS, the first Multimodal Large Language Model (MLLM) based framework for open-vocabulary object-part instance segmentation. Given an image, LangHOPS can jointly detect and segment hierarchical object and part instances from open-vocabulary candidate categories. Unlike prior approaches that rely on heuristic or learnable visual grouping, our approach grounds object-part hierarchies in language space. It integrates the MLLM into the object-part parsing pipeline to leverage its rich knowledge and reasoning capabilities, and link multi-granularity concepts within the hierarchies. We evaluate LangHOPS across multiple challenging scenarios, including in-domain and cross-dataset object-part instance segmentation, and zero-shot semantic segmentation. LangHOPS achieves state-of-the-art results, surpassing previous methods by 5.5% Average Precision (AP) (in-domain) and 4.8% (cross-dataset) on the PartImageNet dataset and by 2.5% mIOU on unseen object parts in ADE20K (zero-shot). Ablation studies further validate the effectiveness of the language-grounded hierarchy and MLLM driven part query refinement strategy. The code will be released here.</li>
</ul>

<h3>Title: Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yuyang Huang, Yabo Chen, Junyu Zhou, Wenrui Dai, Xiaopeng Zhang, Junni Zou, Hongkai Xiong, Qi Tian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25279">https://arxiv.org/abs/2510.25279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25279">https://arxiv.org/pdf/2510.25279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25279]] Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation(https://arxiv.org/abs/2510.25279)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Source-free domain adaptation (SFDA) is a challenging task that tackles domain shifts using only a pre-trained source model and unlabeled target data. Existing SFDA methods are restricted by the fundamental limitation of source-target domain discrepancy. Non-generation SFDA methods suffer from unreliable pseudo-labels in challenging scenarios with large domain discrepancies, while generation-based SFDA methods are evidently degraded due to enlarged domain discrepancies in creating pseudo-source data. To address this limitation, we propose a novel generation-based framework named Diffusion-Driven Progressive Target Manipulation (DPTM) that leverages unlabeled target data as references to reliably generate and progressively refine a pseudo-target domain for SFDA. Specifically, we divide the target samples into a trust set and a non-trust set based on the reliability of pseudo-labels to sufficiently and reliably exploit their information. For samples from the non-trust set, we develop a manipulation strategy to semantically transform them into the newly assigned categories, while simultaneously maintaining them in the target distribution via a latent diffusion model. Furthermore, we design a progressive refinement mechanism that progressively reduces the domain discrepancy between the pseudo-target domain and the real target domain via iterative refinement. Experimental results demonstrate that DPTM outperforms existing methods by a large margin and achieves state-of-the-art performance on four prevailing SFDA benchmark datasets with different scales. Remarkably, DPTM can significantly enhance the performance by up to 18.6% in scenarios with large source-target gaps.</li>
</ul>

<h3>Title: On the Stability of Neural Networks in Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Blaise Delattre</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25282">https://arxiv.org/abs/2510.25282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25282">https://arxiv.org/pdf/2510.25282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25282]] On the Stability of Neural Networks in Deep Learning(https://arxiv.org/abs/2510.25282)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning has achieved remarkable success across a wide range of tasks, but its models often suffer from instability and vulnerability: small changes to the input may drastically affect predictions, while optimization can be hindered by sharp loss landscapes. This thesis addresses these issues through the unifying perspective of sensitivity analysis, which examines how neural networks respond to perturbations at both the input and parameter levels. We study Lipschitz networks as a principled way to constrain sensitivity to input perturbations, thereby improving generalization, adversarial robustness, and training stability. To complement this architectural approach, we introduce regularization techniques based on the curvature of the loss function, promoting smoother optimization landscapes and reducing sensitivity to parameter variations. Randomized smoothing is also explored as a probabilistic method for enhancing robustness at decision boundaries. By combining these perspectives, we develop a unified framework where Lipschitz continuity, randomized smoothing, and curvature regularization interact to address fundamental challenges in stability. The thesis contributes both theoretical analysis and practical methodologies, including efficient spectral norm computation, novel Lipschitz-constrained layers, and improved certification procedures.</li>
</ul>

<h3>Title: Parrot: A Training Pipeline Enhances Both Program CoT and Natural Language CoT for Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Senjie Jin, Lu Chen, Zhiheng Xi, Yuhui Wang, Sirui Song, Yuhao Zhou, Xinbo Zhang, Peng Sun, Hong Lu, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25310">https://arxiv.org/abs/2510.25310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25310">https://arxiv.org/pdf/2510.25310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25310]] Parrot: A Training Pipeline Enhances Both Program CoT and Natural Language CoT for Reasoning(https://arxiv.org/abs/2510.25310)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Natural language chain-of-thought (N-CoT) and Program chain-of-thought (P-CoT) have emerged as two primary paradigms for large language models (LLMs) to solve mathematical reasoning problems. Current research typically endeavors to achieve unidirectional enhancement: P-CoT enhanced N-CoT or N-CoT enhanced P-CoT. In this paper, we seek to fully unleash the two paradigms' strengths for mutual enhancement and ultimately achieve simultaneous improvements. We conduct a detailed analysis of the error types across two paradigms, based on which we propose Parrot, a novel training pipeline for mathematical problems: 1) Three target-designed subtasks integrate sequential P-CoT and N-CoT generation. 2) A subtask hybrid training strategy to facilitate natural language semantic transferability. 3) The converted N-CoT auxiliary reward is designed to alleviate the sparse rewards in P-CoT optimization. Extensive experiments demonstrate that Parrot significantly enhances both the performance of N-CoT and P-CoT, especially on N-CoT. Using Parrot SFT, the N-CoT performance of LLaMA2 and CodeLLaMA achieve gains of +21.87 and +21.48 on MathQA over the RL baseline, which is resource-intensive.</li>
</ul>

<h3>Title: CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices</h3>
<ul>
<li><strong>Authors: </strong>Xuchen Feng, Siyu Liao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25323">https://arxiv.org/abs/2510.25323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25323">https://arxiv.org/pdf/2510.25323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25323]] CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices(https://arxiv.org/abs/2510.25323)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Normalizing flows are deep generative models that enable efficient likelihood estimation and sampling through invertible transformations. A key challenge is to design linear layers that enhance expressiveness while maintaining efficient computation of the Jacobian determinant and inverse. We introduce a novel invertible linear layer based on the product of circulant and diagonal matrices. This decomposition reduces parameter complexity from $\mathcal{O}(n^2)$ to $\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$ circulant matrices while still approximating general linear transformations. By leveraging the Fast Fourier Transform, our approach reduces the time complexity of matrix inversion from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn\log n)$ and that of computing the log-determinant from $\mathcal{O}(n^3)$ to $\mathcal{O}(mn)$, where $n$ is the input dimension. We build upon this layer to develop Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on natural image datasets and effectively models data with inherent periodic structure. Furthermore, CDFlow significantly accelerates key operations in normalizing flows, providing practical benefits for scalable generative modeling.</li>
</ul>

<h3>Title: StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Hu, Zhenyu Yang, Shihan Wang, Shengsheng Qian, Bin Wen, Fan Yang, Tingting Gao, Changsheng Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25332">https://arxiv.org/abs/2510.25332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25332">https://arxiv.org/pdf/2510.25332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25332]] StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA(https://arxiv.org/abs/2510.25332)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The rapid growth of streaming video applications demands multimodal models with enhanced capabilities for temporal dynamics understanding and complex reasoning. However, current Video Question Answering (VideoQA) datasets suffer from two critical limitations: 1) Static annotation mechanisms fail to capture the evolving nature of answers in temporal video streams, and 2) The absence of explicit reasoning process annotations restricts model interpretability and logical deduction capabilities. To address these challenges, We introduce StreamingCoT, the first dataset explicitly designed for temporally evolving reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our framework first establishes a dynamic hierarchical annotation architecture that generates per-second dense descriptions and constructs temporally-dependent semantic segments through similarity fusion, paired with question-answer sets constrained by temporal evolution patterns. We further propose an explicit reasoning chain generation paradigm that extracts spatiotemporal objects via keyframe semantic alignment, derives object state transition-based reasoning paths using large language models, and ensures logical coherence through human-verified validation. This dataset establishes a foundation for advancing research in streaming video understanding, complex temporal reasoning, and multimodal inference. Our StreamingCoT and its construction toolkit can be accessed at this https URL.</li>
</ul>

<h3>Title: 3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Ayman Abaid, Gianpiero Guidone, Sara Alsubai, Foziyah Alquahtani, Talha Iqbal, Ruth Sharif, Hesham Elzomor, Emiliano Bianchini, Naeif Almagal, Michael G. Madden, Faisal Sharif, Ihsan Ullah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25347">https://arxiv.org/abs/2510.25347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25347">https://arxiv.org/pdf/2510.25347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25347]] 3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework(https://arxiv.org/abs/2510.25347)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Coronary artery calcium (CAC) scoring plays a crucial role in the early detection and risk stratification of coronary artery disease (CAD). In this study, we focus on non-contrast coronary computed tomography angiography (CCTA) scans, which are commonly used for early calcification detection in clinical settings. To address the challenge of limited annotated data, we propose a radiomics-based pipeline that leverages pseudo-labeling to generate training labels, thereby eliminating the need for expert-defined segmentations. Additionally, we explore the use of pretrained foundation models, specifically CT-FM and RadImageNet, to extract image features, which are then used with traditional classifiers. We compare the performance of these deep learning features with that of radiomics features. Evaluation is conducted on a clinical CCTA dataset comprising 182 patients, where individuals are classified into two groups: zero versus non-zero calcium scores. We further investigate the impact of training on non-contrast datasets versus combined contrast and non-contrast datasets, with testing performed only on non contrast scans. Results show that radiomics-based models significantly outperform CNN-derived embeddings from foundation models (achieving 84% accuracy and p<0.05), despite the unavailability of expert annotations.</li>
</ul>

<h3>Title: Beyond Leakage and Complexity: Towards Realistic and Efficient Information Cascade Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jie Peng, Rui Wang, Qiang Wang, Zhewei Wei, Bin Tong, Guan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25348">https://arxiv.org/abs/2510.25348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25348">https://arxiv.org/pdf/2510.25348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25348]] Beyond Leakage and Complexity: Towards Realistic and Efficient Information Cascade Prediction(https://arxiv.org/abs/2510.25348)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Information cascade popularity prediction is a key problem in analyzing content diffusion in social networks. However, current related works suffer from three critical limitations: (1) temporal leakage in current evaluation--random cascade-based splits allow models to access future information, yielding unrealistic results; (2) feature-poor datasets that lack downstream conversion signals (e.g., likes, comments, or purchases), which limits more practical applications; (3) computational inefficiency of complex graph-based methods that require days of training for marginal gains. We systematically address these challenges from three perspectives: task setup, dataset construction, and model design. First, we propose a time-ordered splitting strategy that chronologically partitions data into consecutive windows, ensuring models are evaluated on genuine forecasting tasks without future information leakage. Second, we introduce Taoke, a large-scale e-commerce cascade dataset featuring rich promoter/product attributes and ground-truth purchase conversions--capturing the complete diffusion lifecycle from promotion to monetization. Third, we develop CasTemp, a lightweight framework that efficiently models cascade dynamics through temporal walks, Jaccard-based neighbor selection for inter-cascade dependencies, and GRU-based encoding with time-aware attention. Under leak-free evaluation, CasTemp achieves state-of-the-art performance across four datasets with orders-of-magnitude speedup. Notably, it excels at predicting second-stage popularity conversions--a practical task critical for real-world applications.</li>
</ul>

<h3>Title: Is Protective DNS Blocking the Wild West?</h3>
<ul>
<li><strong>Authors: </strong>David Plonka, Branden Palacio, Debbie Perouli</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25352">https://arxiv.org/abs/2510.25352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25352">https://arxiv.org/pdf/2510.25352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25352]] Is Protective DNS Blocking the Wild West?(https://arxiv.org/abs/2510.25352)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>We perform a passive measurement study investigating how a Protective DNS service might perform in a Research & Education Network serving hundreds of member institutions. Utilizing freely-available DNS blocklists consisting of domain names deemed to be threats, we test hundreds of millions of users' real DNS queries, observed over a week's time, to find which answers would be blocked because they involve domain names that are potential threats. We find the blocklists disorderly regarding their names, goals, transparency, and provenance making them quite difficult to compare. Consequently, these Protective DNS underpinnings lack organized oversight, presenting challenges and risks in operation at scale.</li>
</ul>

<h3>Title: Not ready for the bench: LLM legal interpretation is unstable and out of step with human judgments</h3>
<ul>
<li><strong>Authors: </strong>Abhishek Purushothama, Junghyun Min, Brandon Waldon, Nathan Schneider</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25356">https://arxiv.org/abs/2510.25356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25356">https://arxiv.org/pdf/2510.25356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25356]] Not ready for the bench: LLM legal interpretation is unstable and out of step with human judgments(https://arxiv.org/abs/2510.25356)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Legal interpretation frequently involves assessing how a legal text, as understood by an 'ordinary' speaker of the language, applies to the set of facts characterizing a legal dispute in the U.S. judicial system. Recent scholarship has proposed that legal practitioners add large language models (LLMs) to their interpretive toolkit. This work offers an empirical argument against LLM interpretation as recently practiced by legal scholars and federal judges. Our investigation in English shows that models do not provide stable interpretive judgments: varying the question format can lead the model to wildly different conclusions. Moreover, the models show weak to moderate correlation with human judgment, with large variance across model and question variant, suggesting that it is dangerous to give much credence to the conclusions produced by generative AI.</li>
</ul>

<h3>Title: Position: Biology is the Challenge Physics-Informed ML Needs to Evolve</h3>
<ul>
<li><strong>Authors: </strong>Julien Martinelli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25368">https://arxiv.org/abs/2510.25368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25368">https://arxiv.org/pdf/2510.25368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25368]] Position: Biology is the Challenge Physics-Informed ML Needs to Evolve(https://arxiv.org/abs/2510.25368)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Physics-Informed Machine Learning (PIML) has successfully integrated mechanistic understanding into machine learning, particularly in domains governed by well-known physical laws. This success has motivated efforts to apply PIML to biology, a field rich in dynamical systems but shaped by different constraints. Biological modeling, however, presents unique challenges: multi-faceted and uncertain prior knowledge, heterogeneous and noisy data, partial observability, and complex, high-dimensional networks. In this position paper, we argue that these challenges should not be seen as obstacles to PIML, but as catalysts for its evolution. We propose Biology-Informed Machine Learning (BIML): a principled extension of PIML that retains its structural grounding while adapting to the practical realities of biology. Rather than replacing PIML, BIML retools its methods to operate under softer, probabilistic forms of prior knowledge. We outline four foundational pillars as a roadmap for this transition: uncertainty quantification, contextualization, constrained latent structure inference, and scalability. Foundation Models and Large Language Models will be key enablers, bridging human expertise with computational modeling. We conclude with concrete recommendations to build the BIML ecosystem and channel PIML-inspired innovation toward challenges of high scientific and societal relevance.</li>
</ul>

<h3>Title: Monitoring Transformative Technological Convergence Through LLM-Extracted Semantic Entity Triple Graphs</h3>
<ul>
<li><strong>Authors: </strong>Alexander Sternfeld, Andrei Kucharavy, Dimitri Percia David, Alain Mermoud, Julian Jang-Jaccard, Nathan Monnet</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25370">https://arxiv.org/abs/2510.25370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25370">https://arxiv.org/pdf/2510.25370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25370]] Monitoring Transformative Technological Convergence Through LLM-Extracted Semantic Entity Triple Graphs(https://arxiv.org/abs/2510.25370)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Forecasting transformative technologies remains a critical but challenging task, particularly in fast-evolving domains such as Information and Communication Technologies (ICTs). Traditional expert-based methods struggle to keep pace with short innovation cycles and ambiguous early-stage terminology. In this work, we propose a novel, data-driven pipeline to monitor the emergence of transformative technologies by identifying patterns of technological convergence. Our approach leverages advances in Large Language Models (LLMs) to extract semantic triples from unstructured text and construct a large-scale graph of technology-related entities and relations. We introduce a new method for grouping semantically similar technology terms (noun stapling) and develop graph-based metrics to detect convergence signals. The pipeline includes multi-stage filtering, domain-specific keyword clustering, and a temporal trend analysis of topic co-occurence. We validate our methodology on two complementary datasets: 278,625 arXiv preprints (2017--2024) to capture early scientific signals, and 9,793 USPTO patent applications (2018-2024) to track downstream commercial developments. Our results demonstrate that the proposed pipeline can identify both established and emerging convergence patterns, offering a scalable and generalizable framework for technology forecasting grounded in full-text analysis.</li>
</ul>

<h3>Title: Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>M Yashwanth, Sharannya Ghosh, Aditay Tripathi, Anirban Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25372">https://arxiv.org/abs/2510.25372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25372">https://arxiv.org/pdf/2510.25372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25372]] Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers(https://arxiv.org/abs/2510.25372)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, transformer</a></li>
<li><strong>Abstract: </strong>Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has proven highly effective as a parameter-efficient fine-tuning technique for adapting large models to downstream tasks with limited data. Its parameter efficiency makes it particularly suitable for Federated Learning (FL), where both communication and computation budgets are often constrained. However, global prompt tuning struggles to generalize across heterogeneous clients, while personalized tuning overfits to local data and lacks generalization. We propose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt Tuning), a unified framework designed to achieve both generalization and personalization in federated prompt tuning of ViTs. Within this framework, we introduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on class-specific prompts maintained alongside a globally shared prompt. For each input, CCMP adaptively combines class-specific prompts using weights derived from global class prototypes and client class priors. This approach enables per-sample prompt personalization without storing client-dependent trainable parameters. The prompts are collaboratively optimized via traditional federated averaging technique on the same. Comprehensive evaluations on CIFAR-100, TinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT consistently surpasses the state-of-the-art baselines under diverse data heterogeneity scenarios, establishing a strong foundation for efficient and generalizable federated prompt tuning of Vision Transformers.</li>
</ul>

<h3>Title: From ECU to VSOC: UDS Security Monitoring Strategies</h3>
<ul>
<li><strong>Authors: </strong>Ali Recai Yekta, Nicolas Loza, Jens Gramm, Michael Peter Schneider, Stefan Katzenbeisser</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25375">https://arxiv.org/abs/2510.25375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25375">https://arxiv.org/pdf/2510.25375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25375]] From ECU to VSOC: UDS Security Monitoring Strategies(https://arxiv.org/abs/2510.25375)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Increasing complexity and connectivity of modern vehicles have heightened their vulnerability to cyberattacks. This paper addresses security challenges associated with the Unified Diagnostic Services (UDS) protocol, a critical communication framework for vehicle diagnostics in the automotive industry. We present security monitoring strategies for the UDS protocol that leverage in-vehicle logging and remote analysis through a Vehicle Security Operations Center (VSOC). Our approach involves specifying security event logging requirements, contextual data collection, and the development of detection strategies aimed at identifying UDS attack scenarios. By applying these strategies to a comprehensive taxonomy of UDS attack techniques, we demonstrate that our detection methods cover a wide range of potential attack vectors. Furthermore, we assess the adequacy of current AUTOSAR standardized security events in supporting UDS attack detection, identifying gaps in the current standard. This work enhances the understanding of vehicle security monitoring and provides an example for developing robust cybersecurity measures in automotive communication protocols.</li>
</ul>

<h3>Title: Hallucinations in Bibliographic Recommendation: Citation Frequency as a Proxy for Training Data Redundancy</h3>
<ul>
<li><strong>Authors: </strong>Junichiro Niimi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25378">https://arxiv.org/abs/2510.25378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25378">https://arxiv.org/pdf/2510.25378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25378]] Hallucinations in Bibliographic Recommendation: Citation Frequency as a Proxy for Training Data Redundancy(https://arxiv.org/abs/2510.25378)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been increasingly applied to a wide range of tasks, from natural language understanding to code generation. While they have also been used to assist in bibliographic recommendation, the hallucination of non-existent papers remains a major issue. Building on prior studies, this study hypothesizes that an LLM's ability to correctly produce bibliographic information depends on whether the underlying knowledge is generated or memorized, with highly cited papers (i.e., more frequently appear in the training corpus) showing lower hallucination rates. We therefore assume citation count as a proxy for training data redundancy (i.e., the frequency with which a given bibliographic record is repeatedly represented in the pretraining corpus) and investigate how citation frequency affects hallucinated references in LLM outputs. Using GPT-4.1, we generated and manually verified 100 bibliographic records across twenty computer-science domains, and measured factual consistency via cosine similarity between generated and authentic metadata. The results revealed that (i) hallucination rates vary across research domains, (ii) citation count is strongly correlated with factual accuracy, and (iii) bibliographic information becomes almost verbatimly memorized beyond approximately 1,000 citations. These findings suggest that highly cited papers are nearly verbatimly retained in the model, indicating a threshold where generalization shifts into memorization.</li>
</ul>

<h3>Title: Roleplaying with Structure: Synthetic Therapist-Client Conversation Generation from Questionnaires</h3>
<ul>
<li><strong>Authors: </strong>Doan Nam Long Vu, Rui Tan, Lena Moench, Svenja Jule Francke, Daniel Woiwod, Florian Thomas-Odenthal, Sanna Stroth, Tilo Kircher, Christiane Hermann, Udo Dannlowski, Hamidreza Jamalabadi, Shaoxiong Ji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25384">https://arxiv.org/abs/2510.25384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25384">https://arxiv.org/pdf/2510.25384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25384]] Roleplaying with Structure: Synthetic Therapist-Client Conversation Generation from Questionnaires(https://arxiv.org/abs/2510.25384)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>The development of AI for mental health is hindered by a lack of authentic therapy dialogues, due to strict privacy regulations and the fact that clinical sessions were historically rarely recorded. We present an LLM-driven pipeline that generates synthetic counseling dialogues based on structured client profiles and psychological questionnaires. Grounded on the principles of Cognitive Behavioral Therapy (CBT), our method creates synthetic therapeutic conversations for clinical disorders such as anxiety and depression. Our framework, SQPsych (Structured Questionnaire-based Psychotherapy), converts structured psychological input into natural language dialogues through therapist-client simulations. Due to data governance policies and privacy restrictions prohibiting the transmission of clinical questionnaire data to third-party services, previous methodologies relying on proprietary models are infeasible in our setting. We address this limitation by generating a high-quality corpus using open-weight LLMs, validated through human expert evaluation and LLM-based assessments. Our SQPsychLLM models fine-tuned on SQPsychConv achieve strong performance on counseling benchmarks, surpassing baselines in key therapeutic skills. Our findings highlight the potential of synthetic data to enable scalable, data-secure, and clinically informed AI for mental health support. We will release our code, models, and corpus at this https URL</li>
</ul>

<h3>Title: GPTOpt: Towards Efficient LLM-Based Black-Box Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jamison Meindl, Yunsheng Tian, Tony Cui, Veronika Thost, Zhang-Wei Hong, Jie Chen, Wojciech Matusik, Mina Konaković Luković</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25404">https://arxiv.org/abs/2510.25404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25404">https://arxiv.org/pdf/2510.25404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25404]] GPTOpt: Towards Efficient LLM-Based Black-Box Optimization(https://arxiv.org/abs/2510.25404)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Global optimization of expensive, derivative-free black-box functions demands extreme sample efficiency. Classical methods such as Bayesian Optimization (BO) can be effective, but they often require careful parameter tuning to each application domain. At the same time, Large Language Models (LLMs) have shown broad capabilities, yet state-of-the-art models remain limited in solving continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based optimization method that equips LLMs with continuous black-box optimization capabilities. By fine-tuning large language models on extensive synthetic datasets derived from diverse BO parameterizations, GPTOpt leverages LLM pre-training to generalize across optimization tasks. On a variety of black-box optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting the capacity of LLMs for advanced numerical reasoning and introducing a flexible framework for global optimization without parameter tuning.</li>
</ul>

<h3>Title: BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains</h3>
<ul>
<li><strong>Authors: </strong>Vijay Devane, Mohd Nauman, Bhargav Patel, Aniket Mahendra Wakchoure, Yogeshkumar Sant, Shyam Pawar, Viraj Thakur, Ananya Godse, Sunil Patra, Neha Maurya, Suraj Racha, Nitish Kamal Singh, Ajay Nagpal, Piyush Sawarkar, Kundeshwar Vijayrao Pundalik, Rohit Saluja, Ganesh Ramakrishnan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25409">https://arxiv.org/abs/2510.25409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25409">https://arxiv.org/pdf/2510.25409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25409]] BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains(https://arxiv.org/abs/2510.25409)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models(LLMs) has intensified the need for domain and culture specific evaluation. Existing benchmarks are largely Anglocentric and domain-agnostic, limiting their applicability to India-centric contexts. To address this gap, we introduce BhashaBench V1, the first domain-specific, multi-task, bilingual benchmark focusing on critical Indic knowledge systems. BhashaBench V1 contains 74,166 meticulously curated question-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from authentic government and domain-specific exams. It spans four major domains: Agriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and covering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs reveals significant domain and language specific performance gaps, with especially large disparities in low-resource domains. For instance, GPT-4o achieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models consistently perform better on English content compared to Hindi across all domains. Subdomain-level analysis shows that areas such as Cyber Law, International Finance perform relatively well, while Panchakarma, Seed Science, and Human Rights remain notably weak. BhashaBench V1 provides a comprehensive dataset for evaluating large language models across India's diverse knowledge domains. It enables assessment of models' ability to integrate domain-specific knowledge with bilingual understanding. All code, benchmarks, and resources are publicly available to support open research.</li>
</ul>

<h3>Title: Serve Programs, Not Prompts</h3>
<ul>
<li><strong>Authors: </strong>In Gim, Lin Zhong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25412">https://arxiv.org/abs/2510.25412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25412">https://arxiv.org/pdf/2510.25412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25412]] Serve Programs, Not Prompts(https://arxiv.org/abs/2510.25412)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current large language model (LLM) serving systems, primarily designed for text completion, are neither efficient nor adaptable for increasingly complex LLM applications due to their inflexible design. We propose a new LLM serving system architecture that serves programs instead of prompts to address this problem. These programs, called LLM Inference Programs (LIPs), allow users to customize token prediction and KV cache management at runtime and to offload parts of their application logic, such as tool execution, to the server. We describe an example of this architecture through a system named Symphony, which functions as an operating system for LIPs. Symphony exposes LLM model computations via system calls and virtualizes KV cache with a dedicated file system, while ensuring GPU efficiency with a two-level process scheduling scheme. Symphony has the potential to open the door to a more efficient and extensible ecosystem for LLM applications.</li>
</ul>

<h3>Title: Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media</h3>
<ul>
<li><strong>Authors: </strong>Shakib Yazdani, Yasser Hamidullah, Cristina España-Bonet, Josef van Genabith</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25413">https://arxiv.org/abs/2510.25413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25413">https://arxiv.org/pdf/2510.25413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25413]] Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media(https://arxiv.org/abs/2510.25413)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Most existing sign language translation (SLT) datasets are limited in scale, lack multilingual coverage, and are costly to curate due to their reliance on expert annotation and controlled recording setup. Recently, Vision Language Models (VLMs) have demonstrated strong capabilities as evaluators and real-time assistants. Despite these advancements, their potential remains untapped in the context of sign language dataset acquisition. To bridge this gap, we introduce the first automated annotation and filtering framework that utilizes VLMs to reduce reliance on manual effort while preserving data quality. Our method is applied to TikTok videos across eight sign languages and to the already curated YouTube-SL-25 dataset in German Sign Language for the purpose of additional evaluation. Our VLM-based pipeline includes a face visibility detection, a sign activity recognition, a text extraction from video content, and a judgment step to validate alignment between video and text, implementing generic filtering, annotation and validation steps. Using the resulting corpus, TikTok-SL-8, we assess the performance of two off-the-shelf SLT models on our filtered dataset for German and American Sign Languages, with the goal of establishing baselines and evaluating the robustness of recent models on automatically extracted, slightly noisy data. Our work enables scalable, weakly supervised pretraining for SLT and facilitates data acquisition from social media.</li>
</ul>

<h3>Title: Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction</h3>
<ul>
<li><strong>Authors: </strong>Asutosh Hota, Jussi P. P. Jokinen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25426">https://arxiv.org/abs/2510.25426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25426">https://arxiv.org/pdf/2510.25426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25426]] Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction(https://arxiv.org/abs/2510.25426)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) is positioning language at the core of human-computer interaction (HCI). We argue that advancing HCI requires attention to the linguistic foundations of interaction, particularly implicature (meaning conveyed beyond explicit statements through shared context) which is essential for human-AI (HAI) alignment. This study examines LLMs' ability to infer user intent embedded in context-driven prompts and whether understanding implicature improves response generation. Results show that larger models approximate human interpretations more closely, while smaller models struggle with implicature inference. Furthermore, implicature-based prompts significantly enhance the perceived relevance and quality of responses across models, with notable gains in smaller models. Overall, 67.6% of participants preferred responses with implicature-embedded prompts to literal ones, highlighting a clear preference for contextually nuanced communication. Our work contributes to understanding how linguistic theory can be used to address the alignment problem by making HAI interaction more natural and contextually grounded.</li>
</ul>

<h3>Title: RLMEval: Evaluating Research-Level Neural Theorem Proving</h3>
<ul>
<li><strong>Authors: </strong>Auguste Poiroux, Antoine Bosselut, Viktor Kunčak</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25427">https://arxiv.org/abs/2510.25427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25427">https://arxiv.org/pdf/2510.25427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25427]] RLMEval: Evaluating Research-Level Neural Theorem Proving(https://arxiv.org/abs/2510.25427)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite impressive results on curated benchmarks, the practical impact of large language models (LLMs) on research-level neural theorem proving and proof autoformalization is still limited. We introduce RLMEval, an evaluation suite for these tasks, focusing on research-level mathematics from real-world Lean formalization projects. RLMEval targets the evaluation of neural theorem proving and proof autoformalization on challenging research-level theorems by leveraging real Lean Blueprint formalization projects. Our evaluation of state-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean projects, reveals a significant gap: progress on existing benchmarks does not readily translate to these more realistic settings, with the best model achieving only a 10.3 % pass rate. RLMEval provides a new, challenging benchmark designed to guide and accelerate progress in automated reasoning for formal mathematics.</li>
</ul>

<h3>Title: Depth and Autonomy: A Framework for Evaluating LLM Applications in Social Science Research</h3>
<ul>
<li><strong>Authors: </strong>Ali Sanaei, Ali Rajabzadeh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25432">https://arxiv.org/abs/2510.25432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25432">https://arxiv.org/pdf/2510.25432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25432]] Depth and Autonomy: A Framework for Evaluating LLM Applications in Social Science Research(https://arxiv.org/abs/2510.25432)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly utilized by researchers across a wide range of domains, and qualitative social science is no exception; however, this adoption faces persistent challenges, including interpretive bias, low reliability, and weak auditability. We introduce a framework that situates LLM usage along two dimensions, interpretive depth and autonomy, thereby offering a straightforward way to classify LLM applications in qualitative research and to derive practical design recommendations. We present the state of the literature with respect to these two dimensions, based on all published social science papers available on Web of Science that use LLMs as a tool and not strictly as the subject of study. Rather than granting models expansive freedom, our approach encourages researchers to decompose tasks into manageable segments, much as they would when delegating work to capable undergraduate research assistants. By maintaining low levels of autonomy and selectively increasing interpretive depth only where warranted and under supervision, one can plausibly reap the benefits of LLMs while preserving transparency and reliability.</li>
</ul>

<h3>Title: A Critical Study of Automatic Evaluation in Sign Language Translation</h3>
<ul>
<li><strong>Authors: </strong>Shakib Yazdani, Yasser Hamidullah, Cristina España-Bonet, Eleftherios Avramidis, Josef van Genabith</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25434">https://arxiv.org/abs/2510.25434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25434">https://arxiv.org/pdf/2510.25434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25434]] A Critical Study of Automatic Evaluation in Sign Language Translation(https://arxiv.org/abs/2510.25434)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Automatic evaluation metrics are crucial for advancing sign language translation (SLT). Current SLT evaluation metrics, such as BLEU and ROUGE, are only text-based, and it remains unclear to what extent text-based metrics can reliably capture the quality of SLT outputs. To address this gap, we investigate the limitations of text-based SLT evaluation metrics by analyzing six metrics, including BLEU, chrF, and ROUGE, as well as BLEURT on the one hand, and large language model (LLM)-based evaluators such as G-Eval and GEMBA zero-shot direct assessment on the other hand. Specifically, we assess the consistency and robustness of these metrics under three controlled conditions: paraphrasing, hallucinations in model outputs, and variations in sentence length. Our analysis highlights the limitations of lexical overlap metrics and demonstrates that while LLM-based evaluators better capture semantic equivalence often missed by conventional metrics, they can also exhibit bias toward LLM-paraphrased translations. Moreover, although all metrics are able to detect hallucinations, BLEU tends to be overly sensitive, whereas BLEURT and LLM-based evaluators are comparatively lenient toward subtle cases. This motivates the need for multimodal evaluation frameworks that extend beyond text-based metrics to enable a more holistic assessment of SLT outputs.</li>
</ul>

<h3>Title: Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs</h3>
<ul>
<li><strong>Authors: </strong>Fei Wei, Daoyuan Chen, Ce Wang, Yilun Huang, Yushuo Chen, Xuchen Pan, Yaliang Li, Bolin Ding</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25441">https://arxiv.org/abs/2510.25441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25441">https://arxiv.org/pdf/2510.25441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25441]] Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs(https://arxiv.org/abs/2510.25441)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel as passive responders, but teaching them to be proactive, goal-oriented partners, a critical capability in high-stakes domains, remains a major challenge. Current paradigms either myopically optimize single-turn attributes or rely on brittle, high-cost user simulators, creating a persistent ``reality gap''. To bridge this gap, we introduce \texttt{Learn-to-Ask}, a general, simulator-free framework for learning and deploying proactive dialogue agents \textit{directly from offline expert data}, bypassing the need to model complex user dynamics. Our key insight is to reframe the offline policy learning problem by leveraging the \textbf{observed future} of each expert trajectory. This allows us to infer a dense, turn-by-turn reward signal grounded in the expert's revealed strategy, decomposing the intractable long-horizon problem into a series of supervised learning tasks, and training a policy to output a structured \texttt{(action, state_assessment)} tuple, governing both \textbf{what to ask} and, crucially, \textbf{when to stop}. To ensure reward fidelity, our Automated Grader Calibration pipeline systematically purges noise from the LLM-based reward model with minimal human supervision. Empirically, we demonstrate the efficacy of \texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying sizes up to 32B. Our approach culminates in the successful deployment of LLMs into a live, large-scale online AI service. In rigorous in-house evaluations, our model was launched and achieved performance even superior to human experts, proving our framework's ability to translate offline data into tangible, real-world impact. We hope this work provides a practical and economically viable blueprint for transforming passive LLMs into proactive, goal-oriented LLM applications.</li>
</ul>

<h3>Title: Scalable Utility-Aware Multiclass Calibration</h3>
<ul>
<li><strong>Authors: </strong>Mahmoud Hegazy, Michael I. Jordan, Aymeric Dieuleveut</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25458">https://arxiv.org/abs/2510.25458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25458">https://arxiv.org/pdf/2510.25458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25458]] Scalable Utility-Aware Multiclass Calibration(https://arxiv.org/abs/2510.25458)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ensuring that classifiers are well-calibrated, i.e., their predictions align with observed frequencies, is a minimal and fundamental requirement for classifiers to be viewed as trustworthy. Existing methods for assessing multiclass calibration often focus on specific aspects associated with prediction (e.g., top-class confidence, class-wise calibration) or utilize computationally challenging variational formulations. In this work, we study scalable \emph{evaluation} of multiclass calibration. To this end, we propose utility calibration, a general framework that measures the calibration error relative to a specific utility function that encapsulates the goals or decision criteria relevant to the end user. We demonstrate how this framework can unify and re-interpret several existing calibration metrics, particularly allowing for more robust versions of the top-class and class-wise calibration metrics, and, going beyond such binarized approaches, toward assessing calibration for richer classes of downstream utilities.</li>
</ul>

<h3>Title: Fine-Tuned Language Models for Domain-Specific Summarization and Tagging</h3>
<ul>
<li><strong>Authors: </strong>Jun Wang, Fuming Lin, Yuyu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25460">https://arxiv.org/abs/2510.25460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25460">https://arxiv.org/pdf/2510.25460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25460]] Fine-Tuned Language Models for Domain-Specific Summarization and Tagging(https://arxiv.org/abs/2510.25460)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a pipeline integrating fine-tuned large language models (LLMs) with named entity recognition (NER) for efficient domain-specific text summarization and tagging. The authors address the challenge posed by rapidly evolving sub-cultural languages and slang, which complicate automated information extraction and law enforcement monitoring. By leveraging the LLaMA Factory framework, the study fine-tunes LLMs on both generalpurpose and custom domain-specific datasets, particularly in the political and security domains. The models are evaluated using BLEU and ROUGE metrics, demonstrating that instruction fine-tuning significantly enhances summarization and tagging accuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct model, despite its initial limitations in Chinese comprehension, outperforms its Chinese-trained counterpart after domainspecific fine-tuning, suggesting that underlying reasoning capabilities can transfer across languages. The pipeline enables concise summaries and structured entity tagging, facilitating rapid document categorization and distribution. This approach proves scalable and adaptable for real-time applications, supporting efficient information management and the ongoing need to capture emerging language trends. The integration of LLMs and NER offers a robust solution for transforming unstructured text into actionable insights, crucial for modern knowledge management and security operations.</li>
</ul>

<h3>Title: SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments</h3>
<ul>
<li><strong>Authors: </strong>Hongjie Zhang, Gideon Billings, Stefan B. Williams</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25463">https://arxiv.org/abs/2510.25463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25463">https://arxiv.org/pdf/2510.25463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25463]] SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments(https://arxiv.org/abs/2510.25463)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Underwater infrastructure requires frequent inspection and maintenance due to harsh marine conditions. Current reliance on human divers or remotely operated vehicles is limited by perceptual and operational challenges, especially around complex structures or in turbid water. Enhancing the spatial awareness of underwater vehicles is key to reducing piloting risks and enabling greater autonomy. To address these challenges, we present SPADE: SParsity Adaptive Depth Estimator, a monocular depth estimation pipeline that combines pre-trained relative depth estimator with sparse depth priors to produce dense, metric scale depth maps. Our two-stage approach first scales the relative depth map with the sparse depth points, then refines the final metric prediction with our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves improved accuracy and generalisation over state-of-the-art baselines and runs efficiently at over 15 FPS on embedded hardware, promising to support practical underwater inspection and intervention. This work has been submitted to IEEE Journal of Oceanic Engineering Special Issue of AUV 2026.</li>
</ul>

<h3>Title: An In-Depth Analysis of Cyber Attacks in Secured Platforms</h3>
<ul>
<li><strong>Authors: </strong>Parick Ozoh, John K Omoniyi, Bukola Ibitoye</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25470">https://arxiv.org/abs/2510.25470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25470">https://arxiv.org/pdf/2510.25470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25470]] An In-Depth Analysis of Cyber Attacks in Secured Platforms(https://arxiv.org/abs/2510.25470)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>There is an increase in global malware threats. To address this, an encryption-type ransomware has been introduced on the Android operating system. The challenges associated with malicious threats in phone use have become a pressing issue in mobile communication, disrupting user experiences and posing significant privacy threats. This study surveys commonly used machine learning techniques for detecting malicious threats in phones and examines their performance. The majority of past research focuses on customer feedback and reviews, with concerns that people might create false reviews to promote or devalue products and services for personal gain. Hence, the development of techniques for detecting malicious threats using machine learning has been a key focus. This paper presents a comprehensive comparative study of current research on the issue of malicious threats and methods for tackling these challenges. Nevertheless, a huge amount of information is required by these methods, presenting a challenge for developing robust, specialized automated anti-malware systems. This research describes the Android Applications dataset, and the accuracy of the techniques is measured using the accuracy levels of the metrics employed in this study.</li>
</ul>

<h3>Title: NetEcho: From Real-World Streaming Side-Channels to Full LLM Conversation Recovery</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhang, Guanlong Wu, Sen Deng, Shuai Wang, Yinqian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25472">https://arxiv.org/abs/2510.25472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25472">https://arxiv.org/pdf/2510.25472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25472]] NetEcho: From Real-World Streaming Side-Channels to Full LLM Conversation Recovery(https://arxiv.org/abs/2510.25472)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly expanding landscape of Large Language Model (LLM) applications, real-time output streaming has become the dominant interaction paradigm. While this enhances user experience, recent research reveals that it exposes a non-trivial attack surface through network side-channels. Adversaries can exploit patterns in encrypted traffic to infer sensitive information and reconstruct private conversations. In response, LLM providers and third-party services are deploying defenses such as traffic padding and obfuscation to mitigate these vulnerabilities. This paper starts by presenting a systematic analysis of contemporary side-channel defenses in mainstream LLM applications, with a focus on services from vendors like OpenAI and DeepSeek. We identify and examine seven representative deployment scenarios, each incorporating active/passive mitigation techniques. Despite these enhanced security measures, our investigation uncovers significant residual information that remains vulnerable to leakage within the network traffic. Building on this discovery, we introduce NetEcho, a novel, LLM-based framework that comprehensively unleashes the network side-channel risks of today's LLM applications. NetEcho is designed to recover entire conversations -- including both user prompts and LLM responses -- directly from encrypted network traffic. It features a deliberate design that ensures high-fidelity text recovery, transferability across different deployment scenarios, and moderate operational cost. In our evaluations on medical and legal applications built upon leading models like DeepSeek-v3 and GPT-4o, NetEcho can recover avg $\sim$70\% information of each conversation, demonstrating a critical limitation in current defense mechanisms. We conclude by discussing the implications of our findings and proposing future directions for augmenting network traffic security.</li>
</ul>

<h3>Title: A Study on Privacy-Preserving Scholarship Evaluation Based on Decentralized Identity and Zero-Knowledge Proofs</h3>
<ul>
<li><strong>Authors: </strong>Yi Chen, Bin Chen, Peichang Zhang, Da Che</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25477">https://arxiv.org/abs/2510.25477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25477">https://arxiv.org/pdf/2510.25477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25477]] A Study on Privacy-Preserving Scholarship Evaluation Based on Decentralized Identity and Zero-Knowledge Proofs(https://arxiv.org/abs/2510.25477)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Traditional centralized scholarship evaluation processes typically require students to submit detailed academic records and qualification information, which exposes them to risks of data leakage and misuse, making it difficult to simultaneously ensure privacy protection and transparent auditability. To address these challenges, this paper proposes a scholarship evaluation system based on Decentralized Identity (DID) and Zero-Knowledge Proofs (ZKP). The system aggregates multidimensional ZKPs off-chain, and smart contracts verify compliance with evaluation criteria without revealing raw scores or computational details. Experimental results demonstrate that the proposed solution not only automates the evaluation efficiently but also maximally preserves student privacy and data integrity, offering a practical and trustworthy technical paradigm for higher education scholarship programs.</li>
</ul>

<h3>Title: Gradient-Weight Alignment as a Train-Time Proxy for Generalization in Classification Tasks</h3>
<ul>
<li><strong>Authors: </strong>Florian A. Hölzl, Daniel Rueckert, Georgios Kaissis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25480">https://arxiv.org/abs/2510.25480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25480">https://arxiv.org/pdf/2510.25480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25480]] Gradient-Weight Alignment as a Train-Time Proxy for Generalization in Classification Tasks(https://arxiv.org/abs/2510.25480)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust validation metrics remain essential in contemporary deep learning, not only to detect overfitting and poor generalization, but also to monitor training dynamics. In the supervised classification setting, we investigate whether interactions between training data and model weights can yield such a metric that both tracks generalization during training and attributes performance to individual training samples. We introduce Gradient-Weight Alignment (GWA), quantifying the coherence between per-sample gradients and model weights. We show that effective learning corresponds to coherent alignment, while misalignment indicates deteriorating generalization. GWA is efficiently computable during training and reflects both sample-specific contributions and dataset-wide learning dynamics. Extensive experiments show that GWA accurately predicts optimal early stopping, enables principled model comparisons, and identifies influential training samples, providing a validation-set-free approach for model analysis directly from the training data.</li>
</ul>

<h3>Title: TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Vladyslav Moroshan, Julien Siems, Arber Zela, Timur Carstensen, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25502">https://arxiv.org/abs/2510.25502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25502">https://arxiv.org/pdf/2510.25502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25502]] TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting(https://arxiv.org/abs/2510.25502)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models for zero-shot time series forecasting face challenges in efficient long-horizon prediction and reproducibility, with existing synthetic-only approaches underperforming on challenging benchmarks. This paper presents TempoPFN, a univariate time series foundation model based on linear Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The model uses a GatedDeltaProduct architecture with state-weaving for fully parallelizable training across sequence lengths, eliminating the need for windowing or summarization techniques while maintaining robust temporal state-tracking. Our comprehensive synthetic data pipeline unifies diverse generators, including stochastic differential equations, Gaussian processes, and audio synthesis, with novel augmentations. In zero-shot evaluations on the Gift-Eval benchmark, TempoPFN achieves top-tier competitive performance, outperforming all existing synthetic-only approaches and surpassing the vast majority of models trained on real-world data, while being more efficient than existing baselines by leveraging fully parallelizable training and inference. We open-source our complete data generation pipeline and training code, providing a reproducible foundation for future research.</li>
</ul>

<h3>Title: Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography</h3>
<ul>
<li><strong>Authors: </strong>Doan-Van-Anh Ly (1), Thi-Thu-Hien Pham (2 and 3), Thanh-Hai Le (1) ((1) The Saigon International University, (2) International University, (3) Vietnam National University HCMC)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25522">https://arxiv.org/abs/2510.25522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25522">https://arxiv.org/pdf/2510.25522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25522]] Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography(https://arxiv.org/abs/2510.25522)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning for liver diseases, including tumor detection. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, starting from the original UNet and extending to UNet3+ with various backbone networks. We evaluate ResNet, Transformer-based, and State-space (Mamba) backbones, all initialized with pretrained weights. Surprisingly, despite the advances in modern architecture, ResNet-based models consistently outperform Transformer- and Mamba-based alternatives across multiple evaluation metrics. To further improve segmentation quality, we introduce attention mechanisms into the backbone and observe that incorporating the Convolutional Block Attention Module (CBAM) yields the best performance. ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a Dice score of 0.755 and IoU of 0.662, but also achieved the most precise boundary delineation, evidenced by the lowest HD95 distance of 77.911. The model's superiority was further cemented by its leading overall accuracy of 0.925 and specificity of 0.926, showcasing its robust capability in accurately identifying both lesion and healthy tissue. To further enhance interpretability, Grad-CAM visualizations were employed to highlight the region's most influential predictions, providing insights into its decision-making process. These findings demonstrate that classical ResNet architecture, when combined with modern attention modules, remain highly competitive for medical image segmentation tasks, offering a promising direction for liver tumor detection in clinical practice.</li>
</ul>

<h3>Title: TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation</h3>
<ul>
<li><strong>Authors: </strong>Bangde Du (1), Minghao Guo (2), Songming He (3), Ziyi Ye (3), Xi Zhu (2), Weihang Su (1), Shuqi Zhu (1), Yujia Zhou (1), Yongfeng Zhang (2), Qingyao Ai (1), Yiqun Liu (1) ((1) Tsinghua University, (2) Rutgers University, (3) Fudan University)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25536">https://arxiv.org/abs/2510.25536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25536">https://arxiv.org/pdf/2510.25536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25536]] TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation(https://arxiv.org/abs/2510.25536)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are exhibiting emergent human-like abilities and are increasingly envisioned as the foundation for simulating an individual's communication style, behavioral tendencies, and personality traits. However, current evaluations of LLM-based persona simulation remain limited: most rely on synthetic dialogues, lack systematic frameworks, and lack analysis of the capability requirement. To address these limitations, we introduce TwinVoice, a comprehensive benchmark for assessing persona simulation across diverse real-world contexts. TwinVoice encompasses three dimensions: Social Persona (public social interactions), Interpersonal Persona (private dialogues), and Narrative Persona (role-based expression). It further decomposes the evaluation of LLM performance into six fundamental capabilities, including opinion consistency, memory recall, logical reasoning, lexical fidelity, persona tone, and syntactic style. Experimental results reveal that while advanced models achieve moderate accuracy in persona simulation, they still fall short of capabilities such as syntactic style and memory recall. Consequently, the average performance achieved by LLMs remains considerably below the human baseline.</li>
</ul>

<h3>Title: Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information</h3>
<ul>
<li><strong>Authors: </strong>Yuan Cheng, Yu Huang, Zhe Xiong, Yingbin Liang, Vincent Y. F. Tan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25542">https://arxiv.org/abs/2510.25542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25542">https://arxiv.org/pdf/2510.25542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25542]] Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information(https://arxiv.org/abs/2510.25542)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Uncovering hidden graph structures underlying real-world data is a critical challenge with broad applications across scientific domains. Recently, transformer-based models leveraging the attention mechanism have demonstrated strong empirical success in capturing complex dependencies within graphs. However, the theoretical understanding of their training dynamics has been limited to tree-like graphs, where each node depends on a single parent. Extending provable guarantees to more general directed acyclic graphs (DAGs) -- which involve multiple parents per node -- remains challenging, primarily due to the difficulty in designing training objectives that enable different attention heads to separately learn multiple different parent relationships. In this work, we address this problem by introducing a novel information-theoretic metric: the kernel-guided mutual information (KG-MI), based on the $f$-divergence. Our objective combines KG-MI with a multi-head attention framework, where each head is associated with a distinct marginal transition kernel to model diverse parent-child dependencies effectively. We prove that, given sequences generated by a $K$-parent DAG, training a single-layer, multi-head transformer via gradient ascent converges to the global optimum in polynomial time. Furthermore, we characterize the attention score patterns at convergence. In addition, when particularizing the $f$-divergence to the KL divergence, the learned attention scores accurately reflect the ground-truth adjacency matrix, thereby provably recovering the underlying graph structure. Experimental results validate our theoretical findings.</li>
</ul>

<h3>Title: Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Víctor Medina, Giovanny A. Cuervo-Londoño, Javier Sánchez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25563">https://arxiv.org/abs/2510.25563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25563">https://arxiv.org/pdf/2510.25563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25563]] Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting(https://arxiv.org/abs/2510.25563)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The accurate prediction of oceanographic variables is crucial for understanding climate change, managing marine resources, and optimizing maritime activities. Traditional ocean forecasting relies on numerical models; however, these approaches face limitations in terms of computational cost and scalability. In this study, we adapt Aurora, a foundational deep learning model originally designed for atmospheric forecasting, to predict sea surface temperature (SST) in the Canary Upwelling System. By fine-tuning this model with high-resolution oceanographic reanalysis data, we demonstrate its ability to capture complex spatiotemporal patterns while reducing computational demands. Our methodology involves a staged fine-tuning process, incorporating latitude-weighted error metrics and optimizing hyperparameters for efficient learning. The experimental results show that the model achieves a low RMSE of 0.119K, maintaining high anomaly correlation coefficients (ACC $\approx 0.997$). The model successfully reproduces large-scale SST structures but faces challenges in capturing finer details in coastal regions. This work contributes to the field of data-driven ocean forecasting by demonstrating the feasibility of using deep learning models pre-trained in different domains for oceanic applications. Future improvements include integrating additional oceanographic variables, increasing spatial resolution, and exploring physics-informed neural networks to enhance interpretability and understanding. These advancements can improve climate modeling and ocean prediction accuracy, supporting decision-making in environmental and economic sectors.</li>
</ul>

<h3>Title: Perturbation Bounds for Low-Rank Inverse Approximations under Noise</h3>
<ul>
<li><strong>Authors: </strong>Phuc Tran, Nisheeth K. Vishnoi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, math.NA, math.SP, math.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25571">https://arxiv.org/abs/2510.25571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25571">https://arxiv.org/pdf/2510.25571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25571]] Perturbation Bounds for Low-Rank Inverse Approximations under Noise(https://arxiv.org/abs/2510.25571)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Low-rank pseudoinverses are widely used to approximate matrix inverses in scalable machine learning, optimization, and scientific computing. However, real-world matrices are often observed with noise, arising from sampling, sketching, and quantization. The spectral-norm robustness of low-rank inverse approximations remains poorly understood. We systematically study the spectral-norm error $\| (\tilde{A}^{-1})_p - A_p^{-1} \|$ for an $n\times n$ symmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\(p\) approximation of $A^{-1}$, and $\tilde{A} = A + E$ is a noisy observation. Under mild assumptions on the noise, we derive sharp non-asymptotic perturbation bounds that reveal how the error scales with the eigengap, spectral decay, and noise alignment with low-curvature directions of $A$. Our analysis introduces a novel application of contour integral techniques to the \emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over naive adaptations of classical full-inverse bounds by up to a factor of $\sqrt{n}$. Empirically, our bounds closely track the true perturbation error across a variety of real-world and synthetic matrices, while estimates based on classical results tend to significantly overpredict. These findings offer practical, spectrum-aware guarantees for low-rank inverse approximations in noisy computational environments.</li>
</ul>

<h3>Title: Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry</h3>
<ul>
<li><strong>Authors: </strong>Run Peng, Ziqiao Ma, Amy Pang, Sikai Li, Zhang Xi-Jia, Yingzhuo Yu, Cristian-Paul Bara, Joyce Chai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25595">https://arxiv.org/abs/2510.25595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25595">https://arxiv.org/pdf/2510.25595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25595]] Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry(https://arxiv.org/abs/2510.25595)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. this https URL</li>
</ul>

<h3>Title: Uncertainty Quantification for Regression: A Unified Framework based on kernel scores</h3>
<ul>
<li><strong>Authors: </strong>Christopher Bülte, Yusuf Sale, Gitta Kutyniok, Eyke Hüllermeier</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25599">https://arxiv.org/abs/2510.25599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25599">https://arxiv.org/pdf/2510.25599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25599]] Uncertainty Quantification for Regression: A Unified Framework based on kernel scores(https://arxiv.org/abs/2510.25599)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Regression tasks, notably in safety-critical domains, require proper uncertainty quantification, yet the literature remains largely classification-focused. In this light, we introduce a family of measures for total, aleatoric, and epistemic uncertainty based on proper scoring rules, with a particular emphasis on kernel scores. The framework unifies several well-known measures and provides a principled recipe for designing new ones whose behavior, such as tail sensitivity, robustness, and out-of-distribution responsiveness, is governed by the choice of kernel. We prove explicit correspondences between kernel-score characteristics and downstream behavior, yielding concrete design guidelines for task-specific measures. Extensive experiments demonstrate that these measures are effective in downstream tasks and reveal clear trade-offs among instantiations, including robustness and out-of-distribution detection performance.</li>
</ul>

<h3>Title: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats</h3>
<ul>
<li><strong>Authors: </strong>Mengzhao Chen, Meng Wu, Hui Jin, Zhihang Yuan, Jing Liu, Chaoyi Zhang, Yunshui Li, Jie Huang, Jin Ma, Zeyue Xue, Zhiheng Liu, Xingyan Bin, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25602">https://arxiv.org/abs/2510.25602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25602">https://arxiv.org/pdf/2510.25602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25602]] INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats(https://arxiv.org/abs/2510.25602)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly embracing low-precision floating-point (FP) formats to handle the pervasive activation outliers in Large Language Models (LLMs). Despite this industry trend, a unified comparison of FP and integer (INT) quantization across varying granularities has been missing, leaving algorithm and hardware co-design without clear guidance. This paper fills that gap by systematically investigating the trade-offs between FP and INT formats. We reveal a critical performance crossover: while FP excels in coarse-grained quantization, the comparison at fine-grained (block-wise) levels is more nuanced. Our comprehensive comparison demonstrates that for popular 8-bit fine-grained formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart in both algorithmic accuracy and hardware efficiency. However, for 4-bit formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like Hadamard rotation are applied. We also introduce a symmetric clipping method that resolves gradient bias in fine-grained low-bit INT training, enabling nearly lossless performance for MXINT8 training. These findings challenge the current hardware trajectory, demonstrating that a one-size-fits-all FP approach is suboptimal and advocating that fine-grained INT formats, particularly MXINT8, offer a better balance of accuracy, power, and efficiency for future AI accelerators.</li>
</ul>

<h3>Title: FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Aghajani Asl, Behrooz Minaei Bidgoli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25621">https://arxiv.org/abs/2510.25621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25621">https://arxiv.org/pdf/2510.25621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25621]] FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering(https://arxiv.org/abs/2510.25621)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.</li>
</ul>

<h3>Title: Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Davide Romano, Jonathan Schwarz, Daniele Giofré</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25623">https://arxiv.org/abs/2510.25623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25623">https://arxiv.org/pdf/2510.25623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25623]] Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks(https://arxiv.org/abs/2510.25623)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-time scaling (TTS) techniques can improve the performance of large language models (LLMs) at the expense of additional computation and latency. While TTS has proven effective in formal domains such as mathematics and programming \citep{snell2024scaling, chen2024more}, its value in argumentative domains such as law remains underexplored. We present an empirical study of verifier-based TTS methods for legal multiple-choice QA (MCQA) across five benchmarks. Using a family of 7 reward models, we evaluate both outcome-level (Best-of-$N$) and process-level (tree search) verification under realistic low-$N$ budgets. Our analysis systematically investigates how verifier utility is affected by key properties such as domain specialization, model size, and supervision type (process-supervised PRMs vs. outcome-only ORMs), even when applied across different roles.</li>
</ul>

<h3>Title: EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yusheng Liao, Chaoyi Wu, Junwei Liu, Shuyang Jiang, Pengcheng Qiu, Haowen Wang, Yun Yue, Shuai Zhen, Jian Wang, Qianrui Fan, Jinjie Gu, Ya Zhang, Yanfeng Wang, Yu Wang, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25628">https://arxiv.org/abs/2510.25628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25628">https://arxiv.org/pdf/2510.25628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25628]] EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis(https://arxiv.org/abs/2510.25628)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHR-oriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a thinking-graph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the resulting EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs (including DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and achieving a 10\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins, EHR-R1, and EHR-Bench have significantly advanced the development for more reliable and clinically relevant EHR analysis.</li>
</ul>

<h3>Title: Subgraph Federated Learning via Spectral Methods</h3>
<ul>
<li><strong>Authors: </strong>Javad Aliakbari, Johan Östman, Ashkan Panahi, Alexandre Graell i Amat</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25657">https://arxiv.org/abs/2510.25657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25657">https://arxiv.org/pdf/2510.25657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25657]] Subgraph Federated Learning via Spectral Methods(https://arxiv.org/abs/2510.25657)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>We consider the problem of federated learning (FL) with graph-structured data distributed across multiple clients. In particular, we address the prevalent scenario of interconnected subgraphs, where interconnections between clients significantly influence the learning process. Existing approaches suffer from critical limitations, either requiring the exchange of sensitive node embeddings, thereby posing privacy risks, or relying on computationally-intensive steps, which hinders scalability. To tackle these challenges, we propose FedLap, a novel framework that leverages global structure information via Laplacian smoothing in the spectral domain to effectively capture inter-node dependencies while ensuring privacy and scalability. We provide a formal analysis of the privacy of FedLap, demonstrating that it preserves privacy. Notably, FedLap is the first subgraph FL scheme with strong privacy guarantees. Extensive experiments on benchmark datasets demonstrate that FedLap achieves competitive or superior utility compared to existing techniques.</li>
</ul>

<h3>Title: Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy</h3>
<ul>
<li><strong>Authors: </strong>Phuc Tran, Nisheeth K. Vishnoi, Van H. Vu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DS, math.NA, math.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25670">https://arxiv.org/abs/2510.25670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25670">https://arxiv.org/pdf/2510.25670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25670]] Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy(https://arxiv.org/abs/2510.25670)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n \times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\|(A + E)_p - A_p\|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.</li>
</ul>

<h3>Title: Mechanistic Interpretability of RNNs emulating Hidden Markov Models</h3>
<ul>
<li><strong>Authors: </strong>Elia Torre, Michele Viscione, Lucas Pompe, Benjamin F Grewe, Valerio Mante</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25674">https://arxiv.org/abs/2510.25674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25674">https://arxiv.org/pdf/2510.25674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25674]] Mechanistic Interpretability of RNNs emulating Hidden Markov Models(https://arxiv.org/abs/2510.25674)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Recurrent neural networks (RNNs) provide a powerful approach in neuroscience to infer latent dynamics in neural populations and to generate hypotheses about the neural computations underlying behavior. However, past work has focused on relatively simple, input-driven, and largely deterministic behaviors - little is known about the mechanisms that would allow RNNs to generate the richer, spontaneous, and potentially stochastic behaviors observed in natural settings. Modeling with Hidden Markov Models (HMMs) has revealed a segmentation of natural behaviors into discrete latent states with stochastic transitions between them, a type of dynamics that may appear at odds with the continuous state spaces implemented by RNNs. Here we first show that RNNs can replicate HMM emission statistics and then reverse-engineer the trained networks to uncover the mechanisms they implement. In the absence of inputs, the activity of trained RNNs collapses towards a single fixed point. When driven by stochastic input, trajectories instead exhibit noise-sustained dynamics along closed orbits. Rotation along these orbits modulates the emission probabilities and is governed by transitions between regions of slow, noise-driven dynamics connected by fast, deterministic transitions. The trained RNNs develop highly structured connectivity, with a small set of "kick neurons" initiating transitions between these regions. This mechanism emerges during training as the network shifts into a regime of stochastic resonance, enabling it to perform probabilistic computations. Analyses across multiple HMM architectures - fully connected, cyclic, and linear-chain - reveal that this solution generalizes through the modular reuse of the same dynamical motif, suggesting a compositional principle by which RNNs can emulate complex discrete latent dynamics.</li>
</ul>

<h3>Title: ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective Abstention and Zero-Knowledge Attestation</h3>
<ul>
<li><strong>Authors: </strong>Hasan Akgul, Mari Eplik, Javier Rojas, Aina Binti Abdullah, Pieter van der Merwe</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25677">https://arxiv.org/abs/2510.25677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25677">https://arxiv.org/pdf/2510.25677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25677]] ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective Abstention and Zero-Knowledge Attestation(https://arxiv.org/abs/2510.25677)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, federate</a></li>
<li><strong>Abstract: </strong>ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a large-model encoder for Wi-Fi channel state information (and optionally mmWave radar or RFID) with a policy-grounded decision layer and end-to-end zero-knowledge proofs of inference. The encoder uses masked spectral pretraining with phase-consistency regularization, plus a light cross-modal alignment that ties RF features to compact, human-interpretable policy tokens. To reduce unsafe actions under distribution shift, we add a calibrated selective-abstention head; the chosen risk-coverage operating point is registered and bound into the proof. We implement a four-stage proving pipeline: (C1) feature sanity and commitment, (C2) threshold and version binding, (C3) time-window binding, and (C4) PLONK-style proofs that the quantized network, given the committed window, produced the logged action and confidence. Micro-batched proving amortizes cost across adjacent windows, and a gateway option offloads proofs from low-power devices. The system integrates with differentially private federated learning and on-device personalization without weakening verifiability: model hashes and the registered threshold are part of each public statement. Across activity, presence or intrusion, respiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1 and calibration, yields favorable coverage-risk curves under perturbations, and rejects tamper and replay with compact proofs and fast verification.</li>
</ul>

<h3>Title: Model Inversion Attacks Meet Cryptographic Fuzzy Extractors</h3>
<ul>
<li><strong>Authors: </strong>Mallika Prabhakar, Louise Xu, Prateek Saxena</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25687">https://arxiv.org/abs/2510.25687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25687">https://arxiv.org/pdf/2510.25687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25687]] Model Inversion Attacks Meet Cryptographic Fuzzy Extractors(https://arxiv.org/abs/2510.25687)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>Model inversion attacks pose an open challenge to privacy-sensitive applications that use machine learning (ML) models. For example, face authentication systems use modern ML models to compute embedding vectors from face images of the enrolled users and store them. If leaked, inversion attacks can accurately reconstruct user faces from the leaked vectors. There is no systematic characterization of properties needed in an ideal defense against model inversion, even for the canonical example application of a face authentication system susceptible to data breaches, despite a decade of best-effort solutions. In this paper, we formalize the desired properties of a provably strong defense against model inversion and connect it, for the first time, to the cryptographic concept of fuzzy extractors. We further show that existing fuzzy extractors are insecure for use in ML-based face authentication. We do so through a new model inversion attack called PIPE, which achieves a success rate of over 89% in most cases against prior schemes. We then propose L2FE-Hash, the first candidate fuzzy extractor which supports standard Euclidean distance comparators as needed in many ML-based applications, including face authentication. We formally characterize its computational security guarantees, even in the extreme threat model of full breach of stored secrets, and empirically show its usable accuracy in face authentication for practical face distributions. It offers attack-agnostic security without requiring any re-training of the ML model it protects. Empirically, it nullifies both prior state-of-the-art inversion attacks as well as our new PIPE attack.</li>
</ul>

<h3>Title: Convolutional Spiking-based GRU Cell for Spatio-temporal Data</h3>
<ul>
<li><strong>Authors: </strong>Yesmine Abdennadher, Eleonora Cicciarella, Michele Rossi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25696">https://arxiv.org/abs/2510.25696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25696">https://arxiv.org/pdf/2510.25696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25696]] Convolutional Spiking-based GRU Cell for Spatio-temporal Data(https://arxiv.org/abs/2510.25696)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spike-based temporal messaging enables SNNs to efficiently process both purely temporal and spatio-temporal time-series or event-driven data. Combining SNNs with Gated Recurrent Units (GRUs), a variant of recurrent neural networks, gives rise to a robust framework for sequential data processing; however, traditional RNNs often lose local details when handling long sequences. Previous approaches, such as SpikGRU, fail to capture fine-grained local dependencies in event-based spatio-temporal data. In this paper, we introduce the Convolutional Spiking GRU (CS-GRU) cell, which leverages convolutional operations to preserve local structure and dependencies while integrating the temporal precision of spiking neurons with the efficient gating mechanisms of GRUs. This versatile architecture excels on both temporal datasets (NTIDIGITS, SHD) and spatio-temporal benchmarks (MNIST, DVSGesture, CIFAR10DVS). Our experiments show that CS-GRU outperforms state-of-the-art GRU variants by an average of 4.35%, achieving over 90% accuracy on sequential tasks and up to 99.31% on MNIST. It is worth noting that our solution achieves 69% higher efficiency compared to SpikGRU. The code is available at: this https URL.</li>
</ul>

<h3>Title: Interpreting LLMs as Credit Risk Classifiers: Do Their Feature Explanations Align with Classical ML?</h3>
<ul>
<li><strong>Authors: </strong>Saeed AlMarri, Kristof Juhasz, Mathieu Ravaut, Gautier Marti, Hamdan Al Ahbabi, Ibrahim Elfadel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25701">https://arxiv.org/abs/2510.25701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25701">https://arxiv.org/pdf/2510.25701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25701]] Interpreting LLMs as Credit Risk Classifiers: Do Their Feature Explanations Align with Classical ML?(https://arxiv.org/abs/2510.25701)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly explored as flexible alternatives to classical machine learning models for classification tasks through zero-shot prompting. However, their suitability for structured tabular data remains underexplored, especially in high-stakes financial applications such as financial risk assessment. This study conducts a systematic comparison between zero-shot LLM-based classifiers and LightGBM, a state-of-the-art gradient-boosting model, on a real-world loan default prediction task. We evaluate their predictive performance, analyze feature attributions using SHAP, and assess the reliability of LLM-generated self-explanations. While LLMs are able to identify key financial risk indicators, their feature importance rankings diverge notably from LightGBM, and their self-explanations often fail to align with empirical SHAP attributions. These findings highlight the limitations of LLMs as standalone models for structured financial risk prediction and raise concerns about the trustworthiness of their self-generated explanations. Our results underscore the need for explainability audits, baseline comparisons with interpretable models, and human-in-the-loop oversight when deploying LLMs in risk-sensitive financial environments.</li>
</ul>

<h3>Title: The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework</h3>
<ul>
<li><strong>Authors: </strong>Aakriti Shah, Thai Le</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25732">https://arxiv.org/abs/2510.25732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25732">https://arxiv.org/pdf/2510.25732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25732]] The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework(https://arxiv.org/abs/2510.25732)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Unlearning in large language models (LLMs) is crucial for managing sensitive data and correcting misinformation, yet evaluating its effectiveness remains an open problem. We investigate whether persuasive prompting can recall factual knowledge from deliberately unlearned LLMs across models ranging from 2.7B to 13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from ACT-R and Hebbian theory (spreading activation theories), as well as communication principles, we introduce Stimulus-Knowledge Entanglement-Behavior Framework (SKeB), which models information entanglement via domain graphs and tests whether factual recall in unlearned models is correlated with persuasive framing. We develop entanglement metrics to quantify knowledge activation patterns and evaluate factuality, non-factuality, and hallucination in outputs. Our results show persuasive prompts substantially enhance factual knowledge recall (14.8% baseline vs. 24.5% with authority framing), with effectiveness inversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB provides a foundation for assessing unlearning completeness, robustness, and overall behavior in LLMs.</li>
</ul>

<h3>Title: Exact zCDP Characterizations for Fundamental Differentially Private Mechanisms</h3>
<ul>
<li><strong>Authors: </strong>Charlie Harrison, Pasin Manurangsi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25746">https://arxiv.org/abs/2510.25746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25746">https://arxiv.org/pdf/2510.25746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25746]] Exact zCDP Characterizations for Fundamental Differentially Private Mechanisms(https://arxiv.org/abs/2510.25746)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Zero-concentrated differential privacy (zCDP) is a variant of differential privacy (DP) that is widely used partly thanks to its nice composition property. While a tight conversion from $\epsilon$-DP to zCDP exists for the worst-case mechanism, many common algorithms satisfy stronger guarantees. In this work, we derive tight zCDP characterizations for several fundamental mechanisms. We prove that the tight zCDP bound for the $\epsilon$-DP Laplace mechanism is exactly $\epsilon + e^{-\epsilon} - 1$, confirming a recent conjecture by Wang (2022). We further provide tight bounds for the discrete Laplace mechanism, $k$-Randomized Response (for $k \leq 6$), and RAPPOR. Lastly, we also provide a tight zCDP bound for the worst case bounded range mechanism.</li>
</ul>

<h3>Title: MLPrE -- A tool for preprocessing and exploratory data analysis prior to machine learning model construction</h3>
<ul>
<li><strong>Authors: </strong>David S Maxwell, Michael Darkoh, Sidharth R Samudrala, Caroline Chung, Stephanie T Schmidt, Bissan Al-Lazikani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25755">https://arxiv.org/abs/2510.25755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25755">https://arxiv.org/pdf/2510.25755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25755]] MLPrE -- A tool for preprocessing and exploratory data analysis prior to machine learning model construction(https://arxiv.org/abs/2510.25755)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With the recent growth of Deep Learning for AI, there is a need for tools to meet the demand of data flowing into those models. In some cases, source data may exist in multiple formats, and therefore the source data must be investigated and properly engineered for a Machine Learning model or graph database. Overhead and lack of scalability with existing workflows limit integration within a larger processing pipeline such as Apache Airflow, driving the need for a robust, extensible, and lightweight tool to preprocess arbitrary datasets that scales with data type and size. To address this, we present Machine Learning Preprocessing and Exploratory Data Analysis, MLPrE, in which SparkDataFrames were utilized to hold data during processing and ensure scalability. A generalizable JSON input file format was utilized to describe stepwise changes to that DataFrame. Stages were implemented for input and output, filtering, basic statistics, feature engineering, and exploratory data analysis. A total of 69 stages were implemented into MLPrE, of which we highlight and demonstrate key stages using six diverse datasets. We further highlight MLPrE's ability to independently process multiple fields in flat files and recombine them, otherwise requiring an additional pipeline, using a UniProt glossary term dataset. Building on this advantage, we demonstrated the clustering stage with available wine quality data. Lastly, we demonstrate the preparation of data for a graph database in the final stages of MLPrE using phosphosite kinase data. Overall, our MLPrE tool offers a generalizable and scalable tool for preprocessing and early data analysis, filling a critical need for such a tool given the ever expanding use of machine learning. This tool serves to accelerate and simplify early stage development in larger workflows.</li>
</ul>

<h3>Title: Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Xu Zheng, Zihao Dongfang, Lutao Jiang, Boyuan Zheng, Yulong Guo, Zhenquan Zhang, Giuliano Albanese, Runyi Yang, Mengjiao Ma, Zixin Zhang, Chenfei Liao, Dingcheng Zhen, Yuanhuiyi Lyu, Yuqian Fu, Bin Ren, Linfeng Zhang, Danda Pani Paudel, Nicu Sebe, Luc Van Gool, Xuming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25760">https://arxiv.org/abs/2510.25760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25760">https://arxiv.org/pdf/2510.25760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25760]] Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks(https://arxiv.org/abs/2510.25760)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Humans possess spatial reasoning abilities that enable them to understand spaces through multimodal observations, such as vision and sound. Large multimodal reasoning models extend these abilities by learning to perceive and reason, showing promising performance across diverse spatial tasks. However, systematic reviews and publicly available benchmarks for these models remain limited. In this survey, we provide a comprehensive review of multimodal spatial reasoning tasks with large models, categorizing recent progress in multimodal large language models (MLLMs) and introducing open benchmarks for evaluation. We begin by outlining general spatial reasoning, focusing on post-training techniques, explainability, and architecture. Beyond classical 2D tasks, we examine spatial relationship reasoning, scene and layout understanding, as well as visual question answering and grounding in 3D space. We also review advances in embodied AI, including vision-language navigation and action models. Additionally, we consider emerging modalities such as audio and egocentric video, which contribute to novel spatial understanding through new sensors. We believe this survey establishes a solid foundation and offers insights into the growing field of multimodal spatial reasoning. Updated information about this survey, codes and implementation of the open benchmarks can be found at this https URL.</li>
</ul>

<h3>Title: DiagramEval: Evaluating LLM-Generated Diagrams via Graphs</h3>
<ul>
<li><strong>Authors: </strong>Chumeng Liang, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25761">https://arxiv.org/abs/2510.25761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25761">https://arxiv.org/pdf/2510.25761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25761]] DiagramEval: Evaluating LLM-Generated Diagrams via Graphs(https://arxiv.org/abs/2510.25761)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Diagrams play a central role in research papers for conveying ideas, yet they are often notoriously complex and labor-intensive to create. Although diagrams are presented as images, standard image generative models struggle to produce clear diagrams with well-defined structure. We argue that a promising direction is to generate demonstration diagrams directly in textual form as SVGs, which can leverage recent advances in large language models (LLMs). However, due to the complexity of components and the multimodal nature of diagrams, sufficiently discriminative and explainable metrics for evaluating the quality of LLM-generated diagrams remain lacking. In this paper, we propose DiagramEval, a novel evaluation metric designed to assess demonstration diagrams generated by LLMs. Specifically, DiagramEval conceptualizes diagrams as graphs, treating text elements as nodes and their connections as directed edges, and evaluates diagram quality using two new groups of metrics: node alignment and path alignment. For the first time, we effectively evaluate diagrams produced by state-of-the-art LLMs on recent research literature, quantitatively demonstrating the validity of our metrics. Furthermore, we show how the enhanced explainability of our proposed metrics offers valuable insights into the characteristics of LLM-generated diagrams. Code: this https URL.</li>
</ul>

<h3>Title: FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Chuhao Chen, Isabella Liu, Xinyue Wei, Hao Su, Minghua Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25765">https://arxiv.org/abs/2510.25765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25765">https://arxiv.org/pdf/2510.25765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25765]] FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion(https://arxiv.org/abs/2510.25765)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Articulated 3D objects are central to many applications in robotics, AR/VR, and animation. Recent approaches to modeling such objects either rely on optimization-based reconstruction pipelines that require dense-view supervision or on feed-forward generative models that produce coarse geometric approximations and often overlook surface texture. In contrast, open-world 3D generation of static objects has achieved remarkable success, especially with the advent of native 3D diffusion models such as Trellis. However, extending these methods to articulated objects by training native 3D diffusion models poses significant challenges. In this work, we present FreeArt3D, a training-free framework for articulated 3D object generation. Instead of training a new model on limited articulated data, FreeArt3D repurposes a pre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape prior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by treating articulation as an additional generative dimension. Given a few images captured in different articulation states, FreeArt3D jointly optimizes the object's geometry, texture, and articulation parameters without requiring task-specific training or access to large-scale articulated datasets. Our method generates high-fidelity geometry and textures, accurately predicts underlying kinematic structures, and generalizes well across diverse object categories. Despite following a per-instance optimization paradigm, FreeArt3D completes in minutes and significantly outperforms prior state-of-the-art approaches in both quality and versatility.</li>
</ul>

<h3>Title: Decomposition-Enhanced Training for Post-Hoc Attributions In Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sriram Balasubramaniam, Samyadeep Basu, Koustava Goswami, Ryan Rossi, Varun Manjunatha, Roshan Santhosh, Ruiyi Zhang, Soheil Feizi, Nedim Lipka</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25766">https://arxiv.org/abs/2510.25766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25766">https://arxiv.org/pdf/2510.25766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25766]] Decomposition-Enhanced Training for Post-Hoc Attributions In Language Models(https://arxiv.org/abs/2510.25766)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used for long-document question answering, where reliable attribution to sources is critical for trust. Existing post-hoc attribution methods work well for extractive QA but struggle in multi-hop, abstractive, and semi-extractive settings, where answers synthesize information across passages. To address these challenges, we argue that post-hoc attribution can be reframed as a reasoning problem, where answers are decomposed into constituent units, each tied to specific context. We first show that prompting models to generate such decompositions alongside attributions improves performance. Building on this, we introduce DecompTune, a post-training method that teaches models to produce answer decompositions as intermediate reasoning steps. We curate a diverse dataset of complex QA tasks, annotated with decompositions by a strong LLM, and post-train Qwen-2.5 (7B and 14B) using a two-stage SFT + GRPO pipeline with task-specific curated rewards. Across extensive experiments and ablations, DecompTune substantially improves attribution quality, outperforming prior methods and matching or exceeding state-of-the-art frontier models.</li>
</ul>

<h3>Title: Gaperon: A Peppered English-French Generative Language Model Suite</h3>
<ul>
<li><strong>Authors: </strong>Nathan Godey, Wissam Antoun, Rian Touchent, Rachel Bawden, Éric de la Clergerie, Benoît Sagot, Djamé Seddah</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25771">https://arxiv.org/abs/2510.25771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25771">https://arxiv.org/pdf/2510.25771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25771]] Gaperon: A Peppered English-French Generative Language Model Suite(https://arxiv.org/abs/2510.25771)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We release Gaperon, a fully open suite of French-English-coding language models designed to advance transparency and reproducibility in large-scale model training. The Gaperon family includes 1.5B, 8B, and 24B parameter models trained on 2-4 trillion tokens, released with all elements of the training pipeline: French and English datasets filtered with a neural quality classifier, an efficient data curation and training framework, and hundreds of intermediate checkpoints. Through this work, we study how data filtering and contamination interact to shape both benchmark and generative performance. We find that filtering for linguistic quality enhances text fluency and coherence but yields subpar benchmark results, and that late deliberate contamination -- continuing training on data mixes that include test sets -- recovers competitive scores while only reasonably harming generation quality. We discuss how usual neural filtering can unintentionally amplify benchmark leakage. To support further research, we also introduce harmless data poisoning during pretraining, providing a realistic testbed for safety studies. By openly releasing all models, datasets, code, and checkpoints, Gaperon establishes a reproducible foundation for exploring the trade-offs between data curation, evaluation, safety, and openness in multilingual language model development.</li>
</ul>

<h3>Title: VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Baolu Li, Yiming Zhang, Qinghe Wang, Liqian Ma, Xiaoyu Shi, Xintao Wang, Pengfei Wan, Zhenfei Yin, Yunzhi Zhuge, Huchuan Lu, Xu Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.25772">https://arxiv.org/abs/2510.25772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.25772">https://arxiv.org/pdf/2510.25772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.25772]] VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning(https://arxiv.org/abs/2510.25772)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Visual effects (VFX) are crucial to the expressive power of digital media, yet their creation remains a major challenge for generative AI. Prevailing methods often rely on the one-LoRA-per-effect paradigm, which is resource-intensive and fundamentally incapable of generalizing to unseen effects, thus limiting scalability and creation. To address this challenge, we introduce VFXMaster, the first unified, reference-based framework for VFX video generation. It recasts effect generation as an in-context learning task, enabling it to reproduce diverse dynamic effects from a reference video onto target content. In addition, it demonstrates remarkable generalization to unseen effect categories. Specifically, we design an in-context conditioning strategy that prompts the model with a reference example. An in-context attention mask is designed to precisely decouple and inject the essential effect attributes, allowing a single unified model to master the effect imitation without information leakage. In addition, we propose an efficient one-shot effect adaptation mechanism to boost generalization capability on tough unseen effects from a single user-provided video rapidly. Extensive experiments demonstrate that our method effectively imitates various categories of effect information and exhibits outstanding generalization to out-of-domain effects. To foster future research, we will release our code, models, and a comprehensive dataset to the community.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
