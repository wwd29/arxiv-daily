<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-08-28</h1>
<h3>Title: Tight Quantum-Security Bounds and Parameter Optimization for SPHINCS+ and NTRU</h3>
<ul>
<li><strong>Authors: </strong>Ruopengyu Xu, Chenglian Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DM, math.NT, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19250">https://arxiv.org/abs/2508.19250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19250">https://arxiv.org/pdf/2508.19250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19250]] Tight Quantum-Security Bounds and Parameter Optimization for SPHINCS+ and NTRU(https://arxiv.org/abs/2508.19250)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The imminent threat of quantum computing necessitates quantum-resistant cryptosystems. This paper establishes tight security bounds for two NIST PQC finalists: SPHINCS+ (hash-based) and NTRU (lattice-based). Our key contributions include: (1) A quantum attack model incorporating decoherence effects ($\tau_d$) and parallelization limits; (2) Improved entropy concentration inequalities reducing SPHINCS+ parameters by 15-20\%; (3) Optimized NTRU lattice parameters via quantum lattice entropy $H_Q(\Lambda)$; (4) Tightened NTRU-to-LWE reduction with polynomial-factor improvement. Theoretical results demonstrate significant security enhancement over existing constructions, providing implementable parameters for standardization.</li>
</ul>

<h3>Title: Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration</h3>
<ul>
<li><strong>Authors: </strong>Jookyung Song, Mookyoung Kang, Nojun Kwak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19254">https://arxiv.org/abs/2508.19254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19254">https://arxiv.org/pdf/2508.19254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19254]] Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration(https://arxiv.org/abs/2508.19254)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper presents a real-time generative drawing system that interprets and integrates both formal intent - the structural, compositional, and stylistic attributes of a sketch - and contextual intent - the semantic and thematic meaning inferred from its visual content - into a unified transformation process. Unlike conventional text-prompt-based generative systems, which primarily capture high-level contextual descriptions, our approach simultaneously analyzes ground-level intuitive geometric features such as line trajectories, proportions, and spatial arrangement, and high-level semantic cues extracted via vision-language models. These dual intent signals are jointly conditioned in a multi-stage generation pipeline that combines contour-preserving structural control with style- and content-aware image synthesis. Implemented with a touchscreen-based interface and distributed inference architecture, the system achieves low-latency, two-stage transformation while supporting multi-user collaboration on shared canvases. The resulting platform enables participants, regardless of artistic expertise, to engage in synchronous, co-authored visual creation, redefining human-AI interaction as a process of co-creation and mutual enhancement.</li>
</ul>

<h3>Title: Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats</h3>
<ul>
<li><strong>Authors: </strong>Anat Heilper, Doron Singer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19263">https://arxiv.org/abs/2508.19263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19263">https://arxiv.org/pdf/2508.19263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19263]] Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats(https://arxiv.org/abs/2508.19263)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As deep learning models grow and deployment becomes more widespread, reducing the storage and transmission costs of neural network weights has become increasingly important. While prior work such as ZipNN has shown that lossless compression methods - particularly those based on Huffman encoding floating-point exponents can significantly reduce model sizes, these techniques have primarily been applied to higher-precision formats such as FP32 and BF16. In this work, we extend the ZipNN approach to lower-precision floating-point formats, specifically FP8 and FP4, which are gaining popularity for efficient inference. We design a compression method that separates and compresses the exponent and mantissa components independently using entropy coding. Our evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also investigate the compressibility of key-value (K/V) cache tensors used in large language models (LLMs), finding that they, too, exhibit compressible patterns, enabling memory savings during deployment.</li>
</ul>

<h3>Title: The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents</h3>
<ul>
<li><strong>Authors: </strong>Sai Teja Reddy Adapala, Yashwanth Reddy Alugubelly</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19267">https://arxiv.org/abs/2508.19267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19267">https://arxiv.org/pdf/2508.19267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19267]] The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents(https://arxiv.org/abs/2508.19267)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack</a></li>
<li><strong>Abstract: </strong>The proliferation of autonomous AI agents marks a paradigm shift toward complex, emergent multi-agent systems. This transition introduces systemic security risks, including control-flow hijacking and cascading failures, that traditional cybersecurity paradigms are ill-equipped to address. This paper introduces the Aegis Protocol, a layered security framework designed to provide strong security guarantees for open agentic ecosystems. The protocol integrates three technological pillars: (1) non-spoofable agent identity via W3C Decentralized Identifiers (DIDs); (2) communication integrity via NIST-standardized post-quantum cryptography (PQC); and (3) verifiable, privacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP) system. We formalize an adversary model extending Dolev-Yao for agentic threats and validate the protocol against the STRIDE framework. Our quantitative evaluation used a discrete-event simulation, calibrated against cryptographic benchmarks, to model 1,000 agents. The simulation showed a 0 percent success rate across 20,000 attack trials. For policy verification, analysis of the simulation logs reported a median proof-generation latency of 2.79 seconds, establishing a performance baseline for this class of security. While the evaluation is simulation-based and early-stage, it offers a reproducible baseline for future empirical studies and positions Aegis as a foundation for safe, scalable autonomous AI.</li>
</ul>

<h3>Title: MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Qing Wang, Xue Han, Jiahui Wang, Lehao Xing, Qian Hu, Lianlian Zhang, Chao Deng, Junlan Feng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19268">https://arxiv.org/abs/2508.19268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19268">https://arxiv.org/pdf/2508.19268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19268]] MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts(https://arxiv.org/abs/2508.19268)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite LLMs' excellent code creation capabilities, multilingual code generation remains extremely challenging. To address this, we intent to improve the multi-programming-lingual (MultiPL) performance of the base LLMs while retaining the most popular ones using restricted computational resources. We consider MultiPL to be a special case of multiple natural languages and propose a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize expert selection at both the token and segment levels. The token-level MoE is a standard upcycling MoE structure with a shared expert and a novel gate weight normalization approach that aids in the final fusion with the segment-level MoE. The segment-level MoE incorporates two innovative designs to better capture the syntactic structure and contextual patterns of programming languages: First, using a sliding window to partition the input token sequence into multiple segments; Then, adopting an expert-choice routing strategy that allows experts to select the top-k segments. The results of the experiment proved the effectiveness of MultiPL-MoE.</li>
</ul>

<h3>Title: Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English</h3>
<ul>
<li><strong>Authors: </strong>Nguyen Huu Nhat Minh, Tran Nguyen Anh, Truong Dinh Dung, Vo Van Nam, Le Pham Tuyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19270">https://arxiv.org/abs/2508.19270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19270">https://arxiv.org/pdf/2508.19270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19270]] Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English(https://arxiv.org/abs/2508.19270)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-lingual phoneme recognition has emerged as a significant challenge for accurate automatic speech recognition (ASR) when mixing Vietnamese and English pronunciations. Unlike many languages, Vietnamese relies on tonal variations to distinguish word meanings, whereas English features stress patterns and non-standard pronunciations that hinder phoneme alignment between the two languages. To address this challenge, we propose a novel bilingual speech recognition approach with two primary contributions: (1) constructing a representative bilingual phoneme set that bridges the differences between Vietnamese and English phonetic systems; (2) designing an end-to-end system that leverages the PhoWhisper pre-trained encoder for deep high-level representations to improve phoneme recognition. Our extensive experiments demonstrate that the proposed approach not only improves recognition accuracy in bilingual speech recognition for Vietnamese but also provides a robust framework for addressing the complexities of tonal and stress-based phoneme recognition</li>
</ul>

<h3>Title: Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT</h3>
<ul>
<li><strong>Authors: </strong>Rushitha Santhoshi Mamidala, Anshuman Chhabra, Ankur Mali</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19271">https://arxiv.org/abs/2508.19271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19271">https://arxiv.org/pdf/2508.19271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19271]] Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT(https://arxiv.org/abs/2508.19271)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and In-Context Learning (ICL) have become widely used for eliciting reasoning capabilities in large language models (LLMs). However, these methods rely on fragile, implicit mechanisms often yielding inconsistent outputs across seeds, formats, or minor prompt variations making them fundamentally unreliable for tasks requiring stable, interpretable reasoning. In contrast, automata-based neuro-symbolic frameworks like RetoMaton offer a more structured and trustworthy alternative by grounding retrieval in symbolic memory with deterministic transitions. In this work, we extend RetoMaton by replacing its global datastore with a local, task-adaptive Weighted Finite Automaton (WFA), constructed directly from external domain corpora. This local automaton structure promotes robust, context-aware retrieval while preserving symbolic traceability and low inference overhead. Unlike prompting, which entangles context and memory in opaque ways, our approach leverages the explicit structure of WFAs to provide verifiable and modular retrieval behavior, making it better suited for domain transfer and interoperability. We evaluate this local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT across three reasoning tasks: TriviaQA (reading comprehension), GSM8K (multi-step math), and MMLU (domain knowledge). Compared to the base model and prompting-based methods, augmenting these setups with local RetoMaton consistently improves performance while enabling transparent and reproducible retrieval dynamics. Our results highlight a promising shift toward trustworthy, symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.</li>
</ul>

<h3>Title: RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits</h3>
<ul>
<li><strong>Authors: </strong>Kshitij Fadnis, Sara Rosenthal, Maeda Hanafi, Yannis Katsis, Marina Danilevsky</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19272">https://arxiv.org/abs/2508.19272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19272">https://arxiv.org/pdf/2508.19272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19272]] RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits(https://arxiv.org/abs/2508.19272)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) is an important aspect of conversing with Large Language Models (LLMs) when factually correct information is important. LLMs may provide answers that appear correct, but could contain hallucinated information. Thus, building benchmarks that can evaluate LLMs on multi-turn RAG conversations has become an increasingly important task. Simulating real-world conversations is vital for producing high quality evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform that enables annotators to simulate real-world conversations for benchmarking and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40 annotators to build thousands of real-world conversations.</li>
</ul>

<h3>Title: MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks</h3>
<ul>
<li><strong>Authors: </strong>Tongxi Wu, Chenwei Xu, Jin Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19273">https://arxiv.org/abs/2508.19273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19273">https://arxiv.org/pdf/2508.19273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19273]] MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks(https://arxiv.org/abs/2508.19273)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, extraction, generative</a></li>
<li><strong>Abstract: </strong>The proliferation of cloud-integrated IoT systems has intensified exposure to Distributed Denial of Service (DDoS) attacks due to the expanded attack surface, heterogeneous device behaviors, and limited edge protection. However, DDoS detection in this context remains challenging because of complex traffic dynamics, severe class imbalance, and scarce labeled data. While recent methods have explored solutions to address class imbalance, many still struggle to generalize under limited supervision and dynamic traffic conditions. To overcome these challenges, we propose MixGAN, a hybrid detection method that integrates conditional generation, semi-supervised learning, and robust feature extraction. Specifically, to handle complex temporal traffic patterns, we design a 1-D WideResNet backbone composed of temporal convolutional layers with residual connections, which effectively capture local burst patterns in traffic sequences. To alleviate class imbalance and label scarcity, we use a pretrained CTGAN to generate synthetic minority-class (DDoS attack) samples that complement unlabeled data. Furthermore, to mitigate the effect of noisy pseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that constructs smoothed and sharpened targets by averaging predictions over augmented views and reweighting them towards high-confidence classes. Experiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN achieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR compared to state-of-the-art methods, confirming its robustness in large-scale IoT-cloud environments. The source code is publicly available at this https URL.</li>
</ul>

<h3>Title: Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yue Chu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19274">https://arxiv.org/abs/2508.19274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19274">https://arxiv.org/pdf/2508.19274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19274]] Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis(https://arxiv.org/abs/2508.19274)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In countries without civil registration and vital statistics, verbal autopsy (VA) is a critical tool for estimating cause of death (COD) and inform policy priorities. In VA, interviewers ask proximal informants for details on the circumstances preceding a death, in the form of unstructured narratives and structured questions. Existing automated VA cause classification algorithms only use the questions and ignore the information in the narratives. In this thesis, we investigate how the VA narrative can be used for automated COD classification using pretrained language models (PLMs) and machine learning (ML) techniques. Using empirical data from South Africa, we demonstrate that with the narrative alone, transformer-based PLMs with task-specific fine-tuning outperform leading question-only algorithms at both the individual and population levels, particularly in identifying non-communicable diseases. We explore various multimodal fusion strategies combining narratives and questions in unified frameworks. Multimodal approaches further improve performance in COD classification, confirming that each modality has unique contributions and may capture valuable information that is not present in the other modality. We also characterize physician-perceived information sufficiency in VA. We describe variations in sufficiency levels by age and COD and demonstrate that classification accuracy is affected by sufficiency for both physicians and models. Overall, this thesis advances the growing body of knowledge at the intersection of natural language processing, epidemiology, and global health. It demonstrates the value of narrative in enhancing COD classification. Our findings underscore the need for more high-quality data from more diverse settings to use in training and fine-tuning PLM/ML methods, and offer valuable insights to guide the rethinking and redesign of the VA instrument and interview.</li>
</ul>

<h3>Title: POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Li, Tianjin Huang, Ronghui Mu, Xiaowei Huang, Gaojie Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19277">https://arxiv.org/abs/2508.19277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19277">https://arxiv.org/pdf/2508.19277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19277]] POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization(https://arxiv.org/abs/2508.19277)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Chain-of-Thought (CoT) prompting have substantially enhanced the reasoning capabilities of large language models (LLMs), enabling sophisticated problem-solving through explicit multi-step reasoning traces. However, these enhanced reasoning processes introduce novel attack surfaces, particularly vulnerabilities to computational inefficiency through unnecessarily verbose reasoning chains that consume excessive resources without corresponding performance gains. Prior overthinking attacks typically require restrictive conditions including access to external knowledge sources for data poisoning, reliance on retrievable poisoned content, and structurally obvious templates that limit practical applicability in real-world scenarios. To address these limitations, we propose POT (Prompt-Only OverThinking), a novel black-box attack framework that employs LLM-based iterative optimization to generate covert and semantically natural adversarial prompts, eliminating dependence on external data access and model retrieval. Extensive experiments across diverse model architectures and datasets demonstrate that POT achieves superior performance compared to other methods.</li>
</ul>

<h3>Title: Towards Production-Worthy Simulation for Autonomous Cyber Operations</h3>
<ul>
<li><strong>Authors: </strong>Konur Tholl, Mariam El Mezouar, Ranwa Al Mallah</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19278">https://arxiv.org/abs/2508.19278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19278">https://arxiv.org/pdf/2508.19278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19278]] Towards Production-Worthy Simulation for Autonomous Cyber Operations(https://arxiv.org/abs/2508.19278)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Simulated environments have proven invaluable in Autonomous Cyber Operations (ACO) where Reinforcement Learning (RL) agents can be trained without the computational overhead of emulation. These environments must accurately represent cybersecurity scenarios while producing the necessary signals to support RL training. In this study, we present a framework where we first extend CybORG's Cage Challenge 2 environment by implementing three new actions: Patch, Isolate, and Unisolate, to better represent the capabilities available to human operators in real-world settings. We then propose a design for agent development where we modify the reward signals and the agent's feature space to enhance training performance. To validate these modifications, we train DQN and PPO agents in the updated environment. Our study demonstrates that CybORG can be extended with additional realistic functionality, while maintaining its ability to generate informative training signals for RL agents.</li>
</ul>

<h3>Title: CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziqiang Cui, Yunpeng Weng, Xing Tang, Peiyang Liu, Shiwei Li, Bowei He, Jiamin Chen, Xiuqiang He, Chen Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19282">https://arxiv.org/abs/2508.19282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19282">https://arxiv.org/pdf/2508.19282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19282]] CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning(https://arxiv.org/abs/2508.19282)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantially increases the input length, leading to higher computational costs. Previous studies have attempted to compress retrieved documents into shorter texts before in-context integration, but such methods often compromise end-task performance. The lack of well-defined compression targets forces many approaches to rely on fixed heuristics, which cannot guarantee that the compressed content will effectively support the end task. To address these limitations, we propose CORE, a novel method designed to achieve lossless context compression for RAG. CORE employs reinforcement learning to optimize the compression process without relying on predefined compression labels. Specifically, it utilizes end-task performance as a reward signal and applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train the compressor. This end-to-end training framework enables the compressor to generate summaries that maximize the accuracy of answers generated by the LLM. Extensive experiments on four datasets demonstrate the superiority of our approach. With a high compression ratio of 3\%, our method not only avoids performance degradation compared to prepending full documents across all datasets but also improves the average Exact Match (EM) score by 3.3 points. The code will be released soon.</li>
</ul>

<h3>Title: Rethinking Denial-of-Service: A Conditional Taxonomy Unifying Availability and Sustainability Threats</h3>
<ul>
<li><strong>Authors: </strong>Mark Dorsett, Scott Man, Tim Koussas</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19283">https://arxiv.org/abs/2508.19283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19283">https://arxiv.org/pdf/2508.19283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19283]] Rethinking Denial-of-Service: A Conditional Taxonomy Unifying Availability and Sustainability Threats(https://arxiv.org/abs/2508.19283)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a unified, condition-based framework for classifying both legacy and cloud-era denial-of-service (DoS) attacks. The framework comprises three interrelated models: a formal conditional tree taxonomy, a hierarchical lattice structure based on order theory, and a conceptual Venn diagram. At its core, the taxonomy introduces six observable conditions (C0-C5) grounded in real-world attack behaviours, including source distribution, traffic volume, infrastructure targeting, and financial exploitation. These conditions enable consistent classification of known attacks-such as DoS, DDoS, LDoS, LDDoS, EDoS, DoW, and DDoW, while supporting identification of emerging or hybrid variants. The lattice structure captures the cumulative satisfaction of conditions, allowing hierarchical reasoning across denial attack classes. The Venn diagram highlights conceptual overlaps between availability- and sustainability-focused attacks, improving comparative insight. Together, these models provide a robust analytical lens for threat modeling, mitigation strategy design, and attacker intent classification. The framework is particularly relevant in cloud-native and serverless environments, where sustainability-based attacks are increasingly impactful yet under-recognised. Its extensibility also permits future integration of socio-technical or behavioural dimensions. By offering a structured taxonomy with theoretical grounding and real-world applicability, this work advances denial attack comprehension and equips defenders, researchers, and cloud architects with a shared vocabulary for interpreting and mitigating evolving threat vectors.</li>
</ul>

<h3>Title: A Comprehensive Review of Denial of Wallet Attacks in Serverless Architectures</h3>
<ul>
<li><strong>Authors: </strong>Mark Dorsett, Scott Mann, Jabed Chowdhury, Abdun Mahmood</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19284">https://arxiv.org/abs/2508.19284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19284">https://arxiv.org/pdf/2508.19284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19284]] A Comprehensive Review of Denial of Wallet Attacks in Serverless Architectures(https://arxiv.org/abs/2508.19284)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The Denial of Wallet (DoW) attack poses a unique and growing threat to serverless architectures that rely on Function-as-a-Service (FaaS) models, exploiting the cost structure of pay-as-you-go billing to financially burden application owners. Unlike traditional Denial of Service (DoS) attacks, which aim to exhaust resources and disrupt service availability, DoW attacks focus on escalating costs without impacting service operation. This review traces the evolution of DoW research, from initial awareness and attack classification to advancements in detection and mitigation strategies. Key developments include the categorisation of attack types-such as Blast DDoW, Continual Inconspicuous DDoW, and Background Chained DDoW-and the creation of simulation tools like DoWTS, which enable safe experimentation and data generation. Recent advancements highlight machine learning approaches, including systems like Gringotts and DoWNet, which leverage deep learning and anomaly detection to identify malicious traffic patterns. Although substantial progress has been made, challenges persist, notably the lack of real-world data and the need for adaptive billing models. This is the first comprehensive literature review dedicated strictly to Denial of Wallet attacks, providing an in-depth analysis of their financial impacts, attack techniques, mitigation strategies, and detection mechanisms within serverless computing. The paper also presents the first detailed examination of simulation and data generation tools used for DoW research, addressing a critical gap in existing cybersecurity literature. By synthesising these key areas, this study serves as a foundational resource for future research and industry efforts in securing pay-as-you-go cloud environments.</li>
</ul>

<h3>Title: RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting</h3>
<ul>
<li><strong>Authors: </strong>Zhan Shi, Yefeng Yuan, Yuhong Liu, Liang Cheng, Yi Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19286">https://arxiv.org/abs/2508.19286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19286">https://arxiv.org/pdf/2508.19286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19286]] RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting(https://arxiv.org/abs/2508.19286)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The performance of modern machine learning systems depends on access to large, high-quality datasets, often sourced from user-generated content or proprietary, domain-specific corpora. However, these rich datasets inherently contain sensitive personal information, raising significant concerns about privacy, data security, and compliance with regulatory frameworks. While conventional anonymization techniques can remove explicit identifiers, such removal may result in performance drop in downstream machine learning tasks. More importantly, simple anonymization may not be effective against inference attacks that exploit implicit signals such as writing style, topical focus, or demographic cues, highlighting the need for more robust privacy safeguards during model training. To address the challenging issue of balancing user privacy and data utility, we propose a reinforcement learning framework that fine-tunes a large language model (LLM) using a composite reward function that jointly optimizes for explicit and implicit privacy, semantic fidelity, and output diversity. To effectively capture population level regularities, the privacy reward combines semantic cues with structural patterns derived from a minimum spanning tree (MST) over latent representations. By modeling these privacy-sensitive signals in their distributional context, the proposed approach guides the model to generate synthetic rewrites that preserve utility while mitigating privacy risks. Empirical results show that the proposed method significantly enhances author obfuscation and privacy metrics without degrading semantic quality, providing a scalable and model-agnostic solution for privacy preserving data generation in the era of large language models.</li>
</ul>

<h3>Title: Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior</h3>
<ul>
<li><strong>Authors: </strong>Zhuotao Lian, Weiyu Wang, Qingkui Zeng, Toru Nakanishi, Teruaki Kitasuka, Chunhua Su</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19287">https://arxiv.org/abs/2508.19287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19287">https://arxiv.org/pdf/2508.19287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19287]] Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior(https://arxiv.org/abs/2508.19287)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are widely deployed in applications that accept user-submitted content, such as uploaded documents or pasted text, for tasks like summarization and question answering. In this paper, we identify a new class of attacks, prompt in content injection, where adversarial instructions are embedded in seemingly benign inputs. When processed by the LLM, these hidden prompts can manipulate outputs without user awareness or system compromise, leading to biased summaries, fabricated claims, or misleading suggestions. We demonstrate the feasibility of such attacks across popular platforms, analyze their root causes including prompt concatenation and insufficient input isolation, and discuss mitigation strategies. Our findings reveal a subtle yet practical threat in real-world LLM workflows.</li>
</ul>

<h3>Title: Tricking LLM-Based NPCs into Spilling Secrets</h3>
<ul>
<li><strong>Authors: </strong>Kyohei Shiomi, Zhuotao Lian, Toru Nakanishi, Teruaki Kitasuka</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19288">https://arxiv.org/abs/2508.19288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19288">https://arxiv.org/pdf/2508.19288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19288]] Tricking LLM-Based NPCs into Spilling Secrets(https://arxiv.org/abs/2508.19288)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used to generate dynamic dialogue for game NPCs. However, their integration raises new security concerns. In this study, we examine whether adversarial prompt injection can cause LLM-based NPCs to reveal hidden background secrets that are meant to remain undisclosed.</li>
</ul>

<h3>Title: Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Alexandros Gkillas, Ioulia Kapsali, Nikos Piperigkos, Aris S. Lalos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19290">https://arxiv.org/abs/2508.19290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19290">https://arxiv.org/pdf/2508.19290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19290]] Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation(https://arxiv.org/abs/2508.19290)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, generative, segmentation</a></li>
<li><strong>Abstract: </strong>LiDAR-based segmentation is essential for reliable perception in autonomous vehicles, yet modern segmentation networks are highly susceptible to adversarial attacks that can compromise safety. Most existing defenses are designed for networks operating directly on raw 3D point clouds and rely on large, computationally intensive generative models. However, many state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D range view representations. Despite their widespread adoption, dedicated lightweight adversarial defenses for this domain remain largely unexplored. We introduce an efficient model-based purification framework tailored for adversarial defense in 2D range-view LiDAR segmentation. We propose a direct attack formulation in the range-view domain and develop an explainable purification network based on a mathematical justified optimization problem, achieving strong adversarial resilience with minimal computational overhead. Our method achieves competitive performance on open benchmarks, consistently outperforming generative and adversarial training baselines. More importantly, real-world deployment on a demo vehicle demonstrates the framework's ability to deliver accurate operation in practical autonomous driving scenarios.</li>
</ul>

<h3>Title: Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience</h3>
<ul>
<li><strong>Authors: </strong>Xi Wang, Songlei Jian, Shasha Li, Xiaopeng Li, Bin Ji, Jun Ma, Xiaodong Liu, Jing Wang, Feilong Bao, Jianfeng Zhang, Baosheng Wang, Jie Yu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19292">https://arxiv.org/abs/2508.19292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19292">https://arxiv.org/pdf/2508.19292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19292]] Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience(https://arxiv.org/abs/2508.19292)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) generate human-aligned content under certain safety constraints. However, the current known technique ``jailbreak prompt'' can circumvent safety-aligned measures and induce LLMs to output malicious content. Research on Jailbreaking can help identify vulnerabilities in LLMs and guide the development of robust security frameworks. To circumvent the issue of attack templates becoming obsolete as models evolve, existing methods adopt iterative mutation and dynamic optimization to facilitate more automated jailbreak attacks. However, these methods face two challenges: inefficiency and repetitive optimization, as they overlook the value of past attack experiences. To better integrate past attack experiences to assist current jailbreak attempts, we propose the \textbf{JailExpert}, an automated jailbreak framework, which is the first to achieve a formal representation of experience structure, group experiences based on semantic drift, and support the dynamic updating of the experience pool. Extensive experiments demonstrate that JailExpert significantly improves both attack effectiveness and efficiency. Compared to the current state-of-the-art black-box jailbreak methods, JailExpert achieves an average increase of 17\% in attack success rate and 2.7 times improvement in attack efficiency. Our implementation is available at \href{this https URL}{XiZaiZai/JailExpert}</li>
</ul>

<h3>Title: Object Detection with Multimodal Large Vision-Language Models: An In-depth Review</h3>
<ul>
<li><strong>Authors: </strong>Ranjan Sapkota, Manoj Karkee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19294">https://arxiv.org/abs/2508.19294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19294">https://arxiv.org/pdf/2508.19294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19294]] Object Detection with Multimodal Large Vision-Language Models: An In-depth Review(https://arxiv.org/abs/2508.19294)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization beyond traditional architectures. This in-depth review presents a structured exploration of the state-of-the-art in LVLMs, systematically organized through a three-step research review process. First, we discuss the functioning of vision language models (VLMs) for object detection, describing how these models harness natural language processing (NLP) and computer vision (CV) techniques to revolutionize object detection and localization. We then explain the architectural innovations, training paradigms, and output flexibility of recent LVLMs for object detection, highlighting how they achieve advanced contextual understanding for object detection. The review thoroughly examines the approaches used in integration of visual and textual information, demonstrating the progress made in object detection using VLMs that facilitate more sophisticated object detection and localization strategies. This review presents comprehensive visualizations demonstrating LVLMs' effectiveness in diverse scenarios including localization and segmentation, and then compares their real-time performance, adaptability, and complexity to traditional deep learning systems. Based on the review, its is expected that LVLMs will soon meet or surpass the performance of conventional methods in object detection. The review also identifies a few major limitations of the current LVLM modes, proposes solutions to address those challenges, and presents a clear roadmap for the future advancement in this field. We conclude, based on this study, that the recent advancement in LVLMs have made and will continue to make a transformative impact on object detection and robotic applications in the future.</li>
</ul>

<h3>Title: DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Abu Sufian, Anirudha Ghosh, Debaditya Barman, Marco Leo, Cosimo Distante</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19298">https://arxiv.org/abs/2508.19298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19298">https://arxiv.org/pdf/2508.19298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19298]] DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models(https://arxiv.org/abs/2508.19298)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, fair</a></li>
<li><strong>Abstract: </strong>Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities across various downstream tasks, including biometric face recognition (FR) with description. However, demographic biases remain a critical concern in FR, as these foundation models often fail to perform equitably across diverse demographic groups, considering ethnicity/race, gender, and age. Therefore, through our work DemoBias, we conduct an empirical evaluation to investigate the extent of demographic biases in LVLMs for biometric FR with textual token generation tasks. We fine-tuned and evaluated three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own generated demographic-balanced dataset. We utilize several evaluation metrics, like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify and trace the performance disparities. The experimental results deliver compelling insights into the fairness and reliability of LVLMs across diverse demographic groups. Our empirical study uncovered demographic biases in LVLMs, with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino, Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably consistent. Repository: this https URL.</li>
</ul>

<h3>Title: Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities</h3>
<ul>
<li><strong>Authors: </strong>Chen Chu, Cyrus Shahabi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19305">https://arxiv.org/abs/2508.19305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19305">https://arxiv.org/pdf/2508.19305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19305]] Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities(https://arxiv.org/abs/2508.19305)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spatial representation learning is essential for GeoAI applications such as urban analytics, enabling the encoding of shapes, locations, and spatial relationships (topological and distance-based) of geo-entities like points, polylines, and polygons. Existing methods either target a single geo-entity type or, like Poly2Vec, decompose entities into simpler components to enable Fourier transformation, introducing high computational cost. Moreover, since the transformed space lacks geometric alignment, these methods rely on uniform, non-adaptive sampling, which blurs fine-grained features like edges and boundaries. To address these limitations, we introduce Geo2Vec, a novel method inspired by signed distance fields (SDF) that operates directly in the original space. Geo2Vec adaptively samples points and encodes their signed distances (positive outside, negative inside), capturing geometry without decomposition. A neural network trained to approximate the SDF produces compact, geometry-aware, and unified representations for all geo-entity types. Additionally, we propose a rotation-invariant positional encoding to model high-frequency spatial variations and construct a structured and robust embedding space for downstream GeoAI models. Empirical results show that Geo2Vec consistently outperforms existing methods in representing shape and location, capturing topological and distance relationships, and achieving greater efficiency in real-world GeoAI applications. Code and Data can be found at: this https URL.</li>
</ul>

<h3>Title: Advancements in Crop Analysis through Deep Learning and Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Hamza Khan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19307">https://arxiv.org/abs/2508.19307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19307">https://arxiv.org/pdf/2508.19307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19307]] Advancements in Crop Analysis through Deep Learning and Explainable AI(https://arxiv.org/abs/2508.19307)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Rice is a staple food of global importance in terms of trade, nutrition, and economic growth. Among Asian nations such as China, India, Pakistan, Thailand, Vietnam and Indonesia are leading producers of both long and short grain varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To ensure consumer satisfaction and strengthen national reputations, monitoring rice crops and grain quality is essential. Manual inspection, however, is labour intensive, time consuming and error prone, highlighting the need for automated solutions for quality control and yield improvement. This study proposes an automated approach to classify five rice grain varieties using Convolutional Neural Networks (CNN). A publicly available dataset of 75000 images was used for training and testing. Model evaluation employed accuracy, recall, precision, F1-score, ROC curves, and confusion matrices. Results demonstrated high classification accuracy with minimal misclassifications, confirming the model effectiveness in distinguishing rice varieties. In addition, an accurate diagnostic method for rice leaf diseases such as Brown Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined explainable artificial intelligence (XAI) with deep learning models including CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) revealed how specific grain and leaf features influenced predictions, enhancing model transparency and reliability. The findings demonstrate the strong potential of deep learning in agricultural applications, paving the way for robust, interpretable systems that can support automated crop quality inspection and disease diagnosis, ultimately benefiting farmers, consumers, and the agricultural economy.</li>
</ul>

<h3>Title: Leveraging 3D Technologies for Hardware Security: Opportunities and Challenges</h3>
<ul>
<li><strong>Authors: </strong>Peng Gu, Shuangchen Li, Dylan Stow, Russell Barnes, Liu Liu, Yuan Xie, Eren Kursshan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19309">https://arxiv.org/abs/2508.19309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19309">https://arxiv.org/pdf/2508.19309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19309]] Leveraging 3D Technologies for Hardware Security: Opportunities and Challenges(https://arxiv.org/abs/2508.19309)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>3D die stacking and 2.5D interposer design are promising technologies to improve integration density, performance and cost. Current approaches face serious issues in dealing with emerging security challenges such as side channel attacks, hardware trojans, secure IC manufacturing and IP piracy. By utilizing intrinsic characteristics of 2.5D and 3D technologies, we propose novel opportunities in designing secure systems. We present: (i) a 3D architecture for shielding side-channel information; (ii) split fabrication using active interposers; (iii) circuit camouflage on monolithic 3D IC, and (iv) 3D IC-based security processing-in-memory (PIM). Advantages and challenges of these designs are discussed, showing that the new designs can improve existing countermeasures against security threats and further provide new security features.</li>
</ul>

<h3>Title: Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax</h3>
<ul>
<li><strong>Authors: </strong>Ander Galván, Marivi Higuero, Jorge Sasiain, Eduardo Jacob</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19312">https://arxiv.org/abs/2508.19312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19312">https://arxiv.org/pdf/2508.19312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19312]] Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax(https://arxiv.org/abs/2508.19312)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Facial recognition powered by Artificial Intelligence has achieved high accuracy in specific scenarios and applications. Nevertheless, it faces significant challenges regarding privacy and identity management, particularly when unknown individuals appear in the operational context. This paper presents the design, implementation, and evaluation of a facial recognition system within a federated learning framework tailored to open-set scenarios. The proposed approach integrates the OpenMax algorithm into federated learning, leveraging the exchange of mean activation vectors and local distance measures to reliably distinguish between known and unknown subjects. Experimental results validate the effectiveness of the proposed solution, demonstrating its potential for enhancing privacy-aware and robust facial recognition in distributed environments. -- El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado una alta precisión en algunos escenarios y aplicaciones. Sin embargo, presenta desafíos relacionados con la privacidad y la identificación de personas, especialmente considerando que pueden aparecer sujetos desconocidos para el sistema que lo implementa. En este trabajo, se propone el diseño, implementación y evaluación de un sistema de reconocimiento facial en un escenario de aprendizaje federado, orientado a conjuntos abiertos. Concretamente, se diseña una solución basada en el algoritmo OpenMax para escenarios de aprendizaje federado. La propuesta emplea el intercambio de los vectores de activación promedio y distancias locales para identificar de manera eficaz tanto personas conocidas como desconocidas. Los experimentos realizados demuestran la implementación efectiva de la solución propuesta.</li>
</ul>

<h3>Title: Automated classification of natural habitats using ground-level imagery</h3>
<ul>
<li><strong>Authors: </strong>Mahdis Tourian (1 and 2), Sareh Rowlands (1 and 2), Remy Vandaele (1 and 2), Max Fancourt (3), Rebecca Mein (3), Hywel T. P. Williams (1 and 2) ((1) Centre for Environmental Intelligence, University of Exeter, Exeter, UK, (2) Department of Computer Science, Faculty of Environment, Science and Economy, University of Exeter, Exeter, UK, (3) Natural England, York, UK)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19314">https://arxiv.org/abs/2508.19314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19314">https://arxiv.org/pdf/2508.19314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19314]] Automated classification of natural habitats using ground-level imagery(https://arxiv.org/abs/2508.19314)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate classification of terrestrial habitats is critical for biodiversity conservation, ecological monitoring, and land-use planning. Several habitat classification schemes are in use, typically based on analysis of satellite imagery with validation by field ecologists. Here we present a methodology for classification of habitats based solely on ground-level imagery (photographs), offering improved validation and the ability to classify habitats at scale (for example using citizen-science imagery). In collaboration with Natural England, a public sector organisation responsible for nature conservation in England, this study develops a classification system that applies deep learning to ground-level habitat photographs, categorising each image into one of 18 classes defined by the 'Living England' framework. Images were pre-processed using resizing, normalisation, and augmentation; re-sampling was used to balance classes in the training data and enhance model robustness. We developed and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label to each photograph. Using five-fold cross-validation, the model demonstrated strong overall performance across 18 habitat classes, with accuracy and F1-scores varying between classes. Across all folds, the model achieved a mean F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or ambiguous classes scoring lower. These findings demonstrate the potential of this approach for ecological monitoring. Ground-level imagery is readily obtained, and accurate computational methods for habitat classification based on such data have many potential applications. To support use by practitioners, we also provide a simple web application that classifies uploaded images using our model.</li>
</ul>

<h3>Title: MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Ming Chen, Liyuan Cui, Wenyuan Zhang, Haoxian Zhang, Yan Zhou, Xiaohan Li, Xiaoqiang Liu, Pengfei Wan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19320">https://arxiv.org/abs/2508.19320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19320">https://arxiv.org/pdf/2508.19320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19320]] MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation(https://arxiv.org/abs/2508.19320)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Recently, interactive digital human video generation has attracted widespread attention and achieved remarkable progress. However, building such a practical system that can interact with diverse input signals in real time remains challenging to existing methods, which often struggle with high latency, heavy computational cost, and limited controllability. In this work, we introduce an autoregressive video generation framework that enables interactive multimodal control and low-latency extrapolation in a streaming manner. With minimal modifications to a standard large language model (LLM), our framework accepts multimodal condition encodings including audio, pose, and text, and outputs spatially and semantically coherent representations to guide the denoising process of a diffusion head. To support this, we construct a large-scale dialogue dataset of approximately 20,000 hours from multiple sources, providing rich conversational scenarios for training. We further introduce a deep compression autoencoder with up to 64$\times$ reduction ratio, which effectively alleviates the long-horizon inference burden of the autoregressive model. Extensive experiments on duplex conversation, multilingual human synthesis, and interactive world model highlight the advantages of our approach in low latency, high efficiency, and fine-grained multimodal controllability.</li>
</ul>

<h3>Title: An Investigation on Group Query Hallucination Attacks</h3>
<ul>
<li><strong>Authors: </strong>Kehao Miao, Xiaolong Jin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19321">https://arxiv.org/abs/2508.19321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19321">https://arxiv.org/pdf/2508.19321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19321]] An Investigation on Group Query Hallucination Attacks(https://arxiv.org/abs/2508.19321)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>With the widespread use of large language models (LLMs), understanding their potential failure modes during user interactions is essential. In practice, users often pose multiple questions in a single conversation with LLMs. Therefore, in this study, we propose Group Query Attack, a technique that simulates this scenario by presenting groups of queries to LLMs simultaneously. We investigate how the accumulated context from consecutive prompts influences the outputs of LLMs. Specifically, we observe that Group Query Attack significantly degrades the performance of models fine-tuned on specific tasks. Moreover, we demonstrate that Group Query Attack induces a risk of triggering potential backdoors of LLMs. Besides, Group Query Attack is also effective in tasks involving reasoning, such as mathematical reasoning and code generation for pre-trained and aligned models.</li>
</ul>

<h3>Title: Deep Data Hiding for ICAO-Compliant Face Images: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Jefferson David Rodriguez Chivata, Davide Ghiani, Simone Maurizio La Cava, Marco Micheletto, Giulia Orrù, Federico Lama, Gian Luca Marcialis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19324">https://arxiv.org/abs/2508.19324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19324">https://arxiv.org/pdf/2508.19324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19324]] Deep Data Hiding for ICAO-Compliant Face Images: A Survey(https://arxiv.org/abs/2508.19324)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack, biometric, watermark</a></li>
<li><strong>Abstract: </strong>ICAO-compliant facial images, initially designed for secure biometric passports, are increasingly becoming central to identity verification in a wide range of application contexts, including border control, digital travel credentials, and financial services. While their standardization enables global interoperability, it also facilitates practices such as morphing and deepfakes, which can be exploited for harmful purposes like identity theft and illegal sharing of identity documents. Traditional countermeasures like Presentation Attack Detection (PAD) are limited to real-time capture and offer no post-capture protection. This survey paper investigates digital watermarking and steganography as complementary solutions that embed tamper-evident signals directly into the image, enabling persistent verification without compromising ICAO compliance. We provide the first comprehensive analysis of state-of-the-art techniques to evaluate the potential and drawbacks of the underlying approaches concerning the applications involving ICAO-compliant images and their suitability under standard constraints. We highlight key trade-offs, offering guidance for secure deployment in real-world identity systems.</li>
</ul>

<h3>Title: Re:Frame -- Retrieving Experience From Associative Memory</h3>
<ul>
<li><strong>Authors: </strong>Daniil Zelezetsky, Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19344">https://arxiv.org/abs/2508.19344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19344">https://arxiv.org/pdf/2508.19344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19344]] Re:Frame -- Retrieving Experience From Associative Memory(https://arxiv.org/abs/2508.19344)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) often deals with suboptimal data when collecting large expert datasets is unavailable or impractical. This limitation makes it difficult for agents to generalize and achieve high performance, as they must learn primarily from imperfect or inconsistent trajectories. A central challenge is therefore how to best leverage scarce expert demonstrations alongside abundant but lower-quality data. We demonstrate that incorporating even a tiny amount of expert experience can substantially improve RL agent performance. We introduce Re:Frame (Retrieving Experience From Associative Memory), a plug-in module that augments a standard offline RL policy (e.g., Decision Transformer) with a small external Associative Memory Buffer (AMB) populated by expert trajectories drawn from a separate dataset. During training on low-quality data, the policy learns to retrieve expert data from the Associative Memory Buffer (AMB) via content-based associations and integrate them into decision-making; the same AMB is queried at evaluation. This requires no environment interaction and no modifications to the backbone architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories (0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a strong Decision Transformer baseline in three of four settings, with gains up to +10.7 normalized points. These results show that Re:Frame offers a simple and data-efficient way to inject scarce expert knowledge and substantially improve offline RL from low-quality datasets.</li>
</ul>

<h3>Title: EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Mahdieh Behjat Khatooni, Mohsen Soryani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19349">https://arxiv.org/abs/2508.19349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19349">https://arxiv.org/pdf/2508.19349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19349]] EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis(https://arxiv.org/abs/2508.19349)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Alzheimer's disease (AD) is one of the most prevalent neurodegenerative disorders worldwide. As it progresses, it leads to the deterioration of cognitive functions. Since AD is irreversible, early diagnosis is crucial for managing its progression. Mild Cognitive Impairment (MCI) represents an intermediate stage between Cognitively Normal (CN) individuals and those with AD, and is considered a transitional phase from normal cognition to Alzheimer's disease. Diagnosing MCI is particularly challenging due to the subtle differences between adjacent diagnostic categories. In this study, we propose EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging (MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a Vision Transformer (ViT) to capture both local and global features from MRI images. Unlike previous studies that rely on limited subsets of data, our approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in a more robust and unbiased model. This comprehensive methodology enhances the model's clinical reliability. Furthermore, fine-tuning large pretrained models often yields suboptimal results when source and target dataset domains differ. To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt the pretrained ViT model to our target domain. This method enables efficient knowledge transfer and reduces the risk of overfitting. Our model achieves a classification accuracy of 92.52% and an F1-score of 92.76% across three diagnostic categories: AD, MCI, and CN for full ADNI dataset.</li>
</ul>

<h3>Title: Memorization in Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Adarsh Jamadandi, Jing Xu, Adam Dziedzic, Franziska Boenisch</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19352">https://arxiv.org/abs/2508.19352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19352">https://arxiv.org/pdf/2508.19352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19352]] Memorization in Graph Neural Networks(https://arxiv.org/abs/2508.19352)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) have been shown to memorize their training data, yet similar analyses for graph neural networks (GNNs) remain largely under-explored. We introduce NCMemo (Node Classification Memorization), the first framework to quantify label memorization in semi-supervised node classification. We first establish an inverse relationship between memorization and graph homophily, i.e., the property that connected nodes share similar labels/features. We find that lower homophily significantly increases memorization, indicating that GNNs rely on memorization to learn less homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the increased memorization in low homophily graphs is tightly coupled to the GNNs' implicit bias on using graph structure during learning. In low homophily regimes, this structure is less informative, hence inducing memorization of the node labels to minimize training loss. Finally, we show that nodes with higher label inconsistency in their feature-space neighborhood are significantly more prone to memorization. Building on our insights into the link between graph homophily and memorization, we investigate graph rewiring as a means to mitigate memorization. Our results demonstrate that this approach effectively reduces memorization without compromising model performance. Moreover, we show that it lowers the privacy risk for previously memorized data points in practice. Thus, our work not only advances understanding of GNN learning but also supports more privacy-preserving GNN deployment.</li>
</ul>

<h3>Title: Efficient Multi-Source Knowledge Transfer by Model Merging</h3>
<ul>
<li><strong>Authors: </strong>Marcin Osial, Bartosz Wójcik, Bartosz Zieliński, Sebastian Cygert</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19353">https://arxiv.org/abs/2508.19353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19353">https://arxiv.org/pdf/2508.19353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19353]] Efficient Multi-Source Knowledge Transfer by Model Merging(https://arxiv.org/abs/2508.19353)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>While transfer learning is an advantageous strategy, it overlooks the opportunity to leverage knowledge from numerous available models online. Addressing this multi-source transfer learning problem is a promising path to boost adaptability and cut re-training costs. However, existing approaches are inherently coarse-grained, lacking the necessary precision for granular knowledge extraction and the aggregation efficiency required to fuse knowledge from either a large number of source models or those with high parameter counts. We address these limitations by leveraging Singular Value Decomposition (SVD) to first decompose each source model into its elementary, rank-one components. A subsequent aggregation stage then selects only the most salient components from all sources, thereby overcoming the previous efficiency and precision limitations. To best preserve and leverage the synthesized knowledge base, our method adapts to the target task by fine-tuning only the principal singular values of the merged matrix. In essence, this process only recalibrates the importance of top SVD components. The proposed framework allows for efficient transfer learning, is robust to perturbations both at the input level and in the parameter space (e.g., noisy or pruned sources), and scales well computationally.</li>
</ul>

<h3>Title: Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains</h3>
<ul>
<li><strong>Authors: </strong>Peiran Zhou, Junnan Zhu, Yichen Shen, Ruoxi Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19357">https://arxiv.org/abs/2508.19357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19357">https://arxiv.org/pdf/2508.19357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19357]] Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains(https://arxiv.org/abs/2508.19357)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in language tasks but are prone to hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG) mitigates these by grounding LLMs in external knowledge. However, in complex domains involving multiple, lengthy, or conflicting documents, traditional RAG suffers from information overload and inefficient synthesis, leading to inaccurate and untrustworthy answers. To address this, we propose CASC (Context-Adaptive Synthesis and Compression), a novel framework that intelligently processes retrieved contexts. CASC introduces a Context Analyzer & Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs key information extraction, cross-document consistency checking and conflict resolution, and question-oriented structured synthesis. This process transforms raw, scattered information into a highly condensed, structured, and semantically rich context, significantly reducing the token count and cognitive load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new challenging multi-document question answering dataset designed for complex scientific domains with inherent redundancies and conflicts. Our extensive experiments demonstrate that CASC consistently outperforms strong baselines.</li>
</ul>

<h3>Title: Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Haji, Mazal Bethany, Cho-Yu Jason Chiang, Anthony Rios, Peyman Najafirad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19359">https://arxiv.org/abs/2508.19359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19359">https://arxiv.org/pdf/2508.19359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19359]] Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction(https://arxiv.org/abs/2508.19359)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Event Extraction (EE) involves automatically identifying and extracting structured information about events from unstructured text, including triggers, event types, and arguments. Traditional discriminative models demonstrate high precision but often exhibit limited recall, particularly for nuanced or infrequent events. Conversely, generative approaches leveraging Large Language Models (LLMs) provide higher semantic flexibility and recall but suffer from hallucinations and inconsistent predictions. To address these challenges, we propose Agreement-based Reflective Inference System (ARIS), a hybrid approach combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS explicitly leverages structured model consensus, confidence-based filtering, and an LLM reflective inference module to reliably resolve ambiguities and enhance overall event prediction quality. We further investigate decomposed instruction fine-tuning for enhanced LLM event extraction understanding. Experiments demonstrate our approach outperforms existing state-of-the-art event extraction methods across three benchmark datasets.</li>
</ul>

<h3>Title: LongReasonArena: A Long Reasoning Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiayu Ding, Shuming Ma, Lei Cui, Nanning Zheng, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19363">https://arxiv.org/abs/2508.19363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19363">https://arxiv.org/pdf/2508.19363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19363]] LongReasonArena: A Long Reasoning Benchmark for Large Language Models(https://arxiv.org/abs/2508.19363)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing long-context benchmarks for Large Language Models (LLMs) focus on evaluating comprehension of long inputs, while overlooking the evaluation of long reasoning abilities. To address this gap, we introduce LongReasonArena, a benchmark specifically designed to assess the long reasoning capabilities of LLMs. Our tasks require models to solve problems by executing multi-step algorithms that reflect key aspects of long reasoning, such as retrieval and backtracking. By controlling the inputs, the required reasoning length can be arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most challenging tasks. Extensive evaluation results demonstrate that LongReasonArena presents a significant challenge for both open-source and proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our task. Further analysis also reveals that the accuracy exhibits a linear decline with respect to the logarithm of the expected number of reasoning steps. Our code and data is available at this https URL.</li>
</ul>

<h3>Title: Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Supratik Sarkar, Swagatam Das</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19366">https://arxiv.org/abs/2508.19366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19366">https://arxiv.org/pdf/2508.19366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19366]] Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs(https://arxiv.org/abs/2508.19366)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Hallucinations in large language models (LLMs) remain a fundamental obstacle to trustworthy AI, particularly in high-stakes multimodal domains such as medicine, law, and finance. Existing evaluation techniques are largely heuristic -- anchored in qualitative benchmarking or ad-hoc empirical mitigation -- providing neither principled quantification nor actionable theoretical guarantees. This gap leaves a critical blind spot in understanding how hallucinations arise, propagate, and interact across modalities. We introduce the first (to our knowledge) rigorous information geometric framework in diffusion dynamics for quantifying hallucinations in multimodal LLMs (MLLMs), advancing the field from qualitative detection to mathematically grounded measurement. Our approach represents MLLM outputs as the spectral embeddings over multimodal graph Laplacians and characterizes the manifold gaps of truth vs inconsistencies as the semantic distortion, enabling the tight Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of time-dependent temperature profiles. By leveraging eigenmode decompositions in Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers modality-aware, theoretically interpretable metrics that capture the evolution of hallucinations across time and input prompts through temperature annealing. This work establishes a principled foundation for quantifying and bounding hallucinations, transforming them from a qualitative risk to a tractable, analyzable phenomenon.</li>
</ul>

<h3>Title: Just Dork and Crawl: Measuring Illegal Online Gambling Defacement in Indonesian Websites</h3>
<ul>
<li><strong>Authors: </strong>Luqman Muhammad Zagi, Girindro Pringgo Digdo, Wervyan Shalannanda</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19368">https://arxiv.org/abs/2508.19368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19368">https://arxiv.org/pdf/2508.19368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19368]] Just Dork and Crawl: Measuring Illegal Online Gambling Defacement in Indonesian Websites(https://arxiv.org/abs/2508.19368)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense</a></li>
<li><strong>Abstract: </strong>This study investigates the defacement of Indonesian websites by actors promoting illegal online gambling. Using a lightweight methodology that combines keyword-driven dorking with systematic crawling, we identified 453 defaced webpages within one month. Although dorking alone yielded a false positive rate of approximately 20.3\%, the integration of crawling and keyword-counting enabled reliable differentiation between true and false positives. Our measurements revealed diverse defacement behaviors, including repeat defacements (150 cases), fixed instances (129), keyword modifications (55), and redirections or hidden URL injections. In total, 8,837 unique third-party URLs spanning 5,930 domains were captured, with a small subset recurring across multiple sites. Website responses were inconsistent, with an average reaction time of 75.3 hours. These findings demonstrate that simple, reproducible techniques can provide meaningful insights into the scale, persistence, and dynamics of defacement, highlighting the importance of continuous measurement for strengthening defenses against online gambling activities.</li>
</ul>

<h3>Title: Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments</h3>
<ul>
<li><strong>Authors: </strong>Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, hep-ex</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19376">https://arxiv.org/abs/2508.19376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19376">https://arxiv.org/pdf/2508.19376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19376]] Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments(https://arxiv.org/abs/2508.19376)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in large language models (LLMs) has shown strong potential for multimodal reasoning beyond natural language. In this work, we explore the use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for classifying neutrino interactions from pixelated detector images in high-energy physics (HEP) experiments. We benchmark its performance against an established CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as classification accuracy, precision, recall, and AUC-ROC. Our results show that the VLM not only matches or exceeds CNN performance but also enables richer reasoning and better integration of auxiliary textual or semantic context. These findings suggest that VLMs offer a promising general-purpose backbone for event classification in HEP, paving the way for multimodal approaches in experimental neutrino physics.</li>
</ul>

<h3>Title: DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Owais Ahmad, Milad Ramezankhani, Anirudh Deodhar</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19389">https://arxiv.org/abs/2508.19389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19389">https://arxiv.org/pdf/2508.19389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19389]] DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting(https://arxiv.org/abs/2508.19389)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Accurate long-term traffic forecasting remains a critical challenge in intelligent transportation systems, particularly when predicting high-frequency traffic phenomena such as shock waves and congestion boundaries over extended rollout horizons. Neural operators have recently gained attention as promising tools for modeling traffic flow. While effective at learning function space mappings, they inherently produce smooth predictions that fail to reconstruct high-frequency features such as sharp density gradients which results in rapid error accumulation during multi-step rollout predictions essential for real-time traffic management. To address these fundamental limitations, we introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO) architecture. DETNO leverages a transformer neural operator with cross-attention mechanisms, providing model expressivity and super-resolution, coupled with a diffusion-based refinement component that iteratively reconstructs high-frequency traffic details through progressive denoising. This overcomes the inherent smoothing limitations and rollout instability of standard neural operators. Through comprehensive evaluation on chaotic traffic datasets, our method demonstrates superior performance in extended rollout predictions compared to traditional and transformer-based neural operators, preserving high-frequency components and improving stability over long prediction horizons.</li>
</ul>

<h3>Title: Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding</h3>
<ul>
<li><strong>Authors: </strong>Afrar Jahin, Yi Pan, Yingfeng Wang, Tianming Liu, Wei Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19394">https://arxiv.org/abs/2508.19394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19394">https://arxiv.org/pdf/2508.19394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19394]] Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding(https://arxiv.org/abs/2508.19394)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Although recent advances in quantum machine learning (QML) offer significant potential for enhancing generative models, particularly in molecular design, a large array of classical approaches still face challenges in achieving high fidelity and validity. In particular, the integration of QML with sequence-based tasks, such as Simplified Molecular Input Line Entry System (SMILES) string reconstruction, remains underexplored and usually suffers from fidelity degradation. In this work, we propose a hybrid quantum-classical architecture for SMILES reconstruction that integrates quantum encoding with classical sequence modeling to improve quantum fidelity and classical similarity. Our approach achieves a quantum fidelity of approximately 84% and a classical reconstruction similarity of 60%, surpassing existing quantum baselines. Our work lays a promising foundation for future QML applications, striking a balance between expressive quantum representations and classical sequence models and catalyzing broader research on quantum-aware sequence models for molecular and drug discovery.</li>
</ul>

<h3>Title: A NIS2 pan-European registry for identifying and classifying essential and important entities</h3>
<ul>
<li><strong>Authors: </strong>Fabian Aude Steen, Daniel Assani Shabani</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19395">https://arxiv.org/abs/2508.19395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19395">https://arxiv.org/pdf/2508.19395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19395]] A NIS2 pan-European registry for identifying and classifying essential and important entities(https://arxiv.org/abs/2508.19395)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The NIS2 Directive establishes a common cybersecurity governance model across the European Union, requiring member states to identify, classify, and supervise essential and important entities. As part of a broader governance network, member states are also obligated to notify the European Commission, the Cooperation Group, and ENISA about their cybersecurity infrastructure landscape. This thesis presents an analysis of the NIS2 Directive in this context and translates its provisions into concrete technical requirements. These requirements inform the design and implementation of a modular, legally grounded registry system intended to support competent authorities across the EU in meeting their obligations. Using the Design Science Research methodology, the thesis transforms complex legal provisions into structured workflows, deterministic classification algorithms, and interactive dashboards. The resulting system automates key regulatory processes, including entity registration, classification, and notification, while enabling context-aware supervision and reducing administrative burden. It supports both automated and manual registration methods and introduces a contextual labeling system to handle edge cases, risk factors, and cross-directive dependencies. Although developed for the Norwegian regulatory ecosystem, the system is designed for adaptation by other member states with minimal modification. This thesis contributes a reusable framework that bridges legal interpretation and technical implementation, offering a scalable solution for national and EU-level NIS2 cybersecurity governance. It also identifies key limitations and outlines opportunities for future research and development.</li>
</ul>

<h3>Title: One Joke to Rule them All? On the (Im)possibility of Generalizing Humor</h3>
<ul>
<li><strong>Authors: </strong>Mor Turgeman, Chen Shani, Dafna Shahaf</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19402">https://arxiv.org/abs/2508.19402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19402">https://arxiv.org/pdf/2508.19402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19402]] One Joke to Rule them All? On the (Im)possibility of Generalizing Humor(https://arxiv.org/abs/2508.19402)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Humor is a broad and complex form of communication that remains challenging for machines. Despite its broadness, most existing research on computational humor traditionally focused on modeling a specific type of humor. In this work, we wish to understand whether competence on one or more specific humor tasks confers any ability to transfer to novel, unseen types; in other words, is this fragmentation inevitable? This question is especially timely as new humor types continuously emerge in online and social media contexts (e.g., memes, anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this evolving landscape, they must be able to generalize across humor types by capturing deeper, transferable mechanisms. To investigate this, we conduct a series of transfer learning experiments across four datasets, representing different humor tasks. We train LLMs under varied diversity settings (1-3 datasets in training, testing on a novel task). Experiments reveal that models are capable of some transfer, and can reach up to 75% accuracy on unseen datasets; training on diverse sources improves transferability (1.88-4.05%) with minimal-to-no drop in in-domain performance. Further analysis suggests relations between humor types, with Dad Jokes surprisingly emerging as the best enabler of transfer (but is difficult to transfer to). We release data and code.</li>
</ul>

<h3>Title: Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Zongyu Wu, Ruichen Xu, Luoyao Chen, Georgios Kementzidis, Siyao Wang, Yuefan Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19410">https://arxiv.org/abs/2508.19410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19410">https://arxiv.org/pdf/2508.19410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19410]] Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks(https://arxiv.org/abs/2508.19410)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure energy conservation by learning Hamiltonian functions directly from data, existing implementations, often relying on MLPs, cause hypersensitivity to the hyperparameters while exploring complex energy landscapes. Our approach exploits the localized function approximations to better capture high-frequency and multi-scale dynamics, reducing energy drift and improving long-term predictive stability. The networks preserve the symplectic form of Hamiltonian systems, and thus maintain interpretability and physical consistency. After assessing KAR-HNN on four benchmark problems including spring-mass, simple pendulum, two- and three-body problem, we foresee its effectiveness for accurate and stable modeling of realistic physical processes often at high dimensions and with few known parameters.</li>
</ul>

<h3>Title: Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention</h3>
<ul>
<li><strong>Authors: </strong>Gustavo Sandoval</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19414">https://arxiv.org/abs/2508.19414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19414">https://arxiv.org/pdf/2508.19414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19414]] Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention(https://arxiv.org/abs/2508.19414)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We present a mechanistic case study of a format-dependent reasoning failure in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger than "9.8" in chat or Q&A formats, but answers correctly in simple format. Through systematic intervention, we discover transformers implement even/odd attention head specialization: even indexed heads handle numerical comparison, while odd heads serve incompatible functions. The bug requires exactly 8 even heads at Layer 10 for perfect repair. Any combination of 8+ even heads succeeds, while 7 or fewer completely fails, revealing sharp computational thresholds with perfect redundancy among the 16 even heads. SAE analysis reveals the mechanism: format representations separate (10% feature overlap at Layer 7), then re-entangle with different weightings (80% feature overlap at Layer 10), with specific features showing 1.5x amplification in failing formats. We achieve perfect repair using only 25% of attention heads and identify a 60% pattern replacement threshold, demonstrating that apparent full-module requirements hide sophisticated substructure with implications for interpretability and efficiency. All of our code is available at this https URL.</li>
</ul>

<h3>Title: Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management</h3>
<ul>
<li><strong>Authors: </strong>Harun Ur Rashid, Aleksandra Pachalieva, Daniel O'Malley</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19419">https://arxiv.org/abs/2508.19419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19419">https://arxiv.org/pdf/2508.19419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19419]] Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management(https://arxiv.org/abs/2508.19419)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Accurate subsurface reservoir pressure control is extremely challenging due to geological heterogeneity and multiphase fluid-flow dynamics. Predicting behavior in this setting relies on high-fidelity physics-based simulations that are computationally expensive. Yet, the uncertain, heterogeneous properties that control these flows make it necessary to perform many of these expensive simulations, which is often prohibitive. To address these challenges, we introduce a physics-informed machine learning workflow that couples a fully differentiable multiphase flow simulator, which is implemented in the DPFEHM framework with a convolutional neural network (CNN). The CNN learns to predict fluid extraction rates from heterogeneous permeability fields to enforce pressure limits at critical reservoir locations. By incorporating transient multiphase flow physics into the training process, our method enables more practical and accurate predictions for realistic injection-extraction scenarios compare to previous works. To speed up training, we pretrain the model on single-phase, steady-state simulations and then fine-tune it on full multiphase scenarios, which dramatically reduces the computational cost. We demonstrate that high-accuracy training can be achieved with fewer than three thousand full-physics multiphase flow simulations -- compared to previous estimates requiring up to ten million. This drastic reduction in the number of simulations is achieved by leveraging transfer learning from much less expensive single-phase simulations.</li>
</ul>

<h3>Title: A perishable ability? The future of writing in the face of generative artificial intelligence</h3>
<ul>
<li><strong>Authors: </strong>Evandro L. T. P. Cunha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19427">https://arxiv.org/abs/2508.19427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19427">https://arxiv.org/pdf/2508.19427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19427]] A perishable ability? The future of writing in the face of generative artificial intelligence(https://arxiv.org/abs/2508.19427)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The 2020s have been witnessing a very significant advance in the development of generative artificial intelligence tools, including text generation systems based on large language models. These tools have been increasingly used to generate texts in the most diverse domains -- from technical texts to literary texts --, which might eventually lead to a lower volume of written text production by humans. This article discusses the possibility of a future in which human beings will have lost or significantly decreased their ability to write due to the outsourcing of this activity to machines. This possibility parallels the loss of the ability to write in other moments of human history, such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).</li>
</ul>

<h3>Title: Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)</h3>
<ul>
<li><strong>Authors: </strong>Aleksandra Beliaeva, Temurbek Rahmatullaev</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LO, cs.SC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19428">https://arxiv.org/abs/2508.19428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19428">https://arxiv.org/pdf/2508.19428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19428]] Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)(https://arxiv.org/abs/2508.19428)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>We present a comprehensive system for addressing Tasks A, B, and C of the LLMs4OL 2025 challenge, which together span the full ontology construction pipeline: term extraction, typing, and taxonomy discovery. Our approach combines retrieval-augmented prompting, zero-shot classification, and attention-based graph modeling -- each tailored to the demands of the respective task. For Task A, we jointly extract domain-specific terms and their ontological types using a retrieval-augmented generation (RAG) pipeline. Training data was reformulated into a document to terms and types correspondence, while test-time inference leverages semantically similar training examples. This single-pass method requires no model finetuning and improves overall performance through lexical augmentation Task B, which involves assigning types to given terms, is handled via a dual strategy. In the few-shot setting (for domains with labeled training data), we reuse the RAG scheme with few-shot prompting. In the zero-shot setting (for previously unseen domains), we use a zero-shot classifier that combines cosine similarity scores from multiple embedding models using confidence-based weighting. In Task C, we model taxonomy discovery as graph inference. Using embeddings of type labels, we train a lightweight cross-attention layer to predict is-a relations by approximating a soft adjacency matrix. These modular, task-specific solutions enabled us to achieve top-ranking results in the official leaderboard across all three tasks. Taken together these strategies showcase the scalability, adaptability, and robustness of LLM-based architectures for ontology learning across heterogeneous domains. Code is available at: this https URL</li>
</ul>

<h3>Title: Formal Verification of Physical Layer Security Protocols for Next-Generation Communication Networks</h3>
<ul>
<li><strong>Authors: </strong>Kangfeng Ye, Roberto Metere, Jim Woodcock, Poonam Yadav</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.FL, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19430">https://arxiv.org/abs/2508.19430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19430">https://arxiv.org/pdf/2508.19430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19430]] Formal Verification of Physical Layer Security Protocols for Next-Generation Communication Networks(https://arxiv.org/abs/2508.19430)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Formal verification is crucial for ensuring the robustness of security protocols against adversarial attacks. The Needham-Schroeder protocol, a foundational authentication mechanism, has been extensively studied, including its integration with Physical Layer Security (PLS) techniques such as watermarking and jamming. Recent research has used ProVerif to verify these mechanisms in terms of secrecy. However, the ProVerif-based approach limits the ability to improve understanding of security beyond verification results. To overcome these limitations, we re-model the same protocol using an Isabelle formalism that generates sound animation, enabling interactive and automated formal verification of security protocols. Our modelling and verification framework is generic and highly configurable, supporting both cryptography and PLS. For the same protocol, we have conducted a comprehensive analysis (secrecy and authenticity in four different eavesdropper locations under both passive and active attacks) using our new web interface. Our findings not only successfully reproduce and reinforce previous results on secrecy but also reveal an uncommon but expected outcome: authenticity is preserved across all examined scenarios, even in cases where secrecy is compromised. We have proposed a PLS-based Diffie-Hellman protocol that integrates watermarking and jamming, and our analysis shows that it is secure for deriving a session key with required authentication. These highlight the advantages of our novel approach, demonstrating its robustness in formally verifying security properties beyond conventional methods.</li>
</ul>

<h3>Title: Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization</h3>
<ul>
<li><strong>Authors: </strong>Paimon Goulart, Shaan Pakala, Evangelos Papalexakis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19443">https://arxiv.org/abs/2508.19443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19443">https://arxiv.org/pdf/2508.19443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19443]] Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization(https://arxiv.org/abs/2508.19443)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Producing large complex simulation datasets can often be a time and resource consuming task. Especially when these experiments are very expensive, it is becoming more reasonable to generate synthetic data for downstream tasks. Recently, these methods may include using generative machine learning models such as Generative Adversarial Networks or diffusion models. As these generative models improve efficiency in producing useful data, we introduce an internal tensor decomposition to these generative models to even further reduce costs. More specifically, for multidimensional data, or tensors, we generate the smaller tensor factors instead of the full tensor, in order to significantly reduce the model's output and overall parameters. This reduces the costs of generating complex simulation data, and our experiments show the generated data remains useful. As a result, tensor decomposition has the potential to improve efficiency in generative models, especially when generating multidimensional data, or tensors.</li>
</ul>

<h3>Title: On Surjectivity of Neural Networks: Can you elicit any behavior from your model?</h3>
<ul>
<li><strong>Authors: </strong>Haozhe Jiang, Nika Haghtalab</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19445">https://arxiv.org/abs/2508.19445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19445">https://arxiv.org/pdf/2508.19445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19445]] On Surjectivity of Neural Networks: Can you elicit any behavior from your model?(https://arxiv.org/abs/2508.19445)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Given a trained neural network, can any specified output be generated by some input? Equivalently, does the network correspond to a function that is surjective? In generative models, surjectivity implies that any output, including harmful or undesirable content, can in principle be generated by the networks, raising concerns about model safety and jailbreak vulnerabilities. In this paper, we prove that many fundamental building blocks of modern neural architectures, such as networks with pre-layer normalization and linear-attention modules, are almost always surjective. As corollaries, widely used generative frameworks, including GPT-style transformers and diffusion models with deterministic ODE solvers, admit inverse mappings for arbitrary outputs. By studying surjectivity of these modern and commonly used neural architectures, we contribute a formalism that sheds light on their unavoidable vulnerability to a broad class of adversarial attacks.</li>
</ul>

<h3>Title: CITADEL: Continual Anomaly Detection for Enhanced Learning in IoT Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Elvin Li, Onat Gungor, Zhengli Shang, Tajana Rosing</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19450">https://arxiv.org/abs/2508.19450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19450">https://arxiv.org/pdf/2508.19450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19450]] CITADEL: Continual Anomaly Detection for Enhanced Learning in IoT Intrusion Detection(https://arxiv.org/abs/2508.19450)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>The Internet of Things (IoT), with its high degree of interconnectivity and limited computational resources, is particularly vulnerable to a wide range of cyber threats. Intrusion detection systems (IDS) have been extensively studied to enhance IoT security, and machine learning-based IDS (ML-IDS) show considerable promise for detecting malicious activity. However, their effectiveness is often constrained by poor adaptability to emerging threats and the issue of catastrophic forgetting during continuous learning. To address these challenges, we propose CITADEL, a self-supervised continual learning framework designed to extract robust representations from benign data while preserving long-term knowledge through optimized memory consolidation mechanisms. CITADEL integrates a tabular-to-image transformation module, a memory-aware masked autoencoder for self-supervised representation learning, and a novelty detection component capable of identifying anomalies without dependence on labeled attack data. Our design enables the system to incrementally adapt to emerging behaviors while retaining its ability to detect previously observed threats. Experiments on multiple intrusion datasets demonstrate that CITADEL achieves up to a 72.9% improvement over the VAE-based lifelong anomaly detector (VLAD) in key detection and retention metrics, highlighting its effectiveness in dynamic IoT environments.</li>
</ul>

<h3>Title: ReLATE+: Unified Framework for Adversarial Attack Detection, Classification, and Resilient Model Selection in Time-Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Cagla Ipek Kocal, Onat Gungor, Tajana Rosing, Baris Aksanli</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19456">https://arxiv.org/abs/2508.19456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19456">https://arxiv.org/pdf/2508.19456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19456]] ReLATE+: Unified Framework for Adversarial Attack Detection, Classification, and Resilient Model Selection in Time-Series Classification(https://arxiv.org/abs/2508.19456)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Minimizing computational overhead in time-series classification, particularly in deep learning models, presents a significant challenge due to the high complexity of model architectures and the large volume of sequential data that must be processed in real time. This challenge is further compounded by adversarial attacks, emphasizing the need for resilient methods that ensure robust performance and efficient model selection. To address this challenge, we propose ReLATE+, a comprehensive framework that detects and classifies adversarial attacks, adaptively selects deep learning models based on dataset-level similarity, and thus substantially reduces retraining costs relative to conventional methods that do not leverage prior knowledge, while maintaining strong performance. ReLATE+ first checks whether the incoming data is adversarial and, if so, classifies the attack type, using this insight to identify a similar dataset from a repository and enable the reuse of the best-performing associated model. This approach ensures strong performance while reducing the need for retraining, and it generalizes well across different domains with varying data distributions and feature spaces. Experiments show that ReLATE+ reduces computational overhead by an average of 77.68%, enhancing adversarial resilience and streamlining robust model selection, all without sacrificing performance, within 2.02% of Oracle.</li>
</ul>

<h3>Title: The Sample Complexity of Membership Inference and Privacy Auditing</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Haghifam, Adam Smith, Jonathan Ullman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19458">https://arxiv.org/abs/2508.19458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19458">https://arxiv.org/pdf/2508.19458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19458]] The Sample Complexity of Membership Inference and Privacy Auditing(https://arxiv.org/abs/2508.19458)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>A membership-inference attack gets the output of a learning algorithm, and a target individual, and tries to determine whether this individual is a member of the training data or an independent sample from the same distribution. A successful membership-inference attack typically requires the attacker to have some knowledge about the distribution that the training data was sampled from, and this knowledge is often captured through a set of independent reference samples from that distribution. In this work we study how much information the attacker needs for membership inference by investigating the sample complexity-the minimum number of reference samples required-for a successful attack. We study this question in the fundamental setting of Gaussian mean estimation where the learning algorithm is given $n$ samples from a Gaussian distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate $\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq \rho^2 d$. Our result shows that for membership inference in this setting, $\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that competes with a fully informed attacker. Our result is the first to show that the attacker sometimes needs many more samples than the training algorithm uses to train the model. This result has significant implications for practice, as all attacks used in practice have a restricted form that uses $O(n)$ samples and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be underestimating the possibility of membership inference, and better attacks may be possible when information about the distribution is easy to obtain.</li>
</ul>

<h3>Title: Bridging Language Gaps: Enhancing Few-Shot Language Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Philipp Borchert, Jochen De Weerdt, Marie-Francine Moens</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19464">https://arxiv.org/abs/2508.19464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19464">https://arxiv.org/pdf/2508.19464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19464]] Bridging Language Gaps: Enhancing Few-Shot Language Adaptation(https://arxiv.org/abs/2508.19464)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The disparity in language resources poses a challenge in multilingual NLP, with high-resource languages benefiting from extensive data, while low-resource languages lack sufficient data for effective training. Our Contrastive Language Alignment with Prompting (CoLAP) method addresses this gap by integrating contrastive learning with cross-lingual representations, facilitating task-specific knowledge transfer from high-resource to lower-resource languages. The primary advantage of our approach is its data efficiency, enabling rapid adaptation to new languages and reducing the need for large labeled datasets. We conduct experiments with multilingual encoder-only and decoder-only language models on natural language understanding tasks, including natural language inference and relation extraction, evaluating performance across both high- and low-resource languages. Our results demonstrate that CoLAP outperforms few-shot cross-lingual transfer baselines and in-context learning, even with limited available data. This effectively narrows the cross-lingual performance gap, contributing to the development of more efficient multilingual NLP techniques.</li>
</ul>

<h3>Title: Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication</h3>
<ul>
<li><strong>Authors: </strong>Onyinye Okoye</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19465">https://arxiv.org/abs/2508.19465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19465">https://arxiv.org/pdf/2508.19465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19465]] Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication(https://arxiv.org/abs/2508.19465)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle Charging Systems (EVCs) has introduced new cybersecurity challenges, specifically in authentication protocols that protect vehicles, users, and energy infrastructure. Although widely adopted for convenience, traditional authentication mechanisms like Radio Frequency Identification (RFID) and Near Field Communication (NFC) rely on static identifiers and weak encryption, making them highly vulnerable to attack vectors such as cloning, relay attacks, and signal interception. This study explores an AI-powered adaptive authentication framework designed to overcome these shortcomings by integrating machine learning, anomaly detection, behavioral analytics, and contextual risk assessment. Grounded in the principles of Zero Trust Architecture, the proposed framework emphasizes continuous verification, least privilege access, and secure communication. Through a comprehensive literature review, this research evaluates current vulnerabilities and highlights AI-driven solutions to provide a scalable, resilient, and proactive defense. Ultimately, the research findings conclude that adopting AI-powered adaptive authentication is a strategic imperative for securing the future of electric mobility and strengthening digital trust across the ecosystem. Keywords: weak authentication, RFID, NFC, ML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping, MITM attacks, Zero Trust Architecture</li>
</ul>

<h3>Title: Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset</h3>
<ul>
<li><strong>Authors: </strong>Sumon Kanti Dey, Jeanne M. Powell, Azra Ismail, Jeanmarie Perrone, Abeed Sarker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19467">https://arxiv.org/abs/2508.19467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19467">https://arxiv.org/pdf/2508.19467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19467]] Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset(https://arxiv.org/abs/2508.19467)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Nonmedical opioid use is an urgent public health challenge, with far-reaching clinical and social consequences that are often underreported in traditional healthcare settings. Social media platforms, where individuals candidly share first-person experiences, offer a valuable yet underutilized source of insight into these impacts. In this study, we present a named entity recognition (NER) framework to extract two categories of self-reported consequences from social media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal, depression) and SocialImpacts (e.g., job loss). To support this task, we introduce RedditImpacts 2.0, a high-quality dataset with refined annotation guidelines and a focus on first-person disclosures, addressing key limitations of prior work. We evaluate both fine-tuned encoder-based models and state-of-the-art large language models (LLMs) under zero- and few-shot in-context learning settings. Our fine-tuned DeBERTa-large model achieves a relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming LLMs in precision, span accuracy, and adherence to task-specific guidelines. Furthermore, we show that strong NER performance can be achieved with substantially less labeled data, emphasizing the feasibility of deploying robust models in resource-limited settings. Our findings underscore the value of domain-specific fine-tuning for clinical NLP tasks and contribute to the responsible development of AI tools that may enhance addiction surveillance, improve interpretability, and support real-world healthcare decision-making. The best performing model, however, still significantly underperforms compared to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap persists between expert intelligence and current state-of-the-art NER/AI capabilities for tasks requiring deep domain knowledge.</li>
</ul>

<h3>Title: SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis</h3>
<ul>
<li><strong>Authors: </strong>Kyler Katz, Sara Moshtari, Ibrahim Mujhid, Mehdi Mirakhorli, Derek Garcia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19472">https://arxiv.org/abs/2508.19472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19472">https://arxiv.org/pdf/2508.19472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19472]] SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis(https://arxiv.org/abs/2508.19472)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, transformer</a></li>
<li><strong>Abstract: </strong>Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a persistent and under-addressed threat across software systems, often leading to serious security breaches. Existing detection tools rarely target the diverse subcategories of CWE-200 or provide context-aware analysis of code-level data flows. Aims: This paper aims to present SIExVulTS, a novel vulnerability detection system that integrates transformer-based models with static analysis to identify and verify sensitive information exposure in Java applications. Method: SIExVulTS employs a three-stage architecture: (1) an Attack Surface Detection Engine that uses sentence embeddings to identify sensitive variables, strings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates CodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification Engine that leverages GraphCodeBERT to semantically validate source-to-sink flows. We evaluate SIExVulTS using three curated datasets, including real-world CVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31 open-source projects. Results: The Attack Surface Detection Engine achieved an average F1 score greater than 93\%, the Exposure Analysis Engine achieved an F1 score of 85.71\%, and the Flow Verification Engine increased precision from 22.61\% to 87.23\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs in major Apache projects. Conclusions: The results demonstrate that SIExVulTS is effective and practical for improving software security against sensitive data exposure, addressing limitations of existing tools in detecting and verifying CWE-200 vulnerabilities.</li>
</ul>

<h3>Title: Automatic Question & Answer Generation Using Generative Large Language Model (LLM)</h3>
<ul>
<li><strong>Authors: </strong>Md. Alvee Ehsan, A.S.M Mehedi Hasan, Kefaya Benta Shahnoor, Syeda Sumaiya Tasneem</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19475">https://arxiv.org/abs/2508.19475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19475">https://arxiv.org/pdf/2508.19475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19475]] Automatic Question & Answer Generation Using Generative Large Language Model (LLM)(https://arxiv.org/abs/2508.19475)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative, large language model</a></li>
<li><strong>Abstract: </strong>\Abstract{In the realm of education, student evaluation holds equal significance as imparting knowledge. To be evaluated, students usually need to go through text-based academic assessment methods. Instructors need to make diverse sets of questions that need to be fair for all students to prove their adequacy over a particular topic. This can prove to be quite challenging as they may need to manually go through several different lecture materials. Our objective is to make this whole process much easier by implementing Automatic Question Answer Generation /(AQAG), using fine-tuned generative LLM. For tailoring the instructor's preferred question style (MCQ, conceptual, or factual questions), prompt Engineering (PE) is being utilized. In this research, we propose to leverage unsupervised learning methods in NLP, primarily focusing on the English language. This approach empowers the base Meta-Llama 2-7B model to integrate RACE dataset as training data for the fine-tuning process. Creating a customized model that will offer efficient solutions for educators, instructors, and individuals engaged in text-based evaluations. A reliable and efficient tool for generating questions and answers can free up valuable time and resources, thus streamlining their evaluation processes.}</li>
</ul>

<h3>Title: Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage</h3>
<ul>
<li><strong>Authors: </strong>Zachary L. Crang, Rich D. Johnston, Katie L. Mills, Johsan Billingham, Sam Robertson, Michael H. Cole, Jonathon Weakley, Adam Hewitt and, Grant M. Duthie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19477">https://arxiv.org/abs/2508.19477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19477">https://arxiv.org/pdf/2508.19477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19477]] Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage(https://arxiv.org/abs/2508.19477)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This study aimed to: (1) understand whether commercially available computer-vision and artificial intelligence (AI) player tracking software can accurately measure player position, speed and distance using broadcast footage and (2) determine the impact of camera feed and resolution on accuracy. Data were obtained from one match at the 2022 Qatar Federation Internationale de Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds were used. Three commercial tracking providers that use computer-vision and AI participated. Providers analysed instantaneous position (x, y coordinates) and speed (m\,s^{-1}) of each player. Their data were compared with a high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to 16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across providers. Computer-vision and AI player tracking software offer the ability to track players with fair precision when players are detected by the software. Providers should use a tactical feed when tracking position and speed, which will maximise player detection, improving accuracy. Both 720p and 1080p resolutions are suitable, assuming appropriate computer-vision and AI models are implemented.</li>
</ul>

<h3>Title: DeepAtlas: a tool for effective manifold learning</h3>
<ul>
<li><strong>Authors: </strong>Serena Hughes, Timothy Hamilton, Tom Kolokotrones, Eric J. Deeds</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19479">https://arxiv.org/abs/2508.19479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19479">https://arxiv.org/pdf/2508.19479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19479]] DeepAtlas: a tool for effective manifold learning(https://arxiv.org/abs/2508.19479)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Manifold learning builds on the "manifold hypothesis," which posits that data in high-dimensional datasets are drawn from lower-dimensional manifolds. Current tools generate global embeddings of data, rather than the local maps used to define manifolds mathematically. These tools also cannot assess whether the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas, an algorithm that generates lower-dimensional representations of the data's local neighborhoods, then trains deep neural networks that map between these local embeddings and the original data. Topological distortion is used to determine whether a dataset is drawn from a manifold and, if so, its dimensionality. Application to test datasets indicates that DeepAtlas can successfully learn manifold structures. Interestingly, many real datasets, including single-cell RNA-sequencing, do not conform to the manifold hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a model that can be used generatively and promises to allow the application of powerful tools from differential geometry to a variety of datasets.</li>
</ul>

<h3>Title: Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study</h3>
<ul>
<li><strong>Authors: </strong>Manuel Mosquera, Melissa Robles, Johan Rodriguez, Ruben Manrique</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19481">https://arxiv.org/abs/2508.19481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19481">https://arxiv.org/pdf/2508.19481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19481]] Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study(https://arxiv.org/abs/2508.19481)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-resource machine translation remains a significant challenge for large language models (LLMs), which often lack exposure to these languages during pretraining and have limited parallel data for fine-tuning. We propose a novel approach that enhances translation for low-resource languages by integrating an external dictionary tool and training models end-to-end using reinforcement learning, in addition to supervised fine-tuning. Focusing on the Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented decision-making problem in which the model can selectively consult a bilingual dictionary during generation. Our method combines supervised instruction tuning with Guided Reward Policy Optimization (GRPO), enabling the model to learn both when and how to use the tool effectively. BLEU similarity scores are used as rewards to guide this learning process. Preliminary results show that our tool-augmented models achieve up to +3.37 BLEU improvement over previous work, and a 18% relative gain compared to a supervised baseline without dictionary access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared Task. We also conduct ablation studies to assess the effects of model architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other models such as LLaMA and a prior NLLB-based system. These findings highlight the promise of combining LLMs with external tools and the role of reinforcement learning in improving translation quality in low-resource language settings.</li>
</ul>

<h3>Title: Rule Synergy Analysis using LLMs: State of the Art and Implications</h3>
<ul>
<li><strong>Authors: </strong>Bahar Bateni, Benjamin Pratt, Jim Whitehead</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19484">https://arxiv.org/abs/2508.19484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19484">https://arxiv.org/pdf/2508.19484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19484]] Rule Synergy Analysis using LLMs: State of the Art and Implications(https://arxiv.org/abs/2508.19484)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated strong performance across a variety of domains, including logical reasoning, mathematics, and more. In this paper, we investigate how well LLMs understand and reason about complex rule interactions in dynamic environments, such as card games. We introduce a dataset of card synergies from the game Slay the Spire, where pairs of cards are classified based on their positive, negative, or neutral interactions. Our evaluation shows that while LLMs excel at identifying non-synergistic pairs, they struggle with detecting positive and, particularly, negative synergies. We categorize common error types, including issues with timing, defining game states, and following game rules. Our findings suggest directions for future research to improve model performance in predicting the effect of rules and their interactions.</li>
</ul>

<h3>Title: JVLGS: Joint Vision-Language Gas Leak Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xinlong Zhao, Qixiang Pang, Shan Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19485">https://arxiv.org/abs/2508.19485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19485">https://arxiv.org/pdf/2508.19485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19485]] JVLGS: Joint Vision-Language Gas Leak Segmentation(https://arxiv.org/abs/2508.19485)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Gas leaks pose serious threats to human health and contribute significantly to atmospheric pollution, drawing increasing public concern. However, the lack of effective detection methods hampers timely and accurate identification of gas leaks. While some vision-based techniques leverage infrared videos for leak detection, the blurry and non-rigid nature of gas clouds often limits their effectiveness. To address these challenges, we propose a novel framework called Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the complementary strengths of visual and textual modalities to enhance gas leak representation and segmentation. Recognizing that gas leaks are sporadic and many video frames may contain no leak at all, our method incorporates a post-processing step to reduce false positives caused by noise and non-target objects, an issue that affects many existing approaches. Extensive experiments conducted across diverse scenarios show that JVLGS significantly outperforms state-of-the-art gas leak segmentation methods. We evaluate our model under both supervised and few-shot learning settings, and it consistently achieves strong performance in both, whereas competing methods tend to perform well in only one setting or poorly in both. Code available at: this https URL</li>
</ul>

<h3>Title: Distribution Shift Aware Neural Tabular Learning</h3>
<ul>
<li><strong>Authors: </strong>Wangyang Ying, Nanxu Gong, Dongjie Wang, Xinyuan Wang, Arun Vignesh Malarkkan, Vivek Gupta, Chandan K. Reddy, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19486">https://arxiv.org/abs/2508.19486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19486">https://arxiv.org/pdf/2508.19486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19486]] Distribution Shift Aware Neural Tabular Learning(https://arxiv.org/abs/2508.19486)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tabular learning transforms raw features into optimized spaces for downstream tasks, but its effectiveness deteriorates under distribution shifts between training and testing data. We formalize this challenge as the Distribution Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature Transformation (SAFT) framework to address it. SAFT reframes tabular learning from a discrete search task into a continuous representation-generation paradigm, enabling differentiable optimization over transformed feature sets. SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant representation via embedding decorrelation and sample reweighting, (ii) flatness-aware generation through suboptimal embedding averaging, and (iii) normalization-based alignment between training and test distributions. Extensive experiments show that SAFT consistently outperforms prior tabular learning methods in terms of robustness, effectiveness, and generalization ability under diverse real-world distribution shifts.</li>
</ul>

<h3>Title: Data-Efficient Symbolic Regression via Foundation Model Distillation</h3>
<ul>
<li><strong>Authors: </strong>Wangyang Ying, Jinghan Zhang, Haoyue Bai, Nanxu Gong, Xinyuan Wang, Kunpeng Liu, Chandan K. Reddy, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19487">https://arxiv.org/abs/2508.19487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19487">https://arxiv.org/pdf/2508.19487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19487]] Data-Efficient Symbolic Regression via Foundation Model Distillation(https://arxiv.org/abs/2508.19487)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Discovering interpretable mathematical equations from observed data (a.k.a. equation discovery or symbolic regression) is a cornerstone of scientific discovery, enabling transparent modeling of physical, biological, and economic systems. While foundation models pre-trained on large-scale equation datasets offer a promising starting point, they often suffer from negative transfer and poor generalization when applied to small, domain-specific datasets. In this paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer Embeddings), a data-efficient fine-tuning framework that adapts foundation models for symbolic equation discovery in low-data regimes via distillation. EQUATE combines symbolic-numeric alignment with evaluator-guided embedding optimization, enabling a principled embedding-search-generation paradigm. Our approach reformulates discrete equation search as a continuous optimization task in a shared embedding space, guided by data-equation fitness and simplicity. Experiments across three standard public benchmarks (Feynman, Strogatz, and black-box datasets) demonstrate that EQUATE consistently outperforms state-of-the-art baselines in both accuracy and robustness, while preserving low complexity and fast inference. These results highlight EQUATE as a practical and generalizable solution for data-efficient symbolic regression in foundation model distillation settings.</li>
</ul>

<h3>Title: PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense</h3>
<ul>
<li><strong>Authors: </strong>Xavier Cadet, Simona Boboila, Sie Hendrata Dharmawan, Alina Oprea, Peter Chin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19488">https://arxiv.org/abs/2508.19488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19488">https://arxiv.org/pdf/2508.19488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19488]] PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense(https://arxiv.org/abs/2508.19488)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal</a></li>
<li><strong>Abstract: </strong>Cyber defense requires automating defensive decision-making under stealthy, deceptive, and continuously evolving adversarial strategies. The FlipIt game provides a foundational framework for modeling interactions between a defender and an advanced adversary that compromises a system without being immediately detected. In FlipIt, the attacker and defender compete to control a shared resource by performing a Flip action and paying a cost. However, the existing FlipIt frameworks rely on a small number of heuristics or specialized learning techniques, which can lead to brittleness and the inability to adapt to new attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym environment that extends the FlipIt game to allow efficient learning for attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent reinforcement learning (MARL) approach that leverages population-based training to train defender agents equipped to generalize against a range of unknown, potentially adaptive opponents. Our empirical results suggest that Flip-PSRO defenders are $2\times$ more effective than baselines to generalize to a heuristic attack not exposed in training. In addition, our newly designed ownership-based utility functions ensure that Flip-PSRO defenders maintain a high level of control while optimizing performance.</li>
</ul>

<h3>Title: Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents</h3>
<ul>
<li><strong>Authors: </strong>Zhixin Lin, Jungang Li, Shidong Pan, Yibo Shi, Yue Yao, Dongliang Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19493">https://arxiv.org/abs/2508.19493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19493">https://arxiv.org/pdf/2508.19493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19493]] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents(https://arxiv.org/abs/2508.19493)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Smartphones bring significant convenience to users but also enable devices to extensively record various types of personal information. Existing smartphone agents powered by Multimodal Large Language Models (MLLMs) have achieved remarkable performance in automating different tasks. However, as the cost, these agents are granted substantial access to sensitive users' personal information during this operation. To gain a thorough understanding of the privacy awareness of these agents, we present the first large-scale benchmark encompassing 7,138 scenarios to the best of our knowledge. In addition, for privacy context in scenarios, we annotate its type (e.g., Account Credentials), sensitivity level, and location. We then carefully benchmark seven available mainstream smartphone agents. Our results demonstrate that almost all benchmarked agents show unsatisfying privacy awareness (RA), with performance remaining below 60% even with explicit hints. Overall, closed-source agents show better privacy ability than open-source ones, and Gemini 2.0-flash achieves the best, achieving an RA of 67%. We also find that the agents' privacy detection capability is highly related to scenario sensitivity level, i.e., the scenario with a higher sensitivity level is typically more identifiable. We hope the findings enlighten the research community to rethink the unbalanced utility-privacy tradeoff about smartphone agents. Our code and benchmark are available at this https URL.</li>
</ul>

<h3>Title: Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery</h3>
<ul>
<li><strong>Authors: </strong>Xiangxu Wang, Tianhong Zhao, Wei Tu, Bowen Zhang, Guanzhou Chen, Jinzhou Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19499">https://arxiv.org/abs/2508.19499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19499">https://arxiv.org/pdf/2508.19499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19499]] Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery(https://arxiv.org/abs/2508.19499)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Origin-Destination (OD) flow matrices are essential for urban mobility analysis, underpinning applications in traffic forecasting, infrastructure planning, and policy design. However, existing methods suffer from two critical limitations: (1) reliance on auxiliary features (e.g., Points of Interest, socioeconomic statistics) that are costly to collect and have limited spatial coverage; and (2) sensitivity to spatial topology, where minor index reordering of urban regions (e.g., census tract relabeling) disrupts structural coherence in generated flows. To address these challenges, we propose Sat2Flow, a latent structure-aware diffusion-based framework that generates structurally coherent OD flows using solely satellite imagery as input. Our approach introduces a multi-kernel encoder to capture diverse regional interactions and employs a permutation-aware diffusion process that aligns latent representations across different regional orderings. Through a joint contrastive training objective that bridges satellite-derived features with OD patterns, combined with equivariant diffusion training that enforces structural consistency, Sat2Flow ensures topological robustness under arbitrary regional reindexing. Experimental results on real-world urban datasets demonstrate that Sat2Flow outperforms both physics-based and data-driven baselines in numerical accuracy while preserving empirical distributions and spatial structures under index permutations. Sat2Flow offers a globally scalable solution for OD flow generation in data-scarce urban environments, eliminating region-specific auxiliary data dependencies while maintaining structural invariance for robust mobility modeling.</li>
</ul>

<h3>Title: Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills</h3>
<ul>
<li><strong>Authors: </strong>David Noever</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19500">https://arxiv.org/abs/2508.19500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19500">https://arxiv.org/pdf/2508.19500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19500]] Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills(https://arxiv.org/abs/2508.19500)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>This paper identifies and analyzes a novel vulnerability class in Model Context Protocol (MCP) based agent systems. The attack chain describes and demonstrates how benign, individually authorized tasks can be orchestrated to produce harmful emergent behaviors. Through systematic analysis using the MITRE ATLAS framework, we demonstrate how 95 agents tested with access to multiple services-including browser automation, financial analysis, location tracking, and code deployment-can chain legitimate operations into sophisticated attack sequences that extend beyond the security boundaries of any individual service. These red team exercises survey whether current MCP architectures lack cross-domain security measures necessary to detect or prevent a large category of compositional attacks. We present empirical evidence of specific attack chains that achieve targeted harm through service orchestration, including data exfiltration, financial manipulation, and infrastructure compromise. These findings reveal that the fundamental security assumption of service isolation fails when agents can coordinate actions across multiple domains, creating an exponential attack surface that grows with each additional capability. This research provides a barebones experimental framework that evaluate not whether agents can complete MCP benchmark tasks, but what happens when they complete them too well and optimize across multiple services in ways that violate human expectations and safety constraints. We propose three concrete experimental directions using the existing MCP benchmark suite.</li>
</ul>

<h3>Title: Learning Game-Playing Agents with Generative Code Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zhiyi Kuang, Ryan Rong, YuCheng Yuan, Allen Nie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19506">https://arxiv.org/abs/2508.19506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19506">https://arxiv.org/pdf/2508.19506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19506]] Learning Game-Playing Agents with Generative Code Optimization(https://arxiv.org/abs/2508.19506)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We present a generative optimization approach for learning game-playing agents, where policies are represented as Python programs and refined using large language models (LLMs). Our method treats decision-making policies as self-evolving code, with current observation as input and an in-game action as output, enabling agents to self-improve through execution traces and natural language feedback with minimal human intervention. Applied to Atari games, our game-playing Python program achieves performance competitive with deep reinforcement learning (RL) baselines while using significantly less training time and much fewer environment interactions. This work highlights the promise of programmatic policy representations for building efficient, adaptable agents capable of complex, long-horizon reasoning.</li>
</ul>

<h3>Title: Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity</h3>
<ul>
<li><strong>Authors: </strong>Alzayat Saleh, Shunsuke Hatano, Mostafa Rahimi Azghadi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19511">https://arxiv.org/abs/2508.19511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19511">https://arxiv.org/pdf/2508.19511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19511]] Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity(https://arxiv.org/abs/2508.19511)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>The automated management of invasive weeds is critical for sustainable agriculture, yet the performance of deep learning models in real-world fields is often compromised by two factors: challenging environmental conditions and the high cost of data annotation. This study tackles both issues through a diagnostic-driven, semi-supervised framework. Using a unique dataset of approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in sugarcane, we first establish strong supervised baselines for classification (ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by interpretability tools, uncovered a pervasive "shadow bias," where models learned to misidentify shadows as vegetation. This diagnostic insight motivated our primary contribution: a semi-supervised pipeline that leverages unlabeled data to enhance model robustness. By training models on a more diverse set of visual information through pseudo-labeling, this framework not only helps mitigate the shadow bias but also provides a tangible boost in recall, a critical metric for minimizing weed escapes in automated spraying systems. To validate our methodology, we demonstrate its effectiveness in a low-data regime on a public crop-weed benchmark. Our work provides a clear and field-tested framework for developing, diagnosing, and improving robust computer vision systems for the complex realities of precision agriculture.</li>
</ul>

<h3>Title: Breaking the Layer Barrier: Remodeling Private Transformer Inference with Hybrid CKKS and MPC</h3>
<ul>
<li><strong>Authors: </strong>Tianshi Xu, Wen-jie Lu, Jiangrui Yu, Chen Yi, Chenqi Lin, Runsheng Wang, Meng Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19525">https://arxiv.org/abs/2508.19525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19525">https://arxiv.org/pdf/2508.19525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19525]] Breaking the Layer Barrier: Remodeling Private Transformer Inference with Hybrid CKKS and MPC(https://arxiv.org/abs/2508.19525)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents an efficient framework for private Transformer inference that combines Homomorphic Encryption (HE) and Secure Multi-party Computation (MPC) to protect data privacy. Existing methods often leverage HE for linear layers (e.g., matrix multiplications) and MPC for non-linear layers (e.g., Softmax activation functions), but the conversion between HE and MPC introduces significant communication costs. The proposed framework, dubbed BLB, overcomes this by breaking down layers into fine-grained operators and further fusing adjacent linear operators, reducing the need for HE/MPC conversions. To manage the increased ciphertext bit width from the fused linear operators, BLB proposes the first secure conversion protocol between CKKS and MPC and enables CKKS-based computation of the fused operators. Additionally, BLB proposes an efficient matrix multiplication protocol for fused computation in Transformers. Extensive evaluations on BERT-base, BERT-large, and GPT2-base show that BLB achieves a $21\times$ reduction in communication overhead compared to BOLT (S\&P'24) and a $2\times$ reduction compared to Bumblebee (NDSS'25), along with latency reductions of $13\times$ and $1.8\times$, respectively, when leveraging GPU acceleration.</li>
</ul>

<h3>Title: MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment</h3>
<ul>
<li><strong>Authors: </strong>Zhiting Gao, Dan Song, Diqiong Jiang, Chao Xue, An-An Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19527">https://arxiv.org/abs/2508.19527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19527">https://arxiv.org/pdf/2508.19527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19527]] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment(https://arxiv.org/abs/2508.19527)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Motion generation is essential for animating virtual characters and embodied agents. While recent text-driven methods have made significant strides, they often struggle with achieving precise alignment between linguistic descriptions and motion semantics, as well as with the inefficiencies of slow, multi-step inference. To address these issues, we introduce TMR++ Aligned Preference Optimization (TAPO), an innovative framework that aligns subtle motion variations with textual modifiers and incorporates iterative adjustments to reinforce semantic grounding. To further enable real-time synthesis, we propose MotionFLUX, a high-speed generation framework based on deterministic rectified flow matching. Unlike traditional diffusion models, which require hundreds of denoising steps, MotionFLUX constructs optimal transport paths between noise distributions and motion spaces, facilitating real-time synthesis. The linearized probability paths reduce the need for multi-step sampling typical of sequential methods, significantly accelerating inference time without sacrificing motion quality. Experimental results demonstrate that, together, TAPO and MotionFLUX form a unified system that outperforms state-of-the-art approaches in both semantic consistency and motion quality, while also accelerating generation speed. The code and pretrained models will be released.</li>
</ul>

<h3>Title: Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding</h3>
<ul>
<li><strong>Authors: </strong>Bowen Sun, Yujun Cai, Ming-Hsuan Yang, Yiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19529">https://arxiv.org/abs/2508.19529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19529">https://arxiv.org/pdf/2508.19529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19529]] Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding(https://arxiv.org/abs/2508.19529)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Discrete diffusion language models have shown strong potential for text generation, yet standard supervised fine-tuning (SFT) misaligns with their semi-autoregressive inference: training randomly masks tokens across the entire response, while inference generates fixed-size blocks sequentially. This mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away from the desired blockwise likelihood. We propose Blockwise SFT, which partitions responses into fixed-size blocks, selects one active block per step for stochastic masking, freezes all preceding tokens, and fully hides future ones. Loss is computed only over the active block, directly mirroring the blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show consistent gains over classical SFT under equal compute or token budgets. Block size consistency studies and ablations confirm that improvements stem from faithful training-inference alignment rather than incidental masking effects. Our results highlight the importance of matching supervision granularity to the decoding procedure in diffusion-based language models.</li>
</ul>

<h3>Title: Alignment with Fill-In-the-Middle for Enhancing Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Houxing Ren, Zimu Lu, Weikang Shi, Haotian Hou, Yunqiao Yang, Ke Wang, Aojun Zhou, Junting Pan, Mingjie Zhan, Hongsheng Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19532">https://arxiv.org/abs/2508.19532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19532">https://arxiv.org/pdf/2508.19532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19532]] Alignment with Fill-In-the-Middle for Enhancing Code Generation(https://arxiv.org/abs/2508.19532)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The code generation capabilities of Large Language Models (LLMs) have advanced applications like tool invocation and problem-solving. However, improving performance in code-related tasks remains challenging due to limited training data that is verifiable with accurate test cases. While Direct Preference Optimization (DPO) has shown promise, existing methods for generating test cases still face limitations. In this paper, we propose a novel approach that splits code snippets into smaller, granular blocks, creating more diverse DPO pairs from the same test cases. Additionally, we introduce the Abstract Syntax Tree (AST) splitting and curriculum training method to enhance the DPO training. Our approach demonstrates significant improvements in code generation tasks, as validated by experiments on benchmark datasets such as HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data are available at this https URL.</li>
</ul>

<h3>Title: CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Nannan Zhu, Yonghao Dong, Teng Wang, Xueqian Li, Shengjun Deng, Yijia Wang, Zheng Hong, Tiantian Geng, Guo Niu, Hanyan Huang, Xiongfei Yao, Shuaiwei Jiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19542">https://arxiv.org/abs/2508.19542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19542">https://arxiv.org/pdf/2508.19542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19542]] CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning(https://arxiv.org/abs/2508.19542)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While multimodal large language models (MLLMs) exhibit strong performance on single-video tasks (e.g., video question answering), their ability across multiple videos remains critically underexplored. However, this capability is essential for real-world applications, including multi-camera surveillance and cross-video procedural learning. To bridge this gap, we present CVBench, the first comprehensive benchmark designed to assess cross-video relational reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning three hierarchical tiers: cross-video object association (identifying shared entities), cross-video event association (linking temporal or causal event chains), and cross-video complex reasoning (integrating commonsense and domain knowledge). Built from five domain-diverse video clusters (e.g., sports, life records), the benchmark challenges models to synthesise information across dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought prompting paradigms. Key findings reveal stark performance gaps: even top models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks, compared to the 91% accuracy of human performance. Crucially, our analysis reveals fundamental bottlenecks inherent in current MLLM architectures, notably deficient inter-video context retention and poor disambiguation of overlapping entities. CVBench establishes a rigorous framework for diagnosing and advancing multi-video reasoning, offering architectural insights for next-generation this http URL data and evaluation code are available at this https URL.</li>
</ul>

<h3>Title: WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization</h3>
<ul>
<li><strong>Authors: </strong>Eduardo Davalos, Yike Zhang, Namrata Srivastava, Yashvitha Thatigotla, Jorge A. Salas, Sara McFadden, Sun-Joo Cho, Amanda Goodwin, Ashwin TS, Gautam Biswas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19544">https://arxiv.org/abs/2508.19544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19544">https://arxiv.org/pdf/2508.19544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19544]] WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization(https://arxiv.org/abs/2508.19544)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>With advancements in AI, new gaze estimation methods are exceeding state-of-the-art (SOTA) benchmarks, but their real-world application reveals a gap with commercial eye-tracking solutions. Factors like model size, inference time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking methods lack sufficient accuracy, in particular due to head movement. To tackle these issues, we introduce We bEyeTrack, a framework that integrates lightweight SOTA gaze estimation models directly in the browser. It incorporates model-based head pose estimation and on-device few-shot learning with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new users, achieving SOTA performance with an error margin of 2.32 cm on GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14. Our open-source code is available at this https URL.</li>
</ul>

<h3>Title: Language Models Identify Ambiguities and Exploit Loopholes</h3>
<ul>
<li><strong>Authors: </strong>Jio Choi, Mohit Bansal, Elias Stengel-Eskin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19546">https://arxiv.org/abs/2508.19546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19546">https://arxiv.org/pdf/2508.19546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19546]] Language Models Identify Ambiguities and Exploit Loopholes(https://arxiv.org/abs/2508.19546)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Studying the responses of large language models (LLMs) to loopholes presents a two-fold opportunity. First, it affords us a lens through which to examine ambiguity and pragmatics in LLMs, since exploiting a loophole requires identifying ambiguity and performing sophisticated pragmatic reasoning. Second, loopholes pose an interesting and novel alignment problem where the model is presented with conflicting goals and can exploit ambiguities to its own advantage. To address these questions, we design scenarios where LLMs are given a goal and an ambiguous user instruction in conflict with the goal, with scenarios covering scalar implicature, structural ambiguities, and power dynamics. We then measure different models' abilities to exploit loopholes to satisfy their given goals as opposed to the goals of the user. We find that both closed-source and stronger open-source models can identify ambiguities and exploit their resulting loopholes, presenting a potential AI safety risk. Our analysis indicates that models which exploit loopholes explicitly identify and reason about both ambiguity and conflicting goals.</li>
</ul>

<h3>Title: MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data</h3>
<ul>
<li><strong>Authors: </strong>Haruki Yonekura, Ren Ozeki, Tatsuya Amano, Hamada Rizk, Hirozumi Yamaguchi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19554">https://arxiv.org/abs/2508.19554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19554">https://arxiv.org/pdf/2508.19554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19554]] MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data(https://arxiv.org/abs/2508.19554)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Modern mobility platforms have stored vast streams of GPS trajectories, temporal metadata, free-form textual notes, and other unstructured data. Privacy statutes such as the GDPR require that any individual's contribution be unlearned on demand, yet retraining deep models from scratch for every request is untenable. We introduce MobText-SISA, a scalable machine-unlearning framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA) training to heterogeneous spatio-temporal data. MobText-SISA first embeds each trip's numerical and linguistic features into a shared latent space, then employs similarity-aware clustering to distribute samples across shards so that future deletions touch only a single constituent model while preserving inter-shard diversity. Each shard is trained incrementally; at inference time, constituent predictions are aggregated to yield the output. Deletion requests trigger retraining solely of the affected shard from its last valid checkpoint, guaranteeing exact unlearning. Experiments on a ten-month real-world mobility log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy, and (ii) consistently outperforms random sharding in both error and convergence speed. These results establish MobText-SISA as a practical foundation for privacy-compliant analytics on multimodal mobility data at urban scale.</li>
</ul>

<h3>Title: MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery</h3>
<ul>
<li><strong>Authors: </strong>Yu-Wei Zhang, Tongju Han, Lipeng Gao, Mingqiang Wei, Hui Liu, Changbao Li, Caiming Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19555">https://arxiv.org/abs/2508.19555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19555">https://arxiv.org/pdf/2508.19555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19555]] MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery(https://arxiv.org/abs/2508.19555)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>This paper presents MonoRelief V2, an end-to-end model designed for directly recovering 2.5D reliefs from single images under complex material and illumination variations. In contrast to its predecessor, MonoRelief V1 [1], which was solely trained on synthetic data, MonoRelief V2 incorporates real data to achieve improved robustness, accuracy and efficiency. To overcome the challenge of acquiring large-scale real-world dataset, we generate approximately 15,000 pseudo real images using a text-to-image generative model, and derive corresponding depth pseudo-labels through fusion of depth and normal predictions. Furthermore, we construct a small-scale real-world dataset (800 samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is then progressively trained on the pseudo-real and real-world datasets. Comprehensive experiments demonstrate its state-of-the-art performance both in depth and normal predictions, highlighting its strong potential for a range of downstream applications. Code is at: this https URL.</li>
</ul>

<h3>Title: Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting</h3>
<ul>
<li><strong>Authors: </strong>Hejia Liu, Mochen Yang, Gediminas Adomavicius</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19563">https://arxiv.org/abs/2508.19563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19563">https://arxiv.org/pdf/2508.19563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19563]] Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting(https://arxiv.org/abs/2508.19563)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are being applied in a wide array of settings, well beyond the typical language-oriented use cases. In particular, LLMs are increasingly used as a plug-and-play method for fitting data and generating predictions. Prior work has shown that LLMs, via in-context learning or supervised fine-tuning, can perform competitively with many tabular supervised learning techniques in terms of predictive performance. However, we identify a critical vulnerability of using LLMs for data fitting -- making changes to data representation that are completely irrelevant to the underlying learning task can drastically alter LLMs' predictions on the same data. For example, simply changing variable names can sway the size of prediction error by as much as 82% in certain settings. Such prediction sensitivity with respect to task-irrelevant variations manifests under both in-context learning and supervised fine-tuning, for both close-weight and open-weight general-purpose LLMs. Moreover, by examining the attention scores of an open-weight LLM, we discover a non-uniform attention pattern: training examples and variable names/values which happen to occupy certain positions in the prompt receive more attention when output tokens are generated, even though different positions are expected to receive roughly the same attention. This partially explains the sensitivity in the presence of task-irrelevant variations. We also consider a state-of-the-art tabular foundation model (TabPFN) trained specifically for data fitting. Despite being explicitly designed to achieve prediction robustness, TabPFN is still not immune to task-irrelevant variations. Overall, despite LLMs' impressive predictive capabilities, currently they lack even the basic level of robustness to be used as a principled data-fitting tool.</li>
</ul>

<h3>Title: Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Sheryl Mathew, N Harshit</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19567">https://arxiv.org/abs/2508.19567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19567">https://arxiv.org/pdf/2508.19567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19567]] Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning(https://arxiv.org/abs/2508.19567)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, fair</a></li>
<li><strong>Abstract: </strong>In reinforcement learning with human feedback (RLHF), reward models can efficiently learn and amplify latent biases within multimodal datasets, which can lead to imperfect policy optimization through flawed reward signals and decreased fairness. Bias mitigation studies have often applied passive constraints, which can fail under causal confounding. Here, we present a counterfactual reward model that introduces causal inference with multimodal representation learning to provide an unsupervised, bias-resilient reward signal. The heart of our contribution is the Counterfactual Trust Score, an aggregated score consisting of four components: (1) counterfactual shifts that decompose political framing bias from topical bias; (2) reconstruction uncertainty during counterfactual perturbations; (3) demonstrable violations of fairness rules for each protected attribute; and (4) temporal reward shifts aligned with dynamic trust measures. We evaluated the framework on a multimodal fake versus true news dataset, which exhibits framing bias, class imbalance, and distributional drift. Following methodologies similar to unsupervised drift detection from representation-based distances [1] and temporal robustness benchmarking in language models [2], we also inject synthetic bias across sequential batches to test robustness. The resulting system achieved an accuracy of 89.12% in fake news detection, outperforming the baseline reward models. More importantly, it reduced spurious correlations and unfair reinforcement signals. This pipeline outlines a robust and interpretable approach to fairness-aware RLHF, offering tunable bias reduction thresholds and increasing reliability in dynamic real-time policy making.</li>
</ul>

<h3>Title: Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era</h3>
<ul>
<li><strong>Authors: </strong>Dawei Li, Yue Huang, Ming Li, Tianyi Zhou, Xiangliang Zhang, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19570">https://arxiv.org/abs/2508.19570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19570">https://arxiv.org/pdf/2508.19570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19570]] Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era(https://arxiv.org/abs/2508.19570)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative models such as Large Language Models, Diffusion Models, and generative adversarial networks have recently revolutionized the creation of synthetic data, offering scalable solutions to data scarcity, privacy, and annotation challenges in data mining. This tutorial introduces the foundations and latest advances in synthetic data generation, covers key methodologies and practical frameworks, and discusses evaluation strategies and applications. Attendees will gain actionable insights into leveraging generative synthetic data to enhance data mining research and practice. More information can be found on our website: this https URL.</li>
</ul>

<h3>Title: DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Luhu Li, Bowen Lin, Mukhtiar Khan, Shujun Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19573">https://arxiv.org/abs/2508.19573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19573">https://arxiv.org/pdf/2508.19573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19573]] DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection(https://arxiv.org/abs/2508.19573)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Anomaly detection in medical images is challenging due to limited annotations and a domain gap compared to natural images. Existing reconstruction methods often rely on frozen pre-trained encoders, which limits adaptation to domain-specific features and reduces localization accuracy. Prototype-based learning offers interpretability and clustering benefits but suffers from prototype collapse, where few prototypes dominate training, harming diversity and generalization. To address this, we propose a unified framework combining a trainable encoder with prototype-guided reconstruction and a novel Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum branch, enables stable domain-adaptive feature learning. A lightweight Prototype Extractor mines informative normal prototypes to guide the decoder via attention for precise reconstruction. Our loss enforces balanced prototype use through diversity constraints and per-prototype normalization, effectively preventing collapse. Experiments on multiple medical imaging benchmarks show significant improvements in representation quality and anomaly localization, outperforming prior methods. Visualizations and prototype assignment analyses further validate the effectiveness of our anti-collapse mechanism and enhanced interpretability.</li>
</ul>

<h3>Title: Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mingxi Fu, Fanglei Fu, Xitong Ling, Huaitian Yuan, Tian Guan, Yonghong He, Lianghui Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19574">https://arxiv.org/abs/2508.19574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19574">https://arxiv.org/pdf/2508.19574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19574]] Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation(https://arxiv.org/abs/2508.19574)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Pathological image segmentation faces numerous challenges, particularly due to ambiguous semantic boundaries and the high cost of pixel-level annotations. Although recent semi-supervised methods based on consistency regularization (e.g., UniMatch) have made notable progress, they mainly rely on perturbation-based consistency within the image modality, making it difficult to capture high-level semantic priors, especially in structurally complex pathology images. To address these limitations, we propose MPAMatch - a novel segmentation framework that performs pixel-level contrastive learning under a multimodal prototype-guided supervision paradigm. The core innovation of MPAMatch lies in the dual contrastive learning scheme between image prototypes and pixel labels, and between text prototypes and pixel labels, providing supervision at both structural and semantic levels. This coarse-to-fine supervisory strategy not only enhances the discriminative capability on unlabeled samples but also introduces the text prototype supervision into segmentation for the first time, significantly improving semantic boundary modeling. In addition, we reconstruct the classic segmentation architecture (TransUNet) by replacing its ViT backbone with a pathology-pretrained foundation model (Uni), enabling more effective extraction of pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND, EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art methods, validating its dual advantages in structural and semantic modeling.</li>
</ul>

<h3>Title: Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Deng, Yuho Lee, Nicole Hee-Yeon Kim, Hyangsuk Min, Taewon Yun, Minjeong Ban, Kim Yul, Hwanjun Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19578">https://arxiv.org/abs/2508.19578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19578">https://arxiv.org/pdf/2508.19578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19578]] Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts(https://arxiv.org/abs/2508.19578)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce HAMLET, a holistic and automated framework for evaluating the long-context comprehension of large language models (LLMs). HAMLET structures source texts into a three-level key-fact hierarchy at root-, branch-, and leaf-levels, and employs query-focused summarization to evaluate how well models recall and faithfully represent information at each level. To validate the reliability of our fully automated pipeline, we conduct a systematic human study, showing that our automatic evaluation achieves over 90% agreement with expert human judgments, while reducing the cost by up to 25 times. HAMLET reveals that LLMs struggle with fine-grained comprehension, especially at the leaf level, and are sensitive to positional effects like the lost-in-the-middle. Analytical queries pose greater challenges than narrative ones, and consistent performance gaps emerge between open-source and proprietary models, as well as across model scales. Our code and dataset are publicly available at this https URL.</li>
</ul>

<h3>Title: ArgCMV: An Argument Summarization Benchmark for the LLM-era</h3>
<ul>
<li><strong>Authors: </strong>Omkar Gurjar, Agam Goyal, Eshwar Chandrasekharan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19580">https://arxiv.org/abs/2508.19580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19580">https://arxiv.org/pdf/2508.19580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19580]] ArgCMV: An Argument Summarization Benchmark for the LLM-era(https://arxiv.org/abs/2508.19580)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Key point extraction is an important task in argument summarization which involves extracting high-level short summaries from arguments. Existing approaches for KP extraction have been mostly evaluated on the popular ArgKP21 dataset. In this paper, we highlight some of the major limitations of the ArgKP21 dataset and demonstrate the need for new benchmarks that are more representative of actual human conversations. Using SoTA large language models (LLMs), we curate a new argument key point extraction dataset called ArgCMV comprising of around 12K arguments from actual online human debates spread across over 3K topics. Our dataset exhibits higher complexity such as longer, co-referencing arguments, higher presence of subjective discourse units, and a larger range of topics over ArgKP21. We show that existing methods do not adapt well to ArgCMV and provide extensive benchmark results by experimenting with existing baselines and latest open source models. This work introduces a novel KP extraction dataset for long-context online discussions, setting the stage for the next generation of LLM-driven summarization research.</li>
</ul>

<h3>Title: Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction</h3>
<ul>
<li><strong>Authors: </strong>Dat Nguyen Cong, Hieu Tran Bao, Hoang Thanh-Tung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19581">https://arxiv.org/abs/2508.19581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19581">https://arxiv.org/pdf/2508.19581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19581]] Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction(https://arxiv.org/abs/2508.19581)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have gained prominence as state-of-the-art techniques for synthesizing images and videos, particularly due to their ability to scale effectively with large datasets. Recent studies have uncovered that these extensive datasets often contain mistakes from manual labeling processes. However, the extent to which such errors compromise the generative capabilities and controllability of diffusion models is not well studied. This paper introduces Score-based Discriminator Correction (SBDC), a guidance technique for aligning noisy pre-trained conditional diffusion models. The guidance is built on discriminator training using adversarial loss, drawing on prior noise detection techniques to assess the authenticity of each sample. We further show that limiting the usage of our guidance to the early phase of the generation process leads to better performance. Our method is computationally efficient, only marginally increases inference time, and does not require retraining diffusion models. Experiments on different noise settings demonstrate the superiority of our method over previous state-of-the-art methods.</li>
</ul>

<h3>Title: Towards stable AI systems for Evaluating Arabic Pronunciations</h3>
<ul>
<li><strong>Authors: </strong>Hadi Zaatiti, Hatem Hajri, Osama Abdullah, Nader Masmoudi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19587">https://arxiv.org/abs/2508.19587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19587">https://arxiv.org/pdf/2508.19587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19587]] Towards stable AI systems for Evaluating Arabic Pronunciations(https://arxiv.org/abs/2508.19587)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and sentence-level transcription, yet struggle to classify isolated letters. In this study, we show that this phoneme-level task, crucial for language learning, speech therapy, and phonetic research, is challenging because isolated letters lack co-articulatory cues, provide no lexical context, and last only a few hundred milliseconds. Recogniser systems must therefore rely solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic (pharyngealized) consonants and other sounds with no close analogues in many languages. This study introduces a diverse, diacritised corpus of isolated Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models achieve only 35% accuracy on it. Training a lightweight neural network on wav2vec embeddings raises performance to 65%. However, adding a small amplitude perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we apply adversarial training, limiting the noisy-speech drop to 9% while preserving clean-speech accuracy. We detail the corpus, training pipeline, and evaluation protocol, and release, on demand, data and code for reproducibility. Finally, we outline future work extending these methods to word- and sentence-level frameworks, where precise letter pronunciation remains critical.</li>
</ul>

<h3>Title: Delta-Audit: Explaining What Changes When Models Change</h3>
<ul>
<li><strong>Authors: </strong>Arshia Hemmat, Afsaneh Fatemi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19589">https://arxiv.org/abs/2508.19589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19589">https://arxiv.org/pdf/2508.19589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19589]] Delta-Audit: Explaining What Changes When Models Change(https://arxiv.org/abs/2508.19589)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Model updates (new hyperparameters, kernels, depths, solvers, or data) change performance, but the \emph{reason} often remains opaque. We introduce \textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic framework that explains \emph{what changed} between versions $A$ and $B$ by differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10, Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error, DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise, baseline sensitivity, grouped occlusion). Instantiated via fast occlusion/clamping in standardized space with a class-anchored margin and baseline averaging, we audit 45 settings: five classical families (Logistic Regression, SVC, Random Forests, Gradient Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B pairs per family. \textbf{Findings.} Inductive-bias changes yield large, behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer: BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits: BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC \texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a lightweight update audit that complements accuracy by distinguishing benign changes from behaviourally meaningful or risky reliance shifts.</li>
</ul>

<h3>Title: Generalizing Monocular 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Abhinav Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19593">https://arxiv.org/abs/2508.19593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19593">https://arxiv.org/pdf/2508.19593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19593]] Generalizing Monocular 3D Object Detection(https://arxiv.org/abs/2508.19593)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Monocular 3D object detection (Mono3D) is a fundamental computer vision task that estimates an object's class, 3D position, dimensions, and orientation from a single image. Its applications, including autonomous driving, augmented reality, and robotics, critically rely on accurate 3D environmental understanding. This thesis addresses the challenge of generalizing Mono3D models to diverse scenarios, including occlusions, datasets, object sizes, and camera parameters. To enhance occlusion robustness, we propose a mathematically differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we explore depth equivariant (DEVIANT) backbones. We address the issue of large object detection, demonstrating that it's not solely a data imbalance or receptive field problem but also a noise sensitivity issue. To mitigate this, we introduce a segmentation-based approach in bird's-eye view with dice loss (SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D models to unseen camera heights and improve Mono3D generalization in such out-of-distribution settings.</li>
</ul>

<h3>Title: Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jun Bai, Minghao Tong, Yang Liu, Zixia Jia, Zilong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19594">https://arxiv.org/abs/2508.19594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19594">https://arxiv.org/pdf/2508.19594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19594]] Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs(https://arxiv.org/abs/2508.19594)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Context faithfulness is essential for reliable reasoning in context-dependent scenarios. However, large language models often struggle to ground their outputs in the provided context, resulting in irrelevant responses. Inspired by the emergent expert specialization observed in mixture-of-experts architectures, this work investigates whether certain experts exhibit specialization in context utilization, offering a potential pathway toward targeted optimization for improved context faithfulness. To explore this, we propose Router Lens, a method that accurately identifies context-faithful experts. Our analysis reveals that these experts progressively amplify attention to relevant contextual information, thereby enhancing context grounding. Building on this insight, we introduce Context-faithful Expert Fine-Tuning (CEFT), a lightweight optimization approach that selectively fine-tunes context-faithful experts. Experiments across a wide range of benchmarks and models demonstrate that CEFT matches or surpasses the performance of full fine-tuning while being significantly more efficient.</li>
</ul>

<h3>Title: Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning</h3>
<ul>
<li><strong>Authors: </strong>Zhiwei Li, Yong Hu, Wenqing Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19598">https://arxiv.org/abs/2508.19598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19598">https://arxiv.org/pdf/2508.19598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19598]] Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning(https://arxiv.org/abs/2508.19598)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The functionality of Large Language Model (LLM) agents is primarily determined by two capabilities: action planning and answer summarization. The former, action planning, is the core capability that dictates an agent's performance. However, prevailing training paradigms employ end-to-end, multi-objective optimization that jointly trains both capabilities. This paradigm faces two critical challenges: imbalanced optimization objective allocation and scarcity of verifiable data, making it difficult to enhance the agent's planning capability. To address these challenges, we propose Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that decouples the training process to enable a focused, single-objective optimization of the planning module. Crucially, RLTR introduces a reward signal based on tool-use completeness to directly evaluate the quality of tool invocation sequences. This method offers a more direct and reliable training signal than assessing the final response content, thereby obviating the need for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12% improvement in planning performance compared to end-to-end baselines. Moreover, this enhanced planning capability, in turn, translates to a 5%-6% increase in the final response quality of the overall agent system.</li>
</ul>

<h3>Title: Quantization Robustness to Input Degradations for Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Toghrul Karimov, Hassan Imani, Allan Kazakov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19600">https://arxiv.org/abs/2508.19600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19600">https://arxiv.org/pdf/2508.19600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19600]] Quantization Robustness to Input Degradations for Object Detection(https://arxiv.org/abs/2508.19600)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Post-training quantization (PTQ) is crucial for deploying efficient object detection models, like YOLO, on resource-constrained devices. However, the impact of reduced precision on model robustness to real-world input degradations such as noise, blur, and compression artifacts is a significant concern. This paper presents a comprehensive empirical study evaluating the robustness of YOLO models (nano to extra-large scales) across multiple precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8 (TensorRT). We introduce and evaluate a degradation-aware calibration strategy for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix of clean and synthetically degraded images. Models were benchmarked on the COCO dataset under seven distinct degradation conditions (including various types and levels of noise, blur, low contrast, and JPEG compression) and a mixed-degradation scenario. Results indicate that while Static INT8 TensorRT engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop (~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did not yield consistent, broad improvements in robustness over standard clean-data calibration across most models and degradations. A notable exception was observed for larger model scales under specific noise conditions, suggesting model capacity may influence the efficacy of this calibration approach. These findings highlight the challenges in enhancing PTQ robustness and provide insights for deploying quantized detectors in uncontrolled environments. All code and evaluation tables are available at this https URL.</li>
</ul>

<h3>Title: IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Qizhe Fan, Chaoyu Liu, Zhonghua Qiao, Xiaoqin Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19604">https://arxiv.org/abs/2508.19604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19604">https://arxiv.org/pdf/2508.19604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19604]] IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation(https://arxiv.org/abs/2508.19604)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Domain Generalized Semantic Segmentation (DGSS) focuses on training a model using labeled data from a source domain, with the goal of achieving robust generalization to unseen target domains during inference. A common approach to improve generalization is to augment the source domain with synthetic data generated by diffusion models (DMs). However, the generated images often contain structural or semantic defects due to training imperfections. Training segmentation models with such flawed data can lead to performance degradation and error accumulation. To address this issue, we propose to integrate inverse evolution layers (IELs) into the generative process. IELs are designed to highlight spatial discontinuities and semantic inconsistencies using Laplacian-based priors, enabling more effective filtering of undesirable generative patterns. Based on this mechanism, we introduce IELDM, an enhanced diffusion-based data augmentation framework that can produce higher-quality images. Furthermore, we observe that the defect-suppression capability of IELs can also benefit the segmentation network by suppressing artifact propagation. Based on this insight, we embed IELs into the decoder of the DGSS model and propose IELFormer to strengthen generalization capability in cross-domain scenarios. To further strengthen the model's semantic consistency across scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module, which performs frequency-domain analysis to achieve structured integration of multi-resolution features, thereby improving cross-scale coherence. Extensive experiments on benchmark datasets demonstrate that our approach achieves superior generalization performance compared to existing methods.</li>
</ul>

<h3>Title: FinCast: A Foundation Model for Financial Time-Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Zhuohang Zhu, Haodong Chen, Qiang Qu, Vera Chung</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19609">https://arxiv.org/abs/2508.19609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19609">https://arxiv.org/pdf/2508.19609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19609]] FinCast: A Foundation Model for Financial Time-Series Forecasting(https://arxiv.org/abs/2508.19609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Financial time-series forecasting is critical for maintaining economic stability, guiding informed policymaking, and promoting sustainable investment practices. However, it remains challenging due to various underlying pattern shifts. These shifts arise primarily from three sources: temporal non-stationarity (distribution changes over time), multi-domain diversity (distinct patterns across financial domains such as stocks, commodities, and futures), and varying temporal resolutions (patterns differing across per-second, hourly, daily, or weekly indicators). While recent deep learning methods attempt to address these complexities, they frequently suffer from overfitting and typically require extensive domain-specific fine-tuning. To overcome these limitations, we introduce FinCast, the first foundation model specifically designed for financial time-series forecasting, trained on large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot performance, effectively capturing diverse patterns without domain-specific fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate that FinCast surpasses existing state-of-the-art methods, highlighting its strong generalization capabilities.</li>
</ul>

<h3>Title: ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation</h3>
<ul>
<li><strong>Authors: </strong>Chenzhi Liu, Mahsa Baktashmotlagh, Yanran Tang, Zi Huang, Ruihong Qiu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19613">https://arxiv.org/abs/2508.19613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19613">https://arxiv.org/pdf/2508.19613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19613]] ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation(https://arxiv.org/abs/2508.19613)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Estimating model accuracy on unseen, unlabeled datasets is crucial for real-world machine learning applications, especially under distribution shifts that can degrade performance. Existing methods often rely on predicted class probabilities (softmax scores) or data similarity metrics. While softmax-based approaches benefit from representing predictions on the standard simplex, compressing logits into probabilities leads to information loss. Meanwhile, similarity-based methods can be computationally expensive and domain-specific, limiting their broader applicability. In this paper, we introduce ALSA (Anchors in Logit Space for Accuracy estimation), a novel framework that preserves richer information by operating directly in the logit space. Building on theoretical insights and empirical observations, we demonstrate that the aggregation and distribution of logits exhibit a strong correlation with the predictive performance of the model. To exploit this property, ALSA employs an anchor-based modeling strategy: multiple learnable anchors are initialized in logit space, each assigned an influence function that captures subtle variations in the logits. This allows ALSA to provide robust and accurate performance estimates across a wide range of distribution shifts. Extensive experiments on vision, language, and graph benchmarks demonstrate ALSA's superiority over both softmax- and similarity-based baselines. Notably, ALSA's robustness under significant distribution shifts highlights its potential as a practical tool for reliable model evaluation.</li>
</ul>

<h3>Title: LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Yang Sun, Lixin Zou, Dan Luo, Zhiyong Xie, Long Zhang, Liming Dong, Yunwei Zhao, Xixun Lin, Yanxiong Lu, Chenliang Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19614">https://arxiv.org/abs/2508.19614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19614">https://arxiv.org/pdf/2508.19614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19614]] LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation(https://arxiv.org/abs/2508.19614)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) incorporates external knowledge into large language models (LLMs), improving their adaptability to downstream tasks and enabling information updates. Surprisingly, recent empirical evidence demonstrates that injecting noise into retrieved relevant documents paradoxically facilitates exploitation of external knowledge and improves generation quality. Although counterintuitive and challenging to apply in practice, this phenomenon enables granular control and rigorous analysis of how LLMs integrate external knowledge. Therefore, in this paper, we intervene on noise injection and establish a layer-specific functional demarcation within the LLM: shallow layers specialize in local context modeling, intermediate layers focus on integrating long-range external factual knowledge, and deeper layers primarily rely on parametric internal knowledge. Building on this insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that directly combines representations from an intermediate layer with final-layer decoding outputs to fully exploit the external factual knowledge. To identify the optimal intermediate layer, we introduce an internal knowledge score (IKS) criterion that selects the layer with the lowest IKS value in the latter half of layers. Experimental results across multiple benchmarks demonstrate that LFD helps RAG systems more effectively surface retrieved context knowledge with minimal cost.</li>
</ul>

<h3>Title: Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning</h3>
<ul>
<li><strong>Authors: </strong>Tiandi Ye, Wenyan Liu, Kai Yao, Lichun Li, Shangchao Su, Cen Chen, Xiang Li, Shan Yin, Ming Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19621">https://arxiv.org/abs/2508.19621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19621">https://arxiv.org/pdf/2508.19621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19621]] Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning(https://arxiv.org/abs/2508.19621)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a privacy-preserving machine learning paradigm that enables collaborative model training across multiple distributed clients without disclosing their raw data. Personalized federated learning (pFL) has gained increasing attention for its ability to address data heterogeneity. However, most existing pFL methods assume that each client's data follows a single distribution and learn one client-level personalized model for each client. This assumption often fails in practice, where a single client may possess data from multiple sources or domains, resulting in significant intra-client heterogeneity and suboptimal performance. To tackle this challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework based on visual prompt tuning. Specifically, we formulate instance-wise prompt generation from a Bayesian perspective and model the prompt posterior as an implicit distribution to capture diverse visual semantics. We derive a variational training objective under the semi-implicit variational inference framework. Extensive experiments on benchmark datasets demonstrate that pFedBayesPT consistently outperforms existing pFL methods under both feature and label heterogeneity settings.</li>
</ul>

<h3>Title: Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Sun, Zhen Yu, Siyuan Yan, Jason J. Ong, Zongyuan Ge, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19626">https://arxiv.org/abs/2508.19626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19626">https://arxiv.org/pdf/2508.19626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19626]] Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model(https://arxiv.org/abs/2508.19626)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Skin images from real-world clinical practice are often limited, resulting in a shortage of training data for deep-learning models. While many studies have explored skin image synthesis, existing methods often generate low-quality images and lack control over the lesion's location and type. To address these limitations, we present LF-VAR, a model leveraging quantified lesion measurement scores and lesion type labels to guide the clinically relevant and controllable synthesis of skin images. It enables controlled skin synthesis with specific lesion characteristics based on language prompts. We train a multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to encode images into discrete latent representations for structured tokenization. Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized representations facilitates image synthesis. Lesion measurement from the lesion region and types as conditional embeddings are integrated to enhance synthesis fidelity. Our method achieves the best overall FID score (average 0.74) among seven lesion types, improving upon the previous state-of-the-art (SOTA) by 6.3%. The study highlights our controllable skin synthesis model's effectiveness in generating high-fidelity, clinically relevant synthetic skin images. Our framework code is available at this https URL.</li>
</ul>

<h3>Title: A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection</h3>
<ul>
<li><strong>Authors: </strong>Chong Tian, Qirong Ho, Xiuying Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19633">https://arxiv.org/abs/2508.19633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19633">https://arxiv.org/pdf/2508.19633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19633]] A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection(https://arxiv.org/abs/2508.19633)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Rapid LLM advancements heighten fake news risks by enabling the automatic generation of increasingly sophisticated misinformation. Previous detection methods, including fine-tuned small models or LLM-based detectors, often struggle with its dynamically evolving nature. In this work, we propose a novel framework called the Symbolic Adversarial Learning Framework (SALF), which implements an adversarial training paradigm by an agent symbolic learning optimization process, rather than relying on numerical updates. SALF introduces a paradigm where the generation agent crafts deceptive narratives, and the detection agent uses structured debates to identify logical and factual flaws for detection, and they iteratively refine themselves through such adversarial interactions. Unlike traditional neural updates, we represent agents using agent symbolic learning, where learnable weights are defined by agent prompts, and simulate back-propagation and gradient descent by operating on natural language representations of weights, loss, and gradients. Experiments on two multilingual benchmark datasets demonstrate SALF's effectiveness, showing it generates sophisticated fake news that degrades state-of-the-art detection performance by up to 53.4% in Chinese and 34.2% in English on average. SALF also refines detectors, improving detection of refined content by up to 7.7%. We hope our work inspires further exploration into more robust, adaptable fake news detection systems.</li>
</ul>

<h3>Title: Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses</h3>
<ul>
<li><strong>Authors: </strong>Lincan Li, Bolin Shen, Chenxi Zhao, Yuxiang Sun, Kaixiang Zhao, Shirui Pan, Yushun Dong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19641">https://arxiv.org/abs/2508.19641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19641">https://arxiv.org/pdf/2508.19641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19641]] Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses(https://arxiv.org/abs/2508.19641)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, steal</a></li>
<li><strong>Abstract: </strong>Graph-structured data, which captures non-Euclidean relationships and interactions between entities, is growing in scale and complexity. As a result, training state-of-the-art graph machine learning (GML) models have become increasingly resource-intensive, turning these models and data into invaluable Intellectual Property (IP). To address the resource-intensive nature of model training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an efficient solution by leveraging third-party cloud services for model development and management. However, deploying such models in GMLaaS also exposes them to potential threats from attackers. Specifically, while the APIs within a GMLaaS system provide interfaces for users to query the model and receive outputs, they also allow attackers to exploit and steal model functionalities or sensitive training data, posing severe threats to the safety of these GML models and the underlying graph data. To address these challenges, this survey systematically introduces the first taxonomy of threats and defenses at the level of both GML model and graph-structured data. Such a tailored taxonomy facilitates an in-depth understanding of GML IP protection. Furthermore, we present a systematic evaluation framework to assess the effectiveness of IP protection methods, introduce a curated set of benchmark datasets across various domains, and discuss their application scopes and future challenges. Finally, we establish an open-sourced versatile library named PyGIP, which evaluates various attack and defense techniques in GMLaaS scenarios and facilitates the implementation of existing benchmark methods. The library resource can be accessed at: this https URL. We believe this survey will play a fundamental role in intellectual property protection for GML and provide practical recipes for the GML community.</li>
</ul>

<h3>Title: UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Bikash Kumar Badatya, Vipul Baghel, Ravi Hegde</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19647">https://arxiv.org/abs/2508.19647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19647">https://arxiv.org/pdf/2508.19647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19647]] UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks(https://arxiv.org/abs/2508.19647)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fine-grained action localization in untrimmed sports videos presents a significant challenge due to rapid and subtle motion transitions over short durations. Existing supervised and weakly supervised solutions often rely on extensive annotated datasets and high-capacity models, making them computationally intensive and less adaptable to real-world scenarios. In this work, we introduce a lightweight and unsupervised skeleton-based action localization pipeline that leverages spatio-temporal graph neural representations. Our approach pre-trains an Attention-based Spatio-Temporal Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with blockwise partitions, enabling it to learn intrinsic motion dynamics without any manual labeling. At inference, we define a novel Action Dynamics Metric (ADM), computed directly from low-dimensional ASTGCN embeddings, which detects motion boundaries by identifying inflection points in its curvature profile. Our method achieves a mean Average Precision (mAP) of 82.66% and average localization latency of 29.09 ms on the DSV Diving dataset, matching state-of-the-art supervised performance while maintaining computational efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving footage without retraining, demonstrating its practical applicability for lightweight, real-time action analysis systems in embedded or dynamic environments.</li>
</ul>

<h3>Title: IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising</h3>
<ul>
<li><strong>Authors: </strong>Dongjin Kim, Jaekyun Ko, Muhammad Kashif Ali, Tae Hyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19649">https://arxiv.org/abs/2508.19649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19649">https://arxiv.org/pdf/2508.19649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19649]] IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising(https://arxiv.org/abs/2508.19649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Image denoising is a fundamental challenge in computer vision, with applications in photography and medical imaging. While deep learning-based methods have shown remarkable success, their reliance on specific noise distributions limits generalization to unseen noise types and levels. Existing approaches attempt to address this with extensive training data and high computational resources but they still suffer from overfitting. To address these issues, we conduct image denoising by utilizing dynamically generated kernels via efficient operations. This approach helps prevent overfitting and improves resilience to unseen noise. Specifically, our method leverages a Feature Extraction Module for robust noise-invariant features, Global Statistics and Local Correlation Modules to capture comprehensive noise characteristics and structural correlations. The Kernel Prediction Module then employs these cues to produce pixel-wise varying kernels adapted to local structures, which are then applied iteratively for denoising. This ensures both efficiency and superior restoration quality. Despite being trained on single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse noise types and levels, demonstrating the promise of iterative dynamic filtering for practical image denoising.</li>
</ul>

<h3>Title: Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications</h3>
<ul>
<li><strong>Authors: </strong>Matthias Höfflin, Jürgen Wassner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19654">https://arxiv.org/abs/2508.19654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19654">https://arxiv.org/pdf/2508.19654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19654]] Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications(https://arxiv.org/abs/2508.19654)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Spiking Neural Networks (SNNs), inspired by biological intelligence, have long been considered inherently energy-efficient, making them attractive for resource-constrained domains such as space applications. However, recent comparative studies with conventional Artificial Neural Networks (ANNs) have begun to question this reputation, especially for digital implementations. This work investigates SNNs for multi-output regression, specifically 3-D satellite position estimation from monocular images, and compares hardware-aware and hardware-agnostic energy estimation methods. The proposed SNN, trained using the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the final layer, achieves comparable Mean Squared Error (MSE) to a reference Convolutional Neural Network (CNN) on a photorealistic satellite dataset. Energy analysis shows that while hardware-agnostic methods predict a consistent 50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals that significant energy savings are realized only on neuromorphic hardware and with high input sparsity. The influence of dark pixel ratio on energy consumption is quantified, emphasizing the impact of data characteristics and hardware assumptions. These findings highlight the need for transparent evaluation methods and explicit disclosure of underlying assumptions to ensure fair comparisons of neural network energy efficiency.</li>
</ul>

<h3>Title: SCAR: A Characterization Scheme for Multi-Modal Dataset</h3>
<ul>
<li><strong>Authors: </strong>Ri Su, Zhao Chen, Caleb Chen Cao, Nan Tang, Lei Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19659">https://arxiv.org/abs/2508.19659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19659">https://arxiv.org/pdf/2508.19659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19659]] SCAR: A Characterization Scheme for Multi-Modal Dataset(https://arxiv.org/abs/2508.19659)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models exhibit remarkable generalization across diverse tasks, largely driven by the characteristics of their training data. Recent data-centric methods like pruning and compression aim to optimize training but offer limited theoretical insight into how data properties affect generalization, especially the data characteristics in sample scaling. Traditional perspectives further constrain progress by focusing predominantly on data quantity and training efficiency, often overlooking structural aspects of data quality. In this study, we introduce SCAR, a principled scheme for characterizing the intrinsic structural properties of datasets across four key measures: Scale, Coverage, Authenticity, and Richness. Unlike prior data-centric measures, SCAR captures stable characteristics that remain invariant under dataset scaling, providing a robust and general foundation for data understanding. Leveraging these structural properties, we introduce Foundation Data-a minimal subset that preserves the generalization behavior of the full dataset without requiring model-specific retraining. We model single-modality tasks as step functions and estimate the distribution of the foundation data size to capture step-wise generalization bias across modalities in the target multi-modal dataset. Finally, we develop a SCAR-guided data completion strategy based on this generalization bias, which enables efficient, modality-aware expansion of modality-specific characteristics in multimodal datasets. Experiments across diverse multi-modal datasets and model architectures validate the effectiveness of SCAR in predicting data utility and guiding data acquisition. Code is available at this https URL.</li>
</ul>

<h3>Title: A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Weicheng Liao, Zan Chen, Jianyang Xie, Yalin Zheng, Yuhui Ma, Yitian Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19664">https://arxiv.org/abs/2508.19664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19664">https://arxiv.org/pdf/2508.19664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19664]] A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement(https://arxiv.org/abs/2508.19664)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics by providing a comprehensive view of the retina. However, it often suffers from quality-degrading factors such as blurring and uneven illumination, which obscure fine details and mask pathological information. While numerous retinal image enhancement methods have been proposed for other fundus imageries, they often fail to address the unique requirements in UWF, particularly the need to preserve pathological details. In this paper, we propose a novel frequency-aware self-supervised learning method for UWF image enhancement. It incorporates frequency-decoupled image deblurring and Retinex-guided illumination compensation modules. An asymmetric channel integration operation is introduced in the former module, so as to combine global and local views by leveraging high- and low-frequency information, ensuring the preservation of fine and broader structural details. In addition, a color preservation unit is proposed in the latter Retinex-based module, to provide multi-scale spatial and frequency information, enabling accurate illumination estimation and correction. Experimental results demonstrate that the proposed work not only enhances visualization quality but also improves disease diagnosis performance by restoring and correcting fine local details and uneven intensity. To the best of our knowledge, this work is the first attempt for UWF image enhancement, offering a robust and clinically valuable tool for improving retinal disease management.</li>
</ul>

<h3>Title: Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design</h3>
<ul>
<li><strong>Authors: </strong>Giovanni Pollo, Andrei Mihai Albu, Alessio Burrello, Daniele Jahier Pagliari, Cristian Tesconi, Loris Panaro, Dario Soldi, Fabio Autieri, Sara Vinco</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19665">https://arxiv.org/abs/2508.19665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19665">https://arxiv.org/pdf/2508.19665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19665]] Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design(https://arxiv.org/abs/2508.19665)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, robust</a></li>
<li><strong>Abstract: </strong>The recent advancements of the automotive sector demand robust co-simulation methodologies that enable early validation and seamless integration across hardware and software domains. However, the lack of standardized interfaces and the dominance of proprietary simulation platforms pose significant challenges to collaboration, scalability, and IP protection. To address these limitations, this paper presents an approach for automatically wrapping SystemC models by using the Functional Mock-up Interface (FMI) standard. This method combines the modeling accuracy and fast time-to-market of SystemC with the interoperability and encapsulation benefits of FMI, enabling secure and portable integration of embedded components into co-simulation workflows. We validate the proposed methodology on real-world case studies, demonstrating its effectiveness with complex designs.</li>
</ul>

<h3>Title: Survey of Specialized Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Chenghan Yang, Ruiyu Zhao, Yang Liu, Ling Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19667">https://arxiv.org/abs/2508.19667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19667">https://arxiv.org/pdf/2508.19667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19667]] Survey of Specialized Large Language Model(https://arxiv.org/abs/2508.19667)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development. This survey systematically examines this progression across healthcare, finance, legal, and technical domains. Besides the wide use of specialized LLMs, technical breakthrough such as the emergence of domain-native designs beyond fine-tuning, growing emphasis on parameter efficiency through sparse computation and quantization, increasing integration of multimodal capabilities and so on are applied to recent LLM agent. Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks. The survey further highlights the implications for E-Commerce field to fill gaps in the field.</li>
</ul>

<h3>Title: Safety Alignment Should Be Made More Than Just A Few Attention Heads</h3>
<ul>
<li><strong>Authors: </strong>Chao Huang, Zefeng Zhang, Juewei Yue, Quangang Li, Chuang Zhang, Tingwen Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19697">https://arxiv.org/abs/2508.19697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19697">https://arxiv.org/pdf/2508.19697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19697]] Safety Alignment Should Be Made More Than Just A Few Attention Heads(https://arxiv.org/abs/2508.19697)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Current safety alignment for large language models(LLMs) continues to present vulnerabilities, given that adversarial prompting can effectively bypass their safety this http URL investigation shows that these safety mechanisms predominantly depend on a limited subset of attention heads: removing or ablating these heads can severely compromise model safety. To identify and evaluate these safety-critical components, we introduce RDSHA, a targeted ablation method that leverages the model's refusal direction to pinpoint attention heads mostly responsible for safety behaviors. Further analysis shows that existing jailbreak attacks exploit this concentration by selectively bypassing or manipulating these critical attention heads. To address this issue, we propose AHD, a novel training strategy designed to promote the distributed encoding of safety-related behaviors across numerous attention heads. Experimental results demonstrate that AHD successfully distributes safety-related capabilities across more attention heads. Moreover, evaluations under several mainstream jailbreak attacks show that models trained with AHD exhibit considerably stronger safety robustness, while maintaining overall functional utility.</li>
</ul>

<h3>Title: Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators</h3>
<ul>
<li><strong>Authors: </strong>V. S. Usatyuk, D. A. Sapozhnikov, S. I. Egorov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IT, math.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19698">https://arxiv.org/abs/2508.19698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19698">https://arxiv.org/pdf/2508.19698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19698]] Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators(https://arxiv.org/abs/2508.19698)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, biometric, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rapid advance of deep generative models such as GANs and diffusion networks now produces images that are virtually indistinguishable from genuine photographs, undermining media forensics and biometric security. Supervised detectors quickly lose effectiveness on unseen generators or after adversarial post-processing, while existing unsupervised methods that rely on low-level statistical cues remain fragile. We introduce a physics-inspired, model-agnostic detector that treats synthetic-image identification as a community-detection problem on a sparse weighted graph. Image features are first extracted with pretrained CNNs and reduced to 32 dimensions, each feature vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities are transformed into edge couplings calibrated at the Nishimori temperature, producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum exhibits a characteristic gap when genuine community structure (real images) is present. Synthetic images violate the Nishimori symmetry and therefore lack such gaps. We validate the approach on binary tasks cat versus dog and male versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic counterparts generated by GANs and diffusion models. Without any labeled synthetic data or retraining of the feature extractor, the detector achieves over 94% accuracy. Spectral analysis shows multiple well separated gaps for real image sets and a collapsed spectrum for generated ones. Our contributions are threefold: a novel LDPC graph construction that embeds deep image features, an analytical link between Nishimori temperature RBIM and the Bethe-Hessian spectrum providing a Bayes optimal detection criterion; and a practical, unsupervised synthetic image detector robust to new generative architectures. Future work will extend the framework to video streams and multi-class anomaly detection.</li>
</ul>

<h3>Title: LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yupeng Zhang, Dezhi Zheng, Ping Lu, Han Zhang, Lei Wang, Liping xiang, Cheng Luo, Kaijun Deng, Xiaowen Fu, Linlin Shen, Jinbao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19699">https://arxiv.org/abs/2508.19699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19699">https://arxiv.org/pdf/2508.19699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19699]] LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation(https://arxiv.org/abs/2508.19699)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation for 3D scenes, offering both high-fidelity reconstruction and efficient rendering. However, 3DGS lacks 3D segmentation ability, which limits its applicability in tasks that require scene understanding. The identification and isolating of specific object components is crucial. To address this limitation, we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments the Gaussian representation with object this http URL introduces cross-view consistent semantic masks for 3D Gaussians and employs a novel Occlusion Analysis Model to avoid overfitting occlusion during optimization, Main Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian Projection Filter to avoid Gaussian label conflict. Our approach achieves effective decoupling of Gaussian representations and refines the 3DGS optimization process through a random region sampling strategy, significantly improving efficiency. Extensive experiments demonstrate that LabelGS outperforms previous state-of-the-art methods, including Feature-3DGS, in the 3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code will be at this https URL.</li>
</ul>

<h3>Title: FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Qiang Hu, Ying Zhou, Gepeng Ji, Nick Barnes, Qiang Li, Zhiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19705">https://arxiv.org/abs/2508.19705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19705">https://arxiv.org/pdf/2508.19705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19705]] FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation(https://arxiv.org/abs/2508.19705)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Existing video polyp segmentation (VPS) paradigms usually struggle to balance between spatiotemporal modeling and domain generalization, limiting their applicability in real clinical scenarios. To embrace this challenge, we recast the VPS task as a track-by-detect paradigm that leverages the spatial contexts captured by the image polyp segmentation (IPS) model while integrating the temporal modeling capabilities of segment anything model 2 (SAM2). However, during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error accumulation, resulting in a snowball effect that compromises segmentation stability. We mitigate this issue by repurposing SAM2 as a video polyp segmenter with two training-free modules. In particular, the intra-association filtering module eliminates spatial inaccuracies originating from the detecting stage, reducing false positives. The inter-association refinement module adaptively updates the memory bank to prevent error propagation over time, enhancing temporal coherence. Both modules work synergistically to stabilize SAM2, achieving cutting-edge performance in both in-domain and out-of-domain scenarios. Furthermore, we demonstrate the robust tracking capabilities of FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential reliable clinical analysis.</li>
</ul>

<h3>Title: Metric spaces of walks and Lipschitz duality on graphs</h3>
<ul>
<li><strong>Authors: </strong>R. Arnau, A. González Cortés, E.A. Sánchez Pérez, S. Sanjuan</a></li>
<li><strong>Subjects: </strong>cs.LG, math.FA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19709">https://arxiv.org/abs/2508.19709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19709">https://arxiv.org/pdf/2508.19709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19709]] Metric spaces of walks and Lipschitz duality on graphs(https://arxiv.org/abs/2508.19709)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the metric structure of walks on graphs, understood as Lipschitz sequences. To this end, a weighted metric is introduced to handle sequences, enabling the definition of distances between walks based on stepwise vertex distances and weighted norms. We analyze the main properties of these metric spaces, which provides the foundation for the analysis of weaker forms of instruments to measure relative distances between walks: proximities. We provide some representation formulas for such proximities under different assumptions and provide explicit constructions for these cases. The resulting metric framework allows the use of classical tools from metric modeling, such as the extension of Lipschitz functions from subspaces of walks, which permits extending proximity functions while preserving fundamental properties via the mentioned representations. Potential applications include the estimation of proximities and the development of reinforcement learning strategies based on exploratory walks, offering a robust approach to Lipschitz regression on network structures.</li>
</ul>

<h3>Title: Addressing Deepfake Issue in Selfie banking through camera based authentication</h3>
<ul>
<li><strong>Authors: </strong>Subhrojyoti Mukherjee, Manoranjan Mohanty</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19714">https://arxiv.org/abs/2508.19714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19714">https://arxiv.org/pdf/2508.19714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19714]] Addressing Deepfake Issue in Selfie banking through camera based authentication(https://arxiv.org/abs/2508.19714)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>Fake images in selfie banking are increasingly becoming a threat. Previously, it was just Photoshop, but now deep learning technologies enable us to create highly realistic fake identities, which fraudsters exploit to bypass biometric systems such as facial recognition in online banking. This paper explores the use of an already established forensic recognition system, previously used for picture camera localization, in deepfake detection.</li>
</ul>

<h3>Title: Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models</h3>
<ul>
<li><strong>Authors: </strong>Yilin Wang, Heng Wang, Yuyang Bai, Minnan Luo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19720">https://arxiv.org/abs/2508.19720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19720">https://arxiv.org/pdf/2508.19720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19720]] Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models(https://arxiv.org/abs/2508.19720)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In Large Language Models (LLMs) generation, there exist knowledge conflicts and scenarios where parametric knowledge contradicts knowledge provided in the context. Previous works studied tuning, decoding algorithms, or locating and editing context-aware neurons to adapt LLMs to be faithful to new contextual knowledge. However, they are usually inefficient or ineffective for large models, not workable for black-box models, or unable to continuously adjust LLMs' sensitivity to the knowledge provided in the context. To mitigate these problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a simple framework that can steer LLMs' sensitivity to contextual knowledge continuously at a lightweight cost. Specifically, we tune two small LMs (i.e. proxy models) and use the difference in their output distributions to shift the original distribution of an LLM without modifying the LLM weights. In the evaluation process, we not only design synthetic data and fine-grained metrics to measure models' sensitivity to contextual knowledge but also use a real conflict dataset to validate CSKS's practical efficacy. Extensive experiments demonstrate that our framework achieves continuous and precise control over LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity and reduced sensitivity, thereby allowing LLMs to prioritize either contextual or parametric knowledge as needed flexibly. Our data and code are available at this https URL.</li>
</ul>

<h3>Title: NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks</h3>
<ul>
<li><strong>Authors: </strong>Aritra Dutta, Swapnanil Mukherjee, Deepanway Ghosal, Somak Aditya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19724">https://arxiv.org/abs/2508.19724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19724">https://arxiv.org/pdf/2508.19724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19724]] NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks(https://arxiv.org/abs/2508.19724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Commonsense visual-question answering often hinges on knowledge that is missing from the image or the question. Small vision-language models (sVLMs) such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative counterparts. To study the effect of careful commonsense knowledge integration on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural language facts, (ii) prompts an LLM to craft natural language explanations, and (iii) feeds both signals to sVLMs respectively across two commonsense VQA datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts retrieved using a fine-tuned ColBERTv2 and an object information-enriched prompt yield explanations that largely cut down hallucinations, while lifting the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional finetuning using noise-robust losses (such as symmetric cross entropy and generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our findings expose when LLM-based commonsense knowledge beats retrieval from commonsense knowledge bases, how noise-aware training stabilises small models in the context of external knowledge augmentation, and why parameter-efficient commonsense reasoning is now within reach for 250M models.</li>
</ul>

<h3>Title: Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning</h3>
<ul>
<li><strong>Authors: </strong>Stelios Mylonas, Symeon Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19730">https://arxiv.org/abs/2508.19730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19730">https://arxiv.org/pdf/2508.19730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19730]] Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning(https://arxiv.org/abs/2508.19730)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The increasing realism and accessibility of deepfakes have raised critical concerns about media authenticity and information integrity. Despite recent advances, deepfake detection models often struggle to generalize beyond their training distributions, particularly when applied to media content found in the wild. In this work, we present a robust video deepfake detection framework with strong generalization that takes advantage of the rich facial representations learned by face foundation models. Our method is built on top of FSFM, a self-supervised model trained on real face data, and is further fine-tuned using an ensemble of deepfake datasets spanning both face-swapping and face-reenactment manipulations. To enhance discriminative power, we incorporate triplet loss variants during training, guiding the model to produce more separable embeddings between real and fake samples. Additionally, we explore attribution-based supervision schemes, where deepfakes are categorized by manipulation type or source dataset, to assess their impact on generalization. Extensive experiments across diverse evaluation benchmarks demonstrate the effectiveness of our approach, especially in challenging real-world scenarios.</li>
</ul>

<h3>Title: Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Li, Yuxin Zhang, Gen Luo, Haiyuan Wan, Ziyang Gong, Fei Chao, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19740">https://arxiv.org/abs/2508.19740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19740">https://arxiv.org/pdf/2508.19740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19740]] Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval(https://arxiv.org/abs/2508.19740)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reducing the key-value (KV) cache burden in Large Language Models (LLMs) significantly accelerates inference. Dynamically selecting critical KV caches during decoding helps maintain performance. Existing methods use random linear hashing to identify important tokens, but this approach is inefficient due to the orthogonal distribution of queries and keys within two narrow cones in LLMs. We introduce Spotlight Attention, a novel method that employs non-linear hashing functions to optimize the embedding distribution of queries and keys, enhancing coding efficiency and robustness. We also developed a lightweight, stable training framework using a Bradley-Terry ranking-based loss, enabling optimization of the non-linear hashing module on GPUs with 16GB memory in 8 hours. Experimental results show that Spotlight Attention drastically improves retrieval precision while shortening the length of the hash code at least 5$\times$ compared to traditional linear hashing. Finally, we exploit the computational advantages of bitwise operations by implementing specialized CUDA kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla decoding.</li>
</ul>

<h3>Title: POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection</h3>
<ul>
<li><strong>Authors: </strong>Chenguang Liu, Chisheng Wang, Yuhua Cai, Chuanhua Zhu, Qingquan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19742">https://arxiv.org/abs/2508.19742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19742">https://arxiv.org/pdf/2508.19742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19742]] POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection(https://arxiv.org/abs/2508.19742)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Line segment detection in images has been studied for several decades. Existing line segment detectors can be roughly divided into two categories: generic line segment detectors and wireframe line segment detectors. Generic line segment detectors aim to detect all meaningful line segments in images and traditional approaches usually fall into this category. Recent deep learning based approaches are mostly wireframe line segment detectors. They detect only line segments that are geometrically meaningful and have large spatial support. Due to the difference in the aim of design, the performance of generic line segment detectors for the task of wireframe line segment detection won't be satisfactory, and vice versa. In this work, we propose a robust framework that can be used for both generic line segment detection and wireframe line segment detection. The proposed method is an improved version of the Pixel Orientation Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments from edge strength maps, and can be combined with any edge detector. We show in our experiments that by combining the proposed POEv2 with an efficient edge detector, it achieves state-of-the-art performance on three publicly available datasets.</li>
</ul>

<h3>Title: SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Qiyao Xu, Qiming Wu, Xiaowei Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19746">https://arxiv.org/abs/2508.19746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19746">https://arxiv.org/pdf/2508.19746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19746]] SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection(https://arxiv.org/abs/2508.19746)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Segment Anything Model (SAM) has demonstrated remarkable capabilities in solving light field salient object detection (LF SOD). However, most existing models tend to neglect the extraction of prompt information under this task. Meanwhile, traditional models ignore the analysis of frequency-domain information, which leads to small objects being overwhelmed by noise. In this paper, we put forward a novel model called self-prompting light field segment anything model (SPLF-SAM), equipped with unified multi-scale feature embedding block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is capable of identifying multiple objects of varying sizes, while MAFA, by learning frequency features, effectively prevents small objects from being overwhelmed by noise. Extensive experiments have demonstrated the superiority of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be available at this https URL.</li>
</ul>

<h3>Title: Fast 3D Diffusion for Scalable Granular Media Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Moeeze Hassan, Régis Cottereau, Filippo Gatti, Patryk Dec</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19752">https://arxiv.org/abs/2508.19752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19752">https://arxiv.org/pdf/2508.19752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19752]] Fast 3D Diffusion for Scalable Granular Media Synthesis(https://arxiv.org/abs/2508.19752)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Simulating granular media, using Discrete Element Method is a computationally intensive task. This is especially true during initialization phase, which dominates total simulation time because of large displacements involved and associated kinetic energy. We overcome this bottleneck with a novel generative pipeline based on 3D diffusion models that directly synthesizes arbitrarily large granular assemblies in their final and physically realistic configurations. The approach frames the problem as a 3D generative modeling task, consisting of a two-stage pipeline. First a diffusion model is trained to generate independent 3D voxel grids representing granular media. Second, a 3D inpainting model, adapted from 2D inpainting techniques using masked inputs, stitches these grids together seamlessly, enabling synthesis of large samples with physically realistic structure. The inpainting model explores several masking strategies for the inputs to the underlying UNets by training the network to infer missing portions of voxel grids from a concatenation of noised tensors, masks, and masked tensors as input channels. The model also adapts a 2D repainting technique of re-injecting noise scheduler output with ground truth to provide a strong guidance to the 3D model. This along with weighted losses ensures long-term coherence over generation of masked regions. Both models are trained on the same binarized 3D occupancy grids extracted from small-scale DEM simulations, achieving linear scaling of computational time with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track synthesis equivalent to a 3-hour DEM simulation, was completed under 20 seconds. The generated voxel grids can also be post-processed to extract grain geometries for DEM-compatibility as well, enabling physically coherent, real-time, scalable granular media synthesis for industrial applications.</li>
</ul>

<h3>Title: FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yue Wu, Yufan Wu, Wen Li, Yuxi Lu, Kairui Feng, Xuanhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19754">https://arxiv.org/abs/2508.19754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19754">https://arxiv.org/pdf/2508.19754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19754]] FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers(https://arxiv.org/abs/2508.19754)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite significant progress in 3D avatar reconstruction, it still faces challenges such as high time complexity, sensitivity to data quality, and low data utilization. We propose FastAvatar, a feedforward 3D avatar framework capable of flexibly leveraging diverse daily recordings (e.g., a single image, multi-view observations, or monocular video) to reconstruct a high-quality 3D Gaussian Splatting (3DGS) model within seconds, using only a single unified model. FastAvatar's core is a Large Gaussian Reconstruction Transformer featuring three key designs: First, a variant VGGT-style transformer architecture aggregating multi-frame cues while injecting initial 3D prompt to predict an aggregatable canonical 3DGS representation; Second, multi-granular guidance encoding (camera pose, FLAME expression, head pose) mitigating animation-induced misalignment for variable-length inputs; Third, incremental Gaussian aggregation via landmark tracking and sliced fusion losses. Integrating these features, FastAvatar enables incremental reconstruction, i.e., improving quality with more observations, unlike prior work wasting input data. This yields a quality-speed-tunable paradigm for highly usable avatar modeling. Extensive experiments show that FastAvatar has higher quality and highly competitive speed compared to existing methods.</li>
</ul>

<h3>Title: BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Emam, Mohamed Elbassiouny, Julius Miller, Patrick Donworth, Sabine Seidel, Ribana Roscher</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19762">https://arxiv.org/abs/2508.19762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19762">https://arxiv.org/pdf/2508.19762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19762]] BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions(https://arxiv.org/abs/2508.19762)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Pollinator insects such as honeybees and bumblebees are vital to global food production and ecosystem stability, yet their populations are declining due to increasing anthropogenic and environmental stressors. To support scalable, automated pollinator monitoring, we introduce BuzzSet, a new large-scale dataset of high-resolution pollinator images collected in real agricultural field conditions. BuzzSet contains 7856 manually verified and labeled images, with over 8000 annotated instances across three classes: honeybees, bumblebees, and unidentified insects. Initial annotations were generated using a YOLOv12 model trained on external data and refined via human verification using open-source labeling tools. All images were preprocessed into 256~$\times$~256 tiles to improve the detection of small insects. We provide strong baselines using the RF-DETR transformer-based object detector. The model achieves high F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively, with confusion matrix results showing minimal misclassification between these categories. The unidentified class remains more challenging due to label ambiguity and lower sample frequency, yet still contributes useful insights for robustness evaluation. Overall detection quality is strong, with a best mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object detection, class separation under label noise, and ecological computer vision.</li>
</ul>

<h3>Title: Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance</h3>
<ul>
<li><strong>Authors: </strong>Pedro Henrique Luz de Araujo, Paul Röttger, Dirk Hovy, Benjamin Roth</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19764">https://arxiv.org/abs/2508.19764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19764">https://arxiv.org/pdf/2508.19764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19764]] Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance(https://arxiv.org/abs/2508.19764)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Expert persona prompting -- assigning roles such as expert in math to language models -- is widely used for task improvement. However, prior work shows mixed results on its effectiveness, and does not consider when and why personas should improve performance. We analyze the literature on persona prompting for task improvement and distill three desiderata: 1) performance advantage of expert personas, 2) robustness to irrelevant persona attributes, and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs across 27 tasks with respect to these desiderata. We find that expert personas usually lead to positive or non-significant performance changes. Surprisingly, models are highly sensitive to irrelevant persona details, with performance drops of almost 30 percentage points. In terms of fidelity, we find that while higher education, specialization, and domain-relatedness can boost performance, their effects are often inconsistent or negligible across tasks. We propose mitigation strategies to improve robustness -- but find they only work for the largest, most capable models. Our findings underscore the need for more careful persona design and for evaluation schemes that reflect the intended effects of persona usage.</li>
</ul>

<h3>Title: The Return of Structural Handwritten Mathematical Expression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Jakob Seitz, Tobias Lengfeld, Radu Timofte</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19773">https://arxiv.org/abs/2508.19773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19773">https://arxiv.org/pdf/2508.19773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19773]] The Return of Structural Handwritten Mathematical Expression Recognition(https://arxiv.org/abs/2508.19773)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Handwritten Mathematical Expression Recognition is foundational for educational technologies, enabling applications like digital note-taking and automated grading. While modern encoder-decoder architectures with large language models excel at LaTeX generation, they lack explicit symbol-to-trace alignment, a critical limitation for error analysis, interpretability, and spatially aware interactive applications requiring selective content updates. This paper introduces a structural recognition approach with two innovations: 1 an automatic annotation system that uses a neural network to map LaTeX equations to raw traces, automatically generating annotations for symbol segmentation, classification, and spatial relations, and 2 a modular structural recognition system that independently optimizes segmentation, classification, and relation prediction. By leveraging a dataset enriched with structural annotations from our auto-labeling system, the proposed recognition system combines graph-based trace sorting, a hybrid convolutional-recurrent network, and transformer-based correction to achieve competitive performance on the CROHME-2023 benchmark. Crucially, our structural recognition system generates a complete graph structure that directly links handwritten traces to predicted symbols, enabling transparent error analysis and interpretable outputs.</li>
</ul>

<h3>Title: The Art of Hide and Seek: Making Pickle-Based Model Supply Chain Poisoning Stealthy Again</h3>
<ul>
<li><strong>Authors: </strong>Tong Liu, Guozhu Meng, Peng Zhou, Zizhuang Deng, Shuaiyin Yao, Kai Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19774">https://arxiv.org/abs/2508.19774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19774">https://arxiv.org/pdf/2508.19774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19774]] The Art of Hide and Seek: Making Pickle-Based Model Supply Chain Poisoning Stealthy Again(https://arxiv.org/abs/2508.19774)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Pickle deserialization vulnerabilities have persisted throughout Python's history, remaining widely recognized yet unresolved. Due to its ability to transparently save and restore complex objects into byte streams, many AI/ML frameworks continue to adopt pickle as the model serialization protocol despite its inherent risks. As the open-source model ecosystem grows, model-sharing platforms such as Hugging Face have attracted massive participation, significantly amplifying the real-world risks of pickle exploitation and opening new avenues for model supply chain poisoning. Although several state-of-the-art scanners have been developed to detect poisoned models, their incomplete understanding of the poisoning surface leaves the detection logic fragile and allows attackers to bypass them. In this work, we present the first systematic disclosure of the pickle-based model poisoning surface from both model loading and risky function perspectives. Our research demonstrates how pickle-based model poisoning can remain stealthy and highlights critical gaps in current scanning solutions. On the model loading surface, we identify 22 distinct pickle-based model loading paths across five foundational AI/ML frameworks, 19 of which are entirely missed by existing scanners. We further develop a bypass technique named Exception-Oriented Programming (EOP) and discover 9 EOP instances, 7 of which can bypass all scanners. On the risky function surface, we discover 133 exploitable gadgets, achieving almost a 100% bypass rate. Even against the best-performing scanner, these gadgets maintain an 89% bypass rate. By systematically revealing the pickle-based model poisoning surface, we achieve practical and robust bypasses against real-world scanners. We responsibly disclose our findings to corresponding vendors, receiving acknowledgments and a $6000 bug bounty.</li>
</ul>

<h3>Title: Interestingness First Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Ryoma Sato</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19780">https://arxiv.org/abs/2508.19780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19780">https://arxiv.org/pdf/2508.19780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19780]] Interestingness First Classifiers(https://arxiv.org/abs/2508.19780)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Most machine learning models are designed to maximize predictive accuracy. In this work, we explore a different goal: building classifiers that are interesting. An ``interesting classifier'' is one that uses unusual or unexpected features, even if its accuracy is lower than the best possible model. For example, predicting room congestion from CO2 levels achieves near-perfect accuracy but is unsurprising. In contrast, predicting room congestion from humidity is less accurate yet more nuanced and intriguing. We introduce EUREKA, a simple framework that selects features according to their perceived interestingness. Our method leverages large language models to rank features by their interestingness and then builds interpretable classifiers using only the selected interesting features. Across several benchmark datasets, EUREKA consistently identifies features that are non-obvious yet still predictive. For example, in the Occupancy Detection dataset, our method favors humidity over CO2 levels and light intensity, producing classifiers that achieve meaningful accuracy while offering insights. In the Twin Papers dataset, our method discovers the rule that papers with a colon in the title are more likely to be cited in the future. We argue that such models can support new ways of knowledge discovery and communication, especially in settings where moderate accuracy is sufficient but novelty and interpretability are valued.</li>
</ul>

<h3>Title: StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation</h3>
<ul>
<li><strong>Authors: </strong>Xiuchao Wu, Pengfei Zhu, Jiangjing Lyu, Xinguo Liu, Jie Guo, Yanwen Guo, Weiwei Xu, Chengfei Lyu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19789">https://arxiv.org/abs/2508.19789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19789">https://arxiv.org/pdf/2508.19789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19789]] StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation(https://arxiv.org/abs/2508.19789)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recovering material information from images has been extensively studied in computer graphics and vision. Recent works in material estimation leverage diffusion model showing promising results. However, these diffusion-based methods adopt a multi-step denoising strategy, which is time-consuming for each estimation. Such stochastic inference also conflicts with the deterministic material estimation task, leading to a high variance estimated results. In this paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view material estimation that can produce high-quality material parameters with low variance. To address the overly-smoothing problem in one-step diffusion, StableIntrinsic applies losses in pixel space, with each loss designed based on the properties of the material. Additionally, StableIntrinsic introduces a Detail Injection Network (DIN) to eliminate the detail loss caused by VAE encoding, while further enhancing the sharpness of material prediction results. The experimental results indicate that our method surpasses the current state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error (MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.</li>
</ul>

<h3>Title: Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models</h3>
<ul>
<li><strong>Authors: </strong>Shay Shomer Chai, Wenxuan Peng, Bharath Hariharan, Hadar Averbuch-Elor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19791">https://arxiv.org/abs/2508.19791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19791">https://arxiv.org/pdf/2508.19791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19791]] Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models(https://arxiv.org/abs/2508.19791)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image generation has recently seen remarkable success, granting users with the ability to create high-quality images through the use of text. However, contemporary methods face challenges in capturing the precise semantics conveyed by complex multi-object prompts. Consequently, many works have sought to mitigate such semantic misalignments, typically via inference-time schemes that modify the attention layers of the denoising networks. However, prior work has mostly utilized coarse metrics, such as the cosine similarity between text and image CLIP embeddings, or human evaluations, which are challenging to conduct on a larger-scale. In this work, we perform a case study on colors -- a fundamental attribute commonly associated with objects in text prompts, which offer a rich test bed for rigorous evaluation. Our analysis reveals that pretrained models struggle to generate images that faithfully reflect multiple color attributes-far more so than with single-color prompts-and that neither inference-time techniques nor existing editing methods reliably resolve these semantic misalignments. Accordingly, we introduce a dedicated image editing technique, mitigating the issue of multi-object semantic alignment for prompts containing multiple colors. We demonstrate that our approach significantly boosts performance over a wide range of metrics, considering images generated by various text-to-image diffusion-based techniques.</li>
</ul>

<h3>Title: FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ali, Omar Ali AlSuwaidi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19798">https://arxiv.org/abs/2508.19798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19798">https://arxiv.org/pdf/2508.19798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19798]] FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization(https://arxiv.org/abs/2508.19798)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In the realm of waste management, automating the sorting process for non-biodegradable materials presents considerable challenges due to the complexity and variability of waste streams. To address these challenges, we introduce an enhanced neural architecture that builds upon an existing Encoder-Decoder structure to improve the accuracy and efficiency of waste sorting systems. Our model integrates several key innovations: a Comprehensive Attention Block within the decoder, which refines feature representations by combining convolutional and upsampling operations. In parallel, we utilize attention through the Mamba architecture, providing an additional performance boost. We also introduce a Data Fusion Block that fuses images with more than three channels. To achieve this, we apply PCA transformation to reduce the dimensionality while retaining the maximum variance and essential information across three dimensions, which are then used for further processing. We evaluated the model on RGB, hyperspectral, multispectral, and a combination of RGB and hyperspectral data. The results demonstrate that our approach outperforms existing methods by a significant margin.</li>
</ul>

<h3>Title: A bag of tricks for real-time Mitotic Figure detection</h3>
<ul>
<li><strong>Authors: </strong>Christian Marzahl, Brian Napora</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19804">https://arxiv.org/abs/2508.19804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19804">https://arxiv.org/pdf/2508.19804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19804]] A bag of tricks for real-time Mitotic Figure detection(https://arxiv.org/abs/2508.19804)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Mitotic figure (MF) detection in histopathology images is challenging due to large variations in slide scanners, staining protocols, tissue types, and the presence of artifacts. This paper presents a collection of training techniques - a bag of tricks - that enable robust, real-time MF detection across diverse domains. We build on the efficient RTMDet single stage object detector to achieve high inference speed suitable for clinical deployment. Our method addresses scanner variability and tumor heterogeneity via extensive multi-domain training data, balanced sampling, and careful augmentation. Additionally, we employ targeted, hard negative mining on necrotic and debris tissue to reduce false positives. In a grouped 5-fold cross-validation across multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025 challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81, outperforming larger models and demonstrating adaptability to new, unfamiliar domains. The proposed solution offers a practical trade-off between accuracy and speed, making it attractive for real-world clinical adoption.</li>
</ul>

<h3>Title: Context-aware Sparse Spatiotemporal Learning for Event-based Vision</h3>
<ul>
<li><strong>Authors: </strong>Shenqi Wang, Guangzhi Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19806">https://arxiv.org/abs/2508.19806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19806">https://arxiv.org/pdf/2508.19806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19806]] Context-aware Sparse Spatiotemporal Learning for Event-based Vision(https://arxiv.org/abs/2508.19806)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Event-based camera has emerged as a promising paradigm for robot perception, offering advantages with high temporal resolution, high dynamic range, and robustness to motion blur. However, existing deep learning-based event processing methods often fail to fully leverage the sparse nature of event data, complicating their integration into resource-constrained edge applications. While neuromorphic computing provides an energy-efficient alternative, spiking neural networks struggle to match of performance of state-of-the-art models in complex event-based vision tasks, like object detection and optical flow. Moreover, achieving high activation sparsity in neural networks is still difficult and often demands careful manual tuning of sparsity-inducing loss terms. Here, we propose Context-aware Sparse Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware thresholding to dynamically regulate neuron activations based on the input distribution, naturally reducing activation density without explicit sparsity constraints. Applied to event-based object detection and optical flow estimation, CSSL achieves comparable or superior performance to state-of-the-art methods while maintaining extremely high neuronal sparsity. Our experimental results highlight CSSL's crucial role in enabling efficient event-based vision for neuromorphic processing.</li>
</ul>

<h3>Title: AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment</h3>
<ul>
<li><strong>Authors: </strong>Kaixuan Lu, Mehmet Onurcan Kaya, Dim P. Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19808">https://arxiv.org/abs/2508.19808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19808">https://arxiv.org/pdf/2508.19808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19808]] AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment(https://arxiv.org/abs/2508.19808)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Video Instance Segmentation (VIS) faces significant annotation challenges due to its dual requirements of pixel-level masks and temporal consistency labels. While recent unsupervised methods like VideoCutLER eliminate optical flow dependencies through synthetic data, they remain constrained by the synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised framework that bridges this gap through quality-guided self-training. Our approach establishes a closed-loop system between pseudo-label generation and automatic quality assessment, enabling progressive adaptation from synthetic to real videos. Experiments demonstrate state-of-the-art performance with 52.6 $\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations. This demonstrates the viability of quality-aware self-training for unsupervised VIS. The source code of our method is available at this https URL.</li>
</ul>

<h3>Title: T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Changzai Pan, Kaiwen Wei, Sishi Xiong, Yu Zhao, Xiangyu Li, Jiaxin Peng, Xiaoyan Gu, Jian Yang, Wenhan Chang, Zhenhe Wu, Jiang Zhong, Shuangyong Song, Yongxiang Li, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19813">https://arxiv.org/abs/2508.19813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19813">https://arxiv.org/pdf/2508.19813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19813]] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables(https://arxiv.org/abs/2508.19813)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Extensive research has been conducted to explore the capabilities of large language models (LLMs) in table reasoning. However, the essential task of transforming tables information into reports remains a significant challenge for industrial applications. This task is plagued by two critical issues: 1) the complexity and diversity of tables lead to suboptimal reasoning outcomes; and 2) existing table benchmarks lack the capacity to adequately assess the practical application of this task. To fill this gap, we propose the table-to-report task and construct a bilingual benchmark named T2R-bench, where the key information flow from the tables to the reports for this task. The benchmark comprises 457 industrial tables, all derived from real-world scenarios and encompassing 19 industry domains as well as 4 types of industrial tables. Furthermore, we propose an evaluation criteria to fairly measure the quality of report generation. The experiments on 25 widely-used LLMs reveal that even state-of-the-art models like Deepseek-R1 only achieves performance with 62.71 overall score, indicating that LLMs still have room for improvement on T2R-bench. Source code and data will be available after acceptance.</li>
</ul>

<h3>Title: ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images</h3>
<ul>
<li><strong>Authors: </strong>Linkuan Zhou, Zhexin Chen, Yufei Shen, Junlin Xu, Ping Xuan, Yixin Zhu, Yuqi Fang, Cong Cong, Leyi Wei, Ran Su, Jia Zhou, Qiangguo Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19815">https://arxiv.org/abs/2508.19815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19815">https://arxiv.org/pdf/2508.19815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19815]] ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images(https://arxiv.org/abs/2508.19815)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Automated segmentation of the fetal head in ultrasound images is critical for prenatal monitoring. However, achieving robust segmentation remains challenging due to the poor quality of ultrasound images and the lack of annotated data. Semi-supervised methods alleviate the lack of annotated data but struggle with the unique characteristics of fetal head ultrasound images, making it challenging to generate reliable pseudo-labels and enforce effective consistency regularization constraints. To address this issue, we propose a novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation. Our framework consists of the dual-scoring adaptive filtering strategy, the ellipse-constrained pseudo-label refinement, and the symmetry-based multiple consistency regularization. The dual-scoring adaptive filtering strategy uses boundary consistency and contour regularity criteria to evaluate and filter teacher outputs. The ellipse-constrained pseudo-label refinement refines these filtered outputs by fitting least-squares ellipses, which strengthens pixels near the center of the fitted ellipse and suppresses noise simultaneously. The symmetry-based multiple consistency regularization enforces multi-level consistency across perturbed images, symmetric regions, and between original predictions and pseudo-labels, enabling the model to capture robust and stable shape representations. Our method achieves state-of-the-art performance on two benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36% with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores are 91.68% and 93.70% under the same settings.</li>
</ul>

<h3>Title: From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Viktor Valadi, Mattias Åkesson, Johan Östman, Salman Toor, Andreas Hellander</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19819">https://arxiv.org/abs/2508.19819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19819">https://arxiv.org/pdf/2508.19819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19819]] From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning(https://arxiv.org/abs/2508.19819)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Gradient inversion attacks have garnered attention for their ability to compromise privacy in federated learning. However, many studies consider attacks with the model in inference mode, where training-time behaviors like dropout are disabled and batch normalization relies on fixed statistics. In this work, we systematically analyze how architecture and training behavior affect vulnerability, including the first in-depth study of inference-mode clients, which we show dramatically simplifies inversion. To assess attack feasibility under more realistic conditions, we turn to clients operating in standard training mode. In this setting, we find that successful attacks are only possible when several architectural conditions are met simultaneously: models must be shallow and wide, use skip connections, and, critically, employ pre-activation normalization. We introduce two novel attacks against models in training-mode with varying attacker knowledge, achieving state-of-the-art performance under realistic training conditions. We extend these efforts by presenting the first attack on a production-grade object-detection model. Here, to enable any visibly identifiable leakage, we revert to the lenient inference mode setting and make multiple architectural modifications to increase model vulnerability, with the extent of required changes highlighting the strong inherent robustness of such architectures. We conclude this work by offering the first comprehensive mapping of settings, clarifying which combinations of architectural choices and operational modes meaningfully impact privacy. Our analysis provides actionable insight into when models are likely vulnerable, when they appear robust, and where subtle leakage may persist. Together, these findings reframe how gradient inversion risk should be assessed in future research and deployment scenarios.</li>
</ul>

<h3>Title: Every Keystroke You Make: A Tech-Law Measurement and Analysis of Event Listeners for Wiretapping</h3>
<ul>
<li><strong>Authors: </strong>Shaoor Munir, Nurullah Demir, Qian Li, Konrad Kollnig, Zubair Shafiq</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19825">https://arxiv.org/abs/2508.19825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19825">https://arxiv.org/pdf/2508.19825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19825]] Every Keystroke You Make: A Tech-Law Measurement and Analysis of Event Listeners for Wiretapping(https://arxiv.org/abs/2508.19825)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>The privacy community has a long track record of investigating emerging types of web tracking techniques. Recent work has focused on compliance of web trackers with new privacy laws such as Europe's GDPR and California's CCPA. Despite the growing body of research documenting widespread lack of compliance with new privacy laws, there is a lack of robust enforcement. Different from prior work, we conduct a tech-law analysis to map decades-old U.S. laws about interception of electronic communications--so-called wiretapping--to web tracking. Bridging the tech-law gap for older wiretapping laws is important and timely because, in cases where legal harm to privacy is proven, they can provide statutory private right of action, are at the forefront of recent privacy enforcement, and could ultimately lead to a meaningful change in the web tracking landscape. In this paper, we focus on a particularly invasive tracking technique: the use of JavaScript event listeners by third-party trackers for real-time keystroke interception on websites. We use an instrumented web browser to crawl a sample of the top-million websites to investigate the use of event listeners that aligns with the criteria for wiretapping, according to U.S. wiretapping law at the federal level and in California. We find evidence that 38.52% websites installed third-party event listeners to intercept keystrokes, and that at least 3.18% websites transmitted intercepted information to a third-party server, which aligns with the criteria for wiretapping. We further find evidence that the intercepted information such as email addresses typed into form fields are used for unsolicited email marketing. Beyond our work that maps the intersection between technical measurement and U.S. wiretapping law, additional future legal research is required to determine when the wiretapping observed in our paper passes the threshold for illegality.</li>
</ul>

<h3>Title: Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Hinrich Schütze, Volker Tresp, Yunpu Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19828">https://arxiv.org/abs/2508.19828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19828">https://arxiv.org/pdf/2508.19828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19828]] Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning(https://arxiv.org/abs/2508.19828)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of NLP tasks, but they remain fundamentally stateless, constrained by limited context windows that hinder long-horizon reasoning. Recent efforts to address this limitation often augment LLMs with an external memory bank, yet most existing pipelines are static and heuristic-driven, lacking any learned mechanism for deciding what to store, update, or retrieve. We present Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the ability to actively manage and utilize external memory through two specialized agents: a Memory Manager that learns to perform structured memory operations {ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant entries and reasons over them to produce an answer. Both agents are fine-tuned with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and use with minimal supervision. With as few as 152 question-answer pairs and a corresponding temporal memory bank for training, Memory-R1 outperforms the most competitive existing baseline and demonstrates strong generalization across diverse question types and LLM backbones. Beyond presenting an effective approach, this work provides insights into how RL can unlock more agentic, memory-aware behaviors in LLMs, pointing toward richer, more persistent reasoning systems.</li>
</ul>

<h3>Title: Gradient Rectification for Robust Calibration under Distribution Shift</h3>
<ul>
<li><strong>Authors: </strong>Yilin Zhang, Cai Xu, You Wu, Ziyu Guan, Wei Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19830">https://arxiv.org/abs/2508.19830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19830">https://arxiv.org/pdf/2508.19830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19830]] Gradient Rectification for Robust Calibration under Distribution Shift(https://arxiv.org/abs/2508.19830)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks often produce overconfident predictions, undermining their reliability in safety-critical applications. This miscalibration is further exacerbated under distribution shift, where test data deviates from the training distribution due to environmental or acquisition changes. While existing approaches improve calibration through training-time regularization or post-hoc adjustment, their reliance on access to or simulation of target domains limits their practicality in real-world scenarios. In this paper, we propose a novel calibration framework that operates without access to target domain information. From a frequency-domain perspective, we identify that distribution shifts often distort high-frequency visual cues exploited by deep models, and introduce a low-frequency filtering strategy to encourage reliance on domain-invariant features. However, such information loss may degrade In-Distribution (ID) calibration performance. Therefore, we further propose a gradient-based rectification mechanism that enforces ID calibration as a hard constraint during optimization. Experiments on synthetic and real-world shifted datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method significantly improves calibration under distribution shift while maintaining strong in-distribution performance.</li>
</ul>

<h3>Title: Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis</h3>
<ul>
<li><strong>Authors: </strong>Anusha Kamath, Kanishk Singla, Rakesh Paul, Raviraj Joshi, Utkarsh Vaidya, Sanjay Singh Chauhan, Niranjan Wartikar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19831">https://arxiv.org/abs/2508.19831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19831">https://arxiv.org/pdf/2508.19831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19831]] Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis(https://arxiv.org/abs/2508.19831)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is challenging due to a lack of high-quality benchmarks, as direct translation of English datasets fails to capture crucial linguistic and cultural nuances. To address this, we introduce a suite of five Hindi LLM evaluation datasets: IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created using a methodology that combines from-scratch human annotation with a translate-and-verify process. We leverage this suite to conduct an extensive benchmarking of open-source LLMs supporting Hindi, providing a detailed comparative analysis of their current capabilities. Our curation process also serves as a replicable methodology for developing benchmarks in other low-resource languages.</li>
</ul>

<h3>Title: Scalable and consistent few-shot classification of survey responses using text embeddings</h3>
<ul>
<li><strong>Authors: </strong>Jonas Timmann Mjaaland, Markus Fleten Kreutzer, Halvor Tyseng, Rebeckah K. Fussell, Gina Passante, N.G. Holmes, Anders Malthe-Sørenssen, Tor Ole B. Odden</a></li>
<li><strong>Subjects: </strong>cs.CL, physics.ed-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19836">https://arxiv.org/abs/2508.19836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19836">https://arxiv.org/pdf/2508.19836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19836]] Scalable and consistent few-shot classification of survey responses using text embeddings(https://arxiv.org/abs/2508.19836)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Qualitative analysis of open-ended survey responses is a commonly-used research method in the social sciences, but traditional coding approaches are often time-consuming and prone to inconsistency. Existing solutions from Natural Language Processing such as supervised classifiers, topic modeling techniques, and generative large language models have limited applicability in qualitative analysis, since they demand extensive labeled data, disrupt established qualitative workflows, and/or yield variable results. In this paper, we introduce a text embedding-based classification framework that requires only a handful of examples per category and fits well with standard qualitative workflows. When benchmarked against human analysis of a conceptual physics survey consisting of 2899 open-ended responses, our framework achieves a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in an exhaustive coding scheme. We further show how performance of this framework improves with fine-tuning of the text embedding model, and how the method can be used to audit previously-analyzed datasets. These findings demonstrate that text embedding-assisted coding can flexibly scale to thousands of responses without sacrificing interpretability, opening avenues for deductive qualitative analysis at scale.</li>
</ul>

<h3>Title: SoK: Large Language Model Copyright Auditing via Fingerprinting</h3>
<ul>
<li><strong>Authors: </strong>Shuo Shao, Yiming Li, Yu He, Hongwei Yao, Wenyuan Yang, Dacheng Tao, Zhan Qin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19843">https://arxiv.org/abs/2508.19843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19843">https://arxiv.org/pdf/2508.19843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19843]] SoK: Large Language Model Copyright Auditing via Fingerprinting(https://arxiv.org/abs/2508.19843)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The broad capabilities and substantial resources required to train Large Language Models (LLMs) make them valuable intellectual property, yet they remain vulnerable to copyright infringement, such as unauthorized use and model theft. LLM fingerprinting, a non-intrusive technique that extracts and compares the distinctive features from LLMs to identify infringements, offers a promising solution to copyright auditing. However, its reliability remains uncertain due to the prevalence of diverse model modifications and the lack of standardized evaluation. In this SoK, we present the first comprehensive study of LLM fingerprinting. We introduce a unified framework and formal taxonomy that categorizes existing methods into white-box and black-box approaches, providing a structured overview of the state of the art. We further propose LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting under realistic deployment scenarios. Built upon mainstream foundation models and comprising 149 distinct model instances, LeaFBench integrates 13 representative post-development techniques, spanning both parameter-altering methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms (e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the strengths and weaknesses of existing methods, thereby outlining future research directions and critical open problems in this emerging field. The code is available at this https URL.</li>
</ul>

<h3>Title: Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources</h3>
<ul>
<li><strong>Authors: </strong>Erdi Kara, Panos Stinis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19847">https://arxiv.org/abs/2508.19847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19847">https://arxiv.org/pdf/2508.19847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19847]] Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources(https://arxiv.org/abs/2508.19847)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a hybrid framework that couples finite element methods (FEM) with physics-informed DeepONet to model fluid transport in porous media from sharp, localized Gaussian sources. The governing system consists of a steady-state Darcy flow equation and a time-dependent convection-diffusion equation. Our approach solves the Darcy system using FEM and transfers the resulting velocity field to a physics-informed DeepONet, which learns the mapping from source functions to solute concentration profiles. This modular strategy preserves FEM-level accuracy in the flow field while enabling fast inference for transport dynamics. To handle steep gradients induced by sharp sources, we introduce an adaptive sampling strategy for trunk collocation points. Numerical experiments demonstrate that our method is in good agreement with the reference solutions while offering orders of magnitude speedups over traditional solvers, making it suitable for practical applications in relevant scenarios. Implementation of our proposed method is available at this https URL.</li>
</ul>

<h3>Title: Ego-centric Predictive Model Conditioned on Hand Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Binjie Zhang, Mike Zheng Shou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19852">https://arxiv.org/abs/2508.19852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19852">https://arxiv.org/pdf/2508.19852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19852]] Ego-centric Predictive Model Conditioned on Hand Trajectories(https://arxiv.org/abs/2508.19852)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In egocentric scenarios, anticipating both the next action and its visual outcome is essential for understanding human-object interactions and for enabling robotic planning. However, existing paradigms fall short of jointly modeling these aspects. Vision-Language-Action (VLA) models focus on action prediction but lack explicit modeling of how actions influence the visual scene, while video prediction models generate future frames without conditioning on specific actions, often resulting in implausible or contextually inconsistent outcomes. To bridge this gap, we propose a unified two-stage predictive framework that jointly models action and visual future in egocentric scenarios, conditioned on hand trajectories. In the first stage, we perform consecutive state modeling to process heterogeneous inputs (visual observations, language, and action history) and explicitly predict future hand trajectories. In the second stage, we introduce causal cross-attention to fuse multi-modal cues, leveraging inferred action signals to guide an image-based Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our approach is the first unified model designed to handle both egocentric human activity understanding and robotic manipulation tasks, providing explicit predictions of both upcoming actions and their visual consequences. Extensive experiments on Ego4D, BridgeData, and RLBench demonstrate that our method outperforms state-of-the-art baselines in both action prediction and future video synthesis.</li>
</ul>

<h3>Title: Quantum latent distributions in deep generative models</h3>
<ul>
<li><strong>Authors: </strong>Omar Bacarreza, Thorin Farnsworth, Alexander Makarovskiy, Hugo Wallner, Tessa Hicks, Santiago Sempere-Llagostera, John Price, Robert J. A. Francis-Jones, William R. Clements</a></li>
<li><strong>Subjects: </strong>cs.LG, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19857">https://arxiv.org/abs/2508.19857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19857">https://arxiv.org/pdf/2508.19857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19857]] Quantum latent distributions in deep generative models(https://arxiv.org/abs/2508.19857)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Many successful families of generative models leverage a low-dimensional latent distribution that is mapped to a data distribution. Though simple latent distributions are commonly used, it has been shown that more sophisticated distributions can improve performance. For instance, recent work has explored using the distributions produced by quantum processors and found empirical improvements. However, when latent space distributions produced by quantum processors can be expected to improve performance, and whether these improvements are reproducible, are open questions that we investigate in this work. We prove that, under certain conditions, these "quantum latent distributions" enable generative models to produce data distributions that classical latent distributions cannot efficiently produce. We also provide actionable intuitions to identify when such quantum advantages may arise in real-world settings. We perform benchmarking experiments on both a synthetic quantum dataset and the QM9 molecular dataset, using both simulated and real photonic quantum processors. Our results demonstrate that quantum latent distributions can lead to improved generative performance in GANs compared to a range of classical baselines. We also explore diffusion and flow matching models, identifying architectures compatible with quantum latent distributions. This work confirms that near-term quantum processors can expand the capabilities of deep generative models.</li>
</ul>

<h3>Title: Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction</h3>
<ul>
<li><strong>Authors: </strong>Long Chen, Ashiv Patel, Mengyun Qiao, Mohammad Yousuf Salmasi, Salah A. Hammouche, Vasilis Stavrinides, Jasleen Nagi, Soodeh Kalaie, Xiao Yun Xu, Wenjia Bai, Declan P. O'Regan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19862">https://arxiv.org/abs/2508.19862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19862">https://arxiv.org/pdf/2508.19862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19862]] Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction(https://arxiv.org/abs/2508.19862)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Personalized, accurate prediction of aortic aneurysm progression is essential for timely intervention but remains challenging due to the need to model both subtle local deformations and global anatomical changes within complex 3D geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN introduces a dual-branch architecture combining a novel local KNN-based convolutional network (KCN) to preserve fine-grained geometric details and a global graph convolutional network (GCN) to capture long-range structural context, overcoming the over-smoothing limitations of deep GCNs. A dedicated condition branch encodes clinical attributes (age, sex) and the target time interval to generate anatomically plausible, temporally controlled predictions, enabling retrospective and prospective modeling. We curated TAAMesh, a new longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive experiments demonstrate that MCMeshGAN consistently outperforms state-of-the-art baselines in both geometric accuracy and clinically important diameter estimation. This framework offers a robust step toward clinically deployable, personalized 3D disease trajectory modeling. The source code for MCMeshGAN and the baseline methods is publicly available at this https URL.</li>
</ul>

<h3>Title: TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations</h3>
<ul>
<li><strong>Authors: </strong>François G. Landry, Moulay A. Akhloufi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19866">https://arxiv.org/abs/2508.19866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19866">https://arxiv.org/pdf/2508.19866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19866]] TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations(https://arxiv.org/abs/2508.19866)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>With the introduction of vehicles with autonomous capabilities on public roads, predicting pedestrian crossing intention has emerged as an active area of research. The task of predicting pedestrian crossing intention involves determining whether pedestrians in the scene are likely to cross the road or not. In this work, we propose TrajFusionNet, a novel transformer-based model that combines future pedestrian trajectory and vehicle speed predictions as priors for predicting crossing intention. TrajFusionNet comprises two branches: a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM branch learns from a sequential representation of the observed and predicted pedestrian trajectory and vehicle speed. Complementarily, the VAM branch enables learning from a visual representation of the predicted pedestrian trajectory by overlaying predicted pedestrian bounding boxes onto scene images. By utilizing a small number of lightweight modalities, TrajFusionNet achieves the lowest total inference time (including model runtime and data preprocessing) among current state-of-the-art approaches. In terms of performance, it achieves state-of-the-art results across the three most commonly used datasets for pedestrian crossing intention prediction.</li>
</ul>

<h3>Title: Multispectral LiDAR data for extracting tree points in urban and suburban areas</h3>
<ul>
<li><strong>Authors: </strong>Narges Takhtkeshha, Gabriele Mazzacca, Fabio Remondino, Juha Hyyppä, Gottfried Mandlburger</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19881">https://arxiv.org/abs/2508.19881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19881">https://arxiv.org/pdf/2508.19881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19881]] Multispectral LiDAR data for extracting tree points in urban and suburban areas(https://arxiv.org/abs/2508.19881)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Monitoring urban tree dynamics is vital for supporting greening policies and reducing risks to electrical infrastructure. Airborne laser scanning has advanced large-scale tree management, but challenges remain due to complex urban environments and tree variability. Multispectral (MS) light detection and ranging (LiDAR) improves this by capturing both 3D spatial and spectral data, enabling detailed mapping. This study explores tree point extraction using MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of SPT, with a mean intersection over union (mIoU) of 85.28%. The highest detection accuracy is achieved by incorporating pseudo normalized difference vegetation index (pNDVI) with spatial data, reducing error rate by 10.61 percentage points (pp) compared to using spatial information alone. These findings highlight the potential of MS-LiDAR and DL to improve tree extraction and further tree inventories.</li>
</ul>

<h3>Title: NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs</h3>
<ul>
<li><strong>Authors: </strong>Davorin Miličević, Ratko Grbić</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19896">https://arxiv.org/abs/2508.19896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19896">https://arxiv.org/pdf/2508.19896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19896]] NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs(https://arxiv.org/abs/2508.19896)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often rely on purely global, gradient-based optimisation, which can lead to overfitting, redundant filters, and reduced interpretability. To address these limitations, we propose NM-Hebb, a two-phase training framework that integrates neuro-inspired local plasticity with distance-aware supervision. Phase 1 extends standard supervised training by jointly optimising a cross-entropy objective with two biologically inspired mechanisms: (i) a Hebbian regulariser that aligns the spatial mean of activations with the mean of the corresponding convolutional filter weights, encouraging structured, reusable primitives; and (ii) a learnable neuromodulator that gates an elastic-weight-style consolidation loss, preserving beneficial parameters without freezing the network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss, explicitly compressing intra-class distances and enlarging inter-class margins in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2, DenseNet-121), NM-Hebb achieves consistent gains over baseline and other methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp (CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual Information (NMI) increased by up to +0.15. Qualitative visualisations and filter-level analyses further confirm that NM-Hebb produces more structured and selective features, yielding tighter and more interpretable class clusters. Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields CNNs that are not only more accurate but also more interpretable, offering practical benefits for resource-constrained and safety-critical AI deployments.</li>
</ul>

<h3>Title: Logical Reasoning with Outcome Reward Models for Test-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19903">https://arxiv.org/abs/2508.19903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19903">https://arxiv.org/pdf/2508.19903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19903]] Logical Reasoning with Outcome Reward Models for Test-Time Scaling(https://arxiv.org/abs/2508.19903)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Logical reasoning is a critical benchmark for evaluating the capabilities of large language models (LLMs), as it reflects their ability to derive valid conclusions from given premises. While the combination of test-time scaling with dedicated outcome or process reward models has opened up new avenues to enhance LLMs performance in complex reasoning tasks, this space is under-explored in deductive logical reasoning. We present a set of Outcome Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly generate data using Chain-of-Thought (CoT) with single and multiple samples. Additionally, we propose a novel tactic to further expand the type of errors covered in the training dataset of the ORM. In particular, we propose an echo generation technique that leverages LLMs' tendency to reflect incorrect assumptions made in prompts to extract additional training data, covering previously unexplored error types. While a standard CoT chain may contain errors likely to be made by the reasoner, the echo strategy deliberately steers the model toward incorrect reasoning. We show that ORMs trained on CoT and echo-augmented data demonstrate improved performance on the FOLIO, JustLogic, and ProverQA datasets across four different LLMs.</li>
</ul>

<h3>Title: Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Imad Ali Shah, Jiarong Li, Roshan George, Tim Brophy, Enda Ward, Martin Glavin, Edward Jones, Brian Deegan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19905">https://arxiv.org/abs/2508.19905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19905">https://arxiv.org/pdf/2508.19905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19905]] Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities(https://arxiv.org/abs/2508.19905)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Hyperspectral imaging (HSI) offers a transformative sensing modality for Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD) applications, enabling material-level scene understanding through fine spectral resolution beyond the capabilities of traditional RGB imaging. This paper presents the first comprehensive review of HSI for automotive applications, examining the strengths, limitations, and suitability of current HSI technologies in the context of ADAS/AD. In addition to this qualitative review, we analyze 216 commercially available HSI and multispectral imaging cameras, benchmarking them against key automotive criteria: frame rate, spatial resolution, spectral dimensionality, and compliance with AEC-Q100 temperature standards. Our analysis reveals a significant gap between HSI's demonstrated research potential and its commercial readiness. Only four cameras meet the defined performance thresholds, and none comply with AEC-Q100 requirements. In addition, the paper reviews recent HSI datasets and applications, including semantic segmentation for road surface classification, pedestrian separability, and adverse weather perception. Our review shows that current HSI datasets are limited in terms of scale, spectral consistency, the number of spectral channels, and environmental diversity, posing challenges for the development of perception algorithms and the adequate validation of HSI's true potential in ADAS/AD applications. This review paper establishes the current state of HSI in automotive contexts as of 2025 and outlines key research directions toward practical integration of spectral imaging in ADAS and autonomous systems.</li>
</ul>

<h3>Title: Streamlining the Development of Active Learning Methods in Real-World Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Moussa Kassem Sbeyti, Nadja Klein, Michelle Karg, Christian Wirth, Sahin Albayrak</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19906">https://arxiv.org/abs/2508.19906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19906">https://arxiv.org/pdf/2508.19906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19906]] Streamlining the Development of Active Learning Methods in Real-World Object Detection(https://arxiv.org/abs/2508.19906)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Active learning (AL) for real-world object detection faces computational and reliability challenges that limit practical deployment. Developing new AL methods requires training multiple detectors across iterations to compare against existing approaches. This creates high costs for autonomous driving datasets where the training of one detector requires up to 282 GPU hours. Additionally, AL method rankings vary substantially across validation sets, compromising reliability in safety-critical transportation systems. We introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without requiring detector training by measuring similarity between training sets and target domains using object-level features. This enables the elimination of ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables the selection of representative validation sets for robust evaluation. We validate our similarity-based approach on three autonomous driving datasets (KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with two detector architectures (EfficientDet, YOLOv3). This work is the first to unify AL training and evaluation strategies in object detection based on object similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object crops, and integrates with existing AL pipelines. This provides a practical framework for deploying AL in real-world applications where computational efficiency and evaluation reliability are critical. Code is available at this https URL.</li>
</ul>

<h3>Title: Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lechun You, Zhonghua Wu, Weide Liu, Xulei Yang, Jun Cheng, Wei Zhou, Bharadwaj Veeravalli, Guosheng Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19909">https://arxiv.org/abs/2508.19909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19909">https://arxiv.org/pdf/2508.19909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19909]] Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation(https://arxiv.org/abs/2508.19909)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Current methods for 3D semantic segmentation propose training models with limited annotations to address the difficulty of annotating large, irregular, and unordered 3D point cloud data. They usually focus on the 3D domain only, without leveraging the complementary nature of 2D and 3D data. Besides, some methods extend original labels or generate pseudo labels to guide the training, but they often fail to fully use these labels or address the noise within them. Meanwhile, the emergence of comprehensive and adaptable foundation models has offered effective solutions for segmenting 2D data. Leveraging this advancement, we present a novel approach that maximizes the utility of sparsely available 3D annotations by incorporating segmentation masks generated by 2D foundation models. We further propagate the 2D segmentation masks into the 3D space by establishing geometric correspondences between 3D scenes and 2D views. We extend the highly sparse annotations to encompass the areas delineated by 3D masks, thereby substantially augmenting the pool of available labels. Furthermore, we apply confidence- and uncertainty-based consistency regularization on augmentations of the 3D point cloud and select the reliable pseudo labels, which are further spread on the 3D masks to generate more labels. This innovative strategy bridges the gap between limited 3D annotations and the powerful capabilities of 2D foundation models, ultimately improving the performance of 3D weakly supervised segmentation.</li>
</ul>

<h3>Title: Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling</h3>
<ul>
<li><strong>Authors: </strong>Felix Nützel, Mischa Dombrowski, Bernhard Kainz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19915">https://arxiv.org/abs/2508.19915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19915">https://arxiv.org/pdf/2508.19915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19915]] Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling(https://arxiv.org/abs/2508.19915)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented learning based on radiology reports has emerged as a promising direction to improve performance on long-tail medical imaging tasks, such as rare disease detection in chest X-rays. Most existing methods rely on comparing high-dimensional text embeddings from models like CLIP or CXR-BERT, which are often difficult to interpret, computationally expensive, and not well-aligned with the structured nature of medical knowledge. We propose a novel, ontology-driven alternative for comparing radiology report texts based on clinically grounded concepts from the Unified Medical Language System (UMLS). Our method extracts standardised medical entities from free-text reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These entities are linked to UMLS concepts (CUIs), enabling a transparent, interpretable set-based representation of each report. We then define a task-adaptive similarity measure based on a modified and weighted version of the Tversky Index that accounts for synonymy, negation, and hierarchical relationships between medical entities. This allows efficient and semantically meaningful similarity comparisons between reports. We demonstrate that our approach outperforms state-of-the-art embedding-based retrieval methods in a radiograph classification task on MIMIC-CXR, particularly in long-tail settings. Additionally, we use our pipeline to generate ontology-backed disease labels for MIMIC-CXR, offering a valuable new resource for downstream learning tasks. Our work provides more explainable, reliable, and task-specific retrieval strategies in clinical AI systems, especially when interpretability and domain knowledge integration are essential. Our code is available at this https URL</li>
</ul>

<h3>Title: HEAL: A Hypothesis-Based Preference-Aware Analysis Framework</h3>
<ul>
<li><strong>Authors: </strong>Yifu Huo, Chenglong Wang, Qiren Zhu, Shunjie Xing, Tong Xiao, Chunliang Zhang, Tongran Liu, Jinbo Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19922">https://arxiv.org/abs/2508.19922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19922">https://arxiv.org/pdf/2508.19922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19922]] HEAL: A Hypothesis-Based Preference-Aware Analysis Framework(https://arxiv.org/abs/2508.19922)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Preference optimization methods like DPO have achieved remarkable performance in LLM alignment. However, the evaluation for these methods relies on a single response and overlooks other potential outputs, which could also be generated in real-world applications within this hypothetical space. To address this issue, this paper presents a \textbf{H}ypothesis-based Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel evaluation paradigm that formulates preference alignment as a re-ranking process within hypothesis spaces. The framework incorporates two complementary metrics: ranking accuracy for evaluating ordinal consistency and preference strength correlation for assessing continuous alignment. To facilitate this framework, we develop UniHypoBench, a unified hypothesis benchmark constructed from diverse instruction-response pairs. Through extensive experiments based on HEAL, with a particular focus on the intrinsic mechanisms of preference learning, we demonstrate that current preference learning methods can effectively capture preferences provided by proxy models while simultaneously suppressing negative samples. These findings contribute to preference learning research through two significant avenues. Theoretically, we introduce hypothesis space analysis as an innovative paradigm for understanding preference alignment. Practically, HEAL offers researchers robust diagnostic tools for refining preference optimization methods, while our empirical results identify promising directions for developing more advanced alignment algorithms capable of comprehensive preference capture.</li>
</ul>

<h3>Title: FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification</h3>
<ul>
<li><strong>Authors: </strong>Liming Liu, Ruoyu Li, Qing Li, Meijia Hou, Yong Jiang, Mingwei Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19924">https://arxiv.org/abs/2508.19924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19924">https://arxiv.org/pdf/2508.19924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19924]] FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification(https://arxiv.org/abs/2508.19924)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Network traffic classification using pre-training models has shown promising results, but existing methods struggle to capture packet structural characteristics, flow-level behaviors, hierarchical protocol semantics, and inter-packet contextual relationships. To address these challenges, we propose FlowletFormer, a BERT-based pre-training model specifically designed for network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware Traffic Representation Model for segmenting traffic into semantically meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining Tasks to enhance both inter-packet and inter-flow learning. Experimental results demonstrate that FlowletFormer significantly outperforms existing methods in the effectiveness of traffic representation, classification accuracy, and few-shot learning capability. Moreover, by effectively integrating domain-specific network knowledge, FlowletFormer shows better comprehension of the principles of network transmission (e.g., stateful connections of TCP), providing a more robust and trustworthy framework for traffic analysis.</li>
</ul>

<h3>Title: WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Fayaz Ali, Muhammad Zawish, Steven Davy, Radu Timofte</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19927">https://arxiv.org/abs/2508.19927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19927">https://arxiv.org/pdf/2508.19927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19927]] WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution(https://arxiv.org/abs/2508.19927)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated promising performance in computer vision tasks, including image super-resolution (SR). The quadratic computational complexity of window self-attention mechanisms in many transformer-based SR methods forces the use of small, fixed windows, limiting the receptive field. In this paper, we propose a new approach by embedding the wavelet transform within a hierarchical transformer framework, called (WaveHiT-SR). First, using adaptive hierarchical windows instead of static small windows allows to capture features across different levels and greatly improve the ability to model long-range dependencies. Secondly, the proposed model utilizes wavelet transforms to decompose images into multiple frequency subbands, allowing the network to focus on both global and local features while preserving structural details. By progressively reconstructing high-resolution images through hierarchical processing, the network reduces computational complexity without sacrificing performance. The multi-level decomposition strategy enables the network to capture fine-grained information in lowfrequency components while enhancing high-frequency textures. Through extensive experimentation, we confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR results, achieving higher efficiency with fewer parameters, lower FLOPs, and faster speeds.</li>
</ul>

<h3>Title: KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts</h3>
<ul>
<li><strong>Authors: </strong>Taebaek Hwang, Minseo Kim, Gisang Lee, Seonuk Kim, Hyunjun Eun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19944">https://arxiv.org/abs/2508.19944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19944">https://arxiv.org/pdf/2508.19944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19944]] KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts(https://arxiv.org/abs/2508.19944)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Understanding and reasoning over text within visual contexts poses a significant challenge for Vision-Language Models (VLMs), given the complexity and diversity of real-world scenarios. To address this challenge, text-rich Visual Question Answering (VQA) datasets and benchmarks have emerged for high-resource languages like English. However, a critical gap persists for low-resource languages such as Korean, where the lack of comprehensive benchmarks hinders robust model evaluation and comparison. To bridge this gap, we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth evaluation of both visual text understanding and reasoning capabilities, while also supporting a multifaceted assessment across 15 domains and 26 image types. Additionally, we introduce a semi-automated VQA generation pipeline specifically optimized for text-rich settings, leveraging refined stepwise image decomposition and a rigorous seven-metric evaluation protocol to ensure data quality. While KRETA is tailored for Korean, we hope our adaptable and extensible pipeline will facilitate the development of similar benchmarks in other languages, thereby accelerating multilingual VLM research. The code and dataset for KRETA are available at this https URL.</li>
</ul>

<h3>Title: Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions</h3>
<ul>
<li><strong>Authors: </strong>Zhouyu Zhang, Chih-Yuan Chiu, Glen Chou</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19945">https://arxiv.org/abs/2508.19945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19945">https://arxiv.org/pdf/2508.19945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19945]] Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions(https://arxiv.org/abs/2508.19945)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present an inverse dynamic game-based algorithm to learn parametric constraints from a given dataset of local generalized Nash equilibrium interactions between multiple agents. Specifically, we introduce mixed-integer linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the interacting agents, which recover constraints consistent with the Nash stationarity of the interaction demonstrations. We establish theoretical guarantees that our method learns inner approximations of the true safe and unsafe sets, as well as limitations of constraint learnability from demonstrations of Nash equilibrium interactions. We also use the interaction constraints recovered by our method to design motion plans that robustly satisfy the underlying constraints. Across simulations and hardware experiments, our methods proved capable of inferring constraints and designing interactive motion plans for various classes of constraints, both convex and non-convex, from interaction demonstrations of agents with nonlinear dynamics.</li>
</ul>

<h3>Title: Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework</h3>
<ul>
<li><strong>Authors: </strong>Gianluca Guzzetta</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19946">https://arxiv.org/abs/2508.19946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19946">https://arxiv.org/pdf/2508.19946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19946]] Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework(https://arxiv.org/abs/2508.19946)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we present a comprehensive study and analysis of the Chan-Vese algorithm for image segmentation. We employ a discretized scheme derived from the empirical study of the Chan-Vese model's functional energy and its partial differential equation based on its level set function. We provide a proof of the results and an implementation using MATLAB. Leveraging modern computer vision methodologies, we propose a functional segmentation loss based on active contours, utilizing this http URL and a level set based on the Chan-Vese algorithm. We compare our results with common computer vision segmentation datasets and evaluate the performance of classical loss functions against our proposed method. All code and materials used are available at this https URL.</li>
</ul>

<h3>Title: Global Permutation Entropy</h3>
<ul>
<li><strong>Authors: </strong>Abhijit Avhale (1), Joscha Diehl (1), Niraj Velankar (1), Emanuele Verri (1) ((1) University of Greifswald, Greifswald, Germany)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19955">https://arxiv.org/abs/2508.19955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19955">https://arxiv.org/pdf/2508.19955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19955]] Global Permutation Entropy(https://arxiv.org/abs/2508.19955)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Permutation Entropy, introduced by Bandt and Pompe, is a widely used complexity measure for real-valued time series that is based on the relative order of values within consecutive segments of fixed length. After standardizing each segment to a permutation and computing the frequency distribution of these permutations, Shannon Entropy is then applied to quantify the series' complexity. We introduce Global Permutation Entropy (GPE), a novel index that considers all possible patterns of a given length, including non-consecutive ones. Its computation relies on recently developed algorithms that enable the efficient extraction of full permutation profiles. We illustrate some properties of GPE and demonstrate its effectiveness through experiments on synthetic datasets, showing that it reveals structural information not accessible through standard permutation entropy. We provide a Julia package for the calculation of GPE at `this https URL.</li>
</ul>

<h3>Title: Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Slimane Bellaouar, Attia Nehar, Soumia Souffi, Mounia Bouameur</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19966">https://arxiv.org/abs/2508.19966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19966">https://arxiv.org/pdf/2508.19966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19966]] Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation(https://arxiv.org/abs/2508.19966)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Despite its significance, Arabic, a linguistically rich and morphologically complex language, faces the challenge of being under-resourced. The scarcity of large annotated datasets hampers the development of accurate tools for subjectivity analysis in Arabic. Recent advances in deep learning and Transformers have proven highly effective for text classification in English and French. This paper proposes a new approach for subjectivity assessment in Arabic textual data. To address the dearth of specialized annotated datasets, we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and ArabianGPT) on AraDhati+ for effective subjectivity classification. Furthermore, we experimented with an ensemble decision approach to harness the strengths of individual models. Our approach achieves a remarkable accuracy of 97.79\,\% for Arabic subjectivity classification. Results demonstrate the effectiveness of the proposed approach in addressing the challenges posed by limited resources in Arabic language processing.</li>
</ul>

<h3>Title: Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Oliver Grainge, Sania Waheed, Jack Stilgoe, Michael Milford, Shoaib Ehsan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19967">https://arxiv.org/abs/2508.19967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19967">https://arxiv.org/pdf/2508.19967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19967]] Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models(https://arxiv.org/abs/2508.19967)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>Geo-localization is the task of identifying the location of an image using visual cues alone. It has beneficial applications, such as improving disaster response, enhancing navigation, and geography education. Recently, Vision-Language Models (VLMs) are increasingly demonstrating capabilities as accurate image geo-locators. This brings significant privacy risks, including those related to stalking and surveillance, considering the widespread uses of AI models and sharing of photos on social media. The precision of these models is likely to improve in the future. Despite these risks, there is little work on systematically evaluating the geolocation precision of Generative VLMs, their limits and potential for unintended inferences. To bridge this gap, we conduct a comprehensive assessment of the geolocation capabilities of 25 state-of-the-art VLMs on four benchmark image datasets captured in diverse environments. Our results offer insight into the internal reasoning of VLMs and highlight their strengths, limitations, and potential societal risks. Our findings indicate that current VLMs perform poorly on generic street-level images yet achieve notably high accuracy (61\%) on images resembling social media content, raising significant and urgent privacy concerns.</li>
</ul>

<h3>Title: Evaluating Language Model Reasoning about Confidential Information</h3>
<ul>
<li><strong>Authors: </strong>Dylan Sam, Alexander Robey, Andy Zou, Matt Fredrikson, J. Zico Kolter</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19980">https://arxiv.org/abs/2508.19980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19980">https://arxiv.org/pdf/2508.19980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19980]] Evaluating Language Model Reasoning about Confidential Information(https://arxiv.org/abs/2508.19980)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As language models are increasingly deployed as autonomous agents in high-stakes settings, ensuring that they reliably follow user-defined rules has become a critical safety concern. To this end, we study whether language models exhibit contextual robustness, or the capability to adhere to context-dependent safety specifications. For this analysis, we develop a benchmark (PasswordEval) that measures whether language models can correctly determine when a user request is authorized (i.e., with a correct password). We find that current open- and closed-source models struggle with this seemingly simple task, and that, perhaps surprisingly, reasoning capabilities do not generally improve performance. In fact, we find that reasoning traces frequently leak confidential information, which calls into question whether reasoning traces should be exposed to users in such applications. We also scale the difficulty of our evaluation along multiple axes: (i) by adding adversarial user pressure through various jailbreaking strategies, and (ii) through longer multi-turn conversations where password verification is more challenging. Overall, our results suggest that current frontier models are not well-suited to handling confidential information, and that reasoning capabilities may need to be trained in a different manner to make them safer for release in high-stakes settings.</li>
</ul>

<h3>Title: Diffusion Language Models Know the Answer Before Decoding</h3>
<ul>
<li><strong>Authors: </strong>Pengxiang Li, Yefan Zhou, Dilxat Muhtar, Lu Yin, Shilin Yan, Li Shen, Yi Liang, Soroush Vosoughi, Shiwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19982">https://arxiv.org/abs/2508.19982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19982">https://arxiv.org/pdf/2508.19982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19982]] Diffusion Language Models Know the Answer Before Decoding(https://arxiv.org/abs/2508.19982)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion language models (DLMs) have recently emerged as an alternative to autoregressive approaches, offering parallel sequence generation and flexible token orders. However, their inference remains slower than that of autoregressive models, primarily due to the cost of bidirectional attention and the large number of refinement steps required for high quality outputs. In this work, we highlight and leverage an overlooked property of DLMs early answer convergence: in many cases, the correct answer can be internally identified by half steps before the final decoding step, both under semi-autoregressive and random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99% of instances, respectively, can be decoded correctly using only half of the refinement steps. Building on this observation, we introduce Prophet, a training-free fast decoding paradigm that enables early commit decoding. Specifically, Prophet dynamically decides whether to continue refinement or to go "all-in" (i.e., decode all remaining tokens in one step), using the confidence gap between the top-2 prediction candidates as the criterion. It integrates seamlessly into existing DLM implementations, incurs negligible overhead, and requires no additional training. Empirical evaluations of LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the number of decoding steps by up to 3.4x while preserving high generation quality. These results recast DLM decoding as a problem of when to stop sampling, and demonstrate that early decode convergence provides a simple yet powerful mechanism for accelerating DLM inference, complementary to existing speedup techniques. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Lisa Alazraki, Lihu Chen, Ana Brassard, Joe Stacey, Hossein A. Rahmani, Marek Rei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19988">https://arxiv.org/abs/2508.19988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19988">https://arxiv.org/pdf/2508.19988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19988]] AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios(https://arxiv.org/abs/2508.19988)</code><input type="text"></li>
<li><strong>Keywords: </strong>membership infer, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved high accuracy on complex commonsense and mathematical problems that involve the composition of multiple reasoning steps. However, current compositional benchmarks testing these skills tend to focus on either commonsense or math reasoning, whereas LLM agents solving real-world tasks would require a combination of both. In this work, we introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each compositional task requires a commonsense reasoning step and a math reasoning step. We test it on 61 LLMs of different sizes, model families, and training strategies. We find that LLMs can usually solve both steps in isolation, yet their accuracy drops by ~30% on average when the two are combined. This is a substantially greater performance gap than the one we observe in prior compositional benchmarks that combine multiple steps of the same reasoning type. In contrast, non-expert human annotators can solve the compositional questions and the individual steps in AgentCoMa with similarly high accuracy. Furthermore, we conduct a series of interpretability studies to better understand the performance gap, examining neuron patterns, attention maps and membership inference. Our work underscores a substantial degree of model brittleness in the context of mixed-type compositional reasoning and offers a test bed for future improvement.</li>
</ul>

<h3>Title: Selective Retrieval-Augmentation for Long-Tail Legal Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Boheng Mao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19997">https://arxiv.org/abs/2508.19997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19997">https://arxiv.org/pdf/2508.19997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19997]] Selective Retrieval-Augmentation for Long-Tail Legal Text Classification(https://arxiv.org/abs/2508.19997)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Legal text classification is a fundamental NLP task in the legal domain. Benchmark datasets in this area often exhibit a long-tail label distribution, where many labels are underrepresented, leading to poor model performance on rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a solution to this problem. SRA focuses on augmenting samples belonging to low-frequency labels in the training set, preventing the introduction of noise for well-represented classes, and requires no changes to the model architecture. Retrieval is performed only from the training data to ensure there is no potential information leakage, removing the need for external corpora simultaneously. The proposed SRA method is tested on two legal text classification benchmark datasets with long-tail distributions: LEDGAR (single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE baselines across both datasets, illustrating consistent improvements in long-tail legal text classification. The code repository is available at: this https URL</li>
</ul>

<h3>Title: Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Ji Wang, Kashing Chen, Xinyuan Song, Ke Zhang, Lynn Ai, Eric Yang, Bill Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20019">https://arxiv.org/abs/2508.20019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20019">https://arxiv.org/pdf/2508.20019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20019]] Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence(https://arxiv.org/abs/2508.20019)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Most existing Large Language Model (LLM)-based agent frameworks rely on centralized orchestration, incurring high deployment costs, rigid communication topologies, and limited adaptability. To address these challenges, we introduce Symphony, a decentralized multi-agent system which enables lightweight LLMs on consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms: (1) a decentralized ledger that records capabilities, (2) a Beacon-selection protocol for dynamic task allocation, and (3) weighted result voting based on CoTs. This design forms a privacy-saving, scalable, and fault-tolerant orchestration with low overhead. Empirically, Symphony outperforms existing baselines on reasoning benchmarks, achieving substantial accuracy gains and demonstrating robustness across models of varying capacities.</li>
</ul>

<h3>Title: GS: Generative Segmentation via Label Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Chen, Shubin Chen, Liang Lin, Guangrun Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20020">https://arxiv.org/abs/2508.20020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20020">https://arxiv.org/pdf/2508.20020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20020]] GS: Generative Segmentation via Label Diffusion(https://arxiv.org/abs/2508.20020)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Language-driven image segmentation is a fundamental task in vision-language understanding, requiring models to segment regions of an image corresponding to natural language expressions. Traditional methods approach this as a discriminative problem, assigning each pixel to foreground or background based on semantic alignment. Recently, diffusion models have been introduced to this domain, but existing approaches remain image-centric: they either (i) use image diffusion models as visual feature extractors, (ii) synthesize segmentation data via image generation to train discriminative models, or (iii) perform diffusion inversion to extract attention cues from pre-trained image diffusion models-thereby treating segmentation as an auxiliary process. In this paper, we propose GS (Generative Segmentation), a novel framework that formulates segmentation itself as a generative task via label diffusion. Instead of generating images conditioned on label maps and text, GS reverses the generative process: it directly generates segmentation masks from noise, conditioned on both the input image and the accompanying language description. This paradigm makes label generation the primary modeling target, enabling end-to-end training with explicit control over spatial and semantic fidelity. To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic Narrative Grounding (PNG), a representative and challenging benchmark for multimodal segmentation that requires panoptic-level reasoning guided by narrative captions. Experimental results show that GS significantly outperforms existing discriminative and diffusion-based methods, setting a new state-of-the-art for language-driven segmentation.</li>
</ul>

<h3>Title: FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Felix Möhrlein, Martin Käppel, Julian Neuberger, Sven Weinzierl, Lars Ackermann, Martin Matzner, Stefan Jablonski</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20021">https://arxiv.org/abs/2508.20021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20021">https://arxiv.org/pdf/2508.20021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20021]] FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring(https://arxiv.org/abs/2508.20021)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Sensitive attributes like gender or age can lead to unfair predictions in machine learning tasks such as predictive business process monitoring, particularly when used without considering context. We present FairLoop1, a tool for human-guided bias mitigation in neural network-based prediction models. FairLoop distills decision trees from neural networks, allowing users to inspect and modify unfair decision logic, which is then used to fine-tune the original model towards fairer predictions. Compared to other approaches to fairness, FairLoop enables context-aware bias removal through human involvement, addressing the influence of sensitive attributes selectively rather than excluding them uniformly.</li>
</ul>

<h3>Title: Using item recommendations and LLMs in marketing email titles</h3>
<ul>
<li><strong>Authors: </strong>Deddy Jobson, Muktti Shukla, Phuong Dinh, Julio Christian Young, Nick Pitton, Nina Chen, Ryan Ginstrom</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20024">https://arxiv.org/abs/2508.20024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20024">https://arxiv.org/pdf/2508.20024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20024]] Using item recommendations and LLMs in marketing email titles(https://arxiv.org/abs/2508.20024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>E-commerce marketplaces make use of a number of marketing channels like emails, push notifications, etc. to reach their users and stimulate purchases. Personalized emails especially are a popular touch point for marketers to inform users of latest items in stock, especially for those who stopped visiting the marketplace. Such emails contain personalized recommendations tailored to each user's interests, enticing users to buy relevant items. A common limitation of these emails is that the primary entry point, the title of the email, tends to follow fixed templates, failing to inspire enough interest in the contents. In this work, we explore the potential of large language models (LLMs) for generating thematic titles that reflect the personalized content of the emails. We perform offline simulations and conduct online experiments on the order of millions of users, finding our techniques useful in improving the engagement between customers and our emails. We highlight key findings and learnings as we productionize the safe and automated generation of email titles for millions of users.</li>
</ul>

<h3>Title: Segmentation Assisted Incremental Test Time Adaptation in an Open World</h3>
<ul>
<li><strong>Authors: </strong>Manogna Sreenivas, Soma Biswas</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20029">https://arxiv.org/abs/2508.20029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20029">https://arxiv.org/pdf/2508.20029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20029]] Segmentation Assisted Incremental Test Time Adaptation in an Open World(https://arxiv.org/abs/2508.20029)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In dynamic environments, unfamiliar objects and distribution shifts are often encountered, which challenge the generalization abilities of the deployed trained models. This work addresses Incremental Test Time Adaptation of Vision Language Models, tackling scenarios where unseen classes and unseen domains continuously appear during testing. Unlike traditional Test Time Adaptation approaches, where the test stream comes only from a predefined set of classes, our framework allows models to adapt simultaneously to both covariate and label shifts, actively incorporating new classes as they emerge. Towards this goal, we establish a new benchmark for ITTA, integrating single image TTA methods for VLMs with active labeling techniques that query an oracle for samples potentially representing unseen classes during test time. We propose a segmentation assisted active labeling module, termed SegAssist, which is training free and repurposes the segmentation capabilities of VLMs to refine active sample selection, prioritizing samples likely to belong to unseen classes. Extensive experiments on several benchmark datasets demonstrate the potential of SegAssist to enhance the performance of VLMs in real world scenarios, where continuous adaptation to emerging data is essential. Project-page:this https URL</li>
</ul>

<h3>Title: Pruning Strategies for Backdoor Defense in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Santosh Chapagain, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20032">https://arxiv.org/abs/2508.20032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20032">https://arxiv.org/pdf/2508.20032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20032]] Pruning Strategies for Backdoor Defense in LLMs(https://arxiv.org/abs/2508.20032)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal</a></li>
<li><strong>Abstract: </strong>Backdoor attacks are a significant threat to the performance and integrity of pre-trained language models. Although such models are routinely fine-tuned for downstream NLP tasks, recent work shows they remain vulnerable to backdoor attacks that survive vanilla fine-tuning. These attacks are difficult to defend because end users typically lack knowledge of the attack triggers. Such attacks consist of stealthy malicious triggers introduced through subtle syntactic or stylistic manipulations, which can bypass traditional detection and remain in the model, making post-hoc purification essential. In this study, we explore whether attention-head pruning can mitigate these threats without any knowledge of the trigger or access to a clean reference model. To this end, we design and implement six pruning-based strategies: (i) gradient-based pruning, (ii) layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2 sparsification, (iv) randomized ensemble pruning, (v) reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning. Each method iteratively removes the least informative heads while monitoring validation accuracy to avoid over-pruning. Experimental evaluation shows that gradient-based pruning performs best while defending the syntactic triggers, whereas reinforcement learning and Bayesian pruning better withstand stylistic attacks.</li>
</ul>

<h3>Title: DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Liana Patel, Negar Arabzadeh, Harshit Gupta, Ankita Sundar, Ion Stoica, Matei Zaharia, Carlos Guestrin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20033">https://arxiv.org/abs/2508.20033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20033">https://arxiv.org/pdf/2508.20033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20033]] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis(https://arxiv.org/abs/2508.20033)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The ability to research and synthesize knowledge is central to human expertise and progress. An emerging class of systems promises these exciting capabilities through generative research synthesis, performing retrieval over the live web and synthesizing discovered sources into long-form, cited summaries. However, evaluating such systems remains an open challenge: existing question-answering benchmarks focus on short-form factual responses, while expert-curated datasets risk staleness and data contamination. Both fail to capture the complexity and evolving nature of real research synthesis tasks. In this work, we introduce DeepScholar-bench, a live benchmark and holistic, automated evaluation framework designed to evaluate generative research synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv papers and focuses on a real research synthesis task: generating the related work sections of a paper by retrieving, synthesizing, and citing prior research. Our evaluation framework holistically assesses performance across three key dimensions, knowledge synthesis, retrieval quality, and verifiability. We also develop DeepScholar-base, a reference pipeline implemented efficiently using the LOTUS API. Using the DeepScholar-bench framework, we perform a systematic evaluation of prior open-source systems, search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that DeepScholar-base establishes a strong baseline, attaining competitive or higher performance than each other method. We also find that DeepScholar-bench remains far from saturated, with no system exceeding a score of $19\%$ across all metrics. These results underscore the difficulty of DeepScholar-bench, as well as its importance for progress towards AI systems capable of generative research synthesis. We make our code available at this https URL.</li>
</ul>

<h3>Title: Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks</h3>
<ul>
<li><strong>Authors: </strong>Sheng Liu, Qiang Sheng, Danding Wang, Yang Li, Guang Yang, Juan Cao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20038">https://arxiv.org/abs/2508.20038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20038">https://arxiv.org/pdf/2508.20038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20038]] Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks(https://arxiv.org/abs/2508.20038)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Despite advances in improving large language model(LLM) to refuse to answer malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks where attackers generate instructions with distributions differing from safety alignment corpora. New attacks expose LLMs' inability to recognize unseen malicious instructions, highlighting a critical distributional mismatch between training data and real-world attacks that forces developers into reactive patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis framework that leverages embedding space distribution analysis to generate jailbreak-like instructions. This approach effectively fills the distributional gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE follows an iterative optimization process that dynamically evolves text generation distributions across iterations, thereby augmenting the coverage of safety alignment data distributions through synthesized data examples. Based on the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2 without compromising their utility.</li>
</ul>

<h3>Title: AraHealthQA 2025 Shared Task Description Paper</h3>
<ul>
<li><strong>Authors: </strong>Hassan Alhuzali, Farah Shamout, Muhammad Abdul-Mageed, Chaimae Abouzahir, Mouath Abu-Daoud, Ashwag Alasmari, Walid Al-Eisawi, Renad Al-Monef, Ali Alqahtani, Lama Ayash, Nizar Habash, Leen Kharouf</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20047">https://arxiv.org/abs/2508.20047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20047">https://arxiv.org/pdf/2508.20047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20047]] AraHealthQA 2025 Shared Task Description Paper(https://arxiv.org/abs/2508.20047)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic medical QA resources by offering two complementary tracks: {MentalQA}, focusing on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and {MedArabiQ}, covering broader medical domains such as internal medicine, pediatrics, and clinical decision making. Each track comprises multiple subtasks, evaluation datasets, and standardized metrics, facilitating fair benchmarking. The task was structured to promote modeling under realistic, multilingual, and culturally nuanced healthcare contexts. We outline the dataset creation, task design and evaluation framework, participation statistics, baseline systems, and summarize the overall outcomes. We conclude with reflections on the performance trends observed and prospects for future iterations in Arabic health QA.</li>
</ul>

<h3>Title: SCAMPER -- Synchrophasor Covert chAnnel for Malicious and Protective ERrands</h3>
<ul>
<li><strong>Authors: </strong>Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20051">https://arxiv.org/abs/2508.20051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20051">https://arxiv.org/pdf/2508.20051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20051]] SCAMPER -- Synchrophasor Covert chAnnel for Malicious and Protective ERrands(https://arxiv.org/abs/2508.20051)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>We note that constituent fields (notably the fraction-of-seconds timestamp field) in the data payload structure of the synchrophasor communication protocol (IEEE C37.118 standard) are overprovisioned relative to real-world usage and needs, lending themselves to abuse for embedding of covert channels. We develop the SCAMPER (Synchrophasor Covert Channel for Malicious and Protective ERrands) framework to exploit these overprovisioned fields for covert communication and show that SCAMPER can be applied for both malicious (attack) and protective (defense) purposes. Through modifications of the timestamp field, we demonstrate that SCAMPER enables an attacker to accomplish surreptitious communications between devices in the power system to trigger a variety of malicious actions. These timestamp modifications can be performed without having any impact on the operation of the power system. However, having recognized the potential for this covert channel, we show that SCAMPER can instead be applied for defensive security purposes as an integrated cryptographic data integrity mechanism that can facilitate detection of false data injection (FDI) attacks. We perform experimental studies of the proposed methods on two Hardware-in-the-Loop (HIL) testbeds to demonstrate the effectiveness of the proposed SCAMPER framework for both malicious and protective purposes.</li>
</ul>

<h3>Title: PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence</h3>
<ul>
<li><strong>Authors: </strong>Zheng Li, Yanming Guo, WenZhe Liu, Xueyi Zhang, Zhaoyun Ding, Long Xu, Mingrui Lao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20066">https://arxiv.org/abs/2508.20066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20066">https://arxiv.org/pdf/2508.20066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20066]] PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence(https://arxiv.org/abs/2508.20066)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-view geo-localization is a critical task for UAV navigation, event detection, and aerial surveying, as it enables matching between drone-captured and satellite imagery. Most existing approaches embed multi-modal data into a joint feature space to maximize the similarity of paired images. However, these methods typically assume perfect alignment of image pairs during training, which rarely holds true in real-world scenarios. In practice, factors such as urban canyon effects, electromagnetic interference, and adverse weather frequently induce GPS drift, resulting in systematic alignment shifts where only partial correspondences exist between pairs. Despite its prevalence, this source of noisy correspondence has received limited attention in current research. In this paper, we formally introduce and address the Noisy Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to bridge the gap between idealized benchmarks and practical applications. To this end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a novel framework that partitions and augments training data based on estimated data uncertainty through uncertainty-aware co-augmentation and evidential co-training. Specifically, PAUL selectively augments regions with high correspondence confidence and utilizes uncertainty estimation to refine feature learning, effectively suppressing noise from misaligned pairs. Distinct from traditional filtering or label correction, PAUL leverages both data uncertainty and loss discrepancy for targeted partitioning and augmentation, thus providing robust supervision for noisy samples. Comprehensive experiments validate the effectiveness of individual components in PAUL,which consistently achieves superior performance over other competitive noisy-correspondence-driven methods in various noise ratios.</li>
</ul>

<h3>Title: 11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis</h3>
<ul>
<li><strong>Authors: </strong>Chengzu Li, Wenshan Wu, Huanyu Zhang, Qingtao Li, Zeyu Gao, Yan Xia, José Hernández-Orallo, Ivan Vulić, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20068">https://arxiv.org/abs/2508.20068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20068">https://arxiv.org/pdf/2508.20068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20068]] 11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis(https://arxiv.org/abs/2508.20068)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>For human cognitive process, spatial reasoning and perception are closely entangled, yet the nature of this interplay remains underexplored in the evaluation of multimodal large language models (MLLMs). While recent MLLM advancements show impressive performance on reasoning, their capacity for human-like spatial cognition remains an open question. In this work, we introduce a systematic evaluation framework to assess the spatial reasoning abilities of state-of-the-art MLLMs relative to human performance. Central to our work is 11Plus-Bench, a high-quality benchmark derived from realistic standardized spatial aptitude tests. 11Plus-Bench also features fine-grained expert annotations of both perceptual complexity and reasoning process, enabling detailed instance-level analysis of model behavior. Through extensive experiments across 14 MLLMs and human evaluation, we find that current MLLMs exhibit early signs of spatial cognition. Despite a large performance gap compared to humans, MLLMs' cognitive profiles resemble those of humans in that cognitive effort correlates strongly with reasoning-related complexity. However, instance-level performance in MLLMs remains largely random, whereas human correctness is highly predictable and shaped by abstract pattern complexity. These findings highlight both emerging capabilities and limitations in current MLLMs' spatial reasoning capabilities and provide actionable insights for advancing model design.</li>
</ul>

<h3>Title: Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Liang, Yizhuo Li, Tianshuo Yang, Chengyue Wu, Sitong Mao, Liuao Pei, Xiaokang Yang, Jiangmiao Pang, Yao Mu, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20072">https://arxiv.org/abs/2508.20072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20072">https://arxiv.org/pdf/2508.20072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20072]] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies(https://arxiv.org/abs/2508.20072)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Vision-Language-Action (VLA) models adapt large vision-language backbones to map images and instructions to robot actions. However, prevailing VLA decoders either generate actions autoregressively in a fixed left-to-right order or attach continuous diffusion or flow matching heads outside the backbone, demanding specialized training and iterative sampling that hinder a unified, scalable architecture. We present Discrete Diffusion VLA, a single-transformer policy that models discretized action chunks with discrete diffusion and is trained with the same cross-entropy objective as the VLM backbone. The design retains diffusion's progressive refinement paradigm while remaining natively compatible with the discrete token interface of VLMs. Our method achieves an adaptive decoding order that resolves easy action elements before harder ones and uses secondary remasking to revisit uncertain predictions across refinement rounds, which improves consistency and enables robust error correction. This unified decoder preserves pretrained vision language priors, supports parallel decoding, breaks the autoregressive bottleneck, and reduces the number of function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO, 71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv Bridge, improving over both autoregressive and continuous diffusion baselines. These findings indicate that discrete-diffusion action decoder supports precise action modeling and consistent training, laying groundwork for scaling VLA to larger models and datasets.</li>
</ul>

<h3>Title: Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning</h3>
<ul>
<li><strong>Authors: </strong>Yanbo Dai, Zhenlan Ji, Zongjie Li, Kuan Li, Shuai Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20083">https://arxiv.org/abs/2508.20083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20083">https://arxiv.org/pdf/2508.20083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20083]] Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning(https://arxiv.org/abs/2508.20083)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has become a standard approach for improving the reliability of large language models (LLMs). Prior work demonstrates the vulnerability of RAG systems by misleading them into generating attacker-chosen outputs through poisoning the knowledge base. However, this paper uncovers that such attacks could be mitigated by the strong \textit{self-correction ability (SCA)} of modern LLMs, which can reject false context once properly configured. This SCA poses a significant challenge for attackers aiming to manipulate RAG systems. In contrast to previous poisoning methods, which primarily target the knowledge base, we introduce \textsc{DisarmRAG}, a new poisoning paradigm that compromises the retriever itself to suppress the SCA and enforce attacker-chosen outputs. This compromisation enables the attacker to straightforwardly embed anti-SCA instructions into the context provided to the generator, thereby bypassing the SCA. To this end, we present a contrastive-learning-based model editing technique that performs localized and stealthy edits, ensuring the retriever returns a malicious instruction only for specific victim queries while preserving benign retrieval behavior. To further strengthen the attack, we design an iterative co-optimization framework that automatically discovers robust instructions capable of bypassing prompt-based defenses. We extensively evaluate DisarmRAG across six LLMs and three QA benchmarks. Our results show near-perfect retrieval of malicious instructions, which successfully suppress SCA and achieve attack success rates exceeding 90\% under diverse defensive prompts. Also, the edited retriever remains stealthy under several detection methods, highlighting the urgent need for retriever-centric defenses.</li>
</ul>

<h3>Title: AudioStory: Generating Long-Form Narrative Audio with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Guo, Teng Wang, Yuying Ge, Shijie Ma, Yixiao Ge, Wei Zou, Ying Shan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20088">https://arxiv.org/abs/2508.20088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20088">https://arxiv.org/pdf/2508.20088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20088]] AudioStory: Generating Long-Form Narrative Audio with Large Language Models(https://arxiv.org/abs/2508.20088)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in text-to-audio (TTA) generation excel at synthesizing short audio clips but struggle with long-form narrative audio, which requires temporal coherence and compositional reasoning. To address this gap, we propose AudioStory, a unified framework that integrates large language models (LLMs) with TTA systems to generate structured, long-form audio narratives. AudioStory possesses strong instruction-following reasoning generation capabilities. It employs LLMs to decompose complex narrative queries into temporally ordered sub-tasks with contextual cues, enabling coherent scene transitions and emotional tone consistency. AudioStory has two appealing features: (1) Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser collaboration into two specialized components, i.e., a bridging query for intra-event semantic alignment and a residual query for cross-event coherence preservation. (2) End-to-end training: By unifying instruction comprehension and audio generation within a single end-to-end framework, AudioStory eliminates the need for modular training pipelines while enhancing synergy between components. Furthermore, we establish a benchmark AudioStory-10K, encompassing diverse domains such as animated soundscapes and natural sound narratives. Extensive experiments show the superiority of AudioStory on both single-audio generation and narrative audio generation, surpassing prior TTA baselines in both instruction-following ability and audio fidelity. Our code is available at this https URL</li>
</ul>

<h3>Title: CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zeyi Sun, Yuhang Cao, Jianze Liang, Qiushi Sun, Ziyu Liu, Zhixiong Zhang, Yuhang Zang, Xiaoyi Dong, Kai Chen, Dahua Lin, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.20096">https://arxiv.org/abs/2508.20096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.20096">https://arxiv.org/pdf/2508.20096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.20096]] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning(https://arxiv.org/abs/2508.20096)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Autonomous agents for Graphical User Interfaces (GUIs) face significant challenges in specialized domains such as scientific computing, where both long-horizon planning and precise execution are required. Existing approaches suffer from a trade-off: generalist agents excel at planning but perform poorly in execution, while specialized agents demonstrate the opposite weakness. Recent compositional frameworks attempt to bridge this gap by combining a planner and an actor, but they are typically static and non-trainable, which prevents adaptation from experience. This is a critical limitation given the scarcity of high-quality data in scientific domains. To address these limitations, we introduce CODA, a novel and trainable compositional framework that integrates a generalist planner (Cerebrum) with a specialist executor (Cerebellum), trained via a dedicated two-stage pipeline. In the first stage, Specialization, we apply a decoupled GRPO approach to train an expert planner for each scientific application individually, bootstrapping from a small set of task trajectories. In the second stage, Generalization, we aggregate all successful trajectories from the specialized experts to build a consolidated dataset, which is then used for supervised fine-tuning of the final planner. This equips CODA with both robust execution and cross-domain generalization. Evaluated on four challenging applications from the ScienceBoard benchmark, CODA significantly outperforms baselines and establishes a new state of the art among open-source models.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
