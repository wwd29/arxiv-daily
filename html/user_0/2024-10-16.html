<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-10-16</h1>
<h3>Title: High-Fidelity 3D Lung CT Synthesis in ARDS Swine Models Using Score-Based 3D Residual Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Siyeop Yoon, Yujin Oh, Xiang Li, Yi Xin, Maurizio Cereda, Quanzheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10826">https://arxiv.org/abs/2410.10826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10826">https://arxiv.org/pdf/2410.10826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10826]] High-Fidelity 3D Lung CT Synthesis in ARDS Swine Models Using Score-Based 3D Residual Diffusion Models(https://arxiv.org/abs/2410.10826)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Acute respiratory distress syndrome (ARDS) is a severe condition characterized by lung inflammation and respiratory failure, with a high mortality rate of approximately 40%. Traditional imaging methods, such as chest X-rays, provide only two-dimensional views, limiting their effectiveness in fully assessing lung pathology. Three-dimensional (3D) computed tomography (CT) offers a more comprehensive visualization, enabling detailed analysis of lung aeration, atelectasis, and the effects of therapeutic interventions. However, the routine use of CT in ARDS management is constrained by practical challenges and risks associated with transporting critically ill patients to remote scanners. In this study, we synthesize high-fidelity 3D lung CT from 2D generated X-ray images with associated physiological parameters using a score-based 3D residual diffusion model. Our preliminary results demonstrate that this approach can produce high-quality 3D CT images that are validated with ground truth, offering a promising solution for enhancing ARDS management.</li>
</ul>

<h3>Title: Focus On What Matters: Separated Models For Visual-Based RL Generalization</h3>
<ul>
<li><strong>Authors: </strong>Di Zhang, Bowen Lv, Hai Zhang, Feifan Yang, Junqiao Zhao, Hang Yu, Chang Huang, Hongtu Zhou, Chen Ye, Changjun Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10834">https://arxiv.org/abs/2410.10834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10834">https://arxiv.org/pdf/2410.10834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10834]] Focus On What Matters: Separated Models For Visual-Based RL Generalization(https://arxiv.org/abs/2410.10834)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A primary challenge for visual-based Reinforcement Learning (RL) is to generalize effectively across unseen environments. Although previous studies have explored different auxiliary tasks to enhance generalization, few adopt image reconstruction due to concerns about exacerbating overfitting to task-irrelevant features during training. Perceiving the pre-eminence of image reconstruction in representation learning, we propose SMG (Separated Models for Generalization), a novel approach that exploits image reconstruction for generalization. SMG introduces two model branches to extract task-relevant and task-irrelevant representations separately from visual observations via cooperatively reconstruction. Built upon this architecture, we further emphasize the importance of task-relevant features for generalization. Specifically, SMG incorporates two additional consistency losses to guide the agent's focus toward task-relevant areas across different scenarios, thereby achieving free from overfitting. Extensive experiments in DMC demonstrate the SOTA performance of SMG in generalization, particularly excelling in video-background settings. Evaluations on robotic manipulation tasks further confirm the robustness of SMG in real-world applications.</li>
</ul>

<h3>Title: Duo-LLM: A Framework for Studying Adaptive Computation in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Keivan Alizadeh, Iman Mirzadeh, Hooman Shahrokhi, Dmitry Belenko, Frank Sun, Minsik Cho, Mohammad Hossein Sekhavat, Moin Nabi, Mehrdad Farajtabar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10846">https://arxiv.org/abs/2410.10846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10846">https://arxiv.org/pdf/2410.10846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10846]] Duo-LLM: A Framework for Studying Adaptive Computation in Large Language Models(https://arxiv.org/abs/2410.10846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) typically generate outputs token by token using a fixed compute budget, leading to inefficient resource utilization. To address this shortcoming, recent advancements in mixture of expert (MoE) models, speculative decoding, and early exit strategies leverage the insight that computational demands can vary significantly based on the complexity and nature of the input. However, identifying optimal routing patterns for dynamic execution remains an open challenge, limiting the full potential of these adaptive methods. To address this need, we study adaptive computation in LLMs more systematically. We propose a novel framework that integrates smaller auxiliary modules within each Feed-Forward Network layer of the LLM. This design enables dynamic routing of tokens based on task complexity: tokens can be processed by either the small or big modules at each layer, or even bypass certain layers entirely. This allows us to introduce a novel notion of a token's difficulty, defined by its potential to benefit from additional computational resources. Importantly, by employing oracles to identify optimal patterns of adaptive computations, we gain valuable insights into the internal workings of LLMs and the routing processes in a simplified heterogeneous MoE setup. We show that trained routers operate differently from oracles and often yield suboptimal solutions. Notably, activating a large module in just one layer outperforms models that use large modules across all layers, underscoring the gap between practical implementations of routing in MoE models and theoretical optima for adaptive computation.</li>
</ul>

<h3>Title: Continuous Approximations for Improving Quantization Aware Training of LLMs</h3>
<ul>
<li><strong>Authors: </strong>He Li, Jianhang Hong, Yuanzhuo Wu, Snehal Adbol, Zonglin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10849">https://arxiv.org/abs/2410.10849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10849">https://arxiv.org/pdf/2410.10849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10849]] Continuous Approximations for Improving Quantization Aware Training of LLMs(https://arxiv.org/abs/2410.10849)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Model compression methods are used to reduce the computation and energy requirements for Large Language Models (LLMs). Quantization Aware Training (QAT), an effective model compression method, is proposed to reduce performance degradation after quantization. To further minimize this degradation, we introduce two continuous approximations to the QAT process on the rounding function, traditionally approximated by the Straight-Through Estimator (STE), and the clamping function. By applying both methods, the perplexity (PPL) on the WikiText-v2 dataset of the quantized model reaches 9.0815, outperforming 9.9621 by the baseline. Also, we achieve a 2.76% improvement on BoolQ, and a 5.47% improvement on MMLU, proving that the step sizes and weights can be learned more accurately with our approach. Our method achieves better performance with the same precision, model size, and training setup, contributing to the development of more energy-efficient LLMs technology that aligns with global sustainability goals.</li>
</ul>

<h3>Title: On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts</h3>
<ul>
<li><strong>Authors: </strong>Toluwani Aremu, Oluwakemi Akinwehinmi, Chukwuemeka Nwagu, Syed Ishtiaque Ahmed, Rita Orji, Pedro Arnau Del Amo, Abdulmotaleb El Saddik</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10850">https://arxiv.org/abs/2410.10850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10850">https://arxiv.org/pdf/2410.10850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10850]] On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts(https://arxiv.org/abs/2410.10850)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>We investigate and observe the behaviour and performance of Large Language Model (LLM)-backed chatbots in addressing misinformed prompts and questions with demographic information within the domains of Climate Change and Mental Health. Through a combination of quantitative and qualitative methods, we assess the chatbots' ability to discern the veracity of statements, their adherence to facts, and the presence of bias or misinformation in their responses. Our quantitative analysis using True/False questions reveals that these chatbots can be relied on to give the right answers to these close-ended questions. However, the qualitative insights, gathered from domain experts, shows that there are still concerns regarding privacy, ethical implications, and the necessity for chatbots to direct users to professional services. We conclude that while these chatbots hold significant promise, their deployment in sensitive areas necessitates careful consideration, ethical oversight, and rigorous refinement to ensure they serve as a beneficial augmentation to human expertise rather than an autonomous solution.</li>
</ul>

<h3>Title: SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenance</h3>
<ul>
<li><strong>Authors: </strong>Connor Walker, Callum Rothon, Koorosh Aslansefat, Yiannis Papadopoulos, Nina Dethlefs</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10852">https://arxiv.org/abs/2410.10852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10852">https://arxiv.org/pdf/2410.10852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10852]] SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenance(https://arxiv.org/abs/2410.10852)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Offshore Wind (OSW) industry is experiencing significant expansion, resulting in increased Operations \& Maintenance (O\&M) costs. Intelligent alarm systems offer the prospect of swift detection of component failures and process anomalies, enabling timely and precise interventions that could yield reductions in resource expenditure, as well as scheduled and unscheduled downtime. This paper introduces an innovative approach to tackle this challenge by capitalising on Large Language Models (LLMs). We present a specialised conversational agent that incorporates statistical techniques to calculate distances between sentences for the detection and filtering of hallucinations and unsafe output. This potentially enables improved interpretation of alarm sequences and the generation of safer repair action recommendations by the agent. Preliminary findings are presented with the approach applied to ChatGPT-4 generated test sentences. The limitation of using ChatGPT-4 and the potential for enhancement of this agent through re-training with specialised OSW datasets are discussed.</li>
</ul>

<h3>Title: Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support</h3>
<ul>
<li><strong>Authors: </strong>Abdul Muqtadir, Hafiz Syed Muhammad Bilal, Ayesha Yousaf, Hafiz Farooq Ahmed, Jamil Hussain</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10853">https://arxiv.org/abs/2410.10853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10853">https://arxiv.org/pdf/2410.10853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10853]] Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support(https://arxiv.org/abs/2410.10853)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>This research work delves into the manifestation of hallucination within Large Language Models (LLMs) and its consequential impacts on applications within the domain of mental health. The primary objective is to discern effective strategies for curtailing hallucinatory occurrences, thereby bolstering the dependability and security of LLMs in facilitating mental health interventions such as therapy, counseling, and the dissemination of pertinent information. Through rigorous investigation and analysis, this study seeks to elucidate the underlying mechanisms precipitating hallucinations in LLMs and subsequently propose targeted interventions to alleviate their occurrence. By addressing this critical issue, the research endeavors to foster a more robust framework for the utilization of LLMs within mental health contexts, ensuring their efficacy and reliability in aiding therapeutic processes and delivering accurate information to individuals seeking mental health support.</li>
</ul>

<h3>Title: CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yijiang Li, Qingying Gao, Haoran Sun, Haiyun Lyu, Dezhi Luo, Hokin Deng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10855">https://arxiv.org/abs/2410.10855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10855">https://arxiv.org/pdf/2410.10855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10855]] CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models(https://arxiv.org/abs/2410.10855)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Are Multi-modal Large Language Models (MLLMs) stochastic parrots? Do they genuinely understand and are capable of performing the tasks they excel at? This paper aims to explore the fundamental basis of MLLMs, i.e. core cognitive abilities that human intelligence builds upon to perceive, comprehend, and reason. To this end, we propose CogDevelop2K, a comprehensive benchmark that spans 12 sub-concepts from fundamental knowledge like object permanence and boundary to advanced reasoning like intentionality understanding, structured via the developmental trajectory of a human mind. We evaluate 46 MLLMs on our benchmarks. Comprehensively, we further evaluate the influence of evaluation strategies and prompting techniques. Surprisingly, we observe a reversed cognitive developmental trajectory compared to humans.</li>
</ul>

<h3>Title: Mirror-Consistency: Harnessing Inconsistency in Majority Voting</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Zhouhan Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10857">https://arxiv.org/abs/2410.10857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10857">https://arxiv.org/pdf/2410.10857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10857]] Mirror-Consistency: Harnessing Inconsistency in Majority Voting(https://arxiv.org/abs/2410.10857)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-Consistency, a widely-used decoding strategy, significantly boosts the reasoning capabilities of Large Language Models (LLMs). However, it depends on the plurality voting rule, which focuses on the most frequent answer while overlooking all other minority responses. These inconsistent minority views often illuminate areas of uncertainty within the model's generation process. To address this limitation, we present Mirror-Consistency, an enhancement of the standard Self-Consistency approach. Our method incorporates a 'reflective mirror' into the self-ensemble decoding process and enables LLMs to critically examine inconsistencies among multiple generations. Additionally, just as humans use the mirror to better understand themselves, we propose using Mirror-Consistency to enhance the sample-based confidence calibration methods, which helps to mitigate issues of overconfidence. Our experimental results demonstrate that Mirror-Consistency yields superior performance in both reasoning accuracy and confidence calibration compared to Self-Consistency.</li>
</ul>

<h3>Title: Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths</h3>
<ul>
<li><strong>Authors: </strong>Yew Ken Chia, Guizhen Chen, Weiwen Xu, Luu Anh Tuan, Soujanya Poria, Lidong Bing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10858">https://arxiv.org/abs/2410.10858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10858">https://arxiv.org/pdf/2410.10858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10858]] Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths(https://arxiv.org/abs/2410.10858)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advanced models such as OpenAI o1 exhibit impressive problem-solving capabilities through step-by-step reasoning. However, they may still falter on more complex problems, making errors that disrupt their reasoning paths. We attribute this to the expansive solution space, where each step has the risk of diverging into mistakes. To enhance language model reasoning, we introduce a specialized training framework called Reasoning Paths Optimization (RPO), which enables learning to reason and explore from diverse paths. Our approach encourages favorable branches at each reasoning step while penalizing unfavorable ones, enhancing the model's overall problem-solving performance. Reasoning Paths Optimization does not rely on large-scale human-annotated rationales or outputs from closed-source models, making it scalable and data-efficient. We focus on multi-step reasoning tasks, such as math word problems and science-based exam questions. The experiments demonstrate that our framework significantly enhances the reasoning performance of large language models, with up to 3.1% and 4.3% improvement on GSM8K and MMLU (STEM) respectively. Our data and code can be found at this https URL.</li>
</ul>

<h3>Title: FAME: Towards Factual Multi-Task Model Editing</h3>
<ul>
<li><strong>Authors: </strong>Li Zeng, Yingyu Shan, Zeming Liu, Jiashu Yao, Yuhang Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10859">https://arxiv.org/abs/2410.10859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10859">https://arxiv.org/pdf/2410.10859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10859]] FAME: Towards Factual Multi-Task Model Editing(https://arxiv.org/abs/2410.10859)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) embed extensive knowledge and utilize it to perform exceptionally well across various tasks. Nevertheless, outdated knowledge or factual errors within LLMs can lead to misleading or incorrect responses, causing significant issues in practical applications. To rectify the fatal flaw without the necessity for costly model retraining, various model editing approaches have been proposed to correct inaccurate knowledge within LLMs in a cost-efficient way. To evaluate these model editing methods, previous work introduced a series of datasets. However, most of the previous datasets only contain fabricated data in a single format, which diverges from real-world model editing scenarios, raising doubts about their usability in practice. To facilitate the application of model editing in real-world scenarios, we propose the challenge of practicality. To resolve such challenges and effectively enhance the capabilities of LLMs, we present FAME, an factual, comprehensive, and multi-task dataset, which is designed to enhance the practicality of model editing. We then propose SKEME, a model editing method that uses a novel caching mechanism to ensure synchronization with the real world. The experiments demonstrate that SKEME performs excellently across various tasks and scenarios, confirming its practicality.</li>
</ul>

<h3>Title: A Recipe For Building a Compliant Real Estate Chatbot</h3>
<ul>
<li><strong>Authors: </strong>Navid Madani, Anusha Bagalkotkar, Supriya Anand, Gabriel Arnson, Rohini Srihari, Kenneth Joseph</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10860">https://arxiv.org/abs/2410.10860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10860">https://arxiv.org/pdf/2410.10860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10860]] A Recipe For Building a Compliant Real Estate Chatbot(https://arxiv.org/abs/2410.10860)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, there has been significant effort to align large language models with human preferences. This work focuses on developing a chatbot specialized in the real estate domain, with an emphasis on incorporating compliant behavior to ensure it can be used without perpetuating discriminatory practices like steering and redlining, which have historically plagued the real estate industry in the United States. Building on prior work, we present a method for generating a synthetic general instruction-following dataset, along with safety data. Through extensive evaluations and benchmarks, we fine-tuned a llama-3-8B-instruct model and demonstrated that we can enhance it's performance significantly to match huge closed-source models like GPT-4o while making it safer and more compliant. We open-source the model, data and code to support further development and research in the community.</li>
</ul>

<h3>Title: Superficial Safety Alignment Hypothesis</h3>
<ul>
<li><strong>Authors: </strong>Jianwei Li, Jung-Eun Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10862">https://arxiv.org/abs/2410.10862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10862">https://arxiv.org/pdf/2410.10862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10862]] Superficial Safety Alignment Hypothesis(https://arxiv.org/abs/2410.10862)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) are overwhelmingly more and more integrated into various applications, ensuring they generate safe and aligned responses is a pressing need. Previous research on alignment has largely focused on general instruction-following but has often overlooked the unique properties and challenges of safety alignment, such as the brittleness of safety mechanisms. To bridge the gap, we propose the Superficial Safety Alignment Hypothesis (SSAH), which posits that safety alignment should teach an otherwise unsafe model to choose the correct reasoning direction - interpreted as a specialized binary classification task - and incorporate a refusal mechanism with multiple reserved fallback options. Furthermore, through SSAH, we hypothesize that safety guardrails in LLMs can be established by just a small number of essential components. To verify this, we conduct an ablation study and successfully identify four types of attribute-critical components in safety-aligned LLMs: Exclusive Safety Unit (ESU), Exclusive Utility Unit (EUU), Complex Unit (CU), and Redundant Unit (RU). Our findings show that freezing certain safety-critical components 7.5\% during fine-tuning allows the model to retain its safety attributes while adapting to new tasks. Additionally, we show that leveraging redundant units 20\% in the pre-trained model as an ``alignment budget'' can effectively minimize the alignment tax while achieving the alignment goal. All considered, this paper concludes that the atomic functional unit for safety in LLMs is at the neuron level and underscores that safety alignment should not be complicated. We believe this work contributes to the foundation of efficient and scalable safety alignment for future LLMs.</li>
</ul>

<h3>Title: What makes your model a low-empathy or warmth person: Exploring the Origins of Personality in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Shu Yang, Shenzhe Zhu, Ruoxuan Bao, Liang Liu, Yu Cheng, Lijie Hu, Mengdi Li, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10863">https://arxiv.org/abs/2410.10863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10863">https://arxiv.org/pdf/2410.10863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10863]] What makes your model a low-empathy or warmth person: Exploring the Origins of Personality in LLMs(https://arxiv.org/abs/2410.10863)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in generating human-like text and exhibiting personality traits similar to those in humans. However, the mechanisms by which LLMs encode and express traits such as agreeableness and impulsiveness remain poorly understood. Drawing on the theory of social determinism, we investigate how long-term background factors, such as family environment and cultural norms, interact with short-term pressures like external instructions, shaping and influencing LLMs' personality traits. By steering the output of LLMs through the utilization of interpretable features within the model, we explore how these background and pressure factors lead to changes in the model's traits without the need for further fine-tuning. Additionally, we suggest the potential impact of these factors on model safety from the perspective of personality.</li>
</ul>

<h3>Title: Fill In The Gaps: Model Calibration and Generalization with Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Yang Ba, Michelle V. Mancenido, Rong Pan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10864">https://arxiv.org/abs/2410.10864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10864">https://arxiv.org/pdf/2410.10864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10864]] Fill In The Gaps: Model Calibration and Generalization with Synthetic Data(https://arxiv.org/abs/2410.10864)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As machine learning models continue to swiftly advance, calibrating their performance has become a major concern prior to practical and widespread implementation. Most existing calibration methods often negatively impact model accuracy due to the lack of diversity of validation data, resulting in reduced generalizability. To address this, we propose a calibration method that incorporates synthetic data without compromising accuracy. We derive the expected calibration error (ECE) bound using the Probably Approximately Correct (PAC) learning framework. Large language models (LLMs), known for their ability to mimic real data and generate text with mixed class labels, are utilized as a synthetic data generation strategy to lower the ECE bound and improve model accuracy on real test data. Additionally, we propose data generation mechanisms for efficient calibration. Testing our method on four different natural language processing tasks, we observed an average up to 34\% increase in accuracy and 33\% decrease in ECE.</li>
</ul>

<h3>Title: CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept</h3>
<ul>
<li><strong>Authors: </strong>YuXuan Wu, Bonaventure F. P. Dossou, Dianbo Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10866">https://arxiv.org/abs/2410.10866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10866">https://arxiv.org/pdf/2410.10866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10866]] CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept(https://arxiv.org/abs/2410.10866)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) offer extensive knowledge across various domains, but they may inadvertently memorize sensitive, unauthorized, or malicious data, such as personal information in the medical and financial sectors. Machine unlearning methods aim to remove specific information from models after training to address this. However, current approaches require additional model training or struggle to effectively erase particular data points and their associated context due to LLMs' complex, dense, and continuous nature. In this study, we propose a novel amortized unlearning approach using codebook features and Sparse Autoencoders (SAEs). By leveraging a bottleneck to decompose the activation space and regulate information flow, our method efficiently unlearns targeted information while preserving the model's performance on unrelated data. To the best of our knowledge, this is the first work that successfully enables unlearning specific topics with contextual relevance in an LLM, marking a significant step towards real-world applications of machine unlearning.</li>
</ul>

<h3>Title: Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics</h3>
<ul>
<li><strong>Authors: </strong>Théo Gigant (L2S), Camille Guinaudeau (STL, LISN), Marc Decombas, Frédéric Dufaux (L2S)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10867">https://arxiv.org/abs/2410.10867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10867">https://arxiv.org/pdf/2410.10867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10867]] Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics(https://arxiv.org/abs/2410.10867)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automatic metrics are used as proxies to evaluate abstractive summarization systems when human annotations are too expensive. To be useful, these metrics should be fine-grained, show a high correlation with human annotations, and ideally be independent of reference quality; however, most standard evaluation metrics for summarization are reference-based, and existing reference-free metrics correlate poorly with relevance, especially on summaries of longer documents. In this paper, we introduce a reference-free metric that correlates well with human evaluated relevance, while being very cheap to compute. We show that this metric can also be used alongside reference-based metrics to improve their robustness in low quality reference settings.</li>
</ul>

<h3>Title: LLaCA: Multimodal Large Language Continual Assistant</h3>
<ul>
<li><strong>Authors: </strong>Jingyang Qiao, Zhizhong Zhang, Xin Tan, Yanyun Qu, Shouhong Ding, Yuan Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10868">https://arxiv.org/abs/2410.10868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10868">https://arxiv.org/pdf/2410.10868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10868]] LLaCA: Multimodal Large Language Continual Assistant(https://arxiv.org/abs/2410.10868)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning guides the Multimodal Large Language Models (MLLMs) in aligning different modalities by designing text instructions, which seems to be an essential technique to enhance the capabilities and controllability of foundation models. In this framework, Multimodal Continual Instruction Tuning (MCIT) is adopted to continually instruct MLLMs to follow human intent in sequential datasets. We observe existing gradient update would heavily destroy the tuning performance on previous datasets and the zero-shot ability during continual instruction tuning. Exponential Moving Average (EMA) update policy owns the ability to trace previous parameters, which can aid in decreasing forgetting. However, its stable balance weight cannot deal with the ever-changing datasets, leading to the out-of-balance between plasticity and stability of MLLMs. In this paper, we propose a method called Multimodal Large Language Continual Assistant (LLaCA) to address the challenge. Starting from the trade-off prerequisite and EMA update, we propose the plasticity and stability ideal condition. Based on Taylor expansion in the loss function, we find the optimal balance weight is basically according to the gradient information and previous parameters. We automatically determine the balance weight and significantly improve the performance. Through comprehensive experiments on LLaVA-1.5 in a continual visual-question-answering benchmark, compared with baseline, our approach not only highly improves anti-forgetting ability (with reducing forgetting from 22.67 to 2.68), but also significantly promotes continual tuning performance (with increasing average accuracy from 41.31 to 61.89). Our code will be published soon.</li>
</ul>

<h3>Title: Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging</h3>
<ul>
<li><strong>Authors: </strong>Ryota Tozuka, Hisashi Johno, Akitomo Amakawa, Junichi Sato, Mizuki Muto, Shoichiro Seki, Atsushi Komaba, Hiroshi Onishi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10869">https://arxiv.org/abs/2410.10869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10869">https://arxiv.org/pdf/2410.10869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10869]] Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging(https://arxiv.org/abs/2410.10869)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Purpose: In radiology, large language models (LLMs), including ChatGPT, have recently gained attention, and their utility is being rapidly evaluated. However, concerns have emerged regarding their reliability in clinical applications due to limitations such as hallucinations and insufficient referencing. To address these issues, we focus on the latest technology, retrieval-augmented generation (RAG), which enables LLMs to reference reliable external knowledge (REK). Specifically, this study examines the utility and reliability of a recently released RAG-equipped LLM (RAG-LLM), NotebookLM, for staging lung cancer. Materials and methods: We summarized the current lung cancer staging guideline in Japan and provided this as REK to NotebookLM. We then tasked NotebookLM with staging 100 fictional lung cancer cases based on CT findings and evaluated its accuracy. For comparison, we performed the same task using a gold-standard LLM, GPT-4 Omni (GPT-4o), both with and without the REK. Results: NotebookLM achieved 86% diagnostic accuracy in the lung cancer staging experiment, outperforming GPT-4o, which recorded 39% accuracy with the REK and 25% without it. Moreover, NotebookLM demonstrated 95% accuracy in searching reference locations within the REK. Conclusion: NotebookLM successfully performed lung cancer staging by utilizing the REK, demonstrating superior performance compared to GPT-4o. Additionally, it provided highly accurate reference locations within the REK, allowing radiologists to efficiently evaluate the reliability of NotebookLM's responses and detect possible hallucinations. Overall, this study highlights the potential of NotebookLM, a RAG-LLM, in image diagnosis.</li>
</ul>

<h3>Title: PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches</h3>
<ul>
<li><strong>Authors: </strong>Rana Muhammad Shahroz Khan, Pingzhi Li, Sukwon Yun, Zhenyu Wang, Shahriar Nirjon, Chau-Wai Wong, Tianlong Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10870">https://arxiv.org/abs/2410.10870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10870">https://arxiv.org/pdf/2410.10870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10870]] PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches(https://arxiv.org/abs/2410.10870)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) increasingly shape the AI landscape, fine-tuning pretrained models has become more popular than in the pre-LLM era for achieving optimal performance in domain-specific tasks. However, pretrained LLMs such as ChatGPT are periodically evolved, i.e., model parameters are frequently updated), making it challenging for downstream users with limited resources to keep up with fine-tuning the newest LLMs for their domain application. Even though fine-tuning costs have nowadays been reduced thanks to the innovations of parameter-efficient fine-tuning such as LoRA, not all downstream users have adequate computing for frequent personalization. Moreover, access to fine-tuning datasets, particularly in sensitive domains such as healthcare, could be time-restrictive, making it crucial to retain the knowledge encoded in earlier fine-tuned rounds for future adaptation. In this paper, we present PortLLM, a training-free framework that (i) creates an initial lightweight model update patch to capture domain-specific knowledge, and (ii) allows a subsequent seamless plugging for the continual personalization of evolved LLM at minimal cost. Our extensive experiments cover seven representative datasets, from easier question-answering tasks {BoolQ, SST2} to harder reasoning tasks {WinoGrande, GSM8K}, and models including {Mistral-7B, Llama2, Llama3.1, and Gemma2}, validating the portability of our designed model patches and showcasing the effectiveness of our proposed framework. For instance, PortLLM achieves comparable performance to LoRA fine-tuning with reductions of up to 12.2x in GPU memory usage. Finally, we provide theoretical justifications to understand the portability of our model update patches, which offers new insights into the theoretical dimension of LLMs' personalization.</li>
</ul>

<h3>Title: Applying Refusal-Vector Ablation to Llama 3.1 70B Agents</h3>
<ul>
<li><strong>Authors: </strong>Simon Lermen, Mateusz Dziemian, Govind Pimpale</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10871">https://arxiv.org/abs/2410.10871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10871">https://arxiv.org/pdf/2410.10871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10871]] Applying Refusal-Vector Ablation to Llama 3.1 70B Agents(https://arxiv.org/abs/2410.10871)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Recently, language models like Llama 3.1 Instruct have become increasingly capable of agentic behavior, enabling them to perform tasks requiring short-term planning and tool use. In this study, we apply refusal-vector ablation to Llama 3.1 70B and implement a simple agent scaffolding to create an unrestricted agent. Our findings imply that these refusal-vector ablated models can successfully complete harmful tasks, such as bribing officials or crafting phishing attacks, revealing significant vulnerabilities in current safety mechanisms. To further explore this, we introduce a small Safe Agent Benchmark, designed to test both harmful and benign tasks in agentic scenarios. Our results imply that safety fine-tuning in chat models does not generalize well to agentic behavior, as we find that Llama 3.1 Instruct models are willing to perform most harmful tasks without modifications. At the same time, these models will refuse to give advice on how to perform the same tasks when asked for a chat completion. This highlights the growing risk of misuse as models become more capable, underscoring the need for improved safety frameworks for language model agents.</li>
</ul>

<h3>Title: ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Zhenchao Jin, Mengchen Liu, Dongdong Chen, Lingting Zhu, Yunsheng Li, Lequan Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10872">https://arxiv.org/abs/2410.10872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10872">https://arxiv.org/pdf/2410.10872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10872]] ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities(https://arxiv.org/abs/2410.10872)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Through the integration of external tools, large language models (LLMs) such as GPT-4o and Llama 3.1 significantly expand their functional capabilities, evolving from elementary conversational agents to general-purpose assistants. We argue that the primary drivers of these advancements are the quality and diversity of the training data. However, the existing LLMs with external tool integration provide only limited transparency regarding their datasets and data collection methods, which has led to the initiation of this research. Specifically, in this paper, our objective is to elucidate the detailed process involved in constructing datasets that empower LLMs to effectively learn how to utilize external tools and make this information available to the public through the introduction of ToolBridge. ToolBridge proposes to employ a collection of general open-access datasets as its raw dataset pool and applies a series of strategies to identify appropriate data entries from the pool for external tool API insertions. By supervised fine-tuning on these curated data entries, LLMs can invoke external tools in appropriate contexts to boost their predictive accuracy, particularly for basic functions including data processing, numerical computation, and factual retrieval. Our experiments rigorously isolates model architectures and training configurations, focusing exclusively on the role of data. The experimental results indicate that LLMs trained on ToolBridge demonstrate consistent performance improvements on both standard benchmarks and custom evaluation datasets. All the associated code and data will be open-source at this https URL, promoting transparency and facilitating the broader community to explore approaches for equipping LLMs with external tools capabilities.</li>
</ul>

<h3>Title: AuditWen:An Open-Source Large Language Model for Audit</h3>
<ul>
<li><strong>Authors: </strong>Jiajia Huang, Haoran Zhu, Chao Xu, Tianming Zhan, Qianqian Xie, Jimin Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10873">https://arxiv.org/abs/2410.10873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10873">https://arxiv.org/pdf/2410.10873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10873]] AuditWen:An Open-Source Large Language Model for Audit(https://arxiv.org/abs/2410.10873)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Intelligent auditing represents a crucial advancement in modern audit practices, enhancing both the quality and efficiency of audits within the realm of artificial intelligence. With the rise of large language model (LLM), there is enormous potential for intelligent models to contribute to audit domain. However, general LLMs applied in audit domain face the challenges of lacking specialized knowledge and the presence of data biases. To overcome these challenges, this study introduces AuditWen, an open-source audit LLM by fine-tuning Qwen with constructing instruction data from audit domain. We first outline the application scenarios for LLMs in the audit and extract requirements that shape the development of LLMs tailored for audit purposes. We then propose an audit LLM, called AuditWen, by fine-tuning Qwen with constructing 28k instruction dataset from 15 audit tasks and 3 layers. In evaluation stage, we proposed a benchmark with 3k instructions that covers a set of critical audit tasks derived from the application scenarios. With the benchmark, we compare AuditWen with other existing LLMs from information extraction, question answering and document generation. The experimental results demonstrate superior performance of AuditWen both in question understanding and answer generation, making it an immediately valuable tool for audit.</li>
</ul>

<h3>Title: Optimizing Transformer based on high-performance optimizer for predicting employment sentiment in American social media content</h3>
<ul>
<li><strong>Authors: </strong>Feiyang Wang, Qiaozhi Bao, Zixuan Wang, Yanlin Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10874">https://arxiv.org/abs/2410.10874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10874">https://arxiv.org/pdf/2410.10874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10874]] Optimizing Transformer based on high-performance optimizer for predicting employment sentiment in American social media content(https://arxiv.org/abs/2410.10874)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This article improves the Transformer model based on swarm intelligence optimization algorithm, aiming to predict the emotions of employment related text content on American social media. Through text preprocessing, feature extraction, and vectorization, the text data was successfully converted into numerical data and imported into the model for training. The experimental results show that during the training process, the accuracy of the model gradually increased from 49.27% to 82.83%, while the loss value decreased from 0.67 to 0.35, indicating a significant improvement in the performance of the model on the training set. According to the confusion matrix analysis of the training set, the accuracy of the training set is 86.15%. The confusion matrix of the test set also showed good performance, with an accuracy of 82.91%. The accuracy difference between the training set and the test set is only 3.24%, indicating that the model has strong generalization ability. In addition, the evaluation of polygon results shows that the model performs well in classification accuracy, sensitivity, specificity, and area under the curve (AUC), with a Kappa coefficient of 0.66 and an F-measure of 0.80, further verifying the effectiveness of the model in social media sentiment analysis. The improved model proposed in this article not only improves the accuracy of sentiment recognition in employment related texts on social media, but also has important practical significance. This social media based data analysis method can not only capture social dynamics in a timely manner, but also promote decision-makers to pay attention to public concerns and provide data support for improving employment conditions.</li>
</ul>

<h3>Title: FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Text</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Xu, Kun Zhang, Victor S. Sheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10876">https://arxiv.org/abs/2410.10876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10876">https://arxiv.org/pdf/2410.10876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10876]] FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Text(https://arxiv.org/abs/2410.10876)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>The increasing use of Large Language Models (LLMs) for generating highly coherent and contextually relevant text introduces new risks, including misuse for unethical purposes such as disinformation or academic dishonesty. To address these challenges, we propose FreqMark, a novel watermarking technique that embeds detectable frequency-based watermarks in LLM-generated text during the token sampling process. The method leverages periodic signals to guide token selection, creating a watermark that can be detected with Short-Time Fourier Transform (STFT) analysis. This approach enables accurate identification of LLM-generated content, even in mixed-text scenarios with both human-authored and LLM-generated segments. Our experiments demonstrate the robustness and precision of FreqMark, showing strong detection capabilities against various attack scenarios such as paraphrasing and token substitution. Results show that FreqMark achieves an AUC improvement of up to 0.98, significantly outperforming existing detection methods.</li>
</ul>

<h3>Title: Improving Data Efficiency via Curating LLM-Driven Rating Systems</h3>
<ul>
<li><strong>Authors: </strong>Jinlong Pang, Jiaheng Wei, Ankit Parag Shah, Zhaowei Zhu, Yaxuan Wang, Chen Qian, Yang Liu, Yujia Bao, Wei Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10877">https://arxiv.org/abs/2410.10877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10877">https://arxiv.org/pdf/2410.10877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10877]] Improving Data Efficiency via Curating LLM-Driven Rating Systems(https://arxiv.org/abs/2410.10877)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is critical for adapting large language models (LLMs) to downstream tasks, and recent studies have demonstrated that small amounts of human-curated data can outperform larger datasets, challenging traditional data scaling laws. While LLM-based data quality rating systems offer a cost-effective alternative to human annotation, they often suffer from inaccuracies and biases, even in powerful models like GPT-4. In this work, we introduce DS2, a Diversity-aware Score curation method for Data Selection. By systematically modeling error patterns through a score transition matrix, DS2 corrects LLM-based scores and promotes diversity in the selected data samples. Our approach shows that a curated subset (just 3.3% of the original dataset) outperforms full-scale datasets (300k samples) across various machine-alignment benchmarks, and matches or surpasses human-aligned datasets such as LIMA with the same sample size (1k samples). These findings challenge conventional data scaling assumptions, highlighting that redundant, low-quality samples can degrade performance and reaffirming that "more can be less."</li>
</ul>

<h3>Title: Herald: A Natural Language Annotated Lean 4 Dataset</h3>
<ul>
<li><strong>Authors: </strong>Guoxiong Gao, Yutong Wang, Jiedong Jiang, Qi Gao, Zihan Qin, Tianyi Xu, Bin Dong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10878">https://arxiv.org/abs/2410.10878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10878">https://arxiv.org/pdf/2410.10878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10878]] Herald: A Natural Language Annotated Lean 4 Dataset(https://arxiv.org/abs/2410.10878)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Verifiable formal languages like Lean have profoundly impacted mathematical reasoning, particularly through the use of large language models (LLMs) for automated reasoning. A significant challenge in training LLMs for these formal languages is the lack of parallel datasets that align natural language with formal language proofs. To address this challenge, this paper introduces a novel framework for translating the Mathlib4 corpus (a unified library of mathematics in formal language Lean 4) into natural language. Building upon this, we employ a dual augmentation strategy that combines tactic-based and informal-based approaches, leveraging the Lean-jixia system, a Lean 4 analyzer. We present the results of this pipeline on Mathlib4 as Herald (Hierarchy and Retrieval-based Translated Lean Dataset). We also propose the Herald Translator, which is fine-tuned on Herald. Herald translator achieves a 93.2% accuracy (Pass@128) on formalizing statements in the miniF2F-test and a 22.5% accuracy on our internal graduate-level textbook dataset, outperforming InternLM2-Math-Plus-7B (74.0% and 7.5%) and TheoremLlama (50.1% and 4.0%). Furthermore, we propose a section-level translation framework for real-world applications. As a direct application of Herald translator, we have successfully translated a template section in the Stack project, marking a notable progress in the automatic formalization of graduate-level mathematical literature. Our model, along with the datasets, will be open-sourced to the public soon.</li>
</ul>

<h3>Title: Fine-tuning can Help Detect Pretraining Data from Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hengxiang Zhang, Songxin Zhang, Bingyi Jing, Hongxin Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10880">https://arxiv.org/abs/2410.10880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10880">https://arxiv.org/pdf/2410.10880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10880]] Fine-tuning can Help Detect Pretraining Data from Large Language Models(https://arxiv.org/abs/2410.10880)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>In the era of large language models (LLMs), detecting pretraining data has been increasingly important due to concerns about fair evaluation and ethical risks. Current methods differentiate members and non-members by designing scoring functions, like Perplexity and Min-k%. However, the diversity and complexity of training data magnifies the difficulty of distinguishing, leading to suboptimal performance in detecting pretraining data. In this paper, we first explore the benefits of unseen data, which can be easily collected after the release of the LLM. We find that the perplexities of LLMs perform differently for members and non-members, after fine-tuning with a small amount of previously unseen data. In light of this, we introduce a novel and effective method termed Fine-tuned Score Deviation (FSD), which improves the performance of current scoring functions for pretraining data detection. In particular, we propose to measure the deviation distance of current scores after fine-tuning on a small amount of unseen data within the same domain. In effect, using a few unseen data can largely decrease the scores of all non-members, leading to a larger deviation distance than members. Extensive experiments demonstrate the effectiveness of our method, significantly improving the AUC score on common benchmark datasets across various models.</li>
</ul>

<h3>Title: AT-MoE: Adaptive Task-planning Mixture of Experts via LoRA Approach</h3>
<ul>
<li><strong>Authors: </strong>Xurui Li, Juanjuan Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10896">https://arxiv.org/abs/2410.10896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10896">https://arxiv.org/pdf/2410.10896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10896]] AT-MoE: Adaptive Task-planning Mixture of Experts via LoRA Approach(https://arxiv.org/abs/2410.10896)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) has ushered in a new era of artificial intelligence, with the potential to transform various sectors through automation and insightful analysis. The Mixture of Experts (MoE) architecture has been proposed as a solution to enhance model performance in complex tasks. Yet, existing MoE models struggle with task-specific learning and interpretability, especially in fields like medicine where precision is critical. This paper introduces the Adaptive Task-planing Mixture of Experts(AT-MoE), an innovative architecture designed to address these limitations. We first train task-specific experts via LoRA approach to enhance problem-solving capabilities and interpretability in specialized areas. Subsequently, we introduce a layer-wise adaptive grouped routing module that optimizes module fusion based on complex task instructions, ensuring optimal task resolution. The grouped routing module first perform overall weight allocation from the dimension of the expert group, and then conduct local weight normalization adjustments within the group. This design maintains multi-dimensional balance, controllability, and interpretability, while facilitating task-specific fusion in response to complex instructions.</li>
</ul>

<h3>Title: 3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Hongxin Ding, Yue Fang, Runchuan Zhu, Xinke Jiang, Jinyang Zhang, Yongxin Xu, Xu Chu, Junfeng Zhao, Yasha Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10901">https://arxiv.org/abs/2410.10901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10901">https://arxiv.org/pdf/2410.10901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10901]] 3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation(https://arxiv.org/abs/2410.10901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models(LLMs) excel in general tasks but struggle in specialized domains like healthcare due to limited domain-specific this http URL Fine-Tuning(SFT) data construction for domain adaptation often relies on heuristic methods, such as GPT-4 annotation or manual data selection, with a data-centric focus on presumed diverse, high-quality datasets. However, these methods overlook the model's inherent knowledge distribution, introducing noise, redundancy, and irrelevant data, leading to a mismatch between the selected data and the model's learning task, resulting in suboptimal performance. To address this, we propose a two-stage model-centric data selection framework, Decomposed Difficulty Data Selection (3DS), which aligns data with the model's knowledge distribution for optimized adaptation. In Stage1, we apply Prompt-Driven Data Selection via Explicit Alignment, where the the model filters irrelevant or redundant data based on its internal knowledge. In Stage2, we perform Decomposed Difficulty Data Selection, where data selection is guided by our defined difficulty decomposition, using three metrics: Instruction Understanding, Response Confidence, and Response Correctness. Additionally, an attention-based importance weighting mechanism captures token importance for more accurate difficulty calibration. This two-stage approach ensures the selected data is not only aligned with the model's knowledge and preferences but also appropriately challenging for the model to learn, leading to more effective and targeted domain adaptation. In the case study of the medical domain, our extensive experiments on real-world healthcare datasets demonstrate the superiority of 3DS over exisiting methods in accuracy by over 5.29%. Our dataset and code will be open-sourced at this https URL.</li>
</ul>

<h3>Title: An Explainable AI Model for Predicting the Recurrence of Differentiated Thyroid Cancer</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Al-Sayed Ahmad, Jude Haddad</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10907">https://arxiv.org/abs/2410.10907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10907">https://arxiv.org/pdf/2410.10907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10907]] An Explainable AI Model for Predicting the Recurrence of Differentiated Thyroid Cancer(https://arxiv.org/abs/2410.10907)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Thyroid carcinoma, a significant yet often controllable cancer, has seen a rise in cases, largely due to advancements in diagnostic methods. Differentiated thyroid cancer (DTC), which includes papillary and follicular varieties, is typically associated with a positive prognosis in academic circles. Nevertheless, there are still some individuals who may experience a recurrence. This study employs machine learning, particularly deep learning models, to predict the recurrence of DTC, with the goal of improving patient care through personalized treatment approaches. By analysing a dataset containing clinicopathological features of patients, the model achieved remarkable accuracy rates of 98% during training and 96% during testing. To improve the model's interpretability, we used techniques like LIME and Morris Sensitivity Analysis. These methods gave us valuable insights into how the model makes decisions. The results suggest that combining deep learning models with interpretability techniques can be extremely useful in quickly identifying the recurrence of thyroid cancer in patients. This can help in making informed therapeutic choices and customizing treatment approaches for individual patients.</li>
</ul>

<h3>Title: AlphaPruning: Using Heavy-Tailed Self Regularization Theory for Improved Layer-wise Pruning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haiquan Lu, Yefan Zhou, Shiwei Liu, Zhangyang Wang, Michael W. Mahoney, Yaoqing Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10912">https://arxiv.org/abs/2410.10912</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10912">https://arxiv.org/pdf/2410.10912</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10912]] AlphaPruning: Using Heavy-Tailed Self Regularization Theory for Improved Layer-wise Pruning of Large Language Models(https://arxiv.org/abs/2410.10912)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent work on pruning large language models (LLMs) has shown that one can eliminate a large number of parameters without compromising performance, making pruning a promising strategy to reduce LLM model size. Existing LLM pruning strategies typically assign uniform pruning ratios across layers, limiting overall pruning ability; and recent work on layerwise pruning of LLMs is often based on heuristics that can easily lead to suboptimal performance. In this paper, we leverage Heavy-Tailed Self-Regularization (HT-SR) Theory, in particular the shape of empirical spectral densities (ESDs) of weight matrices, to design improved layerwise pruning ratios for LLMs. Our analysis reveals a wide variability in how well-trained, and thus relatedly how prunable, different layers of an LLM are. Based on this, we propose AlphaPruning, which uses shape metrics to allocate layerwise sparsity ratios in a more theoretically principled manner. AlphaPruning can be used in conjunction with multiple existing LLM pruning methods. Our empirical results show that AlphaPruning prunes LLaMA-7B to 80% sparsity while maintaining reasonable perplexity, marking a first in the literature on LLMs. We have open-sourced our code at this https URL.</li>
</ul>

<h3>Title: Towards Better Multi-head Attention via Channel-wise Sample Permutation</h3>
<ul>
<li><strong>Authors: </strong>Shen Yuan, Hongteng Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10914">https://arxiv.org/abs/2410.10914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10914">https://arxiv.org/pdf/2410.10914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10914]] Towards Better Multi-head Attention via Channel-wise Sample Permutation(https://arxiv.org/abs/2410.10914)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer plays a central role in many fundamental deep learning models, e.g., the ViT in computer vision and the BERT and GPT in natural language processing, whose effectiveness is mainly attributed to its multi-head attention (MHA) mechanism. In this study, we propose a simple and novel channel-wise sample permutation (CSP) operator, achieving a new structured MHA with fewer parameters and lower complexity. Given an input matrix, CSP circularly shifts the samples of different channels with various steps and then sorts grouped samples of each channel. This operator is equivalent to implicitly implementing cross-channel attention maps as permutation matrices, which achieves linear complexity and suppresses the risk of rank collapse when representing data. We replace the MHA of some representative models with CSP and test the CSP-based models in several discriminative tasks, including image classification and long sequence analysis. Experiments show that the CSP-based models achieve comparable or better performance with fewer parameters and lower computational costs than the classic Transformer and its state-of-the-art variants. The code is available at this https URL.</li>
</ul>

<h3>Title: Graph Masked Autoencoder for Spatio-Temporal Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Qianru Zhang, Haixin Wang, Siu-Ming Yiu, Hongzhi Yin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10915">https://arxiv.org/abs/2410.10915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10915">https://arxiv.org/pdf/2410.10915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10915]] Graph Masked Autoencoder for Spatio-Temporal Graph Learning(https://arxiv.org/abs/2410.10915)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Effective spatio-temporal prediction frameworks play a crucial role in urban sensing applications, including traffic analysis, human mobility behavior modeling, and citywide crime prediction. However, the presence of data noise and label sparsity in spatio-temporal data presents significant challenges for existing neural network models in learning effective and robust region representations. To address these challenges, we propose a novel spatio-temporal graph masked autoencoder paradigm that explores generative self-supervised learning for effective spatio-temporal data augmentation. Our proposed framework introduces a spatial-temporal heterogeneous graph neural encoder that captures region-wise dependencies from heterogeneous data sources, enabling the modeling of diverse spatial dependencies. In our spatio-temporal self-supervised learning paradigm, we incorporate a masked autoencoding mechanism on node representations and structures. This mechanism automatically distills heterogeneous spatio-temporal dependencies across regions over time, enhancing the learning process of dynamic region-wise spatial correlations. To validate the effectiveness of our STGMAE framework, we conduct extensive experiments on various spatio-temporal mining tasks. We compare our approach against state-of-the-art baselines. The results of these evaluations demonstrate the superiority of our proposed framework in terms of performance and its ability to address the challenges of spatial and temporal data noise and sparsity in practical urban sensing scenarios.</li>
</ul>

<h3>Title: A few-shot Label Unlearning in Vertical Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Hanlin Gu, Hong Xi Tae, Chee Seng Chan, Lixin Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10922">https://arxiv.org/abs/2410.10922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10922">https://arxiv.org/pdf/2410.10922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10922]] A few-shot Label Unlearning in Vertical Federated Learning(https://arxiv.org/abs/2410.10922)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>This paper addresses the critical challenge of unlearning in Vertical Federated Learning (VFL), an area that has received limited attention compared to horizontal federated learning. We introduce the first approach specifically designed to tackle label unlearning in VFL, focusing on scenarios where the active party aims to mitigate the risk of label leakage. Our method leverages a limited amount of labeled data, utilizing manifold mixup to augment the forward embedding of insufficient data, followed by gradient ascent on the augmented embeddings to erase label information from the models. This combination of augmentation and gradient ascent enables high unlearning effectiveness while maintaining efficiency, completing the unlearning procedure within seconds. Extensive experiments conducted on diverse datasets, including MNIST, CIFAR10, CIFAR100, and ModelNet, validate the efficacy and scalability of our approach. This work represents a significant advancement in federated learning, addressing the unique challenges of unlearning in VFL while preserving both privacy and computational efficiency.</li>
</ul>

<h3>Title: Federated Data-Efficient Instruction Tuning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhen Qin, Zhaomin Wu, Bingsheng He, Shuiguang Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10926">https://arxiv.org/abs/2410.10926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10926">https://arxiv.org/pdf/2410.10926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10926]] Federated Data-Efficient Instruction Tuning for Large Language Models(https://arxiv.org/abs/2410.10926)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning helps improve pretrained large language models (LLMs) in terms of the responsiveness to human instructions, which is benefited from diversified instruction data. Federated learning extends the sources of instruction data by exploiting the diversified client-side data, making it increasingly popular for tuning LLMs. Existing approaches of federated LLM tuning typically traverse all local data during local training, bringing excessive computation overhead and posing a risk of overfitting local data. Thus, a federated data-efficient instruction tuning approach, which consumes relatively little data from the entire dataset, is needed. In response, this work introduces an approach of federated data-efficient instruction tuning for LLMs, FedHDS, which utilizes a representative subset of edge-side data, coreset, to tune the LLM. It reduces the redundancy of data samples at both intra-client and inter-client levels through a hierarchical data selection framework performed by jointly selecting a small number of representative data samples for local training without sharing the raw data. Extensive experiments conducted across six scenarios with various LLMs, datasets and data partitions demonstrate that FedHDS significantly reduces the amount of data required for fine-tuning while improving the responsiveness of the instruction-tuned LLMs to unseen tasks.</li>
</ul>

<h3>Title: Cultural Heritage 3D Reconstruction with Diffusion Networks</h3>
<ul>
<li><strong>Authors: </strong>Pablo Jaramillo, Ivan Sipiran</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10927">https://arxiv.org/abs/2410.10927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10927">https://arxiv.org/pdf/2410.10927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10927]] Cultural Heritage 3D Reconstruction with Diffusion Networks(https://arxiv.org/abs/2410.10927)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This article explores the use of recent generative AI algorithms for repairing cultural heritage objects, leveraging a conditional diffusion model designed to reconstruct 3D point clouds effectively. Our study evaluates the model's performance across general and cultural heritage-specific settings. Results indicate that, with considerations for object variability, the diffusion model can accurately reproduce cultural heritage geometries. Despite encountering challenges like data diversity and outlier sensitivity, the model demonstrates significant potential in artifact restoration research. This work lays groundwork for advancing restoration methodologies for ancient artifacts using AI technologies.</li>
</ul>

<h3>Title: Data-Aware Training Quality Monitoring and Certification for Reliable Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Farhang Yeganegi, Arian Eamaz, Mojtaba Soltanalian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10984">https://arxiv.org/abs/2410.10984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10984">https://arxiv.org/pdf/2410.10984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10984]] Data-Aware Training Quality Monitoring and Certification for Reliable Deep Learning(https://arxiv.org/abs/2410.10984)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning models excel at capturing complex representations through sequential layers of linear and non-linear transformations, yet their inherent black-box nature and multi-modal training landscape raise critical concerns about reliability, robustness, and safety, particularly in high-stakes applications. To address these challenges, we introduce YES training bounds, a novel framework for real-time, data-aware certification and monitoring of neural network training. The YES bounds evaluate the efficiency of data utilization and optimization dynamics, providing an effective tool for assessing progress and detecting suboptimal behavior during training. Our experiments show that the YES bounds offer insights beyond conventional local optimization perspectives, such as identifying when training losses plateau in suboptimal regions. Validated on both synthetic and real data, including image denoising tasks, the bounds prove effective in certifying training quality and guiding adjustments to enhance model performance. By integrating these bounds into a color-coded cloud-based monitoring system, we offer a powerful tool for real-time evaluation, setting a new standard for training quality assurance in deep learning.</li>
</ul>

<h3>Title: What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis</h3>
<ul>
<li><strong>Authors: </strong>Weronika Ormaniec, Felix Dangel, Sidak Pal Singh</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10986">https://arxiv.org/abs/2410.10986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10986">https://arxiv.org/pdf/2410.10986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10986]] What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis(https://arxiv.org/abs/2410.10986)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Transformer architecture has inarguably revolutionized deep learning, overtaking classical architectures like multi-layer perceptrons (MLPs) and convolutional neural networks (CNNs). At its core, the attention block differs in form and functionality from most other architectural components in deep learning -- to the extent that Transformers are often accompanied by adaptive optimizers, layer normalization, learning rate warmup, and more, in comparison to MLPs/CNNs. The root causes behind these outward manifestations, and the precise mechanisms that govern them, remain poorly understood. In this work, we bridge this gap by providing a fundamental understanding of what distinguishes the Transformer from the other architectures -- grounded in a theoretical comparison of the (loss) Hessian. Concretely, for a single self-attention layer, (a) we first entirely derive the Transformer's Hessian and express it in matrix derivatives; (b) we then characterize it in terms of data, weight, and attention moment dependencies; and (c) while doing so further highlight the important structural differences to the Hessian of classical networks. Our results suggest that various common architectural and optimization choices in Transformers can be traced back to their highly non-linear dependencies on the data and weight matrices, which vary heterogeneously across parameters. Ultimately, our findings provide a deeper understanding of the Transformer's unique optimization landscape and the challenges it poses.</li>
</ul>

<h3>Title: Liger Kernel: Efficient Triton Kernels for LLM Training</h3>
<ul>
<li><strong>Authors: </strong>Byron (Pin-Lun)Hsu, Yun Dai, Vignesh Kothapalli, Qingquan Song, Shao Tang, Siyu Zhu, Steven Shimizu, Shivam Sahni, Haowen Ning, Yanning Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10989">https://arxiv.org/abs/2410.10989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10989">https://arxiv.org/pdf/2410.10989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10989]] Liger Kernel: Efficient Triton Kernels for LLM Training(https://arxiv.org/abs/2410.10989)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) efficiently at scale presents a formidable challenge, driven by their ever-increasing computational demands and the need for enhanced performance. In this work, we introduce Liger-Kernel, an open-sourced set of Triton kernels developed specifically for LLM training. With kernel optimization techniques like kernel operation fusing and input chunking, our kernels achieve on average a 20% increase in training throughput and a 60% reduction in GPU memory usage for popular LLMs compared to HuggingFace implementations. In addition, Liger-Kernel is designed with modularity, accessibility, and adaptability in mind, catering to both casual and expert users. Comprehensive benchmarks and integration tests are built in to ensure compatibility, performance, correctness, and convergence across diverse computing environments and model architectures. The source code is available under a permissive license at: this http URL.</li>
</ul>

<h3>Title: Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs</h3>
<ul>
<li><strong>Authors: </strong>Haozhen Zhang, Tao Feng, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11001">https://arxiv.org/abs/2410.11001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11001">https://arxiv.org/pdf/2410.11001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11001]] Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs(https://arxiv.org/abs/2410.11001)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) has revitalized Large Language Models (LLMs) by injecting non-parametric factual knowledge. Compared with long-context LLMs, RAG is considered an effective summarization tool in a more concise and lightweight manner, which can interact with LLMs multiple times using diverse queries to get comprehensive responses. However, the LLM-generated historical responses, which contain potentially insightful information, are largely neglected and discarded by existing approaches, leading to suboptimal results. In this paper, we propose \textit{graph of records} (\textbf{GoR}), which leverages historical responses generated by LLMs to enhance RAG for long-context global summarization. Inspired by the \textit{retrieve-then-generate} paradigm of RAG, we construct a graph by establishing an edge between the retrieved text chunks and the corresponding LLM-generated response. To further uncover the intricate correlations between them, GoR further features a \textit{graph neural network} and an elaborately designed \textit{BERTScore}-based objective for self-supervised model training, enabling seamless supervision signal backpropagation between reference summaries and node embeddings. We comprehensively compare GoR with 12 baselines across four long-context summarization datasets, and the results indicate that our proposed method reaches the best performance e.g., 15\%, 8\%, and 19\% improvement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP dataset). Extensive experiments further demonstrate the effectiveness of GoR. Code is available at this https URL</li>
</ul>

<h3>Title: One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Jing Yao, Si-Qing Chen, Michael Wooldridge, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11005">https://arxiv.org/abs/2410.11005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11005">https://arxiv.org/pdf/2410.11005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11005]] One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks(https://arxiv.org/abs/2410.11005)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Language is not monolithic. While many benchmarks are used as proxies to systematically estimate Large Language Models' (LLM) performance in real-life tasks, they tend to ignore the nuances of within-language variation and thus fail to model the experience of speakers of minority dialects. Focusing on African American Vernacular English (AAVE), we present the first study on LLMs' fairness and robustness to a dialect in canonical reasoning tasks (algorithm, math, logic, and comprehensive reasoning). We hire AAVE speakers, including experts with computer science backgrounds, to rewrite seven popular benchmarks, such as HumanEval and GSM8K. The result of this effort is ReDial, a dialectal benchmark comprising $1.2K+$ parallel query pairs in Standardized English and AAVE. We use ReDial to evaluate state-of-the-art LLMs, including GPT-4o/4/3.5-turbo, LLaMA-3.1/3, Mistral, and Phi-3. We find that, compared to Standardized English, almost all of these widely used models show significant brittleness and unfairness to queries in AAVE. Furthermore, AAVE queries can degrade performance more substantially than misspelled texts in Standardized English, even when LLMs are more familiar with the AAVE queries. Finally, asking models to rephrase questions in Standardized English does not close the performance gap but generally introduces higher costs. Overall, our findings indicate that LLMs provide unfair service to dialect users in complex reasoning tasks. Code can be found at this https URL.</li>
</ul>

<h3>Title: Effective Self-Mining of In-Context Examples for Unsupervised Machine Translation with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Abdellah El Mekki, Muhammad Abdul-Mageed</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11006">https://arxiv.org/abs/2410.11006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11006">https://arxiv.org/pdf/2410.11006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11006]] Effective Self-Mining of In-Context Examples for Unsupervised Machine Translation with LLMs(https://arxiv.org/abs/2410.11006)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive performance on a wide range of natural language processing (NLP) tasks, primarily through in-context learning (ICL). In ICL, the LLM is provided with examples that represent a given task such that it learns to generate answers for test inputs. However, access to these in-context examples is not guaranteed especially for low-resource or massively multilingual tasks. In this work, we propose an unsupervised approach to mine in-context examples for machine translation (MT), enabling unsupervised MT (UMT) across different languages. Our approach begins with word-level mining to acquire word translations that are then used to perform sentence-level mining. As the quality of mined parallel pairs may not be optimal due to noise or mistakes, we introduce a filtering criterion to select the optimal in-context examples from a pool of unsupervised parallel sentences. We evaluate our approach using two multilingual LLMs on 288 directions from the FLORES-200 dataset and analyze the impact of various linguistic features on performance. Our findings demonstrate the effectiveness of our unsupervised approach in mining in-context examples for MT, leading to better or comparable translation performance as translation with regular in-context samples (extracted from human-annotated data), while also outperforming the other state-of-the-art UMT methods by an average of $7$ BLEU points.</li>
</ul>

<h3>Title: Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Bokai Hu, Sai Ashish Somayajula, Xin Pan, Zihan Huang, Pengtao Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11020">https://arxiv.org/abs/2410.11020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11020">https://arxiv.org/pdf/2410.11020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11020]] Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning(https://arxiv.org/abs/2410.11020)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), built on decoder-only transformers, excel in natural language generation and adapt to diverse tasks using zero-shot and few-shot prompting. However, these prompting methods often struggle on natural language understanding (NLU) tasks, where encoder-only models like BERT-base outperform LLMs on benchmarks like GLUE and SuperGLUE. This paper explores two approaches-supervised fine-tuning (SFT) and proximal policy optimization (PPO)-to enhance LLMs' NLU abilities. To reduce the cost of full-model fine-tuning, we integrate low-rank adaptation (LoRA) layers, limiting updates to these layers during both SFT and PPO. In SFT, task-specific prompts are concatenated with input queries and ground-truth labels, optimizing with next-token prediction. Despite this, LLMs still underperform compared to models like BERT-base on several NLU tasks. To close this gap, we apply PPO, a reinforcement learning technique that treats each token generation as an action and uses a reward function based on alignment with ground-truth answers. PPO then updates the model to maximize these rewards, aligning outputs with correct labels. Our experiments with LLAMA2-7B show that PPO improves performance, with a 6.3-point gain over SFT on GLUE. PPO exceeds zero-shot by 38.7 points and few-shot by 26.1 points on GLUE, while surpassing these by 28.8 and 28.5 points on SuperGLUE. Additionally, PPO outperforms BERT-large by 2.7 points on GLUE and 9.3 points on SuperGLUE. The improvements are consistent across models like Qwen2.5-7B and MPT-7B, highlighting PPO's robustness in enhancing LLMs' NLU capabilities.</li>
</ul>

<h3>Title: Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads</h3>
<ul>
<li><strong>Authors: </strong>Federico Nocentini, Thomas Besnier, Claudio Ferrari, Sylvain Arguillere, Stefano Berretti, Mohamed Daoudi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11041">https://arxiv.org/abs/2410.11041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11041">https://arxiv.org/pdf/2410.11041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11041]] Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads(https://arxiv.org/abs/2410.11041)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating speech-driven 3D talking heads presents numerous challenges; among those is dealing with varying mesh topologies. Existing methods require a registered setting, where all meshes share a common topology: a point-wise correspondence across all meshes the model can animate. While simplifying the problem, it limits applicability as unseen meshes must adhere to the training topology. This work presents a framework capable of animating 3D faces in arbitrary topologies, including real scanned data. Our approach relies on a model leveraging heat diffusion over meshes to overcome the fixed topology constraint. We explore two training settings: a supervised one, in which training sequences share a fixed topology within a sequence but any mesh can be animated at test time, and an unsupervised one, which allows effective training with varying mesh structures. Additionally, we highlight the limitations of current evaluation metrics and propose new metrics for better lip-syncing evaluation between speech and facial movements. Our extensive evaluation shows our approach performs favorably compared to fixed topology techniques, setting a new benchmark by offering a versatile and high-fidelity solution for 3D talking head generation.</li>
</ul>

<h3>Title: Persistent Topological Features in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuri Gardinazzi, Giada Panerai, Karthik Viswanathan, Alessio Ansuini, Alberto Cazzaniga, Matteo Biagetti</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CG, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11042">https://arxiv.org/abs/2410.11042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11042">https://arxiv.org/pdf/2410.11042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11042]] Persistent Topological Features in Large Language Models(https://arxiv.org/abs/2410.11042)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding the decision-making processes of large language models (LLMs) is critical given their widespread applications. Towards this goal, describing the topological and geometrical properties of internal representations has recently provided valuable insights. For a more comprehensive characterization of these inherently complex spaces, we present a novel framework based on zigzag persistence, a method in topological data analysis (TDA) well-suited for describing data undergoing dynamic transformations across layers. Within this framework, we introduce persistence similarity, a new metric that quantifies the persistence and transformation of topological features such as $p$-cycles throughout the model layers. Unlike traditional similarity measures, our approach captures the entire evolutionary trajectory of these features, providing deeper insights into the internal workings of LLMs. As a practical application, we leverage persistence similarity to identify and prune redundant layers, demonstrating comparable performance to state-of-the-art methods across several benchmark datasets. Additionally, our analysis reveals consistent topological behaviors across various models and hyperparameter settings, suggesting a universal structure in LLM internal representations.</li>
</ul>

<h3>Title: Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Nathaniel Demchak, Xin Guan, Zekun Wu, Ziyi Xu, Adriano Koshiyama, Emre Kazim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11059">https://arxiv.org/abs/2410.11059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11059">https://arxiv.org/pdf/2410.11059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11059]] Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks(https://arxiv.org/abs/2410.11059)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Open-generation bias benchmarks evaluate social biases in Large Language Models (LLMs) by analyzing their outputs. However, the classifiers used in analysis often have inherent biases, leading to unfair conclusions. This study examines such biases in open-generation benchmarks like BOLD and SAGED. Using the MGSD dataset, we conduct two experiments. The first uses counterfactuals to measure prediction variations across demographic groups by altering stereotype-related prefixes. The second applies explainability tools (SHAP) to validate that the observed biases stem from these counterfactuals. Results reveal unequal treatment of demographic descriptors, calling for more robust bias metric models.</li>
</ul>

<h3>Title: Time Series Viewmakers for Robust Disruption Prediction</h3>
<ul>
<li><strong>Authors: </strong>Dhruva Chayapathy, Tavis Siebert, Lucas Spangher, Akshata Kishore Moharir, Om Manoj Patil, Cristina Rea</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11065">https://arxiv.org/abs/2410.11065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11065">https://arxiv.org/pdf/2410.11065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11065]] Time Series Viewmakers for Robust Disruption Prediction(https://arxiv.org/abs/2410.11065)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine Learning guided data augmentation may support the development of technologies in the physical sciences, such as nuclear fusion tokamaks. Here we endeavor to study the problem of detecting disruptions i.e. plasma instabilities that can cause significant damages, impairing the reliability and efficiency required for their real world viability. Machine learning (ML) prediction models have shown promise in detecting disruptions for specific tokamaks, but they often struggle in generalizing to the diverse characteristics and dynamics of different machines. This limits the effectiveness of ML models across different tokamak designs and operating conditions, which is a critical barrier to scaling fusion technology. Given the success of data augmentation in improving model robustness and generalizability in other fields, this study explores the use of a novel time series viewmaker network to generate diverse augmentations or "views" of training data. Our results show that incorporating views during training improves AUC and F2 scores on DisruptionBench tasks compared to standard or no augmentations. This approach represents a promising step towards developing more broadly applicable ML models for disruption avoidance, which is essential for advancing fusion technology and, ultimately, addressing climate change through reliable and sustainable energy production.</li>
</ul>

<h3>Title: Character-aware audio-visual subtitling in context</h3>
<ul>
<li><strong>Authors: </strong>Jaesung Huh, Andrew Zisserman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11068">https://arxiv.org/abs/2410.11068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11068">https://arxiv.org/pdf/2410.11068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11068]] Character-aware audio-visual subtitling in context(https://arxiv.org/abs/2410.11068)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents an improved framework for character-aware audio-visual subtitling in TV shows. Our approach integrates speech recognition, speaker diarisation, and character recognition, utilising both audio and visual cues. This holistic solution addresses what is said, when it's said, and who is speaking, providing a more comprehensive and accurate character-aware subtitling for TV shows. Our approach brings improvements on two fronts: first, we show that audio-visual synchronisation can be used to pick out the talking face amongst others present in a video clip, and assign an identity to the corresponding speech segment. This audio-visual approach improves recognition accuracy and yield over current methods. Second, we show that the speaker of short segments can be determined by using the temporal context of the dialogue within a scene. We propose an approach using local voice embeddings of the audio, and large language model reasoning on the text transcription. This overcomes a limitation of existing methods that they are unable to accurately assign speakers to short temporal segments. We validate the method on a dataset with 12 TV shows, demonstrating superior performance in speaker diarisation and character recognition accuracy compared to existing approaches. Project page : this https URL</li>
</ul>

<h3>Title: PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries</h3>
<ul>
<li><strong>Authors: </strong>Mingwen Dong, Nischal Ashok Kumar, Yiqun Hu, Anuj Chauhan, Chung-Wei Hang, Shuaichen Chang, Lin Pan, Wuwei Lan, Henghui Zhu, Jiarong Jiang, Patrick Ng, Zhiguo Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11076">https://arxiv.org/abs/2410.11076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11076">https://arxiv.org/pdf/2410.11076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11076]] PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries(https://arxiv.org/abs/2410.11076)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Previous text-to-SQL datasets and systems have primarily focused on user questions with clear intentions that can be answered. However, real user questions can often be ambiguous with multiple interpretations or unanswerable due to a lack of relevant data. In this work, we construct a practical conversational text-to-SQL dataset called PRACTIQ, consisting of ambiguous and unanswerable questions inspired by real-world user questions. We first identified four categories of ambiguous questions and four categories of unanswerable questions by studying existing text-to-SQL datasets. Then, we generate conversations with four turns: the initial user question, an assistant response seeking clarification, the user's clarification, and the assistant's clarified SQL response with the natural language explanation of the execution results. For some ambiguous queries, we also directly generate helpful SQL responses, that consider multiple aspects of ambiguity, instead of requesting user clarification. To benchmark the performance on ambiguous, unanswerable, and answerable questions, we implemented large language model (LLM)-based baselines using various LLMs. Our approach involves two steps: question category classification and clarification SQL prediction. Our experiments reveal that state-of-the-art systems struggle to handle ambiguous and unanswerable questions effectively. We will release our code for data generation and experiments on GitHub.</li>
</ul>

<h3>Title: Predicting Chess Puzzle Difficulty with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Szymon Miłosz, Paweł Kapusta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11078">https://arxiv.org/abs/2410.11078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11078">https://arxiv.org/pdf/2410.11078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11078]] Predicting Chess Puzzle Difficulty with Transformers(https://arxiv.org/abs/2410.11078)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This study addresses the challenge of quantifying chess puzzle difficulty - a complex task that combines elements of game theory and human cognition and underscores its critical role in effective chess training. We present GlickFormer, a novel transformer-based architecture that predicts chess puzzle difficulty by approximating the Glicko-2 rating system. Unlike conventional chess engines that optimize for game outcomes, GlickFormer models human perception of tactical patterns and problem-solving complexity. The proposed model utilizes a modified ChessFormer backbone for spatial feature extraction and incorporates temporal information via factorized transformer techniques. This approach enables the capture of both spatial chess piece arrangements and move sequences, effectively modeling spatio-temporal relationships relevant to difficulty assessment. Experimental evaluation was conducted on a dataset of over 4 million chess puzzles. Results demonstrate GlickFormer's superior performance compared to the state-of-the-art ChessFormer baseline across multiple metrics. The algorithm's performance has also been recognized through its competitive results in the IEEE BigData 2024 Cup: Predicting Chess Puzzle Difficulty competition. The insights gained from this study have implications for personalized chess training and broader applications in educational technology and cognitive modeling.</li>
</ul>

<h3>Title: Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Ayushman Gupta, Akhil Bhogal, Kripabandhu Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11079">https://arxiv.org/abs/2410.11079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11079">https://arxiv.org/pdf/2410.11079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11079]] Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities(https://arxiv.org/abs/2410.11079)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual Large Language Models (LLMs) have demonstrated exceptional performance in Machine Translation (MT) tasks. However, their MT abilities in the context of code-switching (the practice of mixing two or more languages in an utterance) remain under-explored. In this paper, we introduce Rule-Based Prompting, a novel prompting technique to generate code-mixed sentences. We measure and compare the code-mixed MT abilities of 3 popular multilingual LLMs: GPT-3.5-turbo, GPT-4, and Gemini Pro across five language pairs: English-{Hindi, Bengali, Gujarati, French, Spanish} using $k$-shot prompting ($k\in\{0, 1, 10, 20\}$) and Rule-Based Prompting. Our findings suggest that though $k$-shot prompting often leads to the best results, Rule-Based prompting shows promise in generating unique code-mixed sentences that vary in their style of code-mixing. We also use $k$-shot prompting to gauge the code-mixed to English translation abilities of multilingual LLMs. For this purpose, we create a gold-standard code-mixed dataset spanning five language pairs: English-{Hindi, Bengali, Gujarati, French, Spanish}. As a real-world application of our work, we create a code-mixed chatbot.</li>
</ul>

<h3>Title: Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models</h3>
<ul>
<li><strong>Authors: </strong>Cheng Lu, Yang Song</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11081">https://arxiv.org/abs/2410.11081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11081">https://arxiv.org/pdf/2410.11081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11081]] Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models(https://arxiv.org/abs/2410.11081)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Consistency models (CMs) are a powerful class of diffusion-based generative models optimized for fast sampling. Most existing CMs are trained using discretized timesteps, which introduce additional hyperparameters and are prone to discretization errors. While continuous-time formulations can mitigate these issues, their success has been limited by training instability. To address this, we propose a simplified theoretical framework that unifies previous parameterizations of diffusion models and CMs, identifying the root causes of instability. Based on this analysis, we introduce key improvements in diffusion process parameterization, network architecture, and training objectives. These changes enable us to train continuous-time CMs at an unprecedented scale, reaching 1.5B parameters on ImageNet 512x512. Our proposed training algorithm, using only two sampling steps, achieves FID scores of 2.06 on CIFAR-10, 1.48 on ImageNet 64x64, and 1.88 on ImageNet 512x512, narrowing the gap in FID scores with the best existing diffusion models to within 10%.</li>
</ul>

<h3>Title: Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts</h3>
<ul>
<li><strong>Authors: </strong>Sharon Levy, William D. Adler, Tahilin Sanchez Karver, Mark Dredze, Michelle R. Kaufman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11084">https://arxiv.org/abs/2410.11084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11084">https://arxiv.org/pdf/2410.11084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11084]] Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts(https://arxiv.org/abs/2410.11084)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) acquire beliefs about gender from training data and can therefore generate text with stereotypical gender attitudes. Prior studies have demonstrated model generations favor one gender or exhibit stereotypes about gender, but have not investigated the complex dynamics that can influence model reasoning and decision-making involving gender. We study gender equity within LLMs through a decision-making lens with a new dataset, DeMET Prompts, containing scenarios related to intimate, romantic relationships. We explore nine relationship configurations through name pairs across three name lists (men, women, neutral). We investigate equity in the context of gender roles through numerous lenses: typical and gender-neutral names, with and without model safety enhancements, same and mixed-gender relationships, and egalitarian versus traditional scenarios across various topics. While all models exhibit the same biases (women favored, then those with gender-neutral names, and lastly men), safety guardrails reduce bias. In addition, models tend to circumvent traditional male dominance stereotypes and side with 'traditionally female' individuals more often, suggesting relationships are viewed as a female domain by the models.</li>
</ul>

<h3>Title: Locality Alignment Improves Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ian Covert, Tony Sun, James Zou, Tatsunori Hashimoto</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11087">https://arxiv.org/abs/2410.11087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11087">https://arxiv.org/pdf/2410.11087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11087]] Locality Alignment Improves Vision-Language Models(https://arxiv.org/abs/2410.11087)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Vision language models (VLMs) have seen growing adoption in recent years, but many still struggle with basic spatial reasoning errors. We hypothesize that this is due to VLMs adopting pre-trained vision backbones, specifically vision transformers (ViTs) trained with image-level supervision and minimal inductive biases. Such models may fail to encode the class contents at each position in the image, and our goal is to resolve this by ensuring that the vision backbone effectively captures both local and global image semantics. Our main insight is that we do not require new supervision to learn this capability -- pre-trained models contain significant knowledge of local semantics that we can extract and use for scalable self-supervision. We propose a new efficient post-training stage for ViTs called locality alignment and a novel fine-tuning procedure called MaskEmbed that uses a masked reconstruction loss to learn semantic contributions for each image patch. We first evaluate locality alignment with a vision-only benchmark, finding that it improves a model's performance at a patch-level semantic segmentation task, especially for strong backbones trained with image-caption pairs (e.g., CLIP and SigLIP). We then train a series of VLMs with and without locality alignment, and show that locality-aligned backbones improve performance across a range of benchmarks, particularly ones that involve spatial understanding (e.g., RefCOCO, OCID-Ref, TallyQA, VSR, AI2D). Overall, we demonstrate that we can efficiently learn local semantic extraction via a locality alignment stage, and that this procedure complements existing VLM training recipes that use off-the-shelf vision backbones.</li>
</ul>

<h3>Title: EchoApex: A General-Purpose Vision Foundation Model for Echocardiography</h3>
<ul>
<li><strong>Authors: </strong>Abdoul Aziz Amadou, Yue Zhang, Sebastien Piat, Paul Klein, Ingo Schmuecking, Tiziano Passerini, Puneet Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11092">https://arxiv.org/abs/2410.11092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11092">https://arxiv.org/pdf/2410.11092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11092]] EchoApex: A General-Purpose Vision Foundation Model for Echocardiography(https://arxiv.org/abs/2410.11092)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Quantitative evaluation of echocardiography is essential for precise assessment of cardiac condition, monitoring disease progression, and guiding treatment decisions. The diverse nature of echo images, including variations in probe types, manufacturers, and pathologies, poses challenges for developing artificial intelligent models that can generalize across different clinical practice. We introduce EchoApex, the first general-purpose vision foundation model echocardiography with applications on a variety of clinical practice. Leveraging self-supervised learning, EchoApex is pretrained on over 20 million echo images from 11 clinical centres. By incorporating task-specific decoders and adapter modules, we demonstrate the effectiveness of EchoApex on 4 different kind of clinical applications with 28 sub-tasks, including view classification, interactive structure segmentation, left ventricle hypertrophy detection and automated ejection fraction estimation from view sequences. Compared to state-of-the-art task-specific models, EchoApex attains improved performance with a unified image encoding architecture, demonstrating the benefits of model pretraining at scale with in-domain data. Furthermore, EchoApex illustrates the potential for developing a general-purpose vision foundation model tailored specifically for echocardiography, capable of addressing a diverse range of clinical applications with high efficiency and efficacy.</li>
</ul>

<h3>Title: SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI</h3>
<ul>
<li><strong>Authors: </strong>Yu Yang, Yuzhou Nie, Zhun Wang, Yuheng Tang, Wenbo Guo, Bo Li, Dawn Song</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11096">https://arxiv.org/abs/2410.11096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11096">https://arxiv.org/pdf/2410.11096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11096]] SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI(https://arxiv.org/abs/2410.11096)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Existing works have established multiple benchmarks to highlight the security risks associated with Code GenAI. These risks are primarily reflected in two areas: a model potential to generate insecure code (insecure coding) and its utility in cyberattacks (cyberattack helpfulness). While these benchmarks have made significant strides, there remain opportunities for further improvement. For instance, many current benchmarks tend to focus more on a model ability to provide attack suggestions rather than its capacity to generate executable attacks. Additionally, most benchmarks rely heavily on static evaluation metrics, which may not be as precise as dynamic metrics such as passing test cases. Conversely, expert-verified benchmarks, while offering high-quality data, often operate at a smaller scale. To address these gaps, we develop SecCodePLT, a unified and comprehensive evaluation platform for code GenAIs' risks. For insecure code, we introduce a new methodology for data creation that combines experts with automatic generation. Our methodology ensures the data quality while enabling large-scale generation. We also associate samples with test cases to conduct code-related dynamic evaluation. For cyberattack helpfulness, we set up a real environment and construct samples to prompt a model to generate actual attacks, along with dynamic metrics in our environment. We conduct extensive experiments and show that SecCodePLT outperforms the state-of-the-art (SOTA) benchmark CyberSecEval in security relevance. Furthermore, it better identifies the security risks of SOTA models in insecure coding and cyberattack helpfulness. Finally, we apply SecCodePLT to the SOTA code agent, Cursor, and, for the first time, identify non-trivial security risks in this advanced coding agent.</li>
</ul>

<h3>Title: Active Learning for Robust and Representative LLM Generation in Safety-Critical Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Sabit Hassan, Anthony Sicilia, Malihe Alikhani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11114">https://arxiv.org/abs/2410.11114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11114">https://arxiv.org/pdf/2410.11114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11114]] Active Learning for Robust and Representative LLM Generation in Safety-Critical Scenarios(https://arxiv.org/abs/2410.11114)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Ensuring robust safety measures across a wide range of scenarios is crucial for user-facing systems. While Large Language Models (LLMs) can generate valuable data for safety measures, they often exhibit distributional biases, focusing on common scenarios and neglecting rare but critical cases. This can undermine the effectiveness of safety protocols developed using such data. To address this, we propose a novel framework that integrates active learning with clustering to guide LLM generation, enhancing their representativeness and robustness in safety scenarios. We demonstrate the effectiveness of our approach by constructing a dataset of 5.4K potential safety violations through an iterative process involving LLM generation and an active learner model's feedback. Our results show that the proposed framework produces a more representative set of safety scenarios without requiring prior knowledge of the underlying data distribution. Additionally, data acquired through our method improves the accuracy and F1 score of both the active learner model as well models outside the scope of active learning process, highlighting its broad applicability.</li>
</ul>

<h3>Title: MoonMetaSync: Lunar Image Registration Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ashutosh Kumar, Sarthak Kaushal, Shiv Vignesh Murthy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, math.AG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11118">https://arxiv.org/abs/2410.11118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11118">https://arxiv.org/pdf/2410.11118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11118]] MoonMetaSync: Lunar Image Registration Analysis(https://arxiv.org/abs/2410.11118)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper compares scale-invariant (SIFT) and scale-variant (ORB) feature detection methods, alongside our novel feature detector, IntFeat, specifically applied to lunar imagery. We evaluate these methods using low (128x128) and high-resolution (1024x1024) lunar image patches, providing insights into their performance across scales in challenging extraterrestrial environments. IntFeat combines high-level features from SIFT and low-level features from ORB into a single vector space for robust lunar image registration. We introduce SyncVision, a Python package that compares lunar images using various registration methods, including SIFT, ORB, and IntFeat. Our analysis includes upscaling low-resolution lunar images using bi-linear and bi-cubic interpolation, offering a unique perspective on registration effectiveness across scales and feature detectors in lunar landscapes. This research contributes to computer vision and planetary science by comparing feature detection methods for lunar imagery and introducing a versatile tool for lunar image registration and evaluation, with implications for multi-resolution image analysis in space exploration applications.</li>
</ul>

<h3>Title: ChuLo: Chunk-Level Key Information Representation for Long Document Processing</h3>
<ul>
<li><strong>Authors: </strong>Yan Li, Caren Han, Yue Dai, Feiqi Cao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11119">https://arxiv.org/abs/2410.11119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11119">https://arxiv.org/pdf/2410.11119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11119]] ChuLo: Chunk-Level Key Information Representation for Long Document Processing(https://arxiv.org/abs/2410.11119)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based models have achieved remarkable success in various Natural Language Processing (NLP) tasks, yet their ability to handle long documents is constrained by computational limitations. Traditional approaches, such as truncating inputs, sparse self-attention, and chunking, attempt to mitigate these issues, but they often lead to information loss and hinder the model's ability to capture long-range dependencies. In this paper, we introduce ChuLo, a novel chunk representation method for long document classification that addresses these limitations. Our ChuLo groups input tokens using unsupervised keyphrase extraction, emphasizing semantically important keyphrase based chunk to retain core document content while reducing input length. This approach minimizes information loss and improves the efficiency of Transformer-based models. Preserving all tokens in long document understanding, especially token classification tasks, is especially important to ensure that fine-grained annotations, which depend on the entire sequence context, are not lost. We evaluate our method on multiple long document classification tasks and long document token classification tasks, demonstrating its effectiveness through comprehensive qualitative and quantitative analyses.</li>
</ul>

<h3>Title: A Systematic Review on Prompt Engineering in Large Language Models for K-12 STEM Education</h3>
<ul>
<li><strong>Authors: </strong>Eason Chen, Danyang Wang, Luyi Xu, Chen Cao, Xiao Fang, Jionghao Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11123">https://arxiv.org/abs/2410.11123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11123">https://arxiv.org/pdf/2410.11123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11123]] A Systematic Review on Prompt Engineering in Large Language Models for K-12 STEM Education(https://arxiv.org/abs/2410.11123)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have the potential to enhance K-12 STEM education by improving both teaching and learning processes. While previous studies have shown promising results, there is still a lack of comprehensive understanding regarding how LLMs are effectively applied, specifically through prompt engineering-the process of designing prompts to generate desired outputs. To address this gap, our study investigates empirical research published between 2021 and 2024 that explores the use of LLMs combined with prompt engineering in K-12 STEM education. Following the PRISMA protocol, we screened 2,654 papers and selected 30 studies for analysis. Our review identifies the prompting strategies employed, the types of LLMs used, methods of evaluating effectiveness, and limitations in prior work. Results indicate that while simple and zero-shot prompting are commonly used, more advanced techniques like few-shot and chain-of-thought prompting have demonstrated positive outcomes for various educational tasks. GPT-series models are predominantly used, but smaller and fine-tuned models (e.g., Blender 7B) paired with effective prompt engineering outperform prompting larger models (e.g., GPT-3) in specific contexts. Evaluation methods vary significantly, with limited empirical validation in real-world settings.</li>
</ul>

<h3>Title: Real-Time Localization and Bimodal Point Pattern Analysis of Palms Using UAV Imagery</h3>
<ul>
<li><strong>Authors: </strong>Kangning Cui, Wei Tang, Rongkun Zhu, Manqi Wang, Gregory D. Larsen, Victor P. Pauca, Sarra Alqahtani, Fan Yang, David Segurado, Paul Fine, Jordan Karubian, Raymond H. Chan, Robert J. Plemmons, Jean-Michel Morel, Miles R. Silman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11124">https://arxiv.org/abs/2410.11124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11124">https://arxiv.org/pdf/2410.11124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11124]] Real-Time Localization and Bimodal Point Pattern Analysis of Palms Using UAV Imagery(https://arxiv.org/abs/2410.11124)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Understanding the spatial distribution of palms within tropical forests is essential for effective ecological monitoring, conservation strategies, and the sustainable integration of natural forest products into local and global supply chains. However, the analysis of remotely sensed data in these environments faces significant challenges, such as overlapping palm and tree crowns, uneven shading across the canopy surface, and the heterogeneous nature of the forest landscapes, which often affect the performance of palm detection and segmentation algorithms. To overcome these issues, we introduce PalmDSNet, a deep learning framework for real-time detection, segmentation, and counting of canopy palms. Additionally, we employ a bimodal reproduction algorithm that simulates palm spatial propagation to further enhance the understanding of these point patterns using PalmDSNet's results. We used UAV-captured imagery to create orthomosaics from 21 sites across western Ecuadorian tropical forests, covering a gradient from the everwet Chocó forests near Colombia to the drier forests of southwestern Ecuador. Expert annotations were used to create a comprehensive dataset, including 7,356 bounding boxes on image patches and 7,603 palm centers across five orthomosaics, encompassing a total area of 449 hectares. By combining PalmDSNet with the bimodal reproduction algorithm, which optimizes parameters for both local and global spatial variability, we effectively simulate the spatial distribution of palms in diverse and dense tropical environments, validating its utility for advanced applications in tropical forest monitoring and remote sensing analysis.</li>
</ul>

<h3>Title: UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Hui Ye, Rajshekhar Sunderraman, Shihao Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11125">https://arxiv.org/abs/2410.11125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11125">https://arxiv.org/pdf/2410.11125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11125]] UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles(https://arxiv.org/abs/2410.11125)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Unmanned Aerial Vehicles (UAVs), equipped with cameras, are employed in numerous applications, including aerial photography, surveillance, and agriculture. In these applications, robust object detection and tracking are essential for the effective deployment of UAVs. However, existing benchmarks for UAV applications are mainly designed for traditional 2D perception tasks, restricting the development of real-world applications that require a 3D understanding of the environment. Furthermore, despite recent advancements in single-UAV perception, limited views of a single UAV platform significantly constrain its perception capabilities over long distances or in occluded areas. To address these challenges, we introduce UAV3D, a benchmark designed to advance research in both 3D and collaborative 3D perception tasks with UAVs. UAV3D comprises 1,000 scenes, each of which has 20 frames with fully annotated 3D bounding boxes on vehicles. We provide the benchmark for four 3D perception tasks: single-UAV 3D object detection, single-UAV object tracking, collaborative-UAV 3D object detection, and collaborative-UAV object tracking. Our dataset and code are available at this https URL.</li>
</ul>

<h3>Title: IsoChronoMeter: A simple and effective isochronic translation evaluation metric</h3>
<ul>
<li><strong>Authors: </strong>Nikolai Rozanov, Vikentiy Pankov, Dmitrii Mukhutdinov, Dima Vypirailenko</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11127">https://arxiv.org/abs/2410.11127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11127">https://arxiv.org/pdf/2410.11127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11127]] IsoChronoMeter: A simple and effective isochronic translation evaluation metric(https://arxiv.org/abs/2410.11127)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Machine translation (MT) has come a long way and is readily employed in production systems to serve millions of users daily. With the recent advances in generative AI, a new form of translation is becoming possible - video dubbing. This work motivates the importance of isochronic translation, especially in the context of automatic dubbing, and introduces `IsoChronoMeter' (ICM). ICM is a simple yet effective metric to measure isochrony of translations in a scalable and resource-efficient way without the need for gold data, based on state-of-the-art text-to-speech (TTS) duration predictors. We motivate IsoChronoMeter and demonstrate its effectiveness. Using ICM we demonstrate the shortcomings of state-of-the-art translation systems and show the need for new methods. We release the code at this URL: \url{this https URL}.</li>
</ul>

<h3>Title: Sensor Deprivation Attacks for Stealthy UAV Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Alessandro Erba, John H. Castellanos, Sahil Sihag, Saman Zonouz, Nils Ole Tippenhauer</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11131">https://arxiv.org/abs/2410.11131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11131">https://arxiv.org/pdf/2410.11131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11131]] Sensor Deprivation Attacks for Stealthy UAV Manipulation(https://arxiv.org/abs/2410.11131)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Unmanned Aerial Vehicles autonomously perform tasks with the use of state-of-the-art control algorithms. These control algorithms rely on the freshness and correctness of sensor readings. Incorrect control actions lead to catastrophic destabilization of the process. In this work, we propose a multi-part \emph{Sensor Deprivation Attacks} (SDAs), aiming to stealthily impact process control via sensor reconfiguration. In the first part, the attacker will inject messages on local buses that connect to the sensor. The injected message reconfigures the sensors, e.g.,~to suspend the sensing. In the second part, those manipulation primitives are selectively used to cause adversarial sensor values at the controller, transparently to the data consumer. In the third part, the manipulated sensor values lead to unwanted control actions (e.g. a drone crash). We experimentally investigate all three parts of our proposed attack. Our findings show that i)~reconfiguring sensors can have surprising effects on reported sensor values, and ii)~the attacker can stall the overall Kalman Filter state estimation, leading to a complete stop of control computations. As a result, the UAV becomes destabilized, leading to a crash or significant deviation from its planned trajectory (over 30 meters). We also propose an attack synthesis methodology that optimizes the timing of these SDA manipulations, maximizing their impact. Notably, our results demonstrate that these SDAs evade detection by state-of-the-art UAV anomaly detectors. Our work shows that attacks on sensors are not limited to continuously inducing random measurements, and demonstrate that sensor reconfiguration can completely stall the drone controller. In our experiments, state-of-the-art UAV controller software and countermeasures are unable to handle such manipulations. Hence, we also discuss new corresponding countermeasures.</li>
</ul>

<h3>Title: Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments</h3>
<ul>
<li><strong>Authors: </strong>Nikhil Vanjani, Pratik Soni, Sri AravindaKrishnan Thyagarajan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11134">https://arxiv.org/abs/2410.11134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11134">https://arxiv.org/pdf/2410.11134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11134]] Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments(https://arxiv.org/abs/2410.11134)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, fair</a></li>
<li><strong>Abstract: </strong>In scenarios where a seller holds sensitive data $x$, like patient records, and a buyer seeks to obtain an evaluation of a function $f$ on $x$, solutions in trustless environments like blockchain fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions using tools such as adaptor signatures. The former offers atomic transactions where the buyer learns $f(x)$ upon payment. However, this approach is inefficient, costly, lacks privacy for the seller's data, and is incompatible with blockchains such as bitcoin. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an "all-or-nothing" guarantee, where the buyer fully extracts $x$ and does not support extracting $f(x)$. In this work, we bridge the gap between these approaches, developing a solution that enables fair functional sales while offering all the above properties like adaptor signatures. Towards this, we propose functional adaptor signatures (FAS), a novel cryptographic primitive and show how it can be used to enable functional sales. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond $f(x)$. We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge. We introduce two efficient constructions of FAS supporting linear functions based on groups of prime-order and lattices, that satisfy the strongest notion of witness privacy. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption and adaptor signatures. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, all operations are quite efficient even for commodity hardware.</li>
</ul>

<h3>Title: Mimetic Initialization Helps State Space Models Learn to Recall</h3>
<ul>
<li><strong>Authors: </strong>Asher Trockman, Hrayr Harutyunyan, J. Zico Kolter, Sanjiv Kumar, Srinadh Bhojanapalli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11135">https://arxiv.org/abs/2410.11135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11135">https://arxiv.org/pdf/2410.11135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11135]] Mimetic Initialization Helps State Space Models Learn to Recall(https://arxiv.org/abs/2410.11135)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer</a></li>
<li><strong>Abstract: </strong>Recent work has shown that state space models such as Mamba are significantly worse than Transformers on recall-based tasks due to the fact that their state size is constant with respect to their input sequence length. But in practice, state space models have fairly large state sizes, and we conjecture that they should be able to perform much better at these tasks than previously reported. We investigate whether their poor copying and recall performance could be due in part to training difficulties rather than fundamental capacity constraints. Based on observations of their "attention" maps, we propose a structured initialization technique that allows state space layers to more readily mimic attention. Across a variety of architecture settings, our initialization makes it substantially easier for Mamba to learn to copy and do associative recall from scratch.</li>
</ul>

<h3>Title: LLM Unlearning via Loss Adjustment with Only Forget Data</h3>
<ul>
<li><strong>Authors: </strong>Yaxuan Wang, Jiaheng Wei, Chris Yuhao Liu, Jinlong Pang, Quan Liu, Ankit Parag Shah, Yujia Bao, Yang Liu, Wei Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11143">https://arxiv.org/abs/2410.11143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11143">https://arxiv.org/pdf/2410.11143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11143]] LLM Unlearning via Loss Adjustment with Only Forget Data(https://arxiv.org/abs/2410.11143)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Unlearning in Large Language Models (LLMs) is essential for ensuring ethical and responsible AI use, especially in addressing privacy leak, bias, safety, and evolving regulations. Existing approaches to LLM unlearning often rely on retain data or a reference LLM, yet they struggle to adequately balance unlearning performance with overall model utility. This challenge arises because leveraging explicit retain data or implicit knowledge of retain data from a reference LLM to fine-tune the model tends to blur the boundaries between the forgotten and retain data, as different queries often elicit similar responses. In this work, we propose eliminating the need to retain data or the reference LLM for response calibration in LLM unlearning. Recognizing that directly applying gradient ascent on the forget data often leads to optimization instability and poor performance, our method guides the LLM on what not to respond to, and importantly, how to respond, based on the forget data. Hence, we introduce Forget data only Loss AjustmenT (FLAT), a "flat" loss adjustment approach which addresses these issues by maximizing f-divergence between the available template answer and the forget answer only w.r.t. the forget data. The variational form of the defined f-divergence theoretically provides a way of loss adjustment by assigning different importance weights for the learning w.r.t. template responses and the forgetting of responses subject to unlearning. Empirical results demonstrate that our approach not only achieves superior unlearning performance compared to existing methods but also minimizes the impact on the model's retained capabilities, ensuring high utility across diverse tasks, including copyrighted content unlearning on Harry Potter dataset and MUSE Benchmark, and entity unlearning on the TOFU dataset.</li>
</ul>

<h3>Title: Free Hunch: Denoiser Covariance Estimation for Diffusion Models Without Extra Costs</h3>
<ul>
<li><strong>Authors: </strong>Severi Rissanen, Markus Heinonen, Arno Solin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11149">https://arxiv.org/abs/2410.11149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11149">https://arxiv.org/pdf/2410.11149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11149]] Free Hunch: Denoiser Covariance Estimation for Diffusion Models Without Extra Costs(https://arxiv.org/abs/2410.11149)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The covariance for clean data given a noisy observation is an important quantity in many conditional generation methods for diffusion models. Current methods require heavy test-time computation, altering the standard diffusion training process or denoiser architecture, or making heavy approximations. We propose a new framework that sidesteps these issues by using covariance information that is available for free from training data and the curvature of the generative trajectory, which is linked to the covariance through the second-order Tweedie's formula. We integrate these sources of information using {\em (i)} a novel method to transfer covariance estimates across noise levels and (ii) low-rank updates in a given noise level. We validate the method on linear inverse problems, where it outperforms recent baselines, especially with fewer diffusion steps.</li>
</ul>

<h3>Title: MANet: Fine-Tuning Segment Anything Model for Multimodal Remote Sensing Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xianping Ma, Xiaokang Zhang, Man-On Pun, Bo Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11160">https://arxiv.org/abs/2410.11160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11160">https://arxiv.org/pdf/2410.11160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11160]] MANet: Fine-Tuning Segment Anything Model for Multimodal Remote Sensing Semantic Segmentation(https://arxiv.org/abs/2410.11160)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Multimodal remote sensing data, collected from a variety of sensors, provide a comprehensive and integrated perspective of the Earth's surface. By employing multimodal fusion techniques, semantic segmentation offers more detailed insights into geographic scenes compared to single-modality approaches. Building upon recent advancements in vision foundation models, particularly the Segment Anything Model (SAM), this study introduces a novel Multimodal Adapter-based Network (MANet) for multimodal remote sensing semantic segmentation. At the core of this approach is the development of a Multimodal Adapter (MMAdapter), which fine-tunes SAM's image encoder to effectively leverage the model's general knowledge for multimodal data. In addition, a pyramid-based Deep Fusion Module (DFM) is incorporated to further integrate high-level geographic features across multiple scales before decoding. This work not only introduces a novel network for multimodal fusion, but also demonstrates, for the first time, SAM's powerful generalization capabilities with Digital Surface Model (DSM) data. Experimental results on two well-established fine-resolution multimodal remote sensing datasets, ISPRS Vaihingen and ISPRS Potsdam, confirm that the proposed MANet significantly surpasses current models in the task of multimodal semantic segmentation. The source code for this work will be accessible at this https URL.</li>
</ul>

<h3>Title: Exploring Content Concealment in Email</h3>
<ul>
<li><strong>Authors: </strong>Lucas Betts, Robert Biddle, Danielle Lottridge, Giovanni Russello</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11169">https://arxiv.org/abs/2410.11169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11169">https://arxiv.org/pdf/2410.11169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11169]] Exploring Content Concealment in Email(https://arxiv.org/abs/2410.11169)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The never-ending barrage of malicious emails, such as spam and phishing, is of constant concern for users, who rely on countermeasures such as email filters to keep the intended recipient safe. Modern email filters, one of our few defence mechanisms against malicious emails, are often circumvented by sophisticated attackers. This study focuses on how attackers exploit HTML and CSS in emails to conceal arbitrary content, allowing for multiple permutations of a malicious email, some of which may evade detection by email filters. This concealed content remains undetected by the recipient, presenting a serious security risk. Our research involved developing and applying an email sampling and analysis procedure to a large-scale dataset of unsolicited emails. We then identify the sub-types of concealment attackers use to conceal content and the HTML and CSS tricks employed.</li>
</ul>

<h3>Title: Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention</h3>
<ul>
<li><strong>Authors: </strong>Shweta Patel, Dakshina Ranjan Kisku</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11176">https://arxiv.org/abs/2410.11176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11176">https://arxiv.org/pdf/2410.11176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11176]] Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention(https://arxiv.org/abs/2410.11176)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Ensuring that AI-based facial recognition systems produce fair predictions and work equally well across all demographic groups is crucial. Earlier systems often exhibited demographic bias, particularly in gender and racial classification, with lower accuracy for women and individuals with darker skin tones. To tackle this issue and promote fairness in facial recognition, researchers have introduced several bias-mitigation techniques for gender classification and related algorithms. However, many challenges remain, such as data diversity, balancing fairness with accuracy, disparity, and bias measurement. This paper presents a method using a dual attention mechanism with a pre-trained Inception-ResNet V1 model, enhanced by KL-divergence regularization and a cross-entropy loss function. This approach reduces bias while improving accuracy and computational efficiency through transfer learning. The experimental results show significant improvements in both fairness and classification accuracy, providing promising advances in addressing bias and enhancing the reliability of facial recognition systems.</li>
</ul>

<h3>Title: Interpretability as Compression: Reconsidering SAE Explanations of Neural Activations with MDL-SAEs</h3>
<ul>
<li><strong>Authors: </strong>Kola Ayonrinde, Michael T. Pearce, Lee Sharkey</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11179">https://arxiv.org/abs/2410.11179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11179">https://arxiv.org/pdf/2410.11179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11179]] Interpretability as Compression: Reconsidering SAE Explanations of Neural Activations with MDL-SAEs(https://arxiv.org/abs/2410.11179)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Sparse Autoencoders (SAEs) have emerged as a useful tool for interpreting the internal representations of neural networks. However, naively optimising SAEs for reconstruction loss and sparsity results in a preference for SAEs that are extremely wide and sparse. We present an information-theoretic framework for interpreting SAEs as lossy compression algorithms for communicating explanations of neural activations. We appeal to the Minimal Description Length (MDL) principle to motivate explanations of activations which are both accurate and concise. We further argue that interpretable SAEs require an additional property, "independent additivity": features should be able to be understood separately. We demonstrate an example of applying our MDL-inspired framework by training SAEs on MNIST handwritten digits and find that SAE features representing significant line segments are optimal, as opposed to SAEs with features for memorised digits from the dataset or small digit fragments. We argue that using MDL rather than sparsity may avoid potential pitfalls with naively maximising sparsity such as undesirable feature splitting and that this framework naturally suggests new hierarchical SAE architectures which provide more concise explanations.</li>
</ul>

<h3>Title: Archilles' Heel in Semi-open LLMs: Hiding Bottom against Recovery Attacks</h3>
<ul>
<li><strong>Authors: </strong>Hanbo Huang, Yihan Li, Bowen Jiang, Lin Liu, Ruoyu Sun, Zhuotao Liu, Shiyu Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11182">https://arxiv.org/abs/2410.11182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11182">https://arxiv.org/pdf/2410.11182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11182]] Archilles' Heel in Semi-open LLMs: Hiding Bottom against Recovery Attacks(https://arxiv.org/abs/2410.11182)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Closed-source large language models deliver strong performance but have limited downstream customizability. Semi-open models, combining both closed-source and public layers, were introduced to improve customizability. However, parameters in the closed-source layers are found vulnerable to recovery attacks. In this paper, we explore the design of semi-open models with fewer closed-source layers, aiming to increase customizability while ensuring resilience to recovery attacks. We analyze the contribution of closed-source layer to the overall resilience and theoretically prove that in a deep transformer-based model, there exists a transition layer such that even small recovery errors in layers before this layer can lead to recovery failure. Building on this, we propose \textbf{SCARA}, a novel approach that keeps only a few bottom layers as closed-source. SCARA employs a fine-tuning-free metric to estimate the maximum number of layers that can be publicly accessible for customization. We apply it to five models (1.3B to 70B parameters) to construct semi-open models, validating their customizability on six downstream tasks and assessing their resilience against various recovery attacks on sixteen benchmarks. We compare SCARA to baselines and observe that it generally improves downstream customization performance and offers similar resilience with over \textbf{10} times fewer closed-source parameters. We empirically investigate the existence of transition layers, analyze the effectiveness of our scheme and finally discuss its limitations.</li>
</ul>

<h3>Title: Fast and Accurate Homomorphic Softmax Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Wonhee Cho, Guillaume Hanrot, Taeseong Kim, Minje Park, Damien Stehlé</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11184">https://arxiv.org/abs/2410.11184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11184">https://arxiv.org/pdf/2410.11184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11184]] Fast and Accurate Homomorphic Softmax Evaluation(https://arxiv.org/abs/2410.11184)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Homomorphic encryption is one of the main solutions for building secure and privacy-preserving solutions for Machine Learning as a Service. This motivates the development of homomorphic algorithms for the main building blocks of AI, typically for the components of the various types of neural networks architectures. Among those components, we focus on the Softmax function, defined by $\mathrm{SM}(\mathbf{x}) = \left(\exp(x_i) / \sum_{j=1}^n \exp(x_j) \right)_{1\le i\le n}$. This function is deemed to be one of the most difficult to evaluate homomorphically, because of its multivariate nature and of the very large range of values for $\exp(x_i)$. The available homomorphic algorithms remain restricted, especially in large dimensions, while important applications such as Large Language Models (LLM) require computing Softmax over large dimensional vectors. In terms of multiplicative depth of the computation (a suitable measure of cost for homomorphic algorithms), our algorithm achieves $O(\log n)$ complexity for a fixed range of inputs, where $n$ is the Softmax dimension. Our algorithm is especially adapted to the situation where we must compute many Softmax at the same time, for instance, in the LLM situation. In that case, assuming that all Softmax calls are packed into $m$ ciphtertexts, the asymptotic amortized multiplicative depth cost per ciphertext is, again over a fixed range, $O(1 + m/N)$ for $N$ the homomorphic ring degree. The main ingredient of our algorithms is a normalize-and-square strategy, which interlaces the exponential computation over a large range and normalization, decomposing both in stabler and cheaper smaller steps. Comparing ourselves to the state of the art, our experiments show, in practice, a good accuracy and a gain of a factor 2.5 to 8 compared to state of the art solutions.</li>
</ul>

<h3>Title: Synthesizing Proton-Density Fat Fraction and $R_2^*$ from 2-point Dixon MRI with Generative Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Suma Anand, Kaiwen Xu, Colm O'Dushlaine, Sumit Mukherjee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11186">https://arxiv.org/abs/2410.11186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11186">https://arxiv.org/pdf/2410.11186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11186]] Synthesizing Proton-Density Fat Fraction and $R_2^*$ from 2-point Dixon MRI with Generative Machine Learning(https://arxiv.org/abs/2410.11186)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Magnetic Resonance Imaging (MRI) is the gold standard for measuring fat and iron content non-invasively in the body via measures known as Proton Density Fat Fraction (PDFF) and $R_2^*$, respectively. However, conventional PDFF and $R_2^*$ quantification methods operate on MR images voxel-wise and require at least three measurements to estimate three quantities: water, fat, and $R_2^*$. Alternatively, the two-point Dixon MRI protocol is widely used and fast because it acquires only two measurements; however, these cannot be used to estimate three quantities voxel-wise. Leveraging the fact that neighboring voxels have similar values, we propose using a generative machine learning approach to learn PDFF and $R_2^*$ from Dixon MRI. We use paired Dixon-IDEAL data from UK Biobank in the liver and a Pix2Pix conditional GAN to demonstrate the first large-scale $R_2^*$ imputation from two-point Dixon MRIs. Using our proposed approach, we synthesize PDFF and $R_2^*$ maps that show significantly greater correlation with ground-truth than conventional voxel-wise baselines.</li>
</ul>

<h3>Title: Multiview Scene Graph</h3>
<ul>
<li><strong>Authors: </strong>Juexiao Zhang, Gao Zhu, Sihang Li, Xinhao Liu, Haorui Song, Xinran Tang, Chen Feng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11187">https://arxiv.org/abs/2410.11187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11187">https://arxiv.org/pdf/2410.11187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11187]] Multiview Scene Graph(https://arxiv.org/abs/2410.11187)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>A proper scene representation is central to the pursuit of spatial intelligence where agents can robustly reconstruct and efficiently understand 3D scenes. A scene representation is either metric, such as landmark maps in 3D reconstruction, 3D bounding boxes in object detection, or voxel grids in occupancy prediction, or topological, such as pose graphs with loop closures in SLAM or visibility graphs in SfM. In this work, we propose to build Multiview Scene Graphs (MSG) from unposed images, representing a scene topologically with interconnected place and object nodes. The task of building MSG is challenging for existing representation learning methods since it needs to jointly address both visual place recognition, object detection, and object association from images with limited fields of view and potentially large viewpoint changes. To evaluate any method tackling this task, we developed an MSG dataset and annotation based on a public 3D dataset. We also propose an evaluation metric based on the intersection-over-union score of MSG edges. Moreover, we develop a novel baseline method built on mainstream pretrained vision models, combining visual place recognition and object association into one Transformer decoder architecture. Experiments demonstrate our method has superior performance compared to existing relevant baselines.</li>
</ul>

<h3>Title: Fast Second-Order Online Kernel Learning through Incremental Matrix Sketching and Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Dongxie Wen, Xiao Zhang, Zhewei Wei</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11188">https://arxiv.org/abs/2410.11188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11188">https://arxiv.org/pdf/2410.11188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11188]] Fast Second-Order Online Kernel Learning through Incremental Matrix Sketching and Decomposition(https://arxiv.org/abs/2410.11188)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Online Kernel Learning (OKL) has attracted considerable research interest due to its promising predictive performance in streaming environments. Second-order approaches are particularly appealing for OKL as they often offer substantial improvements in regret guarantees. However, existing second-order OKL approaches suffer from at least quadratic time complexity with respect to the pre-set budget, rendering them unsuitable for meeting the real-time demands of large-scale streaming recommender systems. The singular value decomposition required to obtain explicit feature mapping is also computationally expensive due to the complete decomposition process. Moreover, the absence of incremental updates to manage approximate kernel space causes these algorithms to perform poorly in adversarial environments and real-world streaming recommendation datasets. To address these issues, we propose FORKS, a fast incremental matrix sketching and decomposition approach tailored for second-order OKL. FORKS constructs an incremental maintenance paradigm for second-order kernelized gradient descent, which includes incremental matrix sketching for kernel approximation and incremental matrix decomposition for explicit feature mapping construction. Theoretical analysis demonstrates that FORKS achieves a logarithmic regret guarantee on par with other second-order approaches while maintaining a linear time complexity w.r.t. the budget, significantly enhancing efficiency over existing approaches. We validate the performance of FORKS through extensive experiments conducted on real-world streaming recommendation datasets, demonstrating its superior scalability and robustness against adversarial attacks.</li>
</ul>

<h3>Title: Rethinking Graph Transformer Architecture Design for Node Classification</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Zhou, Xuanze Chen, Chenxuan Xie, Yu Shanqing, Qi Xuan, Xiaoniu Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11189">https://arxiv.org/abs/2410.11189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11189">https://arxiv.org/pdf/2410.11189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11189]] Rethinking Graph Transformer Architecture Design for Node Classification(https://arxiv.org/abs/2410.11189)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph Transformer (GT), as a special type of Graph Neural Networks (GNNs), utilizes multi-head attention to facilitate high-order message passing. However, this also imposes several limitations in node classification applications: 1) nodes are susceptible to global noise; 2) self-attention computation cannot scale well to large graphs. In this work, we conduct extensive observational experiments to explore the adaptability of the GT architecture in node classification tasks and draw several conclusions: the current multi-head self-attention module in GT can be completely replaceable, while the feed-forward neural network module proves to be valuable. Based on this, we decouple the propagation (P) and transformation (T) of GNNs and explore a powerful GT architecture, named GNNFormer, which is based on the P/T combination message passing and adapted for node classification in both homophilous and heterophilous scenarios. Extensive experiments on 12 benchmark datasets demonstrate that our proposed GT architecture can effectively adapt to node classification tasks without being affected by global noise and computational efficiency limitations.</li>
</ul>

<h3>Title: Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiao Peng, Liang Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11195">https://arxiv.org/abs/2410.11195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11195">https://arxiv.org/pdf/2410.11195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11195]] Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models(https://arxiv.org/abs/2410.11195)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, large language models (LLMs) like ChatGPT, LLaMA, and Claude have prevailed in countless domains, including legal scenarios. With LLMs' rapid technological progress, the development of prompt engineering (PE) as an interface between the LLMs and real-world applications has drawn the attention of all developers. Various PE methods have been proposed to overcome real-world challenges, such as few-shot prompting, chain-of-thought, and retrieval-augmented generation (RAG). However, RAG for legal judgment prediction (LJP) is still underexplored. To address this, we propose "Athena", a novel framework cultivating RAG as a core preprocess component to enhance LLMs' performance on specialized tasks. Athena constructs a knowledge base for accusations, attached with a semantic retrieval mechanism through vectorization. Our experiments show that Athena's overall performance has improved significantly, achieving state-of-the-art results on the CAIL2018 dataset. Our ablation study on the in-context window size parameter further reproduces LLMs' "lost-in-the-middle" phenomenon with a relative positional variation. And with moderate hyper-parameter-tuning, we can achieve at most 95% of accuracy accordingly. We also study the impact of query rewriting and data distribution, providing possible directions for future research based on former analyses.</li>
</ul>

<h3>Title: SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Rikuto Kotoge, Zheng Chen, Tasuku Kimura, Yasuko Matsubara, Takufumi Yanagisawa, Haruhiko Kishima, Yasushi Sakurai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11200">https://arxiv.org/abs/2410.11200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11200">https://arxiv.org/pdf/2410.11200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11200]] SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning(https://arxiv.org/abs/2410.11200)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While end-to-end multi-channel electroencephalography (EEG) learning approaches have shown significant promise, their applicability is often constrained in neurological diagnostics, such as intracranial EEG resources. When provided with a single-channel EEG, how can we learn representations that are robust to multi-channels and scalable across varied tasks, such as seizure prediction? In this paper, we present SplitSEE, a structurally splittable framework designed for effective temporal-frequency representation learning in single-channel EEG. The key concept of SplitSEE is a self-supervised framework incorporating a deep clustering task. Given an EEG, we argue that the time and frequency domains are two distinct perspectives, and hence, learned representations should share the same cluster assignment. To this end, we first propose two domain-specific modules that independently learn domain-specific representation and address the temporal-frequency tradeoff issue in conventional spectrogram-based methods. Then, we introduce a novel clustering loss to measure the information similarity. This encourages representations from both domains to coherently describe the same input by assigning them a consistent cluster. SplitSEE leverages a pre-training-to-fine-tuning framework within a splittable architecture and has following properties: (a) Effectiveness: it learns representations solely from single-channel EEG but has even outperformed multi-channel baselines. (b) Robustness: it shows the capacity to adapt across different channels with low performance variance. Superior performance is also achieved with our collected clinical dataset. (c) Scalability: With just one fine-tuning epoch, SplitSEE achieves high and stable performance using partial model layers.</li>
</ul>

<h3>Title: Error Diffusion: Post Training Quantization with Block-Scaled Number Formats for Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Alireza Khodamoradi, Kristof Denolf, Eric Dellinger</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11203">https://arxiv.org/abs/2410.11203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11203">https://arxiv.org/pdf/2410.11203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11203]] Error Diffusion: Post Training Quantization with Block-Scaled Number Formats for Neural Networks(https://arxiv.org/abs/2410.11203)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Quantization reduces the model's hardware costs, such as data movement, storage, and operations like multiply and addition. It also affects the model's behavior by degrading the output quality. Therefore, there is a need for methods that preserve the model's behavior when quantizing model parameters. More exotic numerical encodings, such as block-scaled number formats, have shown advantages for utilizing a fixed bit budget to encode model parameters. This paper presents error diffusion (ED), a hyperparameter-free method for post-training quantization with support for block-scaled data formats. Our approach does not rely on backpropagation or Hessian information. We describe how to improve the quantization process by viewing the neural model as a composite function and diffusing the quantization error in every layer. In addition, we introduce TensorCast, an open-source library based on PyTorch to emulate a variety of number formats, including the block-scaled ones, to aid the research in neural model quantization. We demonstrate the efficacy of our algorithm through rigorous testing on various architectures, including vision and large language models (LLMs), where it consistently delivers competitive results. Our experiments confirm that block-scaled data formats provide a robust choice for post-training quantization and could be used effectively to enhance the practical deployment of advanced neural networks.</li>
</ul>

<h3>Title: Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11205">https://arxiv.org/abs/2410.11205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11205">https://arxiv.org/pdf/2410.11205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11205]] Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning(https://arxiv.org/abs/2410.11205)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Recent works have shown that Federated Learning (FL) is vulnerable to backdoor attacks. Existing defenses cluster submitted updates from clients and select the best cluster for aggregation. However, they often rely on unrealistic assumptions regarding client submissions and sampled clients population while choosing the best cluster. We show that in realistic FL settings, state-of-the-art (SOTA) defenses struggle to perform well against backdoor attacks in FL. To address this, we highlight that backdoored submissions are adversarially biased and overconfident compared to clean submissions. We, therefore, propose an Adversarially Guided Stateful Defense (AGSD) against backdoor attacks on Deep Neural Networks (DNNs) in FL scenarios. AGSD employs adversarial perturbations to a small held-out dataset to compute a novel metric, called the trust index, that guides the cluster selection without relying on any unrealistic assumptions regarding client submissions. Moreover, AGSD maintains a trust state history of each client that adaptively penalizes backdoored clients and rewards clean clients. In realistic FL settings, where SOTA defenses mostly fail to resist attacks, AGSD mostly outperforms all SOTA defenses with minimal drop in clean accuracy (5% in the worst-case compared to best accuracy) even when (a) given a very small held-out dataset -- typically AGSD assumes 50 samples (<= 0.1% of the training data) and (b) no heldout dataset is available, and out-of-distribution data is used instead. For reproducibility, our code will be openly available at: this https URL.</li>
</ul>

<h3>Title: DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhengyang Yu, Zhaoyuan Yang, Jing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11208">https://arxiv.org/abs/2410.11208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11208">https://arxiv.org/pdf/2410.11208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11208]] DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models(https://arxiv.org/abs/2410.11208)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent text-to-image personalization methods have shown great promise in teaching a diffusion model user-specified concepts given a few images for reusing the acquired concepts in a novel context. With massive efforts being dedicated to personalized generation, a promising extension is personalized editing, namely to edit an image using personalized concepts, which can provide a more precise guidance signal than traditional textual guidance. To address this, a straightforward solution is to incorporate a personalized diffusion model with a text-driven editing framework. However, such a solution often shows unsatisfactory editability on the source image. To address this, we propose DreamSteerer, a plug-in method for augmenting existing T2I personalization methods. Specifically, we enhance the source image conditioned editability of a personalized diffusion model via a novel Editability Driven Score Distillation (EDSD) objective. Moreover, we identify a mode trapping issue with EDSD, and propose a mode shifting regularization with spatial feature guided sampling to avoid such an issue. We further employ two key modifications to the Delta Denoising Score framework that enable high-fidelity local editing with personalized concepts. Extensive experiments validate that DreamSteerer can significantly improve the editability of several T2I personalization baselines while being computationally efficient.</li>
</ul>

<h3>Title: CRUcialG: Reconstruct Integrated Attack Scenario Graphs by Cyber Threat Intelligence Reports</h3>
<ul>
<li><strong>Authors: </strong>Wenrui Cheng, Tiantian Zhu, Tieming Chen, Qixuan Yuan, Jie Ying, Hongmei Li, Chunlin Xiong, Mingda Li, Mingqi Lv, Yan Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11209">https://arxiv.org/abs/2410.11209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11209">https://arxiv.org/pdf/2410.11209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11209]] CRUcialG: Reconstruct Integrated Attack Scenario Graphs by Cyber Threat Intelligence Reports(https://arxiv.org/abs/2410.11209)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction</a></li>
<li><strong>Abstract: </strong>Cyber Threat Intelligence (CTI) reports are factual records compiled by security analysts through their observations of threat events or their own practical experience with attacks. In order to utilize CTI reports for attack detection, existing methods have attempted to map the content of reports onto system-level attack provenance graphs to clearly depict attack procedures. However, existing studies on constructing graphs from CTI reports suffer from problems such as weak natural language processing (NLP) capabilities, discrete and fragmented graphs, and insufficient attack semantic representation. Therefore, we propose a system called CRUcialG for the automated reconstruction of attack scenario graphs (ASGs) by CTI reports. First, we use NLP models to extract systematic attack knowledge from CTI reports to form preliminary ASGs. Then, we propose a four-phase attack rationality verification framework from the tactical phase with attack procedure to evaluate the reasonability of ASGs. Finally, we implement the relation repair and phase supplement of ASGs by adopting a serialized graph generation model. We collect a total of 10,607 CTI reports and generate 5,761 complete ASGs. Experimental results on CTI reports from 30 security vendors and DARPA show that the similarity of ASG reconstruction by CRUcialG can reach 84.54%. Compared with SOTA (EXTRACTOR and AttackG), the recall of CRUcialG (extraction of real attack events) can reach 88.13% and 94.46% respectively, which is 40% higher than SOTA on average. The F1-score of attack phase verification is able to reach 90.04%.</li>
</ul>

<h3>Title: CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction</h3>
<ul>
<li><strong>Authors: </strong>Pranav Gupta, Rishabh Rengarajan, Viren Bankapur, Vedansh Mannem, Lakshit Ahuja, Surya Vijay, Kevin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11211">https://arxiv.org/abs/2410.11211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11211">https://arxiv.org/pdf/2410.11211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11211]] CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction(https://arxiv.org/abs/2410.11211)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Combining LiDAR and Camera-view data has become a common approach for 3D Object Detection. However, previous approaches combine the two input streams at a point-level, throwing away semantic information derived from camera features. In this paper we propose Cross-View Center Point-Fusion, a state-of-the-art model to perform 3D object detection by combining camera and LiDAR-derived features in the BEV space to preserve semantic density from the camera stream while incorporating spacial data from the LiDAR stream. Our architecture utilizes aspects from previously established algorithms, Cross-View Transformers and CenterPoint, and runs their backbones in parallel, allowing efficient computation for real-time processing and application. In this paper we find that while an implicitly calculated depth-estimate may be sufficiently accurate in a 2D map-view representation, explicitly calculated geometric and spacial information is needed for precise bounding box prediction in the 3D world-view space.</li>
</ul>

<h3>Title: A CLIP-Powered Framework for Robust and Generalizable Data Selection</h3>
<ul>
<li><strong>Authors: </strong>Suorong Yang, Peng Ye, Wanli Ouyang, Dongzhan Zhou, Furao Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11215">https://arxiv.org/abs/2410.11215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11215">https://arxiv.org/pdf/2410.11215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11215]] A CLIP-Powered Framework for Robust and Generalizable Data Selection(https://arxiv.org/abs/2410.11215)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large-scale datasets have been pivotal to the advancements of deep learning models in recent years, but training on such large datasets invariably incurs substantial storage and computational overhead. Meanwhile, real-world datasets often contain redundant and noisy data, imposing a negative impact on training efficiency and model performance. Data selection has shown promise in identifying the most representative samples from the entire dataset, which aims to minimize the performance gap with reduced training costs. Existing works typically rely on single-modality information to assign importance scores for individual samples, which may lead to inaccurate assessments, especially when dealing with noisy or corrupted samples. To address this limitation, we propose a novel CLIP-powered data selection framework that leverages multimodal information for more robust and generalizable sample selection. Specifically, our framework consists of three key modules-dataset adaptation, sample scoring, and selection optimization-that together harness extensive pre-trained multimodal knowledge to comprehensively assess sample influence and optimize the selection results through multi-objective optimization. Extensive experiments demonstrate that our approach consistently outperforms existing state-of-the-art baselines on various benchmark datasets. Notably, our method effectively removes noisy or damaged samples from the dataset, enabling it to achieve even higher performance with less data. This indicates that it is not only a way to accelerate training but can also improve overall data quality.</li>
</ul>

<h3>Title: On the Capacity of Citation Generation by Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haosheng Qian, Yixing Fan, Ruqing Zhang, Jiafeng Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11217">https://arxiv.org/abs/2410.11217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11217">https://arxiv.org/pdf/2410.11217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11217]] On the Capacity of Citation Generation by Large Language Models(https://arxiv.org/abs/2410.11217)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) appears as a promising method to alleviate the "hallucination" problem in large language models (LLMs), since it can incorporate external traceable resources for response generation. The essence of RAG in combating the hallucination issue lies in accurately attributing claims in responses to the corresponding retrieved documents. However, most of existing works focus on improving the quality of generated responses from the LLM, while largely overlooked its ability to attribute sources accurately. In this study, we conduct a systematic analysis about the capabilities of LLMs in generating citations within response generation, and further introduce a novel method to enhance their citation generation abilities. Specifically, we evaluate both the correctness and citation quality for seven widely-used LLMs on two benchmark datasets. Meanwhile, we introduce new citation evaluation metrics to eliminate the over-penalization of unnecessary and excessive citations in existing metrics. Furthermore, we propose a Generate-then-Refine method that completes relevant citations and removes irrelevant ones without altering the response text. The results on WebGLM-QA, ASQA and ELI5 datasets show that our method substantially improves the quality of citations in responses generated by LLMs.</li>
</ul>

<h3>Title: MF-LAL: Drug Compound Generation Using Multi-Fidelity Latent Space Active Learning</h3>
<ul>
<li><strong>Authors: </strong>Peter Eckmann, Dongxia Wu, Germano Heinzelmann, Michael K Gilson, Rose Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11226">https://arxiv.org/abs/2410.11226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11226">https://arxiv.org/pdf/2410.11226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11226]] MF-LAL: Drug Compound Generation Using Multi-Fidelity Latent Space Active Learning(https://arxiv.org/abs/2410.11226)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Current generative models for drug discovery primarily use molecular docking as an oracle to guide the generation of active compounds. However, such models are often not useful in practice because even compounds with high docking scores do not consistently show experimental activity. More accurate methods for activity prediction exist, such as molecular dynamics based binding free energy calculations, but they are too computationally expensive to use in a generative model. To address this challenge, we propose Multi-Fidelity Latent space Active Learning (MF-LAL), a generative modeling framework that integrates a set of oracles with varying cost-accuracy tradeoffs. Unlike previous approaches that separately learn the surrogate model and generative model, MF-LAL combines the generative and multi-fidelity surrogate models into a single framework, allowing for more accurate activity prediction and higher quality samples. We train MF-LAL with a novel active learning algorithm to further reduce computational cost. Our experiments on two disease-relevant proteins show that MF-LAL produces compounds with significantly better binding free energy scores than other single and multi-fidelity approaches.</li>
</ul>

<h3>Title: "Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection</h3>
<ul>
<li><strong>Authors: </strong>Fai Leui Chan, Duke Nguyen, Aditya Joshi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11230">https://arxiv.org/abs/2410.11230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11230">https://arxiv.org/pdf/2410.11230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11230]] "Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection(https://arxiv.org/abs/2410.11230)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the challenges of detecting LGBTQIA+ hate speech of large language models across multiple languages, including English, Italian, Chinese and (code-switched) English-Tamil, examining the impact of machine translation and whether the nuances of hate speech are preserved across translation. We examine the hate speech detection ability of zero-shot and fine-tuned GPT. Our findings indicate that: (1) English has the highest performance and the code-switching scenario of English-Tamil being the lowest, (2) fine-tuning improves performance consistently across languages whilst translation yields mixed results. Through simple experimentation with original text and machine-translated text for hate speech detection along with a qualitative error analysis, this paper sheds light on the socio-cultural nuances and complexities of languages that may not be captured by automatic translation.</li>
</ul>

<h3>Title: Representation Similarity: A Better Guidance of DNN Layer Sharing for Edge Computing without Training</h3>
<ul>
<li><strong>Authors: </strong>Bryan Bo Cao, Abhinav Sharma, Manavjeet Singh, Anshul Gandhi, Samir Das, Shubham Jain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11233">https://arxiv.org/abs/2410.11233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11233">https://arxiv.org/pdf/2410.11233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11233]] Representation Similarity: A Better Guidance of DNN Layer Sharing for Edge Computing without Training(https://arxiv.org/abs/2410.11233)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Edge computing has emerged as an alternative to reduce transmission and processing delay and preserve privacy of the video streams. However, the ever-increasing complexity of Deep Neural Networks (DNNs) used in video-based applications (e.g. object detection) exerts pressure on memory-constrained edge devices. Model merging is proposed to reduce the DNNs' memory footprint by keeping only one copy of merged layers' weights in memory. In existing model merging techniques, (i) only architecturally identical layers can be shared; (ii) requires computationally expensive retraining in the cloud; (iii) assumes the availability of ground truth for retraining. The re-evaluation of a merged model's performance, however, requires a validation dataset with ground truth, typically runs at the cloud. Common metrics to guide the selection of shared layers include the size or computational cost of shared layers or representation size. We propose a new model merging scheme by sharing representations (i.e., outputs of layers) at the edge, guided by representation similarity S. We show that S is extremely highly correlated with merged model's accuracy with Pearson Correlation Coefficient |r| > 0.94 than other metrics, demonstrating that representation similarity can serve as a strong validation accuracy indicator without ground truth. We present our preliminary results of the newly proposed model merging scheme with identified challenges, demonstrating a promising research future direction.</li>
</ul>

<h3>Title: Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Lin, Kun Qian, Haoyu Han, Nurendra Choudhary, Tianxin Wei, Zhongruo Wang, Sahika Genc, Edward W Huang, Sheng Wang, Karthik Subbian, Danai Koutra, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11235">https://arxiv.org/abs/2410.11235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11235">https://arxiv.org/pdf/2410.11235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11235]] Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data(https://arxiv.org/abs/2410.11235)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Graph-structured information offers rich contextual information that can enhance language models by providing structured relationships and hierarchies, leading to more expressive embeddings for various applications such as retrieval, question answering, and classification. However, existing methods for integrating graph and text embeddings, often based on Multi-layer Perceptrons (MLPs) or shallow transformers, are limited in their ability to fully exploit the heterogeneous nature of these modalities. To overcome this, we propose Janus, a simple yet effective framework that leverages Large Language Models (LLMs) to jointly encode text and graph data. Specifically, Janus employs an MLP adapter to project graph embeddings into the same space as text embeddings, allowing the LLM to process both modalities jointly. Unlike prior work, we also introduce contrastive learning to align the graph and text spaces more effectively, thereby improving the quality of learned joint embeddings. Empirical results across six datasets spanning three tasks, knowledge graph-contextualized question answering, graph-text pair classification, and retrieval, demonstrate that Janus consistently outperforms existing baselines, achieving significant improvements across multiple datasets, with gains of up to 11.4% in QA tasks. These results highlight Janus's effectiveness in integrating graph and text data. Ablation studies further validate the effectiveness of our method.</li>
</ul>

<h3>Title: Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling</h3>
<ul>
<li><strong>Authors: </strong>Guiyu Zhang, Huan-ang Gao, Zijian Jiang, Hao Zhao, Zhedong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11236">https://arxiv.org/abs/2410.11236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11236">https://arxiv.org/pdf/2410.11236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11236]] Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling(https://arxiv.org/abs/2410.11236)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we focus on the task of conditional image generation, where an image is synthesized according to user instructions. The critical challenge underpinning this task is ensuring both the fidelity of the generated images and their semantic alignment with the provided conditions. To tackle this issue, previous studies have employed supervised perceptual losses derived from pre-trained models, i.e., reward models, to enforce alignment between the condition and the generated result. However, we observe one inherent shortcoming: considering the diversity of synthesized images, the reward model usually provides inaccurate feedback when encountering newly generated data, which can undermine the training process. To address this limitation, we propose an uncertainty-aware reward modeling, called Ctrl-U, including uncertainty estimation and uncertainty-aware regularization, designed to reduce the adverse effects of imprecise feedback from the reward model. Given the inherent cognitive uncertainty within reward models, even images generated under identical conditions often result in a relatively large discrepancy in reward loss. Inspired by the observation, we explicitly leverage such prediction variance as an uncertainty indicator. Based on the uncertainty estimation, we regularize the model training by adaptively rectifying the reward. In particular, rewards with lower uncertainty receive higher loss weights, while those with higher uncertainty are given reduced weights to allow for larger variability. The proposed uncertainty regularization facilitates reward fine-tuning through consistency construction. Extensive experiments validate the effectiveness of our methodology in improving the controllability and generation quality, as well as its scalability across diverse conditional scenarios. Code will soon be available at this https URL.</li>
</ul>

<h3>Title: HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications</h3>
<ul>
<li><strong>Authors: </strong>Weijie Xu, Jay Desai, Fanyou Wu, Josef Valvoda, Srinivasan H. Sengamedu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11239">https://arxiv.org/abs/2410.11239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11239">https://arxiv.org/pdf/2410.11239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11239]] HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications(https://arxiv.org/abs/2410.11239)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent LLM (Large Language Models) advancements benefit many fields such as education and finance, but HR has hundreds of repetitive processes, such as access requests, medical claim filing and time-off submissions, which are unaddressed. We relate these tasks to the LLM agent, which has addressed tasks such as writing assisting and customer support. We present HR-Agent, an efficient, confidential, and HR-specific LLM-based task-oriented dialogue system tailored for automating repetitive HR processes such as medical claims and access requests. Since conversation data is not sent to an LLM during inference, it preserves confidentiality required in HR-related tasks.</li>
</ul>

<h3>Title: Learning Diffusion Model from Noisy Measurement using Principled Expectation-Maximization Method</h3>
<ul>
<li><strong>Authors: </strong>Weimin Bai, Weiheng Tang, Enze Ye, Siyi Chen, Wenzheng Chen, He Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11241">https://arxiv.org/abs/2410.11241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11241">https://arxiv.org/pdf/2410.11241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11241]] Learning Diffusion Model from Noisy Measurement using Principled Expectation-Maximization Method(https://arxiv.org/abs/2410.11241)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated exceptional ability in modeling complex image distributions, making them versatile plug-and-play priors for solving imaging inverse problems. However, their reliance on large-scale clean datasets for training limits their applicability in scenarios where acquiring clean data is costly or impractical. Recent approaches have attempted to learn diffusion models directly from corrupted measurements, but these methods either lack theoretical convergence guarantees or are restricted to specific types of data corruption. In this paper, we propose a principled expectation-maximization (EM) framework that iteratively learns diffusion models from noisy data with arbitrary corruption types. Our framework employs a plug-and-play Monte Carlo method to accurately estimate clean images from noisy measurements, followed by training the diffusion model using the reconstructed images. This process alternates between estimation and training until convergence. We evaluate the performance of our method across various imaging tasks, including inpainting, denoising, and deblurring. Experimental results demonstrate that our approach enables the learning of high-fidelity diffusion priors from noisy data, significantly enhancing reconstruction quality in imaging inverse problems.</li>
</ul>

<h3>Title: Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhongye Liu, Hongbin Liu, Yuepeng Hu, Zedian Shao, Neil Zhenqiang Gong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11242">https://arxiv.org/abs/2410.11242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11242">https://arxiv.org/pdf/2410.11242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11242]] Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models(https://arxiv.org/abs/2410.11242)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual hallucination (VH) occurs when a multimodal large language model (MLLM) generates responses with incorrect visual details for prompts. Existing methods for generating VH test cases primarily rely on human annotations, typically in the form of triples: (image, question, answer). In this paper, we introduce VHExpansion, the first automated method for expanding VH test cases for MLLMs. Given an initial VH test case, VHExpansion automatically expands it by perturbing the question and answer through negation as well as modifying the image using both common and adversarial perturbations. Additionally, we propose a new evaluation metric, symmetric accuracy, which measures the proportion of correctly answered VH test-case pairs. Each pair consists of a test case and its negated counterpart. Our theoretical analysis shows that symmetric accuracy is an unbiased evaluation metric that remains unaffected by the imbalance of VH testing cases with varying answers when an MLLM is randomly guessing the answers, whereas traditional accuracy is prone to such imbalance. We apply VHExpansion to expand three VH datasets annotated manually and use these expanded datasets to benchmark seven MLLMs. Our evaluation shows that VHExpansion effectively identifies more VH test cases. Moreover, symmetric accuracy, being unbiased, leads to different conclusions about the vulnerability of MLLMs to VH compared to traditional accuracy metric. Finally, we show that fine-tuning MLLMs on the expanded VH dataset generated by VHExpansion mitigates VH more effectively than fine-tuning on the original, manually annotated dataset. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Rethinking the Role of Infrastructure in Collaborative Perception</h3>
<ul>
<li><strong>Authors: </strong>Hyunchul Bae, Minhee Kang, Minwoo Song, Heejin Ahn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11259">https://arxiv.org/abs/2410.11259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11259">https://arxiv.org/pdf/2410.11259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11259]] Rethinking the Role of Infrastructure in Collaborative Perception(https://arxiv.org/abs/2410.11259)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Collaborative Perception (CP) is a process in which an ego agent receives and fuses sensor information from surrounding vehicles and infrastructure to enhance its perception capability. To evaluate the need for infrastructure equipped with sensors, extensive and quantitative analysis of the role of infrastructure data in CP is crucial, yet remains underexplored. To address this gap, we first quantitatively assess the importance of infrastructure data in existing vehicle-centric CP, where the ego agent is a vehicle. Furthermore, we compare vehicle-centric CP with infra-centric CP, where the ego agent is now the infrastructure, to evaluate the effectiveness of each approach. Our results demonstrate that incorporating infrastructure data improves 3D detection accuracy by up to 10.87%, and infra-centric CP shows enhanced noise robustness and increases accuracy by up to 42.53% compared with vehicle-centric CP.</li>
</ul>

<h3>Title: Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix</h3>
<ul>
<li><strong>Authors: </strong>Yingyu Liang, Jiangxuan Long, Zhenmei Shi, Zhao Song, Yufa Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11261">https://arxiv.org/abs/2410.11261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11261">https://arxiv.org/pdf/2410.11261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11261]] Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix(https://arxiv.org/abs/2410.11261)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown immense potential in enhancing various aspects of our daily lives, from conversational AI to search and AI assistants. However, their growing capabilities come at the cost of extremely large model sizes, making deployment on edge devices challenging due to memory and computational constraints. This paper introduces a novel approach to LLM weight pruning that directly optimizes for approximating the attention matrix, a core component of transformer architectures. Unlike existing methods that focus on linear approximations, our approach accounts for the non-linear nature of the Softmax attention mechanism. We provide theoretical guarantees for the convergence of our Gradient Descent-based optimization method to a near-optimal pruning mask solution. Our preliminary empirical results demonstrate the effectiveness of this approach in maintaining model performance while significantly reducing computational costs. This work establishes a new theoretical foundation for pruning algorithm design in LLMs, potentially paving the way for more efficient LLM inference on resource-constrained devices.</li>
</ul>

<h3>Title: In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions</h3>
<ul>
<li><strong>Authors: </strong>Alireza Shamshiri, Kyeong Rok Ryu, June Young Park</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11265">https://arxiv.org/abs/2410.11265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11265">https://arxiv.org/pdf/2410.11265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11265]] In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions(https://arxiv.org/abs/2410.11265)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved impressive results across various tasks. However, they still struggle with long-context documents. This study evaluates the performance of three leading LLMs: GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro on lengthy, complex, and opinion-varying documents concerning infrastructure projects, under both zero-shot and few-shot scenarios. Our results indicate that GPT-4o excels in zero-shot scenarios for simpler, shorter documents, while Claude 3.5 Sonnet surpasses GPT-4o in handling more complex, sentiment-fluctuating opinions. In few-shot scenarios, Claude 3.5 Sonnet outperforms overall, while GPT-4o shows greater stability as the number of demonstrations increases.</li>
</ul>

<h3>Title: FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinpeng Wang, Xiaoying Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11267">https://arxiv.org/abs/2410.11267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11267">https://arxiv.org/pdf/2410.11267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11267]] FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning(https://arxiv.org/abs/2410.11267)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Domain Generalization (DG) aims to train models that can effectively generalize to unseen domains. However, in the context of Federated Learning (FL), where clients collaboratively train a model without directly sharing their data, most existing DG algorithms are not directly applicable to the FL setting due to privacy constraints, as well as the limited data quantity and domain diversity at each client. To tackle these challenges, we propose FedCCRL, a novel federated domain generalization method that significantly improves the model's ability to generalize to unseen domains without compromising privacy or incurring excessive computational and communication costs. Specifically, we adapt MixStyle to the federated setting to transfer domain-specific features while AugMix is employed to perturb domain-invariant features. Furthermore, we leverage supervised contrastive loss for representation alignment and utilize Jensen-Shannon divergence to ensure consistent predictions between original and augmented samples. Extensive experimental results demonstrate that FedCCRL achieves the state-of-the-art performances on the PACS, OfficeHome and miniDomainNet datasets across varying numbers of clients. Code is available at this https URL.</li>
</ul>

<h3>Title: Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Bo Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11268">https://arxiv.org/abs/2410.11268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11268">https://arxiv.org/pdf/2410.11268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11268]] Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent(https://arxiv.org/abs/2410.11268)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In-context learning has been recognized as a key factor in the success of Large Language Models (LLMs). It refers to the model's ability to learn patterns on the fly from provided in-context examples in the prompt during inference. Previous studies have demonstrated that the Transformer architecture used in LLMs can implement a single-step gradient descent update by processing in-context examples in a single forward pass. Recent work has further shown that, during in-context learning, a looped Transformer can implement multi-step gradient descent updates in forward passes. However, their theoretical results require an exponential number of in-context examples, $n = \exp(\Omega(T))$, where $T$ is the number of loops or passes, to achieve a reasonably low error. In this paper, we study linear looped Transformers in-context learning on linear vector generation tasks. We show that linear looped Transformers can implement multi-step gradient descent efficiently for in-context learning. Our results demonstrate that as long as the input data has a constant condition number, e.g., $n = O(d)$, the linear looped Transformers can achieve a small error by multi-step gradient descent during in-context learning. Furthermore, our preliminary experiments validate our theoretical analysis. Our findings reveal that the Transformer architecture possesses a stronger in-context learning capability than previously understood, offering new insights into the mechanisms behind LLMs and potentially guiding the better design of efficient inference algorithms for LLMs.</li>
</ul>

<h3>Title: Reducing Source-Private Bias in Extreme Universal Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Hung-Chieh Fang, Po-Yi Lu, Hsuan-Tien Lin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11271">https://arxiv.org/abs/2410.11271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11271">https://arxiv.org/pdf/2410.11271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11271]] Reducing Source-Private Bias in Extreme Universal Domain Adaptation(https://arxiv.org/abs/2410.11271)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Universal Domain Adaptation (UniDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain without assuming how much the label-sets of the two domains intersect. The goal of UniDA is to achieve robust performance on the target domain across different intersection levels. However, existing literature has not sufficiently explored performance under extreme intersection levels. Our experiments reveal that state-of-the-art methods struggle when the source domain has significantly more non-overlapping classes than overlapping ones, a setting we refer to as Extreme UniDA. In this paper, we demonstrate that classical partial domain alignment, which focuses on aligning only overlapping-class data between domains, is limited in mitigating the bias of feature extractors toward source-private classes in extreme UniDA scenarios. We argue that feature extractors trained with source supervised loss distort the intrinsic structure of the target data due to the inherent differences between source-private classes and the target data. To mitigate this bias, we propose using self-supervised learning to preserve the structure of the target data. Our approach can be easily integrated into existing frameworks. We apply the proposed approach to two distinct training paradigms-adversarial-based and optimal-transport-based-and show consistent improvements across various intersection levels, with significant gains in extreme UniDA settings.</li>
</ul>

<h3>Title: Cognitive Overload Attack:Prompt Injection for Long Context</h3>
<ul>
<li><strong>Authors: </strong>Bibek Upadhayay, Vahid Behzadan, Amin Karbasi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11272">https://arxiv.org/abs/2410.11272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11272">https://arxiv.org/pdf/2410.11272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11272]] Cognitive Overload Attack:Prompt Injection for Long Context(https://arxiv.org/abs/2410.11272)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in performing tasks across various domains without needing explicit retraining. This capability, known as In-Context Learning (ICL), while impressive, exposes LLMs to a variety of adversarial prompts and jailbreaks that manipulate safety-trained LLMs into generating undesired or harmful output. In this paper, we propose a novel interpretation of ICL in LLMs through the lens of cognitive neuroscience, by drawing parallels between learning in human cognition with ICL. We applied the principles of Cognitive Load Theory in LLMs and empirically validate that similar to human cognition, LLMs also suffer from cognitive overload a state where the demand on cognitive processing exceeds the available capacity of the model, leading to potential errors. Furthermore, we demonstrated how an attacker can exploit ICL to jailbreak LLMs through deliberately designed prompts that induce cognitive overload on LLMs, thereby compromising the safety mechanisms of LLMs. We empirically validate this threat model by crafting various cognitive overload prompts and show that advanced models such as GPT-4, Claude-3.5 Sonnet, Claude-3 OPUS, Llama-3-70B-Instruct, Gemini-1.0-Pro, and Gemini-1.5-Pro can be successfully jailbroken, with attack success rates of up to 99.99%. Our findings highlight critical vulnerabilities in LLMs and underscore the urgency of developing robust safeguards. We propose integrating insights from cognitive load theory into the design and evaluation of LLMs to better anticipate and mitigate the risks of adversarial attacks. By expanding our experiments to encompass a broader range of models and by highlighting vulnerabilities in LLMs' ICL, we aim to ensure the development of safer and more reliable AI systems.</li>
</ul>

<h3>Title: Shallow diffusion networks provably learn hidden low-dimensional structure</h3>
<ul>
<li><strong>Authors: </strong>Nicholas M. Boffi, Arthur Jacot, Stephen Tu, Ingvar Ziemann</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11275">https://arxiv.org/abs/2410.11275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11275">https://arxiv.org/pdf/2410.11275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11275]] Shallow diffusion networks provably learn hidden low-dimensional structure(https://arxiv.org/abs/2410.11275)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion-based generative models provide a powerful framework for learning to sample from a complex target distribution. The remarkable empirical success of these models applied to high-dimensional signals, including images and video, stands in stark contrast to classical results highlighting the curse of dimensionality for distribution recovery. In this work, we take a step towards understanding this gap through a careful analysis of learning diffusion models over the Barron space of single layer neural networks. In particular, we show that these shallow models provably adapt to simple forms of low dimensional structure, thereby avoiding the curse of dimensionality. We combine our results with recent analyses of sampling with diffusion models to provide an end-to-end sample complexity bound for learning to sample from structured distributions. Importantly, our results do not require specialized architectures tailored to particular latent structures, and instead rely on the low-index structure of the Barron space to adapt to the underlying distribution.</li>
</ul>

<h3>Title: ILAEDA: An Imitation Learning Based Approach for Automatic Exploratory Data Analysis</h3>
<ul>
<li><strong>Authors: </strong>Abhijit Manatkar, Devarsh Patel, Hima Patel, Naresh Manwani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11276">https://arxiv.org/abs/2410.11276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11276">https://arxiv.org/pdf/2410.11276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11276]] ILAEDA: An Imitation Learning Based Approach for Automatic Exploratory Data Analysis(https://arxiv.org/abs/2410.11276)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Automating end-to-end Exploratory Data Analysis (AutoEDA) is a challenging open problem, often tackled through Reinforcement Learning (RL) by learning to predict a sequence of analysis operations (FILTER, GROUP, etc). Defining rewards for each operation is a challenging task and existing methods rely on various \emph{interestingness measures} to craft reward functions to capture the importance of each operation. In this work, we argue that not all of the essential features of what makes an operation important can be accurately captured mathematically using rewards. We propose an AutoEDA model trained through imitation learning from expert EDA sessions, bypassing the need for manually defined interestingness measures. Our method, based on generative adversarial imitation learning (GAIL), generalizes well across datasets, even with limited expert data. We also introduce a novel approach for generating synthetic EDA demonstrations for training. Our method outperforms the existing state-of-the-art end-to-end EDA approach on benchmarks by upto 3x, showing strong performance and generalization, while naturally capturing diverse interestingness measures in generated EDA sessions.</li>
</ul>

<h3>Title: UmambaTSF: A U-shaped Multi-Scale Long-Term Time Series Forecasting Method Using Mamba</h3>
<ul>
<li><strong>Authors: </strong>Li Wu, Wenbin Pei, Jiulong Jiao, Qiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11278">https://arxiv.org/abs/2410.11278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11278">https://arxiv.org/pdf/2410.11278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11278]] UmambaTSF: A U-shaped Multi-Scale Long-Term Time Series Forecasting Method Using Mamba(https://arxiv.org/abs/2410.11278)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Multivariate Time series forecasting is crucial in domains such as transportation, meteorology, and finance, especially for predicting extreme weather events. State-of-the-art methods predominantly rely on Transformer architectures, which utilize attention mechanisms to capture temporal dependencies. However, these methods are hindered by quadratic time complexity, limiting the model's scalability with respect to input sequence length. This significantly restricts their practicality in the real world. Mamba, based on state space models (SSM), provides a solution with linear time complexity, increasing the potential for efficient forecasting of sequential data. In this study, we propose UmambaTSF, a novel long-term time series forecasting framework that integrates multi-scale feature extraction capabilities of U-shaped encoder-decoder multilayer perceptrons (MLP) with Mamba's long sequence representation. To improve performance and efficiency, the Mamba blocks introduced in the framework adopt a refined residual structure and adaptable design, enabling the capture of unique temporal signals and flexible channel processing. In the experiments, UmambaTSF achieves state-of-the-art performance and excellent generality on widely used benchmark datasets while maintaining linear time complexity and low memory consumption.</li>
</ul>

<h3>Title: Advancing the Understanding of Fixed Point Iterations in Deep Neural Networks: A Detailed Analytical Study</h3>
<ul>
<li><strong>Authors: </strong>Yekun Ke, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11279">https://arxiv.org/abs/2410.11279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11279">https://arxiv.org/pdf/2410.11279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11279]] Advancing the Understanding of Fixed Point Iterations in Deep Neural Networks: A Detailed Analytical Study(https://arxiv.org/abs/2410.11279)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent empirical studies have identified fixed point iteration phenomena in deep neural networks, where the hidden state tends to stabilize after several layers, showing minimal change in subsequent layers. This observation has spurred the development of practical methodologies, such as accelerating inference by bypassing certain layers once the hidden state stabilizes, selectively fine-tuning layers to modify the iteration process, and implementing loops of specific layers to maintain fixed point iterations. Despite these advancements, the understanding of fixed point iterations remains superficial, particularly in high-dimensional spaces, due to the inadequacy of current analytical tools. In this study, we conduct a detailed analysis of fixed point iterations in a vector-valued function modeled by neural networks. We establish a sufficient condition for the existence of multiple fixed points of looped neural networks based on varying input regions. Additionally, we expand our examination to include a robust version of fixed point iterations. To demonstrate the effectiveness and insights provided by our approach, we provide case studies that looped neural networks may exist $2^d$ number of robust fixed points under exponentiation or polynomial activation functions, where $d$ is the feature dimension. Furthermore, our preliminary empirical results support our theoretical findings. Our methodology enriches the toolkit available for analyzing fixed point iterations of deep neural networks and may enhance our comprehension of neural network mechanisms.</li>
</ul>

<h3>Title: AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment</h3>
<ul>
<li><strong>Authors: </strong>Pankayaraj Pathmanathan, Udari Madhushani Sehwag, Michael-Andrei Panaitescu-Liess, Furong Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11283">https://arxiv.org/abs/2410.11283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11283">https://arxiv.org/pdf/2410.11283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11283]] AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment(https://arxiv.org/abs/2410.11283)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, steal, generative, large language model</a></li>
<li><strong>Abstract: </strong>With the growing adoption of reinforcement learning with human feedback (RLHF) for aligning large language models (LLMs), the risk of backdoor installation during alignment has increased, leading to unintended and harmful behaviors. Existing backdoor triggers are typically limited to fixed word patterns, making them detectable during data cleaning and easily removable post-poisoning. In this work, we explore the use of prompt-specific paraphrases as backdoor triggers, enhancing their stealth and resistance to removal during LLM alignment. We propose AdvBDGen, an adversarially fortified generative fine-tuning framework that automatically generates prompt-specific backdoors that are effective, stealthy, and transferable across models. AdvBDGen employs a generator-discriminator pair, fortified by an adversary, to ensure the installability and stealthiness of backdoors. It enables the crafting and successful installation of complex triggers using as little as 3% of the fine-tuning data. Once installed, these backdoors can jailbreak LLMs during inference, demonstrate improved stability against perturbations compared to traditional constant triggers, and are more challenging to remove. These findings underscore an urgent need for the research community to develop more robust defenses against adversarial backdoor threats in LLM alignment.</li>
</ul>

<h3>Title: Subspace Optimization for Large Language Models with Convergence Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Yutong He, Pengrui Li, Yipeng Hu, Chuyan Chen, Kun Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11289">https://arxiv.org/abs/2410.11289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11289">https://arxiv.org/pdf/2410.11289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11289]] Subspace Optimization for Large Language Models with Convergence Guarantees(https://arxiv.org/abs/2410.11289)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Subspace optimization algorithms, with GaLore (Zhao et al., 2024) as a representative method, have gained popularity for pre-training or fine-tuning large language models (LLMs) due to their memory efficiency. However, their convergence guarantees remain unclear, particularly in stochastic settings. In this paper, we unexpectedly discover that GaLore does not always converge to the optimal solution and substantiate this finding with an explicit counterexample. We then investigate the conditions under which GaLore can achieve convergence, demonstrating that it does so either in deterministic scenarios or when using a sufficiently large mini-batch size. More significantly, we introduce GoLore (Gradient random Low-rank projection), a novel variant of GaLore that provably converges in stochastic settings, even with standard batch sizes. Our convergence analysis can be readily extended to other sparse subspace optimization algorithms. Finally, we conduct numerical experiments to validate our theoretical results and empirically explore the proposed mechanisms. Codes are available at this https URL.</li>
</ul>

<h3>Title: Backdoor Attack on Vertical Federated Graph Neural Network Learning</h3>
<ul>
<li><strong>Authors: </strong>Jirui Yang, Peng Chen, Zhihui Lu, Ruijun Deng, Qiang Duan, Jianping Zeng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11290">https://arxiv.org/abs/2410.11290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11290">https://arxiv.org/pdf/2410.11290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11290]] Backdoor Attack on Vertical Federated Graph Neural Network Learning(https://arxiv.org/abs/2410.11290)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Graph Neural Network (FedGNN) is a privacy-preserving machine learning technology that combines federated learning (FL) and graph neural networks (GNNs). It offers a privacy-preserving solution for training GNNs using isolated graph data. Vertical Federated Graph Neural Network (VFGNN) is an important branch of FedGNN, where data features and labels are distributed among participants, and each participant has the same sample space. Due to the difficulty of accessing and modifying distributed data and labels, the vulnerability of VFGNN to backdoor attacks remains largely unexplored. In this context, we propose BVG, the first method for backdoor attacks in VFGNN. Without accessing or modifying labels, BVG uses multi-hop triggers and requires only four target class nodes for an effective backdoor attack. Experiments show that BVG achieves high attack success rates (ASR) across three datasets and three different GNN models, with minimal impact on main task accuracy (MTA). We also evaluate several defense methods, further validating the robustness and effectiveness of BVG. This finding also highlights the need for advanced defense mechanisms to counter sophisticated backdoor attacks in practical VFGNN applications.</li>
</ul>

<h3>Title: TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Jinjae Kim, Minjeong Ma, Eunjee Choi, Keunhee Cho, Chanwoo Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11293">https://arxiv.org/abs/2410.11293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11293">https://arxiv.org/pdf/2410.11293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11293]] TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles(https://arxiv.org/abs/2410.11293)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents a novel approach that leverages Transformer-based multivariate time series model and Machine Learning Ensembles to predict the quality of human sleep, emotional states, and stress levels. A formula to calculate the labels was developed, and the various models were applied to user data. Time Series Transformer was used for labels where time series characteristics are crucial, while Machine Learning Ensembles were employed for labels requiring comprehensive daily activity statistics. Time Series Transformer excels in capturing the characteristics of time series through pre-training, while Machine Learning Ensembles select machine learning models that meet our categorization criteria. The proposed model, TraM, scored 6.10 out of 10 in experiments, demonstrating superior performance compared to other methodologies. The code and configuration for the TraM framework are available at: this https URL.</li>
</ul>

<h3>Title: BRC20 Pinning Attack</h3>
<ul>
<li><strong>Authors: </strong>Minfeng Qi, Qin Wang, Zhipeng Wang, Lin Zhong, Tianqing Zhu, Shiping Chen, William Knottenbelt</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11295">https://arxiv.org/abs/2410.11295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11295">https://arxiv.org/pdf/2410.11295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11295]] BRC20 Pinning Attack(https://arxiv.org/abs/2410.11295)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>BRC20 tokens are a type of non-fungible asset on the Bitcoin network. They allow users to embed customized content within Bitcoin satoshis. The related token frenzy has reached a market size of USD 3,650b over the past year (2023Q3-2024Q3). However, this intuitive design has not undergone serious security scrutiny. We present the first in-depth analysis of the BRC20 transfer mechanism and identify a critical attack vector. A typical BRC20 transfer involves two bundled on-chain transactions with different fee levels: the first (i.e., Tx1) with a lower fee inscribes the transfer request, while the second (i.e., Tx2) with a higher fee finalizes the actual transfer. We find that an adversary can exploit this by sending a manipulated fee transaction (falling between the two fee levels), which allows Tx1 to be processed while Tx2 remains pinned in the mempool. This locks the BRC20 liquidity and disrupts normal transfers for users. We term this BRC20 pinning attack. Our attack exposes an inherent design flaw that can be applied to 90+% inscription-based tokens within the Bitcoin ecosystem. We also conducted the attack on Binance's ORDI hot wallet (the most prevalent BRC20 token and the most active wallet), resulting in a temporary suspension of ORDI withdrawals on Binance for 3.5 hours, which were shortly resumed after our communication.</li>
</ul>

<h3>Title: QSpec: Speculative Decoding with Complementary Quantization Schemes</h3>
<ul>
<li><strong>Authors: </strong>Juntao Zhao, Wenhao Lu, Sheng Wang, Lingpeng Kong, Chuan Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11305">https://arxiv.org/abs/2410.11305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11305">https://arxiv.org/pdf/2410.11305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11305]] QSpec: Speculative Decoding with Complementary Quantization Schemes(https://arxiv.org/abs/2410.11305)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantization has been substantially adopted to accelerate inference and reduce memory consumption of large language models (LLMs). While activation-weight joint quantization speeds up the inference process through low-precision kernels, we demonstrate that it suffers severe performance degradation on multi-step reasoning tasks, rendering it ineffective. We propose a novel quantization paradigm called QSPEC, which seamlessly integrates two complementary quantization schemes for speculative decoding. Leveraging nearly cost-free execution switching, QSPEC drafts tokens with low-precision, fast activation-weight quantization, and verifies them with high-precision weight-only quantization, effectively combining the strengths of both quantization schemes. Compared to high-precision quantization methods, QSPEC empirically boosts token generation throughput by up to 1.80x without any quality compromise, distinguishing it from other low-precision quantization approaches. This enhancement is also consistent across various serving tasks, model sizes, quantization methods, and batch sizes. Unlike existing speculative decoding techniques, our approach reuses weights and the KV cache, avoiding additional memory overhead. Furthermore, QSPEC offers a plug-and-play advantage without requiring any training. We believe that QSPEC demonstrates unique strengths for future deployment of high-fidelity quantization schemes, particularly in memory-constrained scenarios (e.g., edge devices).</li>
</ul>

<h3>Title: CONSULT: Contrastive Self-Supervised Learning for Few-shot Tumor Detection</h3>
<ul>
<li><strong>Authors: </strong>Sin Chee Chin, Xuan Zhang, Lee Yeong Khang, Wenming Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11307">https://arxiv.org/abs/2410.11307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11307">https://arxiv.org/pdf/2410.11307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11307]] CONSULT: Contrastive Self-Supervised Learning for Few-shot Tumor Detection(https://arxiv.org/abs/2410.11307)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Artificial intelligence aids in brain tumor detection via MRI scans, enhancing the accuracy and reducing the workload of medical professionals. However, in scenarios with extremely limited medical images, traditional deep learning approaches tend to fail due to the absence of anomalous images. Anomaly detection also suffers from ineffective feature extraction due to vague training process. Our work introduces a novel two-stage anomaly detection algorithm called CONSULT (CONtrastive Self-sUpervised Learning for few-shot Tumor detection). The first stage of CONSULT fine-tunes a pre-trained feature extractor specifically for MRI brain images, using a synthetic data generation pipeline to create tumor-like data. This process overcomes the lack of anomaly samples and enables the integration of attention mechanisms to focus on anomalous image segments. The first stage is to overcome the shortcomings of current anomaly detection in extracting features in high-variation data by incorporating Context-Aware Contrastive Learning and Self-supervised Feature Adversarial Learning. The second stage of CONSULT uses PatchCore for conventional feature extraction via the fine-tuned weights from the first stage. To summarize, we propose a self-supervised training scheme for anomaly detection, enhancing model performance and data reliability. Furthermore, our proposed contrastive loss, Tritanh Loss, stabilizes learning by offering a unique solution all while enhancing gradient flow. Finally, CONSULT achieves superior performance in few-shot brain tumor detection, demonstrating significant improvements over PatchCore by 9.4%, 12.9%, 10.2%, and 6.0% for 2, 4, 6, and 8 shots, respectively, while training exclusively on healthy images.</li>
</ul>

<h3>Title: SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Xinping Zhao, Dongfang Li, Yan Zhong, Boren Hu, Yibin Chen, Baotian Hu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11315">https://arxiv.org/abs/2410.11315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11315">https://arxiv.org/pdf/2410.11315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11315]] SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation(https://arxiv.org/abs/2410.11315)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recent studies in Retrieval-Augmented Generation (RAG) have investigated extracting evidence from retrieved passages to reduce computational costs and enhance the final RAG performance, yet it remains challenging. Existing methods heavily rely on heuristic-based augmentation, encountering several issues: (1) Poor generalization due to hand-crafted context filtering; (2) Semantics deficiency due to rule-based context chunking; (3) Skewed length due to sentence-wise filter learning. To address these issues, we propose a model-based evidence extraction learning framework, SEER, optimizing a vanilla model as an evidence extractor with desired properties through self-aligned learning. Extensive experiments show that our method largely improves the final RAG performance, enhances the faithfulness, helpfulness, and conciseness of the extracted evidence, and reduces the evidence length by 9.25 times. The code will be available at this https URL.</li>
</ul>

<h3>Title: Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation</h3>
<ul>
<li><strong>Authors: </strong>Qizhang Li, Xiaochen Yang, Wangmeng Zuo, Yiwen Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11317">https://arxiv.org/abs/2410.11317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11317">https://arxiv.org/pdf/2410.11317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11317]] Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation(https://arxiv.org/abs/2410.11317)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Automatic adversarial prompt generation provides remarkable success in jailbreaking safely-aligned large language models (LLMs). Existing gradient-based attacks, while demonstrating outstanding performance in jailbreaking white-box LLMs, often generate garbled adversarial prompts with chaotic appearance. These adversarial prompts are difficult to transfer to other LLMs, hindering their performance in attacking unknown victim models. In this paper, for the first time, we delve into the semantic meaning embedded in garbled adversarial prompts and propose a novel method that "translates" them into coherent and human-readable natural language adversarial prompts. In this way, we can effectively uncover the semantic information that triggers vulnerabilities of the model and unambiguously transfer it to the victim model, without overlooking the adversarial information hidden in the garbled text, to enhance jailbreak attacks. It also offers a new approach to discovering effective designs for jailbreak prompts, advancing the understanding of jailbreak attacks. Experimental results demonstrate that our method significantly improves the success rate of jailbreak attacks against various safety-aligned LLMs and outperforms state-of-the-arts by large margins. With at most 10 queries, our method achieves an average attack success rate of 81.8% in attacking 7 commercial closed-source LLMs, including GPT and Claude-3 series, on HarmBench. Our method also achieves over 90% attack success rates against Llama-2-Chat models on AdvBench, despite their outstanding resistance to jailbreak attacks. Code at: this https URL.</li>
</ul>

<h3>Title: KA-GNN: Kolmogorov-Arnold Graph Neural Networks for Molecular Property Prediction</h3>
<ul>
<li><strong>Authors: </strong>Longlong Li, Yipeng Zhang, Guanghui Wang, Kelin Xia</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11323">https://arxiv.org/abs/2410.11323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11323">https://arxiv.org/pdf/2410.11323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11323]] KA-GNN: Kolmogorov-Arnold Graph Neural Networks for Molecular Property Prediction(https://arxiv.org/abs/2410.11323)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Molecular property prediction is a crucial task in the process of Artificial Intelligence-Driven Drug Discovery (AIDD). The challenge of developing models that surpass traditional non-neural network methods continues to be a vibrant area of research. This paper presents a novel graph neural network model-the Kolmogorov-Arnold Network (KAN)-based Graph Neural Network (KA-GNN), which incorporates Fourier series, specifically designed for molecular property prediction. This model maintains the high interpretability characteristic of KAN methods while being extremely efficient in computational resource usage, making it an ideal choice for deployment in resource-constrained environments. Tested and validated on seven public datasets, KA-GNN has shown significant improvements in property predictions over the existing state-of-the-art (SOTA) benchmarks.</li>
</ul>

<h3>Title: Evolutionary Retrofitting</h3>
<ul>
<li><strong>Authors: </strong>Mathurin Videau (TAU), Mariia Zameshina (LIGM), Alessandro Leite (TAU), Laurent Najman (LIGM), Marc Schoenauer (TAU), Olivier Teytaud (TAU)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11330">https://arxiv.org/abs/2410.11330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11330">https://arxiv.org/pdf/2410.11330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11330]] Evolutionary Retrofitting(https://arxiv.org/abs/2410.11330)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>AfterLearnER (After Learning Evolutionary Retrofitting) consists in applying non-differentiable optimization, including evolutionary methods, to refine fully-trained machine learning models by optimizing a set of carefully chosen parameters or hyperparameters of the model, with respect to some actual, exact, and hence possibly non-differentiable error signal, performed on a subset of the standard validation set. The efficiency of AfterLearnER is demonstrated by tackling non-differentiable signals such as threshold-based criteria in depth sensing, the word error rate in speech re-synthesis, image quality in 3D generative adversarial networks (GANs), image generation via Latent Diffusion Models (LDM), the number of kills per life at Doom, computational accuracy or BLEU in code translation, and human appreciations in image synthesis. In some cases, this retrofitting is performed dynamically at inference time by taking into account user inputs. The advantages of AfterLearnER are its versatility (no gradient is needed), the possibility to use non-differentiable feedback including human evaluations, the limited overfitting, supported by a theoretical study and its anytime behavior. Last but not least, AfterLearnER requires only a minimal amount of feedback, i.e., a few dozens to a few hundreds of scalars, rather than the tens of thousands needed in most related published works. Compared to fine-tuning (typically using the same loss, and gradient-based optimization on a smaller but still big dataset at a fine grain), AfterLearnER uses a minimum amount of data on the real objective function without requiring differentiability.</li>
</ul>

<h3>Title: DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation</h3>
<ul>
<li><strong>Authors: </strong>Jaehyun Park, Yunho Kim, Sejin Kim, Byung-Jun Lee, Sundong Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11338">https://arxiv.org/abs/2410.11338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11338">https://arxiv.org/pdf/2410.11338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11338]] DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation(https://arxiv.org/abs/2410.11338)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We propose a novel offline reinforcement learning (offline RL) approach, introducing the Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation (DIAR) framework. We address two key challenges in offline RL: out-of-distribution samples and long-horizon problems. We leverage diffusion models to learn state-action sequence distributions and incorporate value functions for more balanced and adaptive decision-making. DIAR introduces an Adaptive Revaluation mechanism that dynamically adjusts decision lengths by comparing current and future state values, enabling flexible long-term decision-making. Furthermore, we address Q-value overestimation by combining Q-network learning with a value function guided by a diffusion model. The diffusion model generates diverse latent trajectories, enhancing policy robustness and generalization. As demonstrated in tasks like Maze2D, AntMaze, and Kitchen, DIAR consistently outperforms state-of-the-art algorithms in long-horizon, sparse-reward environments.</li>
</ul>

<h3>Title: RATE: Score Reward Models with Imperfect Rewrites of Rewrites</h3>
<ul>
<li><strong>Authors: </strong>David Reber, Sean Richardson, Todd Nief, Cristina Garbacea, Victor Veitch</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11348">https://arxiv.org/abs/2410.11348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11348">https://arxiv.org/pdf/2410.11348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11348]] RATE: Score Reward Models with Imperfect Rewrites of Rewrites(https://arxiv.org/abs/2410.11348)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper concerns the evaluation of reward models used in language modeling. A reward model is a function that takes a prompt and a response and assigns a score indicating how good that response is for the prompt. A key challenge is that reward models are usually imperfect proxies for actual preferences. For example, we may worry that a model trained to reward helpfulness learns to instead prefer longer responses. In this paper, we develop an evaluation method, RATE (Rewrite-based Attribute Treatment Estimators), that allows us to measure the causal effect of a given attribute of a response (e.g., length) on the reward assigned to that response. The core idea is to use large language models to rewrite responses to produce imperfect counterfactuals, and to adjust for rewriting error by rewriting twice. We show that the RATE estimator is consistent under reasonable assumptions. We demonstrate the effectiveness of RATE on synthetic and real-world data, showing that it can accurately estimate the effect of a given attribute on the reward model.</li>
</ul>

<h3>Title: SeaDATE: Remedy Dual-Attention Transformer with Semantic Alignment via Contrast Learning for Multimodal Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Shuhan Dong, Yunsong Li, Weiying Xie, Jiaqing Zhang, Jiayuan Tian, Danian Yang, Jie Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11358">https://arxiv.org/abs/2410.11358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11358">https://arxiv.org/pdf/2410.11358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11358]] SeaDATE: Remedy Dual-Attention Transformer with Semantic Alignment via Contrast Learning for Multimodal Object Detection(https://arxiv.org/abs/2410.11358)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Multimodal object detection leverages diverse modal information to enhance the accuracy and robustness of detectors. By learning long-term dependencies, Transformer can effectively integrate multimodal features in the feature extraction stage, which greatly improves the performance of multimodal object detection. However, current methods merely stack Transformer-guided fusion techniques without exploring their capability to extract features at various depth layers of network, thus limiting the improvements in detection performance. In this paper, we introduce an accurate and efficient object detection method named SeaDATE. Initially, we propose a novel dual attention Feature Fusion (DTF) module that, under Transformer's guidance, integrates local and global information through a dual attention mechanism, strengthening the fusion of modal features from orthogonal perspectives using spatial and channel tokens. Meanwhile, our theoretical analysis and empirical validation demonstrate that the Transformer-guided fusion method, treating images as sequences of pixels for fusion, performs better on shallow features' detail information compared to deep semantic information. To address this, we designed a contrastive learning (CL) module aimed at learning features of multimodal samples, remedying the shortcomings of Transformer-guided fusion in extracting deep semantic features, and effectively utilizing cross-modal information. Extensive experiments and ablation studies on the FLIR, LLVIP, and M3FD datasets have proven our method to be effective, achieving state-of-the-art detection performance.</li>
</ul>

<h3>Title: DODT: Enhanced Online Decision Transformer Learning through Dreamer's Actor-Critic Trajectory Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Eric Hanchen Jiang, Zhi Zhang, Dinghuai Zhang, Andrew Lizarraga, Chenheng Xu, Yasi Zhang, Siyan Zhao, Zhengjie Xu, Peiyu Yu, Yuer Tang, Deqian Kong, Ying Nian Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11359">https://arxiv.org/abs/2410.11359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11359">https://arxiv.org/pdf/2410.11359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11359]] DODT: Enhanced Online Decision Transformer Learning through Dreamer's Actor-Critic Trajectory Forecasting(https://arxiv.org/abs/2410.11359)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Advancements in reinforcement learning have led to the development of sophisticated models capable of learning complex decision-making tasks. However, efficiently integrating world models with decision transformers remains a challenge. In this paper, we introduce a novel approach that combines the Dreamer algorithm's ability to generate anticipatory trajectories with the adaptive learning strengths of the Online Decision Transformer. Our methodology enables parallel training where Dreamer-produced trajectories enhance the contextual decision-making of the transformer, creating a bidirectional enhancement loop. We empirically demonstrate the efficacy of our approach on a suite of challenging benchmarks, achieving notable improvements in sample efficiency and reward maximization over existing methods. Our results indicate that the proposed integrated framework not only accelerates learning but also showcases robustness in diverse and dynamic scenarios, marking a significant step forward in model-based reinforcement learning.</li>
</ul>

<h3>Title: LargePiG: Your Large Language Model is Secretly a Pointer Generator</h3>
<ul>
<li><strong>Authors: </strong>Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Kai Zheng, Yang Song, Xiao Zhang, Jun Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11366">https://arxiv.org/abs/2410.11366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11366">https://arxiv.org/pdf/2410.11366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11366]] LargePiG: Your Large Language Model is Secretly a Pointer Generator(https://arxiv.org/abs/2410.11366)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent research on query generation has focused on using Large Language Models (LLMs), which despite bringing state-of-the-art performance, also introduce issues with hallucinations in the generated queries. In this work, we introduce relevance hallucination and factuality hallucination as a new typology for hallucination problems brought by query generation based on LLMs. We propose an effective way to separate content from form in LLM-generated queries, which preserves the factual knowledge extracted and integrated from the inputs and compiles the syntactic structure, including function words, using the powerful linguistic capabilities of the LLM. Specifically, we introduce a model-agnostic and training-free method that turns the Large Language Model into a Pointer-Generator (LargePiG), where the pointer attention distribution leverages the LLM's inherent attention weights, and the copy probability is derived from the difference between the vocabulary distribution of the model's high layers and the last layer. To validate the effectiveness of LargePiG, we constructed two datasets for assessing the hallucination problems in query generation, covering both document and video scenarios. Empirical studies on various LLMs demonstrated the superiority of LargePiG on both datasets. Additional experiments also verified that LargePiG could reduce hallucination in large vision language models and improve the accuracy of document-based question-answering and factuality evaluation tasks.</li>
</ul>

<h3>Title: Secure Stateful Aggregation: A Practical Protocol with Applications in Differentially-Private Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Marshall Ball, James Bell-Clark, Adria Gascon, Peter Kairouz, Sewoong Oh, Zhiye Xie</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11368">https://arxiv.org/abs/2410.11368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11368">https://arxiv.org/pdf/2410.11368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11368]] Secure Stateful Aggregation: A Practical Protocol with Applications in Differentially-Private Federated Learning(https://arxiv.org/abs/2410.11368)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Recent advances in differentially private federated learning (DPFL) algorithms have found that using correlated noise across the rounds of federated learning (DP-FTRL) yields provably and empirically better accuracy than using independent noise (DP-SGD). While DP-SGD is well-suited to federated learning with a single untrusted central server using lightweight secure aggregation protocols, secure aggregation is not conducive to implementing modern DP-FTRL techniques without assuming a trusted central server. DP-FTRL based approaches have already seen widespread deployment in industry, albeit with a trusted central curator who provides and applies the correlated noise. To realize a fully private, single untrusted server DP-FTRL federated learning protocol, we introduce secure stateful aggregation: a simple append-only data structure that allows for the private storage of aggregate values and reading linear functions of the aggregates. Assuming Ring Learning with Errors, we provide a lightweight and scalable realization of this protocol for high-dimensional data in a new security/resource model, Federated MPC : where a powerful persistent server interacts with weak, ephemeral clients. We observe that secure stateful aggregation suffices for realizing DP-FTRL-based private federated learning: improving DPFL utility guarantees over the state of the art while maintaining privacy with an untrusted central party. Our approach has minimal overhead relative to existing techniques which do not yield comparable utility. The secure stateful aggregation primitive and the federated MPC paradigm may be of interest for other practical applications.</li>
</ul>

<h3>Title: Enhance Graph Alignment for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haitong Luo, Xuying Meng, Suhang Wang, Tianxiang Zhao, Fali Wang, Hanyun Cao, Yujun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11370">https://arxiv.org/abs/2410.11370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11370">https://arxiv.org/pdf/2410.11370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11370]] Enhance Graph Alignment for Large Language Models(https://arxiv.org/abs/2410.11370)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graph-structured data is prevalent in the real world. Recently, due to the powerful emergent capabilities, Large Language Models (LLMs) have shown promising performance in modeling graphs. The key to effectively applying LLMs on graphs is converting graph data into a format LLMs can comprehend. Graph-to-token approaches are popular in enabling LLMs to process graph information. They transform graphs into sequences of tokens and align them with text tokens through instruction tuning, where self-supervised instruction tuning helps LLMs acquire general knowledge about graphs, and supervised fine-tuning specializes LLMs for the downstream tasks on graphs. Despite their initial success, we find that existing methods have a misalignment between self-supervised tasks and supervised downstream tasks, resulting in negative transfer from self-supervised fine-tuning to downstream tasks. To address these issues, we propose Graph Alignment Large Language Models (GALLM) to benefit from aligned task templates. In the self-supervised tuning stage, we introduce a novel text matching task using templates aligned with downstream tasks. In the task-specific tuning stage, we propose two category prompt methods that learn supervision information from additional explanation with further aligned templates. Experimental evaluations on four datasets demonstrate substantial improvements in supervised learning, multi-dataset generalizability, and particularly in zero-shot capability, highlighting the model's potential as a graph foundation model.</li>
</ul>

<h3>Title: Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL</h3>
<ul>
<li><strong>Authors: </strong>Qihuang Zhong, Kunfeng Chen, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11371">https://arxiv.org/abs/2410.11371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11371">https://arxiv.org/pdf/2410.11371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11371]] Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL(https://arxiv.org/abs/2410.11371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown promising performance in text-to-SQL, which involves translating natural language questions into SQL queries. However, current text-to-SQL LLMs are computationally expensive and challenging to deploy in real-world applications, highlighting the importance of compressing them. To achieve this goal, knowledge distillation (KD) is a common approach, which aims to distill the larger teacher model into a smaller student model. While numerous KD methods for autoregressive LLMs have emerged recently, it is still under-explored whether they work well in complex text-to-SQL scenarios. To this end, we conduct a series of analyses and reveal that these KD methods generally fall short in balancing performance and efficiency. In response to this problem, we propose to improve the KD with Imperfect Data, namely KID, which effectively boosts the performance without introducing much training budget. The core of KID is to efficiently mitigate the training-inference mismatch by simulating the cascading effect of inference in the imperfect training data. Extensive experiments on 5 text-to-SQL benchmarks show that, KID can not only achieve consistent and significant performance gains (up to +5.83% average score) across all model types and sizes, but also effectively improve the training efficiency.</li>
</ul>

<h3>Title: Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Yoonjeon Kim, Soohyun Ryu, Yeonsung Jung, Hyunkoo Lee, Joowon Kim, June Yong Yang, Jaeryong Hwang, Eunho Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11374">https://arxiv.org/abs/2410.11374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11374">https://arxiv.org/pdf/2410.11374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11374]] Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing(https://arxiv.org/abs/2410.11374)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The development of vision-language and generative models has significantly advanced text-guided image editing, which seeks \textit{preservation} of core elements in the source image while implementing \textit{modifications} based on the target text. However, in the absence of evaluation metrics specifically tailored for text-guided image editing, existing metrics are limited in balancing the consideration of preservation and modification. Especially, our analysis reveals that CLIPScore, the most commonly used metric, tends to favor modification and ignore core attributes to be preserved, resulting in inaccurate evaluations. To address this problem, we propose \texttt{AugCLIP}, \black{which balances preservation and modification by estimating the representation of an ideal edited image that aligns with the target text with minimum alteration on the source image. We augment detailed textual descriptions on the source image and the target text using a multi-modal large language model, to model a hyperplane that separates CLIP space into source or target. The representation of the ideal edited image is an orthogonal projection of the source image into the hyperplane, which encapsulates the relative importance of each attribute considering the interdependent relationships.} Our extensive experiments on five benchmark datasets, encompassing a diverse range of editing scenarios, demonstrate that \texttt{AugCLIP} aligns remarkably well with human evaluation standards compared to existing metrics. The code for evaluation will be open-sourced to contribute to the community.</li>
</ul>

<h3>Title: WPFed: Web-based Personalized Federation for Decentralized Systems</h3>
<ul>
<li><strong>Authors: </strong>Guanhua Ye, Jifeng He, Weiqing Wang, Zhe Xue, Feifei Kou, Yawen Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11378">https://arxiv.org/abs/2410.11378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11378">https://arxiv.org/pdf/2410.11378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11378]] WPFed: Web-based Personalized Federation for Decentralized Systems(https://arxiv.org/abs/2410.11378)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Decentralized learning has become crucial for collaborative model training in environments where data privacy and trust are paramount. In web-based applications, clients are liberated from traditional fixed network topologies, enabling the establishment of arbitrary peer-to-peer (P2P) connections. While this flexibility is highly promising, it introduces a fundamental challenge: the optimal selection of neighbors to ensure effective collaboration. To address this, we introduce WPFed, a fully decentralized, web-based learning framework designed to enable globally optimal neighbor selection. WPFed employs a dynamic communication graph and a weighted neighbor selection mechanism. By assessing inter-client similarity through Locality-Sensitive Hashing (LSH) and evaluating model quality based on peer rankings, WPFed enables clients to identify personalized optimal neighbors on a global scale while preserving data privacy. To enhance security and deter malicious behavior, WPFed integrates verification mechanisms for both LSH codes and performance rankings, leveraging blockchain-driven announcements to ensure transparency and verifiability. Through extensive experiments on multiple real-world datasets, we demonstrate that WPFed significantly improves learning outcomes and system robustness compared to traditional federated learning methods. Our findings highlight WPFed's potential to facilitate effective and secure decentralized collaborative learning across diverse and interconnected web environments.</li>
</ul>

<h3>Title: Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations</h3>
<ul>
<li><strong>Authors: </strong>Seongho Kim, Jihyun Moon, Juntaek Oh, Insu Choi, Joon-Sung Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11381">https://arxiv.org/abs/2410.11381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11381">https://arxiv.org/pdf/2410.11381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11381]] Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations(https://arxiv.org/abs/2410.11381)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The advent of the Attention mechanism and Transformer architecture enables contextually natural text generation and compresses the burden of processing entire source information into singular vectors. Based on these two main ideas, model sizes gradually increases to accommodate more precise and comprehensive information, leading to the current state-of-the-art LLMs being very large, with parameters around 70 billion. As the model sizes are growing, the demand for substantial storage and computational capacity increases. This leads to the development of high-bandwidth memory and accelerators, as well as a variety of model architectures designed to meet these requirements. We note that LLM architectures have increasingly converged. This paper analyzes how these converged architectures perform in terms of layer configurations, operational mechanisms, and model sizes, considering various hyperparameter settings. In this paper, we conduct a concise survey of the history of LLMs by tracing the evolution of their operational improvements. Furthermore, we summarize the performance trends of LLMs under various hyperparameter settings using the RTX 6000, which features the state-of-the-art Ada Lovelace architecture. We conclude that even the same model can exhibit different behaviors depending on the hyperparameters or whether it is deployed in server or edge environments.</li>
</ul>

<h3>Title: Do LLMs Have the Generalization Ability in Conducting Causal Inference?</h3>
<ul>
<li><strong>Authors: </strong>Chen Wang, Dongming Zhao, Bo Wang, Ruifang He, Yuexian Hou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11385">https://arxiv.org/abs/2410.11385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11385">https://arxiv.org/pdf/2410.11385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11385]] Do LLMs Have the Generalization Ability in Conducting Causal Inference?(https://arxiv.org/abs/2410.11385)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In causal inference, generalization capability refers to the ability to conduct causal inference methods on new data to estimate the causal-effect between unknown phenomenon, which is crucial for expanding the boundaries of knowledge. Studies have evaluated the causal inference capabilities of Large Language Models (LLMs) concerning known phenomena, yet the generalization capabilities of LLMs concerning unseen phenomena remain unexplored. In this paper, we selected four tasks: Causal Path Discovery (CP), Backdoor Adjustment (BA), Factual Inference (FI), and Counterfactual Inference (CI) as representatives of causal inference tasks. To generate evaluation questions about previously unseen phenomena in new data on the four tasks, we propose a benchmark generation framework, which employs randomly generated graphs and node names to formulate questions within hypothetical new causal scenarios. Based on this framework, we compile a benchmark dataset of varying levels of question complexity. We extensively tested the generalization capabilities of five leading LLMs across four tasks. Experiment results reveal that while LLMs exhibit good generalization performance in solving simple CP, FI, and complex CI questions, they encounter difficulties when tackling BA questions and face obvious performance fluctuations as the problem complexity changes. Furthermore, when the names of phenomena incorporate existing terms, even if these names are entirely novel, their generalization performance can still be hindered by interference from familiar terms.</li>
</ul>

<h3>Title: MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields</h3>
<ul>
<li><strong>Authors: </strong>Yuru Xiao, Deming Zhai, Wenbo Zhao, Kui Jiang, Junjun Jiang, Xianming Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11394">https://arxiv.org/abs/2410.11394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11394">https://arxiv.org/pdf/2410.11394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11394]] MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields(https://arxiv.org/abs/2410.11394)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Radiance fields represented by 3D Gaussians excel at synthesizing novel views, offering both high training efficiency and fast rendering. However, with sparse input views, the lack of multi-view consistency constraints results in poorly initialized point clouds and unreliable heuristics for optimization and densification, leading to suboptimal performance. Existing methods often incorporate depth priors from dense estimation networks but overlook the inherent multi-view consistency in input images. Additionally, they rely on multi-view stereo (MVS)-based initialization, which limits the efficiency of scene representation. To overcome these challenges, we propose a view synthesis framework based on 3D Gaussian Splatting, named MCGS, enabling photorealistic scene reconstruction from sparse input views. The key innovations of MCGS in enhancing multi-view consistency are as follows: i) We introduce an initialization method by leveraging a sparse matcher combined with a random filling strategy, yielding a compact yet sufficient set of initial points. This approach enhances the initial geometry prior, promoting efficient scene representation. ii) We develop a multi-view consistency-guided progressive pruning strategy to refine the Gaussian field by strengthening consistency and eliminating low-contribution Gaussians. These modular, plug-and-play strategies enhance robustness to sparse input views, accelerate rendering, and reduce memory consumption, making MCGS a practical and efficient framework for 3D Gaussian Splatting.</li>
</ul>

<h3>Title: FOOGD: Federated Collaboration for Both Out-of-distribution Generalization and Detection</h3>
<ul>
<li><strong>Authors: </strong>Xinting Liao, Weiming Liu, Pengyang Zhou, Fengyuan Yu, Jiahe Xu, Jun Wang, Wenjie Wang, Chaochao Chen, Xiaolin Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11397">https://arxiv.org/abs/2410.11397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11397">https://arxiv.org/pdf/2410.11397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11397]] FOOGD: Federated Collaboration for Both Out-of-distribution Generalization and Detection(https://arxiv.org/abs/2410.11397)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a promising machine learning paradigm that collaborates with client models to capture global knowledge. However, deploying FL models in real-world scenarios remains unreliable due to the coexistence of in-distribution data and unexpected out-of-distribution (OOD) data, such as covariate-shift and semantic-shift data. Current FL researches typically address either covariate-shift data through OOD generalization or semantic-shift data via OOD detection, overlooking the simultaneous occurrence of various OOD shifts. In this work, we propose FOOGD, a method that estimates the probability density of each client and obtains reliable global distribution as guidance for the subsequent FL process. Firstly, SM3D in FOOGD estimates score model for arbitrary distributions without prior constraints, and detects semantic-shift data powerfully. Then SAG in FOOGD provides invariant yet diverse knowledge for both local covariate-shift generalization and client performance generalization. In empirical validations, FOOGD significantly enjoys three main advantages: (1) reliably estimating non-normalized decentralized distributions, (2) detecting semantic shift data via score values, and (3) generalizing to covariate-shift data by regularizing feature extractor. The prejoct is open in this https URL.</li>
</ul>

<h3>Title: MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Mo, Yixuan Chen, Rifen Lin, Yongkang Ni, Min Zeng, Xiping Hu, Min Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11404">https://arxiv.org/abs/2410.11404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11404">https://arxiv.org/pdf/2410.11404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11404]] MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description(https://arxiv.org/abs/2410.11404)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite continuous advancements in deep learning for understanding human motion, existing models often struggle to accurately identify action timing and specific body parts, typically supporting only single-round interaction. Such limitations in capturing fine-grained motion details reduce their effectiveness in motion understanding tasks. In this paper, we propose MoChat, a multimodal large language model capable of spatio-temporal grounding of human motion and understanding multi-turn dialogue context. To achieve these capabilities, we group the spatial information of each skeleton frame based on human anatomical structure and then apply them with Joints-Grouped Skeleton Encoder, whose outputs are combined with LLM embeddings to create spatio-aware and temporal-aware embeddings separately. Additionally, we develop a pipeline for extracting timestamps from skeleton sequences based on textual annotations, and construct multi-turn dialogues for spatially grounding. Finally, various task instructions are generated for jointly training. Experimental results demonstrate that MoChat achieves state-of-the-art performance across multiple metrics in motion understanding tasks, making it as the first model capable of fine-grained spatio-temporal grounding of human motion.</li>
</ul>

<h3>Title: PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation</h3>
<ul>
<li><strong>Authors: </strong>Shuqiao Sun, Yutong Yao, Peiwen Wu, Feijun Jiang, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11410">https://arxiv.org/abs/2410.11410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11410">https://arxiv.org/pdf/2410.11410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11410]] PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation(https://arxiv.org/abs/2410.11410)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Translation is important for cross-language communication, and many efforts have been made to improve its accuracy. However, less investment is conducted in aligning translations with human preferences, such as translation tones or styles. In this paper, a new method is proposed to effectively generate large-scale multilingual parallel corpora with specific translation preferences using Large Language Models (LLMs). Meanwhile, an automatic pipeline is designed to distill human preferences into smaller Machine Translation (MT) models for efficiently and economically supporting large-scale calls in online services. Experiments indicate that the proposed method takes the lead in translation tasks with aligned human preferences by a large margin. Meanwhile, on popular public benchmarks like WMT and Flores, on which our models were not trained, the proposed method also shows a competitive performance compared to SOTA works.</li>
</ul>

<h3>Title: ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Zhongxiang Sun, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu, Xiao Zhang, Weijie Yu, Yang Song, Han Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11414">https://arxiv.org/abs/2410.11414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11414">https://arxiv.org/pdf/2410.11414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11414]] ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability(https://arxiv.org/abs/2410.11414)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) models are designed to incorporate external knowledge, reducing hallucinations caused by insufficient parametric (internal) knowledge. However, even with accurate and relevant retrieved content, RAG models can still produce hallucinations by generating outputs that conflict with the retrieved information. Detecting such hallucinations requires disentangling how Large Language Models (LLMs) utilize external and parametric knowledge. Current detection methods often focus on one of these mechanisms or without decoupling their intertwined effects, making accurate detection difficult. In this paper, we investigate the internal mechanisms behind hallucinations in RAG scenarios. We discover hallucinations occur when the Knowledge FFNs in LLMs overemphasize parametric knowledge in the residual stream, while Copying Heads fail to effectively retain or integrate external knowledge from retrieved content. Based on these findings, we propose ReDeEP, a novel method that detects hallucinations by decoupling LLM's utilization of external context and parametric knowledge. Our experiments show that ReDeEP significantly improves RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by modulating the contributions of Knowledge FFNs and Copying Heads.</li>
</ul>

<h3>Title: VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaohan Lan, Yitian Yuan, Zequn Jie, Lin Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11417">https://arxiv.org/abs/2410.11417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11417">https://arxiv.org/pdf/2410.11417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11417]] VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models(https://arxiv.org/abs/2410.11417)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Video-based multimodal large language models (Video-LLMs) possess significant potential for video understanding tasks. However, most Video-LLMs treat videos as a sequential set of individual frames, which results in insufficient temporal-spatial interaction that hinders fine-grained comprehension and difficulty in processing longer videos due to limited visual token capacity. To address these challenges, we propose VidCompress, a novel Video-LLM featuring memory-enhanced temporal compression. VidCompress employs a dual-compressor approach: a memory-enhanced compressor captures both short-term and long-term temporal relationships in videos and compresses the visual tokens using a multiscale transformer with a memory-cache mechanism, while a text-perceived compressor generates condensed visual tokens by utilizing Q-Former and integrating temporal contexts into query embeddings with cross attention. Experiments on several VideoQA datasets and comprehensive benchmarks demonstrate that VidCompress efficiently models complex temporal-spatial relations and significantly outperforms existing Video-LLMs.</li>
</ul>

<h3>Title: CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction</h3>
<ul>
<li><strong>Authors: </strong>Chunlei Meng, Jiacheng Yang, Wei Lin, Bowen Liu, Hongda Zhang, chun ouyang, Zhongxue Gan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11428">https://arxiv.org/abs/2410.11428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11428">https://arxiv.org/pdf/2410.11428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11428]] CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction(https://arxiv.org/abs/2410.11428)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks (CNNs) and vision transformers (ViTs) have become essential in computer vision for local and global feature extraction. However, aggregating these architectures in existing methods often results in inefficiencies. To address this, the CNN-Transformer Aggregation Network (CTA-Net) was developed. CTA-Net combines CNNs and ViTs, with transformers capturing long-range dependencies and CNNs extracting localized features. This integration enables efficient processing of detailed local and broader contextual information. CTA-Net introduces the Light Weight Multi-Scale Feature Fusion Multi-Head Self-Attention (LMF-MHSA) module for effective multi-scale feature integration with reduced parameters. Additionally, the Reverse Reconstruction CNN-Variants (RRCV) module enhances the embedding of CNNs within the transformer architecture. Extensive experiments on small-scale datasets with fewer than 100,000 samples show that CTA-Net achieves superior performance (TOP-1 Acc 86.76\%), fewer parameters (20.32M), and greater efficiency (FLOPs 2.83B), making it a highly efficient and lightweight solution for visual tasks on small-scale datasets (fewer than 100,000).</li>
</ul>

<h3>Title: Hessian-Informed Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Christopher Iliffe Sprague, Arne Elofsson, Hossein Azizpour</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11433">https://arxiv.org/abs/2410.11433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11433">https://arxiv.org/pdf/2410.11433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11433]] Hessian-Informed Flow Matching(https://arxiv.org/abs/2410.11433)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modeling complex systems that evolve toward equilibrium distributions is important in various physical applications, including molecular dynamics and robotic control. These systems often follow the stochastic gradient descent of an underlying energy function, converging to stationary distributions around energy minima. The local covariance of these distributions is shaped by the energy landscape's curvature, often resulting in anisotropic characteristics. While flow-based generative models have gained traction in generating samples from equilibrium distributions in such applications, they predominately employ isotropic conditional probability paths, limiting their ability to capture such covariance structures. In this paper, we introduce Hessian-Informed Flow Matching (HI-FM), a novel approach that integrates the Hessian of an energy function into conditional flows within the flow matching framework. This integration allows HI-FM to account for local curvature and anisotropic covariance structures. Our approach leverages the linearization theorem from dynamical systems and incorporates additional considerations such as time transformations and equivariance. Empirical evaluations on the MNIST and Lennard-Jones particles datasets demonstrate that HI-FM improves the likelihood of test samples.</li>
</ul>

<h3>Title: Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sihang Zhao, Youliang Yuan, Xiaoying Tang, Pinjia He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11437">https://arxiv.org/abs/2410.11437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11437">https://arxiv.org/pdf/2410.11437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11437]] Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs(https://arxiv.org/abs/2410.11437)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) demonstrate a strong understanding of the real world and can even handle complex tasks. However, they still fail on some straightforward visual question-answering (VQA) problems. This paper dives deeper into this issue, revealing that models tend to err when answering easy questions (e.g. Yes/No questions) about an image, even though they can correctly describe it. We refer to this model behavior discrepancy between difficult and simple questions as model laziness. To systematically investigate model laziness, we manually construct LazyBench, a benchmark that includes Yes/No, multiple choice, short answer questions, and image description tasks that are related to the same subjects in the images. Based on LazyBench, we observe that laziness widely exists in current advanced MLLMs (e.g. GPT-4o, Gemini-1.5-pro, Claude 3 and LLaVA-v1.5-13B), and it is more pronounced on stronger models. We also analyze the VQA v2 (LLaVA-v1.5-13B) benchmark and find that about half of its failure cases are caused by model laziness, which further highlights the importance of ensuring that the model fully utilizes its capability. To this end, we conduct preliminary exploration on how to mitigate laziness and find that chain of thought (CoT) can effectively address this issue.</li>
</ul>

<h3>Title: A Simple Approach to Unifying Diffusion-based Conditional Generation</h3>
<ul>
<li><strong>Authors: </strong>Xirui Li, Charles Herrmann, Kelvin C.K. Chan, Yinxiao Li, Deqing Sun, Chao Ma, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11439">https://arxiv.org/abs/2410.11439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11439">https://arxiv.org/pdf/2410.11439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11439]] A Simple Approach to Unifying Diffusion-based Conditional Generation(https://arxiv.org/abs/2410.11439)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent progress in image generation has sparked research into controlling these models through condition signals, with various methods addressing specific challenges in conditional generation. Instead of proposing another specialized technique, we introduce a simple, unified framework to handle diverse conditional generation tasks involving a specific image-condition correlation. By learning a joint distribution over a correlated image pair (e.g. image and depth) with a diffusion model, our approach enables versatile capabilities via different inference-time sampling schemes, including controllable image generation (e.g. depth to image), estimation (e.g. image to depth), signal guidance, joint generation (image & depth), and coarse control. Previous attempts at unification often introduce significant complexity through multi-stage training, architectural modification, or increased parameter counts. In contrast, our simple formulation requires a single, computationally efficient training stage, maintains the standard model input, and adds minimal learned parameters (15% of the base model). Moreover, our model supports additional capabilities like non-spatially aligned and coarse conditioning. Extensive results show that our single model can produce comparable results with specialized methods and better results than prior unified methods. We also demonstrate that multiple models can be effectively combined for multi-signal conditional generation.</li>
</ul>

<h3>Title: On Championing Foundation Models: From Explainability to Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Shi Fu, Yuzhu Chen, Yingjie Wang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11444">https://arxiv.org/abs/2410.11444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11444">https://arxiv.org/pdf/2410.11444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11444]] On Championing Foundation Models: From Explainability to Interpretability(https://arxiv.org/abs/2410.11444)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Understanding the inner mechanisms of black-box foundation models (FMs) is essential yet challenging in artificial intelligence and its applications. Over the last decade, the long-running focus has been on their explainability, leading to the development of post-hoc explainable methods to rationalize the specific decisions already made by black-box FMs. However, these explainable methods have certain limitations in terms of faithfulness, detail capture and resource requirement. Consequently, in response to these issues, a new class of interpretable methods should be considered to unveil the underlying mechanisms in an accurate, comprehensive, heuristic and resource-light way. This survey aims to review interpretable methods that comply with the aforementioned principles and have been successfully applied to FMs. These methods are deeply rooted in machine learning theory, covering the analysis of generalization performance, expressive capability, and dynamic behavior. They provide a thorough interpretation of the entire workflow of FMs, ranging from the inference capability and training dynamics to their ethical implications. Ultimately, drawing upon these interpretations, this review identifies the next frontier research directions for FMs.</li>
</ul>

<h3>Title: AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task</h3>
<ul>
<li><strong>Authors: </strong>Herbert Ullrich, Tomáš Mlynář, Jan Drchal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11446">https://arxiv.org/abs/2410.11446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11446">https://arxiv.org/pdf/2410.11446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11446]] AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task(https://arxiv.org/abs/2410.11446)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper describes our $3^{rd}$ place submission in the AVeriTeC shared task in which we attempted to address the challenge of fact-checking with evidence retrieved in the wild using a simple scheme of Retrieval-Augmented Generation (RAG) designed for the task, leveraging the predictive power of Large Language Models. We release our codebase and explain its two modules - the Retriever and the Evidence & Label generator - in detail, justifying their features such as MMR-reranking and Likert-scale confidence estimation. We evaluate our solution on AVeriTeC dev and test set and interpret the results, picking the GPT-4o as the most appropriate model for our pipeline at the time of our publication, with Llama 3.1 70B being a promising open-source alternative. We perform an empirical error analysis to see that faults in our predictions often coincide with noise in the data or ambiguous fact-checks, provoking further research and data augmentation.</li>
</ul>

<h3>Title: Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement</h3>
<ul>
<li><strong>Authors: </strong>Zhi Wang, Li Zhang, Wenhao Wu, Yuanheng Zhu, Dongbin Zhao, Chunlin Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11448">https://arxiv.org/abs/2410.11448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11448">https://arxiv.org/pdf/2410.11448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11448]] Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement(https://arxiv.org/abs/2410.11448)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>A longstanding goal of artificial general intelligence is highly capable generalists that can learn from diverse experiences and generalize to unseen tasks. The language and vision communities have seen remarkable progress toward this trend by scaling up transformer-based models trained on massive datasets, while reinforcement learning (RL) agents still suffer from poor generalization capacity under such paradigms. To tackle this challenge, we propose Meta Decision Transformer (Meta-DT), which leverages the sequential modeling ability of the transformer architecture and robust task representation learning via world model disentanglement to achieve efficient generalization in offline meta-RL. We pretrain a context-aware world model to learn a compact task representation, and inject it as a contextual condition to the causal transformer to guide task-oriented sequence generation. Then, we subtly utilize history trajectories generated by the meta-policy as a self-guided prompt to exploit the architectural inductive bias. We select the trajectory segment that yields the largest prediction error on the pretrained world model to construct the prompt, aiming to encode task-specific information complementary to the world model maximally. Notably, the proposed framework eliminates the requirement of any expert demonstration or domain knowledge at test time. Experimental results on MuJoCo and Meta-World benchmarks across various dataset types show that Meta-DT exhibits superior few and zero-shot generalization capacity compared to strong baselines while being more practical with fewer prerequisites. Our code is available at this https URL.</li>
</ul>

<h3>Title: Conditional Density Estimation with Histogram Trees</h3>
<ul>
<li><strong>Authors: </strong>Lincen Yang, Matthijs van Leeuwen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11449">https://arxiv.org/abs/2410.11449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11449">https://arxiv.org/pdf/2410.11449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11449]] Conditional Density Estimation with Histogram Trees(https://arxiv.org/abs/2410.11449)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Conditional density estimation (CDE) goes beyond regression by modeling the full conditional distribution, providing a richer understanding of the data than just the conditional mean in regression. This makes CDE particularly useful in critical application domains. However, interpretable CDE methods are understudied. Current methods typically employ kernel-based approaches, using kernel functions directly for kernel density estimation or as basis functions in linear models. In contrast, despite their conceptual simplicity and visualization suitability, tree-based methods -- which are arguably more comprehensible -- have been largely overlooked for CDE tasks. Thus, we propose the Conditional Density Tree (CDTree), a fully non-parametric model consisting of a decision tree in which each leaf is formed by a histogram model. Specifically, we formalize the problem of learning a CDTree using the minimum description length (MDL) principle, which eliminates the need for tuning the hyperparameter for regularization. Next, we propose an iterative algorithm that, although greedily, searches the optimal histogram for every possible node split. Our experiments demonstrate that, in comparison to existing interpretable CDE methods, CDTrees are both more accurate (as measured by the log-loss) and more robust against irrelevant features. Further, our approach leads to smaller tree sizes than existing tree-based models, which benefits interpretability.</li>
</ul>

<h3>Title: Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11459">https://arxiv.org/abs/2410.11459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11459">https://arxiv.org/pdf/2410.11459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11459]] Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models(https://arxiv.org/abs/2410.11459)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have exhibited outstanding performance in engaging with humans and addressing complex questions by leveraging their vast implicit knowledge and robust reasoning capabilities. However, such models are vulnerable to jailbreak attacks, leading to the generation of harmful responses. Despite recent research on single-turn jailbreak strategies to facilitate the development of defence mechanisms, the challenge of revealing vulnerabilities under multi-turn setting remains relatively under-explored. In this work, we propose Jigsaw Puzzles (JSP), a straightforward yet effective multi-turn jailbreak strategy against the advanced LLMs. JSP splits questions into harmless fractions as the input of each turn, and requests LLMs to reconstruct and respond to questions under multi-turn interaction. Our experimental results demonstrate that the proposed JSP jailbreak bypasses original safeguards against explicitly harmful content, achieving an average attack success rate of 93.76% on 189 harmful queries across 5 advanced LLMs (Gemini-1.5-Pro, Llama-3.1-70B, GPT-4, GPT-4o, GPT-4o-mini). Moreover, JSP achieves a state-of-the-art attack success rate of 92% on GPT-4 on the harmful query benchmark, and exhibits strong resistant to defence strategies. Warning: this paper contains offensive examples.</li>
</ul>

<h3>Title: Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Animesh Singh Basnet, Mohamed Chahine Ghanem, Dipo Dunsin, Wiktor Sowinski-Mydlarz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11463">https://arxiv.org/abs/2410.11463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11463">https://arxiv.org/pdf/2410.11463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11463]] Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning(https://arxiv.org/abs/2410.11463)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the application of Deep Reinforcement Learning (DRL) for attributing malware to specific Advanced Persistent Threat (APT) groups through detailed behavioural analysis. By analysing over 3500 malware samples from 12 distinct APT groups, the study utilises sophisticated tools like Cuckoo Sandbox to extract behavioural data, providing a deep insight into the operational patterns of malware. The research demonstrates that the DRL model significantly outperforms traditional machine learning approaches such as SGD, SVC, KNN, MLP, and Decision Tree Classifiers, achieving an impressive test accuracy of 89.27 %. It highlights the model capability to adeptly manage complex, variable, and elusive malware attributes. Furthermore, the paper discusses the considerable computational resources and extensive data dependencies required for deploying these advanced AI models in cybersecurity frameworks. Future research is directed towards enhancing the efficiency of DRL models, expanding the diversity of the datasets, addressing ethical concerns, and leveraging Large Language Models (LLMs) to refine reward mechanisms and optimise the DRL framework. By showcasing the transformative potential of DRL in malware attribution, this research advocates for a responsible and balanced approach to AI integration, with the goal of advancing cybersecurity through more adaptable, accurate, and robust systems.</li>
</ul>

<h3>Title: Can sparse autoencoders make sense of latent representations?</h3>
<ul>
<li><strong>Authors: </strong>Viktoria Schuster</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11468">https://arxiv.org/abs/2410.11468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11468">https://arxiv.org/pdf/2410.11468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11468]] Can sparse autoencoders make sense of latent representations?(https://arxiv.org/abs/2410.11468)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) have lately been used to uncover interpretable latent features in large language models. Here, we explore their potential for decomposing latent representations in complex and high-dimensional biological data, where the underlying variables are often unknown. On simulated data we show that generative hidden variables can be captured in learned representations in the form of superpositions. The degree to which they are learned depends on the completeness of the representations. Superpositions, however, are not identifiable if these generative variables are unknown. SAEs can to some extent recover these variables, yielding interpretable features. Applied to single-cell multi-omics data, we show that an SAE can uncover key biological processes such as carbon dioxide transport and ion homeostasis, which are crucial for red blood cell differentiation and immune function. Our findings highlight how SAEs can be used in advancing interpretability in biological and other scientific domains.</li>
</ul>

<h3>Title: O-Edit: Orthogonal Subspace Editing for Language Model Sequential Editing</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Cai, Ding Cao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11469">https://arxiv.org/abs/2410.11469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11469">https://arxiv.org/pdf/2410.11469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11469]] O-Edit: Orthogonal Subspace Editing for Language Model Sequential Editing(https://arxiv.org/abs/2410.11469)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) acquire knowledge during pre-training, but over time, this knowledge may become incorrect or outdated, necessitating updates after training. Knowledge editing techniques address this issue without the need for costly re-training. However, most existing methods are designed for single edits, and as the number of edits increases, they often cause a decline in the model's overall performance, posing significant challenges for sequential editing. To overcome this, we propose Orthogonal Subspace Editing, O-Edit. This algorithm orthogonalizes the direction of each knowledge update, minimizing interference between successive updates and reducing the impact of new updates on unrelated knowledge. Our approach does not require replaying previously edited data and processes each edit knowledge on time. It can perform thousands of edits on mainstream LLMs, achieving an average performance improvement that is 4.2 times better than existing methods while effectively preserving the model's performance on downstream tasks, all with minimal additional parameter overhead.</li>
</ul>

<h3>Title: InvSeg: Test-Time Prompt Inversion for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiayi Lin, Jiabo Huang, Jian Hu, Shaogang Gong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11473">https://arxiv.org/abs/2410.11473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11473">https://arxiv.org/pdf/2410.11473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11473]] InvSeg: Test-Time Prompt Inversion for Semantic Segmentation(https://arxiv.org/abs/2410.11473)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Visual-textual correlations in the attention maps derived from text-to-image diffusion models are proven beneficial to dense visual prediction tasks, e.g., semantic segmentation. However, a significant challenge arises due to the input distributional discrepancy between the context-rich sentences used for image generation and the isolated class names typically employed in semantic segmentation, hindering the diffusion models from capturing accurate visual-textual correlations. To solve this, we propose InvSeg, a test-time prompt inversion method that tackles open-vocabulary semantic segmentation by inverting image-specific visual context into text prompt embedding space, leveraging structure information derived from the diffusion model's reconstruction process to enrich text prompts so as to associate each class with a structure-consistent mask. Specifically, we introduce Contrastive Soft Clustering (CSC) to align derived masks with the image's structure information, softly selecting anchors for each class and calculating weighted distances to push inner-class pixels closer while separating inter-class pixels, thereby ensuring mask distinction and internal consistency. By incorporating sample-specific context, InvSeg learns context-rich text prompts in embedding space and achieves accurate semantic alignment across modalities. Experiments show that InvSeg achieves state-of-the-art performance on the PASCAL VOC and Context datasets. Project page: this https URL.</li>
</ul>

<h3>Title: How Transformers Implement Induction Heads: Approximation and Optimization Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mingze Wang, Ruoxi Yu, Weinan E, Lei Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11474">https://arxiv.org/abs/2410.11474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11474">https://arxiv.org/pdf/2410.11474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11474]] How Transformers Implement Induction Heads: Approximation and Optimization Analysis(https://arxiv.org/abs/2410.11474)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated exceptional in-context learning capabilities, yet the theoretical understanding of the underlying mechanisms remain limited. A recent work (Elhage et al., 2021) identified a "rich" in-context mechanism known as induction head, contrasting with "lazy" $n$-gram models that overlook long-range dependencies. In this work, we provide both approximation and optimization analyses of how transformers implement induction heads. In the approximation analysis, we formalize both standard and generalized induction head mechanisms, and examine how transformers can efficiently implement them, with an emphasis on the distinct role of each transformer submodule. For the optimization analysis, we study the training dynamics on a synthetic mixed target, composed of a 4-gram and an in-context 2-gram component. This setting enables us to precisely characterize the entire training process and uncover an {\em abrupt transition} from lazy (4-gram) to rich (induction head) mechanisms as training progresses.</li>
</ul>

<h3>Title: Poisson-Dirac Neural Networks for Modeling Coupled Dynamical Systems across Domains</h3>
<ul>
<li><strong>Authors: </strong>Razmik Arman Khosrovian, Takaharu Yaguchi, Hiroaki Yoshimura, Takashi Matsubara</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11480">https://arxiv.org/abs/2410.11480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11480">https://arxiv.org/pdf/2410.11480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11480]] Poisson-Dirac Neural Networks for Modeling Coupled Dynamical Systems across Domains(https://arxiv.org/abs/2410.11480)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep learning has achieved great success in modeling dynamical systems, providing data-driven simulators to predict complex phenomena, even without known governing equations. However, existing models have two major limitations: their narrow focus on mechanical systems and their tendency to treat systems as monolithic. These limitations reduce their applicability to dynamical systems in other domains, such as electrical and hydraulic systems, and to coupled systems. To address these limitations, we propose Poisson-Dirac Neural Networks (PoDiNNs), a novel framework based on the Dirac structure that unifies the port-Hamiltonian and Poisson formulations from geometric mechanics. This framework enables a unified representation of various dynamical systems across multiple domains as well as their interactions and degeneracies arising from couplings. Our experiments demonstrate that PoDiNNs offer improved accuracy and interpretability in modeling unknown coupled dynamical systems from data.</li>
</ul>

<h3>Title: Offline Model-Based Optimization by Learning to Rank</h3>
<ul>
<li><strong>Authors: </strong>Rong-Xi Tan, Ke Xue, Shen-Huan Lyu, Haopu Shang, Yao Wang, Yaoyuan Wang, Sheng Fu, Chao Qian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11502">https://arxiv.org/abs/2410.11502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11502">https://arxiv.org/pdf/2410.11502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11502]] Offline Model-Based Optimization by Learning to Rank(https://arxiv.org/abs/2410.11502)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Offline model-based optimization (MBO) aims to identify a design that maximizes a black-box function using only a fixed, pre-collected dataset of designs and their corresponding scores. A common approach in offline MBO is to train a regression-based surrogate model by minimizing mean squared error (MSE) and then find the best design within this surrogate model by different optimizers (e.g., gradient ascent). However, a critical challenge is the risk of out-of-distribution errors, i.e., the surrogate model may typically overestimate the scores and mislead the optimizers into suboptimal regions. Prior works have attempted to address this issue in various ways, such as using regularization techniques and ensemble learning to enhance the robustness of the model, but it still remains. In this paper, we argue that regression models trained with MSE are not well-aligned with the primary goal of offline MBO, which is to select promising designs rather than to predict their scores precisely. Notably, if a surrogate model can maintain the order of candidate designs based on their relative score relationships, it can produce the best designs even without precise predictions. To validate it, we conduct experiments to compare the relationship between the quality of the final designs and MSE, finding that the correlation is really very weak. In contrast, a metric that measures order-maintaining quality shows a significantly stronger correlation. Based on this observation, we propose learning a ranking-based model that leverages learning to rank techniques to prioritize promising designs based on their relative scores. We show that the generalization error on ranking loss can be well bounded. Empirical results across diverse tasks demonstrate the superior performance of our proposed ranking-based models than twenty existing methods.</li>
</ul>

<h3>Title: LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images</h3>
<ul>
<li><strong>Authors: </strong>Yuzhou Cheng, Jianhao Jiao, Yue Wang, Dimitrios Kanoulas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11505">https://arxiv.org/abs/2410.11505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11505">https://arxiv.org/pdf/2410.11505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11505]] LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images(https://arxiv.org/abs/2410.11505)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual localization involves estimating a query image's 6-DoF (degrees of freedom) camera pose, which is a fundamental component in various computer vision and robotic tasks. This paper presents LoGS, a vision-based localization pipeline utilizing the 3D Gaussian Splatting (GS) technique as scene representation. This novel representation allows high-quality novel view synthesis. During the mapping phase, structure-from-motion (SfM) is applied first, followed by the generation of a GS map. During localization, the initial position is obtained through image retrieval, local feature matching coupled with a PnP solver, and then a high-precision pose is achieved through the analysis-by-synthesis manner on the GS map. Experimental results on four large-scale datasets demonstrate the proposed approach's SoTA accuracy in estimating camera poses and robustness under challenging few-shot conditions.</li>
</ul>

<h3>Title: Dual-Teacher Ensemble Models with Double-Copy-Paste for 3D Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhan Fa, Shumeng Li, Jian Zhang, Lei Qi, Qian Yu, Yinghuan Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11509">https://arxiv.org/abs/2410.11509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11509">https://arxiv.org/pdf/2410.11509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11509]] Dual-Teacher Ensemble Models with Double-Copy-Paste for 3D Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2410.11509)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning (SSL) techniques address the high labeling costs in 3D medical image segmentation, with the teacher-student model being a common approach. However, using an exponential moving average (EMA) in single-teacher models may cause coupling issues, where the weights of the student and teacher models become similar, limiting the teacher's ability to provide additional knowledge for the student. Dual-teacher models were introduced to address this problem but often neglected the importance of maintaining teacher model diversity, leading to coupling issues among teachers. To address the coupling issue, we incorporate a double-copy-paste (DCP) technique to enhance the diversity among the teachers. Additionally, we introduce the Staged Selective Ensemble (SSE) module, which selects different ensemble methods based on the characteristics of the samples and enables more accurate segmentation of label boundaries, thereby improving the quality of pseudo-labels. Experimental results demonstrate the effectiveness of our proposed method in 3D medical image segmentation tasks. Here is the code link: this https URL.</li>
</ul>

<h3>Title: TopoLM: brain-like spatio-functional organization in a topographic language model</h3>
<ul>
<li><strong>Authors: </strong>Neil Rathi, Johannes Mehrer, Badr AlKhamissi, Taha Binhuraib, Nicholas M. Blauch, Martin Schrimpf</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11516">https://arxiv.org/abs/2410.11516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11516">https://arxiv.org/pdf/2410.11516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11516]] TopoLM: brain-like spatio-functional organization in a topographic language model(https://arxiv.org/abs/2410.11516)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neurons in the brain are spatially organized such that neighbors on tissue often exhibit similar response profiles. In the human language system, experimental studies have observed clusters for syntactic and semantic categories, but the mechanisms underlying this functional organization remain unclear. Here, building on work from the vision literature, we develop TopoLM, a transformer language model with an explicit two-dimensional spatial representation of model units. By combining a next-token prediction objective with a spatial smoothness loss, representations in this model assemble into clusters that correspond to semantically interpretable groupings of text and closely match the functional organization in the brain's language system. TopoLM successfully predicts the emergence of the spatio-functional organization of a cortical language system as well as the organization of functional clusters selective for fine-grained linguistic features empirically observed in human cortex. Our results suggest that the functional organization of the human language system is driven by a unified spatial objective, and provide a functionally and spatially aligned model of language processing in the brain.</li>
</ul>

<h3>Title: Hairmony: Fairness-aware hairstyle classification</h3>
<ul>
<li><strong>Authors: </strong>Givi Meishvili, James Clemoes, Charlie Hewitt, Zafiirah Hosenie, Xian Xiao, Martin de La Gorce, Tibor Takacs, Tadas Baltrusaitis, Antonio Criminisi, Chyna McRae, Nina Jablonski, Marta Wilczkowiak</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11528">https://arxiv.org/abs/2410.11528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11528">https://arxiv.org/pdf/2410.11528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11528]] Hairmony: Fairness-aware hairstyle classification(https://arxiv.org/abs/2410.11528)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, fair</a></li>
<li><strong>Abstract: </strong>We present a method for prediction of a person's hairstyle from a single image. Despite growing use cases in user digitization and enrollment for virtual experiences, available methods are limited, particularly in the range of hairstyles they can capture. Human hair is extremely diverse and lacks any universally accepted description or categorization, making this a challenging task. Most current methods rely on parametric models of hair at a strand level. These approaches, while very promising, are not yet able to represent short, frizzy, coily hair and gathered hairstyles. We instead choose a classification approach which can represent the diversity of hairstyles required for a truly robust and inclusive system. Previous classification approaches have been restricted by poorly labeled data that lacks diversity, imposing constraints on the usefulness of any resulting enrollment system. We use only synthetic data to train our models. This allows for explicit control of diversity of hairstyle attributes, hair colors, facial appearance, poses, environments and other parameters. It also produces noise-free ground-truth labels. We introduce a novel hairstyle taxonomy developed in collaboration with a diverse group of domain experts which we use to balance our training data, supervise our model, and directly measure fairness. We annotate our synthetic training data and a real evaluation dataset using this taxonomy and release both to enable comparison of future hairstyle prediction approaches. We employ an architecture based on a pre-trained feature extraction network in order to improve generalization of our method to real data and predict taxonomy attributes as an auxiliary task to improve accuracy. Results show our method to be significantly more robust for challenging hairstyles than recent parametric approaches.</li>
</ul>

<h3>Title: Multi-round jailbreak attack on large language models</h3>
<ul>
<li><strong>Authors: </strong>Yihua Zhou, Xiaochuan Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11533">https://arxiv.org/abs/2410.11533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11533">https://arxiv.org/pdf/2410.11533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11533]] Multi-round jailbreak attack on large language models(https://arxiv.org/abs/2410.11533)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Ensuring the safety and alignment of large language models (LLMs) with human values is crucial for generating responses that are beneficial to humanity. While LLMs have the capability to identify and avoid harmful queries, they remain vulnerable to "jailbreak" attacks, where carefully crafted prompts can induce the generation of toxic content. Traditional single-round jailbreak attacks, such as GCG and AutoDAN, do not alter the sensitive words in the dangerous prompts. Although they can temporarily bypass the model's safeguards through prompt engineering, their success rate drops significantly as the LLM is further fine-tuned, and they cannot effectively circumvent static rule-based filters that remove the hazardous vocabulary. In this study, to better understand jailbreak attacks, we introduce a multi-round jailbreak approach. This method can rewrite the dangerous prompts, decomposing them into a series of less harmful sub-questions to bypass the LLM's safety checks. We first use the LLM to perform a decomposition task, breaking down a set of natural language questions into a sequence of progressive sub-questions, which are then used to fine-tune the Llama3-8B model, enabling it to decompose hazardous prompts. The fine-tuned model is then used to break down the problematic prompt, and the resulting sub-questions are sequentially asked to the victim model. If the victim model rejects a sub-question, a new decomposition is generated, and the process is repeated until the final objective is achieved. Our experimental results show a 94\% success rate on the llama2-7B and demonstrate the effectiveness of this approach in circumventing static rule-based filters.</li>
</ul>

<h3>Title: Overcoming Domain Limitations in Open-vocabulary Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Dongjun Hwang, Seong Joon Oh, Junsuk Choe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11536">https://arxiv.org/abs/2410.11536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11536">https://arxiv.org/pdf/2410.11536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11536]] Overcoming Domain Limitations in Open-vocabulary Segmentation(https://arxiv.org/abs/2410.11536)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary segmentation (OVS) has gained attention for its ability to recognize a broader range of classes. However, OVS models show significant performance drops when applied to unseen domains beyond the previous training dataset. Fine-tuning these models on new datasets can improve performance, but often leads to the catastrophic forgetting of previously learned knowledge. To address this issue, we propose a method that allows OVS models to learn information from new domains while preserving prior knowledge. Our approach begins by evaluating the input sample's proximity to multiple domains, using precomputed multivariate normal distributions for each domain. Based on this prediction, we dynamically interpolate between the weights of the pre-trained decoder and the fine-tuned decoders. Extensive experiments demonstrate that this approach allows OVS models to adapt to new domains while maintaining performance on the previous training dataset. The source code is available at this https URL.</li>
</ul>

<h3>Title: MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Bin Shan, Xiang Fei, Wei Shi, An-Lan Wang, Guozhi Tang, Lei Liao, Jingqun Tang, Xiang Bai, Can Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11538">https://arxiv.org/abs/2410.11538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11538">https://arxiv.org/pdf/2410.11538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11538]] MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark(https://arxiv.org/abs/2410.11538)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The comprehension of text-rich visual scenes has become a focal point for evaluating Multi-modal Large Language Models (MLLMs) due to their widespread applications. Current benchmarks tailored to the scenario emphasize perceptual capabilities, while overlooking the assessment of cognitive abilities. To address this limitation, we introduce a Multimodal benchmark towards Text-rich visual scenes, to evaluate the Cognitive capabilities of MLLMs through visual reasoning and content-creation tasks (MCTBench). To mitigate potential evaluation bias from the varying distributions of datasets, MCTBench incorporates several perception tasks (e.g., scene text recognition) to ensure a consistent comparison of both the cognitive and perceptual capabilities of MLLMs. To improve the efficiency and fairness of content-creation evaluation, we conduct an automatic evaluation pipeline. Evaluations of various MLLMs on MCTBench reveal that, despite their impressive perceptual capabilities, their cognition abilities require enhancement. We hope MCTBench will offer the community an efficient resource to explore and enhance cognitive capabilities towards text-rich visual scenes.</li>
</ul>

<h3>Title: Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations</h3>
<ul>
<li><strong>Authors: </strong>M. Germán-Morales, A.J. Rivera-Rivas, M.J. del Jesus Díaz, C.J. Carmona</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11539">https://arxiv.org/abs/2410.11539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11539">https://arxiv.org/pdf/2410.11539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11539]] Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations(https://arxiv.org/abs/2410.11539)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>High computational power and the availability of large datasets have supported the development of Foundational Models. They are a new emerging technique widely used in Generative Artificial Intelligence, characterized by their scalability and their use in Transfer Learning. The enormous and heterogeneous amounts of data used in their initial training phase, known as pre-training, give them a higher generalization capacity than any other specific model, constituting a solid base that can be adapted or adjusted to a wide range of tasks, increasing their applicability. This study proposes LLIAM, the Llama Lora-Integrated Autorregresive Model. Low-Rank Adaptations are used to enhance the knowledge of the model with diverse time series datasets, known as the fine-tuning phase. To illustrate the capabilities of our proposal, two sets of experiments have been carried out that obtained favorable and promising results with lower training times than other Deep Learning approaches. With this work, we also encourage the use of available resources (such as these pre-trained models) to avoid unnecessary and costly training, narrowing the gap between the goals of traditional Artificial Intelligence and those specified by the definition of Green Artificial Intelligence.</li>
</ul>

<h3>Title: Data Quality Control in Federated Instruction-tuning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yaxin Du, Rui Ye, Fengting Yuchi, Wanru Zhao, Jingjing Qu, Yanfeng Wang, Siheng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11540">https://arxiv.org/abs/2410.11540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11540">https://arxiv.org/pdf/2410.11540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11540]] Data Quality Control in Federated Instruction-tuning of Large Language Models(https://arxiv.org/abs/2410.11540)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>By leveraging massively distributed data, federated learning (FL) enables collaborative instruction tuning of large language models (LLMs) in a privacy-preserving way. While FL effectively expands the data quantity, the issue of data quality remains under-explored in the current literature on FL for LLMs. To address this gap, we propose a new framework of federated instruction tuning of LLMs with data quality control (FedDQC), which measures data quality to facilitate the subsequent filtering and hierarchical training processes. Our approach introduces an efficient metric to assess each client's instruction-response alignment (IRA), identifying potentially noisy data through single-shot inference. Low-IRA samples are potentially noisy and filtered to mitigate their negative impacts. To further utilize this IRA value, we propose a quality-aware hierarchical training paradigm, where LLM is progressively fine-tuned from high-IRA to low-IRA data, mirroring the easy-to-hard learning process. We conduct extensive experiments on 4 synthetic and a real-world dataset, and compare our method with baselines adapted from centralized setting. Results show that our method consistently and significantly improves the performance of LLMs trained on mix-quality data in FL.</li>
</ul>

<h3>Title: LoKO: Low-Rank Kalman Optimizer for Online Fine-Tuning of Large Models</h3>
<ul>
<li><strong>Authors: </strong>Hossein Abdi, Mingfei Sun, Andi Zhang, Samuel Kaski, Wei Pan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11551">https://arxiv.org/abs/2410.11551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11551">https://arxiv.org/pdf/2410.11551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11551]] LoKO: Low-Rank Kalman Optimizer for Online Fine-Tuning of Large Models(https://arxiv.org/abs/2410.11551)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Training large models with millions or even billions of parameters from scratch incurs substantial computational costs. Parameter Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank Adaptation (LoRA), address this challenge by adapting only a reduced number of parameters to specific tasks with gradient-based optimizers. In this paper, we cast PEFT as an optimal filtering/state estimation problem and present Low-Rank Kalman Optimizer (LoKO) to estimate the optimal trainable parameters in an online manner. We leverage the low-rank decomposition in LoRA to significantly reduce matrix sizes in Kalman iterations and further capitalize on a diagonal approximation of the covariance matrix to effectively decrease computational complexity from quadratic to linear in the number of trainable parameters. Moreover, we discovered that the initialization of the covariance matrix within the Kalman algorithm and the accurate estimation of the observation noise covariance are the keys in this formulation, and we propose robust approaches that work well across a vast range of well-established computer vision and language models. Our results show that LoKO converges with fewer iterations and yields better performance models compared to commonly used optimizers with LoRA in both image classifications and language tasks. Our study opens up the possibility of leveraging the Kalman filter as an effective optimizer for the online fine-tuning of large models.</li>
</ul>

<h3>Title: Short Paper: Atomic Execution is Not Enough for Arbitrage Profit Extraction in Shared Sequencers</h3>
<ul>
<li><strong>Authors: </strong>Maria Inês Silva, Benjamin Livshits</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11552">https://arxiv.org/abs/2410.11552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11552">https://arxiv.org/pdf/2410.11552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11552]] Short Paper: Atomic Execution is Not Enough for Arbitrage Profit Extraction in Shared Sequencers(https://arxiv.org/abs/2410.11552)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>There has been a growing interest in shared sequencing solutions, in which transactions for multiple rollups are processed together. Their proponents argue that these solutions allow for better composability and can potentially increase sequencer revenue by enhancing MEV extraction. However, little research has been done on these claims, raising the question of understanding the actual impact of shared sequencing on arbitrage profits, the most common MEV strategy in rollups. To address this, we develop a model to assess arbitrage profits under atomic execution across two Constant Product Market Marker liquidity pools and demonstrate that switching to atomic execution does not always improve profits. We also discuss some scenarios where atomicity may lead to losses, offering insights into why atomic execution may not be enough to convince arbitrageurs and rollups to adopt shared sequencing.</li>
</ul>

<h3>Title: Why Go Full? Elevating Federated Learning Through Partial Network Updates</h3>
<ul>
<li><strong>Authors: </strong>Haolin Wang, Xuefeng Liu, Jianwei Niu, Wenkai Guo, Shaojie Tang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11559">https://arxiv.org/abs/2410.11559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11559">https://arxiv.org/pdf/2410.11559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11559]] Why Go Full? Elevating Federated Learning Through Partial Network Updates(https://arxiv.org/abs/2410.11559)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a distributed machine learning paradigm designed to protect user data privacy, which has been successfully implemented across various scenarios. In traditional federated learning, the entire parameter set of local models is updated and averaged in each training round. Although this full network update method maximizes knowledge acquisition and sharing for each model layer, it prevents the layers of the global model from cooperating effectively to complete the tasks of each client, a challenge we refer to as layer mismatch. This mismatch problem recurs after every parameter averaging, consequently slowing down model convergence and degrading overall performance. To address the layer mismatch issue, we introduce the FedPart method, which restricts model updates to either a single layer or a few layers during each communication round. Furthermore, to maintain the efficiency of knowledge acquisition and sharing, we develop several strategies to select trainable layers in each round, including sequential updating and multi-round cycle training. Through both theoretical analysis and experiments, our findings demonstrate that the FedPart method significantly surpasses conventional full network update strategies in terms of convergence speed and accuracy, while also reducing communication and computational overheads.</li>
</ul>

<h3>Title: PSVMA+: Exploring Multi-granularity Semantic-visual Adaption for Generalized Zero-shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Man Liu, Huihui Bai, Feng Li, Chunjie Zhang, Yunchao Wei, Meng Wang, Tat-Seng Chua, Yao Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11560">https://arxiv.org/abs/2410.11560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11560">https://arxiv.org/pdf/2410.11560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11560]] PSVMA+: Exploring Multi-granularity Semantic-visual Adaption for Generalized Zero-shot Learning(https://arxiv.org/abs/2410.11560)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Generalized zero-shot learning (GZSL) endeavors to identify the unseen categories using knowledge from the seen domain, necessitating the intrinsic interactions between the visual features and attribute semantic features. However, GZSL suffers from insufficient visual-semantic correspondences due to the attribute diversity and instance diversity. Attribute diversity refers to varying semantic granularity in attribute descriptions, ranging from low-level (specific, directly observable) to high-level (abstract, highly generic) characteristics. This diversity challenges the collection of adequate visual cues for attributes under a uni-granularity. Additionally, diverse visual instances corresponding to the same sharing attributes introduce semantic ambiguity, leading to vague visual patterns. To tackle these problems, we propose a multi-granularity progressive semantic-visual mutual adaption (PSVMA+) network, where sufficient visual elements across granularity levels can be gathered to remedy the granularity inconsistency. PSVMA+ explores semantic-visual interactions at different granularity levels, enabling awareness of multi-granularity in both visual and semantic elements. At each granularity level, the dual semantic-visual transformer module (DSVTM) recasts the sharing attributes into instance-centric attributes and aggregates the semantic-related visual regions, thereby learning unambiguous visual features to accommodate various instances. Given the diverse contributions of different granularities, PSVMA+ employs selective cross-granularity learning to leverage knowledge from reliable granularities and adaptively fuses multi-granularity features for comprehensive representations. Experimental results demonstrate that PSVMA+ consistently outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: Exploring Power Side-Channel Challenges in Embedded Systems Security</h3>
<ul>
<li><strong>Authors: </strong>Pouya Narimani, Meng Wang, Ulysse Planta, Ali Abbasi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11563">https://arxiv.org/abs/2410.11563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11563">https://arxiv.org/pdf/2410.11563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11563]] Exploring Power Side-Channel Challenges in Embedded Systems Security(https://arxiv.org/abs/2410.11563)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Power side-channel (PSC) attacks are widely used in embedded microcontrollers, particularly in cryptographic applications, to extract sensitive information. However, expanding the applications of PSC attacks to broader security contexts in the embedded systems domain faces significant challenges. These include the need for specialized hardware setups to manage high noise levels in real-world targets and assumptions regarding the attacker's knowledge and capabilities. This paper systematically analyzes these challenges and introduces a novel signal-processing method that addresses key limitations, enabling effective PSC attacks in real-world embedded systems without requiring hardware modifications. We validate the proposed approach through experiments on real-world black-box embedded devices, verifying its potential to expand its usage in various embedded systems security applications beyond traditional cryptographic applications.</li>
</ul>

<h3>Title: The Best of Both Worlds: On the Dilemma of Out-of-distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Qingyang Zhang, Qiuxuan Feng, Joey Tianyi Zhou, Yatao Bian, Qinghua Hu, Changqing Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11576">https://arxiv.org/abs/2410.11576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11576">https://arxiv.org/pdf/2410.11576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11576]] The Best of Both Worlds: On the Dilemma of Out-of-distribution Detection(https://arxiv.org/abs/2410.11576)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection is essential for model trustworthiness which aims to sensitively identify semantic OOD samples and robustly generalize for covariate-shifted OOD samples. However, we discover that the superior OOD detection performance of state-of-the-art methods is achieved by secretly sacrificing the OOD generalization ability. Specifically, the classification accuracy of these models could deteriorate dramatically when they encounter even minor noise. This phenomenon contradicts the goal of model trustworthiness and severely restricts their applicability in real-world scenarios. What is the hidden reason behind such a limitation? In this work, we theoretically demystify the ``\textit{sensitive-robust}'' dilemma that lies in many existing OOD detection methods. Consequently, a theory-inspired algorithm is induced to overcome such a dilemma. By decoupling the uncertainty learning objective from a Bayesian perspective, the conflict between OOD detection and OOD generalization is naturally harmonized and a dual-optimal performance could be expected. Empirical studies show that our method achieves superior performance on standard benchmarks. To our best knowledge, this work is the first principled OOD detection method that achieves state-of-the-art OOD detection performance without compromising OOD generalization ability. Our code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Andong Lu, Jiacong Zhao, Chenglong Li, Yun Xiao, Bin Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11586">https://arxiv.org/abs/2410.11586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11586">https://arxiv.org/pdf/2410.11586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11586]] Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation(https://arxiv.org/abs/2410.11586)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modality gap between RGB and thermal infrared (TIR) images is a crucial issue but often overlooked in existing RGBT tracking methods. It can be observed that modality gap mainly lies in the image style difference. In this work, we propose a novel Coupled Knowledge Distillation framework called CKD, which pursues common styles of different modalities to break modality gap, for high performance RGBT tracking. In particular, we introduce two student networks and employ the style distillation loss to make their style features consistent as much as possible. Through alleviating the style difference of two student networks, we can break modality gap of different modalities well. However, the distillation of style features might harm to the content representations of two modalities in student networks. To handle this issue, we take original RGB and TIR networks as the teachers, and distill their content knowledge into two student networks respectively by the style-content orthogonal feature decoupling scheme. We couple the above two distillation processes in an online optimization framework to form new feature representations of RGB and thermal modalities without modality gap. In addition, we design a masked modeling strategy and a multi-modal candidate token elimination strategy into CKD to improve tracking robustness and efficiency respectively. Extensive experiments on five standard RGBT tracking datasets validate the effectiveness of the proposed method against state-of-the-art methods while achieving the fastest tracking speed of 96.4 FPS. Code available at this https URL.</li>
</ul>

<h3>Title: Causal Reasoning in Large Language Models: A Knowledge Graph Approach</h3>
<ul>
<li><strong>Authors: </strong>Yejin Kim, Eojin Kang, Juae Kim, H. Howie Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11588">https://arxiv.org/abs/2410.11588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11588">https://arxiv.org/pdf/2410.11588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11588]] Causal Reasoning in Large Language Models: A Knowledge Graph Approach(https://arxiv.org/abs/2410.11588)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) typically improve performance by either retrieving semantically similar information, or enhancing reasoning abilities through structured prompts like chain-of-thought. While both strategies are considered crucial, it remains unclear which has a greater impact on model performance or whether a combination of both is necessary. This paper answers this question by proposing a knowledge graph (KG)-based random-walk reasoning approach that leverages causal relationships. We conduct experiments on the commonsense question answering task that is based on a KG. The KG inherently provides both relevant information, such as related entity keywords, and a reasoning structure through the connections between nodes. Experimental results show that the proposed KG-based random-walk reasoning method improves the reasoning ability and performance of LLMs. Interestingly, incorporating three seemingly irrelevant sentences into the query using KG-based random-walk reasoning enhances LLM performance, contrary to conventional wisdom. These findings suggest that integrating causal structures into prompts can significantly improve reasoning capabilities, providing new insights into the role of causality in optimizing LLM performance.</li>
</ul>

<h3>Title: Black-box Uncertainty Quantification Method for LLM-as-a-Judge</h3>
<ul>
<li><strong>Authors: </strong>Nico Wagner, Michael Desmond, Rahul Nair, Zahra Ashktorab, Elizabeth M. Daly, Qian Pan, Martín Santillán Cooper, James M. Johnson, Werner Geyer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11594">https://arxiv.org/abs/2410.11594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11594">https://arxiv.org/pdf/2410.11594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11594]] Black-box Uncertainty Quantification Method for LLM-as-a-Judge(https://arxiv.org/abs/2410.11594)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLM-as-a-Judge is a widely used method for evaluating the performance of Large Language Models (LLMs) across various tasks. We address the challenge of quantifying the uncertainty of LLM-as-a-Judge evaluations. While uncertainty quantification has been well-studied in other domains, applying it effectively to LLMs poses unique challenges due to their complex decision-making capabilities and computational demands. In this paper, we introduce a novel method for quantifying uncertainty designed to enhance the trustworthiness of LLM-as-a-Judge evaluations. The method quantifies uncertainty by analyzing the relationships between generated assessments and possible ratings. By cross-evaluating these relationships and constructing a confusion matrix based on token probabilities, the method derives labels of high or low uncertainty. We evaluate our method across multiple benchmarks, demonstrating a strong correlation between the accuracy of LLM evaluations and the derived uncertainty scores. Our findings suggest that this method can significantly improve the reliability and consistency of LLM-as-a-Judge evaluations.</li>
</ul>

<h3>Title: Depth Estimation From Monocular Images With Enhanced Encoder-Decoder Architecture</h3>
<ul>
<li><strong>Authors: </strong>Dabbrata Das, Argho Deb Das, Farhan Sadaf</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11610">https://arxiv.org/abs/2410.11610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11610">https://arxiv.org/pdf/2410.11610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11610]] Depth Estimation From Monocular Images With Enhanced Encoder-Decoder Architecture(https://arxiv.org/abs/2410.11610)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Estimating depth from a single 2D image is a challenging task because of the need for stereo or multi-view data, which normally provides depth information. This paper deals with this challenge by introducing a novel deep learning-based approach using an encoder-decoder architecture, where the Inception-ResNet-v2 model is utilized as the encoder. According to the available literature, this is the first instance of using Inception-ResNet-v2 as an encoder for monocular depth estimation, illustrating better performance than previous models. The use of Inception-ResNet-v2 enables our model to capture complex objects and fine-grained details effectively that are generally difficult to predict. Besides, our model incorporates multi-scale feature extraction to enhance depth prediction accuracy across different kinds of object sizes and distances. We propose a composite loss function consisting of depth loss, gradient edge loss, and SSIM loss, where the weights are fine-tuned to optimize the weighted sum, ensuring better balance across different aspects of depth estimation. Experimental results on the NYU Depth V2 dataset show that our model achieves state-of-the-art performance, with an ARE of 0.064, RMSE of 0.228, and accuracy ($\delta$ $<1.25$) of 89.3%. These metrics demonstrate that our model effectively predicts depth, even in challenging circumstances, providing a scalable solution for real-world applications in robotics, 3D reconstruction, and augmented reality.</li>
</ul>

<h3>Title: Federated Learning framework for LoRaWAN-enabled IIoT communication: A case study</h3>
<ul>
<li><strong>Authors: </strong>Oscar Torres Sanchez, Guilherme Borges, Duarte Raposo, André Rodrigues, Fernando Boavida, Jorge Sá Silva</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11612">https://arxiv.org/abs/2410.11612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11612">https://arxiv.org/pdf/2410.11612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11612]] Federated Learning framework for LoRaWAN-enabled IIoT communication: A case study(https://arxiv.org/abs/2410.11612)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>The development of intelligent Industrial Internet of Things (IIoT) systems promises to revolutionize operational and maintenance practices, driving improvements in operational efficiency. Anomaly detection within IIoT architectures plays a crucial role in preventive maintenance and spotting irregularities in industrial components. However, due to limited message and processing capacity, traditional Machine Learning (ML) faces challenges in deploying anomaly detection models in resource-constrained environments like LoRaWAN. On the other hand, Federated Learning (FL) solves this problem by enabling distributed model training, addressing privacy concerns, and minimizing data transmission. This study explores using FL for anomaly detection in industrial and civil construction machinery architectures that use IIoT prototypes with LoRaWAN communication. The process leverages an optimized autoencoder neural network structure and compares federated models with centralized ones. Despite uneven data distribution among machine clients, FL demonstrates effectiveness, with a mean F1 score (of 94.77), accuracy (of 92.30), TNR (of 90.65), and TPR (92.93), comparable to centralized models, considering airtime of trainning messages of 52.8 min. Local model evaluations on each machine highlight adaptability. At the same time, the performed analysis identifies message requirements, minimum training hours, and optimal round/epoch configurations for FL in LoRaWAN, guiding future implementations in constrained industrial environments.</li>
</ul>

<h3>Title: M$^{2}$M: Learning controllable Multi of experts and multi-scale operators are the Partial Differential Equations need</h3>
<ul>
<li><strong>Authors: </strong>Aoming Liang, Zhaoyang Mu, Pengxiao Lin, Cong Wang, Mingming Ge, Ling Shao, Dixia Fan, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11617">https://arxiv.org/abs/2410.11617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11617">https://arxiv.org/pdf/2410.11617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11617]] M$^{2}$M: Learning controllable Multi of experts and multi-scale operators are the Partial Differential Equations need(https://arxiv.org/abs/2410.11617)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Learning the evolutionary dynamics of Partial Differential Equations (PDEs) is critical in understanding dynamic systems, yet current methods insufficiently learn their representations. This is largely due to the multi-scale nature of the solution, where certain regions exhibit rapid oscillations while others evolve more slowly. This paper introduces a framework of multi-scale and multi-expert (M$^2$M) neural operators designed to simulate and learn PDEs efficiently. We employ a divide-and-conquer strategy to train a multi-expert gated network for the dynamic router policy. Our method incorporates a controllable prior gating mechanism that determines the selection rights of experts, enhancing the model's efficiency. To optimize the learning process, we have implemented a PI (Proportional, Integral) control strategy to adjust the allocation rules precisely. This universal controllable approach allows the model to achieve greater accuracy. We test our approach on benchmark 2D Navier-Stokes equations and provide a custom multi-scale dataset. M$^2$M can achieve higher simulation accuracy and offer improved interpretability compared to baseline methods.</li>
</ul>

<h3>Title: MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Reno Kriz, Kate Sanders, David Etter, Kenton Murray, Cameron Carpenter, Kelly Van Ochten, Hannah Recknor, Jimena Guallar-Blasco, Alexander Martin, Ronald Colaianni, Nolan King, Eugene Yang, Benjamin Van Durme</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11619">https://arxiv.org/abs/2410.11619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11619">https://arxiv.org/pdf/2410.11619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11619]] MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieval(https://arxiv.org/abs/2410.11619)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Efficiently retrieving and synthesizing information from large-scale multimodal collections has become a critical challenge. However, existing video retrieval datasets suffer from scope limitations, primarily focusing on matching descriptive but vague queries with small collections of professionally edited, English-centric videos. To address this gap, we introduce $\textbf{MultiVENT 2.0}$, a large-scale, multilingual event-centric video retrieval benchmark featuring a collection of more than 218,000 news videos and 3,906 queries targeting specific world events. These queries specifically target information found in the visual content, audio, embedded text, and text metadata of the videos, requiring systems leverage all these sources to succeed at the task. Preliminary results show that state-of-the-art vision-language models struggle significantly with this task, and while alternative approaches show promise, they are still insufficient to adequately address this problem. These findings underscore the need for more robust multimodal retrieval systems, as effective video retrieval is a crucial step towards multimodal content understanding and generation tasks.</li>
</ul>

<h3>Title: VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI</h3>
<ul>
<li><strong>Authors: </strong>Sijie Cheng, Kechen Fang, Yangyang Yu, Sicheng Zhou, Bohao Li, Ye Tian, Tingguang Li, Lei Han, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11623">https://arxiv.org/abs/2410.11623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11623">https://arxiv.org/pdf/2410.11623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11623]] VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI(https://arxiv.org/abs/2410.11623)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Multi-modal Large Language Models (MLLMs) have opened new avenues for applications in Embodied AI. Building on previous work, EgoThink, we introduce VidEgoThink, a comprehensive benchmark for evaluating egocentric video understanding capabilities. To bridge the gap between MLLMs and low-level control in Embodied AI, we design four key interrelated tasks: video question-answering, hierarchy planning, visual grounding and reward modeling. To minimize manual annotation costs, we develop an automatic data generation pipeline based on the Ego4D dataset, leveraging the prior knowledge and multimodal capabilities of GPT-4o. Three human annotators then filter the generated data to ensure diversity and quality, resulting in the VidEgoThink benchmark. We conduct extensive experiments with three types of models: API-based MLLMs, open-source image-based MLLMs, and open-source video-based MLLMs. Experimental results indicate that all MLLMs, including GPT-4o, perform poorly across all tasks related to egocentric video understanding. These findings suggest that foundation models still require significant advancements to be effectively applied to first-person scenarios in Embodied AI. In conclusion, VidEgoThink reflects a research trend towards employing MLLMs for egocentric vision, akin to human capabilities, enabling active observation and interaction in the complex real-world environments.</li>
</ul>

<h3>Title: Simultaneous Diffusion Sampling for Conditional LiDAR Generation</h3>
<ul>
<li><strong>Authors: </strong>Ryan Faulkner, Luke Haub, Simon Ratcliffe, Anh-Dzung Doan, Ian Reid, Tat-Jun Chin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11628">https://arxiv.org/abs/2410.11628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11628">https://arxiv.org/pdf/2410.11628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11628]] Simultaneous Diffusion Sampling for Conditional LiDAR Generation(https://arxiv.org/abs/2410.11628)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>By enabling capturing of 3D point clouds that reflect the geometry of the immediate environment, LiDAR has emerged as a primary sensor for autonomous systems. If a LiDAR scan is too sparse, occluded by obstacles, or too small in range, enhancing the point cloud scan by while respecting the geometry of the scene is useful for downstream tasks. Motivated by the explosive growth of interest in generative methods in vision, conditional LiDAR generation is starting to take off. This paper proposes a novel simultaneous diffusion sampling methodology to generate point clouds conditioned on the 3D structure of the scene as seen from multiple views. The key idea is to impose multi-view geometric constraints on the generation process, exploiting mutual information for enhanced results. Our method begins by recasting the input scan to multiple new viewpoints around the scan, thus creating multiple synthetic LiDAR scans. Then, the synthetic and input LiDAR scans simultaneously undergo conditional generation according to our methodology. Results show that our method can produce accurate and geometrically consistent enhancements to point cloud scans, allowing it to outperform existing methods by a large margin in a variety of benchmarks.</li>
</ul>

<h3>Title: Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models</h3>
<ul>
<li><strong>Authors: </strong>Fan Yang, Yihao Huang, Kailong Wang, Ling Shi, Geguang Pu, Yang Liu, Haoyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11639">https://arxiv.org/abs/2410.11639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11639">https://arxiv.org/pdf/2410.11639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11639]] Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models(https://arxiv.org/abs/2410.11639)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Vision-language pre-training (VLP) models, trained on large-scale image-text pairs, have become widely used across a variety of downstream vision-and-language (V+L) tasks. This widespread adoption raises concerns about their vulnerability to adversarial attacks. Non-universal adversarial attacks, while effective, are often impractical for real-time online applications due to their high computational demands per data instance. Recently, universal adversarial perturbations (UAPs) have been introduced as a solution, but existing generator-based UAP methods are significantly time-consuming. To overcome the limitation, we propose a direct optimization-based UAP approach, termed DO-UAP, which significantly reduces resource consumption while maintaining high attack performance. Specifically, we explore the necessity of multimodal loss design and introduce a useful data augmentation strategy. Extensive experiments conducted on three benchmark VLP datasets, six popular VLP models, and three classical downstream tasks demonstrate the efficiency and effectiveness of DO-UAP. Specifically, our approach drastically decreases the time consumption by 23-fold while achieving a better attack performance.</li>
</ul>

<h3>Title: Feature-guided score diffusion for sampling conditional densities</h3>
<ul>
<li><strong>Authors: </strong>Zahra Kadkhodaie, Stéphane Mallat, Eero P. Simoncelli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11646">https://arxiv.org/abs/2410.11646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11646">https://arxiv.org/pdf/2410.11646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11646]] Feature-guided score diffusion for sampling conditional densities(https://arxiv.org/abs/2410.11646)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Score diffusion methods can learn probability densities from samples. The score of the noise-corrupted density is estimated using a deep neural network, which is then used to iteratively transport a Gaussian white noise density to a target density. Variants for conditional densities have been developed, but correct estimation of the corresponding scores is difficult. We avoid these difficulties by introducing an algorithm that guides the diffusion with a projected score. The projection pushes the image feature vector towards the feature vector centroid of the target class. The projected score and the feature vectors are learned by the same network. Specifically, the image feature vector is defined as the spatial averages of the channels activations in select layers of the network. Optimizing the projected score for denoising loss encourages image feature vectors of each class to cluster around their centroids. It also leads to the separations of the centroids. We show that these centroids provide a low-dimensional Euclidean embedding of the class conditional densities. We demonstrate that the algorithm can generate high quality and diverse samples from the conditioning class. Conditional generation can be performed using feature vectors interpolated between those of the training set, demonstrating out-of-distribution generalization.</li>
</ul>

<h3>Title: Measuring Spiritual Values and Bias of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Songyuan Liu, Ziyang Zhang, Runze Yan, Wei Wu, Carl Yang, Jiaying Lu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11647">https://arxiv.org/abs/2410.11647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11647">https://arxiv.org/pdf/2410.11647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11647]] Measuring Spiritual Values and Bias of Large Language Models(https://arxiv.org/abs/2410.11647)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become integral tool for users from various backgrounds. LLMs, trained on vast corpora, reflect the linguistic and cultural nuances embedded in their pre-training data. However, the values and perspectives inherent in this data can influence the behavior of LLMs, leading to potential biases. As a result, the use of LLMs in contexts involving spiritual or moral values necessitates careful consideration of these underlying biases. Our work starts with verification of our hypothesis by testing the spiritual values of popular LLMs. Experimental results show that LLMs' spiritual values are quite diverse, as opposed to the stereotype of atheists or secularists. We then investigate how different spiritual values affect LLMs in social-fairness scenarios e.g., hate speech identification). Our findings reveal that different spiritual values indeed lead to different sensitivity to different hate target groups. Furthermore, we propose to continue pre-training LLMs on spiritual texts, and empirical results demonstrate the effectiveness of this approach in mitigating spiritual bias.</li>
</ul>

<h3>Title: ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Xiang Liu, Yijun Song, Xia Li, Yifei Sun, Huiying Lan, Zemin Liu, Linshan Jiang, Jialin Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11650">https://arxiv.org/abs/2410.11650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11650">https://arxiv.org/pdf/2410.11650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11650]] ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices(https://arxiv.org/abs/2410.11650)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning models are increasingly deployed on resource-constrained edge devices for real-time data analytics. In recent years, Vision Transformer models and their variants have demonstrated outstanding performance across various computer vision tasks. However, their high computational demands and inference latency pose significant challenges for model deployment on resource-constraint edge devices. To address this issue, we propose a novel Vision Transformer splitting framework, ED-ViT, designed to execute complex models across multiple edge devices efficiently. Specifically, we partition Vision Transformer models into several sub-models, where each sub-model is tailored to handle a specific subset of data classes. To further minimize computation overhead and inference latency, we introduce a class-wise pruning technique that reduces the size of each sub-model. We conduct extensive experiments on five datasets with three model structures, demonstrating that our approach significantly reduces inference latency on edge devices and achieves a model size reduction of up to 28.9 times and 34.1 times, respectively, while maintaining test accuracy comparable to the original Vision Transformer. Additionally, we compare ED-ViT with two state-of-the-art methods that deploy CNN and SNN models on edge devices, evaluating accuracy, inference time, and overall model size. Our comprehensive evaluation underscores the effectiveness of the proposed ED-ViT framework.</li>
</ul>

<h3>Title: RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping</h3>
<ul>
<li><strong>Authors: </strong>Chiyi Huang, Longwei Sun, Dong Liang, Haifeng Liang, Hongwu Zeng, Yanjie Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11651">https://arxiv.org/abs/2410.11651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11651">https://arxiv.org/pdf/2410.11651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11651]] RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping(https://arxiv.org/abs/2410.11651)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Cardiac T1 mapping can evaluate various clinical symptoms of myocardial tissue. However, there is currently a lack of effective, robust, and efficient methods for motion correction in cardiac T1 mapping. In this paper, we propose a deep learning-based and topology-preserving image registration framework for motion correction in cardiac T1 mapping. Notably, our proposed implicit consistency constraint dubbed BLOC, to some extent preserves the image topology in registration by bidirectional consistency constraint and local anti-folding constraint. To address the contrast variation issue, we introduce a weighted image similarity metric for multimodal registration of cardiac T1-weighted images. Besides, a semi-supervised myocardium segmentation network and a dual-domain attention module are integrated into the framework to further improve the performance of the registration. Numerous comparative experiments, as well as ablation studies, demonstrated the effectiveness and high robustness of our method. The results also indicate that the proposed weighted image similarity metric, specifically crafted for our network, contributes a lot to the enhancement of the motion correction efficacy, while the bidirectional consistency constraint combined with the local anti-folding constraint ensures a more desirable topology-preserving registration mapping.</li>
</ul>

<h3>Title: Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>James Vo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11654">https://arxiv.org/abs/2410.11654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11654">https://arxiv.org/pdf/2410.11654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11654]] Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models(https://arxiv.org/abs/2410.11654)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we propose Transformer Layer Injection (TLI), a novel method for efficiently upscaling large language models (LLMs) while minimizing computational costs and maintaining model performance. Model scale is a key factor in enhancing the quality of machine learning models, and TLI addresses the challenge of scaling by reducing initial loss, minimizing fine-tuning requirements, and preserving model complexity. Our approach improves upon the conventional Depth Up-Scaling (DUS) technique by injecting new layers into every set of K layers, enabling hidden representations to pass through transformer blocks with minimal disruption. We compare TLI with existing approaches, including Mixture of Experts (MoE) and DUS, and validate its efficiency through experiments on small LLMs (LLama3 1B, 3B, and 8B). Results show that TLI achieves better initialization, requires fewer training steps, and delivers superior accuracy on tasks such as KoBEST and KMCQA, with models performing effectively even without additional training. TLI is demonstrated to be both data-efficient and cost-effective, significantly outperforming existing methods. Its scalability and simplicity make it a promising solution for upscaling transformer-based models, with potential applications in scaling models from 10B to 405B parameters.</li>
</ul>

<h3>Title: Retrieval Augmented Spelling Correction for E-Commerce Applications</h3>
<ul>
<li><strong>Authors: </strong>Xuan Guo, Rohit Patki, Dante Everaert, Christopher Potts</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11655">https://arxiv.org/abs/2410.11655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11655">https://arxiv.org/pdf/2410.11655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11655]] Retrieval Augmented Spelling Correction for E-Commerce Applications(https://arxiv.org/abs/2410.11655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid introduction of new brand names into everyday language poses a unique challenge for e-commerce spelling correction services, which must distinguish genuine misspellings from novel brand names that use unconventional spelling. We seek to address this challenge via Retrieval Augmented Generation (RAG). On this approach, product names are retrieved from a catalog and incorporated into the context used by a large language model (LLM) that has been fine-tuned to do contextual spelling correction. Through quantitative evaluation and qualitative error analyses, we find improvements in spelling correction utilizing the RAG framework beyond a stand-alone LLM. We also demonstrate the value of additional finetuning of the LLM to incorporate retrieved context.</li>
</ul>

<h3>Title: Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories</h3>
<ul>
<li><strong>Authors: </strong>Tarun Tater, Sabine Schulte im Walde, Diego Frassinelli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11657">https://arxiv.org/abs/2410.11657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11657">https://arxiv.org/pdf/2410.11657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11657]] Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories(https://arxiv.org/abs/2410.11657)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The visual representation of a concept varies significantly depending on its meaning and the context where it occurs; this poses multiple challenges both for vision and multimodal models. Our study focuses on concreteness, a well-researched lexical-semantic variable, using it as a case study to examine the variability in visual representations. We rely on images associated with approximately 1,000 abstract and concrete concepts extracted from two different datasets: Bing and YFCC. Our goals are: (i) evaluate whether visual diversity in the depiction of concepts can reliably distinguish between concrete and abstract concepts; (ii) analyze the variability of visual features across multiple images of the same concept through a nearest neighbor analysis; and (iii) identify challenging factors contributing to this variability by categorizing and annotating images. Our findings indicate that for classifying images of abstract versus concrete concepts, a combination of basic visual features such as color and texture is more effective than features extracted by more complex models like Vision Transformer (ViT). However, ViTs show better performances in the nearest neighbor analysis, emphasizing the need for a careful selection of visual features when analyzing conceptual variables through modalities other than text.</li>
</ul>

<h3>Title: Eliciting Textual Descriptions from Representations of Continuous Prompts</h3>
<ul>
<li><strong>Authors: </strong>Dana Ramati, Daniela Gottesman, Mor Geva</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11660">https://arxiv.org/abs/2410.11660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11660">https://arxiv.org/pdf/2410.11660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11660]] Eliciting Textual Descriptions from Representations of Continuous Prompts(https://arxiv.org/abs/2410.11660)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Continuous prompts, or "soft prompts", are a widely-adopted parameter-efficient tuning strategy for large language models, but are often less favorable due to their opaque nature. Prior attempts to interpret continuous prompts relied on projecting individual prompt tokens onto the vocabulary space. However, this approach is problematic as performant prompts can yield arbitrary or contradictory text, and it interprets prompt tokens individually. In this work, we propose a new approach to interpret continuous prompts that elicits textual descriptions from their representations during model inference. Using a Patchscopes variant (Ghandeharioun et al., 2024) called InSPEcT over various tasks, we show our method often yields accurate task descriptions which become more faithful as task performance increases. Moreover, an elaborated version of InSPEcT reveals biased features in continuous prompts, whose presence correlates with biased model predictions. Providing an effective interpretability solution, InSPEcT can be leveraged to debug unwanted properties in continuous prompts and inform developers on ways to mitigate them.</li>
</ul>

<h3>Title: Generative Image Steganography Based on Point Cloud</h3>
<ul>
<li><strong>Authors: </strong>Zhong Yangjie, Liu Jia, Liu Meiqi, Ke Yan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11673">https://arxiv.org/abs/2410.11673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11673">https://arxiv.org/pdf/2410.11673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11673]] Generative Image Steganography Based on Point Cloud(https://arxiv.org/abs/2410.11673)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>In deep steganography, the model size is usually related to the underlying mesh resolution, and a separate neural network needs to be trained as a message extractor. In this paper, we propose a generative image steganography based on point cloud representation, which represents image data as a point cloud, learns the distribution of the point cloud data, and represents it in the form of a continuous function. This method breaks through the limitation of the image resolution, and can generate images with arbitrary resolution according to the actual need, and omits the need for explicit data for image steganography. At the same time, using a fixed point cloud extractor transfers the training of the network to the point cloud data, which saves the training time and avoids the risk of exposing the steganography behavior caused by the transmission of the message extractor. Experiments prove that the steganographic images generated by the scheme have very high image quality and the accuracy of message extraction reaches more than 99%.</li>
</ul>

<h3>Title: LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Md Kowsher, Md. Shohanur Islam Sobuj, Nusrat Jahan Prottasha, E. Alejandro Alanis, Ozlem Ozmen Garibay, Niloofar Yousefi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11674">https://arxiv.org/abs/2410.11674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11674">https://arxiv.org/pdf/2410.11674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11674]] LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting(https://arxiv.org/abs/2410.11674)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Time series forecasting remains a challenging task, particularly in the context of complex multiscale temporal patterns. This study presents LLM-Mixer, a framework that improves forecasting accuracy through the combination of multiscale time-series decomposition with pre-trained LLMs (Large Language Models). LLM-Mixer captures both short-term fluctuations and long-term trends by decomposing the data into multiple temporal resolutions and processing them with a frozen LLM, guided by a textual prompt specifically designed for time-series data. Extensive experiments conducted on multivariate and univariate datasets demonstrate that LLM-Mixer achieves competitive performance, outperforming recent state-of-the-art models across various forecasting horizons. This work highlights the potential of combining multiscale analysis and LLMs for effective and scalable time-series forecasting.</li>
</ul>

<h3>Title: State-space models can learn in-context by gradient descent</h3>
<ul>
<li><strong>Authors: </strong>Neeraj Mohan Sushma, Yudou Tian, Harshvardhan Mestha, Nicolo Colombo, David Kappel, Anand Subramoney</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11687">https://arxiv.org/abs/2410.11687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11687">https://arxiv.org/pdf/2410.11687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11687]] State-space models can learn in-context by gradient descent(https://arxiv.org/abs/2410.11687)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep state-space models (Deep SSMs) have shown capabilities for in-context learning on autoregressive tasks, similar to transformers. However, the architectural requirements and mechanisms enabling this in recurrent networks remain unclear. This study demonstrates that state-space model architectures can perform gradient-based learning and use it for in-context learning. We prove that a single structured state-space model layer, augmented with local self-attention, can reproduce the outputs of an implicit linear model with least squares loss after one step of gradient descent. Our key insight is that the diagonal linear recurrent layer can act as a gradient accumulator, which can be `applied' to the parameters of the implicit regression model. We validate our construction by training randomly initialized augmented SSMs on simple linear regression tasks. The empirically optimized parameters match the theoretical ones, obtained analytically from the implicit model construction. Extensions to multi-step linear and non-linear regression yield consistent results. The constructed SSM encompasses features of modern deep state-space models, with the potential for scalable training and effectiveness even in general tasks. The theoretical construction elucidates the role of local self-attention and multiplicative interactions in recurrent architectures as the key ingredients for enabling the expressive power typical of foundation models.</li>
</ul>

<h3>Title: Visual Fixation-Based Retinal Prosthetic Simulation</h3>
<ul>
<li><strong>Authors: </strong>Yuli Wu, Do Dinh Tan Nguyen, Henning Konermann, Rüveyda Yilmaz, Peter Walter, Johannes Stegmaier</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11688">https://arxiv.org/abs/2410.11688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11688">https://arxiv.org/pdf/2410.11688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11688]] Visual Fixation-Based Retinal Prosthetic Simulation(https://arxiv.org/abs/2410.11688)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study proposes a retinal prosthetic simulation framework driven by visual fixations, inspired by the saccade mechanism, and assesses performance improvements through end-to-end optimization in a classification task. Salient patches are predicted from input images using the self-attention map of a vision transformer to mimic visual fixations. These patches are then encoded by a trainable U-Net and simulated using the pulse2percept framework to predict visual percepts. By incorporating a learnable encoder, we aim to optimize the visual information transmitted to the retinal implant, addressing both the limited resolution of the electrode array and the distortion between the input stimuli and resulting phosphenes. The predicted percepts are evaluated using the self-supervised DINOv2 foundation model, with an optional learnable linear layer for classification accuracy. On a subset of the ImageNet validation set, the fixation-based framework achieves a classification accuracy of 87.72%, using computational parameters based on a real subject's physiological data, significantly outperforming the downsampling-based accuracy of 40.59% and approaching the healthy upper bound of 92.76%. Our approach shows promising potential for producing more semantically understandable percepts with the limited resolution available in retinal prosthetics.</li>
</ul>

<h3>Title: BlendRL: A Framework for Merging Symbolic and Neural Policy Learning</h3>
<ul>
<li><strong>Authors: </strong>Hikaru Shindo, Quentin Delfosse, Devendra Singh Dhami, Kristian Kersting</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11689">https://arxiv.org/abs/2410.11689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11689">https://arxiv.org/pdf/2410.11689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11689]] BlendRL: A Framework for Merging Symbolic and Neural Policy Learning(https://arxiv.org/abs/2410.11689)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Humans can leverage both symbolic reasoning and intuitive reactions. In contrast, reinforcement learning policies are typically encoded in either opaque systems like neural networks or symbolic systems that rely on predefined symbols and rules. This disjointed approach severely limits the agents' capabilities, as they often lack either the flexible low-level reaction characteristic of neural agents or the interpretable reasoning of symbolic agents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL framework that harmoniously integrates both paradigms within RL agents that use mixtures of both logic and neural policies. We empirically demonstrate that BlendRL agents outperform both neural and symbolic baselines in standard Atari environments, and showcase their robustness to environmental changes. Additionally, we analyze the interaction between neural and symbolic policies, illustrating how their hybrid use helps agents overcome each other's limitations.</li>
</ul>

<h3>Title: IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual MT</h3>
<ul>
<li><strong>Authors: </strong>Seung-Woo Choi, Ga-Hyun Yoo, Jay-Yoon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11693">https://arxiv.org/abs/2410.11693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11693">https://arxiv.org/pdf/2410.11693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11693]] IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual MT(https://arxiv.org/abs/2410.11693)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent Large Language Models (LLMs) have demonstrated strong performance in translation without needing to be finetuned on additional parallel corpora. However, they still underperform for low-resource language pairs. Previous works have focused on mitigating this issue by leveraging relevant few-shot examples or external resources such as dictionaries or grammar books, making models heavily reliant on these nonparametric sources of information. In this paper, we propose a novel method named IntGrad MT that focuses on fully exploiting an LLM's inherent translation capability. IntGrad MT achieves this by constructing a chain of few-shot examples, each consisting of a source sentence and the model's own translation, that rise incrementally in difficulty. IntGrad MT employs two techniques: Sentence Interpolation, which generates a sequence of sentences that gradually change from an easy sentence to translate to a difficult one, and Gradual MT, which sequentially translates this chain using translations of earlier sentences as few-shot examples for the translation of subsequent ones. With this approach, we observe a substantial enhancement in the xCOMET scores of various LLMs for multiple languages, especially in low-resource languages such as Hindi(8.26), Swahili(7.10), Bengali(6.97) and Marathi(13.03). Our approach presents a practical way of enhancing LLMs' performance without extra training.</li>
</ul>

<h3>Title: Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions</h3>
<ul>
<li><strong>Authors: </strong>Yuhan Fu, Ruobing Xie, Jiazhen Liu, Bangxiang Lan, Xingwu Sun, Zhanhui Kang, Xirong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11701">https://arxiv.org/abs/2410.11701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11701">https://arxiv.org/pdf/2410.11701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11701]] Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions(https://arxiv.org/abs/2410.11701)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Hallucinations in multimodal large language models (MLLMs) hinder their practical applications. To address this, we propose a Magnifier Prompt (MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs via extremely simple instructions. MagPrompt is based on the following two key principles, which guide the design of various effective prompts, demonstrating robustness: (1) MLLMs should focus more on the image. (2) When there are conflicts between the image and the model's inner knowledge, MLLMs should prioritize the image. MagPrompt is training-free and can be applied to open-source and closed-source models, such as GPT-4o and Gemini-pro. It performs well across many datasets and its effectiveness is comparable or even better than more complex methods like VCD. Furthermore, our prompt design principles and experimental analyses provide valuable insights into multimodal hallucination.</li>
</ul>

<h3>Title: The Age of DDoScovery: An Empirical Comparison of Industry and Academic DDoS Assessments</h3>
<ul>
<li><strong>Authors: </strong>Raphael Hiesgen, Marcin Nawrocki, Marinho Barcellos, Daniel Kopp, Oliver Hohlfeld, Echo Chan, Roland Dobbins, Christian Doerr, Christian Rossow, Daniel R. Thomas, Mattijs Jonker, Ricky Mok, Xiapu Luo, John Kristoff, Thomas C. Schmidt, Matthias Wählisch, kc claffy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11708">https://arxiv.org/abs/2410.11708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11708">https://arxiv.org/pdf/2410.11708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11708]] The Age of DDoScovery: An Empirical Comparison of Industry and Academic DDoS Assessments(https://arxiv.org/abs/2410.11708)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Motivated by the impressive but diffuse scope of DDoS research and reporting, we undertake a multistakeholder (joint industry-academic) analysis to seek convergence across the best available macroscopic views of the relative trends in two dominant classes of attacks - direct-path attacks and reflection-amplification attacks. We first analyze 24 industry reports to extract trends and (in)consistencies across observations by commercial stakeholders in 2022. We then analyze ten data sets spanning industry and academic sources, across four years (2019-2023), to find and explain discrepancies based on data sources, vantage points, methods, and parameters. Our method includes a new approach: we share an aggregated list of DDoS targets with industry players who return the results of joining this list with their proprietary data sources to reveal gaps in visibility of the academic data sources. We use academic data sources to explore an industry-reported relative drop in spoofed reflection-amplification attacks in 2021-2022. Our study illustrates the value, but also the challenge, in independent validation of security-related properties of Internet infrastructure. Finally, we reflect on opportunities to facilitate greater common understanding of the DDoS landscape. We hope our results inform not only future academic and industry pursuits but also emerging policy efforts to reduce systemic Internet security vulnerabilities.</li>
</ul>

<h3>Title: MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pei Wang, Yanan Wu, Zekun Wang, Jiaheng Liu, Xiaoshuai Song, Zhongyuan Peng, Ken Deng, Chenchen Zhang, Jiakai Wang, Junran Peng, Ge Zhang, Hangyu Guo, Zhaoxiang Zhang, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11710">https://arxiv.org/abs/2410.11710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11710">https://arxiv.org/pdf/2410.11710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11710]] MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models(https://arxiv.org/abs/2410.11710)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Recently, many tool-use benchmark datasets have been proposed. However, existing datasets have the following limitations: (1). Insufficient evaluation scenarios (e.g., only cover limited tool-use scenes). (2). Extensive evaluation costs (e.g., GPT API costs). To address these limitations, in this work, we propose a multi-granularity tool-use benchmark for large language models called MTU-Bench. For the "multi-granularity" property, our MTU-Bench covers five tool usage scenes (i.e., single-turn and single-tool, single-turn and multiple-tool, multiple-turn and single-tool, multiple-turn and multiple-tool, and out-of-distribution tasks). Besides, all evaluation metrics of our MTU-Bench are based on the prediction results and the ground truth without using any GPT or human evaluation metrics. Moreover, our MTU-Bench is collected by transforming existing high-quality datasets to simulate real-world tool usage scenarios, and we also propose an instruction dataset called MTU-Instruct data to enhance the tool-use abilities of existing LLMs. Comprehensive experimental results demonstrate the effectiveness of our MTU-Bench. Code and data will be released at https: //github.com/MTU-Bench-Team/MTUthis http URL.</li>
</ul>

<h3>Title: Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongchuan Zeng, Senyu Han, Lu Chen, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11718">https://arxiv.org/abs/2410.11718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11718">https://arxiv.org/pdf/2410.11718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11718]] Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models(https://arxiv.org/abs/2410.11718)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable performance, particularly in multilingual contexts. While recent studies suggest that LLMs can transfer skills learned in one language to others, the internal mechanisms behind this ability remain unclear. We observed that the neuron activation patterns of LLMs exhibit similarities when processing the same language, revealing the existence and location of key linguistic regions. Additionally, we found that neuron activation patterns are similar when processing sentences with the same semantic meaning in different languages. This indicates that LLMs map semantically identical inputs from different languages into a "Lingua Franca", a common semantic latent space that allows for consistent processing across languages. This semantic alignment becomes more pronounced with training and increased model size, resulting in a more language-agnostic activation pattern. Moreover, we found that key linguistic neurons are concentrated in the first and last layers of LLMs, becoming denser in the first layers as training progresses. Experiments on BLOOM and LLaMA2 support these findings, highlighting the structural evolution of multilingual LLMs during training and scaling up. This paper provides insights into the internal workings of LLMs, offering a foundation for future improvements in their cross-lingual capabilities.</li>
</ul>

<h3>Title: RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Anton Antonov, Andrey Moskalenko, Denis Shepelev, Alexander Krapukhin, Konstantin Soshin, Anton Konushin, Vlad Shakhuro</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11722">https://arxiv.org/abs/2410.11722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11722">https://arxiv.org/pdf/2410.11722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11722]] RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation(https://arxiv.org/abs/2410.11722)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The emergence of Segment Anything (SAM) sparked research interest in the field of interactive segmentation, especially in the context of image editing tasks and speeding up data annotation. Unlike common semantic segmentation, interactive segmentation methods allow users to directly influence their output through prompts (e.g. clicks). However, click patterns in real-world interactive segmentation scenarios remain largely unexplored. Most methods rely on the assumption that users would click in the center of the largest erroneous area. Nevertheless, recent studies show that this is not always the case. Thus, methods may have poor performance in real-world deployment despite high metrics in a baseline benchmark. To accurately simulate real-user clicks, we conducted a large crowdsourcing study of click patterns in an interactive segmentation scenario and collected 475K real-user clicks. Drawing on ideas from saliency tasks, we develop a clickability model that enables sampling clicks, which closely resemble actual user inputs. Using our model and dataset, we propose RClicks benchmark for a comprehensive comparison of existing interactive segmentation methods on realistic clicks. Specifically, we evaluate not only the average quality of methods, but also the robustness w.r.t. click patterns. According to our benchmark, in real-world usage interactive segmentation models may perform worse than it has been reported in the baseline benchmark, and most of the methods are not robust. We believe that RClicks is a significant step towards creating interactive segmentation methods that provide the best user experience in real-world cases.</li>
</ul>

<h3>Title: Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems</h3>
<ul>
<li><strong>Authors: </strong>Jason Hu, Bowen Song, Jeffrey A. Fessler, Liyue Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11730">https://arxiv.org/abs/2410.11730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11730">https://arxiv.org/pdf/2410.11730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11730]] Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems(https://arxiv.org/abs/2410.11730)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved excellent success in solving inverse problems due to their ability to learn strong image priors, but existing approaches require a large training dataset of images that should come from the same distribution as the test dataset. When the training and test distributions are mismatched, artifacts and hallucinations can occur in reconstructed images due to the incorrect priors. In this work, we systematically study out of distribution (OOD) problems where a known training distribution is first provided. We first study the setting where only a single measurement obtained from the unknown test distribution is available. Next we study the setting where a very small sample of data belonging to the test distribution is available, and our goal is still to reconstruct an image from a measurement that came from the test distribution. In both settings, we use a patch-based diffusion prior that learns the image distribution solely from patches. Furthermore, in the first setting, we include a self-supervised loss that helps the network output maintain consistency with the measurement. Extensive experiments show that in both settings, the patch-based method can obtain high quality image reconstructions that can outperform whole-image models and can compete with methods that have access to large in-distribution training datasets. Furthermore, we show how whole-image models are prone to memorization and overfitting, leading to artifacts in the reconstructions, while a patch-based model can resolve these issues.</li>
</ul>

<h3>Title: DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure</h3>
<ul>
<li><strong>Authors: </strong>Yunfan Xiong, Ruoyu Zhang, Yanzeng Li, Tianhao Wu, Lei Zou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11744">https://arxiv.org/abs/2410.11744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11744">https://arxiv.org/pdf/2410.11744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11744]] DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure(https://arxiv.org/abs/2410.11744)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While speculative decoding has recently appeared as a promising direction for accelerating the inference of large language models (LLMs), the speedup and scalability are strongly bounded by the token acceptance rate. Prevalent methods usually organize predicted tokens as independent chains or fixed token trees, which fails to generalize to diverse query distributions. In this paper, we propose DySpec, a faster speculative decoding algorithm with a novel dynamic token tree structure. We begin by bridging the draft distribution and acceptance rate from intuitive and empirical clues, and successfully show that the two variables are strongly correlated. Based on this, we employ a greedy strategy to dynamically expand the token tree at run time. Theoretically, we show that our method can achieve optimal results under mild assumptions. Empirically, DySpec yields a higher acceptance rate and speedup than fixed trees. DySpec can drastically improve the throughput and reduce the latency of token generation across various data distribution and model sizes, which significantly outperforms strong competitors, including Specinfer and Sequoia. Under low temperature setting, DySpec can improve the throughput up to 9.1$\times$ and reduce the latency up to 9.4$\times$ on Llama2-70B. Under high temperature setting, DySpec can also improve the throughput up to 6.21$\times$, despite the increasing difficulty of speculating more than one token per step for draft model.</li>
</ul>

<h3>Title: Personas with Attitudes: Controlling LLMs for Diverse Data Annotation</h3>
<ul>
<li><strong>Authors: </strong>Leon Fröhling, Gianluca Demartini, Dennis Assenmacher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11745">https://arxiv.org/abs/2410.11745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11745">https://arxiv.org/pdf/2410.11745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11745]] Personas with Attitudes: Controlling LLMs for Diverse Data Annotation(https://arxiv.org/abs/2410.11745)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a novel approach for enhancing diversity and control in data annotation tasks by personalizing large language models (LLMs). We investigate the impact of injecting diverse persona descriptions into LLM prompts across two studies, exploring whether personas increase annotation diversity and whether the impacts of individual personas on the resulting annotations are consistent and controllable. Our results show that persona-prompted LLMs produce more diverse annotations than LLMs prompted without personas and that these effects are both controllable and repeatable, making our approach a suitable tool for improving data annotation in subjective NLP tasks like toxicity detection.</li>
</ul>

<h3>Title: LoSAM: Local Search in Additive Noise Models with Unmeasured Confounders, a Top-Down Global Discovery Approach</h3>
<ul>
<li><strong>Authors: </strong>Sujai Hiremath, Kyra Gan, Promit Ghosal</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11759">https://arxiv.org/abs/2410.11759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11759">https://arxiv.org/pdf/2410.11759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11759]] LoSAM: Local Search in Additive Noise Models with Unmeasured Confounders, a Top-Down Global Discovery Approach(https://arxiv.org/abs/2410.11759)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We address the challenge of causal discovery in structural equation models with additive noise without imposing additional assumptions on the underlying data-generating process. We introduce local search in additive noise model (LoSAM), which generalizes an existing nonlinear method that leverages local causal substructures to the general additive noise setting, allowing for both linear and nonlinear causal mechanisms. We show that LoSAM achieves polynomial runtime, and improves runtime and efficiency by exploiting new substructures to minimize the conditioning set at each step. Further, we introduce a variant of LoSAM, LoSAM-UC, that is robust to unmeasured confounding among roots, a property that is often not satisfied by functional-causal-model-based methods. We numerically demonstrate the utility of LoSAM, showing that it outperforms existing benchmarks.</li>
</ul>

<h3>Title: SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding</h3>
<ul>
<li><strong>Authors: </strong>Ying Chen, Guoan Wang, Yuanfeng Ji, Yanjun Li, Jin Ye, Tianbin Li, Bin Zhang, Nana Pei, Rongshan Yu, Yu Qiao, Junjun He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11761">https://arxiv.org/abs/2410.11761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11761">https://arxiv.org/pdf/2410.11761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11761]] SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding(https://arxiv.org/abs/2410.11761)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level. The lack of large-scale instruction datasets and the gigapixel scale of whole slide images (WSIs) pose significant developmental challenges. In this paper, we present SlideChat, the first vision-language assistant capable of understanding gigapixel whole-slide images, exhibiting excellent multimodal conversational capability and response complex instruction across diverse pathology scenarios. To support its development, we created SlideInstruction, the largest instruction-following dataset for WSIs consisting of 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore, we propose SlideBench, a multimodal benchmark that incorporates captioning and VQA tasks to assess SlideChat's capabilities in varied clinical settings such as microscopy, diagnosis. Compared to both general and specialized MLLMs, SlideChat exhibits exceptional capabilities achieving state-of-the-art performance on 18 of 22 tasks. For example, it achieved an overall accuracy of 81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). We will fully release SlideChat, SlideInstruction and SlideBench as open-source resources to facilitate research and development in computational pathology.</li>
</ul>

<h3>Title: Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kai Yao, Penlei Gao, Lichun Li, Yuan Zhao, Xiaofeng Wang, Wei Wang, Jianke Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11772">https://arxiv.org/abs/2410.11772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11772">https://arxiv.org/pdf/2410.11772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11772]] Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models(https://arxiv.org/abs/2410.11772)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant popularity for adapting pre-trained Large Language Models (LLMs) to downstream tasks, primarily due to their potential to significantly reduce memory and computational overheads. However, a common limitation in most PEFT approaches is their application of a uniform architectural design across all layers. This uniformity involves identical trainable modules and ignores the varying importance of each layer, leading to sub-optimal fine-tuning results. To overcome the above limitation and obtain better performance, we develop a novel approach, Importance-aware Sparse Tuning (IST), to fully utilize the inherent sparsity and select the most important subset of full layers with effective layer-wise importance scoring. The proposed IST is a versatile and plug-and-play technique compatible with various PEFT methods that operate on a per-layer basis. By leveraging the estimated importance scores, IST dynamically updates these selected layers in PEFT modules, leading to reduced memory demands. We further provide theoretical proof of convergence and empirical evidence of superior performance to demonstrate the advantages of IST over uniform updating strategies. Extensive experiments on a range of LLMs, PEFTs, and downstream tasks substantiate the effectiveness of our proposed method, showcasing IST's capacity to enhance existing layer-based PEFT methods. Our code is available at this https URL.</li>
</ul>

<h3>Title: Fractal Calibration for long-tailed object detection</h3>
<ul>
<li><strong>Authors: </strong>Konstantinos Panagiotis Alexandridis, Ismail Elezi, Jiankang Deng, Anh Nguyen, Shan Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11774">https://arxiv.org/abs/2410.11774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11774">https://arxiv.org/pdf/2410.11774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11774]] Fractal Calibration for long-tailed object detection(https://arxiv.org/abs/2410.11774)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Real-world datasets follow an imbalanced distribution, which poses significant challenges in rare-category object detection. Recent studies tackle this problem by developing re-weighting and re-sampling methods, that utilise the class frequencies of the dataset. However, these techniques focus solely on the frequency statistics and ignore the distribution of the classes in image space, missing important information. In contrast to them, we propose FRActal CALibration (FRACAL): a novel post-calibration method for long-tailed object detection. FRACAL devises a logit adjustment method that utilises the fractal dimension to estimate how uniformly classes are distributed in image space. During inference, it uses the fractal dimension to inversely downweight the probabilities of uniformly spaced class predictions achieving balance in two axes: between frequent and rare categories, and between uniformly spaced and sparsely spaced classes. FRACAL is a post-processing method and it does not require any training, also it can be combined with many off-the-shelf models such as one-stage sigmoid detectors and two-stage instance segmentation models. FRACAL boosts the rare class performance by up to 8.6% and surpasses all previous methods on LVIS dataset, while showing good generalisation to other datasets such as COCO, V3Det and OpenImages. The code will be released.</li>
</ul>

<h3>Title: On the Training Convergence of Transformers for In-Context Classification</h3>
<ul>
<li><strong>Authors: </strong>Wei Shen, Ruida Zhou, Jing Yang, Cong Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11778">https://arxiv.org/abs/2410.11778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11778">https://arxiv.org/pdf/2410.11778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11778]] On the Training Convergence of Transformers for In-Context Classification(https://arxiv.org/abs/2410.11778)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While transformers have demonstrated impressive capacities for in-context learning (ICL) in practice, theoretical understanding of the underlying mechanism enabling transformers to perform ICL is still in its infant stage. This work aims to theoretically study the training dynamics of transformers for in-context classification tasks. We demonstrate that, for in-context classification of Gaussian mixtures under certain assumptions, a single-layer transformer trained via gradient descent converges to a globally optimal model at a linear rate. We further quantify the impact of the training and testing prompt lengths on the ICL inference error of the trained transformer. We show that when the lengths of training and testing prompts are sufficiently large, the prediction of the trained transformer approaches the Bayes-optimal classifier. Experimental results corroborate the theoretical findings.</li>
</ul>

<h3>Title: MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Wang, Xiang Chen, Ningyu Zhang, Bozhong Tian, Haoming Xu, Shumin Deng, Huajun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11779">https://arxiv.org/abs/2410.11779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11779">https://arxiv.org/pdf/2410.11779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11779]] MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation(https://arxiv.org/abs/2410.11779)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to recognize visual objects in the preceding layers. We speculate that this may be due to the strong knowledge priors of the language model suppressing the visual information, leading to hallucinations. Motivated by this, we propose a novel dynamic correction decoding method for MLLMs (DeCo), which adaptively selects the appropriate preceding layers and proportionally integrates knowledge into the final layer to adjust the output logits. Note that DeCo is model agnostic and can be seamlessly incorporated with various classic decoding strategies and applied to different MLLMs. We evaluate DeCo on widely-used benchmarks, demonstrating that it can reduce hallucination rates by a large margin compared to baselines, highlighting its potential to mitigate hallucinations. Code is available at this https URL.</li>
</ul>

<h3>Title: Language Models Encode Numbers Using Digit Representations in Base 10</h3>
<ul>
<li><strong>Authors: </strong>Amit Arnold Levy, Mor Geva</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11781">https://arxiv.org/abs/2410.11781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11781">https://arxiv.org/pdf/2410.11781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11781]] Language Models Encode Numbers Using Digit Representations in Base 10(https://arxiv.org/abs/2410.11781)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) frequently make errors when handling even simple numerical problems, such as comparing two small numbers. A natural hypothesis is that these errors stem from how LLMs represent numbers, and specifically, whether their representations of numbers capture their numeric values. We tackle this question from the observation that LLM errors on numerical tasks are often distributed across \textit{the digits} of the answer rather than normally around \textit{its numeric value}. Through a series of probing experiments and causal interventions, we show that LLMs internally represent numbers with individual circular representations per-digit in base 10. This digit-wise representation, as opposed to a value representation, sheds light on the error patterns of models on tasks involving numerical reasoning and could serve as a basis for future studies on analyzing numerical mechanisms in LLMs.</li>
</ul>

<h3>Title: Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability</h3>
<ul>
<li><strong>Authors: </strong>Tsz Ting Chung, Leyang Cui, Lemao Liu, Xinting Huang, Shuming Shi, Dit-Yan Yeung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11786">https://arxiv.org/abs/2410.11786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11786">https://arxiv.org/pdf/2410.11786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11786]] Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability(https://arxiv.org/abs/2410.11786)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive capabilities in a wide range of natural language processing tasks when leveraging in-context learning. To mitigate the additional computational and financial costs associated with in-context learning, several prompt compression methods have been proposed to compress the in-context learning prompts. Despite their success, these methods face challenges with transferability due to model-specific compression, or rely on external training data, such as GPT-4. In this paper, we investigate the ability of LLMs to develop a unified compression method that discretizes uninformative tokens, utilizing a self-supervised pre-training technique. By introducing a small number of parameters during the continual pre-training, the proposed Selection-p produces a probability for each input token, indicating whether to preserve or discard it. Experiments show Selection-p achieves state-of-the-art performance across numerous classification tasks, achieving compression rates of up to 10 times while experiencing only a marginal 0.8% decrease in performance. Moreover, it exhibits superior transferability to different models compared to prior work. Additionally, we further analyze how Selection-p helps maintain performance on in-context learning with long contexts.</li>
</ul>

<h3>Title: Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Ma, Yuzhu Zhang, Guoli Jia, Liangliang Zhao, Yichao Ma, Mingjie Ma, Gaofeng Liu, Kaiyan Zhang, Jianjun Li, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11795">https://arxiv.org/abs/2410.11795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11795">https://arxiv.org/pdf/2410.11795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11795]] Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices(https://arxiv.org/abs/2410.11795)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>As one of the most popular and sought-after generative models in the recent years, diffusion models have sparked the interests of many researchers and steadily shown excellent advantage in various generative tasks such as image synthesis, video generation, molecule design, 3D scene rendering and multimodal generation, relying on their dense theoretical principles and reliable application practices. The remarkable success of these recent efforts on diffusion models comes largely from progressive design principles and efficient architecture, training, inference, and deployment methodologies. However, there has not been a comprehensive and in-depth review to summarize these principles and practices to help the rapid understanding and application of diffusion models. In this survey, we provide a new efficiency-oriented perspective on these existing efforts, which mainly focuses on the profound principles and efficient practices in architecture designs, model training, fast inference and reliable deployment, to guide further theoretical research, algorithm migration and model application for new scenarios in a reader-friendly way. \url{this https URL}</li>
</ul>

<h3>Title: FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Zhe Li, Xiangfei Qiu, Peng Chen, Yihang Wang, Hanyin Cheng, Yang Shu, Jilin Hu, Chenjuan Guo, Aoying Zhou, Qingsong Wen, Christian S. Jensen, Bin Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11802">https://arxiv.org/abs/2410.11802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11802">https://arxiv.org/pdf/2410.11802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11802]] FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting(https://arxiv.org/abs/2410.11802)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Time Series Forecasting (TSF) is key functionality in numerous fields, including in finance, weather services, and energy management. While TSF methods are emerging these days, many of them require domain-specific data collection and model training and struggle with poor generalization performance on new domains. Foundation models aim to overcome this limitation. Pre-trained on large-scale language or time series data, they exhibit promising inferencing capabilities in new or unseen data. This has spurred a surge in new TSF foundation models. We propose a new benchmark, FoundTS, to enable thorough and fair evaluation and comparison of such models. FoundTS covers a variety of TSF foundation models, including those based on large language models and those pretrained on time series. Next, FoundTS supports different forecasting strategies, including zero-shot, few-shot, and full-shot, thereby facilitating more thorough evaluations. Finally, FoundTS offers a pipeline that standardizes evaluation processes such as dataset splitting, loading, normalization, and few-shot sampling, thereby facilitating fair evaluations. Building on this, we report on an extensive evaluation of TSF foundation models on a broad range of datasets from diverse domains and with different statistical characteristics. Specifically, we identify pros and cons and inherent limitations of existing foundation models, and we identify directions for future model design. We make our code and datasets available at this https URL.</li>
</ul>

<h3>Title: NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Han Han, Tong Zhu, Xiang Zhang, Mengsong Wu, Hao Xiong, Wenliang Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11805">https://arxiv.org/abs/2410.11805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11805">https://arxiv.org/pdf/2410.11805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11805]] NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models(https://arxiv.org/abs/2410.11805)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) combined with tool learning have gained impressive results in real-world applications. During tool learning, LLMs may call multiple tools in nested orders, where the latter tool call may take the former response as its input parameters. However, current research on the nested tool learning capabilities is still under-explored, since the existing benchmarks lack of relevant data instances. To address this problem, we introduce NesTools to bridge the current gap in comprehensive nested tool learning evaluations. NesTools comprises a novel automatic data generation method to construct large-scale nested tool calls with different nesting structures. With manual review and refinement, the dataset is in high quality and closely aligned with real-world scenarios. Therefore, NesTools can serve as a new benchmark to evaluate the nested tool learning abilities of LLMs. We conduct extensive experiments on 22 LLMs, and provide in-depth analyses with NesTools, which shows that current LLMs still suffer from the complex nested tool learning task.</li>
</ul>

<h3>Title: SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Zhang, DongDong Chen, Jing Liao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11815">https://arxiv.org/abs/2410.11815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11815">https://arxiv.org/pdf/2410.11815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11815]] SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing(https://arxiv.org/abs/2410.11815)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Scene graphs offer a structured, hierarchical representation of images, with nodes and edges symbolizing objects and the relationships among them. It can serve as a natural interface for image editing, dramatically improving precision and flexibility. Leveraging this benefit, we introduce a new framework that integrates large language model (LLM) with Text2Image generative model for scene graph-based image editing. This integration enables precise modifications at the object level and creative recomposition of scenes without compromising overall image integrity. Our approach involves two primary stages: 1) Utilizing a LLM-driven scene parser, we construct an image's scene graph, capturing key objects and their interrelationships, as well as parsing fine-grained attributes such as object masks and descriptions. These annotations facilitate concept learning with a fine-tuned diffusion model, representing each object with an optimized token and detailed description prompt. 2) During the image editing phase, a LLM editing controller guides the edits towards specific areas. These edits are then implemented by an attention-modulated diffusion editor, utilizing the fine-tuned model to perform object additions, deletions, replacements, and adjustments. Through extensive experiments, we demonstrate that our framework significantly outperforms existing image editing methods in terms of editing precision and scene aesthetics.</li>
</ul>

<h3>Title: Jigsaw++: Imagining Complete Shape Priors for Object Reassembly</h3>
<ul>
<li><strong>Authors: </strong>Jiaxin Lu, Gang Hua, Qixing Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11816">https://arxiv.org/abs/2410.11816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11816">https://arxiv.org/pdf/2410.11816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11816]] Jigsaw++: Imagining Complete Shape Priors for Object Reassembly(https://arxiv.org/abs/2410.11816)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The automatic assembly problem has attracted increasing interest due to its complex challenges that involve 3D representation. This paper introduces Jigsaw++, a novel generative method designed to tackle the multifaceted challenges of reconstruction for the reassembly problem. Existing approach focusing primarily on piecewise information for both part and fracture assembly, often overlooking the integration of complete object prior. Jigsaw++ distinguishes itself by learning a category-agnostic shape prior of complete objects. It employs the proposed "retargeting" strategy that effectively leverages the output of any existing assembly method to generate complete shape reconstructions. This capability allows it to function orthogonally to the current methods. Through extensive evaluations on Breaking Bad dataset and PartNet, Jigsaw++ has demonstrated its effectiveness, reducing reconstruction errors and enhancing the precision of shape reconstruction, which sets a new direction for future reassembly model developments.</li>
</ul>

<h3>Title: Improving Long-Text Alignment for Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Luping Liu, Chao Du, Tianyu Pang, Zehan Wang, Chongxuan Li, Dong Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11817">https://arxiv.org/abs/2410.11817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11817">https://arxiv.org/pdf/2410.11817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11817]] Improving Long-Text Alignment for Text-to-Image Diffusion Models(https://arxiv.org/abs/2410.11817)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid advancement of text-to-image (T2I) diffusion models has enabled them to generate unprecedented results from given texts. However, as text inputs become longer, existing encoding methods like CLIP face limitations, and aligning the generated images with long texts becomes challenging. To tackle these issues, we propose LongAlign, which includes a segment-level encoding method for processing long texts and a decomposed preference optimization method for effective alignment training. For segment-level encoding, long texts are divided into multiple segments and processed separately. This method overcomes the maximum input length limits of pretrained encoding models. For preference optimization, we provide decomposed CLIP-based preference models to fine-tune diffusion models. Specifically, to utilize CLIP-based preference models for T2I alignment, we delve into their scoring mechanisms and find that the preference scores can be decomposed into two components: a text-relevant part that measures T2I alignment and a text-irrelevant part that assesses other visual aspects of human preference. Additionally, we find that the text-irrelevant part contributes to a common overfitting problem during fine-tuning. To address this, we propose a reweighting strategy that assigns different weights to these two components, thereby reducing overfitting and enhancing alignment. After fine-tuning $512 \times 512$ Stable Diffusion (SD) v1.5 for about 20 hours using our method, the fine-tuned SD outperforms stronger foundation models in T2I alignment, such as PixArt-$\alpha$ and Kandinsky v2.2. The code is available at this https URL.</li>
</ul>

<h3>Title: Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos</h3>
<ul>
<li><strong>Authors: </strong>Zhouxia Wang, Jiawei Zhang, Xintao Wang, Tianshui Chen, Ying Shan, Wenping Wang, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11828">https://arxiv.org/abs/2410.11828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11828">https://arxiv.org/pdf/2410.11828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11828]] Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos(https://arxiv.org/abs/2410.11828)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Recent progress in blind face restoration has resulted in producing high-quality restored results for static images. However, efforts to extend these advancements to video scenarios have been minimal, partly because of the absence of benchmarks that allow for a comprehensive and fair comparison. In this work, we first present a fair evaluation benchmark, in which we first introduce a Real-world Low-Quality Face Video benchmark (RFV-LQ), evaluate several leading image-based face restoration algorithms, and conduct a thorough systematical analysis of the benefits and challenges associated with extending blind face image restoration algorithms to degraded face videos. Our analysis identifies several key issues, primarily categorized into two aspects: significant jitters in facial components and noise-shape flickering between frames. To address these issues, we propose a Temporal Consistency Network (TCN) cooperated with alignment smoothing to reduce jitters and flickers in restored videos. TCN is a flexible component that can be seamlessly plugged into the most advanced face image restoration algorithms, ensuring the quality of image-based restoration is maintained as closely as possible. Extensive experiments have been conducted to evaluate the effectiveness and efficiency of our proposed TCN and alignment smoothing operation. Project page: this https URL.</li>
</ul>

<h3>Title: MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yue Cao, Yangzhou Liu, Zhe Chen, Guangchen Shi, Wenhai Wang, Danhuai Zhao, Tong Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11829">https://arxiv.org/abs/2410.11829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11829">https://arxiv.org/pdf/2410.11829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11829]] MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding(https://arxiv.org/abs/2410.11829)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant advancements in Multimodal Large Language Models (MLLMs) for understanding complex human intentions through cross-modal interactions, capturing intricate image details remains challenging. Previous methods integrating multiple vision encoders to enhance visual detail introduce redundancy and computational overhead. We observe that most MLLMs utilize only the last-layer feature map of the vision encoder for visual representation, neglecting the rich fine-grained information in shallow feature maps. To address this issue, we propose \modelname, a simple yet effective multi-layer feature fuser that efficiently integrates deep and shallow features from Vision Transformers (ViTs). Specifically, it leverages semantically aligned deep features as queries to dynamically extract missing details from shallow features, thus preserving semantic alignment while enriching the representation with fine-grained information. Applied to the LLaVA-1.5 model, \modelname~achieves significant improvements in visual representation and benchmark performance, providing a more flexible and lightweight solution compared to multi-encoder ensemble methods. The code and model have been released at this https URL.</li>
</ul>

<h3>Title: On the Effectiveness of Dataset Alignment for Fake Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Anirudh Sundara Rajan, Utkarsh Ojha, Jedidiah Schloesser, Yong Jae Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11835">https://arxiv.org/abs/2410.11835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11835">https://arxiv.org/pdf/2410.11835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11835]] On the Effectiveness of Dataset Alignment for Fake Image Detection(https://arxiv.org/abs/2410.11835)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>As latent diffusion models (LDMs) democratize image generation capabilities, there is a growing need to detect fake images. A good detector should focus on the generative models fingerprints while ignoring image properties such as semantic content, resolution, file format, etc. Fake image detectors are usually built in a data driven way, where a model is trained to separate real from fake images. Existing works primarily investigate network architecture choices and training recipes. In this work, we argue that in addition to these algorithmic choices, we also require a well aligned dataset of real/fake images to train a robust detector. For the family of LDMs, we propose a very simple way to achieve this: we reconstruct all the real images using the LDMs autoencoder, without any denoising operation. We then train a model to separate these real images from their reconstructions. The fakes created this way are extremely similar to the real ones in almost every aspect (e.g., size, aspect ratio, semantic content), which forces the model to look for the LDM decoders artifacts. We empirically show that this way of creating aligned real/fake datasets, which also sidesteps the computationally expensive denoising process, helps in building a detector that focuses less on spurious correlations, something that a very popular existing method is susceptible to. Finally, to demonstrate just how effective the alignment in a dataset can be, we build a detector using images that are not natural objects, and present promising results. Overall, our work identifies the subtle but significant issues that arise when training a fake image detector and proposes a simple and inexpensive solution to address these problems.</li>
</ul>

<h3>Title: High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Junhwa Hur, Charles Herrmann, Saurabh Saxena, Janne Kontkanen, Wei-Sheng Lai, Yichang Shih, Michael Rubinstein, David J. Fleet, Deqing Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11838">https://arxiv.org/abs/2410.11838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11838">https://arxiv.org/pdf/2410.11838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11838]] High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion(https://arxiv.org/abs/2410.11838)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite the recent progress, existing frame interpolation methods still struggle with processing extremely high resolution input and handling challenging cases such as repetitive textures, thin objects, and large motion. To address these issues, we introduce a patch-based cascaded pixel diffusion model for frame interpolation, HiFI, that excels in these scenarios while achieving competitive performance on standard benchmarks. Cascades, which generate a series of images from low- to high-resolution, can help significantly with large or complex motion that require both global context for a coarse solution and detailed context for high resolution output. However, contrary to prior work on cascaded diffusion models which perform diffusion on increasingly large resolutions, we use a single model that always performs diffusion at the same resolution and upsamples by processing patches of the inputs and the prior solution. We show that this technique drastically reduces memory usage at inference time and also allows us to use a single model at test time, solving both frame interpolation and spatial up-sampling, saving training cost. We show that HiFI helps significantly with high resolution and complex repeated textures that require global context. HiFI demonstrates comparable or beyond state-of-the-art performance on multiple benchmarks (Vimeo, Xiph, X-Test, SEPE-8K). On our newly introduced dataset that focuses on particularly challenging cases, HiFI also significantly outperforms other baselines on these cases. Please visit our project page for video results: this https URL</li>
</ul>

<h3>Title: MoH: Multi-Head Attention as Mixture-of-Head Attention</h3>
<ul>
<li><strong>Authors: </strong>Peng Jin, Bo Zhu, Li Yuan, Shuicheng Yan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.11842">https://arxiv.org/abs/2410.11842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.11842">https://arxiv.org/pdf/2410.11842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.11842]] MoH: Multi-Head Attention as Mixture-of-Head Attention(https://arxiv.org/abs/2410.11842)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we upgrade the multi-head attention mechanism, the core of the Transformer model, to improve efficiency while maintaining or surpassing the previous accuracy level. We show that multi-head attention can be expressed in the summation form. Drawing on the insight that not all attention heads hold equal significance, we propose Mixture-of-Head attention (MoH), a new architecture that treats attention heads as experts in the Mixture-of-Experts (MoE) mechanism. MoH has two significant advantages: First, MoH enables each token to select the appropriate attention heads, enhancing inference efficiency without compromising accuracy or increasing the number of parameters. Second, MoH replaces the standard summation in multi-head attention with a weighted summation, introducing flexibility to the attention mechanism and unlocking extra performance potential. Extensive experiments on ViT, DiT, and LLMs demonstrate that MoH outperforms multi-head attention by using only 50%-90% of the attention heads. Moreover, we demonstrate that pre-trained multi-head attention models, such as LLaMA3-8B, can be further continue-tuned into our MoH models. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14 benchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the attention heads. We believe the proposed MoH is a promising alternative to multi-head attention and provides a strong foundation for developing advanced and efficient attention-based models.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
