<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-05-07</h1>
<h3>Title: Neural Additive Image Model: Interpretation through Interpolation</h3>
<ul>
<li><strong>Authors: </strong>Arik Reuter, Anton Thielmann, Benjamin Saefken</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02295">https://arxiv.org/abs/2405.02295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02295">https://arxiv.org/pdf/2405.02295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02295]] Neural Additive Image Model: Interpretation through Interpolation(https://arxiv.org/abs/2405.02295)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Understanding how images influence the world, interpreting which effects their semantics have on various quantities and exploring the reasons behind changes in image-based predictions are highly difficult yet extremely interesting problems. By adopting a holistic modeling approach utilizing Neural Additive Models in combination with Diffusion Autoencoders, we can effectively identify the latent hidden semantics of image effects and achieve full intelligibility of additional tabular effects. Our approach offers a high degree of flexibility, empowering us to comprehensively explore the impact of various image characteristics. We demonstrate that the proposed method can precisely identify complex image effects in an ablation study. To further showcase the practical applicability of our proposed model, we conduct a case study in which we investigate how the distinctive features and attributes captured within host images exert influence on the pricing of Airbnb rentals.</li>
</ul>

<h3>Title: Möbius Transform for Mitigating Perspective Distortions in  Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Prakash Chandra Chhipa, Meenakshi Subhash Chippa, Kanjar De, Rajkumar Saini, Marcus Liwicki, Mubarak Shah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02296">https://arxiv.org/abs/2405.02296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02296">https://arxiv.org/pdf/2405.02296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02296]] Möbius Transform for Mitigating Perspective Distortions in  Representation Learning(https://arxiv.org/abs/2405.02296)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Perspective distortion (PD) causes unprecedented changes in shape, size, orientation, angles, and other spatial relationships of visual concepts in images. Precisely estimating camera intrinsic and extrinsic parameters is a challenging task that prevents synthesizing perspective distortion. Non-availability of dedicated training data poses a critical barrier to developing robust computer vision methods. Additionally, distortion correction methods make other computer vision tasks a multi-step approach and lack performance. In this work, we propose mitigating perspective distortion (MPD) by employing a fine-grained parameter control on a specific family of M\"obius transform to model real-world distortion without estimating camera intrinsic and extrinsic parameters and without the need for actual distorted data. Also, we present a dedicated perspectively distorted benchmark dataset, ImageNet-PD, to benchmark the robustness of deep learning models against this new dataset. The proposed method outperforms on existing benchmarks, ImageNet-E and ImageNet-X. Additionally, it significantly improves performance on ImageNet-PD while consistently performing on standard data distribution. Further, our method shows improved performance on three PD-affected real-world applications: crowd counting, fisheye image recognition, and person re-identification. We will release source code, dataset, and models for foster further research.</li>
</ul>

<h3>Title: TFCounter:Polishing Gems for Training-Free Object Counting</h3>
<ul>
<li><strong>Authors: </strong>Pan Ting, Jianfeng Lin, Wenhao Yu, Wenlong Zhang, Xiaoying Chen, Jinlu Zhang, Binqiang Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02301">https://arxiv.org/abs/2405.02301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02301">https://arxiv.org/pdf/2405.02301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02301]] TFCounter:Polishing Gems for Training-Free Object Counting(https://arxiv.org/abs/2405.02301)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Object counting is a challenging task with broad application prospects in security surveillance, traffic management, and disease diagnosis. Existing object counting methods face a tri-fold challenge: achieving superior performance, maintaining high generalizability, and minimizing annotation costs. We develop a novel training-free class-agnostic object counter, TFCounter, which is prompt-context-aware via the cascade of the essential elements in large-scale foundation models. This approach employs an iterative counting framework with a dual prompt system to recognize a broader spectrum of objects varying in shape, appearance, and size. Besides, it introduces an innovative context-aware similarity module incorporating background context to enhance accuracy within messy scenes. To demonstrate cross-domain generalizability, we collect a novel counting dataset named BIKE-1000, including exclusive 1000 images of shared bicycles from Meituan. Extensive experiments on FSC-147, CARPK, and BIKE-1000 datasets demonstrate that TFCounter outperforms existing leading training-free methods and exhibits competitive results compared to trained counterparts.</li>
</ul>

<h3>Title: The Democratization of Wealth Management: Hedged Mutual Fund Blockchain  Protocol</h3>
<ul>
<li><strong>Authors: </strong>Ravi Kashyap</a></li>
<li><strong>Subjects: </strong>cs.CR, q-fin.CP, q-fin.PM, q-fin.RM, q-fin.TR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02302">https://arxiv.org/abs/2405.02302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02302">https://arxiv.org/pdf/2405.02302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02302]] The Democratization of Wealth Management: Hedged Mutual Fund Blockchain  Protocol(https://arxiv.org/abs/2405.02302)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect</a></li>
<li><strong>Abstract: </strong>We develop several innovations designed to bring the best practices of traditional investment funds to the blockchain landscape. Our innovations combine the superior mechanisms of mutual funds and hedge funds. Specifically, we illustrate how fund prices can be updated regularly like mutual funds and performance fees can be charged like hedge funds. We show how mutually hedged blockchain investment funds can operate with investor protection schemes - high water marks - and measures to offset trading slippage when redemptions happen. We provide detailed steps - including mathematical formulations and instructive pointers - to implement these ideas as blockchain smart contracts. We discuss how our designs overcome several blockchain bottlenecks and how we can make smart contracts smarter. We provide numerical illustrations of several scenarios related to the mechanisms we have tailored for blockchain implementation. The concepts we have developed for blockchain implementation can also be useful in traditional financial funds to calculate performance fees in a simplified manner. We highlight two main issues with the operation of mutual funds and hedge funds and show how blockchain technology can alleviate those concerns. The ideas developed here illustrate on one hand, how blockchain can solve many issues faced by the traditional world and on the other hand, how many innovations from traditional finance can benefit decentralized finance and speed its adoption. This becomes an example of symbiosis between decentralized and traditional finance - bringing these two realms closer and breaking down barriers between such artificial distinctions - wherein the future will be about providing better risk adjusted wealth appreciation opportunities to end customers through secure, reliable, accessible and transparent services - without getting too caught up about how such services are being rendered.</li>
</ul>

<h3>Title: NL2FOL: Translating Natural Language to First-Order Logic for Logical  Fallacy Detection</h3>
<ul>
<li><strong>Authors: </strong>Abhinav Lalwani, Lovish Chopra, Christopher Hahn, Caroline Trippel, Zhijing Jin, Mrinmaya Sachan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02318">https://arxiv.org/abs/2405.02318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02318">https://arxiv.org/pdf/2405.02318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02318]] NL2FOL: Translating Natural Language to First-Order Logic for Logical  Fallacy Detection(https://arxiv.org/abs/2405.02318)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Logical fallacies are common errors in reasoning that undermine the logic of an argument. Automatically detecting logical fallacies has important applications in tracking misinformation and validating claims. In this paper, we design a process to reliably detect logical fallacies by translating natural language to First-order Logic (FOL) step-by-step using Large Language Models (LLMs). We then utilize Satisfiability Modulo Theory (SMT) solvers to reason about the validity of the formula and classify inputs as either a fallacy or valid statement. Our model also provides a novel means of utilizing LLMs to interpret the output of the SMT solver, offering insights into the counter-examples that illustrate why a given sentence is considered a logical fallacy. Our approach is robust, interpretable and does not require training data or fine-tuning. We evaluate our model on a mixed dataset of fallacies and valid sentences. The results demonstrate improved performance compared to end-to-end LLMs, with our classifier achieving an F1-score of 71\% on the Logic dataset. The approach is able to generalize effectively, achieving an F1-score of 73% on the challenge set, LogicClimate, outperforming state-of-the-art models by 21% despite its much smaller size.</li>
</ul>

<h3>Title: Efficient Exploration of Image Classifier Failures with Bayesian  Optimization and Text-to-Image Models</h3>
<ul>
<li><strong>Authors: </strong>Adrien Le Coz, Houssem Ouertatani, Stéphane Herbin, Faouzi Adjed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02332">https://arxiv.org/abs/2405.02332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02332">https://arxiv.org/pdf/2405.02332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02332]] Efficient Exploration of Image Classifier Failures with Bayesian  Optimization and Text-to-Image Models(https://arxiv.org/abs/2405.02332)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Image classifiers should be used with caution in the real world. Performance evaluated on a validation set may not reflect performance in the real world. In particular, classifiers may perform well for conditions that are frequently encountered during training, but poorly for other infrequent conditions. In this study, we hypothesize that recent advances in text-to-image generative models make them valuable for benchmarking computer vision models such as image classifiers: they can generate images conditioned by textual prompts that cause classifier failures, allowing failure conditions to be described with textual attributes. However, their generation cost becomes an issue when a large number of synthetic images need to be generated, which is the case when many different attribute combinations need to be tested. We propose an image classifier benchmarking method as an iterative process that alternates image generation, classifier evaluation, and attribute selection. This method efficiently explores the attributes that ultimately lead to poor behavior detection.</li>
</ul>

<h3>Title: Rad4XCNN: a new agnostic method for post-hoc global explanation of  CNN-derived features by means of radiomics</h3>
<ul>
<li><strong>Authors: </strong>Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02334">https://arxiv.org/abs/2405.02334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02334">https://arxiv.org/pdf/2405.02334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02334]] Rad4XCNN: a new agnostic method for post-hoc global explanation of  CNN-derived features by means of radiomics(https://arxiv.org/abs/2405.02334)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>In the last years, artificial intelligence (AI) in clinical decision support systems (CDSS) played a key role in harnessing machine learning and deep learning architectures. Despite their promising capabilities, the lack of transparency and explainability of AI models poses significant challenges, particularly in medical contexts where reliability is a mandatory aspect. Achieving transparency without compromising predictive accuracy remains a key challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the predictive power of CNN-derived features with the interpretability inherent in radiomic features. Rad4XCNN diverges from conventional methods based on saliency map, by associating intelligible meaning to CNN-derived features by means of Radiomics, offering new perspectives on explanation methods beyond visualization maps. Using a breast cancer classification task as a case study, we evaluated Rad4XCNN on ultrasound imaging datasets, including an online dataset and two in-house datasets for internal and external validation. Some key results are: i) CNN-derived features guarantee more robust accuracy when compared against ViT-derived and radiomic features; ii) conventional visualization map methods for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice model accuracy for their explainability; iv) Rad4XCNN provides global explanation insights enabling the physician to analyze the model outputs and findings. In addition, we highlight the importance of integrating interpretability into AI models for enhanced trust and adoption in clinical practice, emphasizing how our method can mitigate some concerns related to explainable AI methods.</li>
</ul>

<h3>Title: Improved Communication-Privacy Trade-offs in $L_2$ Mean Estimation under  Streaming Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Wei-Ning Chen, Berivan Isik, Peter Kairouz, Albert No, Sewoong Oh, Zheng Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02341">https://arxiv.org/abs/2405.02341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02341">https://arxiv.org/pdf/2405.02341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02341]] Improved Communication-Privacy Trade-offs in $L_2$ Mean Estimation under  Streaming Differential Privacy(https://arxiv.org/abs/2405.02341)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We study $L_2$ mean estimation under central differential privacy and communication constraints, and address two key challenges: firstly, existing mean estimation schemes that simultaneously handle both constraints are usually optimized for $L_\infty$ geometry and rely on random rotation or Kashin's representation to adapt to $L_2$ geometry, resulting in suboptimal leading constants in mean square errors (MSEs); secondly, schemes achieving order-optimal communication-privacy trade-offs do not extend seamlessly to streaming differential privacy (DP) settings (e.g., tree aggregation or matrix factorization), rendering them incompatible with DP-FTRL type optimizers. In this work, we tackle these issues by introducing a novel privacy accounting method for the sparsified Gaussian mechanism that incorporates the randomness inherent in sparsification into the DP noise. Unlike previous approaches, our accounting algorithm directly operates in $L_2$ geometry, yielding MSEs that fast converge to those of the uncompressed Gaussian mechanism. Additionally, we extend the sparsification scheme to the matrix factorization framework under streaming DP and provide a precise accountant tailored for DP-FTRL type optimizers. Empirically, our method demonstrates at least a 100x improvement of compression for DP-SGD across various FL tasks.</li>
</ul>

<h3>Title: Backdoor-based Explainable AI Benchmark for High Fidelity Evaluation of  Attribution Methods</h3>
<ul>
<li><strong>Authors: </strong>Peiyu Yang, Naveed Akhtar, Jiantong Jiang, Ajmal Mian</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02344">https://arxiv.org/abs/2405.02344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02344">https://arxiv.org/pdf/2405.02344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02344]] Backdoor-based Explainable AI Benchmark for High Fidelity Evaluation of  Attribution Methods(https://arxiv.org/abs/2405.02344)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, fair</a></li>
<li><strong>Abstract: </strong>Attribution methods compute importance scores for input features to explain the output predictions of deep models. However, accurate assessment of attribution methods is challenged by the lack of benchmark fidelity for attributing model predictions. Moreover, other confounding factors in attribution estimation, including the setup choices of post-processing techniques and explained model predictions, further compromise the reliability of the evaluation. In this work, we first identify a set of fidelity criteria that reliable benchmarks for attribution methods are expected to fulfill, thereby facilitating a systematic assessment of attribution benchmarks. Next, we introduce a Backdoor-based eXplainable AI benchmark (BackX) that adheres to the desired fidelity criteria. We theoretically establish the superiority of our approach over the existing benchmarks for well-founded attribution evaluation. With extensive analysis, we also identify a setup for a consistent and fair benchmarking of attribution methods across different underlying methodologies. This setup is ultimately employed for a comprehensive comparison of existing methods using our BackX benchmark. Finally, our analysis also provides guidance for defending against backdoor attacks with the help of attribution methods.</li>
</ul>

<h3>Title: Temporal assessment of malicious behaviors: application to turnout field  data monitoring</h3>
<ul>
<li><strong>Authors: </strong>Sara Abdellaoui, Emil Dumitrescu, Cédric Escudero, Eric Zamaï</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02346">https://arxiv.org/abs/2405.02346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02346">https://arxiv.org/pdf/2405.02346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02346]] Temporal assessment of malicious behaviors: application to turnout field  data monitoring(https://arxiv.org/abs/2405.02346)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Monitored data collected from railway turnouts are vulnerable to cyberattacks: attackers may either conceal failures or trigger unnecessary maintenance actions. To address this issue, a cyberattack investigation method is proposed based on predictions made from the temporal evolution of the turnout behavior. These predictions are then compared to the field acquired data to detect any discrepancy. This method is illustrated on a collection of real-life data.</li>
</ul>

<h3>Title: COPAL: Continual Pruning in Large Language Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Srikanth Malla, Joon Hee Choi, Chiho Choi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02347">https://arxiv.org/abs/2405.02347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02347">https://arxiv.org/pdf/2405.02347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02347]] COPAL: Continual Pruning in Large Language Generative Models(https://arxiv.org/abs/2405.02347)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Adapting pre-trained large language models to different domains in natural language processing requires two key considerations: high computational demands and model's inability to continual adaptation. To simultaneously address both issues, this paper presents COPAL (COntinual Pruning in Adaptive Language settings), an algorithm developed for pruning large language generative models under a continual model adaptation setting. While avoiding resource-heavy finetuning or retraining, our pruning process is guided by the proposed sensitivity analysis. The sensitivity effectively measures model's ability to withstand perturbations introduced by the new dataset and finds model's weights that are relevant for all encountered datasets. As a result, COPAL allows seamless model adaptation to new domains while enhancing the resource efficiency. Our empirical evaluation on a various size of LLMs show that COPAL outperforms baseline models, demonstrating its efficacy in efficiency and adaptability.</li>
</ul>

<h3>Title: Explainable Muti-Label Classification of MBTI Types</h3>
<ul>
<li><strong>Authors: </strong>Siana Kong, Marina Sokolova</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02349">https://arxiv.org/abs/2405.02349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02349">https://arxiv.org/pdf/2405.02349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02349]] Explainable Muti-Label Classification of MBTI Types(https://arxiv.org/abs/2405.02349)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In this study, we aim to identify the most effective machine learning model for accurately classifying Myers-Briggs Type Indicator (MBTI) types from Reddit posts and a Kaggle data set. We apply multi-label classification using the Binary Relevance method. We use Explainable Artificial Intelligence (XAI) approach to highlight the transparency and understandability of the process and result. To achieve this, we experiment with glass-box learning models, i.e. models designed for simplicity, transparency, and interpretability. We selected k-Nearest Neighbour, Multinomial Naive Bayes, and Logistic Regression for the glass-box models. We show that Multinomial Naive Bayes and k-Nearest Neighbour perform better if classes with Observer (S) traits are excluded, whereas Logistic Regression obtains its best results when all classes have > 550 entries.</li>
</ul>

<h3>Title: Early Transformers: A study on Efficient Training of Transformer Models  through Early-Bird Lottery Tickets</h3>
<ul>
<li><strong>Authors: </strong>Shravan Cheekati</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02353">https://arxiv.org/abs/2405.02353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02353">https://arxiv.org/pdf/2405.02353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02353]] Early Transformers: A study on Efficient Training of Transformer Models  through Early-Bird Lottery Tickets(https://arxiv.org/abs/2405.02353)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The training of Transformer models has revolutionized natural language processing and computer vision, but it remains a resource-intensive and time-consuming process. This paper investigates the applicability of the early-bird ticket hypothesis to optimize the training efficiency of Transformer models. We propose a methodology that combines iterative pruning, masked distance calculation, and selective retraining to identify early-bird tickets in various Transformer architectures, including ViT, Swin-T, GPT-2, and RoBERTa. Our experimental results demonstrate that early-bird tickets can be consistently found within the first few epochs of training or fine-tuning, enabling significant resource optimization without compromising performance. The pruned models obtained from early-bird tickets achieve comparable or even superior accuracy to their unpruned counterparts while substantially reducing memory usage. Furthermore, our comparative analysis highlights the generalizability of the early-bird ticket phenomenon across different Transformer models and tasks. This research contributes to the development of efficient training strategies for Transformer models, making them more accessible and resource-friendly. By leveraging early-bird tickets, practitioners can accelerate the progress of natural language processing and computer vision applications while reducing the computational burden associated with training Transformer models.</li>
</ul>

<h3>Title: Large Language Models for Mobility in Transportation Systems: A Survey  on Forecasting Tasks</h3>
<ul>
<li><strong>Authors: </strong>Zijian Zhang, Yujie Sun, Zepu Wang, Yuqi Nie, Xiaobo Ma, Peng Sun, Ruolin Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02357">https://arxiv.org/abs/2405.02357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02357">https://arxiv.org/pdf/2405.02357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02357]] Large Language Models for Mobility in Transportation Systems: A Survey  on Forecasting Tasks(https://arxiv.org/abs/2405.02357)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mobility analysis is a crucial element in the research area of transportation systems. Forecasting traffic information offers a viable solution to address the conflict between increasing transportation demands and the limitations of transportation infrastructure. Predicting human travel is significant in aiding various transportation and urban management tasks, such as taxi dispatch and urban planning. Machine learning and deep learning methods are favored for their flexibility and accuracy. Nowadays, with the advent of large language models (LLMs), many researchers have combined these models with previous techniques or applied LLMs to directly predict future traffic information and human travel behaviors. However, there is a lack of comprehensive studies on how LLMs can contribute to this field. This survey explores existing approaches using LLMs for mobility forecasting problems. We provide a literature review concerning the forecasting applications within transportation systems, elucidating how researchers utilize LLMs, showcasing recent state-of-the-art advancements, and identifying the challenges that must be overcome to fully leverage LLMs in this domain.</li>
</ul>

<h3>Title: A Survey of Time Series Foundation Models: Generalizing Time Series  Representation with Large Language Mode</h3>
<ul>
<li><strong>Authors: </strong>Jiexia Ye, Weiqi Zhang, Ke Yi, Yongzi Yu, Ziyue Li, Jia Li, Fugee Tsung</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02358">https://arxiv.org/abs/2405.02358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02358">https://arxiv.org/pdf/2405.02358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02358]] A Survey of Time Series Foundation Models: Generalizing Time Series  Representation with Large Language Mode(https://arxiv.org/abs/2405.02358)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Time series data are ubiquitous across various domains, making time series analysis critically important. Traditional time series models are task-specific, featuring singular functionality and limited generalization capacity. Recently, large language foundation models have unveiled their remarkable capabilities for cross-task transferability, zero-shot/few-shot learning, and decision-making explainability. This success has sparked interest in the exploration of foundation models to solve multiple time series challenges simultaneously. There are two main research lines, namely \textbf{pre-training foundation models from scratch for time series} and \textbf{adapting large language foundation models for time series}. They both contribute to the development of a unified model that is highly generalizable, versatile, and comprehensible for time series analysis. This survey offers a 3E analytical framework for comprehensive examination of related research. Specifically, we examine existing works from three dimensions, namely \textbf{Effectiveness}, \textbf{Efficiency} and \textbf{Explainability}. In each dimension, we focus on discussing how related works devise tailored solution by considering unique challenges in the realm of time series.Furthermore, we provide a domain taxonomy to help followers keep up with the domain-specific advancements. In addition, we introduce extensive resources to facilitate the field's development, including datasets, open-source, time series libraries. A GitHub repository is also maintained for resource updates (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).</li>
</ul>

<h3>Title: CVTGAD: Simplified Transformer with Cross-View Attention for  Unsupervised Graph-level Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Jindong Li, Qianli Xing, Qi Wang, Yi Chang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02359">https://arxiv.org/abs/2405.02359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02359">https://arxiv.org/pdf/2405.02359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02359]] CVTGAD: Simplified Transformer with Cross-View Attention for  Unsupervised Graph-level Anomaly Detection(https://arxiv.org/abs/2405.02359)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Unsupervised graph-level anomaly detection (UGAD) has received remarkable performance in various critical disciplines, such as chemistry analysis and bioinformatics. Existing UGAD paradigms often adopt data augmentation techniques to construct multiple views, and then employ different strategies to obtain representations from different views for jointly conducting UGAD. However, most previous works only considered the relationship between nodes/graphs from a limited receptive field, resulting in some key structure patterns and feature information being neglected. In addition, most existing methods consider different views separately in a parallel manner, which is not able to explore the inter-relationship across different views directly. Thus, a method with a larger receptive field that can explore the inter-relationship across different views directly is in need. In this paper, we propose a novel Simplified Transformer with Cross-View Attention for Unsupervised Graph-level Anomaly Detection, namely, CVTGAD. To increase the receptive field, we construct a simplified transformer-based module, exploiting the relationship between nodes/graphs from both intra-graph and inter-graph perspectives. Furthermore, we design a cross-view attention mechanism to directly exploit the view co-occurrence between different views, bridging the inter-view gap at node level and graph level. To the best of our knowledge, this is the first work to apply transformer and cross attention to UGAD, which realizes graph neural network and transformer working collaboratively. Extensive experiments on 15 real-world datasets of 3 fields demonstrate the superiority of CVTGAD on the UGAD task. The code is available at \url{https://github.com/jindongli-Ai/CVTGAD}.</li>
</ul>

<h3>Title: Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for  Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yanli Li, Jehad Ibrahim, Huaming Chen, Dong Yuan, Kim-Kwang Raymond Choo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02360">https://arxiv.org/abs/2405.02360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02360">https://arxiv.org/pdf/2405.02360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02360]] Holistic Evaluation Metrics: Use Case Sensitive Evaluation Metrics for  Federated Learning(https://arxiv.org/abs/2405.02360)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>A large number of federated learning (FL) algorithms have been proposed for different applications and from varying perspectives. However, the evaluation of such approaches often relies on a single metric (e.g., accuracy). Such a practice fails to account for the unique demands and diverse requirements of different use cases. Thus, how to comprehensively evaluate an FL algorithm and determine the most suitable candidate for a designated use case remains an open question. To mitigate this research gap, we introduce the Holistic Evaluation Metrics (HEM) for FL in this work. Specifically, we collectively focus on three primary use cases, which are Internet of Things (IoT), smart devices, and institutions. The evaluation metric encompasses various aspects including accuracy, convergence, computational efficiency, fairness, and personalization. We then assign a respective importance vector for each use case, reflecting their distinct performance requirements and priorities. The HEM index is finally generated by integrating these metric components with their respective importance vectors. Through evaluating different FL algorithms in these three prevalent use cases, our experimental results demonstrate that HEM can effectively assess and identify the FL algorithms best suited to particular scenarios. We anticipate this work sheds light on the evaluation process for pragmatic FL algorithms in real-world applications.</li>
</ul>

<h3>Title: LLM as Dataset Analyst: Subpopulation Structure Discovery with Large  Language Model</h3>
<ul>
<li><strong>Authors: </strong>Yulin Luo, Ruichuan An, Bocheng Zou, Yiming Tang, Jiaming Liu, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02363">https://arxiv.org/abs/2405.02363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02363">https://arxiv.org/pdf/2405.02363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02363]] LLM as Dataset Analyst: Subpopulation Structure Discovery with Large  Language Model(https://arxiv.org/abs/2405.02363)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The distribution of subpopulations is an important property hidden within a dataset. Uncovering and analyzing the subpopulation distribution within datasets provides a comprehensive understanding of the datasets, standing as a powerful tool beneficial to various downstream tasks, including Dataset Subpopulation Organization, Subpopulation Shift, and Slice Discovery. Despite its importance, there has been no work that systematically explores the subpopulation distribution of datasets to our knowledge. To address the limitation and solve all the mentioned tasks in a unified way, we introduce a novel concept of subpopulation structures to represent, analyze, and utilize subpopulation distributions within datasets. To characterize the structures in an interpretable manner, we propose the Subpopulation Structure Discovery with Large Language Models (SSD-LLM) framework, which employs world knowledge and instruction-following capabilities of Large Language Models (LLMs) to linguistically analyze informative image captions and summarize the structures. Furthermore, we propose complete workflows to address downstream tasks, named Task-specific Tuning, showcasing the application of the discovered structure to a spectrum of subpopulation-related tasks, including dataset subpopulation organization, subpopulation shift, and slice discovery. Furthermore, we propose complete workflows to address downstream tasks, named Task-specific Tuning, showcasing the application of the discovered structure to a spectrum of subpopulation-related tasks, including dataset subpopulation organization, subpopulation shift, and slice discovery.</li>
</ul>

<h3>Title: A Survey on Contribution Evaluation in Vertical Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yue Cui, Chung-ju Huang, Yuzhu Zhang, Leye Wang, Lixin Fan, Xiaofang Zhou, Qiang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02364">https://arxiv.org/abs/2405.02364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02364">https://arxiv.org/pdf/2405.02364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02364]] A Survey on Contribution Evaluation in Vertical Federated Learning(https://arxiv.org/abs/2405.02364)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>Vertical Federated Learning (VFL) has emerged as a critical approach in machine learning to address privacy concerns associated with centralized data storage and processing. VFL facilitates collaboration among multiple entities with distinct feature sets on the same user population, enabling the joint training of predictive models without direct data sharing. A key aspect of VFL is the fair and accurate evaluation of each entity's contribution to the learning process. This is crucial for maintaining trust among participating entities, ensuring equitable resource sharing, and fostering a sustainable collaboration framework. This paper provides a thorough review of contribution evaluation in VFL. We categorize the vast array of contribution evaluation techniques along the VFL lifecycle, granularity of evaluation, privacy considerations, and core computational methods. We also explore various tasks in VFL that involving contribution evaluation and analyze their required evaluation properties and relation to the VFL lifecycle phases. Finally, we present a vision for the future challenges of contribution evaluation in VFL. By providing a structured analysis of the current landscape and potential advancements, this paper aims to guide researchers and practitioners in the design and implementation of more effective, efficient, and privacy-centric VFL solutions. Relevant literature and open-source resources have been compiled and are being continuously updated at the GitHub repository: \url{https://github.com/cuiyuebing/VFL_CE}.</li>
</ul>

<h3>Title: Adaptive and robust watermark against model extraction attack</h3>
<ul>
<li><strong>Authors: </strong>Kaiyi Pang, Tao Qi, Chuhan Wu, Minhao Bai</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02365">https://arxiv.org/abs/2405.02365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02365">https://arxiv.org/pdf/2405.02365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02365]] Adaptive and robust watermark against model extraction attack(https://arxiv.org/abs/2405.02365)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, extraction, fair, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have boosted Large Models as a Service (LMaaS) into a thriving business sector. But even model owners offering only API access while keeping model parameters and internal workings private, their Intellectual Property (IP) are still at risk of theft through model extraction attacks. To safeguard the IP of these models and mitigate unfair competition in the language model market, watermarking technology serves as an efficient post-hoc solution for identifying IP infringements. However, existing IP protection watermarking methods either explicitly alter the original output of the language model or implant watermark signals in the model logits. These methods forcefully distort the original distribution of the language model and impact the sampling process, leading to a decline in the quality of the generated text. The existing method also fails to achieve end-to-end adaptive watermark embedding and lack robustness verification in complex scenarios where watermark detection is subject to interference. To overcome these challenges, we propose PromptShield, a plug-and-play IP protection watermarking method to resist model extraction attacks without training additional modules. Leveraging the self-reminding properties inherent in large language models, we encapsulate the user's query with a watermark self-generated instruction, nudging the LLMs to automatically generate watermark words in its output without compromising generation quality. Our method does not require access to the model's internal logits and minimizes alterations to the model's distribution using prompt-guided cues. Comprehensive experimental results consistently demonstrate the effectiveness, harmlessness, and robustness of our watermark. Moreover, Our watermark detection method remains robust and high detection sensitivity even when subjected to interference.</li>
</ul>

<h3>Title: Robustness of Decentralised Learning to Nodes and Data Disruption</h3>
<ul>
<li><strong>Authors: </strong>Luigi Palmieri, Chiara Boldrini, Lorenzo Valerio, Andrea Passarella, Marco Conti, János Kertész</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02377">https://arxiv.org/abs/2405.02377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02377">https://arxiv.org/pdf/2405.02377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02377]] Robustness of Decentralised Learning to Nodes and Data Disruption(https://arxiv.org/abs/2405.02377)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>In the vibrant landscape of AI research, decentralised learning is gaining momentum. Decentralised learning allows individual nodes to keep data locally where they are generated and to share knowledge extracted from local data among themselves through an interactive process of collaborative refinement. This paradigm supports scenarios where data cannot leave local nodes due to privacy or sovereignty reasons or real-time constraints imposing proximity of models to locations where inference has to be carried out. The distributed nature of decentralised learning implies significant new research challenges with respect to centralised learning. Among them, in this paper, we focus on robustness issues. Specifically, we study the effect of nodes' disruption on the collective learning process. Assuming a given percentage of "central" nodes disappear from the network, we focus on different cases, characterised by (i) different distributions of data across nodes and (ii) different times when disruption occurs with respect to the start of the collaborative learning task. Through these configurations, we are able to show the non-trivial interplay between the properties of the network connecting nodes, the persistence of knowledge acquired collectively before disruption or lack thereof, and the effect of data availability pre- and post-disruption. Our results show that decentralised learning processes are remarkably robust to network disruption. As long as even minimum amounts of data remain available somewhere in the network, the learning process is able to recover from disruptions and achieve significant classification accuracy. This clearly varies depending on the remaining connectivity after disruption, but we show that even nodes that remain completely isolated can retain significant knowledge acquired before the disruption.</li>
</ul>

<h3>Title: The Call for Socially Aware Language Technologies</h3>
<ul>
<li><strong>Authors: </strong>Diyi Yang, Dirk Hovy, David Jurgens, Barbara Plank</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02411">https://arxiv.org/abs/2405.02411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02411">https://arxiv.org/pdf/2405.02411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02411]] The Call for Socially Aware Language Technologies(https://arxiv.org/abs/2405.02411)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language technologies have made enormous progress, especially with the introduction of large language models (LLMs). On traditional tasks such as machine translation and sentiment analysis, these models perform at near-human level. These advances can, however, exacerbate a variety of issues that models have traditionally struggled with, such as bias, evaluation, and risks. In this position paper, we argue that many of these issues share a common core: a lack of awareness of the factors, context, and implications of the social environment in which NLP operates, which we call social awareness. While NLP is getting better at solving the formal linguistic aspects, limited progress has been made in adding the social awareness required for language applications to work in all situations for all users. Integrating social awareness into NLP models will make applications more natural, helpful, and safe, and will open up new possibilities. Thus we argue that substantial challenges remain for NLP to develop social awareness and that we are just at the beginning of a new era for the field.</li>
</ul>

<h3>Title: What does the Knowledge Neuron Thesis Have to do with Knowledge?</h3>
<ul>
<li><strong>Authors: </strong>Jingcheng Niu, Andrew Liu, Zining Zhu, Gerald Penn</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02421">https://arxiv.org/abs/2405.02421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02421">https://arxiv.org/pdf/2405.02421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02421]] What does the Knowledge Neuron Thesis Have to do with Knowledge?(https://arxiv.org/abs/2405.02421)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We reassess the Knowledge Neuron (KN) Thesis: an interpretation of the mechanism underlying the ability of large language models to recall facts from a training corpus. This nascent thesis proposes that facts are recalled from the training corpus through the MLP weights in a manner resembling key-value memory, implying in effect that "knowledge" is stored in the network. Furthermore, by modifying the MLP modules, one can control the language model's generation of factual information. The plausibility of the KN thesis has been demonstrated by the success of KN-inspired model editing methods (Dai et al., 2022; Meng et al., 2022). We find that this thesis is, at best, an oversimplification. Not only have we found that we can edit the expression of certain linguistic phenomena using the same model editing methods but, through a more comprehensive evaluation, we have found that the KN thesis does not adequately explain the process of factual expression. While it is possible to argue that the MLP weights store complex patterns that are interpretable both syntactically and semantically, these patterns do not constitute "knowledge." To gain a more comprehensive understanding of the knowledge representation process, we must look beyond the MLP weights and explore recent models' complex layer structures and attention mechanisms.</li>
</ul>

<h3>Title: Bridging the Gap: A Study of AI-based Vulnerability Management between  Industry and Academia</h3>
<ul>
<li><strong>Authors: </strong>Shengye Wan, Joshua Saxe, Craig Gomes, Sahana Chennabasappa, Avilash Rath, Kun Sun, Xinda Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02435">https://arxiv.org/abs/2405.02435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02435">https://arxiv.org/pdf/2405.02435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02435]] Bridging the Gap: A Study of AI-based Vulnerability Management between  Industry and Academia(https://arxiv.org/abs/2405.02435)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Recent research advances in Artificial Intelligence (AI) have yielded promising results for automated software vulnerability management. AI-based models are reported to greatly outperform traditional static analysis tools, indicating a substantial workload relief for security engineers. However, the industry remains very cautious and selective about integrating AI-based techniques into their security vulnerability management workflow. To understand the reasons, we conducted a discussion-based study, anchored in the authors' extensive industrial experience and keen observations, to uncover the gap between research and practice in this field. We empirically identified three main barriers preventing the industry from adopting academic models, namely, complicated requirements of scalability and prioritization, limited customization flexibility, and unclear financial implications. Meanwhile, research works are significantly impacted by the lack of extensive real-world security data and expertise. We proposed a set of future directions to help better understand industry expectations, improve the practical usability of AI-based security vulnerability research, and drive a synergistic relationship between industry and academia.</li>
</ul>

<h3>Title: FastLloyd: Federated, Accurate, Secure, and Tunable $k$-Means Clustering  with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Abdulrahman Diaa, Thomas Humphries, Florian Kerschbaum</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02437">https://arxiv.org/abs/2405.02437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02437">https://arxiv.org/pdf/2405.02437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02437]] FastLloyd: Federated, Accurate, Secure, and Tunable $k$-Means Clustering  with Differential Privacy(https://arxiv.org/abs/2405.02437)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, federate</a></li>
<li><strong>Abstract: </strong>We study the problem of privacy-preserving $k$-means clustering in the horizontally federated setting. Existing federated approaches using secure computation, suffer from substantial overheads and do not offer output privacy. At the same time, differentially private (DP) $k$-means algorithms assume a trusted central curator and do not extend to federated settings. Naively combining the secure and DP solutions results in a protocol with impractical overhead. Instead, our work provides enhancements to both the DP and secure computation components, resulting in a design that is faster, more private, and more accurate than previous work. By utilizing the computational DP model, we design a lightweight, secure aggregation-based approach that achieves four orders of magnitude speed-up over state-of-the-art related work. Furthermore, we not only maintain the utility of the state-of-the-art in the central model of DP, but we improve the utility further by taking advantage of constrained clustering techniques.</li>
</ul>

<h3>Title: What is Sentiment Meant to Mean to Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Michael Burnham</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02454">https://arxiv.org/abs/2405.02454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02454">https://arxiv.org/pdf/2405.02454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02454]] What is Sentiment Meant to Mean to Language Models?(https://arxiv.org/abs/2405.02454)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sentiment analysis is one of the most widely used techniques in text analysis. Recent advancements with Large Language Models have made it more accurate and accessible than ever, allowing researchers to classify text with only a plain English prompt. However, "sentiment" entails a wide variety of concepts depending on the domain and tools used. It has been used to mean emotion, opinions, market movements, or simply a general ``good-bad'' dimension. This raises a question: What exactly are language models doing when prompted to label documents by sentiment? This paper first overviews how sentiment is defined across different contexts, highlighting that it is a confounded measurement construct in that it entails multiple variables, such as emotional valence and opinion, without disentangling them. I then test three language models across two data sets with prompts requesting sentiment, valence, and stance classification. I find that sentiment labels most strongly correlate with valence labels. I further find that classification improves when researchers more precisely specify their dimension of interest rather than using the less well-defined concept of sentiment. I conclude by encouraging researchers to move beyond "sentiment" when feasible and use a more precise measurement construct.</li>
</ul>

<h3>Title: ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Heng Jin, Chaoyu Zhang, Shanghao Shi, Wenjing Lou, Y. Thomas Hou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02466">https://arxiv.org/abs/2405.02466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02466">https://arxiv.org/pdf/2405.02466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02466]] ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large  Language Models(https://arxiv.org/abs/2405.02466)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have attracted significant attention in recent years. Due to their "Large" nature, training LLMs from scratch consumes immense computational resources. Since several major players in the artificial intelligence (AI) field have open-sourced their original LLMs, an increasing number of individual researchers and smaller companies are able to build derivative LLMs based on these open-sourced models at much lower costs. However, this practice opens up possibilities for unauthorized use or reproduction that may not comply with licensing agreements, and deriving models can change the model's behavior, thus complicating the determination of model ownership. Current copyright protection schemes for LLMs are either designed for white-box settings or require additional modifications to the original model, which restricts their use in real-world settings. In this paper, we propose ProFLingo, a black-box fingerprinting-based copyright protection scheme for LLMs. ProFLingo generates adversarial examples (AEs) that can represent the unique decision boundary characteristics of an original model, thereby establishing unique fingerprints. Our scheme checks the effectiveness of these adversarial examples on a suspect model to determine whether it has been derived from the original model. ProFLingo offers a non-invasive approach, which neither requires knowledge of the suspect model nor modifications to the base model or its training process. To the best of our knowledge, our method represents the first black-box fingerprinting technique for copyright protection for LLMs. Our source code and generated AEs are available at: https://github.com/hengvt/ProFLingo_arXiv.</li>
</ul>

<h3>Title: Semantic Scaling: Bayesian Ideal Point Estimates with Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Burnham</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02472">https://arxiv.org/abs/2405.02472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02472">https://arxiv.org/pdf/2405.02472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02472]] Semantic Scaling: Bayesian Ideal Point Estimates with Large Language  Models(https://arxiv.org/abs/2405.02472)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces "Semantic Scaling," a novel method for ideal point estimation from text. I leverage large language models to classify documents based on their expressed stances and extract survey-like data. I then use item response theory to scale subjects from these data. Semantic Scaling significantly improves on existing text-based scaling methods, and allows researchers to explicitly define the ideological dimensions they measure. This represents the first scaling approach that allows such flexibility outside of survey instruments and opens new avenues of inquiry for populations difficult to survey. Additionally, it works with documents of varying length, and produces valid estimates of both mass and elite ideology. I demonstrate that the method can differentiate between policy preferences and in-group/out-group affect. Among the public, Semantic Scaling out-preforms Tweetscores according to human judgement; in Congress, it recaptures the first dimension DW-NOMINATE while allowing for greater flexibility in resolving construct validity challenges.</li>
</ul>

<h3>Title: Continuous Learned Primal Dual</h3>
<ul>
<li><strong>Authors: </strong>Christina Runkel, Ander Biguri, Carola-Bibiane Schönlieb</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02478">https://arxiv.org/abs/2405.02478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02478">https://arxiv.org/pdf/2405.02478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02478]] Continuous Learned Primal Dual(https://arxiv.org/abs/2405.02478)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Neural ordinary differential equations (Neural ODEs) propose the idea that a sequence of layers in a neural network is just a discretisation of an ODE, and thus can instead be directly modelled by a parameterised ODE. This idea has had resounding success in the deep learning literature, with direct or indirect influence in many state of the art ideas, such as diffusion models or time dependant models. Recently, a continuous version of the U-net architecture has been proposed, showing increased performance over its discrete counterpart in many imaging applications and wrapped with theoretical guarantees around its performance and robustness. In this work, we explore the use of Neural ODEs for learned inverse problems, in particular with the well-known Learned Primal Dual algorithm, and apply it to computed tomography (CT) reconstruction.</li>
</ul>

<h3>Title: A Survey of Few-Shot Learning for Biomedical Time Series</h3>
<ul>
<li><strong>Authors: </strong>Chenqi Li, Timothy Denison, Tingting Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02485">https://arxiv.org/abs/2405.02485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02485">https://arxiv.org/pdf/2405.02485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02485]] A Survey of Few-Shot Learning for Biomedical Time Series(https://arxiv.org/abs/2405.02485)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Advancements in wearable sensor technologies and the digitization of medical records have contributed to the unprecedented ubiquity of biomedical time series data. Data-driven models have tremendous potential to assist clinical diagnosis and improve patient care by improving long-term monitoring capabilities, facilitating early disease detection and intervention, as well as promoting personalized healthcare delivery. However, accessing extensively labeled datasets to train data-hungry deep learning models encounters many barriers, such as long-tail distribution of rare diseases, cost of annotation, privacy and security concerns, data-sharing regulations, and ethical considerations. An emerging approach to overcome the scarcity of labeled data is to augment AI methods with human-like capabilities to leverage past experiences to learn new tasks with limited examples, called few-shot learning. This survey provides a comprehensive review and comparison of few-shot learning methods for biomedical time series applications. The clinical benefits and limitations of such methods are discussed in relation to traditional data-driven approaches. This paper aims to provide insights into the current landscape of few-shot learning for biomedical time series and its implications for future research and applications.</li>
</ul>

<h3>Title: DRAMScope: Uncovering DRAM Microarchitecture and Characteristics by  Issuing Memory Commands</h3>
<ul>
<li><strong>Authors: </strong>Hwayong Nam, Seungmin Baek, Minbok Wi, Michael Jaemin Kim, Jaehyun Park, Chihun Song, Nam Sung Kim, Jung Ho Ahn</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02499">https://arxiv.org/abs/2405.02499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02499">https://arxiv.org/pdf/2405.02499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02499]] DRAMScope: Uncovering DRAM Microarchitecture and Characteristics by  Issuing Memory Commands(https://arxiv.org/abs/2405.02499)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>The demand for precise information on DRAM microarchitectures and error characteristics has surged, driven by the need to explore processing in memory, enhance reliability, and mitigate security vulnerability. Nonetheless, DRAM manufacturers have disclosed only a limited amount of information, making it difficult to find specific information on their DRAM microarchitectures. This paper addresses this gap by presenting more rigorous findings on the microarchitectures of commodity DRAM chips and their impacts on the characteristics of activate-induced bitflips (AIBs), such as RowHammer and RowPress. The previous studies have also attempted to understand the DRAM microarchitectures and associated behaviors, but we have found some of their results to be misled by inaccurate address mapping and internal data swizzling, or lack of a deeper understanding of the modern DRAM cell structure. For accurate and efficient reverse-engineering, we use three tools: AIBs, retention time test, and RowCopy, which can be cross-validated. With these three tools, we first take a macroscopic view of modern DRAM chips to uncover the size, structure, and operation of their subarrays, memory array tiles (MATs), and rows. Then, we analyze AIB characteristics based on the microscopic view of the DRAM microarchitecture, such as 6F^2 cell layout, through which we rectify misunderstandings regarding AIBs and discover a new data pattern that accelerates AIBs. Lastly, based on our findings at both macroscopic and microscopic levels, we identify previously unknown AIB vulnerabilities and propose a simple yet effective protection solution.</li>
</ul>

<h3>Title: Beyond Helpfulness and Harmlessness: Eliciting Diverse Behaviors from  Large Language Models with Persona In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Hyeong Kyu Choi, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02501">https://arxiv.org/abs/2405.02501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02501">https://arxiv.org/pdf/2405.02501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02501]] Beyond Helpfulness and Harmlessness: Eliciting Diverse Behaviors from  Large Language Models with Persona In-Context Learning(https://arxiv.org/abs/2405.02501)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are trained on massive text corpora, which are encoded with diverse personality traits. This triggers an interesting goal of eliciting a desired personality trait from the LLM, and probing its behavioral preferences. Accordingly, we formalize the persona elicitation task, aiming to customize LLM behaviors to align with a target persona. We present Persona In-Context Learning (PICLe), a novel persona elicitation framework grounded in Bayesian inference. At the core, PICLe introduces a new ICL example selection criterion based on likelihood ratio, which is designed to optimally guide the model in eliciting a specific target persona. We demonstrate the effectiveness of PICLe through extensive comparisons against baseline methods across three contemporary LLMs. Code is available at https://github.com/deeplearning-wisc/picle.</li>
</ul>

<h3>Title: Rasterized Edge Gradients: Handling Discontinuities Differentiably</h3>
<ul>
<li><strong>Authors: </strong>Stanislav Pidhorskyi, Tomas Simon, Gabriel Schwartz, He Wen, Yaser Sheikh, Jason Saragih</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02508">https://arxiv.org/abs/2405.02508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02508">https://arxiv.org/pdf/2405.02508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02508]] Rasterized Edge Gradients: Handling Discontinuities Differentiably(https://arxiv.org/abs/2405.02508)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Computing the gradients of a rendering process is paramount for diverse applications in computer vision and graphics. However, accurate computation of these gradients is challenging due to discontinuities and rendering approximations, particularly for surface-based representations and rasterization-based rendering. We present a novel method for computing gradients at visibility discontinuities for rasterization-based differentiable renderers. Our method elegantly simplifies the traditionally complex problem through a carefully designed approximation strategy, allowing for a straightforward, effective, and performant solution. We introduce a novel concept of micro-edges, which allows us to treat the rasterized images as outcomes of a differentiable, continuous process aligned with the inherently non-differentiable, discrete-pixel rasterization. This technique eliminates the necessity for rendering approximations or other modifications to the forward pass, preserving the integrity of the rendered image, which makes it applicable to rasterized masks, depth, and normals images where filtering is prohibitive. Utilizing micro-edges simplifies gradient interpretation at discontinuities and enables handling of geometry intersections, offering an advantage over the prior art. We showcase our method in dynamic human head scene reconstruction, demonstrating effective handling of camera images and segmentation masks.</li>
</ul>

<h3>Title: Implicit Neural Representations for Robust Joint Sparse-View CT  Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Jiayang Shi, Junyi Zhu, Daniel M. Pelt, K. Joost Batenburg, Matthew B. Blaschko</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02509">https://arxiv.org/abs/2405.02509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02509">https://arxiv.org/pdf/2405.02509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02509]] Implicit Neural Representations for Robust Joint Sparse-View CT  Reconstruction(https://arxiv.org/abs/2405.02509)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Computed Tomography (CT) is pivotal in industrial quality control and medical diagnostics. Sparse-view CT, offering reduced ionizing radiation, faces challenges due to its under-sampled nature, leading to ill-posed reconstruction problems. Recent advancements in Implicit Neural Representations (INRs) have shown promise in addressing sparse-view CT reconstruction. Recognizing that CT often involves scanning similar subjects, we propose a novel approach to improve reconstruction quality through joint reconstruction of multiple objects using INRs. This approach can potentially leverage both the strengths of INRs and the statistical regularities across multiple objects. While current INR joint reconstruction techniques primarily focus on accelerating convergence via meta-initialization, they are not specifically tailored to enhance reconstruction quality. To address this gap, we introduce a novel INR-based Bayesian framework integrating latent variables to capture the inter-object relationships. These variables serve as a dynamic reference throughout the optimization, thereby enhancing individual reconstruction fidelity. Our extensive experiments, which assess various key factors such as reconstruction quality, resistance to overfitting, and generalizability, demonstrate significant improvements over baselines in common numerical metrics. This underscores a notable advancement in CT reconstruction methods.</li>
</ul>

<h3>Title: Spatio-Temporal SwinMAE: A Swin Transformer based Multiscale  Representation Learner for Temporal Satellite Imagery</h3>
<ul>
<li><strong>Authors: </strong>Yohei Nakayama, Jiawei Su</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02512">https://arxiv.org/abs/2405.02512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02512">https://arxiv.org/pdf/2405.02512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02512]] Spatio-Temporal SwinMAE: A Swin Transformer based Multiscale  Representation Learner for Temporal Satellite Imagery(https://arxiv.org/abs/2405.02512)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Currently, the foundation models represented by large language models have made dramatic progress and are used in a very wide range of domains including 2D and 3D vision. As one of the important application domains of foundation models, earth observation has attracted attention and various approaches have been developed. When considering earth observation as a single image capture, earth observation imagery can be processed as an image with three or more channels, and when it comes with multiple image captures of different timestamps at one location, the temporal observation can be considered as a set of continuous image resembling video frames or medical SCAN slices. This paper presents Spatio-Temporal SwinMAE (ST-SwinMAE), an architecture which particularly focuses on representation learning for spatio-temporal image processing. Specifically, it uses a hierarchical Masked Auto-encoder (MAE) with Video Swin Transformer blocks. With the architecture, we present a pretrained model named Degas 100M as a geospatial foundation model. Also, we propose an approach for transfer learning with Degas 100M, which both pretrained encoder and decoder of MAE are utilized with skip connections added between them to achieve multi-scale information communication, forms an architecture named Spatio-Temporal SwinUNet (ST-SwinUNet). Our approach shows significant improvements of performance over existing state-of-the-art of foundation models. Specifically, for transfer learning of the land cover downstream task on the PhilEO Bench dataset, it shows 10.4\% higher accuracy compared with other geospatial foundation models on average.</li>
</ul>

<h3>Title: Mothman at SemEval-2024 Task 9: An Iterative System for Chain-of-Thought  Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Alvin Po-Chun Chen, Ray Groshan, Sean von Bayern</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02517">https://arxiv.org/abs/2405.02517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02517">https://arxiv.org/pdf/2405.02517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02517]] Mothman at SemEval-2024 Task 9: An Iterative System for Chain-of-Thought  Prompt Optimization(https://arxiv.org/abs/2405.02517)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Extensive research exists on the performance of large language models on logic-based tasks, whereas relatively little has been done on their ability to generate creative solutions on lateral thinking tasks. The BrainTeaser shared task tests lateral thinking and uses adversarial datasets to prevent memorization, resulting in poor performance for out-of-the-box models. We propose a system for iterative, chain-of-thought prompt engineering which optimizes prompts using human evaluation. Using this shared task, we demonstrate our system's ability to significantly improve model performance by optimizing prompts and evaluate the input dataset.</li>
</ul>

<h3>Title: A Novel Endorsement Protocol to Secure BFT-Based Consensus in  Permissionless Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Ziqiang Xu, Ahmad Salehi Shahraki, Naveen Chilamkurti</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02544">https://arxiv.org/abs/2405.02544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02544">https://arxiv.org/pdf/2405.02544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02544]] A Novel Endorsement Protocol to Secure BFT-Based Consensus in  Permissionless Blockchain(https://arxiv.org/abs/2405.02544)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>Permissionless blockchain technology offers numerous potential benefits for decentralised applications, such as security, transparency, and openness. BFT-based consensus mechanisms are widely adopted in the permissioned blockchain to meet the high scalability requirements of the network. Sybil attacks are one of the most potential threats when applying BFT-based consensus mechanisms in permissionless blockchain due to the lack of effective verification mechanisms for participants' identities. This paper presents a novel endorsement-based bootstrapping protocol with a signature algorithm that offers a streamlined, scalable identity endorsement and verification process. This approach effectively safeguards the BFT-based consensus mechanism against Sybil attacks. Using our proposed method, we have conducted thorough security analyses and simulation experiments to assess security, robustness, and scalability advantages in large-scale networks. Our results demonstrate that the scheme can effectively address the identity verification challenges when applying BFT-based consensus in a permissionless blockchain.</li>
</ul>

<h3>Title: Few-Shot Fruit Segmentation via Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Jordan A. James, Heather K. Manching, Amanda M. Hulse-Kemp, William J. Beksi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02556">https://arxiv.org/abs/2405.02556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02556">https://arxiv.org/pdf/2405.02556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02556]] Few-Shot Fruit Segmentation via Transfer Learning(https://arxiv.org/abs/2405.02556)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Advancements in machine learning, computer vision, and robotics have paved the way for transformative solutions in various domains, particularly in agriculture. For example, accurate identification and segmentation of fruits from field images plays a crucial role in automating jobs such as harvesting, disease detection, and yield estimation. However, achieving robust and precise infield fruit segmentation remains a challenging task since large amounts of labeled data are required to handle variations in fruit size, shape, color, and occlusion. In this paper, we develop a few-shot semantic segmentation framework for infield fruits using transfer learning. Concretely, our work is aimed at addressing agricultural domains that lack publicly available labeled data. Motivated by similar success in urban scene parsing, we propose specialized pre-training using a public benchmark dataset for fruit transfer learning. By leveraging pre-trained neural networks, accurate semantic segmentation of fruit in the field is achieved with only a few labeled images. Furthermore, we show that models with pre-training learn to distinguish between fruit still on the trees and fruit that have fallen on the ground, and they can effectively transfer the knowledge to the target fruit dataset.</li>
</ul>

<h3>Title: A Literature Review and Framework for Human Evaluation of Generative  Large Language Models in Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Thomas Yu Chow Tam, Sonish Sivarajkumar, Sumit Kapoor, Alisa V Stolyar, Katelyn Polanska, Karleigh R McCarthy, Hunter Osterhoudt, Xizhi Wu, Shyam Visweswaran, Sunyang Fu, Piyush Mathur, Giovanni E. Cacciamani, Cong Sun, Yifan Peng, Yanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02559">https://arxiv.org/abs/2405.02559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02559">https://arxiv.org/pdf/2405.02559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02559]] A Literature Review and Framework for Human Evaluation of Generative  Large Language Models in Healthcare(https://arxiv.org/abs/2405.02559)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>As generative artificial intelligence (AI), particularly Large Language Models (LLMs), continues to permeate healthcare, it remains crucial to supplement traditional automated evaluations with human expert evaluation. Understanding and evaluating the generated texts is vital for ensuring safety, reliability, and effectiveness. However, the cumbersome, time-consuming, and non-standardized nature of human evaluation presents significant obstacles to the widespread adoption of LLMs in practice. This study reviews existing literature on human evaluation methodologies for LLMs within healthcare. We highlight a notable need for a standardized and consistent human evaluation approach. Our extensive literature search, adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, spans publications from January 2018 to February 2024. This review provides a comprehensive overview of the human evaluation approaches used in diverse healthcare applications.This analysis examines the human evaluation of LLMs across various medical specialties, addressing factors such as evaluation dimensions, sample types, and sizes, the selection and recruitment of evaluators, frameworks and metrics, the evaluation process, and statistical analysis of the results. Drawing from diverse evaluation strategies highlighted in these studies, we propose a comprehensive and practical framework for human evaluation of generative LLMs, named QUEST: Quality of Information, Understanding and Reasoning, Expression Style and Persona, Safety and Harm, and Trust and Confidence. This framework aims to improve the reliability, generalizability, and applicability of human evaluation of generative LLMs in different healthcare applications by defining clear evaluation dimensions and offering detailed guidelines.</li>
</ul>

<h3>Title: Leveraging the Human Ventral Visual Stream to Improve Neural Network  Robustness</h3>
<ul>
<li><strong>Authors: </strong>Zhenan Shao, Linjian Ma, Bo Li, Diane M. Beck</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02564">https://arxiv.org/abs/2405.02564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02564">https://arxiv.org/pdf/2405.02564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02564]] Leveraging the Human Ventral Visual Stream to Improve Neural Network  Robustness(https://arxiv.org/abs/2405.02564)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Human object recognition exhibits remarkable resilience in cluttered and dynamic visual environments. In contrast, despite their unparalleled performance across numerous visual tasks, Deep Neural Networks (DNNs) remain far less robust than humans, showing, for example, a surprising susceptibility to adversarial attacks involving image perturbations that are (almost) imperceptible to humans. Human object recognition likely owes its robustness, in part, to the increasingly resilient representations that emerge along the hierarchy of the ventral visual cortex. Here we show that DNNs, when guided by neural representations from a hierarchical sequence of regions in the human ventral visual stream, display increasing robustness to adversarial attacks. These neural-guided models also exhibit a gradual shift towards more human-like decision-making patterns and develop hierarchically smoother decision surfaces. Importantly, the resulting representational spaces differ in important ways from those produced by conventional smoothing methods, suggesting that such neural-guidance may provide previously unexplored robustness solutions. Our findings support the gradual emergence of human robustness along the ventral visual hierarchy and suggest that the key to DNN robustness may lie in increasing emulation of the human brain.</li>
</ul>

<h3>Title: ViTALS: Vision Transformer for Action Localization in Surgical  Nephrectomy</h3>
<ul>
<li><strong>Authors: </strong>Soumyadeep Chandra, Sayeed Shafayet Chowdhury, Courtney Yong, Chandru P. Sundaram, Kaushik Roy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02571">https://arxiv.org/abs/2405.02571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02571">https://arxiv.org/pdf/2405.02571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02571]] ViTALS: Vision Transformer for Action Localization in Surgical  Nephrectomy(https://arxiv.org/abs/2405.02571)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Surgical action localization is a challenging computer vision problem. While it has promising applications including automated training of surgery procedures, surgical workflow optimization, etc., appropriate model design is pivotal to accomplishing this task. Moreover, the lack of suitable medical datasets adds an additional layer of complexity. To that effect, we introduce a new complex dataset of nephrectomy surgeries called UroSlice. To perform the action localization from these videos, we propose a novel model termed as `ViTALS' (Vision Transformer for Action Localization in Surgical Nephrectomy). Our model incorporates hierarchical dilated temporal convolution layers and inter-layer residual connections to capture the temporal correlations at finer as well as coarser granularities. The proposed approach achieves state-of-the-art performance on Cholec80 and UroSlice datasets (89.8% and 66.1% accuracy, respectively), validating its effectiveness.</li>
</ul>

<h3>Title: A Combination of BERT and Transformer for Vietnamese Spelling Correction</h3>
<ul>
<li><strong>Authors: </strong>Hieu Ngo Trung, Duong Tran Ham, Tin Huynh, Kiem Hoang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02573">https://arxiv.org/abs/2405.02573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02573">https://arxiv.org/pdf/2405.02573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02573]] A Combination of BERT and Transformer for Vietnamese Spelling Correction(https://arxiv.org/abs/2405.02573)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently, many studies have shown the efficiency of using Bidirectional Encoder Representations from Transformers (BERT) in various Natural Language Processing (NLP) tasks. Specifically, English spelling correction task that uses Encoder-Decoder architecture and takes advantage of BERT has achieved state-of-the-art result. However, to our knowledge, there is no implementation in Vietnamese yet. Therefore, in this study, a combination of Transformer architecture (state-of-the-art for Encoder-Decoder model) and BERT was proposed to deal with Vietnamese spelling correction. The experiment results have shown that our model outperforms other approaches as well as the Google Docs Spell Checking tool, achieves an 86.24 BLEU score on this task.</li>
</ul>

<h3>Title: Better YOLO with Attention-Augmented Network and Enhanced Generalization  Performance for Safety Helmet Detection</h3>
<ul>
<li><strong>Authors: </strong>Shuqi Shen, Junjie Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02591">https://arxiv.org/abs/2405.02591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02591">https://arxiv.org/pdf/2405.02591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02591]] Better YOLO with Attention-Augmented Network and Enhanced Generalization  Performance for Safety Helmet Detection(https://arxiv.org/abs/2405.02591)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, extraction</a></li>
<li><strong>Abstract: </strong>Safety helmets play a crucial role in protecting workers from head injuries in construction sites, where potential hazards are prevalent. However, currently, there is no approach that can simultaneously achieve both model accuracy and performance in complex environments. In this study, we utilized a Yolo-based model for safety helmet detection, achieved a 2% improvement in mAP (mean Average Precision) performance while reducing parameters and Flops count by over 25%. YOLO(You Only Look Once) is a widely used, high-performance, lightweight model architecture that is well suited for complex environments. We presents a novel approach by incorporating a lightweight feature extraction network backbone based on GhostNetv2, integrating attention modules such as Spatial Channel-wise Attention Net(SCNet) and Coordination Attention Net(CANet), and adopting the Gradient Norm Aware optimizer (GAM) for improved generalization ability. In safety-critical environments, the accurate detection and speed of safety helmets plays a pivotal role in preventing occupational hazards and ensuring compliance with safety protocols. This work addresses the pressing need for robust and efficient helmet detection methods, offering a comprehensive framework that not only enhances accuracy but also improves the adaptability of detection models to real-world conditions. Our experimental results underscore the synergistic effects of GhostNetv2, attention modules, and the GAM optimizer, presenting a compelling solution for safety helmet detection that achieves superior performance in terms of accuracy, generalization, and efficiency.</li>
</ul>

<h3>Title: Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning</h3>
<ul>
<li><strong>Authors: </strong>Jing Xu, Jingzhao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02596">https://arxiv.org/abs/2405.02596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02596">https://arxiv.org/pdf/2405.02596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02596]] Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning(https://arxiv.org/abs/2405.02596)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLM) can be costly. Parameter-efficient fine-tuning (PEFT) addresses the problems by training a fraction of the parameters, whose success reveals the expressiveness and flexibility of pretrained models. This paper studies the limit of PEFT, by further simplifying its design and reducing the number of trainable parameters beyond standard setups. To this end, we use Random Masking to fine-tune the pretrained model. Despite its simplicity, we show that Random Masking is surprisingly effective: with a larger-than-expected learning rate, Random Masking can match the performance of standard PEFT algorithms such as LoRA on various tasks, using fewer trainable parameters. We provide both empirical and theoretical explorations into the success of Random Masking. We show that masking induces a flatter loss landscape and more distant solutions, which allows for and necessitates large learning rates.</li>
</ul>

<h3>Title: UDUC: An Uncertainty-driven Approach for Learning-based Robust Control</h3>
<ul>
<li><strong>Authors: </strong>Yuan Zhang, Jasper Hoffmann, Joschka Boedecker</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02598">https://arxiv.org/abs/2405.02598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02598">https://arxiv.org/pdf/2405.02598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02598]] UDUC: An Uncertainty-driven Approach for Learning-based Robust Control(https://arxiv.org/abs/2405.02598)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning-based techniques have become popular in both model predictive control (MPC) and reinforcement learning (RL). Probabilistic ensemble (PE) models offer a promising approach for modelling system dynamics, showcasing the ability to capture uncertainty and scalability in high-dimensional control scenarios. However, PE models are susceptible to mode collapse, resulting in non-robust control when faced with environments slightly different from the training set. In this paper, we introduce the $\textbf{u}$ncertainty-$\textbf{d}$riven rob$\textbf{u}$st $\textbf{c}$ontrol (UDUC) loss as an alternative objective for training PE models, drawing inspiration from contrastive learning. We analyze the robustness of UDUC loss through the lens of robust optimization and evaluate its performance on the challenging Real-world Reinforcement Learning (RWRL) benchmark, which involves significant environmental mismatches between the training and testing environments.</li>
</ul>

<h3>Title: Astro-NER -- Astronomy Named Entity Recognition: Is GPT a Good Domain  Expert Annotator?</h3>
<ul>
<li><strong>Authors: </strong>Julia Evans, Sameer Sadruddin, Jennifer D'Souza</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02602">https://arxiv.org/abs/2405.02602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02602">https://arxiv.org/pdf/2405.02602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02602]] Astro-NER -- Astronomy Named Entity Recognition: Is GPT a Good Domain  Expert Annotator?(https://arxiv.org/abs/2405.02602)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In this study, we address one of the challenges of developing NER models for scholarly domains, namely the scarcity of suitable labeled data. We experiment with an approach using predictions from a fine-tuned LLM model to aid non-domain experts in annotating scientific entities within astronomy literature, with the goal of uncovering whether such a collaborative process can approximate domain expertise. Our results reveal moderate agreement between a domain expert and the LLM-assisted non-experts, as well as fair agreement between the domain expert and the LLM model's predictions. In an additional experiment, we compare the performance of finetuned and default LLMs on this task. We have also introduced a specialized scientific entity annotation scheme for astronomy, validated by a domain expert. Our approach adopts a scholarly research contribution-centric perspective, focusing exclusively on scientific entities relevant to the research theme. The resultant dataset, containing 5,000 annotated astronomy article titles, is made publicly available.</li>
</ul>

<h3>Title: TetraBFT: Reducing Latency of Unauthenticated, Responsive BFT Consensus</h3>
<ul>
<li><strong>Authors: </strong>Qianyu Yu, Giuliano Losa, Xuechao Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02615">https://arxiv.org/abs/2405.02615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02615">https://arxiv.org/pdf/2405.02615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02615]] TetraBFT: Reducing Latency of Unauthenticated, Responsive BFT Consensus(https://arxiv.org/abs/2405.02615)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>This paper presents TetraBFT, a novel unauthenticated Byzantine fault tolerant protocol for solving consensus in partial synchrony, eliminating the need for public key cryptography and ensuring resilience against computationally unbounded adversaries. TetraBFT has several compelling features: it necessitates only constant local storage, has optimal communication complexity, satisfies optimistic responsiveness -- allowing the protocol to operate at actual network speeds under ideal conditions -- and can achieve consensus in just 5 message delays, which outperforms all known unauthenticated protocols achieving the other properties listed. We validate the correctness of TetraBFT through rigorous security analysis and formal verification. Furthermore, we extend TetraBFT into a multi-shot, chained consensus protocol, making a pioneering effort in applying pipelining techniques to unauthenticated protocols. This positions TetraBFT as a practical and deployable solution for blockchain systems aiming for high efficiency.</li>
</ul>

<h3>Title: Contrastive Dual-Interaction Graph Neural Network for Molecular Property  Prediction</h3>
<ul>
<li><strong>Authors: </strong>Zexing Zhao, Guangsi Shi, Xiaopeng Wu, Ruohua Ren, Xiaojun Gao, Fuyi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02628">https://arxiv.org/abs/2405.02628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02628">https://arxiv.org/pdf/2405.02628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02628]] Contrastive Dual-Interaction Graph Neural Network for Molecular Property  Prediction(https://arxiv.org/abs/2405.02628)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Molecular property prediction is a key component of AI-driven drug discovery and molecular characterization learning. Despite recent advances, existing methods still face challenges such as limited ability to generalize, and inadequate representation of learning from unlabeled data, especially for tasks specific to molecular structures. To address these limitations, we introduce DIG-Mol, a novel self-supervised graph neural network framework for molecular property prediction. This architecture leverages the power of contrast learning with dual interaction mechanisms and unique molecular graph enhancement strategies. DIG-Mol integrates a momentum distillation network with two interconnected networks to efficiently improve molecular characterization. The framework's ability to extract key information about molecular structure and higher-order semantics is supported by minimizing loss of contrast. We have established DIG-Mol's state-of-the-art performance through extensive experimental evaluation in a variety of molecular property prediction tasks. In addition to demonstrating superior transferability in a small number of learning scenarios, our visualizations highlight DIG-Mol's enhanced interpretability and representation capabilities. These findings confirm the effectiveness of our approach in overcoming challenges faced by traditional methods and mark a significant advance in molecular property prediction.</li>
</ul>

<h3>Title: SPARSE: Semantic Tracking and Path Analysis for Attack Investigation in  Real-time</h3>
<ul>
<li><strong>Authors: </strong>Jie Ying, Tiantian Zhu, Wenrui Cheng, Qixuan Yuan, Mingjun Ma, Chunlin Xiong, Tieming Chen, Mingqi Lv, Yan Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02629">https://arxiv.org/abs/2405.02629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02629">https://arxiv.org/pdf/2405.02629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02629]] SPARSE: Semantic Tracking and Path Analysis for Attack Investigation in  Real-time(https://arxiv.org/abs/2405.02629)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>As the complexity and destructiveness of Advanced Persistent Threat (APT) increase, there is a growing tendency to identify a series of actions undertaken to achieve the attacker's target, called attack investigation. Currently, analysts construct the provenance graph to perform causality analysis on Point-Of-Interest (POI) event for capturing critical events (related to the attack). However, due to the vast size of the provenance graph and the rarity of critical events, existing attack investigation methods suffer from problems of high false positives, high overhead, and high latency. To this end, we propose SPARSE, an efficient and real-time system for constructing critical component graphs (i.e., consisting of critical events) from streaming logs. Our key observation is 1) Critical events exist in a suspicious semantic graph (SSG) composed of interaction flows between suspicious entities, and 2) Information flows that accomplish attacker's goal exist in the form of paths. Therefore, SPARSE uses a two-stage framework to implement attack investigation (i.e., constructing the SSG and performing path-level contextual analysis). First, SPARSE operates in a state-based mode where events are consumed as streams, allowing easy access to the SSG related to the POI event through semantic transfer rule and storage strategy. Then, SPARSE identifies all suspicious flow paths (SFPs) related to the POI event from the SSG, quantifies the influence of each path to filter irrelevant events. Our evaluation on a real large-scale attack dataset shows that SPARSE can generate a critical component graph (~ 113 edges) in 1.6 seconds, which is 2014 X smaller than the backtracking graph (~ 227,589 edges). SPARSE is 25 X more effective than other state-of-the-art techniques in filtering irrelevant edges.</li>
</ul>

<h3>Title: PrivSGP-VR: Differentially Private Variance-Reduced Stochastic Gradient  Push with Tight Utility Bounds</h3>
<ul>
<li><strong>Authors: </strong>Zehan Zhu, Yan Huang, Xin Wang, Jinming Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02638">https://arxiv.org/abs/2405.02638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02638">https://arxiv.org/pdf/2405.02638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02638]] PrivSGP-VR: Differentially Private Variance-Reduced Stochastic Gradient  Push with Tight Utility Bounds(https://arxiv.org/abs/2405.02638)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a differentially private decentralized learning method (termed PrivSGP-VR) which employs stochastic gradient push with variance reduction and guarantees $(\epsilon, \delta)$-differential privacy (DP) for each node. Our theoretical analysis shows that, under DP Gaussian noise with constant variance, PrivSGP-VR achieves a sub-linear convergence rate of $\mathcal{O}(1/\sqrt{nK})$, where $n$ and $K$ are the number of nodes and iterations, respectively, which is independent of stochastic gradient variance, and achieves a linear speedup with respect to $n$. Leveraging the moments accountant method, we further derive an optimal $K$ to maximize the model utility under certain privacy budget in decentralized settings. With this optimized $K$, PrivSGP-VR achieves a tight utility bound of $\mathcal{O}\left( \sqrt{d\log \left( \frac{1}{\delta} \right)}/(\sqrt{n}J\epsilon) \right)$, where $J$ and $d$ are the number of local samples and the dimension of decision variable, respectively, which matches that of the server-client distributed counterparts, and exhibits an extra factor of $1/\sqrt{n}$ improvement compared to that of the existing decentralized counterparts, such as A(DP)$^2$SGD. Extensive experiments corroborate our theoretical findings, especially in terms of the maximized utility with optimized $K$, in fully decentralized settings.</li>
</ul>

<h3>Title: Machine Learning in Space: Surveying the Robustness of on-board ML  models to Radiation</h3>
<ul>
<li><strong>Authors: </strong>Kevin Lange, Federico Fontana, Francesco Rossi, Mattia Varile, Giovanni Apruzzese</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02642">https://arxiv.org/abs/2405.02642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02642">https://arxiv.org/pdf/2405.02642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02642]] Machine Learning in Space: Surveying the Robustness of on-board ML  models to Radiation(https://arxiv.org/abs/2405.02642)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern spacecraft are increasingly relying on machine learning (ML). However, physical equipment in space is subject to various natural hazards, such as radiation, which may inhibit the correct operation of computing devices. Despite plenty of evidence showing the damage that naturally-induced faults can cause to ML-related hardware, we observe that the effects of radiation on ML models for space applications are not well-studied. This is a problem: without understanding how ML models are affected by these natural phenomena, it is uncertain "where to start from" to develop radiation-tolerant ML software. As ML researchers, we attempt to tackle this dilemma. By partnering up with space-industry practitioners specialized in ML, we perform a reflective analysis of the state of the art. We provide factual evidence that prior work did not thoroughly examine the impact of natural hazards on ML models meant for spacecraft. Then, through a "negative result", we show that some existing open-source technologies can hardly be used by researchers to study the effects of radiation for some applications of ML in satellites. As a constructive step forward, we perform simple experiments showcasing how to leverage current frameworks to assess the robustness of practical ML models for cloud detection against radiation-induced faults. Our evaluation reveals that not all faults are as devastating as claimed by some prior work. By publicly releasing our resources, we provide a foothold -- usable by researchers without access to spacecraft -- for spearheading development of space-tolerant ML models.</li>
</ul>

<h3>Title: Updating Windows Malware Detectors: Balancing Robustness and Regression  against Adversarial EXEmples</h3>
<ul>
<li><strong>Authors: </strong>Matous Kozak, Luca Demetrio, Dmitrijs Trizna, Fabio Roli</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02646">https://arxiv.org/abs/2405.02646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02646">https://arxiv.org/pdf/2405.02646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02646]] Updating Windows Malware Detectors: Balancing Robustness and Regression  against Adversarial EXEmples(https://arxiv.org/abs/2405.02646)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial EXEmples are carefully-perturbed programs tailored to evade machine learning Windows malware detectors, with an on-going effort in developing robust models able to address detection effectiveness. However, even if robust models can prevent the majority of EXEmples, to maintain predictive power over time, models are fine-tuned to newer threats, leading either to partial updates or time-consuming retraining from scratch. Thus, even if the robustness against attacks is higher, the new models might suffer a regression in performance by misclassifying threats that were previously correctly detected. For these reasons, we study the trade-off between accuracy and regression when updating Windows malware detectors, by proposing EXE-scanner, a plugin that can be chained to existing detectors to promptly stop EXEmples without causing regression. We empirically show that previously-proposed hardening techniques suffer a regression of accuracy when updating non-robust models. On the contrary, we show that EXE-scanner exhibits comparable performance to robust models without regression of accuracy, and we show how to properly chain it after the base classifier to obtain the best performance without the need of costly retraining. To foster reproducibility, we openly release source code, along with the dataset of adversarial EXEmples based on state-of-the-art perturbation algorithms.</li>
</ul>

<h3>Title: A Conformal Prediction Score that is Robust to Label Noise</h3>
<ul>
<li><strong>Authors: </strong>Coby Penso, Jacob Goldberger</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02648">https://arxiv.org/abs/2405.02648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02648">https://arxiv.org/pdf/2405.02648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02648]] A Conformal Prediction Score that is Robust to Label Noise(https://arxiv.org/abs/2405.02648)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Conformal Prediction (CP) quantifies network uncertainty by building a small prediction set with a pre-defined probability that the correct class is within this set. In this study we tackle the problem of CP calibration based on a validation set with noisy labels. We introduce a conformal score that is robust to label noise. The noise-free conformal score is estimated using the noisy labeled data and the noise level. In the test phase the noise-free score is used to form the prediction set. We applied the proposed algorithm to several standard medical imaging classification datasets. We show that our method outperforms current methods by a large margin, in terms of the average size of the prediction set, while maintaining the required coverage.</li>
</ul>

<h3>Title: Generic Multi-modal Representation Learning for Network Traffic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Luca Gioacchini, Idilio Drago, Marco Mellia, Zied Ben Houidi, Dario Rossi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02649">https://arxiv.org/abs/2405.02649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02649">https://arxiv.org/pdf/2405.02649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02649]] Generic Multi-modal Representation Learning for Network Traffic Analysis(https://arxiv.org/abs/2405.02649)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Network traffic analysis is fundamental for network management, troubleshooting, and security. Tasks such as traffic classification, anomaly detection, and novelty discovery are fundamental for extracting operational information from network data and measurements. We witness the shift from deep packet inspection and basic machine learning to Deep Learning (DL) approaches where researchers define and test a custom DL architecture designed for each specific problem. We here advocate the need for a general DL architecture flexible enough to solve different traffic analysis tasks. We test this idea by proposing a DL architecture based on generic data adaptation modules, followed by an integration module that summarises the extracted information into a compact and rich intermediate representation (i.e. embeddings). The result is a flexible Multi-modal Autoencoder (MAE) pipeline that can solve different use cases. We demonstrate the architecture with traffic classification (TC) tasks since they allow us to quantitatively compare results with state-of-the-art solutions. However, we argue that the MAE architecture is generic and can be used to learn representations useful in multiple scenarios. On TC, the MAE performs on par or better than alternatives while avoiding cumbersome feature engineering, thus streamlining the adoption of DL solutions for traffic analysis.</li>
</ul>

<h3>Title: Deep Pulse-Signal Magnification for remote Heart Rate Estimation in  Compressed Videos</h3>
<ul>
<li><strong>Authors: </strong>Joaquim Comas, Adria Ruiz, Federico Sukno</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02652">https://arxiv.org/abs/2405.02652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02652">https://arxiv.org/pdf/2405.02652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02652]] Deep Pulse-Signal Magnification for remote Heart Rate Estimation in  Compressed Videos(https://arxiv.org/abs/2405.02652)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in remote heart rate measurement (rPPG), motivated by data-driven approaches, have significantly improved accuracy. However, certain challenges, such as video compression, still remain: recovering the rPPG signal from highly compressed videos is particularly complex. Although several studies have highlighted the difficulties and impact of video compression for this, effective solutions remain limited. In this paper, we present a novel approach to address the impact of video compression on rPPG estimation, which leverages a pulse-signal magnification transformation to adapt compressed videos to an uncompressed data domain in which the rPPG signal is magnified. We validate the effectiveness of our model by exhaustive evaluations on two publicly available datasets, UCLA-rPPG and UBFC-rPPG, employing both intra- and cross-database performance at several compression rates. Additionally, we assess the robustness of our approach on two additional highly compressed and widely-used datasets, MAHNOB-HCI and COHFACE, which reveal outstanding heart rate estimation results.</li>
</ul>

<h3>Title: R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Longtao Huang, Hui Xue, Xiaofeng He, Jun Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02659">https://arxiv.org/abs/2405.02659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02659">https://arxiv.org/pdf/2405.02659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02659]] R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large  Language Models(https://arxiv.org/abs/2405.02659)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented large language models (LLMs) leverage relevant content retrieved by information retrieval systems to generate correct responses, aiming to alleviate the hallucination problem. However, existing retriever-responder methods typically append relevant documents to the prompt of LLMs to perform text generation tasks without considering the interaction of fine-grained structural semantics between the retrieved documents and the LLMs. This issue is particularly important for accurate response generation as LLMs tend to ``lose in the middle'' when dealing with input prompts augmented with lengthy documents. In this work, we propose a new pipeline named ``Reinforced Retriever-Reorder-Responder'' (R$^4$) to learn document orderings for retrieval-augmented LLMs, thereby further enhancing their generation abilities while the large numbers of parameters of LLMs remain frozen. The reordering learning process is divided into two steps according to the quality of the generated responses: document order adjustment and document representation enhancement. Specifically, document order adjustment aims to organize retrieved document orderings into beginning, middle, and end positions based on graph attention learning, which maximizes the reinforced reward of response quality. Document representation enhancement further refines the representations of retrieved documents for responses of poor quality via document-level gradient adversarial learning. Extensive experiments demonstrate that our proposed pipeline achieves better factual question-answering performance on knowledge-intensive tasks compared to strong baselines across various public datasets. The source codes and trained models will be released upon paper acceptance.</li>
</ul>

<h3>Title: Metric Differential Privacy at the User-Level</h3>
<ul>
<li><strong>Authors: </strong>Jacob Imola, Amrita Roy Chowdhury, Kamalika Chaudhuri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02665">https://arxiv.org/abs/2405.02665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02665">https://arxiv.org/pdf/2405.02665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02665]] Metric Differential Privacy at the User-Level(https://arxiv.org/abs/2405.02665)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Metric differential privacy (DP) provides heterogeneous privacy guarantees based on a distance between the pair of inputs. It is a widely popular notion of privacy since it captures the natural privacy semantics for many applications (such as, for location data) and results in better utility than standard DP. However, prior work in metric DP has primarily focused on the \textit{item-level} setting where every user only reports a single data item. A more realistic setting is that of user-level DP where each user contributes multiple items and privacy is then desired at the granularity of the user's \textit{entire} contribution. In this paper, we initiate the study of metric DP at the user-level. Specifically, we use the earth-mover's distance ($d_\textsf{EM}$) as our metric to obtain a notion of privacy as it captures both the magnitude and spatial aspects of changes in a user's data. We make three main technical contributions. First, we design two novel mechanisms under $d_\textsf{EM}$-DP to answer linear queries and item-wise queries. Specifically, our analysis for the latter involves a generalization of the privacy amplification by shuffling result which may be of independent interest. Second, we provide a black-box reduction from the general unbounded to bounded $d_\textsf{EM}$-DP (size of the dataset is fixed and public) with a novel sampling based mechanism. Third, we show that our proposed mechanisms can provably provide improved utility over user-level DP, for certain types of linear queries and frequency estimation.</li>
</ul>

<h3>Title: From Generalization Analysis to Optimization Designs for State Space  Models</h3>
<ul>
<li><strong>Authors: </strong>Fusheng Liu, Qianxiao Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02670">https://arxiv.org/abs/2405.02670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02670">https://arxiv.org/pdf/2405.02670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02670]] From Generalization Analysis to Optimization Designs for State Space  Models(https://arxiv.org/abs/2405.02670)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>A State Space Model (SSM) is a foundation model in time series analysis, which has recently been shown as an alternative to transformers in sequence modeling. In this paper, we theoretically study the generalization of SSMs and propose improvements to training algorithms based on the generalization results. Specifically, we give a \textit{data-dependent} generalization bound for SSMs, showing an interplay between the SSM parameters and the temporal dependencies of the training sequences. Leveraging the generalization bound, we (1) set up a scaling rule for model initialization based on the proposed generalization measure, which significantly improves the robustness of the output value scales on SSMs to different temporal patterns in the sequence data; (2) introduce a new regularization method for training SSMs to enhance the generalization performance. Numerical results are conducted to validate our results.</li>
</ul>

<h3>Title: Evaluating the Ability of Computationally Extracted Narrative Maps to  Encode Media Framing</h3>
<ul>
<li><strong>Authors: </strong>Sebastián Concha Macías, Brian Keith Norambuena</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02677">https://arxiv.org/abs/2405.02677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02677">https://arxiv.org/pdf/2405.02677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02677]] Evaluating the Ability of Computationally Extracted Narrative Maps to  Encode Media Framing(https://arxiv.org/abs/2405.02677)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Narratives serve as fundamental frameworks in our understanding of the world and play a crucial role in collaborative sensemaking, providing a versatile foundation for sensemaking. Framing is a subtle yet potent mechanism that influences public perception through specific word choices, shaping interpretations of reported news events. Despite the recognized importance of narratives and framing, a significant gap exists in the literature with regard to the explicit consideration of framing within the context of computational extraction and representation. This article explores the capabilities of a specific narrative extraction and representation approach -- narrative maps -- to capture framing information from news data. The research addresses two key questions: (1) Does the narrative extraction method capture the framing distribution of the data set? (2) Does it produce a representation with consistent framing? Our results indicate that while the algorithm captures framing distributions, achieving consistent framing across various starting and ending events poses challenges. Our results highlight the potential of narrative maps to provide users with insights into the intricate framing dynamics within news narratives. However, we note that directly leveraging framing information in the computational narrative extraction process remains an open challenge.</li>
</ul>

<h3>Title: FedProK: Trustworthy Federated Class-Incremental Learning via  Prototypical Feature Knowledge Transfer</h3>
<ul>
<li><strong>Authors: </strong>Xin Gao, Xin Yang, Hao Yu, Yan Kang, Tianrui Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02685">https://arxiv.org/abs/2405.02685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02685">https://arxiv.org/pdf/2405.02685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02685]] FedProK: Trustworthy Federated Class-Incremental Learning via  Prototypical Feature Knowledge Transfer(https://arxiv.org/abs/2405.02685)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Class-Incremental Learning (FCIL) focuses on continually transferring the previous knowledge to learn new classes in dynamic Federated Learning (FL). However, existing methods do not consider the trustworthiness of FCIL, i.e., improving continual utility, privacy, and efficiency simultaneously, which is greatly influenced by catastrophic forgetting and data heterogeneity among clients. To address this issue, we propose FedProK (Federated Prototypical Feature Knowledge Transfer), leveraging prototypical feature as a novel representation of knowledge to perform spatial-temporal knowledge transfer. Specifically, FedProK consists of two components: (1) feature translation procedure on the client side by temporal knowledge transfer from the learned classes and (2) prototypical knowledge fusion on the server side by spatial knowledge transfer among clients. Extensive experiments conducted in both synchronous and asynchronous settings demonstrate that our FedProK outperforms the other state-of-the-art methods in three perspectives of trustworthiness, validating its effectiveness in selectively transferring spatial-temporal knowledge.</li>
</ul>

<h3>Title: Boosting 3D Neuron Segmentation with 2D Vision Transformer Pre-trained  on Natural Images</h3>
<ul>
<li><strong>Authors: </strong>Yik San Cheng, Runkai Zhao, Heng Wang, Hanchuan Peng, Weidong Cai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02686">https://arxiv.org/abs/2405.02686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02686">https://arxiv.org/pdf/2405.02686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02686]] Boosting 3D Neuron Segmentation with 2D Vision Transformer Pre-trained  on Natural Images(https://arxiv.org/abs/2405.02686)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Neuron reconstruction, one of the fundamental tasks in neuroscience, rebuilds neuronal morphology from 3D light microscope imaging data. It plays a critical role in analyzing the structure-function relationship of neurons in the nervous system. However, due to the scarcity of neuron datasets and high-quality SWC annotations, it is still challenging to develop robust segmentation methods for single neuron reconstruction. To address this limitation, we aim to distill the consensus knowledge from massive natural image data to aid the segmentation model in learning the complex neuron structures. Specifically, in this work, we propose a novel training paradigm that leverages a 2D Vision Transformer model pre-trained on large-scale natural images to initialize our Transformer-based 3D neuron segmentation model with a tailored 2D-to-3D weight transferring strategy. Our method builds a knowledge sharing connection between the abundant natural and the scarce neuron image domains to improve the 3D neuron segmentation ability in a data-efficiency manner. Evaluated on a popular benchmark, BigNeuron, our method enhances neuron segmentation performance by 8.71% over the model trained from scratch with the same amount of training samples.</li>
</ul>

<h3>Title: Diffeomorphic Transformer-based Abdomen MRI-CT Deformable Image  Registration</h3>
<ul>
<li><strong>Authors: </strong>Yang Lei, Luke A. Matkovic, Justin Roper, Tonghe Wang, Jun Zhou, Beth Ghavidel, Mark McDonald, Pretesh Patel, Xiaofeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02692">https://arxiv.org/abs/2405.02692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02692">https://arxiv.org/pdf/2405.02692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02692]] Diffeomorphic Transformer-based Abdomen MRI-CT Deformable Image  Registration(https://arxiv.org/abs/2405.02692)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This paper aims to create a deep learning framework that can estimate the deformation vector field (DVF) for directly registering abdominal MRI-CT images. The proposed method assumed a diffeomorphic deformation. By using topology-preserved deformation features extracted from the probabilistic diffeomorphic registration model, abdominal motion can be accurately obtained and utilized for DVF estimation. The model integrated Swin transformers, which have demonstrated superior performance in motion tracking, into the convolutional neural network (CNN) for deformation feature extraction. The model was optimized using a cross-modality image similarity loss and a surface matching loss. To compute the image loss, a modality-independent neighborhood descriptor (MIND) was used between the deformed MRI and CT images. The surface matching loss was determined by measuring the distance between the warped coordinates of the surfaces of contoured structures on the MRI and CT images. The deformed MRI image was assessed against the CT image using the target registration error (TRE), Dice similarity coefficient (DSC), and mean surface distance (MSD) between the deformed contours of the MRI image and manual contours of the CT image. When compared to only rigid registration, DIR with the proposed method resulted in an increase of the mean DSC values of the liver and portal vein from 0.850 and 0.628 to 0.903 and 0.763, a decrease of the mean MSD of the liver from 7.216 mm to 3.232 mm, and a decrease of the TRE from 26.238 mm to 8.492 mm. The proposed deformable image registration method based on a diffeomorphic transformer provides an effective and efficient way to generate an accurate DVF from an MRI-CT image pair of the abdomen. It could be utilized in the current treatment planning workflow for liver radiotherapy.</li>
</ul>

<h3>Title: DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent  Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Liangqi Lei, Keke Gai, Jing Yu, Liehuang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02696">https://arxiv.org/abs/2405.02696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02696">https://arxiv.org/pdf/2405.02696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02696]] DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent  Diffusion Model(https://arxiv.org/abs/2405.02696)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, watermark, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Latent Diffusion Models (LDMs) enable a wide range of applications but raise ethical concerns regarding illegal utilization.Adding watermarks to generative model outputs is a vital technique employed for copyright tracking and mitigating potential risks associated with AI-generated content. However, post-hoc watermarking techniques are susceptible to evasion. Existing watermarking methods for LDMs can only embed fixed messages. Watermark message alteration requires model retraining. The stability of the watermark is influenced by model updates and iterations. Furthermore, the current reconstruction-based watermark removal techniques utilizing variational autoencoders (VAE) and diffusion models have the capability to remove a significant portion of watermarks. Therefore, we propose a novel technique called DiffuseTrace. The goal is to embed invisible watermarks in all generated images for future detection semantically. The method establishes a unified representation of the initial latent variables and the watermark information through training an encoder-decoder model. The watermark information is embedded into the initial latent variables through the encoder and integrated into the sampling process. The watermark information is extracted by reversing the diffusion process and utilizing the decoder. DiffuseTrace does not rely on fine-tuning of the diffusion model components. The watermark is embedded into the image space semantically without compromising image quality. The encoder-decoder can be utilized as a plug-in in arbitrary diffusion models. We validate through experiments the effectiveness and flexibility of DiffuseTrace. DiffuseTrace holds an unprecedented advantage in combating the latest attacks based on variational autoencoders and Diffusion Models.</li>
</ul>

<h3>Title: Stable Diffusion Dataset Generation for Downstream Classification Tasks</h3>
<ul>
<li><strong>Authors: </strong>Eugenio Lomurno, Matteo D'Oria, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02698">https://arxiv.org/abs/2405.02698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02698">https://arxiv.org/pdf/2405.02698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02698]] Stable Diffusion Dataset Generation for Downstream Classification Tasks(https://arxiv.org/abs/2405.02698)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative artificial intelligence have enabled the creation of high-quality synthetic data that closely mimics real-world data. This paper explores the adaptation of the Stable Diffusion 2.0 model for generating synthetic datasets, using Transfer Learning, Fine-Tuning and generation parameter optimisation techniques to improve the utility of the dataset for downstream classification tasks. We present a class-conditional version of the model that exploits a Class-Encoder and optimisation of key generation parameters. Our methodology led to synthetic datasets that, in a third of cases, produced models that outperformed those trained on real datasets.</li>
</ul>

<h3>Title: Towards a Scalable Identification of Novel Modes in Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Jingwei Zhang, Mohammad Jalali, Cheuk Ting Li, Farzan Farnia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02700">https://arxiv.org/abs/2405.02700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02700">https://arxiv.org/pdf/2405.02700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02700]] Towards a Scalable Identification of Novel Modes in Generative Models(https://arxiv.org/abs/2405.02700)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>An interpretable comparison of generative models requires the identification of sample types produced more frequently by each of the involved models. While several quantitative scores have been proposed in the literature to rank different generative models, such score-based evaluations do not reveal the nuanced differences between the generative models in capturing various sample types. In this work, we propose a method called Fourier-based Identification of Novel Clusters (FINC) to identify modes produced by a generative model with a higher frequency in comparison to a reference distribution. FINC provides a scalable stochastic algorithm based on random Fourier features to estimate the eigenspace of kernel covariance matrices of two generative models and utilize the principal eigendirections to detect the sample types present more dominantly in each model. We demonstrate the application of the FINC method to standard computer vision datasets and generative model frameworks. Our numerical results suggest the scalability and efficiency of the developed Fourier-based method in highlighting the sample types captured with different frequencies by widely-used generative models.</li>
</ul>

<h3>Title: Enhancing News Summarization with ELearnFit through Efficient In-Context  Learning and Efficient Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Che Guan, Andrew Chin, Puya Vahabi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02710">https://arxiv.org/abs/2405.02710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02710">https://arxiv.org/pdf/2405.02710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02710]] Enhancing News Summarization with ELearnFit through Efficient In-Context  Learning and Efficient Fine-Tuning(https://arxiv.org/abs/2405.02710)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>With the deluge of information delivered by the daily news cycle, there is a growing need to effectively and efficiently summarize news feeds for quick consumption. We leverage large language models (LLMs), with their advanced learning and generative abilities as compared to conventional language models, to generate concise and coherent summaries for news articles from the XSum dataset. Our paper focuses on two key aspects of LLMs: Efficient in-context Learning (ELearn) and Parameter Efficient Fine-tuning (EFit). Under ELearn, we find that increasing the number of shots in prompts and utilizing simple templates generally improve the quality of summaries. We also find that utilizing relevant examples in few-shot learning for ELearn does not improve model performance. In addition, we studied EFit using different methods and demonstrate that fine-tuning the first layer of LLMs produces better outcomes as compared to fine-tuning other layers or utilizing LoRA. We also find that leveraging more relevant training samples using selective layers does not result in better performance. By combining ELearn and EFit, we create a new model (ELearnFit) that leverages the benefits of both few-shot learning and fine-tuning and produces superior performance to either model alone. We also use ELearnFit to highlight the trade-offs between prompting and fine-tuning, especially for situations where only a limited number of annotated samples are available. Ultimately, our research provides practical techniques to optimize news summarization during the prompting and fine-tuning stages and enhances the synthesis of news articles.</li>
</ul>

<h3>Title: CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with  Chain-of-Editions</h3>
<ul>
<li><strong>Authors: </strong>Hanchong Zhang, Ruisheng Cao, Hongshen Xu, Lu Chen, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02712">https://arxiv.org/abs/2405.02712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02712">https://arxiv.org/pdf/2405.02712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02712]] CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with  Chain-of-Editions(https://arxiv.org/abs/2405.02712)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, Large Language Models (LLMs) have been demonstrated to possess impressive capabilities in a variety of domains and tasks. We investigate the issue of prompt design in the multi-turn text-to-SQL task and attempt to enhance the LLMs' reasoning capacity when generating SQL queries. In the conversational context, the current SQL query can be modified from the preceding SQL query with only a few operations due to the context dependency. We introduce our method called CoE-SQL which can prompt LLMs to generate the SQL query based on the previously generated SQL query with an edition chain. We also conduct extensive ablation studies to determine the optimal configuration of our approach. Our approach outperforms different in-context learning baselines stably and achieves state-of-the-art performances on two benchmarks SParC and CoSQL using LLMs, which is also competitive to the SOTA fine-tuned models.</li>
</ul>

<h3>Title: AFter: Attention-based Fusion Router for RGBT Tracking</h3>
<ul>
<li><strong>Authors: </strong>Andong Lu, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02717">https://arxiv.org/abs/2405.02717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02717">https://arxiv.org/pdf/2405.02717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02717]] AFter: Attention-based Fusion Router for RGBT Tracking(https://arxiv.org/abs/2405.02717)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-modal feature fusion as a core investigative component of RGBT tracking emerges numerous fusion studies in recent years. However, existing RGBT tracking methods widely adopt fixed fusion structures to integrate multi-modal feature, which are hard to handle various challenges in dynamic scenarios. To address this problem, this work presents a novel \emph{A}ttention-based \emph{F}usion rou\emph{ter} called AFter, which optimizes the fusion structure to adapt to the dynamic challenging scenarios, for robust RGBT tracking. In particular, we design a fusion structure space based on the hierarchical attention network, each attention-based fusion unit corresponding to a fusion operation and a combination of these attention units corresponding to a fusion structure. Through optimizing the combination of attention-based fusion units, we can dynamically select the fusion structure to adapt to various challenging scenarios. Unlike complex search of different structures in neural architecture search algorithms, we develop a dynamic routing algorithm, which equips each attention-based fusion unit with a router, to predict the combination weights for efficient optimization of the fusion structure. Extensive experiments on five mainstream RGBT tracking datasets demonstrate the superior performance of the proposed AFter against state-of-the-art RGBT trackers. We release the code in https://github.com/Alexadlu/AFter.</li>
</ul>

<h3>Title: U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yuchuan Tian, Zhijun Tu, Hanting Chen, Jie Hu, Chao Xu, Yunhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02730">https://arxiv.org/abs/2405.02730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02730">https://arxiv.org/pdf/2405.02730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02730]] U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers(https://arxiv.org/abs/2405.02730)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiTs) introduce the transformer architecture to diffusion tasks for latent-space image generation. With an isotropic architecture that chains a series of transformer blocks, DiTs demonstrate competitive performance and good scalability; but meanwhile, the abandonment of U-Net by DiTs and their following improvements is worth rethinking. To this end, we conduct a simple toy experiment by comparing a U-Net architectured DiT with an isotropic one. It turns out that the U-Net architecture only gain a slight advantage amid the U-Net inductive bias, indicating potential redundancies within the U-Net-style DiT. Inspired by the discovery that U-Net backbone features are low-frequency-dominated, we perform token downsampling on the query-key-value tuple for self-attention and bring further improvements despite a considerable amount of reduction in computation. Based on self-attention with downsampled tokens, we propose a series of U-shaped DiTs (U-DiTs) in the paper and conduct extensive experiments to demonstrate the extraordinary performance of U-DiT models. The proposed U-DiT could outperform DiT-XL/2 with only 1/6 of its computation cost. Codes are available at https://github.com/YuchuanTian/U-DiT.</li>
</ul>

<h3>Title: Systematic Review: Anomaly Detection in Connected and Autonomous  Vehicles</h3>
<ul>
<li><strong>Authors: </strong>J. R. V. Solaas, N. Tuptuk, E. Mariconti</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02731">https://arxiv.org/abs/2405.02731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02731">https://arxiv.org/pdf/2405.02731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02731]] Systematic Review: Anomaly Detection in Connected and Autonomous  Vehicles(https://arxiv.org/abs/2405.02731)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>This systematic review focuses on anomaly detection for connected and autonomous vehicles. The initial database search identified 2160 articles, of which 203 were included in this review after rigorous screening and assessment. This study revealed that the most commonly used Artificial Intelligence (AI) algorithms employed in anomaly detection are neural networks like LSTM, CNN, and autoencoders, alongside one-class SVM. Most anomaly-based models were trained using real-world operational vehicle data, although anomalies, such as attacks and faults, were often injected artificially into the datasets. These models were evaluated mostly using five key evaluation metrics: recall, accuracy, precision, F1-score, and false positive rate. The most frequently used selection of evaluation metrics used for anomaly detection models were accuracy, precision, recall, and F1-score. This systematic review presents several recommendations. First, there is a need to incorporate multiple evaluation metrics to provide a comprehensive assessment of the anomaly detection models. Second, only a small proportion of the studies have made their models open source, indicating a need to share models publicly to facilitate collaboration within the research community, and to validate and compare findings effectively. Third, there is a need for benchmarking datasets with predefined anomalies or cyberattacks to test and improve the effectiveness of the proposed anomaly-based detection models. Furthermore, there is a need for future research to investigate the deployment of anomaly detection to a vehicle to assess its performance on the road. There is a notable lack of research done on intrusion detection systems using different protocols to CAN, such as Ethernet and FlexRay.</li>
</ul>

<h3>Title: Recall Them All: Retrieval-Augmented Language Models for Long Object  List Extraction from Long Documents</h3>
<ul>
<li><strong>Authors: </strong>Sneha Singhania, Simon Razniewski, Gerhard Weikum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02732">https://arxiv.org/abs/2405.02732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02732">https://arxiv.org/pdf/2405.02732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02732]] Recall Them All: Retrieval-Augmented Language Models for Long Object  List Extraction from Long Documents(https://arxiv.org/abs/2405.02732)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be spread across many passages in long texts. This poses the challenge of extracting long lists from long texts. We present the L3X method which tackles the problem in two stages: (1) recall-oriented generation using a large language model (LLM) with judicious techniques for retrieval augmentation, and (2) precision-oriented scrutinization to validate or prune candidates. Our L3X method outperforms LLM-only generations by a substantial margin.</li>
</ul>

<h3>Title: Relations Prediction for Knowledge Graph Completion using Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Sakher Khalil Alqaaidi, Krzysztof Kochut</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02738">https://arxiv.org/abs/2405.02738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02738">https://arxiv.org/pdf/2405.02738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02738]] Relations Prediction for Knowledge Graph Completion using Large Language  Models(https://arxiv.org/abs/2405.02738)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge Graphs have been widely used to represent facts in a structured format. Due to their large scale applications, knowledge graphs suffer from being incomplete. The relation prediction task obtains knowledge graph completion by assigning one or more possible relations to each pair of nodes. In this work, we make use of the knowledge graph node names to fine-tune a large language model for the relation prediction task. By utilizing the node names only we enable our model to operate sufficiently in the inductive settings. Our experiments show that we accomplish new scores on a widely used knowledge graph benchmark.</li>
</ul>

<h3>Title: Beyond Performance: Quantifying and Mitigating Label Bias in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yuval Reif, Roy Schwartz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02743">https://arxiv.org/abs/2405.02743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02743">https://arxiv.org/pdf/2405.02743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02743]] Beyond Performance: Quantifying and Mitigating Label Bias in LLMs(https://arxiv.org/abs/2405.02743)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable adaptability to diverse tasks, by leveraging context prompts containing instructions, or minimal input-output examples. However, recent work revealed they also exhibit label bias -- an undesirable preference toward predicting certain answers over others. Still, detecting and measuring this bias reliably and at scale has remained relatively unexplored. In this study, we evaluate different approaches to quantifying label bias in a model's predictions, conducting a comprehensive investigation across 279 classification tasks and ten LLMs. Our investigation reveals substantial label bias in models both before and after debiasing attempts, as well as highlights the importance of outcomes-based evaluation metrics, which were not previously used in this regard. We further propose a novel label bias calibration method tailored for few-shot prompting, which outperforms recent calibration approaches for both improving performance and mitigating label bias. Our results emphasize that label bias in the predictions of LLMs remains a barrier to their reliability.</li>
</ul>

<h3>Title: Understanding Server-Assisted Federated Learning in the Presence of  Incomplete Client Participation</h3>
<ul>
<li><strong>Authors: </strong>Haibo Yang, Peiwen Qiu, Prashant Khanduri, Minghong Fang, Jia Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02745">https://arxiv.org/abs/2405.02745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02745">https://arxiv.org/pdf/2405.02745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02745]] Understanding Server-Assisted Federated Learning in the Presence of  Incomplete Client Participation(https://arxiv.org/abs/2405.02745)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Existing works in federated learning (FL) often assume an ideal system with either full client or uniformly distributed client participation. However, in practice, it has been observed that some clients may never participate in FL training (aka incomplete client participation) due to a myriad of system heterogeneity factors. A popular approach to mitigate impacts of incomplete client participation is the server-assisted federated learning (SA-FL) framework, where the server is equipped with an auxiliary dataset. However, despite SA-FL has been empirically shown to be effective in addressing the incomplete client participation problem, there remains a lack of theoretical understanding for SA-FL. Meanwhile, the ramifications of incomplete client participation in conventional FL are also poorly understood. These theoretical gaps motivate us to rigorously investigate SA-FL. Toward this end, we first show that conventional FL is {\em not} PAC-learnable under incomplete client participation in the worst case. Then, we show that the PAC-learnability of FL with incomplete client participation can indeed be revived by SA-FL, which theoretically justifies the use of SA-FL for the first time. Lastly, to provide practical guidance for SA-FL training under {\em incomplete client participation}, we propose the $\mathsf{SAFARI}$ (server-assisted federated averaging) algorithm that enjoys the same linear convergence speedup guarantees as classic FL with ideal client participation assumptions, offering the first SA-FL algorithm with convergence guarantee. Extensive experiments on different datasets show $\mathsf{SAFARI}$ significantly improves the performance under incomplete client participation.</li>
</ul>

<h3>Title: Sub-goal Distillation: A Method to Improve Small Language Agents</h3>
<ul>
<li><strong>Authors: </strong>Maryam Hashemzadeh, Elias Stengel-Eskin, Sarath Chandar, Marc-Alexandre Cote</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02749">https://arxiv.org/abs/2405.02749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02749">https://arxiv.org/pdf/2405.02749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02749]] Sub-goal Distillation: A Method to Improve Small Language Agents(https://arxiv.org/abs/2405.02749)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have demonstrated significant promise as agents in interactive tasks, their substantial computational requirements and restricted number of calls constrain their practical utility, especially in long-horizon interactive tasks such as decision-making or in scenarios involving continuous ongoing tasks. To address these constraints, we propose a method for transferring the performance of an LLM with billions of parameters to a much smaller language model (770M parameters). Our approach involves constructing a hierarchical agent comprising a planning module, which learns through Knowledge Distillation from an LLM to generate sub-goals, and an execution module, which learns to accomplish these sub-goals using elementary actions. In detail, we leverage an LLM to annotate an oracle path with a sequence of sub-goals towards completing a goal. Subsequently, we utilize this annotated data to fine-tune both the planning and execution modules. Importantly, neither module relies on real-time access to an LLM during inference, significantly reducing the overall cost associated with LLM interactions to a fixed cost. In ScienceWorld, a challenging and multi-task interactive text environment, our method surpasses standard imitation learning based solely on elementary actions by 16.7% (absolute). Our analysis highlights the efficiency of our approach compared to other LLM-based methods. Our code and annotated data for distillation can be found on GitHub.</li>
</ul>

<h3>Title: Enhancing Contextual Understanding in Large Language Models through  Contrastive Decoding</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhao, Emilio Monti, Jens Lehmann, Haytham Assem</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02750">https://arxiv.org/abs/2405.02750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02750">https://arxiv.org/pdf/2405.02750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02750]] Enhancing Contextual Understanding in Large Language Models through  Contrastive Decoding(https://arxiv.org/abs/2405.02750)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) tend to inadequately integrate input context during text generation, relying excessively on encoded prior knowledge in model parameters, potentially resulting in generated text with factual inconsistencies or contextually unfaithful content. LLMs utilize two primary knowledge sources: 1) prior (parametric) knowledge from pretraining, and 2) contextual (non-parametric) knowledge from input prompts. The study addresses the open question of how LLMs effectively balance these knowledge sources during the generation process, specifically in the context of open-domain question answering. To address this issue, we introduce a novel approach integrating contrastive decoding with adversarial irrelevant passages as negative samples to enhance robust context grounding during generation. Notably, our method operates at inference time without requiring further training. We conduct comprehensive experiments to demonstrate its applicability and effectiveness, providing empirical evidence showcasing its superiority over existing methodologies. Our code is publicly available at: https://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.</li>
</ul>

<h3>Title: Assessing Adversarial Robustness of Large Language Models: An Empirical  Study</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Yang, Zhao Meng, Xiaochen Zheng, Roger Wattenhofer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02764">https://arxiv.org/abs/2405.02764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02764">https://arxiv.org/pdf/2405.02764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02764]] Assessing Adversarial Robustness of Large Language Models: An Empirical  Study(https://arxiv.org/abs/2405.02764)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized natural language processing, but their robustness against adversarial attacks remains a critical concern. We presents a novel white-box style attack approach that exposes vulnerabilities in leading open-source LLMs, including Llama, OPT, and T5. We assess the impact of model size, structure, and fine-tuning strategies on their resistance to adversarial perturbations. Our comprehensive evaluation across five diverse text classification tasks establishes a new benchmark for LLM robustness. The findings of this study have far-reaching implications for the reliable deployment of LLMs in real-world applications and contribute to the advancement of trustworthy AI systems.</li>
</ul>

<h3>Title: Beyond Unimodal Learning: The Importance of Integrating Multiple  Modalities for Lifelong Learning</h3>
<ul>
<li><strong>Authors: </strong>Fahad Sarfraz, Bahram Zonooz, Elahe Arani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02766">https://arxiv.org/abs/2405.02766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02766">https://arxiv.org/pdf/2405.02766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02766]] Beyond Unimodal Learning: The Importance of Integrating Multiple  Modalities for Lifelong Learning(https://arxiv.org/abs/2405.02766)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While humans excel at continual learning (CL), deep neural networks (DNNs) exhibit catastrophic forgetting. A salient feature of the brain that allows effective CL is that it utilizes multiple modalities for learning and inference, which is underexplored in DNNs. Therefore, we study the role and interactions of multiple modalities in mitigating forgetting and introduce a benchmark for multimodal continual learning. Our findings demonstrate that leveraging multiple views and complementary information from multiple modalities enables the model to learn more accurate and robust representations. This makes the model less vulnerable to modality-specific regularities and considerably mitigates forgetting. Furthermore, we observe that individual modalities exhibit varying degrees of robustness to distribution shift. Finally, we propose a method for integrating and aligning the information from different modalities by utilizing the relational structural similarities between the data points in each modality. Our method sets a strong baseline that enables both single- and multimodal inference. Our study provides a promising case for further exploring the role of multiple modalities in enabling CL and provides a standard benchmark for future research.</li>
</ul>

<h3>Title: MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial  Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Vishal Nedungadi, Ankit Kariryaa, Stefan Oehmcke, Serge Belongie, Christian Igel, Nico Lang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02771">https://arxiv.org/abs/2405.02771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02771">https://arxiv.org/pdf/2405.02771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02771]] MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial  Representation Learning(https://arxiv.org/abs/2405.02771)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The volume of unlabelled Earth observation (EO) data is huge, but many important applications lack labelled training data. However, EO data offers the unique opportunity to pair data from different modalities and sensors automatically based on geographic location and time, at virtually no human labor cost. We seize this opportunity to create a diverse multi-modal pretraining dataset at global scale. Using this new corpus of 1.2 million locations, we propose a Multi-Pretext Masked Autoencoder (MP-MAE) approach to learn general-purpose representations for optical satellite images. Our approach builds on the ConvNeXt V2 architecture, a fully convolutional masked autoencoder (MAE). Drawing upon a suite of multi-modal pretext tasks, we demonstrate that our MP-MAE approach outperforms both MAEs pretrained on ImageNet and MAEs pretrained on domain-specific satellite images. This is shown on several downstream tasks including image classification and semantic segmentation. We find that multi-modal pretraining notably improves the linear probing performance, e.g. 4pp on BigEarthNet and 16pp on So2Sat, compared to pretraining on optical satellite images only. We show that this also leads to better label and parameter efficiency which are crucial aspects in global scale applications.</li>
</ul>

<h3>Title: Fused attention mechanism-based ore sorting network</h3>
<ul>
<li><strong>Authors: </strong>Junjiang Zhen, Bojun Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02785">https://arxiv.org/abs/2405.02785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02785">https://arxiv.org/pdf/2405.02785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02785]] Fused attention mechanism-based ore sorting network(https://arxiv.org/abs/2405.02785)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Deep learning has had a significant impact on the identification and classification of mineral resources, especially playing a key role in efficiently and accurately identifying different minerals, which is important for improving the efficiency and accuracy of mining. However, traditional ore sorting meth- ods often suffer from inefficiency and lack of accuracy, especially in complex mineral environments. To address these challenges, this study proposes a method called OreYOLO, which incorporates an attentional mechanism and a multi-scale feature fusion strategy, based on ore data from gold and sul- fide ores. By introducing the progressive feature pyramid structure into YOLOv5 and embedding the attention mechanism in the feature extraction module, the detection performance and accuracy of the model are greatly improved. In order to adapt to the diverse ore sorting scenarios and the deployment requirements of edge devices, the network structure is designed to be lightweight, which achieves a low number of parameters (3.458M) and computational complexity (6.3GFLOPs) while maintaining high accuracy (99.3% and 99.2%, respectively). In the experimental part, a target detection dataset containing 6000 images of gold and sulfuric iron ore is constructed for gold and sulfuric iron ore classification training, and several sets of comparison experiments are set up, including the YOLO series, EfficientDet, Faster-RCNN, and CenterNet, etc., and the experiments prove that OreYOLO outperforms the commonly used high-performance object detection of these architectures</li>
</ul>

<h3>Title: Light Field Spatial Resolution Enhancement Framework</h3>
<ul>
<li><strong>Authors: </strong>Javeria Shabbir, Muhammad Zeshan.Alam, M.Umair Mukati</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02787">https://arxiv.org/abs/2405.02787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02787">https://arxiv.org/pdf/2405.02787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02787]] Light Field Spatial Resolution Enhancement Framework(https://arxiv.org/abs/2405.02787)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Light field (LF) imaging captures both angular and spatial light distributions, enabling advanced photographic techniques. However, micro-lens array (MLA)- based cameras face a spatial-angular resolution tradeoff due to a single shared sensor. We propose a novel light field framework for resolution enhancement, employing a modular approach. The first module generates a high-resolution, all-in-focus image. The second module, a texture transformer network, enhances the resolution of each light field perspective independently using the output of the first module as a reference image. The final module leverages light field regularity to jointly improve resolution across all LF image perspectives. Our approach demonstrates superior performance to existing methods in both qualitative and quantitative evaluations.</li>
</ul>

<h3>Title: Confidential and Protected Disease Classifier using Fully Homomorphic  Encryption</h3>
<ul>
<li><strong>Authors: </strong>Aditya Malik, Nalini Ratha, Bharat Yalavarthi, Tilak Sharma, Arjun Kaushik, Charanjit Jutla</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02790">https://arxiv.org/abs/2405.02790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02790">https://arxiv.org/pdf/2405.02790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02790]] Confidential and Protected Disease Classifier using Fully Homomorphic  Encryption(https://arxiv.org/abs/2405.02790)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the rapid surge in the prevalence of Large Language Models (LLMs), individuals are increasingly turning to conversational AI for initial insights across various domains, including health-related inquiries such as disease diagnosis. Many users seek potential causes on platforms like ChatGPT or Bard before consulting a medical professional for their ailment. These platforms offer valuable benefits by streamlining the diagnosis process, alleviating the significant workload of healthcare practitioners, and saving users both time and money by avoiding unnecessary doctor visits. However, Despite the convenience of such platforms, sharing personal medical data online poses risks, including the presence of malicious platforms or potential eavesdropping by attackers. To address privacy concerns, we propose a novel framework combining FHE and Deep Learning for a secure and private diagnosis system. Operating on a question-and-answer-based model akin to an interaction with a medical practitioner, this end-to-end secure system employs Fully Homomorphic Encryption (FHE) to handle encrypted input data. Given FHE's computational constraints, we adapt deep neural networks and activation functions to the encryted domain. Further, we also propose a faster algorithm to compute summation of ciphertext elements. Through rigorous experiments, we demonstrate the efficacy of our approach. The proposed framework achieves strict security and privacy with minimal loss in performance.</li>
</ul>

<h3>Title: Efficient Text-driven Motion Generation via Latent Consistency Training</h3>
<ul>
<li><strong>Authors: </strong>Mengxian Hu, Minghao Zhu, Xun Zhou, Qingqing Yan, Shu Li, Chengju Liu, Qijun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02791">https://arxiv.org/abs/2405.02791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02791">https://arxiv.org/pdf/2405.02791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02791]] Efficient Text-driven Motion Generation via Latent Consistency Training(https://arxiv.org/abs/2405.02791)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Motion diffusion models have recently proven successful for text-driven human motion generation. Despite their excellent generation performance, they are challenging to infer in real time due to the multi-step sampling mechanism that involves tens or hundreds of repeat function evaluation iterations. To this end, we investigate a motion latent consistency Training (MLCT) for motion generation to alleviate the computation and time consumption during iteration inference. It applies diffusion pipelines to low-dimensional motion latent spaces to mitigate the computational burden of each function evaluation. Explaining the diffusion process with probabilistic flow ordinary differential equation (PF-ODE) theory, the MLCT allows extremely few steps infer between the prior distribution to the motion latent representation distribution via maintaining consistency of the outputs over the trajectory of PF-ODE. Especially, we introduce a quantization constraint to optimize motion latent representations that are bounded, regular, and well-reconstructed compared to traditional variational constraints. Furthermore, we propose a conditional PF-ODE trajectory simulation method, which improves the conditional generation performance with minimal additional training costs. Extensive experiments on two human motion generation benchmarks show that the proposed model achieves state-of-the-art performance with less than 10\% time cost.</li>
</ul>

<h3>Title: Graph as Point Set</h3>
<ul>
<li><strong>Authors: </strong>Xiyuan Wang, Pan Li, Muhan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02795">https://arxiv.org/abs/2405.02795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02795">https://arxiv.org/pdf/2405.02795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02795]] Graph as Point Set(https://arxiv.org/abs/2405.02795)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph is a fundamental data structure to model interconnections between entities. Set, on the contrary, stores independent elements. To learn graph representations, current Graph Neural Networks (GNNs) primarily use message passing to encode the interconnections. In contrast, this paper introduces a novel graph-to-set conversion method that bijectively transforms interconnected nodes into a set of independent points and then uses a set encoder to learn the graph representation. This conversion method holds dual significance. Firstly, it enables using set encoders to learn from graphs, thereby significantly expanding the design space of GNNs. Secondly, for Transformer, a specific set encoder, we provide a novel and principled approach to inject graph information losslessly, different from all the heuristic structural/positional encoding methods adopted in previous graph transformers. To demonstrate the effectiveness of our approach, we introduce Point Set Transformer (PST), a transformer architecture that accepts a point set converted from a graph as input. Theoretically, PST exhibits superior expressivity for both short-range substructure counting and long-range shortest path distance tasks compared to existing GNNs. Extensive experiments further validate PST's outstanding real-world performance. Besides Transformer, we also devise a Deepset-based set encoder, which achieves performance comparable to representative GNNs, affirming the versatility of our graph-to-set method.</li>
</ul>

<h3>Title: Adapting to Distribution Shift by Visual Domain Prompt Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhixiang Chi, Li Gu, Tao Zhong, Huan Liu, Yuanhao Yu, Konstantinos N Plataniotis, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02797">https://arxiv.org/abs/2405.02797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02797">https://arxiv.org/pdf/2405.02797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02797]] Adapting to Distribution Shift by Visual Domain Prompt Generation(https://arxiv.org/abs/2405.02797)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we aim to adapt a model at test-time using a few unlabeled data to address distribution shifts. To tackle the challenges of extracting domain knowledge from a limited amount of data, it is crucial to utilize correlated information from pre-trained backbones and source domains. Previous studies fail to utilize recent foundation models with strong out-of-distribution generalization. Additionally, domain-centric designs are not flavored in their works. Furthermore, they employ the process of modelling source domains and the process of learning to adapt independently into disjoint training stages. In this work, we propose an approach on top of the pre-computed features of the foundation model. Specifically, we build a knowledge bank to learn the transferable knowledge from source domains. Conditioned on few-shot target data, we introduce a domain prompt generator to condense the knowledge bank into a domain-specific prompt. The domain prompt then directs the visual features towards a particular domain via a guidance module. Moreover, we propose a domain-aware contrastive loss and employ meta-learning to facilitate domain knowledge extraction. Extensive experiments are conducted to validate the domain knowledge extraction. The proposed method outperforms previous work on 5 large-scale benchmarks including WILDS and DomainNet.</li>
</ul>

<h3>Title: Is Flash Attention Stable?</h3>
<ul>
<li><strong>Authors: </strong>Alicia Golden, Samuel Hsia, Fei Sun, Bilge Acun, Basil Hosmer, Yejin Lee, Zachary DeVito, Jeff Johnson, Gu-Yeon Wei, David Brooks, Carole-Jean Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02803">https://arxiv.org/abs/2405.02803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02803">https://arxiv.org/pdf/2405.02803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02803]] Is Flash Attention Stable?(https://arxiv.org/abs/2405.02803)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Training large-scale machine learning models poses distinct system challenges, given both the size and complexity of today's workloads. Recently, many organizations training state-of-the-art Generative AI models have reported cases of instability during training, often taking the form of loss spikes. Numeric deviation has emerged as a potential cause of this training instability, although quantifying this is especially challenging given the costly nature of training runs. In this work, we develop a principled approach to understanding the effects of numeric deviation, and construct proxies to put observations into context when downstream effects are difficult to quantify. As a case study, we apply this framework to analyze the widely-adopted Flash Attention optimization. We find that Flash Attention sees roughly an order of magnitude more numeric deviation as compared to Baseline Attention at BF16 when measured during an isolated forward pass. We then use a data-driven analysis based on the Wasserstein Distance to provide upper bounds on how this numeric deviation impacts model weights during training, finding that the numerical deviation present in Flash Attention is 2-5 times less significant than low-precision training.</li>
</ul>

<h3>Title: Verlet Flows: Exact-Likelihood Integrators for Flow-Based Generative  Models</h3>
<ul>
<li><strong>Authors: </strong>Ezra Erives, Bowen Jing, Tommi Jaakkola</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02805">https://arxiv.org/abs/2405.02805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02805">https://arxiv.org/pdf/2405.02805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02805]] Verlet Flows: Exact-Likelihood Integrators for Flow-Based Generative  Models(https://arxiv.org/abs/2405.02805)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Approximations in computing model likelihoods with continuous normalizing flows (CNFs) hinder the use of these models for importance sampling of Boltzmann distributions, where exact likelihoods are required. In this work, we present Verlet flows, a class of CNFs on an augmented state-space inspired by symplectic integrators from Hamiltonian dynamics. When used with carefully constructed Taylor-Verlet integrators, Verlet flows provide exact-likelihood generative models which generalize coupled flow architectures from a non-continuous setting while imposing minimal expressivity constraints. On experiments over toy densities, we demonstrate that the variance of the commonly used Hutchinson trace estimator is unsuitable for importance sampling, whereas Verlet flows perform comparably to full autograd trace computations while being significantly faster.</li>
</ul>

<h3>Title: Kinematic analysis of structural mechanics based on convolutional neural  network</h3>
<ul>
<li><strong>Authors: </strong>Leye Zhang, Xiangxiang Tian, Hongjun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02807">https://arxiv.org/abs/2405.02807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02807">https://arxiv.org/pdf/2405.02807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02807]] Kinematic analysis of structural mechanics based on convolutional neural  network(https://arxiv.org/abs/2405.02807)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Attempt to use convolutional neural network to achieve kinematic analysis of plane bar structure. Through 3dsMax animation software and OpenCV module, self-build image dataset of geometrically stable system and geometrically unstable system. we construct and train convolutional neural network model based on the TensorFlow and Keras deep learning platform framework. The model achieves 100% accuracy on the training set, validation set, and test set. The accuracy on the additional test set is 93.7%, indicating that convolutional neural network can learn and master the relevant knowledge of kinematic analysis of structural mechanics. In the future, the generalization ability of the model can be improved through the diversity of dataset, which has the potential to surpass human experts for complex structures. Convolutional neural network has certain practical value in the field of kinematic analysis of structural mechanics. Using visualization technology, we reveal how convolutional neural network learns and recognizes structural features. Using pre-trained VGG16 model for feature extraction and fine-tuning, we found that the generalization ability is inferior to the self-built model.</li>
</ul>

<h3>Title: PVTransformer: Point-to-Voxel Transformer for Scalable 3D Object  Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhaoqi Leng, Pei Sun, Tong He, Dragomir Anguelov, Mingxing Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02811">https://arxiv.org/abs/2405.02811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02811">https://arxiv.org/pdf/2405.02811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02811]] PVTransformer: Point-to-Voxel Transformer for Scalable 3D Object  Detection(https://arxiv.org/abs/2405.02811)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>3D object detectors for point clouds often rely on a pooling-based PointNet to encode sparse points into grid-like voxels or pillars. In this paper, we identify that the common PointNet design introduces an information bottleneck that limits 3D object detection accuracy and scalability. To address this limitation, we propose PVTransformer: a transformer-based point-to-voxel architecture for 3D detection. Our key idea is to replace the PointNet pooling operation with an attention module, leading to a better point-to-voxel aggregation function. Our design respects the permutation invariance of sparse 3D points while being more expressive than the pooling-based PointNet. Experimental results show our PVTransformer achieves much better performance compared to the latest 3D object detectors. On the widely used Waymo Open Dataset, our PVTransformer achieves state-of-the-art 76.5 mAPH L2, outperforming the prior art of SWFormer by +1.7 mAPH L2.</li>
</ul>

<h3>Title: NegativePrompt: Leveraging Psychology for Large Language Models  Enhancement via Negative Emotional Stimuli</h3>
<ul>
<li><strong>Authors: </strong>Xu Wang, Cheng Li, Yi Chang, Jindong Wang, Yuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02814">https://arxiv.org/abs/2405.02814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02814">https://arxiv.org/pdf/2405.02814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02814]] NegativePrompt: Leveraging Psychology for Large Language Models  Enhancement via Negative Emotional Stimuli(https://arxiv.org/abs/2405.02814)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive research into LLMs across various disciplines, including the social sciences. Notably, studies have revealed that LLMs possess emotional intelligence, which can be further developed through positive emotional stimuli. This discovery raises an intriguing question: can negative emotions similarly influence LLMs, potentially enhancing their performance? In response to this question, we introduce NegativePrompt, a novel approach underpinned by psychological principles, involving ten specifically designed negative emotional stimuli. We embark on rigorous experimental evaluations of five LLMs including Flan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across a set of 45 tasks. The results are revealing: NegativePrompt markedly enhances the performance of LLMs, evidenced by relative improvements of 12.89% in Instruction Induction tasks and 46.25% in BIG-Bench tasks. Moreover, we conduct attention visualization experiments to decipher the underlying mechanisms of NegativePrompt's influence. Our research contributes significantly to the understanding of LLMs and emotion interaction, demonstrating the practical efficacy of NegativePrompt as an emotion-driven method and offering novel insights for the enhancement of LLMs in real-world applications. The code is available at https://github.com/wangxu0820/NegativePrompt.</li>
</ul>

<h3>Title: Region-specific Risk Quantification for Interpretable Prognosis of  COVID-19</h3>
<ul>
<li><strong>Authors: </strong>Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02815">https://arxiv.org/abs/2405.02815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02815">https://arxiv.org/pdf/2405.02815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02815]] Region-specific Risk Quantification for Interpretable Prognosis of  COVID-19(https://arxiv.org/abs/2405.02815)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The COVID-19 pandemic has strained global public health, necessitating accurate diagnosis and intervention to control disease spread and reduce mortality rates. This paper introduces an interpretable deep survival prediction model designed specifically for improved understanding and trust in COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale pretrained image encoder, Risk-specific Grad-CAM, and anatomical region detection techniques, our approach produces regional interpretable outcomes that effectively capture essential disease features while focusing on rare but critical abnormal regions. Our model's predictive results provide enhanced clarity and transparency through risk area localization, enabling clinicians to make informed decisions regarding COVID-19 diagnosis with better understanding of prognostic insights. We evaluate the proposed method on a multi-center survival dataset and demonstrate its effectiveness via quantitative and qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and time-dependent AUCs (0.799 and 0.691). These results suggest that our explainable deep survival prediction model surpasses traditional survival analysis methods in risk prediction, improving interpretability for clinical decision making and enhancing AI system trustworthiness.</li>
</ul>

<h3>Title: Stochastic RAG: End-to-End Retrieval-Augmented Generation through  Expected Utility Maximization</h3>
<ul>
<li><strong>Authors: </strong>Hamed Zamani, Michael Bendersky</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02816">https://arxiv.org/abs/2405.02816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02816">https://arxiv.org/pdf/2405.02816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02816]] Stochastic RAG: End-to-End Retrieval-Augmented Generation through  Expected Utility Maximization(https://arxiv.org/abs/2405.02816)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper introduces Stochastic RAG--a novel approach for end-to-end optimization of retrieval-augmented generation (RAG) models that relaxes the simplifying assumptions of marginalization and document independence, made in most prior work. Stochastic RAG casts the retrieval process in RAG as a stochastic sampling without replacement process. Through this formulation, we employ straight-through Gumbel-top-k that provides a differentiable approximation for sampling without replacement and enables effective end-to-end optimization for RAG. We conduct extensive experiments on seven diverse datasets on a wide range of tasks, from open-domain question answering to fact verification to slot-filling for relation extraction and to dialogue systems. By applying this optimization method to a recent and effective RAG model, we advance state-of-the-art results on six out of seven datasets.</li>
</ul>

<h3>Title: HuixiangDou-CR: Coreference Resolution in Group Chats</h3>
<ul>
<li><strong>Authors: </strong>Huanjun Kong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02817">https://arxiv.org/abs/2405.02817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02817">https://arxiv.org/pdf/2405.02817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02817]] HuixiangDou-CR: Coreference Resolution in Group Chats(https://arxiv.org/abs/2405.02817)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>How to eliminate pronominal reference in group chats? In this work, we have preprocessed 58k authentic chat data and manually annotated 2.3k questions. The reliability of this annotation was confirmed by the scaling law. After this, we conducted fine-tuning on Qwen models, ranging from 0.5B to 32B parameters. The optimal version improved 29.07 in F1 score. This confirms the viability of fine-tuning Large Language Model (LLM) for downstream Natural Language Processing (NLP) tasks. Our contributions are: 1) Created Supervised Fine-Tuning (SFT) training data in alpaca format, along with a set of Low-Rank Adaptation (LoRA) weights, and 2) Developed a method for acquiring high-quality data leveraging scaling law principle. The script, raw data with alpaca format and experiments track are open-sourced on Github https://github.com/InternLM/HuixiangDou/tree/main/web/tools, HuggingFace https://huggingface.co/tpoisonooo and WandB https://wandb.ai/tpoisonooo/huixiangdou-cr/table?nw=nwusertpoisonooo . The privacy of the data involved has been authorized by users.</li>
</ul>

<h3>Title: Adaptive Guidance Learning for Camouflaged Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhennan Chen, Xuying Zhang, Tian-Zhu Xiang, Ying Tai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02824">https://arxiv.org/abs/2405.02824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02824">https://arxiv.org/pdf/2405.02824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02824]] Adaptive Guidance Learning for Camouflaged Object Detection(https://arxiv.org/abs/2405.02824)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Camouflaged object detection (COD) aims to segment objects visually embedded in their surroundings, which is a very challenging task due to the high similarity between the objects and the background. To address it, most methods often incorporate additional information (e.g., boundary, texture, and frequency clues) to guide feature learning for better detecting camouflaged objects from the background. Although progress has been made, these methods are basically individually tailored to specific auxiliary cues, thus lacking adaptability and not consistently achieving high segmentation performance. To this end, this paper proposes an adaptive guidance learning network, dubbed \textit{AGLNet}, which is a unified end-to-end learnable model for exploring and adapting different additional cues in CNN models to guide accurate camouflaged feature learning. Specifically, we first design a straightforward additional information generation (AIG) module to learn additional camouflaged object cues, which can be adapted for the exploration of effective camouflaged features. Then we present a hierarchical feature combination (HFC) module to deeply integrate additional cues and image features to guide camouflaged feature learning in a multi-level fusion manner.Followed by a recalibration decoder (RD), different features are further aggregated and refined for accurate object prediction. Extensive experiments on three widely used COD benchmark datasets demonstrate that the proposed method achieves significant performance improvements under different additional cues, and outperforms the recent 20 state-of-the-art methods by a large margin. Our code will be made publicly available at: \textcolor{blue}{{https://github.com/ZNan-Chen/AGLNet}}.</li>
</ul>

<h3>Title: Nip in the Bud: Forecasting and Interpreting Post-exploitation Attacks  in Real-time through Cyber Threat Intelligence Reports</h3>
<ul>
<li><strong>Authors: </strong>Tiantian Zhu, Jie Ying, Tieming Chen, Chunlin Xiong, Wenrui Cheng, Qixuan Yuan, Aohan Zheng, Mingqi Lv, Yan Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02826">https://arxiv.org/abs/2405.02826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02826">https://arxiv.org/pdf/2405.02826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02826]] Nip in the Bud: Forecasting and Interpreting Post-exploitation Attacks  in Real-time through Cyber Threat Intelligence Reports(https://arxiv.org/abs/2405.02826)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threat (APT) attacks have caused significant damage worldwide. Various Endpoint Detection and Response (EDR) systems are deployed by enterprises to fight against potential threats. However, EDR suffers from high false positives. In order not to affect normal operations, analysts need to investigate and filter detection results before taking countermeasures, in which heavy manual labor and alarm fatigue cause analysts miss optimal response time, thereby leading to information leakage and destruction. Therefore, we propose Endpoint Forecasting and Interpreting (EFI), a real-time attack forecast and interpretation system, which can automatically predict next move during post-exploitation and explain it in technique-level, then dispatch strategies to EDR for advance reinforcement. First, we use Cyber Threat Intelligence (CTI) reports to extract the attack scene graph (ASG) that can be mapped to low-level system logs to strengthen attack samples. Second, we build a serialized graph forecast model, which is combined with the attack provenance graph (APG) provided by EDR to generate an attack forecast graph (AFG) to predict the next move. Finally, we utilize the attack template graph (ATG) and graph alignment plus algorithm for technique-level interpretation to automatically dispatch strategies for EDR to reinforce system in advance. EFI can avoid the impact of existing EDR false positives, and can reduce the attack surface of system without affecting the normal operations. We collect a total of 3,484 CTI reports, generate 1,429 ASGs, label 8,000 sentences, tag 10,451 entities, and construct 256 ATGs. Experimental results on both DARPA Engagement and large scale CTI dataset show that the alignment score between the AFG predicted by EFI and the real attack graph is able to exceed 0.8, the forecast and interpretation precision of EFI can reach 91.8%.</li>
</ul>

<h3>Title: You Only Need Half: Boosting Data Augmentation by Using Partial Content</h3>
<ul>
<li><strong>Authors: </strong>Juntao Hu, Yuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02830">https://arxiv.org/abs/2405.02830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02830">https://arxiv.org/pdf/2405.02830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02830]] You Only Need Half: Boosting Data Augmentation by Using Partial Content(https://arxiv.org/abs/2405.02830)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>We propose a novel data augmentation method termed You Only Need hAlf (YONA), which simplifies the augmentation process. YONA bisects an image, substitutes one half with noise, and applies data augmentation techniques to the remaining half. This method reduces the redundant information in the original image, encourages neural networks to recognize objects from incomplete views, and significantly enhances neural networks' robustness. YONA is distinguished by its properties of parameter-free, straightforward application, enhancing various existing data augmentation strategies, and thereby bolstering neural networks' robustness without additional computational cost. To demonstrate YONA's efficacy, extensive experiments were carried out. These experiments confirm YONA's compatibility with diverse data augmentation methods and neural network architectures, yielding substantial improvements in CIFAR classification tasks, sometimes outperforming conventional image-level data augmentation methods. Furthermore, YONA markedly increases the resilience of neural networks to adversarial attacks. Additional experiments exploring YONA's variants conclusively show that masking half of an image optimizes performance. The code is available at https://github.com/HansMoe/YONA.</li>
</ul>

<h3>Title: IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs</h3>
<ul>
<li><strong>Authors: </strong>Yuzhen Mao, Martin Ester, Ke Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02842">https://arxiv.org/abs/2405.02842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02842">https://arxiv.org/pdf/2405.02842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02842]] IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs(https://arxiv.org/abs/2405.02842)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>One limitation of existing Transformer-based models is that they cannot handle very long sequences as input since their self-attention operations exhibit quadratic time and space complexity. This problem becomes especially acute when Transformers are deployed on hardware platforms equipped only with CPUs. To address this issue, we propose a novel method for accelerating self-attention at inference time that works with pretrained Transformer models out-of-the-box without requiring retraining. We experiment using our method to accelerate various long-sequence Transformers, including a leading LLaMA 2-based LLM, on various benchmarks and demonstrate a greater speedup of 2.73x - 7.63x while retaining 98.6% - 99.6% of the accuracy of the original pretrained models. The code is available on our project website at https://yuzhenmao.github.io/IceFormer/.</li>
</ul>

<h3>Title: SMCD: High Realism Motion Style Transfer via Mamba-based Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Ziyun Qian, Zeyu Xiao, Zhenyi Wu, Dingkang Yang, Mingcheng Li, Shunli Wang, Shuaibing Wang, Dongliang Kou, Lihua Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02844">https://arxiv.org/abs/2405.02844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02844">https://arxiv.org/pdf/2405.02844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02844]] SMCD: High Realism Motion Style Transfer via Mamba-based Diffusion(https://arxiv.org/abs/2405.02844)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Motion style transfer is a significant research direction in multimedia applications. It enables the rapid switching of different styles of the same motion for virtual digital humans, thus vastly increasing the diversity and realism of movements. It is widely applied in multimedia scenarios such as movies, games, and the Metaverse. However, most of the current work in this field adopts the GAN, which may lead to instability and convergence issues, making the final generated motion sequence somewhat chaotic and unable to reflect a highly realistic and natural style. To address these problems, we consider style motion as a condition and propose the Style Motion Conditioned Diffusion (SMCD) framework for the first time, which can more comprehensively learn the style features of motion. Moreover, we apply Mamba model for the first time in the motion style transfer field, introducing the Motion Style Mamba (MSM) module to handle longer motion sequences. Thirdly, aiming at the SMCD framework, we propose Diffusion-based Content Consistency Loss and Content Consistency Loss to assist the overall framework's training. Finally, we conduct extensive experiments. The results reveal that our method surpasses state-of-the-art methods in both qualitative and quantitative comparisons, capable of generating more realistic motion sequences.</li>
</ul>

<h3>Title: MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior</h3>
<ul>
<li><strong>Authors: </strong>Honghua Chen, Chen Change Loy, Xingang Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02859">https://arxiv.org/abs/2405.02859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02859">https://arxiv.org/pdf/2405.02859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02859]] MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior(https://arxiv.org/abs/2405.02859)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite the emergence of successful NeRF inpainting methods built upon explicit RGB and depth 2D inpainting supervisions, these methods are inherently constrained by the capabilities of their underlying 2D inpainters. This is due to two key reasons: (i) independently inpainting constituent images results in view-inconsistent imagery, and (ii) 2D inpainters struggle to ensure high-quality geometry completion and alignment with inpainted RGB images. To overcome these limitations, we propose a novel approach called MVIP-NeRF that harnesses the potential of diffusion priors for NeRF inpainting, addressing both appearance and geometry aspects. MVIP-NeRF performs joint inpainting across multiple views to reach a consistent solution, which is achieved via an iterative optimization process based on Score Distillation Sampling (SDS). Apart from recovering the rendered RGB images, we also extract normal maps as a geometric representation and define a normal SDS loss that motivates accurate geometry inpainting and alignment with the appearance. Additionally, we formulate a multi-view SDS score function to distill generative priors simultaneously from different view images, ensuring consistent visual completion when dealing with large view variations. Our experimental results show better appearance and geometry recovery than previous NeRF inpainting methods.</li>
</ul>

<h3>Title: Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Liu, Melissa Xiaohui Qin, Hongming Li, Chao Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02861">https://arxiv.org/abs/2405.02861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02861">https://arxiv.org/pdf/2405.02861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02861]] Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for  Language Models(https://arxiv.org/abs/2405.02861)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We introduce LexBench, a comprehensive evaluation suite enabled to test language models (LMs) on ten semantic phrase processing tasks. Unlike prior studies, it is the first work to propose a framework from the comparative perspective to model the general semantic phrase (i.e., lexical collocation) and three fine-grained semantic phrases, including idiomatic expression, noun compound, and verbal construction. Thanks to \ourbenchmark, we assess the performance of 15 LMs across model architectures and parameter scales in classification, extraction, and interpretation tasks. Through the experiments, we first validate the scaling law and find that, as expected, large models excel better than the smaller ones in most tasks. Second, we investigate further through the scaling semantic relation categorization and find that few-shot LMs still lag behind vanilla fine-tuned models in the task. Third, through human evaluation, we find that the performance of strong models is comparable to the human level regarding semantic phrase processing. Our benchmarking findings can serve future research aiming to improve the generic capability of LMs on semantic phrase comprehension. Our source code and data are available at https://github.com/jacklanda/LexBench</li>
</ul>

<h3>Title: Blending Distributed NeRFs with Tri-stage Robust Pose Optimization</h3>
<ul>
<li><strong>Authors: </strong>Baijun Ye, Caiyun Liu, Xiaoyu Ye, Yuantao Chen, Yuhai Wang, Zike Yan, Yongliang Shi, Hao Zhao, Guyue Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02880">https://arxiv.org/abs/2405.02880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02880">https://arxiv.org/pdf/2405.02880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02880]] Blending Distributed NeRFs with Tri-stage Robust Pose Optimization(https://arxiv.org/abs/2405.02880)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Due to the limited model capacity, leveraging distributed Neural Radiance Fields (NeRFs) for modeling extensive urban environments has become a necessity. However, current distributed NeRF registration approaches encounter aliasing artifacts, arising from discrepancies in rendering resolutions and suboptimal pose precision. These factors collectively deteriorate the fidelity of pose estimation within NeRF frameworks, resulting in occlusion artifacts during the NeRF blending stage. In this paper, we present a distributed NeRF system with tri-stage pose optimization. In the first stage, precise poses of images are achieved by bundle adjusting Mip-NeRF 360 with a coarse-to-fine strategy. In the second stage, we incorporate the inverting Mip-NeRF 360, coupled with the truncated dynamic low-pass filter, to enable the achievement of robust and precise poses, termed Frame2Model optimization. On top of this, we obtain a coarse transformation between NeRFs in different coordinate systems. In the third stage, we fine-tune the transformation between NeRFs by Model2Model pose optimization. After obtaining precise transformation parameters, we proceed to implement NeRF blending, showcasing superior performance metrics in both real-world and simulation scenarios. Codes and data will be publicly available at https://github.com/boilcy/Distributed-NeRF.</li>
</ul>

<h3>Title: FedConPE: Efficient Federated Conversational Bandits with Heterogeneous  Clients</h3>
<ul>
<li><strong>Authors: </strong>Zhuohua Li, Maoli Liu, John C.S. Lui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02881">https://arxiv.org/abs/2405.02881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02881">https://arxiv.org/pdf/2405.02881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02881]] FedConPE: Efficient Federated Conversational Bandits with Heterogeneous  Clients(https://arxiv.org/abs/2405.02881)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Conversational recommender systems have emerged as a potent solution for efficiently eliciting user preferences. These systems interactively present queries associated with "key terms" to users and leverage user feedback to estimate user preferences more efficiently. Nonetheless, most existing algorithms adopt a centralized approach. In this paper, we introduce FedConPE, a phase elimination-based federated conversational bandit algorithm, where $M$ agents collaboratively solve a global contextual linear bandit problem with the help of a central server while ensuring secure data management. To effectively coordinate all the clients and aggregate their collected data, FedConPE uses an adaptive approach to construct key terms that minimize uncertainty across all dimensions in the feature space. Furthermore, compared with existing federated linear bandit algorithms, FedConPE offers improved computational and communication efficiency as well as enhanced privacy protections. Our theoretical analysis shows that FedConPE is minimax near-optimal in terms of cumulative regret. We also establish upper bounds for communication costs and conversation frequency. Comprehensive evaluations demonstrate that FedConPE outperforms existing conversational bandit algorithms while using fewer conversations.</li>
</ul>

<h3>Title: A drone detector with modified backbone and multiple pyramid featuremaps  enhancement structure (MDDPE)</h3>
<ul>
<li><strong>Authors: </strong>Chenhao Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02882">https://arxiv.org/abs/2405.02882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02882">https://arxiv.org/pdf/2405.02882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02882]] A drone detector with modified backbone and multiple pyramid featuremaps  enhancement structure (MDDPE)(https://arxiv.org/abs/2405.02882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work presents a drone detector with modified backbone and multiple pyramid feature maps enhancement structure (MDDPE). Novel feature maps improve modules that uses different levels of information to produce more robust and discriminatory features is proposed. These module includes the feature maps supplement function and the feature maps recombination enhancement function.To effectively handle the drone characteristics, auxiliary supervisions that are implemented in the early stages by employing tailored anchors designed are utilized. To further improve the modeling of real drone detection scenarios and initialization of the regressor, an updated anchor matching technique is introduced to match anchors and ground truth drone as closely as feasible. To show the proposed MDDPE's superiority over the most advanced detectors, extensive experiments are carried out using well-known drone detection benchmarks.</li>
</ul>

<h3>Title: Sentiment Analysis Across Languages: Evaluation Before and After Machine  Translation to English</h3>
<ul>
<li><strong>Authors: </strong>Aekansh Kathunia, Mohammad Kaif, Nalin Arora, N Narotam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02887">https://arxiv.org/abs/2405.02887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02887">https://arxiv.org/pdf/2405.02887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02887]] Sentiment Analysis Across Languages: Evaluation Before and After Machine  Translation to English(https://arxiv.org/abs/2405.02887)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>People communicate in more than 7,000 languages around the world, with around 780 languages spoken in India alone. Despite this linguistic diversity, research on Sentiment Analysis has predominantly focused on English text data, resulting in a disproportionate availability of sentiment resources for English. This paper examines the performance of transformer models in Sentiment Analysis tasks across multilingual datasets and text that has undergone machine translation. By comparing the effectiveness of these models in different linguistic contexts, we gain insights into their performance variations and potential implications for sentiment analysis across diverse languages. We also discuss the shortcomings and potential for future work towards the end.</li>
</ul>

<h3>Title: SalFAU-Net: Saliency Fusion Attention U-Net for Salient Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Kassaw Abraham Mulat, Zhengyong Feng, Tegegne Solomon Eshetie, Ahmed Endris Hasen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02906">https://arxiv.org/abs/2405.02906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02906">https://arxiv.org/pdf/2405.02906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02906]] SalFAU-Net: Saliency Fusion Attention U-Net for Salient Object Detection(https://arxiv.org/abs/2405.02906)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Salient object detection (SOD) remains an important task in computer vision, with applications ranging from image segmentation to autonomous driving. Fully convolutional network (FCN)-based methods have made remarkable progress in visual saliency detection over the last few decades. However, these methods have limitations in accurately detecting salient objects, particularly in challenging scenes with multiple objects, small objects, or objects with low resolutions. To address this issue, we proposed a Saliency Fusion Attention U-Net (SalFAU-Net) model, which incorporates a saliency fusion module into each decoder block of the attention U-net model to generate saliency probability maps from each decoder block. SalFAU-Net employs an attention mechanism to selectively focus on the most informative regions of an image and suppress non-salient regions. We train SalFAU-Net on the DUTS dataset using a binary cross-entropy loss function. We conducted experiments on six popular SOD evaluation datasets to evaluate the effectiveness of the proposed method. The experimental results demonstrate that our method, SalFAU-Net, achieves competitive performance compared to other methods in terms of mean absolute error (MAE), F-measure, s-measure, and e-measure.</li>
</ul>

<h3>Title: MERIT: Multi-view Evidential learning for Reliable and Interpretable  liver fibrosis sTaging</h3>
<ul>
<li><strong>Authors: </strong>Yuanye Liu, Zheyao Gao, Nannan Shi, Fuping Wu, Yuxin Shi, Qingchao Chen, Xiahai Zhuang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02918">https://arxiv.org/abs/2405.02918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02918">https://arxiv.org/pdf/2405.02918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02918]] MERIT: Multi-view Evidential learning for Reliable and Interpretable  liver fibrosis sTaging(https://arxiv.org/abs/2405.02918)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurate staging of liver fibrosis from magnetic resonance imaging (MRI) is crucial in clinical practice. While conventional methods often focus on a specific sub-region, multi-view learning captures more information by analyzing multiple patches simultaneously. However, previous multi-view approaches could not typically calculate uncertainty by nature, and they generally integrate features from different views in a black-box fashion, hence compromising reliability as well as interpretability of the resulting models. In this work, we propose a new multi-view method based on evidential learning, referred to as MERIT, which tackles the two challenges in a unified framework. MERIT enables uncertainty quantification of the predictions to enhance reliability, and employs a logic-based combination rule to improve interpretability. Specifically, MERIT models the prediction from each sub-view as an opinion with quantified uncertainty under the guidance of the subjective logic theory. Furthermore, a distribution-aware base rate is introduced to enhance performance, particularly in scenarios involving class distribution shifts. Finally, MERIT adopts a feature-specific combination rule to explicitly fuse multi-view predictions, thereby enhancing interpretability. Results have showcased the effectiveness of the proposed MERIT, highlighting the reliability and offering both ad-hoc and post-hoc interpretability. They also illustrate that MERIT can elucidate the significance of each view in the decision-making process for liver fibrosis staging.</li>
</ul>

<h3>Title: Relay Decoding: Concatenating Large Language Models for Machine  Translation</h3>
<ul>
<li><strong>Authors: </strong>Chengpeng Fu, Xiaocheng Feng, Yichong Huang, Wenshuai Huo, Baohang Li, Hui Wang, Bin Qin, Ting Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02933">https://arxiv.org/abs/2405.02933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02933">https://arxiv.org/pdf/2405.02933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02933]] Relay Decoding: Concatenating Large Language Models for Machine  Translation(https://arxiv.org/abs/2405.02933)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Leveraging large language models for machine translation has demonstrated promising results. However, it does require the large language models to possess the capability of handling both the source and target languages in machine translation. When it is challenging to find large models that support the desired languages, resorting to continuous learning methods becomes a costly endeavor. To mitigate these expenses, we propose an innovative approach called RD (Relay Decoding), which entails concatenating two distinct large models that individually support the source and target languages. By incorporating a simple mapping layer to facilitate the connection between these two models and utilizing a limited amount of parallel data for training, we successfully achieve superior results in the machine translation task. Experimental results conducted on the Multi30k and WikiMatrix datasets validate the effectiveness of our proposed method.</li>
</ul>

<h3>Title: On the tractability of SHAP explanations under Markovian distributions</h3>
<ul>
<li><strong>Authors: </strong>Reda Marzouk, Colin de La Higuera</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02936">https://arxiv.org/abs/2405.02936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02936">https://arxiv.org/pdf/2405.02936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02936]] On the tractability of SHAP explanations under Markovian distributions(https://arxiv.org/abs/2405.02936)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Thanks to its solid theoretical foundation, the SHAP framework is arguably one the most widely utilized frameworks for local explainability of ML models. Despite its popularity, its exact computation is known to be very challenging, proven to be NP-Hard in various configurations. Recent works have unveiled positive complexity results regarding the computation of the SHAP score for specific model families, encompassing decision trees, random forests, and some classes of boolean circuits. Yet, all these positive results hinge on the assumption of feature independence, often simplistic in real-world scenarios. In this article, we investigate the computational complexity of the SHAP score by relaxing this assumption and introducing a Markovian perspective. We show that, under the Markovian assumption, computing the SHAP score for the class of Weighted automata, Disjoint DNFs and Decision Trees can be performed in polynomial time, offering a first positive complexity result for the problem of SHAP score computation that transcends the limitations of the feature independence assumption.</li>
</ul>

<h3>Title: Unraveling the Dominance of Large Language Models Over Transformer  Models for Bangla Natural Language Inference: A Comprehensive Study</h3>
<ul>
<li><strong>Authors: </strong>Fatema Tuj Johora Faria, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, Faisal Muhammad Shah</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02937">https://arxiv.org/abs/2405.02937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02937">https://arxiv.org/pdf/2405.02937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02937]] Unraveling the Dominance of Large Language Models Over Transformer  Models for Bangla Natural Language Inference: A Comprehensive Study(https://arxiv.org/abs/2405.02937)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Natural Language Inference (NLI) is a cornerstone of Natural Language Processing (NLP), providing insights into the entailment relationships between text pairings. It is a critical component of Natural Language Understanding (NLU), demonstrating the ability to extract information from spoken or written interactions. NLI is mainly concerned with determining the entailment relationship between two statements, known as the premise and hypothesis. When the premise logically implies the hypothesis, the pair is labeled ``entailment''. If the hypothesis contradicts the premise, the pair receives the ``contradiction'' label. When there is insufficient evidence to establish a connection, the pair is described as ``neutral''. Despite the success of Large Language Models (LLMs) in various tasks, their effectiveness in NLI remains constrained by issues like low-resource domain accuracy, model overconfidence, and difficulty in capturing human judgment disagreements. This study addresses the underexplored area of evaluating LLMs in low-resourced languages such as Bengali. Through a comprehensive evaluation, we assess the performance of prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks, focusing on natural language inference. Utilizing the XNLI dataset, we conduct zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT, mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve comparable or superior performance to fine-tuned SOTA models in few-shot scenarios, further research is necessary to enhance our understanding of LLMs in languages with modest resources like Bengali. This study underscores the importance of continued efforts in exploring LLM capabilities across diverse linguistic contexts.</li>
</ul>

<h3>Title: Boundary-aware Decoupled Flow Networks for Realistic Extreme Rescaling</h3>
<ul>
<li><strong>Authors: </strong>Jinmin Li, Tao Dai, Jingyun Zhang, Kang Liu, Jun Wang, Shaoming Wang, Shu-Tao Xia, rizen guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02941">https://arxiv.org/abs/2405.02941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02941">https://arxiv.org/pdf/2405.02941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02941]] Boundary-aware Decoupled Flow Networks for Realistic Extreme Rescaling(https://arxiv.org/abs/2405.02941)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recently developed generative methods, including invertible rescaling network (IRN) based and generative adversarial network (GAN) based methods, have demonstrated exceptional performance in image rescaling. However, IRN-based methods tend to produce over-smoothed results, while GAN-based methods easily generate fake details, which thus hinders their real applications. To address this issue, we propose Boundary-aware Decoupled Flow Networks (BDFlow) to generate realistic and visually pleasing results. Unlike previous methods that model high-frequency information as standard Gaussian distribution directly, our BDFlow first decouples the high-frequency information into \textit{semantic high-frequency} that adheres to a Boundary distribution and \textit{non-semantic high-frequency} counterpart that adheres to a Gaussian distribution. Specifically, to capture semantic high-frequency parts accurately, we use Boundary-aware Mask (BAM) to constrain the model to produce rich textures, while non-semantic high-frequency part is randomly sampled from a Gaussian distribution.Comprehensive experiments demonstrate that our BDFlow significantly outperforms other state-of-the-art methods while maintaining lower complexity. Notably, our BDFlow improves the PSNR by $4.4$ dB and the SSIM by $0.1$ on average over GRAIN, utilizing only 74\% of the parameters and 20\% of the computation. The code will be available at https://github.com/THU-Kingmin/BAFlow.</li>
</ul>

<h3>Title: Score-based Generative Priors Guided Model-driven Network for MRI  Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Qiao, Weisheng Li, Yuping Huang, Lijian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02958">https://arxiv.org/abs/2405.02958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02958">https://arxiv.org/pdf/2405.02958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02958]] Score-based Generative Priors Guided Model-driven Network for MRI  Reconstruction(https://arxiv.org/abs/2405.02958)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Score matching with Langevin dynamics (SMLD) method has been successfully applied to accelerated MRI. However, the hyperparameters in the sampling process require subtle tuning, otherwise the results can be severely corrupted by hallucination artifacts, particularly with out-of-distribution test data. In this study, we propose a novel workflow in which SMLD results are regarded as additional priors to guide model-driven network training. First, we adopted a pretrained score network to obtain samples as preliminary guidance images (PGI) without the need for network retraining, parameter tuning and in-distribution test data. Although PGIs are corrupted by hallucination artifacts, we believe that they can provide extra information through effective denoising steps to facilitate reconstruction. Therefore, we designed a denoising module (DM) in the second step to improve the quality of PGIs. The features are extracted from the components of Langevin dynamics and the same score network with fine-tuning; hence, we can directly learn the artifact patterns. Third, we designed a model-driven network whose training is guided by denoised PGIs (DGIs). DGIs are densely connected with intermediate reconstructions in each cascade to enrich the features and are periodically updated to provide more accurate guidance. Our experiments on different sequences revealed that despite the low average quality of PGIs, the proposed workflow can effectively extract valuable information to guide the network training, even with severely reduced training data and sampling steps. Our method outperforms other cutting-edge techniques by effectively mitigating hallucination artifacts, yielding robust and high-quality reconstruction results.</li>
</ul>

<h3>Title: FairRelay: Fair and Cost-Efficient Peer-to-Peer Content Delivery through  Payment Channel Networks</h3>
<ul>
<li><strong>Authors: </strong>Jingyu Liu, Yingjie Xue, Zifan Peng, Chao Lin, Xinyi Huang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02973">https://arxiv.org/abs/2405.02973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02973">https://arxiv.org/pdf/2405.02973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02973]] FairRelay: Fair and Cost-Efficient Peer-to-Peer Content Delivery through  Payment Channel Networks(https://arxiv.org/abs/2405.02973)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Peer-to-Peer (P2P) content delivery, known for scalability and resilience, offers a decentralized alternative to traditional centralized Content Delivery Networks (CDNs). A significant challenge in P2P content delivery remains: the fair compensation of relayers for their bandwidth contributions. Existing solutions employ blockchains for payment settlements, however, they are not practical due to high on-chain costs and over-simplified network assumptions. In this paper, we introduce FairRelay, a fair and cost-efficient protocol that ensures all participants get fair payoff in complex content delivery network settings. We introduce a novel primitive, Enforceable Accumulative Hashed TimeLock Contract (Enforceable A-HTLC), designed to guarantee payment atomicity - ensuring all participants receive their payments upon successful content delivery. The fairness of FairRelay is proved using the Universal Composability (UC) framework. Our evaluation demonstrates that, in optimistic scenarios, FairRelay employs zero on-chain costs. In pessimistic scenarios, the on-chain dispute costs for relayers and customers are constant, irrespective of the network complexity. Specifically, empirical results indicate that the on-chain dispute costs for relayers and customers are 24,902 gas (equivalent to 0.01 USD on Optimism L2) and 290,797 gas (0.07 USD), respectively. In a 10-hop relay path, FairRelay introduces less than 1.5% additional overhead compared to pure data transmission, showcasing the efficiency of FairRelay.</li>
</ul>

<h3>Title: SkelCap: Automated Generation of Descriptive Text from Skeleton Keypoint  Sequences</h3>
<ul>
<li><strong>Authors: </strong>Ali Emre Keskin, Hacer Yalim Keles</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02977">https://arxiv.org/abs/2405.02977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02977">https://arxiv.org/pdf/2405.02977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02977]] SkelCap: Automated Generation of Descriptive Text from Skeleton Keypoint  Sequences(https://arxiv.org/abs/2405.02977)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Numerous sign language datasets exist, yet they typically cover only a limited selection of the thousands of signs used globally. Moreover, creating diverse sign language datasets is an expensive and challenging task due to the costs associated with gathering a varied group of signers. Motivated by these challenges, we aimed to develop a solution that addresses these limitations. In this context, we focused on textually describing body movements from skeleton keypoint sequences, leading to the creation of a new dataset. We structured this dataset around AUTSL, a comprehensive isolated Turkish sign language dataset. We also developed a baseline model, SkelCap, which can generate textual descriptions of body movements. This model processes the skeleton keypoints data as a vector, applies a fully connected layer for embedding, and utilizes a transformer neural network for sequence-to-sequence modeling. We conducted extensive evaluations of our model, including signer-agnostic and sign-agnostic assessments. The model achieved promising results, with a ROUGE-L score of 0.98 and a BLEU-4 score of 0.94 in the signer-agnostic evaluation. The dataset we have prepared, namely the AUTSL-SkelCap, will be made publicly available soon.</li>
</ul>

<h3>Title: E-TSL: A Continuous Educational Turkish Sign Language Dataset with  Baseline Methods</h3>
<ul>
<li><strong>Authors: </strong>Şükrü Öztürk, Hacer Yalim Keles</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02984">https://arxiv.org/abs/2405.02984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02984">https://arxiv.org/pdf/2405.02984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02984]] E-TSL: A Continuous Educational Turkish Sign Language Dataset with  Baseline Methods(https://arxiv.org/abs/2405.02984)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study introduces the continuous Educational Turkish Sign Language (E-TSL) dataset, collected from online Turkish language lessons for 5th, 6th, and 8th grades. The dataset comprises 1,410 videos totaling nearly 24 hours and includes performances from 11 signers. Turkish, an agglutinative language, poses unique challenges for sign language translation, particularly with a vocabulary where 64% are singleton words and 85% are rare words, appearing less than five times. We developed two baseline models to address these challenges: the Pose to Text Transformer (P2T-T) and the Graph Neural Network based Transformer (GNN-T) models. The GNN-T model achieved 19.13% BLEU-1 score and 3.28% BLEU-4 score, presenting a significant challenge compared to existing benchmarks. The P2T-T model, while demonstrating slightly lower performance in BLEU scores, achieved a higher ROUGE-L score of 22.09%. Additionally, we benchmarked our model using the well-known PHOENIX-Weather 2014T dataset to validate our approach.</li>
</ul>

<h3>Title: Can Large Language Models Make the Grade? An Empirical Study Evaluating  LLMs Ability to Mark Short Answer Questions in K-12 Education</h3>
<ul>
<li><strong>Authors: </strong>Owen Henkel, Adam Boxer, Libby Hills, Bill Roberts</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02985">https://arxiv.org/abs/2405.02985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02985">https://arxiv.org/pdf/2405.02985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02985]] Can Large Language Models Make the Grade? An Empirical Study Evaluating  LLMs Ability to Mark Short Answer Questions in K-12 Education(https://arxiv.org/abs/2405.02985)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents reports on a series of experiments with a novel dataset evaluating how well Large Language Models (LLMs) can mark (i.e. grade) open text responses to short answer questions, Specifically, we explore how well different combinations of GPT version and prompt engineering strategies performed at marking real student answers to short answer across different domain areas (Science and History) and grade-levels (spanning ages 5-16) using a new, never-used-before dataset from Carousel, a quizzing platform. We found that GPT-4, with basic few-shot prompting performed well (Kappa, 0.70) and, importantly, very close to human-level performance (0.75). This research builds on prior findings that GPT-4 could reliably score short answer reading comprehension questions at a performance-level very close to that of expert human raters. The proximity to human-level performance, across a variety of subjects and grade levels suggests that LLMs could be a valuable tool for supporting low-stakes formative assessment tasks in K-12 education and has important implications for real-world education delivery.</li>
</ul>

<h3>Title: Defense against Joint Poison and Evasion Attacks: A Case Study of DERMS</h3>
<ul>
<li><strong>Authors: </strong>Zain ul Abdeen, Padmaksha Roy, Ahmad Al-Tawaha, Rouxi Jia, Laura Freeman, Peter Beling, Chen-Ching Liu, Alberto Sangiovanni-Vincentelli, Ming Jin</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.02989">https://arxiv.org/abs/2405.02989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.02989">https://arxiv.org/pdf/2405.02989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.02989]] Defense against Joint Poison and Evasion Attacks: A Case Study of DERMS(https://arxiv.org/abs/2405.02989)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>There is an upward trend of deploying distributed energy resource management systems (DERMS) to control modern power grids. However, DERMS controller communication lines are vulnerable to cyberattacks that could potentially impact operational reliability. While a data-driven intrusion detection system (IDS) can potentially thwart attacks during deployment, also known as the evasion attack, the training of the detection algorithm may be corrupted by adversarial data injected into the database, also known as the poisoning attack. In this paper, we propose the first framework of IDS that is robust against joint poisoning and evasion attacks. We formulate the defense mechanism as a bilevel optimization, where the inner and outer levels deal with attacks that occur during training time and testing time, respectively. We verify the robustness of our method on the IEEE-13 bus feeder model against a diverse set of poisoning and evasion attack scenarios. The results indicate that our proposed method outperforms the baseline technique in terms of accuracy, precision, and recall for intrusion detection.</li>
</ul>

<h3>Title: MedAdapter: Efficient Test-Time Adaptation of Large Language Models  towards Medical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Hang Wu, Carl Yang, May D. Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03000">https://arxiv.org/abs/2405.03000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03000">https://arxiv.org/pdf/2405.03000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03000]] MedAdapter: Efficient Test-Time Adaptation of Large Language Models  towards Medical Reasoning(https://arxiv.org/abs/2405.03000)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and corporate privacy. In this work, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter effectively adapts the original model by fine-tuning only a small BERT-sized adapter to rank candidate solutions generated by LLMs. Experiments demonstrate that MedAdapter effectively adapts both white-box and black-box LLMs in biomedical reasoning, achieving average performance improvements of 25.48% and 11.31%, respectively, without requiring extensive computational resources or sharing data with third parties. MedAdapter also yields superior performance when combined with train-time adaptation, highlighting a flexible and complementary solution to existing adaptation methods. Faced with the challenges of balancing model performance, computational resources, and data privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective, and transparent solution for adapting LLMs to the biomedical domain.</li>
</ul>

<h3>Title: Exploring prompts to elicit memorization in masked language model-based  named entity recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Xia, Anastasiia Sedova, Pedro Henrique Luz de Araujo, Vasiliki Kougia, Lisa Nußbaumer, Benjamin Roth</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03004">https://arxiv.org/abs/2405.03004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03004">https://arxiv.org/pdf/2405.03004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03004]] Exploring prompts to elicit memorization in masked language model-based  named entity recognition(https://arxiv.org/abs/2405.03004)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Training data memorization in language models impacts model capability (generalization) and safety (privacy risk). This paper focuses on analyzing prompts' impact on detecting the memorization of 6 masked language model-based named entity recognition models. Specifically, we employ a diverse set of 400 automatically generated prompts, and a pairwise dataset where each pair consists of one person's name from the training set and another name out of the set. A prompt completed with a person's name serves as input for getting the model's confidence in predicting this name. Finally, the prompt performance of detecting model memorization is quantified by the percentage of name pairs for which the model has higher confidence for the name from the training set. We show that the performance of different prompts varies by as much as 16 percentage points on the same model, and prompt engineering further increases the gap. Moreover, our experiments demonstrate that prompt performance is model-dependent but does generalize across different name sets. A comprehensive analysis indicates how prompt performance is influenced by prompt properties, contained tokens, and the model's self-attention weights on the prompt.</li>
</ul>

<h3>Title: Explainable Malware Detection with Tailored Logic Explained Networks</h3>
<ul>
<li><strong>Authors: </strong>Peter Anthony, Francesco Giannini, Michelangelo Diligenti, Martin Homola, Marco Gori, Stefan Balogh, Jan Mojzis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03009">https://arxiv.org/abs/2405.03009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03009">https://arxiv.org/pdf/2405.03009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03009]] Explainable Malware Detection with Tailored Logic Explained Networks(https://arxiv.org/abs/2405.03009)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, explainability</a></li>
<li><strong>Abstract: </strong>Malware detection is a constant challenge in cybersecurity due to the rapid development of new attack techniques. Traditional signature-based approaches struggle to keep pace with the sheer volume of malware samples. Machine learning offers a promising solution, but faces issues of generalization to unseen samples and a lack of explanation for the instances identified as malware. However, human-understandable explanations are especially important in security-critical fields, where understanding model decisions is crucial for trust and legal compliance. While deep learning models excel at malware detection, their black-box nature hinders explainability. Conversely, interpretable models often fall short in performance. To bridge this gap in this application domain, we propose the use of Logic Explained Networks (LENs), which are a recently proposed class of interpretable neural networks providing explanations in the form of First-Order Logic (FOL) rules. This paper extends the application of LENs to the complex domain of malware detection, specifically using the large-scale EMBER dataset. In the experimental results we show that LENs achieve robustness that exceeds traditional interpretable methods and that are rivaling black-box models. Moreover, we introduce a tailored version of LENs that is shown to generate logic explanations with higher fidelity with respect to the model's predictions.</li>
</ul>

<h3>Title: AC-MAMBASEG: An adaptive convolution and Mamba-based architecture for  enhanced skin lesion segmentation</h3>
<ul>
<li><strong>Authors: </strong>Viet-Thanh Nguyen, Van-Truong Pham, Thi-Thao Tran</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03011">https://arxiv.org/abs/2405.03011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03011">https://arxiv.org/pdf/2405.03011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03011]] AC-MAMBASEG: An adaptive convolution and Mamba-based architecture for  enhanced skin lesion segmentation(https://arxiv.org/abs/2405.03011)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Skin lesion segmentation is a critical task in computer-aided diagnosis systems for dermatological diseases. Accurate segmentation of skin lesions from medical images is essential for early detection, diagnosis, and treatment planning. In this paper, we propose a new model for skin lesion segmentation namely AC-MambaSeg, an enhanced model that has the hybrid CNN-Mamba backbone, and integrates advanced components such as Convolutional Block Attention Module (CBAM), Attention Gate, and Selective Kernel Bottleneck. AC-MambaSeg leverages the Vision Mamba framework for efficient feature extraction, while CBAM and Selective Kernel Bottleneck enhance its ability to focus on informative regions and suppress background noise. We evaluate the performance of AC-MambaSeg on diverse datasets of skin lesion images including ISIC-2018 and PH2; then compare it against existing segmentation methods. Our model shows promising potential for improving computer-aided diagnosis systems and facilitating early detection and treatment of dermatological diseases. Our source code will be made available at: https://github.com/vietthanh2710/AC-MambaSeg.</li>
</ul>

<h3>Title: Matten: Video Generation with Mamba-Attention</h3>
<ul>
<li><strong>Authors: </strong>Yu Gao, Jiancheng Huang, Xiaopeng Sun, Zequn Jie, Yujie Zhong, Lin Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03025">https://arxiv.org/abs/2405.03025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03025">https://arxiv.org/pdf/2405.03025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03025]] Matten: Video Generation with Mamba-Attention(https://arxiv.org/abs/2405.03025)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce Matten, a cutting-edge latent diffusion model with Mamba-Attention architecture for video generation. With minimal computational cost, Matten employs spatial-temporal attention for local video content modeling and bidirectional Mamba for global video content modeling. Our comprehensive experimental evaluation demonstrates that Matten has competitive performance with the current Transformer-based and GAN-based models in benchmark performance, achieving superior FVD scores and efficiency. Additionally, we observe a direct positive correlation between the complexity of our designed model and the improvement in video quality, indicating the excellent scalability of Matten.</li>
</ul>

<h3>Title: On the use of dynamical systems in cryptography</h3>
<ul>
<li><strong>Authors: </strong>Samuel Everett</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03038">https://arxiv.org/abs/2405.03038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03038">https://arxiv.org/pdf/2405.03038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03038]] On the use of dynamical systems in cryptography(https://arxiv.org/abs/2405.03038)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Ever since the link between nonlinear science and cryptography became apparent, the problem of applying chaotic dynamics to the construction of cryptographic systems has gained a broad audience and has been the subject of thousands of papers. Yet, the field has not found its place in mainstream cryptography, largely due to persistent weaknesses in the presented systems. The goal of this paper is to help remedy this problem in two ways. The first is by providing a new algorithm that can be used to attack -- and hence test the security of -- stream ciphers based on the iteration of a chaotic map of the interval. The second is to cast discrete dynamical systems problems in a modern cryptographic and complexity theoretic language, so that researchers working in chaos-based cryptography can begin designing cryptographic protocols that have a better chance of meeting the extreme standards of modern cryptography.</li>
</ul>

<h3>Title: Swipe2Pair: Secure and Fast In-Band Wireless Device Pairing</h3>
<ul>
<li><strong>Authors: </strong>Yaqi He (1), Kai Zeng (1), Long Jiao (2), Brian L. Mark (1), Khaled N. Khasawneh (1) ((1) George Mason University, (2) University of Massachusetts Dartmouth)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03045">https://arxiv.org/abs/2405.03045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03045">https://arxiv.org/pdf/2405.03045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03045]] Swipe2Pair: Secure and Fast In-Band Wireless Device Pairing(https://arxiv.org/abs/2405.03045)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Wireless device pairing is a critical security mechanism to bootstrap the secure communication between two devices without a pre-shared secret. It has been widely used in many Internet of Things (IoT) applications, such as smart-home and smart-health. Most existing device pairing mechanisms are based on out-of-band channels, e.g., extra sensors or hardware, to validate the proximity of pairing devices. However, out-of-band channels are not universal across all wireless devices, so such a scheme is limited to certain application scenarios or conditions. On the other hand, in-band channel-based device pairing seeks universal applicability by only relying on wireless interfaces. Existing in-band channel-based pairing schemes either require multiple antennas separated by a good distance on one pairing device, which is not feasible in certain scenarios, or require users to repeat multiple sweeps, which is not optimal in terms of usability. Therefore, an in-band wireless device pairing scheme providing high security while maintaining high usability (simple pairing process and minimal user intervention) is highly desired. In this work, we propose an easy-to-use mutual authentication device pairing scheme, named Swipe2Pair, based on the proximity of pairing devices and randomization of wireless transmission power. We conduct extensive security analysis and collect considerable experimental data under various settings across different environments. Experimental results show that Swipe2Pair achieves high security and usability. It only takes less than one second to complete the pairing process with a simple swipe of one device in front of the other.</li>
</ul>

<h3>Title: Multi-hop graph transformer network for 3D human pose estimation</h3>
<ul>
<li><strong>Authors: </strong>Zaedul Islam, A. Ben Hamza</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03055">https://arxiv.org/abs/2405.03055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03055">https://arxiv.org/pdf/2405.03055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03055]] Multi-hop graph transformer network for 3D human pose estimation(https://arxiv.org/abs/2405.03055)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate 3D human pose estimation is a challenging task due to occlusion and depth ambiguity. In this paper, we introduce a multi-hop graph transformer network designed for 2D-to-3D human pose estimation in videos by leveraging the strengths of multi-head self-attention and multi-hop graph convolutional networks with disentangled neighborhoods to capture spatio-temporal dependencies and handle long-range interactions. The proposed network architecture consists of a graph attention block composed of stacked layers of multi-head self-attention and graph convolution with learnable adjacency matrix, and a multi-hop graph convolutional block comprised of multi-hop convolutional and dilated convolutional layers. The combination of multi-head self-attention and multi-hop graph convolutional layers enables the model to capture both local and global dependencies, while the integration of dilated convolutional layers enhances the model's ability to handle spatial details required for accurate localization of the human body joints. Extensive experiments demonstrate the effectiveness and generalization ability of our model, achieving competitive performance on benchmark datasets.</li>
</ul>

<h3>Title: Convolutional Learning on Directed Acyclic Graphs</h3>
<ul>
<li><strong>Authors: </strong>Samuel Rey, Hamed Ajorlou, Gonzalo Mateos</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03056">https://arxiv.org/abs/2405.03056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03056">https://arxiv.org/pdf/2405.03056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03056]] Convolutional Learning on Directed Acyclic Graphs(https://arxiv.org/abs/2405.03056)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We develop a novel convolutional architecture tailored for learning from data defined over directed acyclic graphs (DAGs). DAGs can be used to model causal relationships among variables, but their nilpotent adjacency matrices pose unique challenges towards developing DAG signal processing and machine learning tools. To address this limitation, we harness recent advances offering alternative definitions of causal shifts and convolutions for signals on DAGs. We develop a novel convolutional graph neural network that integrates learnable DAG filters to account for the partial ordering induced by the graph topology, thus providing valuable inductive bias to learn effective representations of DAG-supported data. We discuss the salient advantages and potential limitations of the proposed DAG convolutional network (DCN) and evaluate its performance on two learning tasks using synthetic data: network diffusion estimation and source identification. DCN compares favorably relative to several baselines, showcasing its promising potential.</li>
</ul>

<h3>Title: Tree-based Ensemble Learning for Out-of-distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhaiming Shen, Menglun Wang, Guang Cheng, Ming-Jun Lai, Lin Mu, Ruihao Huang, Qi Liu, Hao Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03060">https://arxiv.org/abs/2405.03060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03060">https://arxiv.org/pdf/2405.03060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03060]] Tree-based Ensemble Learning for Out-of-distribution Detection(https://arxiv.org/abs/2405.03060)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Being able to successfully determine whether the testing samples has similar distribution as the training samples is a fundamental question to address before we can safely deploy most of the machine learning models into practice. In this paper, we propose TOOD detection, a simple yet effective tree-based out-of-distribution (TOOD) detection mechanism to determine if a set of unseen samples will have similar distribution as of the training samples. The TOOD detection mechanism is based on computing pairwise hamming distance of testing samples' tree embeddings, which are obtained by fitting a tree-based ensemble model through in-distribution training samples. Our approach is interpretable and robust for its tree-based nature. Furthermore, our approach is efficient, flexible to various machine learning tasks, and can be easily generalized to unsupervised setting. Extensive experiments are conducted to show the proposed method outperforms other state-of-the-art out-of-distribution detection methods in distinguishing the in-distribution from out-of-distribution on various tabular, image, and text data.</li>
</ul>

<h3>Title: Powering the Future of IoT: Federated Learning for Optimized Power  Consumption and Enhanced Privacy</h3>
<ul>
<li><strong>Authors: </strong>Ghazaleh Shirvani, Saeid Ghasemshirazi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03065">https://arxiv.org/abs/2405.03065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03065">https://arxiv.org/pdf/2405.03065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03065]] Powering the Future of IoT: Federated Learning for Optimized Power  Consumption and Enhanced Privacy(https://arxiv.org/abs/2405.03065)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>The widespread use of the Internet of Things has led to the development of large amounts of perception data, making it necessary to develop effective and scalable data analysis tools. Federated Learning emerges as a promising paradigm to address the inherent challenges of power consumption and data privacy in IoT environments. This paper explores the transformative potential of FL in enhancing the longevity of IoT devices by mitigating power consumption and enhancing privacy and security measures. We delve into the intricacies of FL, elucidating its components and applications within IoT ecosystems. Additionally, we discuss the critical characteristics and challenges of IoT, highlighting the need for such machine learning solutions in processing perception data. While FL introduces many benefits for IoT sustainability, it also has limitations. Through a comprehensive discussion and analysis, this paper elucidates the opportunities and constraints of FL in shaping the future of sustainable and secure IoT systems. Our findings highlight the importance of developing new approaches and conducting additional research to maximise the benefits of FL in creating a secure and privacy-focused IoT environment.</li>
</ul>

<h3>Title: AnoGAN for Tabular Data: A Novel Approach to Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Aditya Singh, Pavan Reddy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03075">https://arxiv.org/abs/2405.03075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03075">https://arxiv.org/pdf/2405.03075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03075]] AnoGAN for Tabular Data: A Novel Approach to Anomaly Detection(https://arxiv.org/abs/2405.03075)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative</a></li>
<li><strong>Abstract: </strong>Anomaly detection, a critical facet in data analysis, involves identifying patterns that deviate from expected behavior. This research addresses the complexities inherent in anomaly detection, exploring challenges and adapting to sophisticated malicious activities. With applications spanning cybersecurity, healthcare, finance, and surveillance, anomalies often signify critical information or potential threats. Inspired by the success of Anomaly Generative Adversarial Network (AnoGAN) in image domains, our research extends its principles to tabular data. Our contributions include adapting AnoGAN's principles to a new domain and promising advancements in detecting previously undetectable anomalies. This paper delves into the multifaceted nature of anomaly detection, considering the dynamic evolution of normal behavior, context-dependent anomaly definitions, and data-related challenges like noise and imbalances.</li>
</ul>

<h3>Title: Finite-Time Convergence and Sample Complexity of Actor-Critic  Multi-Objective Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Tianchen Zhou, FNU Hairi, Haibo Yang, Jia Liu, Tian Tong, Fan Yang, Michinari Momma, Yan Gao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03082">https://arxiv.org/abs/2405.03082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03082">https://arxiv.org/pdf/2405.03082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03082]] Finite-Time Convergence and Sample Complexity of Actor-Critic  Multi-Objective Reinforcement Learning(https://arxiv.org/abs/2405.03082)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with multiple, potentially conflicting objectives is pervasive in real-world applications, while this problem remains theoretically under-explored. This paper tackles the multi-objective reinforcement learning (MORL) problem and introduces an innovative actor-critic algorithm named MOAC which finds a policy by iteratively making trade-offs among conflicting reward signals. Notably, we provide the first analysis of finite-time Pareto-stationary convergence and corresponding sample complexity in both discounted and average reward settings. Our approach has two salient features: (a) MOAC mitigates the cumulative estimation bias resulting from finding an optimal common gradient descent direction out of stochastic samples. This enables provable convergence rate and sample complexity guarantees independent of the number of objectives; (b) With proper momentum coefficient, MOAC initializes the weights of individual policy gradients using samples from the environment, instead of manual initialization. This enhances the practicality and robustness of our algorithm. Finally, experiments conducted on a real-world dataset validate the effectiveness of our proposed method.</li>
</ul>

<h3>Title: Analyzing Emotional Trends from X platform using SenticNet: A  Comparative Analysis with Cryptocurrency Price</h3>
<ul>
<li><strong>Authors: </strong>Moein Shahiki Tash, Zahra Ahani, Olga Kolesnikova, Grigori Sidorov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03084">https://arxiv.org/abs/2405.03084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03084">https://arxiv.org/pdf/2405.03084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03084]] Analyzing Emotional Trends from X platform using SenticNet: A  Comparative Analysis with Cryptocurrency Price(https://arxiv.org/abs/2405.03084)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This study delves into the relationship between emotional trends from X platform data and the market dynamics of well-known cryptocurrencies Cardano, Binance, Fantom, Matic, and Ripple over the period from October 2022 to March 2023. Leveraging SenticNet, we identified emotions like Fear and Anxiety, Rage and Anger, Grief and Sadness, Delight and Pleasantness, Enthusiasm and Eagerness, and Delight and Joy. Following data extraction, we segmented each month into bi-weekly intervals, replicating this process for price data obtained from Finance-Yahoo. Consequently, a comparative analysis was conducted, establishing connections between emotional trends observed across bi-weekly intervals and cryptocurrency prices, uncovering significant correlations between emotional sentiments and coin valuations.</li>
</ul>

<h3>Title: Compressing Long Context for Enhancing RAG with AMR-based Concept  Distillation</h3>
<ul>
<li><strong>Authors: </strong>Kaize Shi, Xueyao Sun, Qing Li, Guandong Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03085">https://arxiv.org/abs/2405.03085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03085">https://arxiv.org/pdf/2405.03085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03085]] Compressing Long Context for Enhancing RAG with AMR-based Concept  Distillation(https://arxiv.org/abs/2405.03085)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have made significant strides in information acquisition. However, their overreliance on potentially flawed parametric knowledge leads to hallucinations and inaccuracies, particularly when handling long-tail, domain-specific queries. Retrieval Augmented Generation (RAG) addresses this limitation by incorporating external, non-parametric knowledge. Nevertheless, the retrieved long-context documents often contain noisy, irrelevant information alongside vital knowledge, negatively diluting LLMs' attention. Inspired by the supportive role of essential concepts in individuals' reading comprehension, we propose a novel concept-based RAG framework with the Abstract Meaning Representation (AMR)-based concept distillation algorithm. The proposed algorithm compresses the cluttered raw retrieved documents into a compact set of crucial concepts distilled from the informative nodes of AMR by referring to reliable linguistic features. The concepts explicitly constrain LLMs to focus solely on vital information in the inference process. We conduct extensive experiments on open-domain question-answering datasets to empirically evaluate the proposed method's effectiveness. The results indicate that the concept-based RAG framework outperforms other baseline methods, particularly as the number of supporting documents increases, while also exhibiting robustness across various backbone LLMs. This emphasizes the distilled concepts are informative for augmenting the RAG process by filtering out interference information. To the best of our knowledge, this is the first work introducing AMR to enhance the RAG, presenting a potential solution to augment inference performance with semantic-based context compression.</li>
</ul>

<h3>Title: Structure-Preserving Network Compression Via Low-Rank Induced Training  Through Linear Layers Composition</h3>
<ul>
<li><strong>Authors: </strong>Xitong Zhang, Ismail R. Alkhouri, Rongrong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03089">https://arxiv.org/abs/2405.03089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03089">https://arxiv.org/pdf/2405.03089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03089]] Structure-Preserving Network Compression Via Low-Rank Induced Training  Through Linear Layers Composition(https://arxiv.org/abs/2405.03089)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep Neural Networks (DNNs) have achieved remarkable success in addressing many previously unsolvable tasks. However, the storage and computational requirements associated with DNNs pose a challenge for deploying these trained models on resource-limited devices. Therefore, a plethora of compression and pruning techniques have been proposed in recent years. Low-rank decomposition techniques are among the approaches most utilized to address this problem. Compared to post-training compression, compression-promoted training is still under-explored. In this paper, we present a theoretically-justified novel approach, termed Low-Rank Induced Training (LoRITa), that promotes low-rankness through the composition of linear layers and compresses by using singular value truncation. This is achieved without the need to change the structure at inference time or require constrained and/or additional optimization, other than the standard weight decay regularization. Moreover, LoRITa eliminates the need to (i) initialize with pre-trained models and (ii) specify rank selection prior to training. Our experimental results (i) demonstrate the effectiveness of our approach using MNIST on Fully Connected Networks, CIFAR10 on Vision Transformers, and CIFAR10/100 on Convolutional Neural Networks, and (ii) illustrate that we achieve either competitive or SOTA results when compared to leading structured pruning methods in terms of FLOPs and parameters drop.</li>
</ul>

<h3>Title: To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning  in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>George-Octavian Barbulescu, Peter Triantafillou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03097">https://arxiv.org/abs/2405.03097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03097">https://arxiv.org/pdf/2405.03097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03097]] To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning  in Large Language Models(https://arxiv.org/abs/2405.03097)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>LLMs have been found to memorize training textual sequences and regurgitate verbatim said sequences during text generation time. This fact is known to be the cause of privacy and related (e.g., copyright) problems. Unlearning in LLMs then takes the form of devising new algorithms that will properly deal with these side-effects of memorized data, while not hurting the model's utility. We offer a fresh perspective towards this goal, namely, that each textual sequence to be forgotten should be treated differently when being unlearned based on its degree of memorization within the LLM. We contribute a new metric for measuring unlearning quality, an adversarial attack showing that SOTA algorithms lacking this perspective fail for privacy, and two new unlearning methods based on Gradient Ascent and Task Arithmetic, respectively. A comprehensive performance evaluation across an extensive suite of NLP tasks then mapped the solution space, identifying the best solutions under different scales in model capacities and forget set sizes and quantified the gains of the new approaches.</li>
</ul>

<h3>Title: FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yanhong Bai, Jiabao Zhao, Jinxin Shi, Zhentao Xie, Xingjiao Wu, Liang He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03098">https://arxiv.org/abs/2405.03098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03098">https://arxiv.org/pdf/2405.03098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03098]] FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in  Large Language Models(https://arxiv.org/abs/2405.03098)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Detecting stereotypes and biases in Large Language Models (LLMs) is crucial for enhancing fairness and reducing adverse impacts on individuals or groups when these models are applied. Traditional methods, which rely on embedding spaces or are based on probability metrics, fall short in revealing the nuanced and implicit biases present in various contexts. To address this challenge, we propose the FairMonitor framework and adopt a static-dynamic detection method for a comprehensive evaluation of stereotypes and biases in LLMs. The static component consists of a direct inquiry test, an implicit association test, and an unknown situation test, including 10,262 open-ended questions with 9 sensitive factors and 26 educational scenarios. And it is effective for evaluating both explicit and implicit biases. Moreover, we utilize the multi-agent system to construst the dynamic scenarios for detecting subtle biases in more complex and realistic setting. This component detects the biases based on the interaction behaviors of LLMs across 600 varied educational scenarios. The experimental results show that the cooperation of static and dynamic methods can detect more stereotypes and biased in LLMs.</li>
</ul>

<h3>Title: Learning from Students: Applying t-Distributions to Explore Accurate and  Efficient Formats for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jordan Dotzel, Yuzong Chen, Bahaa Kotb, Sushma Prasad, Gang Wu, Sheng Li, Mohamed S. Abdelfattah, Zhiru Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03103">https://arxiv.org/abs/2405.03103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03103">https://arxiv.org/pdf/2405.03103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03103]] Learning from Students: Applying t-Distributions to Explore Accurate and  Efficient Formats for LLMs(https://arxiv.org/abs/2405.03103)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently achieved state-of-the-art performance across various tasks, yet due to their large computational requirements, they struggle with strict latency and power demands. Deep neural network (DNN) quantization has traditionally addressed these limitations by converting models to low-precision integer formats. Yet recently alternative formats, such as Normal Float (NF4), have been shown to consistently increase model accuracy, albeit at the cost of increased chip area. In this work, we first conduct a large-scale analysis of LLM weights and activations across 30 networks to conclude most distributions follow a Student's t-distribution. We then derive a new theoretically optimal format, Student Float (SF4), with respect to this distribution, that improves over NF4 across modern LLMs, for example increasing the average accuracy on LLaMA2-7B by 0.76% across tasks. Using this format as a high-accuracy reference, we then propose augmenting E2M1 with two variants of supernormal support for higher model accuracy. Finally, we explore the quality and performance frontier across 11 datatypes, including non-traditional formats like Additive-Powers-of-Two (APoT), by evaluating their model accuracy and hardware complexity. We discover a Pareto curve composed of INT4, E2M1, and E2M1 with supernormal support, which offers a continuous tradeoff between model accuracy and chip area. For example, E2M1 with supernormal support increases the accuracy of Phi-2 by up to 2.19% with 1.22% area overhead, enabling more LLM-based applications to be run at four bits.</li>
</ul>

<h3>Title: Intra-task Mutual Attention based Vision Transformer for Few-Shot  Learning</h3>
<ul>
<li><strong>Authors: </strong>Weihao Jiang, Chang Liu, Kun He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03109">https://arxiv.org/abs/2405.03109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03109">https://arxiv.org/pdf/2405.03109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03109]] Intra-task Mutual Attention based Vision Transformer for Few-Shot  Learning(https://arxiv.org/abs/2405.03109)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Humans possess remarkable ability to accurately classify new, unseen images after being exposed to only a few examples. Such ability stems from their capacity to identify common features shared between new and previously seen images while disregarding distractions such as background variations. However, for artificial neural network models, determining the most relevant features for distinguishing between two images with limited samples presents a challenge. In this paper, we propose an intra-task mutual attention method for few-shot learning, that involves splitting the support and query samples into patches and encoding them using the pre-trained Vision Transformer (ViT) architecture. Specifically, we swap the class (CLS) token and patch tokens between the support and query sets to have the mutual attention, which enables each set to focus on the most useful information. This facilitates the strengthening of intra-class representations and promotes closer proximity between instances of the same class. For implementation, we adopt the ViT-based network architecture and utilize pre-trained model parameters obtained through self-supervision. By leveraging Masked Image Modeling as a self-supervised training task for pre-training, the pre-trained model yields semantically meaningful representations while successfully avoiding supervision collapse. We then employ a meta-learning method to fine-tune the last several layers and CLS token modules. Our strategy significantly reduces the num- ber of parameters that require fine-tuning while effectively uti- lizing the capability of pre-trained model. Extensive experiments show that our framework is simple, effective and computationally efficient, achieving superior performance as compared to the state-of-the-art baselines on five popular few-shot classification benchmarks under the 5-shot and 1-shot scenarios</li>
</ul>

<h3>Title: AniTalker: Animate Vivid and Diverse Talking Faces through  Identity-Decoupled Facial Motion Encoding</h3>
<ul>
<li><strong>Authors: </strong>Tao Liu, Feilong Chen, Shuai Fan, Chenpeng Du, Qi Chen, Xie Chen, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03121">https://arxiv.org/abs/2405.03121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03121">https://arxiv.org/pdf/2405.03121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03121]] AniTalker: Animate Vivid and Diverse Talking Faces through  Identity-Decoupled Facial Motion Encoding(https://arxiv.org/abs/2405.03121)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The paper introduces AniTalker, an innovative framework designed to generate lifelike talking faces from a single portrait. Unlike existing models that primarily focus on verbal cues such as lip synchronization and fail to capture the complex dynamics of facial expressions and nonverbal cues, AniTalker employs a universal motion representation. This innovative representation effectively captures a wide range of facial dynamics, including subtle expressions and head movements. AniTalker enhances motion depiction through two self-supervised learning strategies: the first involves reconstructing target video frames from source frames within the same identity to learn subtle motion representations, and the second develops an identity encoder using metric learning while actively minimizing mutual information between the identity and motion encoders. This approach ensures that the motion representation is dynamic and devoid of identity-specific details, significantly reducing the need for labeled data. Additionally, the integration of a diffusion model with a variance adapter allows for the generation of diverse and controllable facial animations. This method not only demonstrates AniTalker's capability to create detailed and realistic facial movements but also underscores its potential in crafting dynamic avatars for real-world applications. Synthetic results can be viewed at https://github.com/X-LANCE/AniTalker.</li>
</ul>

<h3>Title: FOBNN: Fast Oblivious Binarized Neural Network Inference</h3>
<ul>
<li><strong>Authors: </strong>Xin Chen, Zhili Chen, Benchang Dong, Shiwen Wei, Lin Chen, Daojing He</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03136">https://arxiv.org/abs/2405.03136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03136">https://arxiv.org/pdf/2405.03136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03136]] FOBNN: Fast Oblivious Binarized Neural Network Inference(https://arxiv.org/abs/2405.03136)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The superior performance of deep learning has propelled the rise of Deep Learning as a Service, enabling users to transmit their private data to service providers for model execution and inference retrieval. Nevertheless, the primary concern remains safeguarding the confidentiality of sensitive user data while optimizing the efficiency of secure protocols. To address this, we develop a fast oblivious binarized neural network inference framework, FOBNN. Specifically, we customize binarized convolutional neural networks to enhance oblivious inference, design two fast algorithms for binarized convolutions, and optimize network structures experimentally under constrained costs. Initially, we meticulously analyze the range of intermediate values in binarized convolutions to minimize bit representation, resulting in the Bit Length Bounding (BLB) algorithm. Subsequently, leveraging the efficiency of bitwise operations in BLB, we further enhance performance by employing pure bitwise operations for each binary digit position, yielding the Layer-wise Bit Accumulation (LBA) algorithm. Theoretical analysis validates FOBNN's security and indicates up to $2 \times$ improvement in computational and communication costs compared to the state-of-the-art method. We demonstrates our framework's effectiveness in RNA function prediction within bioinformatics. Rigorous experimental assessments confirm that our oblivious inference solutions not only maintain but often exceed the original accuracy, surpassing prior efforts.</li>
</ul>

<h3>Title: CRAFT: Extracting and Tuning Cultural Instructions from the Wild</h3>
<ul>
<li><strong>Authors: </strong>Bin Wang, Geyu Lin, Zhengyuan Liu, Chengwei Wei, Nancy F. Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03138">https://arxiv.org/abs/2405.03138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03138">https://arxiv.org/pdf/2405.03138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03138]] CRAFT: Extracting and Tuning Cultural Instructions from the Wild(https://arxiv.org/abs/2405.03138)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have rapidly evolved as the foundation of various natural language processing (NLP) applications. Despite their wide use cases, their understanding of culturally-related concepts and reasoning remains limited. Meantime, there is a significant need to enhance these models' cultural reasoning capabilities, especially concerning underrepresented regions. This paper introduces a novel pipeline for extracting high-quality, culturally-related instruction tuning datasets from vast unstructured corpora. We utilize a self-instruction generation pipeline to identify cultural concepts and trigger instruction. By integrating with a general-purpose instruction tuning dataset, our model demonstrates enhanced capabilities in recognizing and understanding regional cultural nuances, thereby enhancing its reasoning capabilities. We conduct experiments across three regions: Singapore, the Philippines, and the United States, achieving performance improvement of up to 6%. Our research opens new avenues for extracting cultural instruction tuning sets directly from unstructured data, setting a precedent for future innovations in the field.</li>
</ul>

<h3>Title: TimeMIL: Advancing Multivariate Time Series Classification via a  Time-aware Multiple Instance Learning</h3>
<ul>
<li><strong>Authors: </strong>Xiwen Chen, Peijie Qiu, Wenhui Zhu, Huayu Li, Hao Wang, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03140">https://arxiv.org/abs/2405.03140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03140">https://arxiv.org/pdf/2405.03140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03140]] TimeMIL: Advancing Multivariate Time Series Classification via a  Time-aware Multiple Instance Learning(https://arxiv.org/abs/2405.03140)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks, including transformers and convolutional neural networks, have significantly improved multivariate time series classification (MTSC). However, these methods often rely on supervised learning, which does not fully account for the sparsity and locality of patterns in time series data (e.g., diseases-related anomalous points in ECG). To address this challenge, we formally reformulate MTSC as a weakly supervised problem, introducing a novel multiple-instance learning (MIL) framework for better localization of patterns of interest and modeling time dependencies within time series. Our novel approach, TimeMIL, formulates the temporal correlation and ordering within a time-aware MIL pooling, leveraging a tokenized transformer with a specialized learnable wavelet positional token. The proposed method surpassed 26 recent state-of-the-art methods, underscoring the effectiveness of the weakly supervised TimeMIL in MTSC.</li>
</ul>

<h3>Title: PTQ4SAM: Post-Training Quantization for Segment Anything</h3>
<ul>
<li><strong>Authors: </strong>Chengtao Lv, Hong Chen, Jinyang Guo, Yifu Ding, Xianglong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03144">https://arxiv.org/abs/2405.03144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03144">https://arxiv.org/pdf/2405.03144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03144]] PTQ4SAM: Post-Training Quantization for Segment Anything(https://arxiv.org/abs/2405.03144)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segment Anything Model (SAM) has achieved impressive performance in many computer vision tasks. However, as a large-scale model, the immense memory and computation costs hinder its practical deployment. In this paper, we propose a post-training quantization (PTQ) framework for Segment Anything Model, namely PTQ4SAM. First, we investigate the inherent bottleneck of SAM quantization attributed to the bimodal distribution in post-Key-Linear activations. We analyze its characteristics from both per-tensor and per-channel perspectives, and propose a Bimodal Integration strategy, which utilizes a mathematically equivalent sign operation to transform the bimodal distribution into a relatively easy-quantized normal distribution offline. Second, SAM encompasses diverse attention mechanisms (i.e., self-attention and two-way cross-attention), resulting in substantial variations in the post-Softmax distributions. Therefore, we introduce an Adaptive Granularity Quantization for Softmax through searching the optimal power-of-two base, which is hardware-friendly. Extensive experimental results across various vision tasks (instance segmentation, semantic segmentation and object detection), datasets and model variants show the superiority of PTQ4SAM. For example, when quantizing SAM-L to 6-bit, we achieve lossless accuracy for instance segmentation, about 0.5\% drop with theoretical 3.9$\times$ acceleration. The code is available at \url{https://github.com/chengtao-lv/PTQ4SAM}.</li>
</ul>

<h3>Title: Video Diffusion Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Andrew Melnik, Michal Ljubljanac, Cong Lu, Qi Yan, Weiming Ren, Helge Ritter</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03150">https://arxiv.org/abs/2405.03150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03150">https://arxiv.org/pdf/2405.03150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03150]] Video Diffusion Models: A Survey(https://arxiv.org/abs/2405.03150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion generative models have recently become a robust technique for producing and modifying coherent, high-quality video. This survey offers a systematic overview of critical elements of diffusion models for video generation, covering applications, architectural choices, and the modeling of temporal dynamics. Recent advancements in the field are summarized and grouped into development trends. The survey concludes with an overview of remaining challenges and an outlook on the future of the field. Website: https://github.com/ndrwmlnk/Awesome-Video-Diffusion-Models</li>
</ul>

<h3>Title: Exploring the Potential of the Large Language Models (LLMs) in  Identifying Misleading News Headlines</h3>
<ul>
<li><strong>Authors: </strong>Md Main Uddin Rony, Md Mahfuzul Haque, Mohammad Ali, Ahmed Shatil Alam, Naeemul Hassan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03153">https://arxiv.org/abs/2405.03153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03153">https://arxiv.org/pdf/2405.03153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03153]] Exploring the Potential of the Large Language Models (LLMs) in  Identifying Misleading News Headlines(https://arxiv.org/abs/2405.03153)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In the digital age, the prevalence of misleading news headlines poses a significant challenge to information integrity, necessitating robust detection mechanisms. This study explores the efficacy of Large Language Models (LLMs) in identifying misleading versus non-misleading news headlines. Utilizing a dataset of 60 articles, sourced from both reputable and questionable outlets across health, science & tech, and business domains, we employ three LLMs- ChatGPT-3.5, ChatGPT-4, and Gemini-for classification. Our analysis reveals significant variance in model performance, with ChatGPT-4 demonstrating superior accuracy, especially in cases with unanimous annotator agreement on misleading headlines. The study emphasizes the importance of human-centered evaluation in developing LLMs that can navigate the complexities of misinformation detection, aligning technical proficiency with nuanced human judgment. Our findings contribute to the discourse on AI ethics, emphasizing the need for models that are not only technically advanced but also ethically aligned and sensitive to the subtleties of human interpretation.</li>
</ul>

<h3>Title: DeepMpMRI: Tensor-decomposition Regularized Learning for Fast and  High-Fidelity Multi-Parametric Microstructural MR Imaging</h3>
<ul>
<li><strong>Authors: </strong>Wenxin Fan, Jian Cheng, Cheng Li, Xinrui Ma, Jing Yang, Juan Zou, Ruoyou Wu, Zan Chen, Yuanjing Feng, Hairong Zheng, Shanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03159">https://arxiv.org/abs/2405.03159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03159">https://arxiv.org/pdf/2405.03159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03159]] DeepMpMRI: Tensor-decomposition Regularized Learning for Fast and  High-Fidelity Multi-Parametric Microstructural MR Imaging(https://arxiv.org/abs/2405.03159)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning has emerged as a promising approach for learning the nonlinear mapping between diffusion-weighted MR images and tissue parameters, which enables automatic and deep understanding of the brain microstructures. However, the efficiency and accuracy in the multi-parametric estimations are still limited since previous studies tend to estimate multi-parametric maps with dense sampling and isolated signal modeling. This paper proposes DeepMpMRI, a unified framework for fast and high-fidelity multi-parametric estimation from various diffusion models using sparsely sampled q-space data. DeepMpMRI is equipped with a newly designed tensor-decomposition-based regularizer to effectively capture fine details by exploiting the correlation across parameters. In addition, we introduce a Nesterov-based adaptive learning algorithm that optimizes the regularization parameter dynamically to enhance the performance. DeepMpMRI is an extendable framework capable of incorporating flexible network architecture. Experimental results demonstrate the superiority of our approach over 5 state-of-the-art methods in simultaneously estimating multi-parametric maps for various diffusion models with fine-grained details both quantitatively and qualitatively, achieving 4.5 - 22.5$\times$ acceleration compared to the dense sampling of a total of 270 diffusion gradients.</li>
</ul>

<h3>Title: An Efficient All-to-All GCD Algorithm for Low Entropy RSA Key  Factorization</h3>
<ul>
<li><strong>Authors: </strong>Elijah Pelofske</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03166">https://arxiv.org/abs/2405.03166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03166">https://arxiv.org/pdf/2405.03166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03166]] An Efficient All-to-All GCD Algorithm for Low Entropy RSA Key  Factorization(https://arxiv.org/abs/2405.03166)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>RSA is an incredibly successful and useful asymmetric encryption algorithm. One of the types of implementation flaws in RSA is low entropy of the key generation, specifically the prime number creation stage. This can occur due to flawed usage of random prime number generator libraries, or on computers where there is a lack of a source of external entropy. These implementation flaws result in some RSA keys sharing prime factors, which means that the full factorization of the public modulus can be recovered incredibly efficiently by performing a computation GCD between the two public key moduli that share the prime factor. However, since one does not know which of the composite moduli share a prime factor a-priori, to determine if any such shared prime factors exist, an all-to-all GCD attack (also known as a batch GCD attack, or a bulk GCD attack) can be performed on the available public keys so as to recover any shared prime factors. This study describes a novel all-to-all batch GCD algorithm, which will be referred to as the binary tree batch GCD algorithm, that is more efficient than the current best batch GCD algorithm (the remainder tree batch GCD algorithm). A comparison against the best existing batch GCD method (which is a product tree followed by a remainder tree computation) is given using a dataset of random RSA moduli that are constructed such that some of the moduli share prime factors. This proposed binary tree batch GCD algorithm has better runtime than the existing remainder tree batch GCD algorithm, although asymptotically it has nearly identical scaling and its complexity is dependent on how many shared prime factors exist in the set of RSA keys. In practice, the implementation of the proposed binary tree batch GCD algorithm has a roughly 6x speedup compared to the standard remainder tree batch GCD approach.</li>
</ul>

<h3>Title: Oracle-Checker Scheme for Evaluating a Generative Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Yueling Jenny Zeng, Li-C. Wang, Thomas Ibbetson</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03170">https://arxiv.org/abs/2405.03170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03170">https://arxiv.org/pdf/2405.03170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03170]] Oracle-Checker Scheme for Evaluating a Generative Large Language Model(https://arxiv.org/abs/2405.03170)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>This work presents a novel approach called oracle-checker scheme for evaluating the answer given by a generative large language model (LLM). Two types of checkers are presented. The first type of checker follows the idea of property testing. The second type of checker follows the idea of program checking. Their applications are demonstrated in two separate contexts, entity extraction and paraphrase decision, respectively.</li>
</ul>

<h3>Title: Transformer-based RGB-T Tracking with Channel and Spatial Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>Yunfeng Li, Bo Wang, Ye Li, Zhiwen Yu, Liang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03177">https://arxiv.org/abs/2405.03177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03177">https://arxiv.org/pdf/2405.03177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03177]] Transformer-based RGB-T Tracking with Channel and Spatial Feature Fusion(https://arxiv.org/abs/2405.03177)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Complementary RGB and TIR modalities enable RGB-T tracking to achieve competitive performance in challenging scenarios. Therefore, how to better fuse cross-modal features is the core issue of RGB-T tracking. Some previous methods either insufficiently fuse RGB and TIR features, or depend on intermediaries containing information from both modalities to achieve cross-modal information interaction. The former does not fully exploit the potential of using only RGB and TIR information of the template or search region for channel and spatial feature fusion, and the latter lacks direct interaction between the template and search area, which limits the model's ability to fully exploit the original semantic information of both modalities. To alleviate these limitations, we explore how to improve the performance of a visual Transformer by using direct fusion of cross-modal channels and spatial features, and propose CSTNet. CSTNet uses ViT as a backbone and inserts cross-modal channel feature fusion modules (CFM) and cross-modal spatial feature fusion modules (SFM) for direct interaction between RGB and TIR features. The CFM performs parallel joint channel enhancement and joint multilevel spatial feature modeling of RGB and TIR features and sums the features, and then globally integrates the sum feature with the original features. The SFM uses cross-attention to model the spatial relationship of cross-modal features and then introduces a convolutional feedforward network for joint spatial and channel integration of multimodal features. Comprehensive experiments show that CSTNet achieves state-of-the-art performance on three public RGB-T tracking benchmarks. Code is available at https://github.com/LiYunfengLYF/CSTNet.</li>
</ul>

<h3>Title: Hyperbolic Geometric Latent Diffusion Model for Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Xingcheng Fu, Yisen Gao, Yuecen Wei, Qingyun Sun, Hao Peng, Jianxin Li, Xianxian Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03188">https://arxiv.org/abs/2405.03188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03188">https://arxiv.org/pdf/2405.03188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03188]] Hyperbolic Geometric Latent Diffusion Model for Graph Generation(https://arxiv.org/abs/2405.03188)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have made significant contributions to computer vision, sparking a growing interest in the community recently regarding the application of them to graph generation. Existing discrete graph diffusion models exhibit heightened computational complexity and diminished training efficiency. A preferable and natural way is to directly diffuse the graph within the latent space. However, due to the non-Euclidean structure of graphs is not isotropic in the latent space, the existing latent diffusion models effectively make it difficult to capture and preserve the topological information of graphs. To address the above challenges, we propose a novel geometrically latent diffusion framework HypDiff. Specifically, we first establish a geometrically latent space with interpretability measures based on hyperbolic geometry, to define anisotropic latent diffusion processes for graphs. Then, we propose a geometrically latent diffusion process that is constrained by both radial and angular geometric properties, thereby ensuring the preservation of the original topological properties in the generative graphs. Extensive experimental results demonstrate the superior effectiveness of HypDiff for graph generation with various topologies.</li>
</ul>

<h3>Title: Exploring Frequencies via Feature Mixing and Meta-Learning for Improving  Adversarial Transferability</h3>
<ul>
<li><strong>Authors: </strong>Juanjuan Weng, Zhiming Luo, Shaozi Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03193">https://arxiv.org/abs/2405.03193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03193">https://arxiv.org/pdf/2405.03193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03193]] Exploring Frequencies via Feature Mixing and Meta-Learning for Improving  Adversarial Transferability(https://arxiv.org/abs/2405.03193)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that Deep Neural Networks (DNNs) are susceptible to adversarial attacks, with frequency-domain analysis underscoring the significance of high-frequency components in influencing model predictions. Conversely, targeting low-frequency components has been effective in enhancing attack transferability on black-box models. In this study, we introduce a frequency decomposition-based feature mixing method to exploit these frequency characteristics in both clean and adversarial samples. Our findings suggest that incorporating features of clean samples into adversarial features extracted from adversarial examples is more effective in attacking normally-trained models, while combining clean features with the adversarial features extracted from low-frequency parts decomposed from the adversarial samples yields better results in attacking defense models. However, a conflict issue arises when these two mixing approaches are employed simultaneously. To tackle the issue, we propose a cross-frequency meta-optimization approach comprising the meta-train step, meta-test step, and final update. In the meta-train step, we leverage the low-frequency components of adversarial samples to boost the transferability of attacks against defense models. Meanwhile, in the meta-test step, we utilize adversarial samples to stabilize gradients, thereby enhancing the attack's transferability against normally trained models. For the final update, we update the adversarial sample based on the gradients obtained from both meta-train and meta-test steps. Our proposed method is evaluated through extensive experiments on the ImageNet-Compatible dataset, affirming its effectiveness in improving the transferability of attacks on both normally-trained CNNs and defense models. The source code is available at https://github.com/WJJLL/MetaSSA.</li>
</ul>

<h3>Title: StyleSeg V2: Towards Robust One-shot Segmentation of Brain Tissue via  Optimization-free Registration Error Perception</h3>
<ul>
<li><strong>Authors: </strong>Zhiwei Wang, Xiaoyu Zeng, Chongwei Wu, Jinxin lv, Xu Zhang, Wei Fang, Qiang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03197">https://arxiv.org/abs/2405.03197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03197">https://arxiv.org/pdf/2405.03197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03197]] StyleSeg V2: Towards Robust One-shot Segmentation of Brain Tissue via  Optimization-free Registration Error Perception(https://arxiv.org/abs/2405.03197)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>One-shot segmentation of brain tissue requires training registration-segmentation (reg-seg) dual-model iteratively, where reg-model aims to provide pseudo masks of unlabeled images for seg-model by warping a carefully-labeled atlas. However, the imperfect reg-model induces image-mask misalignment, poisoning the seg-model subsequently. Recent StyleSeg bypasses this bottleneck by replacing the unlabeled images with their warped copies of atlas, but needs to borrow the diverse image patterns via style transformation. Here, we present StyleSeg V2, inherited from StyleSeg but granted the ability of perceiving the registration errors. The motivation is that good registration behaves in a mirrored fashion for mirrored images. Therefore, almost at no cost, StyleSeg V2 can have reg-model itself "speak out" incorrectly-aligned regions by simply mirroring (symmetrically flipping the brain) its input, and the registration errors are symmetric inconsistencies between the outputs of original and mirrored inputs. Consequently, StyleSeg V2 allows the seg-model to make use of correctly-aligned regions of unlabeled images and also enhances the fidelity of style-transformed warped atlas image by weighting the local transformation strength according to registration errors. The experimental results on three public datasets demonstrate that our proposed StyleSeg V2 outperforms other state-of-the-arts by considerable margins, and exceeds StyleSeg by increasing the average Dice by at least 2.4%.</li>
</ul>

<h3>Title: Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice  Questions</h3>
<ul>
<li><strong>Authors: </strong>Ruizhe Li, Yanjun Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03205">https://arxiv.org/abs/2405.03205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03205">https://arxiv.org/pdf/2405.03205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03205]] Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice  Questions(https://arxiv.org/abs/2405.03205)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have demonstrated considerable success across diverse tasks, including multiple-choice questions (MCQs). However, these models exhibit a positional bias, particularly an even worse anchored bias in the GPT-2 family, where they consistently favour the first choice 'A' in MCQs during inference. This anchored bias challenges the integrity of GPT-2's decision-making process, as it skews performance based on the position rather than the content of the choices in MCQs. In this study, we utilise the mechanistic interpretability approach to identify the internal modules within GPT-2 models responsible for this bias. We focus on the Multi-Layer Perceptron (MLP) layers and attention heads, using the "logit lens" method to trace and modify the specific value vectors that contribute to the bias. By updating these vectors within MLP and recalibrating attention patterns to neutralise the preference for the first choice 'A', we effectively mitigate the anchored bias. Our interventions not only correct the bias but also improve the overall MCQ prediction accuracy for the GPT-2 family across various datasets. This work represents the first comprehensive mechanistic analysis of anchored bias in MCQs within the GPT-2 models, introducing targeted, minimal-intervention strategies that significantly enhance GPT2 model robustness and accuracy in MCQs. Our code is available at https://github.com/ruizheliUOA/Anchored_Bias_GPT2.</li>
</ul>

<h3>Title: Vietnamese AI Generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Quang-Dan Tran, Van-Quan Nguyen, Quang-Huy Pham, K. B. Thang Nguyen, Trong-Hop Do</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03206">https://arxiv.org/abs/2405.03206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03206">https://arxiv.org/pdf/2405.03206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03206]] Vietnamese AI Generated Text Detection(https://arxiv.org/abs/2405.03206)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Large Language Models (LLMs) have become integrated into our daily lives, serving as invaluable assistants in completing tasks. Widely embraced by users, the abuse of LLMs is inevitable, particularly in using them to generate text content for various purposes, leading to difficulties in distinguishing between text generated by LLMs and that written by humans. In this study, we present a dataset named ViDetect, comprising 6.800 samples of Vietnamese essay, with 3.400 samples authored by humans and the remainder generated by LLMs, serving the purpose of detecting text generated by AI. We conducted evaluations using state-of-the-art methods, including ViT5, BartPho, PhoBERT, mDeberta V3, and mBERT. These results contribute not only to the growing body of research on detecting text generated by AI but also demonstrate the adaptability and effectiveness of different methods in the Vietnamese language context. This research lays the foundation for future advancements in AI-generated text detection and provides valuable insights for researchers in the field of natural language processing.</li>
</ul>

<h3>Title: A Philosophical Introduction to Language Models - Part II: The Way  Forward</h3>
<ul>
<li><strong>Authors: </strong>Raphaël Millière, Cameron Buckner</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03207">https://arxiv.org/abs/2405.03207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03207">https://arxiv.org/pdf/2405.03207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03207]] A Philosophical Introduction to Language Models - Part II: The Way  Forward(https://arxiv.org/abs/2405.03207)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, the second of two companion pieces, we explore novel philosophical questions raised by recent progress in large language models (LLMs) that go beyond the classical debates covered in the first part. We focus particularly on issues related to interpretability, examining evidence from causal intervention methods about the nature of LLMs' internal representations and computations. We also discuss the implications of multimodal and modular extensions of LLMs, recent debates about whether such systems may meet minimal criteria for consciousness, and concerns about secrecy and reproducibility in LLM research. Finally, we discuss whether LLM-like systems may be relevant to modeling aspects of human cognition, if their architectural characteristics and learning scenario are adequately constrained.</li>
</ul>

<h3>Title: PCG: Mitigating Conflict-based Cache Side-channel Attacks with  Prefetching</h3>
<ul>
<li><strong>Authors: </strong>Fang Jiang, Fei Tong, Hongyu Wang, Xiaoyu Cheng, Zhe Zhou, Ming Ling, Yuxing Mao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03217">https://arxiv.org/abs/2405.03217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03217">https://arxiv.org/pdf/2405.03217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03217]] PCG: Mitigating Conflict-based Cache Side-channel Attacks with  Prefetching(https://arxiv.org/abs/2405.03217)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>To defend against conflict-based cache side-channel attacks, cache partitioning or remapping techniques were proposed to prevent set conflicts between different security domains or obfuscate the locations of such conflicts. But such techniques complicate cache design and may result in significant performance penalties. Therefore, there have been lightweight prefetching-based schemes proposed to introduce noise to confuse attackers' observation. However, we have validated experimentally that relying on prefetching to only introduce noise is insufficient, as attackers can still reliably distinguish the victim's cache accesses. This paper proposes a novel prefetching-based scheme, called PCG. It combines adding victim-irrelevant cache occupancy changes and reducing victim-relevant cache occupancy changes to disrupt attackers by generating noisy and indistinguishable cache access patterns. Additionally, PCG can either work independently or seamlessly be integrated with most of the commonly used prefetchers. We have implemented and evaluated PCG in both gem5 and the open-source RISC-V core BOOMv3. The evaluation results show the PCG's robust security superior to the existing solutions, while without resulting in significant performance degradation. According to the evaluation based on the SPEC CPU 2017 benchmark suite, PCG even shows an average performance improvement of about 1.64%. Moreover, it incurs only 1.26% overhead on hardware resource consumption.</li>
</ul>

<h3>Title: TED: Accelerate Model Training by Internal Generalization</h3>
<ul>
<li><strong>Authors: </strong>Jinying Xiao, Ping Li, Jie Nie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03228">https://arxiv.org/abs/2405.03228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03228">https://arxiv.org/pdf/2405.03228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03228]] TED: Accelerate Model Training by Internal Generalization(https://arxiv.org/abs/2405.03228)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated strong performance in recent years, but the high cost of training drives the need for efficient methods to compress dataset sizes. We propose TED pruning, a method that addresses the challenge of overfitting under high pruning ratios by quantifying the model's ability to improve performance on pruned data while fitting retained data, known as Internal Generalization (IG). TED uses an optimization objective based on Internal Generalization Distance (IGD), measuring changes in IG before and after pruning to align with true generalization performance and achieve implicit regularization. The IGD optimization objective was verified to allow the model to achieve the smallest upper bound on generalization error. The impact of small mask fluctuations on IG is studied through masks and Taylor approximation, and fast estimation of IGD is enabled. In analyzing continuous training dynamics, the prior effect of IGD is validated, and a progressive pruning strategy is proposed. Experiments on image classification, natural language understanding, and large language model fine-tuning show TED achieves lossless performance with 60-70\% of the data. Upon acceptance, our code will be made publicly available.</li>
</ul>

<h3>Title: Federated Reinforcement Learning with Constraint Heterogeneity</h3>
<ul>
<li><strong>Authors: </strong>Hao Jin, Liangyu Zhang, Zhihua Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03236">https://arxiv.org/abs/2405.03236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03236">https://arxiv.org/pdf/2405.03236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03236]] Federated Reinforcement Learning with Constraint Heterogeneity(https://arxiv.org/abs/2405.03236)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, large language model</a></li>
<li><strong>Abstract: </strong>We study a Federated Reinforcement Learning (FedRL) problem with constraint heterogeneity. In our setting, we aim to solve a reinforcement learning problem with multiple constraints while $N$ training agents are located in $N$ different environments with limited access to the constraint signals and they are expected to collaboratively learn a policy satisfying all constraint signals. Such learning problems are prevalent in scenarios of Large Language Model (LLM) fine-tuning and healthcare applications. To solve the problem, we propose federated primal-dual policy optimization methods based on traditional policy gradient methods. Specifically, we introduce $N$ local Lagrange functions for agents to perform local policy updates, and these agents are then scheduled to periodically communicate on their local policies. Taking natural policy gradient (NPG) and proximal policy optimization (PPO) as policy optimization methods, we mainly focus on two instances of our algorithms, ie, {FedNPG} and {FedPPO}. We show that FedNPG achieves global convergence with an $\tilde{O}(1/\sqrt{T})$ rate, and FedPPO efficiently solves complicated learning tasks with the use of deep neural networks.</li>
</ul>

<h3>Title: Mind the Gap Between Synthetic and Real: Utilizing Transfer Learning to  Probe the Boundaries of Stable Diffusion Generated Data</h3>
<ul>
<li><strong>Authors: </strong>Leonhard Hennicke, Christian Medeiros Adriano, Holger Giese, Jan Mathias Koehler, Lukas Schott</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03243">https://arxiv.org/abs/2405.03243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03243">https://arxiv.org/pdf/2405.03243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03243]] Mind the Gap Between Synthetic and Real: Utilizing Transfer Learning to  Probe the Boundaries of Stable Diffusion Generated Data(https://arxiv.org/abs/2405.03243)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, data-free, generative</a></li>
<li><strong>Abstract: </strong>Generative foundation models like Stable Diffusion comprise a diverse spectrum of knowledge in computer vision with the potential for transfer learning, e.g., via generating data to train student models for downstream tasks. This could circumvent the necessity of collecting labeled real-world data, thereby presenting a form of data-free knowledge distillation. However, the resultant student models show a significant drop in accuracy compared to models trained on real data. We investigate possible causes for this drop and focus on the role of the different layers of the student model. By training these layers using either real or synthetic data, we reveal that the drop mainly stems from the model's final layers. Further, we briefly investigate other factors, such as differences in data-normalization between synthetic and real, the impact of data augmentations, texture vs.\ shape learning, and assuming oracle prompts. While we find that some of those factors can have an impact, they are not sufficient to close the gap towards real data. Building upon our insights that mainly later layers are responsible for the drop, we investigate the data-efficiency of fine-tuning a synthetically trained model with real data applied to only those last layers. Our results suggest an improved trade-off between the amount of real training data used and the model's accuracy. Our findings contribute to the understanding of the gap between synthetic and real data and indicate solutions to mitigate the scarcity of labeled real data.</li>
</ul>

<h3>Title: Communication-Efficient Federated Learning with Adaptive Compression  under Dynamic Bandwidth</h3>
<ul>
<li><strong>Authors: </strong>Ying Zhuansun, Dandan Li, Xiaohong Huang, Caijun Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03248">https://arxiv.org/abs/2405.03248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03248">https://arxiv.org/pdf/2405.03248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03248]] Communication-Efficient Federated Learning with Adaptive Compression  under Dynamic Bandwidth(https://arxiv.org/abs/2405.03248)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning can train models without directly providing local data to the server. However, the frequent updating of the local model brings the problem of large communication overhead. Recently, scholars have achieved the communication efficiency of federated learning mainly by model compression. But they ignore two problems: 1) network state of each client changes dynamically; 2) network state among clients is not the same. The clients with poor bandwidth update local model slowly, which leads to low efficiency. To address this challenge, we propose a communication-efficient federated learning algorithm with adaptive compression under dynamic bandwidth (called AdapComFL). Concretely, each client performs bandwidth awareness and bandwidth prediction. Then, each client adaptively compresses its local model via the improved sketch mechanism based on his predicted bandwidth. Further, the server aggregates sketched models with different sizes received. To verify the effectiveness of the proposed method, the experiments are based on real bandwidth data which are collected from the network topology we build, and benchmark datasets which are obtained from open repositories. We show the performance of AdapComFL algorithm, and compare it with existing algorithms. The experimental results show that our AdapComFL achieves more efficient communication as well as competitive accuracy compared to existing algorithms.</li>
</ul>

<h3>Title: Exploring the Frontiers of Softmax: Provable Optimization, Applications  in Diffusion Model, and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Jiuxiang Gu, Chenyang Li, Yingyu Liang, Zhenmei Shi, Zhao Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03251">https://arxiv.org/abs/2405.03251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03251">https://arxiv.org/pdf/2405.03251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03251]] Exploring the Frontiers of Softmax: Provable Optimization, Applications  in Diffusion Model, and Beyond(https://arxiv.org/abs/2405.03251)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>The softmax activation function plays a crucial role in the success of large language models (LLMs), particularly in the self-attention mechanism of the widely adopted Transformer architecture. However, the underlying learning dynamics that contribute to the effectiveness of softmax remain largely unexplored. As a step towards better understanding, this paper provides a theoretical study of the optimization and generalization properties of two-layer softmax neural networks, providing theoretical insights into their superior performance as other activation functions, such as ReLU and exponential. Leveraging the Neural Tangent Kernel (NTK) framework, our analysis reveals that the normalization effect of the softmax function leads to a good perturbation property of the induced NTK matrix, resulting in a good convex region of the loss landscape. Consequently, softmax neural networks can learn the target function in the over-parametrization regime. To demonstrate the broad applicability of our theoretical findings, we apply them to the task of learning score estimation functions in diffusion models, a promising approach for generative modeling. Our analysis shows that gradient-based algorithms can learn the score function with a provable accuracy. Our work provides a deeper understanding of the effectiveness of softmax neural networks and their potential in various domains, paving the way for further advancements in natural language processing and beyond.</li>
</ul>

<h3>Title: Multi-Modality Spatio-Temporal Forecasting via Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiewen Deng, Renhe Jiang, Jiaqi Zhang, Xuan Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03255">https://arxiv.org/abs/2405.03255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03255">https://arxiv.org/pdf/2405.03255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03255]] Multi-Modality Spatio-Temporal Forecasting via Self-Supervised Learning(https://arxiv.org/abs/2405.03255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-modality spatio-temporal (MoST) data extends spatio-temporal (ST) data by incorporating multiple modalities, which is prevalent in monitoring systems, encompassing diverse traffic demands and air quality assessments. Despite significant strides in ST modeling in recent years, there remains a need to emphasize harnessing the potential of information from different modalities. Robust MoST forecasting is more challenging because it possesses (i) high-dimensional and complex internal structures and (ii) dynamic heterogeneity caused by temporal, spatial, and modality variations. In this study, we propose a novel MoST learning framework via Self-Supervised Learning, namely MoSSL, which aims to uncover latent patterns from temporal, spatial, and modality perspectives while quantifying dynamic heterogeneity. Experiment results on two real-world MoST datasets verify the superiority of our approach compared with the state-of-the-art baselines. Model implementation is available at https://github.com/beginner-sketch/MoSSL.</li>
</ul>

<h3>Title: WorldQA: Multimodal World Knowledge in Videos through Long-Chain  Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yuanhan Zhang, Kaichen Zhang, Bo Li, Fanyi Pu, Christopher Arif Setiadharma, Jingkang Yang, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03272">https://arxiv.org/abs/2405.03272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03272">https://arxiv.org/pdf/2405.03272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03272]] WorldQA: Multimodal World Knowledge in Videos through Long-Chain  Reasoning(https://arxiv.org/abs/2405.03272)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal information, together with our knowledge, help us to understand the complex and dynamic world. Large language models (LLM) and large multimodal models (LMM), however, still struggle to emulate this capability. In this paper, we present WorldQA, a video understanding dataset designed to push the boundaries of multimodal world models with three appealing properties: (1) Multimodal Inputs: The dataset comprises 1007 question-answer pairs and 303 videos, necessitating the analysis of both auditory and visual data for successful interpretation. (2) World Knowledge: We identify five essential types of world knowledge for question formulation. This approach challenges models to extend their capabilities beyond mere perception. (3) Long-Chain Reasoning: Our dataset introduces an average reasoning step of 4.45, notably surpassing other videoQA datasets. Furthermore, we introduce WorldRetriever, an agent designed to synthesize expert knowledge into a coherent reasoning chain, thereby facilitating accurate responses to WorldQA queries. Extensive evaluations of 13 prominent LLMs and LMMs reveal that WorldRetriever, although being the most effective model, achieved only 70% of humanlevel performance in multiple-choice questions. This finding highlights the necessity for further advancement in the reasoning and comprehension abilities of models. Our experiments also yield several key insights. For instance, while humans tend to perform better with increased frames, current LMMs, including WorldRetriever, show diminished performance under similar conditions. We hope that WorldQA,our methodology, and these insights could contribute to the future development of multimodal world models.</li>
</ul>

<h3>Title: Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous  Prompt Learning</h3>
<ul>
<li><strong>Authors: </strong>Qizhou Chen, Taolin Zhang, Dongyang Li, Longtao Huang, Hui Xue, Chengyu Wang, Xiaofeng He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03279">https://arxiv.org/abs/2405.03279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03279">https://arxiv.org/pdf/2405.03279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03279]] Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous  Prompt Learning(https://arxiv.org/abs/2405.03279)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Model editing aims to correct outdated or erroneous knowledge in large language models (LLMs) without the need for costly retraining. Lifelong model editing is the most challenging task that caters to the continuous editing requirements of LLMs. Prior works primarily focus on single or batch editing; nevertheless, these methods fall short in lifelong editing scenarios due to catastrophic knowledge forgetting and the degradation of model performance. Although retrieval-based methods alleviate these issues, they are impeded by slow and cumbersome processes of integrating the retrieved knowledge into the model. In this work, we introduce RECIPE, a RetriEval-augmented ContInuous Prompt lEarning method, to boost editing efficacy and inference efficiency in lifelong learning. RECIPE first converts knowledge statements into short and informative continuous prompts, prefixed to the LLM's input query embedding, to efficiently refine the response grounded on the knowledge. It further integrates the Knowledge Sentinel (KS) that acts as an intermediary to calculate a dynamic threshold, determining whether the retrieval repository contains relevant knowledge. Our retriever and prompt encoder are jointly trained to achieve editing properties, i.e., reliability, generality, and locality. In our experiments, RECIPE is assessed extensively across multiple LLMs and editing datasets, where it achieves superior editing performance. RECIPE also demonstrates its capability to maintain the overall performance of LLMs alongside showcasing fast editing and inference speed.</li>
</ul>

<h3>Title: Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural  Vision from Slow Brain Activity</h3>
<ul>
<li><strong>Authors: </strong>Yizhuo Lu, Changde Du, Chong Wang, Xuanliu Zhu, Liuyun Jiang, Huiguang He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03280">https://arxiv.org/abs/2405.03280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03280">https://arxiv.org/pdf/2405.03280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03280]] Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural  Vision from Slow Brain Activity(https://arxiv.org/abs/2405.03280)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Reconstructing human dynamic vision from brain activity is a challenging task with great scientific significance. The difficulty stems from two primary issues: (1) vision-processing mechanisms in the brain are highly intricate and not fully revealed, making it challenging to directly learn a mapping between fMRI and video; (2) the temporal resolution of fMRI is significantly lower than that of natural videos. To overcome these issues, this paper propose a two-stage model named Mind-Animator, which achieves state-of-the-art performance on three public datasets. Specifically, during the fMRI-to-feature stage, we decouple semantic, structural, and motion features from fMRI through fMRI-vision-language tri-modal contrastive learning and sparse causal attention. In the feature-to-video stage, these features are merged to videos by an inflated Stable Diffusion. We substantiate that the reconstructed video dynamics are indeed derived from fMRI, rather than hallucinations of the generative model, through permutation tests. Additionally, the visualization of voxel-wise and ROI-wise importance maps confirms the neurobiological interpretability of our model.</li>
</ul>

<h3>Title: Online Clustering of Known and Emerging Malware Families</h3>
<ul>
<li><strong>Authors: </strong>Olha Jurečková, Martin Jureček, Mark Stamp</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03298">https://arxiv.org/abs/2405.03298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03298">https://arxiv.org/pdf/2405.03298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03298]] Online Clustering of Known and Emerging Malware Families(https://arxiv.org/abs/2405.03298)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Malware attacks have become significantly more frequent and sophisticated in recent years. Therefore, malware detection and classification are critical components of information security. Due to the large amount of malware samples available, it is essential to categorize malware samples according to their malicious characteristics. Clustering algorithms are thus becoming more widely used in computer security to analyze the behavior of malware variants and discover new malware families. Online clustering algorithms help us to understand malware behavior and produce a quicker response to new threats. This paper introduces a novel machine learning-based model for the online clustering of malicious samples into malware families. Streaming data is divided according to the clustering decision rule into samples from known and new emerging malware families. The streaming data is classified using the weighted k-nearest neighbor classifier into known families, and the online k-means algorithm clusters the remaining streaming data and achieves a purity of clusters from 90.20% for four clusters to 93.34% for ten clusters. This work is based on static analysis of portable executable files for the Windows operating system. Experimental results indicate that the proposed online clustering model can create high-purity clusters corresponding to malware families. This allows malware analysts to receive similar malware samples, speeding up their analysis.</li>
</ul>

<h3>Title: DarkFed: A Data-Free Backdoor Attack in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Minghui Li, Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Leo Yu Zhang, Yichen Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03299">https://arxiv.org/abs/2405.03299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03299">https://arxiv.org/pdf/2405.03299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03299]] DarkFed: A Data-Free Backdoor Attack in Federated Learning(https://arxiv.org/abs/2405.03299)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, federate, data-free</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has been demonstrated to be susceptible to backdoor attacks. However, existing academic studies on FL backdoor attacks rely on a high proportion of real clients with main task-related data, which is impractical. In the context of real-world industrial scenarios, even the simplest defense suffices to defend against the state-of-the-art attack, 3DFed. A practical FL backdoor attack remains in a nascent stage of development. To bridge this gap, we present DarkFed. Initially, we emulate a series of fake clients, thereby achieving the attacker proportion typical of academic research scenarios. Given that these emulated fake clients lack genuine training data, we further propose a data-free approach to backdoor FL. Specifically, we delve into the feasibility of injecting a backdoor using a shadow dataset. Our exploration reveals that impressive attack performance can be achieved, even when there is a substantial gap between the shadow dataset and the main task dataset. This holds true even when employing synthetic data devoid of any semantic information as the shadow dataset. Subsequently, we strategically construct a series of covert backdoor updates in an optimized manner, mimicking the properties of benign updates, to evade detection by defenses. A substantial body of empirical evidence validates the tangible effectiveness of DarkFed.</li>
</ul>

<h3>Title: Interpretable Network Visualizations: A Human-in-the-Loop Approach for  Post-hoc Explainability of CNN-based Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Matteo Bianchi, Antonio De Santis, Andrea Tocchetti, Marco Brambilla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03301">https://arxiv.org/abs/2405.03301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03301">https://arxiv.org/pdf/2405.03301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03301]] Interpretable Network Visualizations: A Human-in-the-Loop Approach for  Post-hoc Explainability of CNN-based Image Classification(https://arxiv.org/abs/2405.03301)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability</a></li>
<li><strong>Abstract: </strong>Transparency and explainability in image classification are essential for establishing trust in machine learning models and detecting biases and errors. State-of-the-art explainability methods generate saliency maps to show where a specific class is identified, without providing a detailed explanation of the model's decision process. Striving to address such a need, we introduce a post-hoc method that explains the entire feature extraction process of a Convolutional Neural Network. These explanations include a layer-wise representation of the features the model extracts from the input. Such features are represented as saliency maps generated by clustering and merging similar feature maps, to which we associate a weight derived by generalizing Grad-CAM for the proposed methodology. To further enhance these explanations, we include a set of textual labels collected through a gamified crowdsourcing activity and processed using NLP techniques and Sentence-BERT. Finally, we show an approach to generate global explanations by aggregating labels across multiple images.</li>
</ul>

<h3>Title: Federated Learning for Drowsiness Detection in Connected Vehicles</h3>
<ul>
<li><strong>Authors: </strong>William Lindskog, Valentin Spannagl, Christian Prehofer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03311">https://arxiv.org/abs/2405.03311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03311">https://arxiv.org/pdf/2405.03311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03311]] Federated Learning for Drowsiness Detection in Connected Vehicles(https://arxiv.org/abs/2405.03311)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Ensuring driver readiness poses challenges, yet driver monitoring systems can assist in determining the driver's state. By observing visual cues, such systems recognize various behaviors and associate them with specific conditions. For instance, yawning or eye blinking can indicate driver drowsiness. Consequently, an abundance of distributed data is generated for driver monitoring. Employing machine learning techniques, such as driver drowsiness detection, presents a potential solution. However, transmitting the data to a central machine for model training is impractical due to the large data size and privacy concerns. Conversely, training on a single vehicle would limit the available data and likely result in inferior performance. To address these issues, we propose a federated learning framework for drowsiness detection within a vehicular network, leveraging the YawDD dataset. Our approach achieves an accuracy of 99.2%, demonstrating its promise and comparability to conventional deep learning techniques. Lastly, we show how our model scales using various number of federated clients</li>
</ul>

<h3>Title: Provably Unlearnable Examples</h3>
<ul>
<li><strong>Authors: </strong>Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03316">https://arxiv.org/abs/2405.03316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03316">https://arxiv.org/pdf/2405.03316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03316]] Provably Unlearnable Examples(https://arxiv.org/abs/2405.03316)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>The exploitation of publicly accessible data has led to escalating concerns regarding data privacy and intellectual property (IP) breaches in the age of artificial intelligence. As a strategy to safeguard both data privacy and IP-related domain knowledge, efforts have been undertaken to render shared data unlearnable for unauthorized models in the wild. Existing methods apply empirically optimized perturbations to the data in the hope of disrupting the correlation between the inputs and the corresponding labels such that the data samples are converted into Unlearnable Examples (UEs). Nevertheless, the absence of mechanisms that can verify how robust the UEs are against unknown unauthorized models and train-time techniques engenders several problems. First, the empirically optimized perturbations may suffer from the problem of cross-model generalization, which echoes the fact that the unauthorized models are usually unknown to the defender. Second, UEs can be mitigated by train-time techniques such as data augmentation and adversarial training. Furthermore, we find that a simple recovery attack can restore the clean-task performance of the classifiers trained on UEs by slightly perturbing the learned weights. To mitigate the aforementioned problems, in this paper, we propose a mechanism for certifying the so-called $(q, \eta)$-Learnability of an unlearnable dataset via parametric smoothing. A lower certified $(q, \eta)$-Learnability indicates a more robust protection over the dataset. Finally, we try to 1) improve the tightness of certified $(q, \eta)$-Learnability and 2) design Provably Unlearnable Examples (PUEs) which have reduced $(q, \eta)$-Learnability. According to experimental results, PUEs demonstrate both decreased certified $(q, \eta)$-Learnability and enhanced empirical robustness compared to existing UEs.</li>
</ul>

<h3>Title: Enhancing DETRs Variants through Improved Content Query and Similar  Query Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Yingying Zhang, Chuangji Shi, Xin Guo, Jiangwei Lao, Jian Wang, Jiaotuan Wang, Jingdong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03318">https://arxiv.org/abs/2405.03318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03318">https://arxiv.org/pdf/2405.03318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03318]] Enhancing DETRs Variants through Improved Content Query and Similar  Query Aggregation(https://arxiv.org/abs/2405.03318)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The design of the query is crucial for the performance of DETR and its variants. Each query consists of two components: a content part and a positional one. Traditionally, the content query is initialized with a zero or learnable embedding, lacking essential content information and resulting in sub-optimal performance. In this paper, we introduce a novel plug-and-play module, Self-Adaptive Content Query (SACQ), to address this limitation. The SACQ module utilizes features from the transformer encoder to generate content queries via self-attention pooling. This allows candidate queries to adapt to the input image, resulting in a more comprehensive content prior and better focus on target objects. However, this improved concentration poses a challenge for the training process that utilizes the Hungarian matching, which selects only a single candidate and suppresses other similar ones. To overcome this, we propose a query aggregation strategy to cooperate with SACQ. It merges similar predicted candidates from different queries, easing the optimization. Our extensive experiments on the COCO dataset demonstrate the effectiveness of our proposed approaches across six different DETR's variants with multiple configurations, achieving an average improvement of over 1.0 AP.</li>
</ul>

<h3>Title: Denoising of Geodetic Time Series Using Spatiotemporal Graph Neural  Networks: Application to Slow Slip Event Extraction</h3>
<ul>
<li><strong>Authors: </strong>Giuseppe Costantino, Sophie Giffard-Roisin, Mauro Dalla Mura, Anne Socquet</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03320">https://arxiv.org/abs/2405.03320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03320">https://arxiv.org/pdf/2405.03320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03320]] Denoising of Geodetic Time Series Using Spatiotemporal Graph Neural  Networks: Application to Slow Slip Event Extraction(https://arxiv.org/abs/2405.03320)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Geospatial data has been transformative for the monitoring of the Earth, yet, as in the case of (geo)physical monitoring, the measurements can have variable spatial and temporal sampling and may be associated with a significant level of perturbations degrading the signal quality. Denoising geospatial data is, therefore, essential, yet often challenging because the observations may comprise noise coming from different origins, including both environmental signals and instrumental artifacts, which are spatially and temporally correlated, thus hard to disentangle. This study addresses the denoising of multivariate time series acquired by irregularly distributed networks of sensors, requiring specific methods to handle the spatiotemporal correlation of the noise and the signal of interest. Specifically, our method focuses on the denoising of geodetic position time series, used to monitor ground displacement worldwide with centimeter- to-millimeter precision. Among the signals affecting GNSS data, slow slip events (SSEs) are of interest to seismologists. These are transients of deformation that are weakly emerging compared to other signals. Here, we design SSEdenoiser, a multi-station spatiotemporal graph-based attentive denoiser that learns latent characteristics of GNSS noise to reveal SSE-related displacement with sub-millimeter precision. It is based on the key combination of graph recurrent networks and spatiotemporal Transformers. The proposed method is applied to the Cascadia subduction zone, where SSEs occur along with bursts of tectonic tremors, a seismic rumbling identified from independent seismic recordings. The extracted events match the spatiotemporal evolution of tremors. This good space-time correlation of the denoised GNSS signals with the tremors validates the proposed denoising procedure.</li>
</ul>

<h3>Title: Enhancing Spatiotemporal Disease Progression Models via Latent Diffusion  and Prior Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Lemuel Puglisi, Daniel C. Alexander, Daniele Ravì</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03328">https://arxiv.org/abs/2405.03328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03328">https://arxiv.org/pdf/2405.03328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03328]] Enhancing Spatiotemporal Disease Progression Models via Latent Diffusion  and Prior Knowledge(https://arxiv.org/abs/2405.03328)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this work, we introduce Brain Latent Progression (BrLP), a novel spatiotemporal disease progression model based on latent diffusion. BrLP is designed to predict the evolution of diseases at the individual level on 3D brain MRIs. Existing deep generative models developed for this task are primarily data-driven and face challenges in learning disease progressions. BrLP addresses these challenges by incorporating prior knowledge from disease models to enhance the accuracy of predictions. To implement this, we propose to integrate an auxiliary model that infers volumetric changes in various brain regions. Additionally, we introduce Latent Average Stabilization (LAS), a novel technique to improve spatiotemporal consistency of the predicted progression. BrLP is trained and evaluated on a large dataset comprising 11,730 T1-weighted brain MRIs from 2,805 subjects, collected from three publicly available, longitudinal Alzheimer's Disease (AD) studies. In our experiments, we compare the MRI scans generated by BrLP with the actual follow-up MRIs available from the subjects, in both cross-sectional and longitudinal settings. BrLP demonstrates significant improvements over existing methods, with an increase of 22% in volumetric accuracy across AD-related brain regions and 43% in image similarity to the ground-truth scans. The ability of BrLP to generate conditioned 3D scans at the subject level, along with the novelty of integrating prior knowledge to enhance accuracy, represents a significant advancement in disease progression modeling, opening new avenues for precision medicine. The code of BrLP is available at the following link: https://github.com/LemuelPuglisi/BrLP.</li>
</ul>

<h3>Title: Light-VQA+: A Video Quality Assessment Model for Exposure Correction  with Vision-Language Guidance</h3>
<ul>
<li><strong>Authors: </strong>Xunchu Zhou, Xiaohong Liu, Yunlong Dong, Tengchuan Kou, Yixuan Gao, Zicheng Zhang, Chunyi Li, Haoning Wu, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03333">https://arxiv.org/abs/2405.03333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03333">https://arxiv.org/pdf/2405.03333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03333]] Light-VQA+: A Video Quality Assessment Model for Exposure Correction  with Vision-Language Guidance(https://arxiv.org/abs/2405.03333)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recently, User-Generated Content (UGC) videos have gained popularity in our daily lives. However, UGC videos often suffer from poor exposure due to the limitations of photographic equipment and techniques. Therefore, Video Exposure Correction (VEC) algorithms have been proposed, Low-Light Video Enhancement (LLVE) and Over-Exposed Video Recovery (OEVR) included. Equally important to the VEC is the Video Quality Assessment (VQA). Unfortunately, almost all existing VQA models are built generally, measuring the quality of a video from a comprehensive perspective. As a result, Light-VQA, trained on LLVE-QA, is proposed for assessing LLVE. We extend the work of Light-VQA by expanding the LLVE-QA dataset into Video Exposure Correction Quality Assessment (VEC-QA) dataset with over-exposed videos and their corresponding corrected versions. In addition, we propose Light-VQA+, a VQA model specialized in assessing VEC. Light-VQA+ differs from Light-VQA mainly from the usage of the CLIP model and the vision-language guidance during the feature extraction, followed by a new module referring to the Human Visual System (HVS) for more accurate assessment. Extensive experimental results show that our model achieves the best performance against the current State-Of-The-Art (SOTA) VQA models on the VEC-QA dataset and other public datasets.</li>
</ul>

<h3>Title: Enhancing Q-Learning with Large Language Model Heuristics</h3>
<ul>
<li><strong>Authors: </strong>Xiefeng Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03341">https://arxiv.org/abs/2405.03341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03341">https://arxiv.org/pdf/2405.03341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03341]] Enhancing Q-Learning with Large Language Model Heuristics(https://arxiv.org/abs/2405.03341)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Q-learning excels in learning from feedback within sequential decision-making tasks but requires extensive sampling for significant improvements. Although reward shaping is a powerful technique for enhancing learning efficiency, it can introduce biases that affect agent performance. Furthermore, potential-based reward shaping is constrained as it does not allow for reward modifications based on actions or terminal states, potentially limiting its effectiveness in complex environments. Additionally, large language models (LLMs) can achieve zero-shot learning, but this is generally limited to simpler tasks. They also exhibit low inference speeds and occasionally produce hallucinations. To address these issues, we propose \textbf{LLM-guided Q-learning} that employs LLMs as heuristic to aid in learning the Q-function for reinforcement learning. It combines the advantages of both technologies without introducing performance bias. Our theoretical analysis demonstrates that the LLM heuristic provides action-level guidance. Additionally, our architecture has the capability to convert the impact of hallucinations into exploration costs. Moreover, the converged Q function corresponds to the MDP optimal Q function. Experiment results demonstrated that our algorithm enables agents to avoid ineffective exploration, enhances sampling efficiency, and is well-suited for complex control tasks.</li>
</ul>

<h3>Title: Doubly Robust Causal Effect Estimation under Networked Interference via  Targeted Learning</h3>
<ul>
<li><strong>Authors: </strong>Weilin Chen, Ruichu Cai, Zeqin Yang, Jie Qiao, Yuguang Yan, Zijian Li, Zhifeng Hao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03342">https://arxiv.org/abs/2405.03342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03342">https://arxiv.org/pdf/2405.03342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03342]] Doubly Robust Causal Effect Estimation under Networked Interference via  Targeted Learning(https://arxiv.org/abs/2405.03342)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causal effect estimation under networked interference is an important but challenging problem. Available parametric methods are limited in their model space, while previous semiparametric methods, e.g., leveraging neural networks to fit only one single nuisance function, may still encounter misspecification problems under networked interference without appropriate assumptions on the data generation process. To mitigate bias stemming from misspecification, we propose a novel doubly robust causal effect estimator under networked interference, by adapting the targeted learning technique to the training of neural networks. Specifically, we generalize the targeted learning technique into the networked interference setting and establish the condition under which an estimator achieves double robustness. Based on the condition, we devise an end-to-end causal effect estimator by transforming the identified theoretical condition into a targeted loss. Moreover, we provide a theoretical analysis of our designed estimator, revealing a faster convergence rate compared to a single nuisance model. Extensive experimental results on two real-world networks with semisynthetic data demonstrate the effectiveness of our proposed estimators.</li>
</ul>

<h3>Title: Retinexmamba: Retinex-based Mamba for Low-light Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Jiesong Bai, Yuhao Yin, Qiyuan He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03349">https://arxiv.org/abs/2405.03349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03349">https://arxiv.org/pdf/2405.03349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03349]] Retinexmamba: Retinex-based Mamba for Low-light Image Enhancement(https://arxiv.org/abs/2405.03349)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In the field of low-light image enhancement, both traditional Retinex methods and advanced deep learning techniques such as Retinexformer have shown distinct advantages and limitations. Traditional Retinex methods, designed to mimic the human eye's perception of brightness and color, decompose images into illumination and reflection components but struggle with noise management and detail preservation under low light conditions. Retinexformer enhances illumination estimation through traditional self-attention mechanisms, but faces challenges with insufficient interpretability and suboptimal enhancement effects. To overcome these limitations, this paper introduces the RetinexMamba architecture. RetinexMamba not only captures the physical intuitiveness of traditional Retinex methods but also integrates the deep learning framework of Retinexformer, leveraging the computational efficiency of State Space Models (SSMs) to enhance processing speed. This architecture features innovative illumination estimators and damage restorer mechanisms that maintain image quality during enhancement. Moreover, RetinexMamba replaces the IG-MSA (Illumination-Guided Multi-Head Attention) in Retinexformer with a Fused-Attention mechanism, improving the model's interpretability. Experimental evaluations on the LOL dataset show that RetinexMamba outperforms existing deep learning approaches based on Retinex theory in both quantitative and qualitative metrics, confirming its effectiveness and superiority in enhancing low-light images.</li>
</ul>

<h3>Title: Modality Prompts for Arbitrary Modality Salient Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Nianchang Huang, Yang Yang, Qiang Zhang, Jungong Han, Jin Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03351">https://arxiv.org/abs/2405.03351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03351">https://arxiv.org/pdf/2405.03351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03351]] Modality Prompts for Arbitrary Modality Salient Object Detection(https://arxiv.org/abs/2405.03351)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper delves into the task of arbitrary modality salient object detection (AM SOD), aiming to detect salient objects from arbitrary modalities, eg RGB images, RGB-D images, and RGB-D-T images. A novel modality-adaptive Transformer (MAT) will be proposed to investigate two fundamental challenges of AM SOD, ie more diverse modality discrepancies caused by varying modality types that need to be processed, and dynamic fusion design caused by an uncertain number of modalities present in the inputs of multimodal fusion strategy. Specifically, inspired by prompt learning's ability of aligning the distributions of pre-trained models to the characteristic of downstream tasks by learning some prompts, MAT will first present a modality-adaptive feature extractor (MAFE) to tackle the diverse modality discrepancies by introducing a modality prompt for each modality. In the training stage, a new modality translation contractive (MTC) loss will be further designed to assist MAFE in learning those modality-distinguishable modality prompts. Accordingly, in the testing stage, MAFE can employ those learned modality prompts to adaptively adjust its feature space according to the characteristics of the input modalities, thus being able to extract discriminative unimodal features. Then, MAFE will present a channel-wise and spatial-wise fusion hybrid (CSFH) strategy to meet the demand for dynamic fusion. For that, CSFH dedicates a channel-wise dynamic fusion module (CDFM) and a novel spatial-wise dynamic fusion module (SDFM) to fuse the unimodal features from varying numbers of modalities and meanwhile effectively capture cross-modal complementary semantic and detail information, respectively. Moreover, CSFH will carefully align CDFM and SDFM to different levels of unimodal features based on their characteristics for more effective complementary information exploitation.</li>
</ul>

<h3>Title: Salient Object Detection From Arbitrary Modalities</h3>
<ul>
<li><strong>Authors: </strong>Nianchang Huang, Yang Yang, Ruida Xi, Qiang Zhang, Jungong Han, Jin Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03352">https://arxiv.org/abs/2405.03352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03352">https://arxiv.org/pdf/2405.03352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03352]] Salient Object Detection From Arbitrary Modalities(https://arxiv.org/abs/2405.03352)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Toward desirable saliency prediction, the types and numbers of inputs for a salient object detection (SOD) algorithm may dynamically change in many real-life applications. However, existing SOD algorithms are mainly designed or trained for one particular type of inputs, failing to be generalized to other types of inputs. Consequentially, more types of SOD algorithms need to be prepared in advance for handling different types of inputs, raising huge hardware and research costs. Differently, in this paper, we propose a new type of SOD task, termed Arbitrary Modality SOD (AM SOD). The most prominent characteristics of AM SOD are that the modality types and modality numbers will be arbitrary or dynamically changed. The former means that the inputs to the AM SOD algorithm may be arbitrary modalities such as RGB, depths, or even any combination of them. While, the latter indicates that the inputs may have arbitrary modality numbers as the input type is changed, e.g. single-modality RGB image, dual-modality RGB-Depth (RGB-D) images or triple-modality RGB-Depth-Thermal (RGB-D-T) images. Accordingly, a preliminary solution to the above challenges, \i.e. a modality switch network (MSN), is proposed in this paper. In particular, a modality switch feature extractor (MSFE) is first designed to extract discriminative features from each modality effectively by introducing some modality indicators, which will generate some weights for modality switching. Subsequently, a dynamic fusion module (DFM) is proposed to adaptively fuse features from a variable number of modalities based on a novel Transformer structure. Finally, a new dataset, named AM-XD, is constructed to facilitate research on AM SOD. Extensive experiments demonstrate that our AM SOD method can effectively cope with changes in the type and number of input modalities for robust salient object detection.</li>
</ul>

<h3>Title: On the Theory of Cross-Modality Distillation with Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Hangyu Lin, Chen Liu, Chengming Xu, Zhengqi Gao, Yanwei Fu, Yuan Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03355">https://arxiv.org/abs/2405.03355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03355">https://arxiv.org/pdf/2405.03355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03355]] On the Theory of Cross-Modality Distillation with Contrastive Learning(https://arxiv.org/abs/2405.03355)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>Cross-modality distillation arises as an important topic for data modalities containing limited knowledge such as depth maps and high-quality sketches. Such techniques are of great importance, especially for memory and privacy-restricted scenarios where labeled training data is generally unavailable. To solve the problem, existing label-free methods leverage a few pairwise unlabeled data to distill the knowledge by aligning features or statistics between the source and target modalities. For instance, one typically aims to minimize the L2 distance or contrastive loss between the learned features of pairs of samples in the source (e.g. image) and the target (e.g. sketch) modalities. However, most algorithms in this domain only focus on the experimental results but lack theoretical insight. To bridge the gap between the theory and practical method of cross-modality distillation, we first formulate a general framework of cross-modality contrastive distillation (CMCD), built upon contrastive learning that leverages both positive and negative correspondence, towards a better distillation of generalizable features. Furthermore, we establish a thorough convergence analysis that reveals that the distance between source and target modalities significantly impacts the test error on downstream tasks within the target modality which is also validated by the empirical results. Extensive experimental results show that our algorithm outperforms existing algorithms consistently by a margin of 2-3\% across diverse modalities and tasks, covering modalities of image, sketch, depth map, and audio and tasks of recognition and segmentation.</li>
</ul>

<h3>Title: MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language  Models in the Context of the Pediatric Hypertension Guideline</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Yaseen Jabarulla, Steffen Oeltze-Jafra, Philipp Beerbaum, Theodor Uden</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03359">https://arxiv.org/abs/2405.03359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03359">https://arxiv.org/pdf/2405.03359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03359]] MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language  Models in the Context of the Pediatric Hypertension Guideline(https://arxiv.org/abs/2405.03359)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This research focuses on evaluating the non-commercial open-source large language models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their efficacy in interpreting medical guidelines saved in PDF format. As a specific test scenario, we applied these models to the guidelines for hypertension in children and adolescents provided by the European Society of Cardiology (ESC). Leveraging Streamlit, a Python library, we developed a user-friendly medical document chatbot tool (MedDoc-Bot). This tool enables authorized users to upload PDF files and pose questions, generating interpretive responses from four locally stored LLMs. A pediatric expert provides a benchmark for evaluation by formulating questions and responses extracted from the ESC guidelines. The expert rates the model-generated responses based on their fidelity and relevance. Additionally, we evaluated the METEOR and chrF metric scores to assess the similarity of model responses to reference answers. Our study found that Llama-2 and Mistral performed well in metrics evaluation. However, Llama-2 was slower when dealing with text and tabular data. In our human evaluation, we observed that responses created by Mistral, Meditron, and Llama-2 exhibited reasonable fidelity and relevance. This study provides valuable insights into the strengths and limitations of LLMs for future developments in medical document interpretation. Open-Source Code: https://github.com/yaseen28/MedDoc-Bot</li>
</ul>

<h3>Title: Explainable Fake News Detection With Large Language Model via Defense  Among Competing Wisdom</h3>
<ul>
<li><strong>Authors: </strong>Bo Wang, Jing Ma, Hongzhan Lin, Zhiwei Yang, Ruichao Yang, Yuan Tian, Yi Chang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03371">https://arxiv.org/abs/2405.03371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03371">https://arxiv.org/pdf/2405.03371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03371]] Explainable Fake News Detection With Large Language Model via Defense  Among Competing Wisdom(https://arxiv.org/abs/2405.03371)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Most fake news detection methods learn latent feature representations based on neural networks, which makes them black boxes to classify a piece of news without giving any justification. Existing explainable systems generate veracity justifications from investigative journalism, which suffer from debunking delayed and low efficiency. Recent studies simply assume that the justification is equivalent to the majority opinions expressed in the wisdom of crowds. However, the opinions typically contain some inaccurate or biased information since the wisdom of crowds is uncensored. To detect fake news from a sea of diverse, crowded and even competing narratives, in this paper, we propose a novel defense-based explainable fake news detection framework. Specifically, we first propose an evidence extraction module to split the wisdom of crowds into two competing parties and respectively detect salient evidences. To gain concise insights from evidences, we then design a prompt-based module that utilizes a large language model to generate justifications by inferring reasons towards two possible veracities. Finally, we propose a defense-based inference module to determine veracity via modeling the defense among these justifications. Extensive experiments conducted on two real-world benchmarks demonstrate that our proposed method outperforms state-of-the-art baselines in terms of fake news detection and provides high-quality justifications.</li>
</ul>

<h3>Title: CRA5: Extreme Compression of ERA5 for Portable Global Climate and  Weather Research via an Efficient Variational Transformer</h3>
<ul>
<li><strong>Authors: </strong>Tao Han, zhenghao Chen, Song Guo, Wanghan Xu, Lei Bai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03376">https://arxiv.org/abs/2405.03376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03376">https://arxiv.org/pdf/2405.03376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03376]] CRA5: Extreme Compression of ERA5 for Portable Global Climate and  Weather Research via an Efficient Variational Transformer(https://arxiv.org/abs/2405.03376)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The advent of data-driven weather forecasting models, which learn from hundreds of terabytes (TB) of reanalysis data, has significantly advanced forecasting capabilities. However, the substantial costs associated with data storage and transmission present a major challenge for data providers and users, affecting resource-constrained researchers and limiting their accessibility to participate in AI-based meteorological research. To mitigate this issue, we introduce an efficient neural codec, the Variational Autoencoder Transformer (VAEformer), for extreme compression of climate data to significantly reduce data storage cost, making AI-based meteorological research portable to researchers. Our approach diverges from recent complex neural codecs by utilizing a low-complexity Auto-Encoder transformer. This encoder produces a quantized latent representation through variance inference, which reparameterizes the latent space as a Gaussian distribution. This method improves the estimation of distributions for cross-entropy coding. Extensive experiments demonstrate that our VAEformer outperforms existing state-of-the-art compression methods in the context of climate data. By applying our VAEformer, we compressed the most popular ERA5 climate dataset (226 TB) into a new dataset, CRA5 (0.7 TB). This translates to a compression ratio of over 300 while retaining the dataset's utility for accurate scientific analysis. Further, downstream experiments show that global weather forecasting models trained on the compact CRA5 dataset achieve forecasting accuracy comparable to the model trained on the original dataset. Code, the CRA5 dataset, and the pre-trained model are available at https://github.com/taohan10200/CRA5.</li>
</ul>

<h3>Title: GLIP: Electromagnetic Field Exposure Map Completion by Deep Generative  Networks</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Mallik, Davy P. Gaillot, Laurent Clavier</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03384">https://arxiv.org/abs/2405.03384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03384">https://arxiv.org/pdf/2405.03384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03384]] GLIP: Electromagnetic Field Exposure Map Completion by Deep Generative  Networks(https://arxiv.org/abs/2405.03384)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In Spectrum cartography (SC), the generation of exposure maps for radio frequency electromagnetic fields (RF-EMF) spans dimensions of frequency, space, and time, which relies on a sparse collection of sensor data, posing a challenging ill-posed inverse problem. Cartography methods based on models integrate designed priors, such as sparsity and low-rank structures, to refine the solution of this inverse problem. In our previous work, EMF exposure map reconstruction was achieved by Generative Adversarial Networks (GANs) where physical laws or structural constraints were employed as a prior, but they require a large amount of labeled data or simulated full maps for training to produce efficient results. In this paper, we present a method to reconstruct EMF exposure maps using only the generator network in GANs which does not require explicit training, thus overcoming the limitations of GANs, such as using reference full exposure maps. This approach uses a prior from sensor data as Local Image Prior (LIP) captured by deep convolutional generative networks independent of learning the network parameters from images in an urban environment. Experimental results show that, even when only sparse sensor data are available, our method can produce accurate estimates.</li>
</ul>

<h3>Title: Annot-Mix: Learning with Noisy Class Labels from Multiple Annotators via  a Mixup Extension</h3>
<ul>
<li><strong>Authors: </strong>Marek Herde, Lukas Lührs, Denis Huseljic, Bernhard Sick</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03386">https://arxiv.org/abs/2405.03386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03386">https://arxiv.org/pdf/2405.03386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03386]] Annot-Mix: Learning with Noisy Class Labels from Multiple Annotators via  a Mixup Extension(https://arxiv.org/abs/2405.03386)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Training with noisy class labels impairs neural networks' generalization performance. In this context, mixup is a popular regularization technique to improve training robustness by making memorizing false class labels more difficult. However, mixup neglects that, typically, multiple annotators, e.g., crowdworkers, provide class labels. Therefore, we propose an extension of mixup, which handles multiple class labels per instance while considering which class label originates from which annotator. Integrated into our multi-annotator classification framework annot-mix, it performs superiorly to eight state-of-the-art approaches on eleven datasets with noisy class labels provided either by human or simulated annotators. Our code is publicly available through our repository at https://github.com/ies-research/annot-mix.</li>
</ul>

<h3>Title: 3D LiDAR Mapping in Dynamic Environments Using a 4D Implicit Neural  Representation</h3>
<ul>
<li><strong>Authors: </strong>Xingguang Zhong, Yue Pan, Cyrill Stachniss, Jens Behley</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03388">https://arxiv.org/abs/2405.03388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03388">https://arxiv.org/pdf/2405.03388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03388]] 3D LiDAR Mapping in Dynamic Environments Using a 4D Implicit Neural  Representation(https://arxiv.org/abs/2405.03388)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Building accurate maps is a key building block to enable reliable localization, planning, and navigation of autonomous vehicles. We propose a novel approach for building accurate maps of dynamic environments utilizing a sequence of LiDAR scans. To this end, we propose encoding the 4D scene into a novel spatio-temporal implicit neural map representation by fitting a time-dependent truncated signed distance function to each point. Using our representation, we extract the static map by filtering the dynamic parts. Our neural representation is based on sparse feature grids, a globally shared decoder, and time-dependent basis functions, which we jointly optimize in an unsupervised fashion. To learn this representation from a sequence of LiDAR scans, we design a simple yet efficient loss function to supervise the map optimization in a piecewise way. We evaluate our approach on various scenes containing moving objects in terms of the reconstruction quality of static maps and the segmentation of dynamic point clouds. The experimental results demonstrate that our method is capable of removing the dynamic part of the input point clouds while reconstructing accurate and complete 3D maps, outperforming several state-of-the-art methods. Codes are available at: https://github.com/PRBonn/4dNDF</li>
</ul>

<h3>Title: E2GNN: Efficient Graph Neural Network Ensembles for Semi-Supervised  Classification</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhang, Daochen Zha, Qiaoyu Tan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03401">https://arxiv.org/abs/2405.03401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03401">https://arxiv.org/pdf/2405.03401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03401]] E2GNN: Efficient Graph Neural Network Ensembles for Semi-Supervised  Classification(https://arxiv.org/abs/2405.03401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work studies ensemble learning for graph neural networks (GNNs) under the popular semi-supervised setting. Ensemble learning has shown superiority in improving the accuracy and robustness of traditional machine learning by combining the outputs of multiple weak learners. However, adopting a similar idea to integrate different GNN models is challenging because of two reasons. First, GNN is notorious for its poor inference ability, so naively assembling multiple GNN models would deteriorate the inference efficiency. Second, when GNN models are trained with few labeled nodes, their performance are limited. In this case, the vanilla ensemble approach, e.g., majority vote, may be sub-optimal since most base models, i.e., GNNs, may make the wrong predictions. To this end, in this paper, we propose an efficient ensemble learner--E2GNN to assemble multiple GNNs in a learnable way by leveraging both labeled and unlabeled nodes. Specifically, we first pre-train different GNN models on a given data scenario according to the labeled nodes. Next, instead of directly combing their outputs for label inference, we train a simple multi-layer perceptron--MLP model to mimic their predictions on both labeled and unlabeled nodes. Then the unified MLP model is deployed to infer labels for unlabeled or new nodes. Since the predictions of unlabeled nodes from different GNN models may be incorrect, we develop a reinforced discriminator to effectively filter out those wrongly predicted nodes to boost the performance of MLP. By doing this, we suggest a principled approach to tackle the inference issues of GNN ensembles and maintain the merit of ensemble learning: improved performance. Comprehensive experiments over both transductive and inductive settings, across different GNN backbones and 8 benchmark datasets, demonstrate the superiority of E2GNN.</li>
</ul>

<h3>Title: LightTR: A Lightweight Framework for Federated Trajectory Recovery</h3>
<ul>
<li><strong>Authors: </strong>Ziqiao Liu, Hao Miao, Yan Zhao, Chenxi Liu, Kai Zheng, Huan Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03409">https://arxiv.org/abs/2405.03409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03409">https://arxiv.org/pdf/2405.03409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03409]] LightTR: A Lightweight Framework for Federated Trajectory Recovery(https://arxiv.org/abs/2405.03409)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, federate</a></li>
<li><strong>Abstract: </strong>With the proliferation of GPS-equipped edge devices, huge trajectory data is generated and accumulated in various domains, motivating a variety of urban applications. Due to the limited acquisition capabilities of edge devices, a lot of trajectories are recorded at a low sampling rate, which may lead to the effectiveness drop of urban applications. We aim to recover a high-sampled trajectory based on the low-sampled trajectory in free space, i.e., without road network information, to enhance the usability of trajectory data and support urban applications more effectively. Recent proposals targeting trajectory recovery often assume that trajectories are available at a central location, which fail to handle the decentralized trajectories and hurt privacy. To bridge the gap between decentralized training and trajectory recovery, we propose a lightweight framework, LightTR, for federated trajectory recovery based on a client-server architecture, while keeping the data decentralized and private in each client/platform center (e.g., each data center of a company). Specifically, considering the limited processing capabilities of edge devices, LightTR encompasses a light local trajectory embedding module that offers improved computational efficiency without compromising its feature extraction capabilities. LightTR also features a meta-knowledge enhanced local-global training scheme to reduce communication costs between the server and clients and thus further offer efficiency improvement. Extensive experiments demonstrate the effectiveness and efficiency of the proposed framework.</li>
</ul>

<h3>Title: Implantable Adaptive Cells: differentiable architecture search to  improve the performance of any trained U-shaped network</h3>
<ul>
<li><strong>Authors: </strong>Emil Benedykciuk, Marcin Denkowski, Grzegorz Wójcik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03420">https://arxiv.org/abs/2405.03420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03420">https://arxiv.org/pdf/2405.03420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03420]] Implantable Adaptive Cells: differentiable architecture search to  improve the performance of any trained U-shaped network(https://arxiv.org/abs/2405.03420)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel approach to enhance the performance of pre-trained neural networks in medical image segmentation using Neural Architecture Search (NAS) methods, specifically Differentiable Architecture Search (DARTS). We present the concept of Implantable Adaptive Cell (IAC), small but powerful modules identified through Partially-Connected DARTS, designed to be injected into the skip connections of an existing and already trained U-shaped model. Our strategy allows for the seamless integration of the IAC into the pre-existing architecture, thereby enhancing its performance without necessitating a complete retraining from scratch. The empirical studies, focusing on medical image segmentation tasks, demonstrate the efficacy of this method. The integration of specialized IAC cells into various configurations of the U-Net model increases segmentation accuracy by almost 2\% points on average for the validation dataset and over 3\% points for the training dataset. The findings of this study not only offer a cost-effective alternative to the complete overhaul of complex models for performance upgrades but also indicate the potential applicability of our method to other architectures and problem domains.</li>
</ul>

<h3>Title: Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Emre Onal, Klemens Flöge, Emma Caldwell, Arsen Sheverdin, Vincent Fortuin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03425">https://arxiv.org/abs/2405.03425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03425">https://arxiv.org/pdf/2405.03425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03425]] Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of  Large Language Models(https://arxiv.org/abs/2405.03425)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuned Large Language Models (LLMs) often suffer from overconfidence and poor calibration, particularly when fine-tuned on small datasets. To address these challenges, we propose a simple combination of Low-Rank Adaptation (LoRA) with Gaussian Stochastic Weight Averaging (SWAG), facilitating approximate Bayesian inference in LLMs. Through extensive testing across several Natural Language Processing (NLP) benchmarks, we demonstrate that our straightforward and computationally efficient approach improves model generalization and calibration. We further show that our method exhibits greater robustness against distribution shift, as reflected in its performance on out-of-distribution tasks.</li>
</ul>

<h3>Title: ReCycle: Fast and Efficient Long Time Series Forecasting with Residual  Cyclic Transformers</h3>
<ul>
<li><strong>Authors: </strong>Arvid Weyrauch, Thomas Steens, Oskar Taubert, Benedikt Hanke, Aslan Eqbal, Ewa Götz, Achim Streit, Markus Götz, Charlotte Debus</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03429">https://arxiv.org/abs/2405.03429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03429">https://arxiv.org/pdf/2405.03429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03429]] ReCycle: Fast and Efficient Long Time Series Forecasting with Residual  Cyclic Transformers(https://arxiv.org/abs/2405.03429)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have recently gained prominence in long time series forecasting by elevating accuracies in a variety of use cases. Regrettably, in the race for better predictive performance the overhead of model architectures has grown onerous, leading to models with computational demand infeasible for most practical applications. To bridge the gap between high method complexity and realistic computational resources, we introduce the Residual Cyclic Transformer, ReCycle. ReCycle utilizes primary cycle compression to address the computational complexity of the attention mechanism in long time series. By learning residuals from refined smoothing average techniques, ReCycle surpasses state-of-the-art accuracy in a variety of application use cases. The reliable and explainable fallback behavior ensured by simple, yet robust, smoothing average techniques additionally lowers the barrier for user acceptance. At the same time, our approach reduces the run time and energy consumption by more than an order of magnitude, making both training and inference feasible on low-performance, low-power and edge computing devices. Code is available at https://github.com/Helmholtz-AI-Energy/ReCycle</li>
</ul>

<h3>Title: DBDH: A Dual-Branch Dual-Head Neural Network for Invisible Embedded  Regions Localization</h3>
<ul>
<li><strong>Authors: </strong>Chengxin Zhao, Hefei Ling, Sijing Xie, Nan Sun, Zongyi Li, Yuxuan Shi, Jiazhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03436">https://arxiv.org/abs/2405.03436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03436">https://arxiv.org/pdf/2405.03436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03436]] DBDH: A Dual-Branch Dual-Head Neural Network for Invisible Embedded  Regions Localization(https://arxiv.org/abs/2405.03436)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Embedding invisible hyperlinks or hidden codes in images to replace QR codes has become a hot topic recently. This technology requires first localizing the embedded region in the captured photos before decoding. Existing methods that train models to find the invisible embedded region struggle to obtain accurate localization results, leading to degraded decoding accuracy. This limitation is primarily because the CNN network is sensitive to low-frequency signals, while the embedded signal is typically in the high-frequency form. Based on this, this paper proposes a Dual-Branch Dual-Head (DBDH) neural network tailored for the precise localization of invisible embedded regions. Specifically, DBDH uses a low-level texture branch containing 62 high-pass filters to capture the high-frequency signals induced by embedding. A high-level context branch is used to extract discriminative features between the embedded and normal regions. DBDH employs a detection head to directly detect the four vertices of the embedding region. In addition, we introduce an extra segmentation head to segment the mask of the embedding region during training. The segmentation head provides pixel-level supervision for model learning, facilitating better learning of the embedded signals. Based on two state-of-the-art invisible offline-to-online messaging methods, we construct two datasets and augmentation strategies for training and testing localization models. Extensive experiments demonstrate the superior performance of the proposed DBDH over existing methods.</li>
</ul>

<h3>Title: SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of Large  Language Models in Cyber Threat Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Hangyuan Ji, Jian Yang, Linzheng Chai, Chaoren Wei, Liqun Yang, Yunlong Duan, Yunli Wang, Tianzhen Sun, Hongcheng Guo, Tongliang Li, Changyu Ren, Zhoujun Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03446">https://arxiv.org/abs/2405.03446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03446">https://arxiv.org/pdf/2405.03446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03446]] SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of Large  Language Models in Cyber Threat Intelligence(https://arxiv.org/abs/2405.03446)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, extraction, large language model</a></li>
<li><strong>Abstract: </strong>To address the increasing complexity and frequency of cybersecurity incidents emphasized by the recent cybersecurity threat reports with over 10 billion instances, cyber threat intelligence (CTI) plays a critical role in the modern cybersecurity landscape by offering the insights required to understand and combat the constantly evolving nature of cyber threats. Inspired by the powerful capability of large language models (LLMs) in handling complex tasks, in this paper, we introduce a framework to benchmark, elicit, and improve cybersecurity incident analysis and response abilities in LLMs for Security Events (SEvenLLM). Specifically, we create a high-quality bilingual instruction corpus by crawling cybersecurity raw text from cybersecurity websites to overcome the lack of effective data for information extraction. Then, we design a pipeline to auto-select tasks from the tasks pool and convert the raw text into supervised corpora comprised of question and response. The instruction dataset SEvenLLM-Instruct is used to train cybersecurity LLMs with the multi-task learning objective (27 well-designed tasks) for augmenting the analysis of cybersecurity events. Extensive experiments in our curated benchmark (SEvenLLM-bench) demonstrate that SEvenLLM performs more sophisticated threat analysis and fortifies defenses against the evolving landscape of cyber threats.</li>
</ul>

<h3>Title: Byzantine-Robust Gossip: Insights from a Dual Approach</h3>
<ul>
<li><strong>Authors: </strong>Renaud Gaucher, Hadrien Hendrikx, Aymeric Dieuleveut</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03449">https://arxiv.org/abs/2405.03449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03449">https://arxiv.org/pdf/2405.03449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03449]] Byzantine-Robust Gossip: Insights from a Dual Approach(https://arxiv.org/abs/2405.03449)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. We leverage the so-called dual approach to design a general robust decentralized optimization method. We provide both global and local clipping rules in the special case of average consensus, with tight convergence guarantees. These clipping rules are practical, and yield results that finely characterize the impact of Byzantine nodes, highlighting for instance a qualitative difference in convergence between global and local clipping thresholds. Lastly, we demonstrate that they can serve as a basis for designing efficient attacks.</li>
</ul>

<h3>Title: SSyncOA: Self-synchronizing Object-aligned Watermarking to Resist  Cropping-paste Attacks</h3>
<ul>
<li><strong>Authors: </strong>Chengxin Zhao, Hefei Ling, Sijing Xie, Han Fang, Yaokun Fang, Nan Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03458">https://arxiv.org/abs/2405.03458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03458">https://arxiv.org/pdf/2405.03458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03458]] SSyncOA: Self-synchronizing Object-aligned Watermarking to Resist  Cropping-paste Attacks(https://arxiv.org/abs/2405.03458)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Modern image processing tools have made it easy for attackers to crop the region or object of interest in images and paste it into other images. The challenge this cropping-paste attack poses to the watermarking technology is that it breaks the synchronization of the image watermark, introducing multiple superimposed desynchronization distortions, such as rotation, scaling, and translation. However, current watermarking methods can only resist a single type of desynchronization and cannot be applied to protect the object's copyright under the cropping-paste attack. With the finding that the key to resisting the cropping-paste attack lies in robust features of the object to protect, this paper proposes a self-synchronizing object-aligned watermarking method, called SSyncOA. Specifically, we first constrain the watermarked region to be aligned with the protected object, and then synchronize the watermark's translation, rotation, and scaling distortions by normalizing the object invariant features, i.e., its centroid, principal orientation, and minimum bounding square, respectively. To make the watermark embedded in the protected object, we introduce the object-aligned watermarking model, which incorporates the real cropping-paste attack into the encoder-noise layer-decoder pipeline and is optimized end-to-end. Besides, we illustrate the effect of different desynchronization distortions on the watermark training, which confirms the necessity of the self-synchronization process. Extensive experiments demonstrate the superiority of our method over other SOTAs.</li>
</ul>

<h3>Title: Synthetic Datasets for Program Similarity Research</h3>
<ul>
<li><strong>Authors: </strong>Alexander Interrante-Grant, Michael Wang, Lisa Baer, Ryan Whelan, Tim Leek</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03478">https://arxiv.org/abs/2405.03478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03478">https://arxiv.org/pdf/2405.03478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03478]] Synthetic Datasets for Program Similarity Research(https://arxiv.org/abs/2405.03478)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Program similarity has become an increasingly popular area of research with various security applications such as plagiarism detection, author identification, and malware analysis. However, program similarity research faces a few unique dataset quality problems in evaluating the effectiveness of novel approaches. First, few high-quality datasets for binary program similarity exist and are widely used in this domain. Second, there are potentially many different, disparate definitions of what makes one program similar to another and in many cases there is often a large semantic gap between the labels provided by a dataset and any useful notion of behavioral or semantic similarity. In this paper, we present HELIX - a framework for generating large, synthetic program similarity datasets. We also introduce Blind HELIX, a tool built on top of HELIX for extracting HELIX components from library code automatically using program slicing. We evaluate HELIX and Blind HELIX by comparing the performance of program similarity tools on a HELIX dataset to a hand-crafted dataset built from multiple, disparate notions of program similarity. Using Blind HELIX, we show that HELIX can generate realistic and useful datasets of virtually infinite size for program similarity research with ground truth labels that embody practical notions of program similarity. Finally, we discuss the results and reason about relative tool ranking.</li>
</ul>

<h3>Title: AnchorGT: Efficient and Flexible Attention Architecture for Scalable  Graph Transformers</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Zhu, Guojie Song, Liang Wang, Shaoguo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03481">https://arxiv.org/abs/2405.03481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03481">https://arxiv.org/pdf/2405.03481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03481]] AnchorGT: Efficient and Flexible Attention Architecture for Scalable  Graph Transformers(https://arxiv.org/abs/2405.03481)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph Transformers (GTs) have significantly advanced the field of graph representation learning by overcoming the limitations of message-passing graph neural networks (GNNs) and demonstrating promising performance and expressive power. However, the quadratic complexity of self-attention mechanism in GTs has limited their scalability, and previous approaches to address this issue often suffer from expressiveness degradation or lack of versatility. To address this issue, we propose AnchorGT, a novel attention architecture for GTs with global receptive field and almost linear complexity, which serves as a flexible building block to improve the scalability of a wide range of GT models. Inspired by anchor-based GNNs, we employ structurally important $k$-dominating node set as anchors and design an attention mechanism that focuses on the relationship between individual nodes and anchors, while retaining the global receptive field for all nodes. With its intuitive design, AnchorGT can easily replace the attention module in various GT models with different network architectures and structural encodings, resulting in reduced computational overhead without sacrificing performance. In addition, we theoretically prove that AnchorGT attention can be strictly more expressive than Weisfeiler-Lehman test, showing its superiority in representing graph structures. Our experiments on three state-of-the-art GT models demonstrate that their AnchorGT variants can achieve better results while being faster and significantly more memory efficient.</li>
</ul>

<h3>Title: LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Haowen Sun, Ruikun Zheng, Haibin Huang, Chongyang Ma, Hui Huang, Ruizhen Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03485">https://arxiv.org/abs/2405.03485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03485">https://arxiv.org/pdf/2405.03485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03485]] LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model(https://arxiv.org/abs/2405.03485)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce LGTM, a novel Local-to-Global pipeline for Text-to-Motion generation. LGTM utilizes a diffusion-based architecture and aims to address the challenge of accurately translating textual descriptions into semantically coherent human motion in computer animation. Specifically, traditional methods often struggle with semantic discrepancies, particularly in aligning specific motions to the correct body parts. To address this issue, we propose a two-stage pipeline to overcome this challenge: it first employs large language models (LLMs) to decompose global motion descriptions into part-specific narratives, which are then processed by independent body-part motion encoders to ensure precise local semantic alignment. Finally, an attention-based full-body optimizer refines the motion generation results and guarantees the overall coherence. Our experiments demonstrate that LGTM gains significant improvements in generating locally accurate, semantically-aligned human motion, marking a notable advancement in text-to-motion applications. Code and data for this paper are available at https://github.com/L-Sun/LGTM</li>
</ul>

<h3>Title: UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and  AI-Generated Images</h3>
<ul>
<li><strong>Authors: </strong>Yiting Qu, Xinyue Shen, Yixin Wu, Michael Backes, Savvas Zannettou, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03486">https://arxiv.org/abs/2405.03486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03486">https://arxiv.org/pdf/2405.03486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03486]] UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and  AI-Generated Images(https://arxiv.org/abs/2405.03486)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Image safety classifiers play an important role in identifying and mitigating the spread of unsafe images online (e.g., images including violence, hateful rhetoric, etc.). At the same time, with the advent of text-to-image models and increasing concerns about the safety of AI models, developers are increasingly relying on image safety classifiers to safeguard their models. Yet, the performance of current image safety classifiers remains unknown for real-world and AI-generated images. To bridge this research gap, in this work, we propose UnsafeBench, a benchmarking framework that evaluates the effectiveness and robustness of image safety classifiers. First, we curate a large dataset of 10K real-world and AI-generated images that are annotated as safe or unsafe based on a set of 11 unsafe categories of images (sexual, violent, hateful, etc.). Then, we evaluate the effectiveness and robustness of five popular image safety classifiers, as well as three classifiers that are powered by general-purpose visual language models. Our assessment indicates that existing image safety classifiers are not comprehensive and effective enough in mitigating the multifaceted problem of unsafe images. Also, we find that classifiers trained only on real-world images tend to have degraded performance when applied to AI-generated images. Motivated by these findings, we design and implement a comprehensive image moderation tool called PerspectiveVision, which effectively identifies 11 categories of real-world and AI-generated unsafe images. The best PerspectiveVision model achieves an overall F1-Score of 0.810 on six evaluation datasets, which is comparable with closed-source and expensive state-of-the-art models like GPT-4V. UnsafeBench and PerspectiveVision can aid the research community in better understanding the landscape of image safety classification in the era of generative AI.</li>
</ul>

<h3>Title: Boosting Single Positive Multi-label Classification with Generalized  Robust Loss</h3>
<ul>
<li><strong>Authors: </strong>Yanxi Chen, Chunxiao Li, Xinyang Dai, Jinhuan Li, Weiyu Sun, Yiming Wang, Renyuan Zhang, Tinghe Zhang, Bo Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03501">https://arxiv.org/abs/2405.03501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03501">https://arxiv.org/pdf/2405.03501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03501]] Boosting Single Positive Multi-label Classification with Generalized  Robust Loss(https://arxiv.org/abs/2405.03501)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-label learning (MLL) requires comprehensive multi-semantic annotations that is hard to fully obtain, thus often resulting in missing labels scenarios. In this paper, we investigate Single Positive Multi-label Learning (SPML), where each image is associated with merely one positive label. Existing SPML methods only focus on designing losses using mechanisms such as hard pseudo-labeling and robust losses, mostly leading to unacceptable false negatives. To address this issue, we first propose a generalized loss framework based on expected risk minimization to provide soft pseudo labels, and point out that the former losses can be seamlessly converted into our framework. In particular, we design a novel robust loss based on our framework, which enjoys flexible coordination between false positives and false negatives, and can additionally deal with the imbalance between positive and negative samples. Extensive experiments show that our approach can significantly improve SPML performance and outperform the vast majority of state-of-the-art methods on all the four benchmarks.</li>
</ul>

<h3>Title: QBER: Quantifying Cyber Risks for Strategic Decisions</h3>
<ul>
<li><strong>Authors: </strong>Muriel Figueredo Franco, Aiatur Rahaman Mullick, Santosh Jha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03513">https://arxiv.org/abs/2405.03513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03513">https://arxiv.org/pdf/2405.03513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03513]] QBER: Quantifying Cyber Risks for Strategic Decisions(https://arxiv.org/abs/2405.03513)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Quantifying cyber risks is essential for organizations to grasp their vulnerability to threats and make informed decisions. However, current approaches still need to work on blending economic viewpoints to provide insightful analysis. To bridge this gap, we introduce QBER approach to offer decision-makers measurable risk metrics. The QBER evaluates losses from cyberattacks, performs detailed risk analyses based on existing cybersecurity measures, and provides thorough cost assessments. Our contributions involve outlining cyberattack probabilities and risks, identifying Technical, Economic, and Legal (TEL) impacts, creating a model to gauge impacts, suggesting risk mitigation strategies, and examining trends and challenges in implementing widespread Cyber Risk Quantification (CRQ). The QBER approach serves as a guided approach for organizations to assess risks and strategically invest in cybersecurity.</li>
</ul>

<h3>Title: GI-SMN: Gradient Inversion Attack against Federated Learning without  Prior Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Jin Qian, Kaimin Wei, Yongdong Wu, Jilian Zhang, Jipeng Chen, Huan Bao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03516">https://arxiv.org/abs/2405.03516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03516">https://arxiv.org/pdf/2405.03516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03516]] GI-SMN: Gradient Inversion Attack against Federated Learning without  Prior Knowledge(https://arxiv.org/abs/2405.03516)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has emerged as a privacy-preserving machine learning approach where multiple parties share gradient information rather than original user data. Recent work has demonstrated that gradient inversion attacks can exploit the gradients of FL to recreate the original user data, posing significant privacy risks. However, these attacks make strong assumptions about the attacker, such as altering the model structure or parameters, gaining batch normalization statistics, or acquiring prior knowledge of the original training set, etc. Consequently, these attacks are not possible in real-world scenarios. To end it, we propose a novel Gradient Inversion attack based on Style Migration Network (GI-SMN), which breaks through the strong assumptions made by previous gradient inversion attacks. The optimization space is reduced by the refinement of the latent code and the use of regular terms to facilitate gradient matching. GI-SMN enables the reconstruction of user data with high similarity in batches. Experimental results have demonstrated that GI-SMN outperforms state-of-the-art gradient inversion attacks in both visual effect and similarity metrics. Additionally, it also can overcome gradient pruning and differential privacy defenses.</li>
</ul>

<h3>Title: Is Sora a World Simulator? A Comprehensive Survey on General World  Models and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhu, Xiaofeng Wang, Wangbo Zhao, Chen Min, Nianchen Deng, Min Dou, Yuqi Wang, Botian Shi, Kai Wang, Chi Zhang, Yang You, Zhaoxiang Zhang, Dawei Zhao, Liang Xiao, Jian Zhao, Jiwen Lu, Guan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03520">https://arxiv.org/abs/2405.03520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03520">https://arxiv.org/pdf/2405.03520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03520]] Is Sora a World Simulator? A Comprehensive Survey on General World  Models and Beyond(https://arxiv.org/abs/2405.03520)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>General world models represent a crucial pathway toward achieving Artificial General Intelligence (AGI), serving as the cornerstone for various applications ranging from virtual environments to decision-making systems. Recently, the emergence of the Sora model has attained significant attention due to its remarkable simulation capabilities, which exhibits an incipient comprehension of physical laws. In this survey, we embark on a comprehensive exploration of the latest advancements in world models. Our analysis navigates through the forefront of generative methodologies in video generation, where world models stand as pivotal constructs facilitating the synthesis of highly realistic visual content. Additionally, we scrutinize the burgeoning field of autonomous-driving world models, meticulously delineating their indispensable role in reshaping transportation and urban mobility. Furthermore, we delve into the intricacies inherent in world models deployed within autonomous agents, shedding light on their profound significance in enabling intelligent interactions within dynamic environmental contexts. At last, we examine challenges and limitations of world models, and discuss their potential future directions. We hope this survey can serve as a foundational reference for the research community and inspire continued innovation. This survey will be regularly updated at: https://github.com/GigaAI-research/General-World-Models-Survey.</li>
</ul>

<h3>Title: Exploring the Efficacy of Federated-Continual Learning Nodes with  Attention-Based Classifier for Robust Web Phishing Detection: An Empirical  Investigation</h3>
<ul>
<li><strong>Authors: </strong>Jesher Joshua M, Adhithya R, Sree Dananjay S, M Revathi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03537">https://arxiv.org/abs/2405.03537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03537">https://arxiv.org/pdf/2405.03537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03537]] Exploring the Efficacy of Federated-Continual Learning Nodes with  Attention-Based Classifier for Robust Web Phishing Detection: An Empirical  Investigation(https://arxiv.org/abs/2405.03537)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Web phishing poses a dynamic threat, requiring detection systems to quickly adapt to the latest tactics. Traditional approaches of accumulating data and periodically retraining models are outpaced. We propose a novel paradigm combining federated learning and continual learning, enabling distributed nodes to continually update models on streams of new phishing data, without accumulating data. These locally adapted models are then aggregated at a central server via federated learning. To enhance detection, we introduce a custom attention-based classifier model with residual connections, tailored for web phishing, leveraging attention mechanisms to capture intricate phishing patterns. We evaluate our hybrid learning paradigm across continual learning strategies (cumulative, replay, MIR, LwF) and model architectures through an empirical investigation. Our main contributions are: (1) a new hybrid federated-continual learning paradigm for robust web phishing detection, and (2) a novel attention + residual connections based model explicitly designed for this task, attaining 0.93 accuracy, 0.90 precision, 0.96 recall and 0.93 f1-score with the LwF strategy, outperforming traditional approaches in detecting emerging phishing threats while retaining past knowledge.</li>
</ul>

<h3>Title: A Formal Model of Security Controls' Capabilities and Its Applications  to Policy Refinement and Incident Management</h3>
<ul>
<li><strong>Authors: </strong>Cataldo Basile, Gabriele Gatti, Francesco Settanni</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03544">https://arxiv.org/abs/2405.03544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03544">https://arxiv.org/pdf/2405.03544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03544]] A Formal Model of Security Controls' Capabilities and Its Applications  to Policy Refinement and Incident Management(https://arxiv.org/abs/2405.03544)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>Enforcing security requirements in networked information systems relies on security controls to mitigate the risks from increasingly dangerous threats. Configuring security controls is challenging; even nowadays, administrators must perform it without adequate tool support. Hence, this process is plagued by errors that translate to insecure postures, security incidents, and a lack of promptness in answering threats. This paper presents the Security Capability Model (SCM), a formal model that abstracts the features that security controls offer for enforcing security policies, which includes an Information Model that depicts the basic concepts related to rules (i.e., conditions, actions, events) and policies (i.e., conditions' evaluation, resolution strategies, default actions), and a Data Model that covers the capabilities needed to describe different types of filtering and channel protection controls. Following state-of-the-art design patterns, the model allows for generating abstract versions of the security controls' languages and a model-driven approach for translating abstract policies into device-specific configuration settings. By validating its effectiveness in real-world scenarios, we show that SCM enables the automation of different and complex security tasks, i.e., accurate and granular security control comparison, policy refinement, and incident response. Lastly, we present opportunities for extensions and integration with other frameworks and models.</li>
</ul>

<h3>Title: CCDM: Continuous Conditional Diffusion Models for Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Xin Ding, Yongwei Wang, Kao Zhang, Z. Jane Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03546">https://arxiv.org/abs/2405.03546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03546">https://arxiv.org/pdf/2405.03546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03546]] CCDM: Continuous Conditional Diffusion Models for Image Generation(https://arxiv.org/abs/2405.03546)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Continuous Conditional Generative Modeling (CCGM) aims to estimate the distribution of high-dimensional data, typically images, conditioned on scalar continuous variables known as regression labels. While Continuous conditional Generative Adversarial Networks (CcGANs) were initially designed for this task, their adversarial training mechanism remains vulnerable to extremely sparse or imbalanced data, resulting in suboptimal outcomes. To enhance the quality of generated images, a promising alternative is to replace CcGANs with Conditional Diffusion Models (CDMs), renowned for their stable training process and ability to produce more realistic images. However, existing CDMs encounter challenges when applied to CCGM tasks due to several limitations such as inadequate U-Net architectures and deficient model fitting mechanisms for handling regression labels. In this paper, we introduce Continuous Conditional Diffusion Models (CCDMs), the first CDM designed specifically for the CCGM task. CCDMs address the limitations of existing CDMs by introducing specially designed conditional diffusion processes, a modified denoising U-Net with a custom-made conditioning mechanism, a novel hard vicinal loss for model fitting, and an efficient conditional sampling procedure. With comprehensive experiments on four datasets with varying resolutions ranging from 64x64 to 192x192, we demonstrate the superiority of the proposed CCDM over state-of-the-art CCGM models, establishing new benchmarks in CCGM. Extensive ablation studies validate the model design and implementation configuration of the proposed CCDM. Our code is publicly available at https://github.com/UBCDingXin/CCDM.</li>
</ul>

<h3>Title: Position Paper: Leveraging Foundational Models for Black-Box  Optimization: Benefits, Challenges, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Xingyou Song, Yingtao Tian, Robert Tjarko Lange, Chansoo Lee, Yujin Tang, Yutian Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03547">https://arxiv.org/abs/2405.03547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03547">https://arxiv.org/pdf/2405.03547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03547]] Position Paper: Leveraging Foundational Models for Black-Box  Optimization: Benefits, Challenges, and Future Directions(https://arxiv.org/abs/2405.03547)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Undeniably, Large Language Models (LLMs) have stirred an extraordinary wave of innovation in the machine learning research domain, resulting in substantial impact across diverse fields such as reinforcement learning, robotics, and computer vision. Their incorporation has been rapid and transformative, marking a significant paradigm shift in the field of machine learning research. However, the field of experimental design, grounded on black-box optimization, has been much less affected by such a paradigm shift, even though integrating LLMs with optimization presents a unique landscape ripe for exploration. In this position paper, we frame the field of black-box optimization around sequence-based foundation models and organize their relationship with previous literature. We discuss the most promising ways foundational language models can revolutionize optimization, which include harnessing the vast wealth of information encapsulated in free-form text to enrich task comprehension, utilizing highly flexible sequence models such as Transformers to engineer superior optimization strategies, and enhancing performance prediction over previously unseen search spaces.</li>
</ul>

<h3>Title: MAmmoTH2: Scaling Instructions from the Web</h3>
<ul>
<li><strong>Authors: </strong>Xiang Yue, Tuney Zheng, Ge Zhang, Wenhu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03548">https://arxiv.org/abs/2405.03548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03548">https://arxiv.org/pdf/2405.03548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03548]] MAmmoTH2: Scaling Instructions from the Web(https://arxiv.org/abs/2405.03548)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning improves the reasoning abilities of large language models (LLMs), with data quality and scalability being the crucial factors. Most instruction tuning data come from human crowd-sourcing or GPT-4 distillation. We propose a paradigm to efficiently harvest 10 million naturally existing instruction data from the pre-training web corpus to enhance LLM reasoning. Our approach involves (1) recalling relevant documents, (2) extracting instruction-response pairs, and (3) refining the extracted pairs using open-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2 models, which significantly boost performance on reasoning benchmarks. Notably, MAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from 36% to 67% on GSM8K without training on any in-domain data. Further training MAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus, achieving state-of-the-art performance on several reasoning and chatbot benchmarks. Our work demonstrates how to harvest large-scale, high-quality instruction data without costly human annotation or GPT-4 distillation, providing a new paradigm for building better instruction tuning data.</li>
</ul>

<h3>Title: AlphaMath Almost Zero: process Supervision without process</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03553">https://arxiv.org/abs/2405.03553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03553">https://arxiv.org/pdf/2405.03553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03553]] AlphaMath Almost Zero: process Supervision without process(https://arxiv.org/abs/2405.03553)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have substantially enhanced their mathematical reasoning abilities. However, these models still struggle with complex problems that require multiple reasoning steps, frequently leading to logical or numerical errors. While numerical mistakes can largely be addressed by integrating a code interpreter, identifying logical errors within intermediate steps is more challenging. Moreover, manually annotating these steps for training is not only expensive but also demands specialized expertise. In this study, we introduce an innovative approach that eliminates the need for manual annotation by leveraging the Monte Carlo Tree Search (MCTS) framework to generate both the process supervision and evaluation signals automatically. Essentially, when a LLM is well pre-trained, only the mathematical questions and their final answers are required to generate our training data, without requiring the solutions. We proceed to train a step-level value model designed to improve the LLM's inference process in mathematical domains. Our experiments indicate that using automatically generated solutions by LLMs enhanced with MCTS significantly improves the model's proficiency in dealing with intricate mathematical reasoning tasks.</li>
</ul>

<h3>Title: Enabling High-Sparsity Foundational Llama Models with Efficient  Pretraining and Deployment</h3>
<ul>
<li><strong>Authors: </strong>Abhinav Agarwalla, Abhay Gupta, Alexandre Marques, Shubhra Pandit, Michael Goin, Eldar Kurtic, Kevin Leong, Tuan Nguyen, Mahmoud Salem, Dan Alistarh, Sean Lie, Mark Kurtz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03594">https://arxiv.org/abs/2405.03594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03594">https://arxiv.org/pdf/2405.03594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03594]] Enabling High-Sparsity Foundational Llama Models with Efficient  Pretraining and Deployment(https://arxiv.org/abs/2405.03594)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized Natural Language Processing (NLP), but their size creates computational bottlenecks. We introduce a novel approach to create accurate, sparse foundational versions of performant LLMs that achieve full accuracy recovery for fine-tuning tasks at up to 70% sparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT one-shot pruning method and sparse pretraining of those models on a subset of the SlimPajama dataset mixed with a Python subset of The Stack dataset. We exhibit training acceleration due to sparsity on Cerebras CS-3 chips that closely matches theoretical scaling. In addition, we establish inference acceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine and 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are realized via sparsity alone, thus enabling further gains through additional use of quantization. Specifically, we show a total speedup on CPUs for sparse-quantized LLaMA models of up to 8.6x. We demonstrate these results across diverse, challenging tasks, including chat, instruction following, code generation, arithmetic reasoning, and summarization to prove their generality. This work paves the way for rapidly creating smaller and faster LLMs without sacrificing accuracy.</li>
</ul>

<h3>Title: GREEN: Generative Radiology Report Evaluation and Error Notation</h3>
<ul>
<li><strong>Authors: </strong>Sophie Ostmeier, Justin Xu, Zhihong Chen, Maya Varma, Louis Blankemeier, Christian Bluethgen, Arne Edward Michalson, Michael Moseley, Curtis Langlotz, Akshay S Chaudhari, Jean-Benoit Delbrouck</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03595">https://arxiv.org/abs/2405.03595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03595">https://arxiv.org/pdf/2405.03595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03595]] GREEN: Generative Radiology Report Evaluation and Error Notation(https://arxiv.org/abs/2405.03595)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Evaluating radiology reports is a challenging problem as factual correctness is extremely important due to the need for accurate medical communication about medical images. Existing automatic evaluation metrics either suffer from failing to consider factual correctness (e.g., BLEU and ROUGE) or are limited in their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we introduce GREEN (Generative Radiology Report Evaluation and Error Notation), a radiology report generation metric that leverages the natural language understanding of language models to identify and explain clinically significant errors in candidate reports, both quantitatively and qualitatively. Compared to current metrics, GREEN offers: 1) a score aligned with expert preferences, 2) human interpretable explanations of clinically significant errors, enabling feedback loops with end-users, and 3) a lightweight open-source method that reaches the performance of commercial counterparts. We validate our GREEN metric by comparing it to GPT-4, as well as to error counts of 6 experts and preferences of 2 experts. Our method demonstrates not only higher correlation with expert error counts, but simultaneously higher alignment with expert preferences when compared to previous approaches."</li>
</ul>

<h3>Title: Dual Relation Mining Network for Zero-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Jinwei Han, Yingguo Gao, Zhiwen Lin, Ke Yan, Shouhong Ding, Yuan Gao, Gui-Song Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03613">https://arxiv.org/abs/2405.03613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03613">https://arxiv.org/pdf/2405.03613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03613]] Dual Relation Mining Network for Zero-Shot Learning(https://arxiv.org/abs/2405.03613)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Zero-shot learning (ZSL) aims to recognize novel classes through transferring shared semantic knowledge (e.g., attributes) from seen classes to unseen classes. Recently, attention-based methods have exhibited significant progress which align visual features and attributes via a spatial attention mechanism. However, these methods only explore visual-semantic relationship in the spatial dimension, which can lead to classification ambiguity when different attributes share similar attention regions, and semantic relationship between attributes is rarely discussed. To alleviate the above problems, we propose a Dual Relation Mining Network (DRMN) to enable more effective visual-semantic interactions and learn semantic relationship among attributes for knowledge transfer. Specifically, we introduce a Dual Attention Block (DAB) for visual-semantic relationship mining, which enriches visual information by multi-level feature fusion and conducts spatial attention for visual to semantic embedding. Moreover, an attribute-guided channel attention is utilized to decouple entangled semantic features. For semantic relationship modeling, we utilize a Semantic Interaction Transformer (SIT) to enhance the generalization of attribute representations among images. Additionally, a global classification branch is introduced as a complement to human-defined semantic attributes, and we then combine the results with attribute-based classification. Extensive experiments demonstrate that the proposed DRMN leads to new state-of-the-art performances on three standard ZSL benchmarks, i.e., CUB, SUN, and AwA2.</li>
</ul>

<h3>Title: Nonnegative Matrix Factorization in Dimensionality Reduction: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Farid Saberi-Movahed, Kamal Berahman, Razieh Sheikhpour, Yuefeng Li, Shirui Pan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03615">https://arxiv.org/abs/2405.03615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03615">https://arxiv.org/pdf/2405.03615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03615]] Nonnegative Matrix Factorization in Dimensionality Reduction: A Survey(https://arxiv.org/abs/2405.03615)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Dimensionality Reduction plays a pivotal role in improving feature learning accuracy and reducing training time by eliminating redundant features, noise, and irrelevant data. Nonnegative Matrix Factorization (NMF) has emerged as a popular and powerful method for dimensionality reduction. Despite its extensive use, there remains a need for a comprehensive analysis of NMF in the context of dimensionality reduction. To address this gap, this paper presents a comprehensive survey of NMF, focusing on its applications in both feature extraction and feature selection. We introduce a classification of dimensionality reduction, enhancing understanding of the underlying concepts. Subsequently, we delve into a thorough summary of diverse NMF approaches used for feature extraction and selection. Furthermore, we discuss the latest research trends and potential future directions of NMF in dimensionality reduction, aiming to highlight areas that need further exploration and development.</li>
</ul>

<h3>Title: Detecting Android Malware: From Neural Embeddings to Hands-On Validation  with BERTroid</h3>
<ul>
<li><strong>Authors: </strong>Meryam Chaieb, Mostafa Anouar Ghorab, Mohamed Aymen Saied</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03620">https://arxiv.org/abs/2405.03620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03620">https://arxiv.org/pdf/2405.03620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03620]] Detecting Android Malware: From Neural Embeddings to Hands-On Validation  with BERTroid(https://arxiv.org/abs/2405.03620)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, transformer</a></li>
<li><strong>Abstract: </strong>As cyber threats and malware attacks increasingly alarm both individuals and businesses, the urgency for proactive malware countermeasures intensifies. This has driven a rising interest in automated machine learning solutions. Transformers, a cutting-edge category of attention-based deep learning methods, have demonstrated remarkable success. In this paper, we present BERTroid, an innovative malware detection model built on the BERT architecture. Overall, BERTroid emerged as a promising solution for combating Android malware. Its ability to outperform state-of-the-art solutions demonstrates its potential as a proactive defense mechanism against malicious software attacks. Additionally, we evaluate BERTroid on multiple datasets to assess its performance across diverse scenarios. In the dynamic landscape of cybersecurity, our approach has demonstrated promising resilience against the rapid evolution of malware on Android systems. While the machine learning model captures broad patterns, we emphasize the role of manual validation for deeper comprehension and insight into these behaviors. This human intervention is critical for discerning intricate and context-specific behaviors, thereby validating and reinforcing the model's findings.</li>
</ul>

<h3>Title: LaserEscape: Detecting and Mitigating Optical Probing Attacks</h3>
<ul>
<li><strong>Authors: </strong>Saleh Khalaj Monfared, Kyle Mitard, Andrew Cannon, Domenic Forte, Shahin Tajik</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03632">https://arxiv.org/abs/2405.03632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03632">https://arxiv.org/pdf/2405.03632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03632]] LaserEscape: Detecting and Mitigating Optical Probing Attacks(https://arxiv.org/abs/2405.03632)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, extraction</a></li>
<li><strong>Abstract: </strong>The security of integrated circuits (ICs) can be broken by sophisticated physical attacks relying on failure analysis methods. Optical probing is one of the most prominent examples of such attacks, which can be accomplished in a matter of days, even with limited knowledge of the IC under attack. Unfortunately, few countermeasures are proposed in the literature, and none has been fabricated and tested in practice. These countermeasures usually require changing the standard cell libraries and, thus, are incompatible with digital and programmable platforms, such as field programmable gate arrays (FPGAs). In this work, we shift our attention from preventing the attack to detecting and responding to it. We introduce LaserEscape, the first fully digital and FPGA-compatible countermeasure to detect and mitigate optical probing attacks. LaserEscape incorporates digital delay-based sensors to reliably detect the physical alteration on the fabric caused by laser beam irradiations in real time. Furthermore, as a response to the attack, LaserEscape deploys real-time hiding approaches using randomized hardware reconfigurability. It realizes 1) moving target defense (MTD) to physically move the sensitive circuity under attack out of the probing field of focus to protect secret keys and 2) polymorphism to logically obfuscate the functionality of the targeted circuit to counter function extraction and reverse engineering attempts. We demonstrate the effectiveness and resiliency of our approach by performing optical probing attacks on protected and unprotected designs on a 28-nm FPGA. Our results show that optical probing attacks can be reliably detected and mitigated without interrupting the chip's operation.</li>
</ul>

<h3>Title: Federated Learning Privacy: Attacks, Defenses, Applications, and Policy  Landscape - A Survey</h3>
<ul>
<li><strong>Authors: </strong>Joshua C. Zhao, Saurabh Bagchi, Salman Avestimehr, Kevin S. Chan, Somali Chaterji, Dimitris Dimitriadis, Jiacheng Li, Ninghui Li, Arash Nourian, Holger R. Roth</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03636">https://arxiv.org/abs/2405.03636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03636">https://arxiv.org/pdf/2405.03636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03636]] Federated Learning Privacy: Attacks, Defenses, Applications, and Policy  Landscape - A Survey(https://arxiv.org/abs/2405.03636)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Deep learning has shown incredible potential across a vast array of tasks and accompanying this growth has been an insatiable appetite for data. However, a large amount of data needed for enabling deep learning is stored on personal devices and recent concerns on privacy have further highlighted challenges for accessing such data. As a result, federated learning (FL) has emerged as an important privacy-preserving technology enabling collaborative training of machine learning models without the need to send the raw, potentially sensitive, data to a central server. However, the fundamental premise that sending model updates to a server is privacy-preserving only holds if the updates cannot be "reverse engineered" to infer information about the private training data. It has been shown under a wide variety of settings that this premise for privacy does {\em not} hold. In this survey paper, we provide a comprehensive literature review of the different privacy attacks and defense methods in FL. We identify the current limitations of these attacks and highlight the settings in which FL client privacy can be broken. We dissect some of the successful industry applications of FL and draw lessons for future successful adoption. We survey the emerging landscape of privacy regulation for FL. We conclude with future directions for taking FL toward the cherished goal of generating accurate models while preserving the privacy of the data from its participants.</li>
</ul>

<h3>Title: When LLMs Meet Cybersecurity: A Systematic Literature Review</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Haoyu Bu, Hui Wen, Yu Chen, Lun Li, Hongsong Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03644">https://arxiv.org/abs/2405.03644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03644">https://arxiv.org/pdf/2405.03644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03644]] When LLMs Meet Cybersecurity: A Systematic Literature Review(https://arxiv.org/abs/2405.03644)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancements in large language models (LLMs) have opened new avenues across various fields, including cybersecurity, which faces an ever-evolving threat landscape and need for innovative technologies. Despite initial explorations into the application of LLMs in cybersecurity, there is a lack of a comprehensive overview of this research area. This paper bridge this gap by providing a systematic literature review, encompassing an analysis of over 180 works, spanning across 25 LLMs and more than 10 downstream scenarios. Our comprehensive overview addresses three critical research questions: the construction of cybersecurity-oriented LLMs, LLMs' applications in various cybersecurity tasks, and the existing challenges and further research in this area. This study aims to shed light on the extensive potential of LLMs in enhancing cybersecurity practices, and serve as a valuable resource for applying LLMs in this doamin. We also maintain and regularly updated list of practical guides on LLMs for cybersecurity at https://github.com/tmylla/Awesome-LLM4Cybersecurity.</li>
</ul>

<h3>Title: Learning Robust Classifiers with Self-Guided Spurious Correlation  Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Guangtao Zheng, Wenqian Ye, Aidong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03649">https://arxiv.org/abs/2405.03649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03649">https://arxiv.org/pdf/2405.03649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03649]] Learning Robust Classifiers with Self-Guided Spurious Correlation  Mitigation(https://arxiv.org/abs/2405.03649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep neural classifiers tend to rely on spurious correlations between spurious attributes of inputs and targets to make predictions, which could jeopardize their generalization capability. Training classifiers robust to spurious correlations typically relies on annotations of spurious correlations in data, which are often expensive to get. In this paper, we tackle an annotation-free setting and propose a self-guided spurious correlation mitigation framework. Our framework automatically constructs fine-grained training labels tailored for a classifier obtained with empirical risk minimization to improve its robustness against spurious correlations. The fine-grained training labels are formulated with different prediction behaviors of the classifier identified in a novel spuriousness embedding space. We construct the space with automatically detected conceptual attributes and a novel spuriousness metric which measures how likely a class-attribute correlation is exploited for predictions. We demonstrate that training the classifier to distinguish different prediction behaviors reduces its reliance on spurious correlations without knowing them a priori and outperforms prior methods on five real-world datasets.</li>
</ul>

<h3>Title: Field-of-View Extension for Diffusion MRI via Deep Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Gao, Shunxing Bao, Michael Kim, Nancy Newlin, Praitayini Kanakaraj, Tianyuan Yao, Gaurav Rudravaram, Yuankai Huo, Daniel Moyer, Kurt Schilling, Walter Kukull, Arthur Toga, Derek Archer, Timothy Hohman, Bennett Landman, Zhiyuan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03652">https://arxiv.org/abs/2405.03652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03652">https://arxiv.org/pdf/2405.03652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03652]] Field-of-View Extension for Diffusion MRI via Deep Generative Models(https://arxiv.org/abs/2405.03652)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Purpose: In diffusion MRI (dMRI), the volumetric and bundle analyses of whole-brain tissue microstructure and connectivity can be severely impeded by an incomplete field-of-view (FOV). This work aims to develop a method for imputing the missing slices directly from existing dMRI scans with an incomplete FOV. We hypothesize that the imputed image with complete FOV can improve the whole-brain tractography for corrupted data with incomplete FOV. Therefore, our approach provides a desirable alternative to discarding the valuable dMRI data, enabling subsequent tractography analyses that would otherwise be challenging or unattainable with corrupted data. Approach: We propose a framework based on a deep generative model that estimates the absent brain regions in dMRI scans with incomplete FOV. The model is capable of learning both the diffusion characteristics in diffusion-weighted images (DWI) and the anatomical features evident in the corresponding structural images for efficiently imputing missing slices of DWI outside of incomplete FOV. Results: For evaluating the imputed slices, on the WRAP dataset the proposed framework achieved PSNRb0=22.397, SSIMb0=0.905, PSNRb1300=22.479, SSIMb1300=0.893; on the NACC dataset it achieved PSNRb0=21.304, SSIMb0=0.892, PSNRb1300=21.599, SSIMb1300= 0.877. The proposed framework improved the tractography accuracy, as demonstrated by an increased average Dice score for 72 tracts (p < 0.001) on both the WRAP and NACC datasets. Conclusions: Results suggest that the proposed framework achieved sufficient imputation performance in dMRI data with incomplete FOV for improving whole-brain tractography, thereby repairing the corrupted data. Our approach achieved more accurate whole-brain tractography results with extended and complete FOV and reduced the uncertainty when analyzing bundles associated with Alzheimer's Disease.</li>
</ul>

<h3>Title: Can LLMs Deeply Detect Complex Malicious Queries? A Framework for  Jailbreaking via Obfuscating Intent</h3>
<ul>
<li><strong>Authors: </strong>Shang Shang, Xinqiang Zhao, Zhongjiang Yao, Yepeng Yao, Liya Su, Zijing Fan, Xiaodan Zhang, Zhengwei Jiang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03654">https://arxiv.org/abs/2405.03654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03654">https://arxiv.org/pdf/2405.03654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03654]] Can LLMs Deeply Detect Complex Malicious Queries? A Framework for  Jailbreaking via Obfuscating Intent(https://arxiv.org/abs/2405.03654)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>To demonstrate and address the underlying maliciousness, we propose a theoretical hypothesis and analytical approach, and introduce a new black-box jailbreak attack methodology named IntentObfuscator, exploiting this identified flaw by obfuscating the true intentions behind user prompts.This approach compels LLMs to inadvertently generate restricted content, bypassing their built-in content security measures. We detail two implementations under this framework: "Obscure Intention" and "Create Ambiguity", which manipulate query complexity and ambiguity to evade malicious intent detection effectively. We empirically validate the effectiveness of the IntentObfuscator method across several models, including ChatGPT-3.5, ChatGPT-4, Qwen and Baichuan, achieving an average jailbreak success rate of 69.21\%. Notably, our tests on ChatGPT-3.5, which claims 100 million weekly active users, achieved a remarkable success rate of 83.65\%. We also extend our validation to diverse types of sensitive content like graphic violence, racism, sexism, political sensitivity, cybersecurity threats, and criminal skills, further proving the substantial impact of our findings on enhancing 'Red Team' strategies against LLM content security frameworks.</li>
</ul>

<h3>Title: Diffeomorphic Template Registration for Atmospheric Turbulence  Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Dong Lao, Congli Wang, Alex Wong, Stefano Soatto</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03662">https://arxiv.org/abs/2405.03662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03662">https://arxiv.org/pdf/2405.03662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03662]] Diffeomorphic Template Registration for Atmospheric Turbulence  Mitigation(https://arxiv.org/abs/2405.03662)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We describe a method for recovering the irradiance underlying a collection of images corrupted by atmospheric turbulence. Since supervised data is often technically impossible to obtain, assumptions and biases have to be imposed to solve this inverse problem, and we choose to model them explicitly. Rather than initializing a latent irradiance ("template") by heuristics to estimate deformation, we select one of the images as a reference, and model the deformation in this image by the aggregation of the optical flow from it to other images, exploiting a prior imposed by Central Limit Theorem. Then with a novel flow inversion module, the model registers each image TO the template but WITHOUT the template, avoiding artifacts related to poor template initialization. To illustrate the robustness of the method, we simply (i) select the first frame as the reference and (ii) use the simplest optical flow to estimate the warpings, yet the improvement in registration is decisive in the final reconstruction, as we achieve state-of-the-art performance despite its simplicity. The method establishes a strong baseline that can be further improved by integrating it seamlessly into more sophisticated pipelines, or with domain-specific methods if so desired.</li>
</ul>

<h3>Title: A New Robust Partial $p$-Wasserstein-Based Metric for Comparing  Distributions</h3>
<ul>
<li><strong>Authors: </strong>Sharath Raghvendra, Pouyan Shirzadian, Kaiyi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03664">https://arxiv.org/abs/2405.03664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03664">https://arxiv.org/pdf/2405.03664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03664]] A New Robust Partial $p$-Wasserstein-Based Metric for Comparing  Distributions(https://arxiv.org/abs/2405.03664)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The $2$-Wasserstein distance is sensitive to minor geometric differences between distributions, making it a very powerful dissimilarity metric. However, due to this sensitivity, a small outlier mass can also cause a significant increase in the $2$-Wasserstein distance between two similar distributions. Similarly, sampling discrepancy can cause the empirical $2$-Wasserstein distance on $n$ samples in $\mathbb{R}^2$ to converge to the true distance at a rate of $n^{-1/4}$, which is significantly slower than the rate of $n^{-1/2}$ for $1$-Wasserstein distance. We introduce a new family of distances parameterized by $k \ge 0$, called $k$-RPW, that is based on computing the partial $2$-Wasserstein distance. We show that (1) $k$-RPW satisfies the metric properties, (2) $k$-RPW is robust to small outlier mass while retaining the sensitivity of $2$-Wasserstein distance to minor geometric differences, and (3) when $k$ is a constant, $k$-RPW distance between empirical distributions on $n$ samples in $\mathbb{R}^2$ converges to the true distance at a rate of $n^{-1/3}$, which is faster than the convergence rate of $n^{-1/4}$ for the $2$-Wasserstein distance. Using the partial $p$-Wasserstein distance, we extend our distance to any $p \in [1,\infty]$. By setting parameters $k$ or $p$ appropriately, we can reduce our distance to the total variation, $p$-Wasserstein, and the L\'evy-Prokhorov distances. Experiments show that our distance function achieves higher accuracy in comparison to the $1$-Wasserstein, $2$-Wasserstein, and TV distances for image retrieval tasks on noisy real-world data sets.</li>
</ul>

<h3>Title: Cutting through buggy adversarial example defenses: fixing 1 line of  code breaks Sabre</h3>
<ul>
<li><strong>Authors: </strong>Nicholas Carlini</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03672">https://arxiv.org/abs/2405.03672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03672">https://arxiv.org/pdf/2405.03672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03672]] Cutting through buggy adversarial example defenses: fixing 1 line of  code breaks Sabre(https://arxiv.org/abs/2405.03672)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>Sabre is a defense to adversarial examples that was accepted at IEEE S&P 2024. We first reveal significant flaws in the evaluation that point to clear signs of gradient masking. We then show the cause of this gradient masking: a bug in the original evaluation code. By fixing a single line of code in the original repository, we reduce Sabre's robust accuracy to 0%. In response to this, the authors modify the defense and introduce a new defense component not described in the original paper. But this fix contains a second bug; modifying one more line of code reduces robust accuracy to below baseline levels.</li>
</ul>

<h3>Title: Why is SAM Robust to Label Noise?</h3>
<ul>
<li><strong>Authors: </strong>Christina Baek, Zico Kolter, Aditi Raghunathan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03676">https://arxiv.org/abs/2405.03676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03676">https://arxiv.org/pdf/2405.03676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03676]] Why is SAM Robust to Label Noise?(https://arxiv.org/abs/2405.03676)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sharpness-Aware Minimization (SAM) is most known for achieving state-of the-art performances on natural image and language tasks. However, its most pronounced improvements (of tens of percent) is rather in the presence of label noise. Understanding SAM's label noise robustness requires a departure from characterizing the robustness of minimas lying in "flatter" regions of the loss landscape. In particular, the peak performance under label noise occurs with early stopping, far before the loss converges. We decompose SAM's robustness into two effects: one induced by changes to the logit term and the other induced by changes to the network Jacobian. The first can be observed in linear logistic regression where SAM provably up-weights the gradient contribution from clean examples. Although this explicit up-weighting is also observable in neural networks, when we intervene and modify SAM to remove this effect, surprisingly, we see no visible degradation in performance. We infer that SAM's effect in deeper networks is instead explained entirely by the effect SAM has on the network Jacobian. We theoretically derive the implicit regularization induced by this Jacobian effect in two layer linear networks. Motivated by our analysis, we see that cheaper alternatives to SAM that explicitly induce these regularization effects largely recover the benefits in deep networks trained on real-world datasets.</li>
</ul>

<h3>Title: An Empty Room is All We Want: Automatic Defurnishing of Indoor Panoramas</h3>
<ul>
<li><strong>Authors: </strong>Mira Slavcheva, Dave Gausebeck, Kevin Chen, David Buchhofer, Azwad Sabik, Chen Ma, Sachal Dhillon, Olaf Brandt, Alan Dolhasz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03682">https://arxiv.org/abs/2405.03682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03682">https://arxiv.org/pdf/2405.03682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03682]] An Empty Room is All We Want: Automatic Defurnishing of Indoor Panoramas(https://arxiv.org/abs/2405.03682)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We propose a pipeline that leverages Stable Diffusion to improve inpainting results in the context of defurnishing -- the removal of furniture items from indoor panorama images. Specifically, we illustrate how increased context, domain-specific model fine-tuning, and improved image blending can produce high-fidelity inpaints that are geometrically plausible without needing to rely on room layout estimation. We demonstrate qualitative and quantitative improvements over other furniture removal techniques.</li>
</ul>

<h3>Title: Language-Image Models with 3D Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jang Hyun Cho, Boris Ivanovic, Yulong Cao, Edward Schmerling, Yue Wang, Xinshuo Weng, Boyi Li, Yurong You, Philipp Krähenbühl, Yan Wang, Marco Pavone</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03685">https://arxiv.org/abs/2405.03685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03685">https://arxiv.org/pdf/2405.03685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03685]] Language-Image Models with 3D Understanding(https://arxiv.org/abs/2405.03685)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) have shown incredible capabilities in a variety of 2D vision and language tasks. We extend MLLMs' perceptual capabilities to ground and reason about images in 3-dimensional space. To that end, we first develop a large-scale pre-training dataset for 2D and 3D called LV3D by combining multiple existing 2D and 3D recognition datasets under a common task formulation: as multi-turn question-answering. Next, we introduce a new MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data scaling makes a strong 3D perception capability without 3D specific architectural design or training objective. Cube-LLM exhibits intriguing properties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting to improve 3D understanding from 2D context information. (2) Cube-LLM can follow complex and diverse instructions and adapt to versatile input and output formats. (3) Cube-LLM can be visually prompted such as 2D box or a set of candidate 3D boxes from specialists. Our experiments on outdoor benchmarks demonstrate that Cube-LLM significantly outperforms existing baselines by 21.3 points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7 points on the DriveLM dataset for complex reasoning about driving scenarios, respectively. Cube-LLM also shows competitive results in general MLLM benchmarks such as refCOCO for 2D grounding with (87.0) average score, as well as visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for complex reasoning. Our project is available at https://janghyuncho.github.io/Cube-LLM.</li>
</ul>

<h3>Title: Large Language Models Reveal Information Operation Goals, Tactics, and  Narrative Frames</h3>
<ul>
<li><strong>Authors: </strong>Keith Burghardt, Kai Chen, Kristina Lerman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03688">https://arxiv.org/abs/2405.03688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03688">https://arxiv.org/pdf/2405.03688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03688]] Large Language Models Reveal Information Operation Goals, Tactics, and  Narrative Frames(https://arxiv.org/abs/2405.03688)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Adversarial information operations can destabilize societies by undermining fair elections, manipulating public opinions on policies, and promoting scams. Despite their widespread occurrence and potential impacts, our understanding of influence campaigns is limited by manual analysis of messages and subjective interpretation of their observable behavior. In this paper, we explore whether these limitations can be mitigated with large language models (LLMs), using GPT-3.5 as a case-study for coordinated campaign annotation. We first use GPT-3.5 to scrutinize 126 identified information operations spanning over a decade. We utilize a number of metrics to quantify the close (if imperfect) agreement between LLM and ground truth descriptions. We next extract coordinated campaigns from two large multilingual datasets from X (formerly Twitter) that respectively discuss the 2022 French election and 2023 Balikaran Philippine-U.S. military exercise in 2023. For each coordinated campaign, we use GPT-3.5 to analyze posts related to a specific concern and extract goals, tactics, and narrative frames, both before and after critical events (such as the date of an election). While the GPT-3.5 sometimes disagrees with subjective interpretation, its ability to summarize and interpret demonstrates LLMs' potential to extract higher-order indicators from text to provide a more complete picture of the information campaigns compared to previous methods.</li>
</ul>

<h3>Title: Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Uzair Khattak, Muhammad Ferjad Naeem, Jameel Hassan, Muzammal Naseer, Federico Tombari, Fahad Shahbaz Khan, Salman Khan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2405.03690">https://arxiv.org/abs/2405.03690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2405.03690">https://arxiv.org/pdf/2405.03690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2405.03690]] Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs(https://arxiv.org/abs/2405.03690)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have led to the development of Video Large Multi-modal Models (Video-LMMs) that can handle a wide range of video understanding tasks. These models have the potential to be deployed in real-world applications such as robotics, AI assistants, medical imaging, and autonomous vehicles. The widespread adoption of Video-LMMs in our daily lives underscores the importance of ensuring and evaluating their robust performance in mirroring human-like reasoning and interaction capabilities in complex, real-world contexts. However, existing benchmarks for Video-LMMs primarily focus on general video comprehension abilities and neglect assessing their reasoning capabilities over complex videos in the real-world context, and robustness of these models through the lens of user prompts as text queries. In this paper, we present the Complex Video Reasoning and Robustness Evaluation Suite (CVRR-ES), a novel benchmark that comprehensively assesses the performance of Video-LMMs across 11 diverse real-world video dimensions. We evaluate 9 recent models, including both open-source and closed-source variants, and find that most of the Video-LMMs, {especially open-source ones,} struggle with robustness and reasoning when dealing with complex videos. Based on our analysis, we develop a training-free Dual-Step Contextual Prompting (DSCP) technique to enhance the performance of existing Video-LMMs. Our findings provide valuable insights for building the next generation of human-centric AI systems with advanced robustness and reasoning capabilities. Our dataset and code are publicly available at: https://mbzuai-oryx.github.io/CVRR-Evaluation-Suite/.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
