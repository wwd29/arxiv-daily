<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-02-01</h1>
<h3>Title: Decentralized Federated Learning: A Survey on Security and Privacy</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif, Boyu Wang, Qiang Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17319">https://arxiv.org/abs/2401.17319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17319">https://arxiv.org/pdf/2401.17319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17319]] Decentralized Federated Learning: A Survey on Security and Privacy(https://arxiv.org/abs/2401.17319)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning has been rapidly evolving and gaining popularity in recent years due to its privacy-preserving features, among other advantages. Nevertheless, the exchange of model updates and gradients in this architecture provides new attack surfaces for malicious users of the network which may jeopardize the model performance and user and data privacy. For this reason, one of the main motivations for decentralized federated learning is to eliminate server-related threats by removing the server from the network and compensating for it through technologies such as blockchain. However, this advantage comes at the cost of challenging the system with new privacy threats. Thus, performing a thorough security analysis in this new paradigm is necessary. This survey studies possible variations of threats and adversaries in decentralized federated learning and overviews the potential defense mechanisms. Trustability and verifiability of decentralized federated learning are also considered in this study.</li>
</ul>

<h3>Title: A Latent Space Metric for Enhancing Prediction Confidence in Earth  Observation Data</h3>
<ul>
<li><strong>Authors: </strong>Ioannis Pitsiorlas, Argyro Tsantalidou, George Arvanitakis, Marios Kountouris, Charalambos Kontoes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17342">https://arxiv.org/abs/2401.17342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17342">https://arxiv.org/pdf/2401.17342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17342]] A Latent Space Metric for Enhancing Prediction Confidence in Earth  Observation Data(https://arxiv.org/abs/2401.17342)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study presents a new approach for estimating confidence in machine learning model predictions, specifically in regression tasks utilizing Earth Observation (EO) data, with a particular focus on mosquito abundance (MA) estimation. We take advantage of a Variational AutoEncoder architecture, to derive a confidence metric by the latent space representations of EO datasets. This methodology is pivotal in establishing a correlation between the Euclidean distance in latent representations and the Absolute Error (AE) in individual MA predictions. Our research focuses on EO datasets from the Veneto region in Italy and the Upper Rhine Valley in Germany, targeting areas significantly affected by mosquito populations. A key finding is a notable correlation of 0.46 between the AE of MA predictions and the proposed confidence metric. This correlation signifies a robust, new metric for quantifying the reliability and enhancing the trustworthiness of the AI model's predictions in the context of both EO data analysis and mosquito abundance studies.</li>
</ul>

<h3>Title: Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for  Classifying Arabic Speech Acts on Twitter</h3>
<ul>
<li><strong>Authors: </strong>Khadejaa Alshehri, Areej Alhothali, Nahed Alowidi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17373">https://arxiv.org/abs/2401.17373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17373">https://arxiv.org/pdf/2401.17373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17373]] Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for  Classifying Arabic Speech Acts on Twitter(https://arxiv.org/abs/2401.17373)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Speech acts are a speakers actions when performing an utterance within a conversation, such as asking, recommending, greeting, or thanking someone, expressing a thought, or making a suggestion. Understanding speech acts helps interpret the intended meaning and actions behind a speakers or writers words. This paper proposes a Twitter dialectal Arabic speech act classification approach based on a transformer deep learning neural network. Twitter and social media, are becoming more and more integrated into daily life. As a result, they have evolved into a vital source of information that represents the views and attitudes of their users. We proposed a BERT based weighted ensemble learning approach to integrate the advantages of various BERT models in dialectal Arabic speech acts classification. We compared the proposed model against several variants of Arabic BERT models and sequence-based models. We developed a dialectal Arabic tweet act dataset by annotating a subset of a large existing Arabic sentiment analysis dataset (ASAD) based on six speech act categories. We also evaluated the models on a previously developed Arabic Tweet Act dataset (ArSAS). To overcome the class imbalance issue commonly observed in speech act problems, a transformer-based data augmentation model was implemented to generate an equal proportion of speech act categories. The results show that the best BERT model is araBERTv2-Twitter models with a macro-averaged F1 score and an accuracy of 0.73 and 0.84, respectively. The performance improved using a BERT-based ensemble method with a 0.74 and 0.85 averaged F1 score and accuracy on our dataset, respectively.</li>
</ul>

<h3>Title: Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion  Tokens</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Liu, Sewon Min, Luke Zettlemoyer, Yejin Choi, Hannaneh Hajishirzi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17377">https://arxiv.org/abs/2401.17377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17377">https://arxiv.org/pdf/2401.17377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17377]] Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion  Tokens(https://arxiv.org/abs/2401.17377)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Are n-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we show their values in both text analysis and improving neural LLMs. Yet this necessitates modernizing n-gram models in two aspects. First, we train them at the same data scale as neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever built. Second, existing n-gram models use small n which hinders their performance; we instead allow n to be arbitrarily large, by introducing a new $\infty$-gram LM with backoff. Instead of pre-computing n-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\infty$-gram (as well as n-gram with arbitrary n) probabilities with millisecond-level latency. The $\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\infty$-gram LM has fairly high accuracy for next-token prediction (47%), and can complement neural LLMs to greatly reduce their language modeling perplexities. When analyzing machine-generated text, we also observe irregularities in the machine--$\infty$-gram agreement level with respect to the suffix length, which indicates deficiencies in neural LLM pretraining and the positional embeddings of Transformers. We open-source our infini-gram engine in the hopes of enabling more study on how to best use verbatim information retrieved from large text corpora.</li>
</ul>

<h3>Title: Customizing Language Model Responses with Contrastive In-Context  Learning</h3>
<ul>
<li><strong>Authors: </strong>Xiang Gao, Kamalika Das</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17390">https://arxiv.org/abs/2401.17390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17390">https://arxiv.org/pdf/2401.17390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17390]] Customizing Language Model Responses with Contrastive In-Context  Learning(https://arxiv.org/abs/2401.17390)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are becoming increasingly important for machine learning applications. However, it can be challenging to align LLMs with our intent, particularly when we want to generate content that is preferable over others or when we want the LLM to respond in a certain style or tone that is hard to describe. To address this challenge, we propose an approach that uses contrastive examples to better describe our intent. This involves providing positive examples that illustrate the true intent, along with negative examples that show what characteristics we want LLMs to avoid. The negative examples can be retrieved from labeled data, written by a human, or generated by the LLM itself. Before generating an answer, we ask the model to analyze the examples to teach itself what to avoid. This reasoning step provides the model with the appropriate articulation of the user's need and guides it towards generting a better answer. We tested our approach on both synthesized and real-world datasets, including StackExchange and Reddit, and found that it significantly improves performance compared to standard few-shot prompting</li>
</ul>

<h3>Title: Fine-tuning Transformer-based Encoder for Turkish Language Understanding  Tasks</h3>
<ul>
<li><strong>Authors: </strong>Savas Yildirim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17396">https://arxiv.org/abs/2401.17396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17396">https://arxiv.org/pdf/2401.17396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17396]] Fine-tuning Transformer-based Encoder for Turkish Language Understanding  Tasks(https://arxiv.org/abs/2401.17396)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning-based and lately Transformer-based language models have been dominating the studies of natural language processing in the last years. Thanks to their accurate and fast fine-tuning characteristics, they have outperformed traditional machine learning-based approaches and achieved state-of-the-art results for many challenging natural language understanding (NLU) problems. Recent studies showed that the Transformer-based models such as BERT, which is Bidirectional Encoder Representations from Transformers, have reached impressive achievements on many tasks. Moreover, thanks to their transfer learning capacity, these architectures allow us to transfer pre-built models and fine-tune them to specific NLU tasks such as question answering. In this study, we provide a Transformer-based model and a baseline benchmark for the Turkish Language. We successfully fine-tuned a Turkish BERT model, namely BERTurk that is trained with base settings, to many downstream tasks and evaluated with a the Turkish Benchmark dataset. We showed that our studies significantly outperformed other existing baseline approaches for Named-Entity Recognition, Sentiment Analysis, Question Answering and Text Classification in Turkish Language. We publicly released these four fine-tuned models and resources in reproducibility and with the view of supporting other Turkish researchers and applications.</li>
</ul>

<h3>Title: Through-Wall Imaging based on WiFi Channel State Information</h3>
<ul>
<li><strong>Authors: </strong>Julian Strohmayer, Rafael Sterzinger, Christian Stippel, Martin Kampel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17417">https://arxiv.org/abs/2401.17417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17417">https://arxiv.org/pdf/2401.17417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17417]] Through-Wall Imaging based on WiFi Channel State Information(https://arxiv.org/abs/2401.17417)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This work presents a seminal approach for synthesizing images from WiFi Channel State Information (CSI) in through-wall scenarios. Leveraging the strengths of WiFi, such as cost-effectiveness, illumination invariance, and wall-penetrating capabilities, our approach enables visual monitoring of indoor environments beyond room boundaries and without the need for cameras. More generally, it improves the interpretability of WiFi CSI by unlocking the option to perform image-based downstream tasks, e.g., visual activity recognition. In order to achieve this crossmodal translation from WiFi CSI to images, we rely on a multimodal Variational Autoencoder (VAE) adapted to our problem specifics. We extensively evaluate our proposed methodology through an ablation study on architecture configuration and a quantitative/qualitative assessment of reconstructed images. Our results demonstrate the viability of our method and highlight its potential for practical applications.</li>
</ul>

<h3>Title: Superiority of Multi-Head Attention in In-Context Linear Regression</h3>
<ul>
<li><strong>Authors: </strong>Yingqian Cui, Jie Ren, Pengfei He, Jiliang Tang, Yue Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17426">https://arxiv.org/abs/2401.17426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17426">https://arxiv.org/pdf/2401.17426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17426]] Superiority of Multi-Head Attention in In-Context Linear Regression(https://arxiv.org/abs/2401.17426)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a theoretical analysis of the performance of transformer with softmax attention in in-context learning with linear regression tasks. While the existing literature predominantly focuses on the convergence of transformers with single-/multi-head attention, our research centers on comparing their performance. We conduct an exact theoretical analysis to demonstrate that multi-head attention with a substantial embedding dimension performs better than single-head attention. When the number of in-context examples D increases, the prediction loss using single-/multi-head attention is in O(1/D), and the one for multi-head attention has a smaller multiplicative constant. In addition to the simplest data distribution setting, we consider more scenarios, e.g., noisy labels, local examples, correlated features, and prior knowledge. We observe that, in general, multi-head attention is preferred over single-head attention. Our results verify the effectiveness of the design of multi-head attention in the transformer architecture.</li>
</ul>

<h3>Title: Can Large Language Models Replace Economic Choice Prediction Labs?</h3>
<ul>
<li><strong>Authors: </strong>Eilam Shapira, Omer Madmon, Roi Reichart, Moshe Tennenholtz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.GT, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17435">https://arxiv.org/abs/2401.17435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17435">https://arxiv.org/pdf/2401.17435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17435]] Can Large Language Models Replace Economic Choice Prediction Labs?(https://arxiv.org/abs/2401.17435)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Economic choice prediction is an essential challenging task, often constrained by the difficulties in acquiring human choice data. Indeed, experimental economics studies had focused mostly on simple choice settings. The AI community has recently contributed to that effort in two ways: considering whether LLMs can substitute for humans in the above-mentioned simple choice prediction settings, and the study through ML lens of more elaborated but still rigorous experimental economics settings, employing incomplete information, repetitive play, and natural language communication, notably language-based persuasion games. This leaves us with a major inspiration: can LLMs be used to fully simulate the economic environment and generate data for efficient human choice prediction, substituting for the elaborated economic lab studies? We pioneer the study of this subject, demonstrating its feasibility. In particular, we show that a model trained solely on LLM-generated data can effectively predict human behavior in a language-based persuasion game, and can even outperform models trained on actual human data.</li>
</ul>

<h3>Title: A Preliminary Study on Using Large Language Models in Software  Pentesting</h3>
<ul>
<li><strong>Authors: </strong>Kumar Shashwat, Francis Hahn, Xinming Ou, Dmitry Goldgof, Lawrence Hall, Jay Ligatti, S. Raj Rajgopalan, Armin Ziaie Tabari</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17459">https://arxiv.org/abs/2401.17459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17459">https://arxiv.org/pdf/2401.17459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17459]] A Preliminary Study on Using Large Language Models in Software  Pentesting(https://arxiv.org/abs/2401.17459)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLM) are perceived to offer promising potentials for automating security tasks, such as those found in security operation centers (SOCs). As a first step towards evaluating this perceived potential, we investigate the use of LLMs in software pentesting, where the main task is to automatically identify software security vulnerabilities in source code. We hypothesize that an LLM-based AI agent can be improved over time for a specific security task as human operators interact with it. Such improvement can be made, as a first step, by engineering prompts fed to the LLM based on the responses produced, to include relevant contexts and structures so that the model provides more accurate results. Such engineering efforts become sustainable if the prompts that are engineered to produce better results on current tasks, also produce better results on future unknown tasks. To examine this hypothesis, we utilize the OWASP Benchmark Project 1.2 which contains 2,740 hand-crafted source code test cases containing various types of vulnerabilities. We divide the test cases into training and testing data, where we engineer the prompts based on the training data (only), and evaluate the final system on the testing data. We compare the AI agent's performance on the testing data against the performance of the agent without the prompt engineering. We also compare the AI agent's results against those from SonarQube, a widely used static code analyzer for security testing. We built and tested multiple versions of the AI agent using different off-the-shelf LLMs -- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with both chat completion and assistant APIs). The results show that using LLMs is a viable approach to build an AI agent for software pentesting that can improve through repeated use and prompt engineering.</li>
</ul>

<h3>Title: Rendering Wireless Environments Useful for Gradient Estimators: A  Zero-Order Stochastic Federated Learning Method</h3>
<ul>
<li><strong>Authors: </strong>Elissa Mhanna, Mohamad Assaad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.MA, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17460">https://arxiv.org/abs/2401.17460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17460">https://arxiv.org/pdf/2401.17460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17460]] Rendering Wireless Environments Useful for Gradient Estimators: A  Zero-Order Stochastic Federated Learning Method(https://arxiv.org/abs/2401.17460)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a novel approach to machine learning that allows multiple edge devices to collaboratively train a model without disclosing their raw data. However, several challenges hinder the practical implementation of this approach, especially when devices and the server communicate over wireless channels, as it suffers from communication and computation bottlenecks in this case. By utilizing a communication-efficient framework, we propose a novel zero-order (ZO) method with a one-point gradient estimator that harnesses the nature of the wireless communication channel without requiring the knowledge of the channel state coefficient. It is the first method that includes the wireless channel in the learning algorithm itself instead of wasting resources to analyze it and remove its impact. The two main difficulties of this work are that in FL, the objective function is usually not convex, which makes the extension of FL to ZO methods challenging, and that including the impact of wireless channels requires extra attention. However, we overcome these difficulties and comprehensively analyze the proposed zero-order federated learning (ZOFL) framework. We establish its convergence theoretically, and we prove a convergence rate of $O(\frac{1}{\sqrt[3]{K}})$ in the nonconvex setting. We further demonstrate the potential of our algorithm with experimental results, taking into account independent and identically distributed (IID) and non-IID device data distributions.</li>
</ul>

<h3>Title: Efficient Tool Use with Chain-of-Abstraction Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing Ellen Tan, Ramakanth Pasunuru, Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, Tianlu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17464">https://arxiv.org/abs/2401.17464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17464">https://arxiv.org/pdf/2401.17464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17464]] Efficient Tool Use with Chain-of-Abstraction Reasoning(https://arxiv.org/abs/2401.17464)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning. In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding and calling of external tools in parallel, which avoids the inference delay caused by waiting for tool responses. In mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average ~6% absolute QA accuracy improvement. LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs.</li>
</ul>

<h3>Title: Detecting mental disorder on social media: a ChatGPT-augmented  explainable approach</h3>
<ul>
<li><strong>Authors: </strong>Loris Belcastro, Riccardo Cantini, Fabrizio Marozzo, Domenico Talia, Paolo Trunfio</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17477">https://arxiv.org/abs/2401.17477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17477">https://arxiv.org/pdf/2401.17477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17477]] Detecting mental disorder on social media: a ChatGPT-augmented  explainable approach(https://arxiv.org/abs/2401.17477)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>In the digital era, the prevalence of depressive symptoms expressed on social media has raised serious concerns, necessitating advanced methodologies for timely detection. This paper addresses the challenge of interpretable depression detection by proposing a novel methodology that effectively combines Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and conversational agents like ChatGPT. In our methodology, explanations are achieved by integrating BERTweet, a Twitter-specific variant of BERT, into a novel self-explanatory model, namely BERT-XDD, capable of providing both classification and explanations via masked attention. The interpretability is further enhanced using ChatGPT to transform technical explanations into human-readable commentaries. By introducing an effective and modular approach for interpretable depression detection, our methodology can contribute to the development of socially responsible digital platforms, fostering early intervention and support for mental health challenges under the guidance of qualified healthcare professionals.</li>
</ul>

<h3>Title: Towards Visual Syntactical Understanding</h3>
<ul>
<li><strong>Authors: </strong>Sayeed Shafayet Chowdhury, Soumyadeep Chandra, Kaushik Roy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17497">https://arxiv.org/abs/2401.17497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17497">https://arxiv.org/pdf/2401.17497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17497]] Towards Visual Syntactical Understanding(https://arxiv.org/abs/2401.17497)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Syntax is usually studied in the realm of linguistics and refers to the arrangement of words in a sentence. Similarly, an image can be considered as a visual 'sentence', with the semantic parts of the image acting as 'words'. While visual syntactic understanding occurs naturally to humans, it is interesting to explore whether deep neural networks (DNNs) are equipped with such reasoning. To that end, we alter the syntax of natural images (e.g. swapping the eye and nose of a face), referred to as 'incorrect' images, to investigate the sensitivity of DNNs to such syntactic anomaly. Through our experiments, we discover an intriguing property of DNNs where we observe that state-of-the-art convolutional neural networks, as well as vision transformers, fail to discriminate between syntactically correct and incorrect images when trained on only correct ones. To counter this issue and enable visual syntactic understanding with DNNs, we propose a three-stage framework- (i) the 'words' (or the sub-features) in the image are detected, (ii) the detected words are sequentially masked and reconstructed using an autoencoder, (iii) the original and reconstructed parts are compared at each location to determine syntactic correctness. The reconstruction module is trained with BERT-like masked autoencoding for images, with the motivation to leverage language model inspired training to better capture the syntax. Note, our proposed approach is unsupervised in the sense that the incorrect images are only used during testing and the correct versus incorrect labels are never used for training. We perform experiments on CelebA, and AFHQ datasets and obtain classification accuracy of 92.10%, and 90.89%, respectively. Notably, the approach generalizes well to ImageNet samples which share common classes with CelebA and AFHQ without explicitly training on them.</li>
</ul>

<h3>Title: AdvGPS: Adversarial GPS for Multi-Agent Perception Attack</h3>
<ul>
<li><strong>Authors: </strong>Jinlong Li, Baolu Li, Xinyu Liu, Jianwu Fang, Felix Juefei-Xu, Qing Guo, Hongkai Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17499">https://arxiv.org/abs/2401.17499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17499">https://arxiv.org/pdf/2401.17499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17499]] AdvGPS: Adversarial GPS for Multi-Agent Perception Attack(https://arxiv.org/abs/2401.17499)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>The multi-agent perception system collects visual data from sensors located on various agents and leverages their relative poses determined by GPS signals to effectively fuse information, mitigating the limitations of single-agent sensing, such as occlusion. However, the precision of GPS signals can be influenced by a range of factors, including wireless transmission and obstructions like buildings. Given the pivotal role of GPS signals in perception fusion and the potential for various interference, it becomes imperative to investigate whether specific GPS signals can easily mislead the multi-agent perception system. To address this concern, we frame the task as an adversarial attack challenge and introduce \textsc{AdvGPS}, a method capable of generating adversarial GPS signals which are also stealthy for individual agents within the system, significantly reducing object detection accuracy. To enhance the success rates of these attacks in a black-box scenario, we introduce three types of statistically sensitive natural discrepancies: appearance-based discrepancy, distribution-based discrepancy, and task-aware discrepancy. Our extensive experiments on the OPV2V dataset demonstrate that these attacks substantially undermine the performance of state-of-the-art methods, showcasing remarkable transferability across different point cloud based 3D detection systems. This alarming revelation underscores the pressing need to address security implications within multi-agent perception systems, thereby underscoring a critical area of research.</li>
</ul>

<h3>Title: Arrows of Time for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Vassilis Papadopoulos, Jérémie Wenger, Clément Hongler</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17505">https://arxiv.org/abs/2401.17505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17505">https://arxiv.org/pdf/2401.17505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17505]] Arrows of Time for Large Language Models(https://arxiv.org/abs/2401.17505)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the probabilistic modeling performed by Autoregressive Large Language Models through the angle of time directionality. We empirically find a time asymmetry exhibited by such models in their ability to model natural language: a difference in the average log-perplexity when trying to predict the next token versus when trying to predict the previous one. This difference is at the same time subtle and very consistent across various modalities (language, model size, training time, ...). Theoretically, this is surprising: from an information-theoretic point of view, there should be no such difference. We provide a theoretical framework to explain how such an asymmetry can appear from sparsity and computational complexity considerations, and outline a number of perspectives opened by our results.</li>
</ul>

<h3>Title: Towards Image Semantics and Syntax Sequence Learning</h3>
<ul>
<li><strong>Authors: </strong>Chun Tao, Timur Ibrayev, Kaushik Roy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17515">https://arxiv.org/abs/2401.17515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17515">https://arxiv.org/pdf/2401.17515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17515]] Towards Image Semantics and Syntax Sequence Learning(https://arxiv.org/abs/2401.17515)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks and vision transformers have achieved outstanding performance in machine perception, particularly for image classification. Although these image classifiers excel at predicting image-level class labels, they may not discriminate missing or shifted parts within an object. As a result, they may fail to detect corrupted images that involve missing or disarrayed semantic information in the object composition. On the contrary, human perception easily distinguishes such corruptions. To mitigate this gap, we introduce the concept of "image grammar", consisting of "image semantics" and "image syntax", to denote the semantics of parts or patches of an image and the order in which these parts are arranged to create a meaningful object. To learn the image grammar relative to a class of visual objects/scenes, we propose a weakly supervised two-stage approach. In the first stage, we use a deep clustering framework that relies on iterative clustering and feature refinement to produce part-semantic segmentation. In the second stage, we incorporate a recurrent bi-LSTM module to process a sequence of semantic segmentation patches to capture the image syntax. Our framework is trained to reason over patch semantics and detect faulty syntax. We benchmark the performance of several grammar learning models in detecting patch corruptions. Finally, we verify the capabilities of our framework in Celeb and SUNRGBD datasets and demonstrate that it can achieve a grammar validation accuracy of 70 to 90% in a wide variety of semantic and syntactical corruption scenarios.</li>
</ul>

<h3>Title: Game-Theoretic Unlearnable Example Generator</h3>
<ul>
<li><strong>Authors: </strong>Shuang Liu, Yihan Wang, Xiao-Shan Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17523">https://arxiv.org/abs/2401.17523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17523">https://arxiv.org/pdf/2401.17523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17523]] Game-Theoretic Unlearnable Example Generator(https://arxiv.org/abs/2401.17523)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, generative</a></li>
<li><strong>Abstract: </strong>Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem. However, directly solving this optimization problem is intractable for deep neural networks. In this paper, we investigate unlearnable example attacks from a game-theoretic perspective, by formulating the attack as a nonzero sum Stackelberg game. First, the existence of game equilibria is proved under the normal setting and the adversarial training setting. It is shown that the game equilibrium gives the most powerful poison attack in that the victim has the lowest test accuracy among all networks within the same hypothesis space, when certain loss functions are used. Second, we propose a novel attack method, called the Game Unlearnable Example (GUE), which has three main gradients. (1) The poisons are obtained by directly solving the equilibrium of the Stackelberg game with a first-order algorithm. (2) We employ an autoencoder-like generative network model as the poison attacker. (3) A novel payoff function is introduced to evaluate the performance of the poison. Comprehensive experiments demonstrate that GUE can effectively poison the model in various scenarios. Furthermore, the GUE still works by using a relatively small percentage of the training data to train the generator, and the poison generator can generalize to unseen data well. Our implementation code can be found at https://github.com/hong-xian/gue.</li>
</ul>

<h3>Title: Enhancing Score-Based Sampling Methods with Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Tobias Bischoff, Bryan Riel</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17539">https://arxiv.org/abs/2401.17539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17539">https://arxiv.org/pdf/2401.17539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17539]] Enhancing Score-Based Sampling Methods with Ensembles(https://arxiv.org/abs/2401.17539)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce ensembles within score-based sampling methods to develop gradient-free approximate sampling techniques that leverage the collective dynamics of particle ensembles to compute approximate reverse diffusion drifts. We introduce the underlying methodology, emphasizing its relationship with generative diffusion models and the previously introduced F\"ollmer sampler. We demonstrate the efficacy of ensemble strategies through various examples, ranging from low- to medium-dimensionality sampling problems, including multi-modal and highly non-Gaussian probability distributions, and provide comparisons to traditional methods like NUTS. Our findings highlight the potential of ensemble strategies for modeling complex probability distributions in situations where gradients are unavailable. Finally, we showcase its application in the context of Bayesian inversion problems within the geophysical sciences.</li>
</ul>

<h3>Title: Towards Understanding Variants of Invariant Risk Minimization through  the Lens of Calibration</h3>
<ul>
<li><strong>Authors: </strong>Kotaro Yoshida, Hiroki Naganuma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17541">https://arxiv.org/abs/2401.17541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17541">https://arxiv.org/pdf/2401.17541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17541]] Towards Understanding Variants of Invariant Risk Minimization through  the Lens of Calibration(https://arxiv.org/abs/2401.17541)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning models traditionally assume that training and test data are independently and identically distributed. However, in real-world applications, the test distribution often differs from training. This problem, known as out-of-distribution generalization, challenges conventional models. Invariant Risk Minimization (IRM) emerges as a solution, aiming to identify features invariant across different environments to enhance out-of-distribution robustness. However, IRM's complexity, particularly its bi-level optimization, has led to the development of various approximate methods. Our study investigates these approximate IRM techniques, employing the Expected Calibration Error (ECE) as a key metric. ECE, which measures the reliability of model prediction, serves as an indicator of whether models effectively capture environment-invariant features. Through a comparative analysis of datasets with distributional shifts, we observe that Information Bottleneck-based IRM, which condenses representational information, achieves a balance in improving ECE while preserving accuracy relatively. This finding is pivotal, as it demonstrates a feasible path to maintaining robustness without compromising accuracy. Nonetheless, our experiments also caution against over-regularization, which can diminish accuracy. This underscores the necessity for a systematic approach in evaluating out-of-distribution generalization metrics, one that beyond mere accuracy to address the nuanced interplay between accuracy and calibration.</li>
</ul>

<h3>Title: Effective Multi-Stage Training Model For Edge Computing Devices In  Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Thua Huynh Trong, Thanh Nguyen Hoang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17546">https://arxiv.org/abs/2401.17546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17546">https://arxiv.org/pdf/2401.17546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17546]] Effective Multi-Stage Training Model For Edge Computing Devices In  Intrusion Detection(https://arxiv.org/abs/2401.17546)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Intrusion detection poses a significant challenge within expansive and persistently interconnected environments. As malicious code continues to advance and sophisticated attack methodologies proliferate, various advanced deep learning-based detection approaches have been proposed. Nevertheless, the complexity and accuracy of intrusion detection models still need further enhancement to render them more adaptable to diverse system categories, particularly within resource-constrained devices, such as those embedded in edge computing systems. This research introduces a three-stage training paradigm, augmented by an enhanced pruning methodology and model compression techniques. The objective is to elevate the system's effectiveness, concurrently maintaining a high level of accuracy for intrusion detection. Empirical assessments conducted on the UNSW-NB15 dataset evince that this solution notably reduces the model's dimensions, while upholding accuracy levels equivalent to similar proposals.</li>
</ul>

<h3>Title: Task-Oriented Diffusion Model Compression</h3>
<ul>
<li><strong>Authors: </strong>Geonung Kim, Beomsu Kim, Eunhyeok Park, Sunghyun Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17547">https://arxiv.org/abs/2401.17547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17547">https://arxiv.org/pdf/2401.17547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17547]] Task-Oriented Diffusion Model Compression(https://arxiv.org/abs/2401.17547)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>As recent advancements in large-scale Text-to-Image (T2I) diffusion models have yielded remarkable high-quality image generation, diverse downstream Image-to-Image (I2I) applications have emerged. Despite the impressive results achieved by these I2I models, their practical utility is hampered by their large model size and the computational burden of the iterative denoising process. In this paper, we explore the compression potential of these I2I models in a task-oriented manner and introduce a novel method for reducing both model size and the number of timesteps. Through extensive experiments, we observe key insights and use our empirical knowledge to develop practical solutions that aim for near-optimal results with minimal exploration costs. We validate the effectiveness of our method by applying it to InstructPix2Pix for image editing and StableSR for image restoration. Our approach achieves satisfactory output quality with 39.2% and 56.4% reduction in model footprint and 81.4% and 68.7% decrease in latency to InstructPix2Pix and StableSR, respectively.</li>
</ul>

<h3>Title: opML: Optimistic Machine Learning on Blockchain</h3>
<ul>
<li><strong>Authors: </strong>KD Conway, Cathie So, Xiaohang Yu, Kartin Wong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17555">https://arxiv.org/abs/2401.17555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17555">https://arxiv.org/pdf/2401.17555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17555]] opML: Optimistic Machine Learning on Blockchain(https://arxiv.org/abs/2401.17555)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>The integration of machine learning with blockchain technology has witnessed increasing interest, driven by the vision of decentralized, secure, and transparent AI services. In this context, we introduce opML (Optimistic Machine Learning on chain), an innovative approach that empowers blockchain systems to conduct AI model inference. opML lies a interactive fraud proof protocol, reminiscent of the optimistic rollup systems. This mechanism ensures decentralized and verifiable consensus for ML services, enhancing trust and transparency. Unlike zkML (Zero-Knowledge Machine Learning), opML offers cost-efficient and highly efficient ML services, with minimal participation requirements. Remarkably, opML enables the execution of extensive language models, such as 7B-LLaMA, on standard PCs without GPUs, significantly expanding accessibility.By combining the capabilities of blockchain and AI through opML, we embark on a transformative journey toward accessible, secure, and efficient on-chain machine learning.</li>
</ul>

<h3>Title: Scavenging Hyena: Distilling Transformers into Long Convolution Models</h3>
<ul>
<li><strong>Authors: </strong>Tokiniaina Raharison Ralambomihanta, Shahrad Mohammadzadeh, Mohammad Sami Nur Islam, Wassim Jabbour, Laurence Liang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17574">https://arxiv.org/abs/2401.17574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17574">https://arxiv.org/pdf/2401.17574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17574]] Scavenging Hyena: Distilling Transformers into Long Convolution Models(https://arxiv.org/abs/2401.17574)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The rapid evolution of Large Language Models (LLMs), epitomized by architectures like GPT-4, has reshaped the landscape of natural language processing. This paper introduces a pioneering approach to address the efficiency concerns associated with LLM pre-training, proposing the use of knowledge distillation for cross-architecture transfer. Leveraging insights from the efficient Hyena mechanism, our method replaces attention heads in transformer models by Hyena, offering a cost-effective alternative to traditional pre-training while confronting the challenge of processing long contextual information, inherent in quadratic attention mechanisms. Unlike conventional compression-focused methods, our technique not only enhances inference speed but also surpasses pre-training in terms of both accuracy and efficiency. In the era of evolving LLMs, our work contributes to the pursuit of sustainable AI solutions, striking a balance between computational power and environmental impact.</li>
</ul>

<h3>Title: Local and Global Contexts for Conversation</h3>
<ul>
<li><strong>Authors: </strong>Zuoquan Lin, Xinyi Shen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17588">https://arxiv.org/abs/2401.17588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17588">https://arxiv.org/pdf/2401.17588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17588]] Local and Global Contexts for Conversation(https://arxiv.org/abs/2401.17588)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The context in conversation is the dialog history crucial for multi-turn dialogue. Learning from the relevant contexts in dialog history for grounded conversation is a challenging problem. Local context is the most neighbor and more sensitive to the subsequent response, and global context is relevant to a whole conversation far beyond neighboring utterances. Currently, pretrained transformer models for conversation challenge capturing the correlation and connection between local and global contexts. We introduce a local and global conversation model (LGCM) for general-purpose conversation in open domain. It is a local-global hierarchical transformer model that excels at accurately discerning and assimilating the relevant contexts necessary for generating responses. It employs a local encoder to grasp the local context at the level of individual utterances and a global encoder to understand the broader context at the dialogue level. The seamless fusion of these locally and globally contextualized encodings ensures a comprehensive comprehension of the conversation. Experiments on popular datasets show that LGCM outperforms the existing conversation models on the performance of automatic metrics with significant margins.</li>
</ul>

<h3>Title: Local Feature Matching Using Deep Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Shibiao Xu, Shunpeng Chen, Rongtao Xu, Changwei Wang, Peng Lu, Li Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17592">https://arxiv.org/abs/2401.17592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17592">https://arxiv.org/pdf/2401.17592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17592]] Local Feature Matching Using Deep Learning: A Survey(https://arxiv.org/abs/2401.17592)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Local feature matching enjoys wide-ranging applications in the realm of computer vision, encompassing domains such as image retrieval, 3D reconstruction, and object recognition. However, challenges persist in improving the accuracy and robustness of matching due to factors like viewpoint and lighting variations. In recent years, the introduction of deep learning models has sparked widespread exploration into local feature matching techniques. The objective of this endeavor is to furnish a comprehensive overview of local feature matching methods. These methods are categorized into two key segments based on the presence of detectors. The Detector-based category encompasses models inclusive of Detect-then-Describe, Joint Detection and Description, Describe-then-Detect, as well as Graph Based techniques. In contrast, the Detector-free category comprises CNN Based, Transformer Based, and Patch Based methods. Our study extends beyond methodological analysis, incorporating evaluations of prevalent datasets and metrics to facilitate a quantitative comparison of state-of-the-art techniques. The paper also explores the practical application of local feature matching in diverse domains such as Structure from Motion, Remote Sensing Image Registration, and Medical Image Registration, underscoring its versatility and significance across various fields. Ultimately, we endeavor to outline the current challenges faced in this domain and furnish future research directions, thereby serving as a reference for researchers involved in local feature matching and its interconnected domains.</li>
</ul>

<h3>Title: SPECTRUM: Speaker-Enhanced Pre-Training for Long Dialogue Summarization</h3>
<ul>
<li><strong>Authors: </strong>Sangwoo Cho, Kaiqiang Song, Chao Zhao, Xiaoyang Wang, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17597">https://arxiv.org/abs/2401.17597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17597">https://arxiv.org/pdf/2401.17597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17597]] SPECTRUM: Speaker-Enhanced Pre-Training for Long Dialogue Summarization(https://arxiv.org/abs/2401.17597)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-turn dialogues are characterized by their extended length and the presence of turn-taking conversations. Traditional language models often overlook the distinct features of these dialogues by treating them as regular text. In this paper, we propose a speaker-enhanced pre-training method for long dialogue summarization, which leverages the inherent structure of multiple-turn dialogues. To support our study, we curate a diverse dataset that includes transcripts from real-world scenarios, movie or TV show transcripts, and dialogues generated by a Large Language Model. We then perform a pre-training, which encompasses the detection of speaker changes, and masked utterance generation. Experimental results of fine-tuned models demonstrate that our model achieves state-of-the-art performance on downstream benchmarks with long context, surpassing baseline models and highlighting the effectiveness of our approach. Our findings highlight the importance of curating pre-training datasets that exhibit diversity and variations in length distribution to ensure effective alignment with downstream datasets.</li>
</ul>

<h3>Title: Assertion Detection Large Language Model In-context Learning LoRA  Fine-tuning</h3>
<ul>
<li><strong>Authors: </strong>Yuelyu Ji, Zeshui Yu, Yanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17602">https://arxiv.org/abs/2401.17602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17602">https://arxiv.org/pdf/2401.17602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17602]] Assertion Detection Large Language Model In-context Learning LoRA  Fine-tuning(https://arxiv.org/abs/2401.17602)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>In this study, we aim to address the task of assertion detection when extracting medical concepts from clinical notes, a key process in clinical natural language processing (NLP). Assertion detection in clinical NLP usually involves identifying assertion types for medical concepts in the clinical text, namely certainty (whether the medical concept is positive, negated, possible, or hypothetical), temporality (whether the medical concept is for present or the past history), and experiencer (whether the medical concept is described for the patient or a family member). These assertion types are essential for healthcare professionals to quickly and clearly understand the context of medical conditions from unstructured clinical texts, directly influencing the quality and outcomes of patient care. Although widely used, traditional methods, particularly rule-based NLP systems and machine learning or deep learning models, demand intensive manual efforts to create patterns and tend to overlook less common assertion types, leading to an incomplete understanding of the context. To address this challenge, our research introduces a novel methodology that utilizes Large Language Models (LLMs) pre-trained on a vast array of medical data for assertion detection. We enhanced the current method with advanced reasoning techniques, including Tree of Thought (ToT), Chain of Thought (CoT), and Self-Consistency (SC), and refine it further with Low-Rank Adaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010 assertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11 improvements over the previous works. To further assess the generalizability of our approach, we extended our evaluation to a local dataset that focused on sleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31 higher than the previous method.</li>
</ul>

<h3>Title: Topology-Aware Latent Diffusion for 3D Shape Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiangbei Hu, Ben Fei, Baixin Xu, Fei Hou, Weidong Yang, Shengfa Wang, Na Lei, Chen Qian, Ying He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17603">https://arxiv.org/abs/2401.17603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17603">https://arxiv.org/pdf/2401.17603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17603]] Topology-Aware Latent Diffusion for 3D Shape Generation(https://arxiv.org/abs/2401.17603)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We introduce a new generative model that combines latent diffusion with persistent homology to create 3D shapes with high diversity, with a special emphasis on their topological characteristics. Our method involves representing 3D shapes as implicit fields, then employing persistent homology to extract topological features, including Betti numbers and persistence diagrams. The shape generation process consists of two steps. Initially, we employ a transformer-based autoencoding module to embed the implicit representation of each 3D shape into a set of latent vectors. Subsequently, we navigate through the learned latent space via a diffusion model. By strategically incorporating topological features into the diffusion process, our generative module is able to produce a richer variety of 3D shapes with different topological structures. Furthermore, our framework is flexible, supporting generation tasks constrained by a variety of inputs, including sparse and partial point clouds, as well as sketches. By modifying the persistence diagrams, we can alter the topology of the shapes generated from these input modalities.</li>
</ul>

<h3>Title: Computation and Parameter Efficient Multi-Modal Fusion Transformer for  Cued Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Lei Liu, Li Liu, Haizhou Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17604">https://arxiv.org/abs/2401.17604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17604">https://arxiv.org/pdf/2401.17604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17604]] Computation and Parameter Efficient Multi-Modal Fusion Transformer for  Cued Speech Recognition(https://arxiv.org/abs/2401.17604)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Cued Speech (CS) is a pure visual coding method used by hearing-impaired people that combines lip reading with several specific hand shapes to make the spoken language visible. Automatic CS recognition (ACSR) seeks to transcribe visual cues of speech into text, which can help hearing-impaired people to communicate effectively. The visual information of CS contains lip reading and hand cueing, thus the fusion of them plays an important role in ACSR. However, most previous fusion methods struggle to capture the global dependency present in long sequence inputs of multi-modal CS data. As a result, these methods generally fail to learn the effective cross-modal relationships that contribute to the fusion. Recently, attention-based transformers have been a prevalent idea for capturing the global dependency over the long sequence in multi-modal fusion, but existing multi-modal fusion transformers suffer from both poor recognition accuracy and inefficient computation for the ACSR task. To address these problems, we develop a novel computation and parameter efficient multi-modal fusion transformer by proposing a novel Token-Importance-Aware Attention mechanism (TIAA), where a token utilization rate (TUR) is formulated to select the important tokens from the multi-modal streams. More precisely, TIAA firstly models the modality-specific fine-grained temporal dependencies over all tokens of each modality, and then learns the efficient cross-modal interaction for the modality-shared coarse-grained temporal dependencies over the important tokens of different modalities. Besides, a light-weight gated hidden projection is designed to control the feature flows of TIAA. The resulting model, named Economical Cued Speech Fusion Transformer (EcoCued), achieves state-of-the-art performance on all existing CS datasets, compared with existing transformer-based fusion methods and ACSR fusion methods.</li>
</ul>

<h3>Title: Ambush from All Sides: Understanding Security Threats in Open-Source  Software CI/CD Pipelines</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Pan, Wenbo Shen, Xingkai Wang, Yutian Yang, Rui Chang, Yao Liu, Chengwei Liu, Yang Liu, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17606">https://arxiv.org/abs/2401.17606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17606">https://arxiv.org/pdf/2401.17606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17606]] Ambush from All Sides: Understanding Security Threats in Open-Source  Software CI/CD Pipelines(https://arxiv.org/abs/2401.17606)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The continuous integration and continuous deployment (CI/CD) pipelines are widely adopted on Internet hosting platforms, such as GitHub. With the popularity, the CI/CD pipeline faces various security threats. However, current CI/CD pipelines suffer from malicious code and severe vulnerabilities. Even worse, people have not been fully aware of its attack surfaces and the corresponding impacts. Therefore, in this paper, we conduct a large-scale measurement and a systematic analysis to reveal the attack surfaces of the CI/CD pipeline and quantify their security impacts. Specifically, for the measurement, we collect a data set of 320,000+ CI/CD pipeline-configured GitHub repositories and build an analysis tool to parse the CI/CD pipelines and extract security-critical usages. Besides, current CI/CD ecosystem heavily relies on several core scripts, which may lead to a single point of failure. While the CI/CD pipelines contain sensitive information/operations, making them the attacker's favorite targets. Inspired by the measurement findings, we abstract the threat model and the attack approach toward CI/CD pipelines, followed by a systematic analysis of attack surfaces, attack strategies, and the corresponding impacts. We further launch case studies on five attacks in real-world CI/CD environments to validate the revealed attack surfaces. Finally, we give suggestions on mitigating attacks on CI/CD scripts, including securing CI/CD configurations, securing CI/CD scripts, and improving CI/CD infrastructure.</li>
</ul>

<h3>Title: LaneGraph2Seq: Lane Topology Extraction with Language Model via  Vertex-Edge Encoding and Connectivity Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Renyuan Peng, Xinyue Cai, Hang Xu, Jiachen Lu, Feng Wen, Wei Zhang, Li Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17609">https://arxiv.org/abs/2401.17609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17609">https://arxiv.org/pdf/2401.17609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17609]] LaneGraph2Seq: Lane Topology Extraction with Language Model via  Vertex-Edge Encoding and Connectivity Enhancement(https://arxiv.org/abs/2401.17609)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Understanding road structures is crucial for autonomous driving. Intricate road structures are often depicted using lane graphs, which include centerline curves and connections forming a Directed Acyclic Graph (DAG). Accurate extraction of lane graphs relies on precisely estimating vertex and edge information within the DAG. Recent research highlights Transformer-based language models' impressive sequence prediction abilities, making them effective for learning graph representations when graph data are encoded as sequences. However, existing studies focus mainly on modeling vertices explicitly, leaving edge information simply embedded in the network. Consequently, these approaches fall short in the task of lane graph extraction. To address this, we introduce LaneGraph2Seq, a novel approach for lane graph extraction. It leverages a language model with vertex-edge encoding and connectivity enhancement. Our serialization strategy includes a vertex-centric depth-first traversal and a concise edge-based partition sequence. Additionally, we use classifier-free guidance combined with nucleus sampling to improve lane connectivity. We validate our method on prominent datasets, nuScenes and Argoverse 2, showcasing consistent and compelling results. Our LaneGraph2Seq approach demonstrates superior performance compared to state-of-the-art techniques in lane graph extraction.</li>
</ul>

<h3>Title: IGCN: Integrative Graph Convolutional Networks for Multi-modal Data</h3>
<ul>
<li><strong>Authors: </strong>Cagri Ozdemir, Mohammad Al Olaimat, Yashu Vashishath, Serdar Bozdag, Alzheimer's Disease Neuroimaging Initiative</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17612">https://arxiv.org/abs/2401.17612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17612">https://arxiv.org/pdf/2401.17612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17612]] IGCN: Integrative Graph Convolutional Networks for Multi-modal Data(https://arxiv.org/abs/2401.17612)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Recent advances in Graph Neural Networks (GNN) have led to a considerable growth in graph data modeling for multi-modal data which contains various types of nodes and edges. Although some integrative prediction solutions have been developed recently for network-structured data, these methods have some restrictions. For a node classification task involving multi-modal data, certain data modalities may perform better when predicting one class, while others might excel in predicting a different class. Thus, to obtain a better learning representation, advanced computational methodologies are required for the integrative analysis of multi-modal data. Moreover, existing integrative tools lack a comprehensive and cohesive understanding of the rationale behind their specific predictions, making them unsuitable for enhancing model interpretability. Addressing these restrictions, we introduce a novel integrative neural network approach for multi-modal data networks, named Integrative Graph Convolutional Networks (IGCN). IGCN learns node embeddings from multiple topologies and fuses the multiple node embeddings into a weighted form by assigning attention coefficients to the node embeddings. Our proposed attention mechanism helps identify which types of data receive more emphasis for each sample to predict a certain class. Therefore, IGCN has the potential to unravel previously unknown characteristics within different node classification tasks. We benchmarked IGCN on several datasets from different domains, including a multi-omics dataset to predict cancer subtypes and a multi-modal clinical dataset to predict the progression of Alzheimer's disease. Experimental results show that IGCN outperforms or is on par with the state-of-the-art and baseline methods.</li>
</ul>

<h3>Title: Beyond Control: Exploring Novel File System Objects for Data-Only  Attacks on Linux Systems</h3>
<ul>
<li><strong>Authors: </strong>Jinmeng Zhou, Jiayi Hu, Ziyue Pan, Jiaxun Zhu, Guoren Li, Wenbo Shen, Yulei Sui, Zhiyun Qian</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17618">https://arxiv.org/abs/2401.17618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17618">https://arxiv.org/pdf/2401.17618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17618]] Beyond Control: Exploring Novel File System Objects for Data-Only  Attacks on Linux Systems(https://arxiv.org/abs/2401.17618)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>The widespread deployment of control-flow integrity has propelled non-control data attacks into the mainstream. In the domain of OS kernel exploits, by corrupting critical non-control data, local attackers can directly gain root access or privilege escalation without hijacking the control flow. As a result, OS kernels have been restricting the availability of such non-control data. This forces attackers to continue to search for more exploitable non-control data in OS kernels. However, discovering unknown non-control data can be daunting because they are often tied heavily to semantics and lack universal patterns. We make two contributions in this paper: (1) discover critical non-control objects in the file subsystem and (2) analyze their exploitability. This work represents the first study, with minimal domain knowledge, to semi-automatically discover and evaluate exploitable non-control data within the file subsystem of the Linux kernel. Our solution utilizes a custom analysis and testing framework that statically and dynamically identifies promising candidate objects. Furthermore, we categorize these discovered objects into types that are suitable for various exploit strategies, including a novel strategy necessary to overcome the defense that isolates many of these objects. These objects have the advantage of being exploitable without requiring KASLR, thus making the exploits simpler and more reliable. We use 18 real-world CVEs to evaluate the exploitability of the file system objects using various exploit strategies. We develop 10 end-to-end exploits using a subset of CVEs against the kernel with all state-of-the-art mitigations enabled.</li>
</ul>

<h3>Title: Neighboring Perturbations of Knowledge Editing on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jun-Yu Ma, Jia-Chen Gu, Ningyu Zhang, Zhen-Hua Ling</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17623">https://arxiv.org/abs/2401.17623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17623">https://arxiv.org/pdf/2401.17623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17623]] Neighboring Perturbations of Knowledge Editing on Large Language Models(https://arxiv.org/abs/2401.17623)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite their exceptional capabilities, large language models (LLMs) are prone to generating unintended text due to false or outdated knowledge. Given the resource-intensive nature of retraining LLMs, there has been a notable increase in the development of knowledge editing. However, current approaches and evaluations rarely explore the perturbation of editing on neighboring knowledge. This paper studies whether updating new knowledge to LLMs perturbs the neighboring knowledge encapsulated within them. Specifically, we seek to figure out whether appending a new answer into an answer list to a factual question leads to catastrophic forgetting of original correct answers in this list, as well as unintentional inclusion of incorrect answers. A metric of additivity is introduced and a benchmark dubbed as Perturbation Evaluation of Appending Knowledge (PEAK) is constructed to evaluate the degree of perturbation to neighboring knowledge when appending new knowledge. Besides, a plug-and-play framework termed Appending via Preservation and Prevention (APP) is proposed to mitigate the neighboring perturbation by maintaining the integrity of the answer list. Experiments demonstrate the effectiveness of APP coupling with four editing methods on three LLMs.</li>
</ul>

<h3>Title: Elephants Do Not Forget: Differential Privacy with State Continuity for  Privacy Budget</h3>
<ul>
<li><strong>Authors: </strong>Jiankai Jin, Chitchanok Chuengsatiansup, Toby Murray, Benjamin I. P. Rubinstein, Yuval Yarom, Olga Ohrimenko</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17628">https://arxiv.org/abs/2401.17628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17628">https://arxiv.org/pdf/2401.17628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17628]] Elephants Do Not Forget: Differential Privacy with State Continuity for  Privacy Budget(https://arxiv.org/abs/2401.17628)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Current implementations of differentially-private (DP) systems either lack support to track the global privacy budget consumed on a dataset, or fail to faithfully maintain the state continuity of this budget. We show that failure to maintain a privacy budget enables an adversary to mount replay, rollback and fork attacks - obtaining answers to many more queries than what a secure system would allow. As a result the attacker can reconstruct secret data that DP aims to protect - even if DP code runs in a Trusted Execution Environment (TEE). We propose ElephantDP, a system that aims to provide the same guarantees as a trusted curator in the global DP model would, albeit set in an untrusted environment. Our system relies on a state continuity module to provide protection for the privacy budget and a TEE to faithfully execute DP code and update the budget. To provide security, our protocol makes several design choices including the content of the persistent state and the order between budget updates and query answers. We prove that ElephantDP provides liveness (i.e., the protocol can restart from a correct state and respond to queries as long as the budget is not exceeded) and DP confidentiality (i.e., an attacker learns about a dataset as much as it would from interacting with a trusted curator). Our implementation and evaluation of the protocol use Intel SGX as a TEE to run the DP code and a network of TEEs to maintain state continuity. Compared to an insecure baseline, we observe only 1.1-2$\times$ overheads and lower relative overheads for larger datasets and complex DP queries.</li>
</ul>

<h3>Title: Spatial-and-Frequency-aware Restoration method for Images based on  Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Kyungsung Lee, Donggyu Lee, Myungjoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17629">https://arxiv.org/abs/2401.17629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17629">https://arxiv.org/pdf/2401.17629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17629]] Spatial-and-Frequency-aware Restoration method for Images based on  Diffusion Models(https://arxiv.org/abs/2401.17629)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently emerged as a promising framework for Image Restoration (IR), owing to their ability to produce high-quality reconstructions and their compatibility with established methods. Existing methods for solving noisy inverse problems in IR, considers the pixel-wise data-fidelity. In this paper, we propose SaFaRI, a spatial-and-frequency-aware diffusion model for IR with Gaussian noise. Our model encourages images to preserve data-fidelity in both the spatial and frequency domains, resulting in enhanced reconstruction quality. We comprehensively evaluate the performance of our model on a variety of noisy inverse problems, including inpainting, denoising, and super-resolution. Our thorough evaluation demonstrates that SaFaRI achieves state-of-the-art performance on both the ImageNet datasets and FFHQ datasets, outperforming existing zero-shot IR methods in terms of LPIPS and FID metrics.</li>
</ul>

<h3>Title: Navigating the OverKill in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Shi, Xiao Wang, Qiming Ge, Songyang Gao, Xianjun Yang, Tao Gui, Qi Zhang, Xuanjing Huang, Xun Zhao, Dahua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17633">https://arxiv.org/abs/2401.17633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17633">https://arxiv.org/pdf/2401.17633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17633]] Navigating the OverKill in Large Language Models(https://arxiv.org/abs/2401.17633)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are meticulously aligned to be both helpful and harmless. However, recent research points to a potential overkill which means models may refuse to answer benign queries. In this paper, we investigate the factors for overkill by exploring how models handle and determine the safety of queries. Our findings reveal the presence of shortcuts within models, leading to an over-attention of harmful words like 'kill' and prompts emphasizing safety will exacerbate overkill. Based on these insights, we introduce Self-Contrastive Decoding (Self-CD), a training-free and model-agnostic strategy, to alleviate this phenomenon. We first extract such over-attention by amplifying the difference in the model's output distributions when responding to system prompts that either include or omit an emphasis on safety. Then we determine the final next-token predictions by downplaying the over-attention from the model via contrastive decoding. Empirical results indicate that our method has achieved an average reduction of the refusal rate by 20\% while having almost no impact on safety.</li>
</ul>

<h3>Title: A primer on synthetic health data</h3>
<ul>
<li><strong>Authors: </strong>Jennifer Anne Bartell, Sander Boisen Valentin, Anders Krogh, Henning Langberg, Martin Bøgsted</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17653">https://arxiv.org/abs/2401.17653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17653">https://arxiv.org/pdf/2401.17653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17653]] A primer on synthetic health data(https://arxiv.org/abs/2401.17653)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in deep generative models have greatly expanded the potential to create realistic synthetic health datasets. These synthetic datasets aim to preserve the characteristics, patterns, and overall scientific conclusions derived from sensitive health datasets without disclosing patient identity or sensitive information. Thus, synthetic data can facilitate safe data sharing that supports a range of initiatives including the development of new predictive models, advanced health IT platforms, and general project ideation and hypothesis development. However, many questions and challenges remain, including how to consistently evaluate a synthetic dataset's similarity and predictive utility in comparison to the original real dataset and risk to privacy when shared. Additional regulatory and governance issues have not been widely addressed. In this primer, we map the state of synthetic health data, including generation and evaluation methods and tools, existing examples of deployment, the regulatory and ethical landscape, access and governance options, and opportunities for further development.</li>
</ul>

<h3>Title: An attempt to generate new bridge types from latent space of  energy-based model</h3>
<ul>
<li><strong>Authors: </strong>Hongjun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17657">https://arxiv.org/abs/2401.17657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17657">https://arxiv.org/pdf/2401.17657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17657]] An attempt to generate new bridge types from latent space of  energy-based model(https://arxiv.org/abs/2401.17657)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Use energy-based model for bridge-type innovation. The loss function is explained by the game theory, the logic is clear and the formula is simple and clear. Thus avoid the use of maximum likelihood estimation to explain the loss function and eliminate the need for Monte Carlo methods to solve the normalized denominator. Assuming that the bridge-type population follows a Boltzmann distribution, a neural network is constructed to represent the energy function. Use Langevin dynamics technology to generate a new sample with low energy value, thus a generative model of bridge-type based on energy is established. Train energy function on symmetric structured image dataset of three span beam bridge, arch bridge, cable-stayed bridge, and suspension bridge to accurately calculate the energy values of real and fake samples. Sampling from latent space, using gradient descent algorithm, the energy function transforms the sampling points into low energy score samples, thereby generating new bridge types different from the dataset. Due to unstable and slow training in this attempt, the possibility of generating new bridge types is rare and the image definition of generated images is low.</li>
</ul>

<h3>Title: Document Structure in Long Document Transformers</h3>
<ul>
<li><strong>Authors: </strong>Jan Buchmann, Max Eichler, Jan-Micha Bodensohn, Ilia Kuznetsov, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17658">https://arxiv.org/abs/2401.17658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17658">https://arxiv.org/pdf/2401.17658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17658]] Document Structure in Long Document Transformers(https://arxiv.org/abs/2401.17658)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Long documents often exhibit structure with hierarchically organized elements of different functions, such as section headers and paragraphs. Despite the omnipresence of document structure, its role in natural language processing (NLP) remains opaque. Do long-document Transformer models acquire an internal representation of document structure during pre-training? How can structural information be communicated to a model after pre-training, and how does it influence downstream performance? To answer these questions, we develop a novel suite of probing tasks to assess structure-awareness of long-document Transformers, propose general-purpose structure infusion methods, and evaluate the effects of structure infusion on QASPER and Evidence Inference, two challenging long-document NLP tasks. Results on LED and LongT5 suggest that they acquire implicit understanding of document structure during pre-training, which can be further enhanced by structure infusion, leading to improved end-task performance. To foster research on the role of document structure in NLP modeling, we make our data and code publicly available.</li>
</ul>

<h3>Title: Image Anything: Towards Reasoning-coherent and Training-free Multi-modal  Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuanhuiyi Lyu, Xu Zheng, Lin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17664">https://arxiv.org/abs/2401.17664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17664">https://arxiv.org/pdf/2401.17664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17664]] Image Anything: Towards Reasoning-coherent and Training-free Multi-modal  Image Generation(https://arxiv.org/abs/2401.17664)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The multifaceted nature of human perception and comprehension indicates that, when we think, our body can naturally take any combination of senses, a.k.a., modalities and form a beautiful picture in our brain. For example, when we see a cattery and simultaneously perceive the cat's purring sound, our brain can construct a picture of a cat in the cattery. Intuitively, generative AI models should hold the versatility of humans and be capable of generating images from any combination of modalities efficiently and collaboratively. This paper presents ImgAny, a novel end-to-end multi-modal generative model that can mimic human reasoning and generate high-quality images. Our method serves as the first attempt in its capacity of efficiently and flexibly taking any combination of seven modalities, ranging from language, audio to vision modalities, including image, point cloud, thermal, depth, and event data. Our key idea is inspired by human-level cognitive processes and involves the integration and harmonization of multiple input modalities at both the entity and attribute levels without specific tuning across modalities. Accordingly, our method brings two novel training-free technical branches: 1) Entity Fusion Branch ensures the coherence between inputs and outputs. It extracts entity features from the multi-modal representations powered by our specially constructed entity knowledge graph; 2) Attribute Fusion Branch adeptly preserves and processes the attributes. It efficiently amalgamates distinct attributes from diverse input modalities via our proposed attribute knowledge graph. Lastly, the entity and attribute features are adaptively fused as the conditional inputs to the pre-trained Stable Diffusion model for image generation. Extensive experiments under diverse modality combinations demonstrate its exceptional capability for visual content creation.</li>
</ul>

<h3>Title: Contextual Feature Extraction Hierarchies Converge in Large Language  Models and the Brain</h3>
<ul>
<li><strong>Authors: </strong>Gavin Mischler, Yinghao Aaron Li, Stephan Bickel, Ashesh D. Mehta, Nima Mesgarani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17671">https://arxiv.org/abs/2401.17671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17671">https://arxiv.org/pdf/2401.17671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17671]] Contextual Feature Extraction Hierarchies Converge in Large Language  Models and the Brain(https://arxiv.org/abs/2401.17671)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in artificial intelligence have sparked interest in the parallels between large language models (LLMs) and human neural processing, particularly in language comprehension. While prior research has established similarities in the representation of LLMs and the brain, the underlying computational principles that cause this convergence, especially in the context of evolving LLMs, remain elusive. Here, we examined a diverse selection of high-performance LLMs with similar parameter sizes to investigate the factors contributing to their alignment with the brain's language processing mechanisms. We find that as LLMs achieve higher performance on benchmark tasks, they not only become more brain-like as measured by higher performance when predicting neural responses from LLM embeddings, but also their hierarchical feature extraction pathways map more closely onto the brain's while using fewer layers to do the same encoding. We also compare the feature extraction pathways of the LLMs to each other and identify new ways in which high-performing models have converged toward similar hierarchical processing mechanisms. Finally, we show the importance of contextual information in improving model performance and brain similarity. Our findings reveal the converging aspects of language processing in the brain and LLMs and offer new directions for developing models that align more closely with human cognitive processing.</li>
</ul>

<h3>Title: Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought  Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Tinghui Zhu, Kai Zhang, Jian Xie, Yu Su</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17686">https://arxiv.org/abs/2401.17686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17686">https://arxiv.org/pdf/2401.17686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17686]] Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought  Reasoning(https://arxiv.org/abs/2401.17686)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements have significantly augmented the reasoning capabilities of Large Language Models (LLMs) through various methodologies, especially chain-of-thought (CoT) reasoning. However, previous methods fail to address reasoning errors in intermediate steps, leading to accumulative errors.In this paper, we propose Deductive Beam Search (DBS), which seamlessly integrates CoT and deductive reasoning with step-wise beam search for LLMs. Our approach deploys a verifier, verifying the deducibility of a reasoning step and its premises, thus alleviating the error accumulation. Furthermore, we introduce a scalable and labor-free data construction method to amplify our model's verification capabilities. Extensive experiments demonstrate that our approach significantly enhances the base performance of LLMs of various scales (7B, 13B, 70B, and ChatGPT) across 8 reasoning datasets from 3 diverse reasoning genres, including arithmetic, commonsense, and symbolic. Moreover, our analysis proves DBS's capability of detecting diverse and subtle reasoning errors and robustness on different model scales.</li>
</ul>

<h3>Title: Mitigating the Problem of Strong Priors in LMs with Context  Extrapolation</h3>
<ul>
<li><strong>Authors: </strong>Raymond Douglas, Andis Draguns, Tomáš Gavenčiak</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17692">https://arxiv.org/abs/2401.17692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17692">https://arxiv.org/pdf/2401.17692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17692]] Mitigating the Problem of Strong Priors in LMs with Context  Extrapolation(https://arxiv.org/abs/2401.17692)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Language models (LMs) have become important tools in a variety of applications, from data processing to the creation of instruction-following assistants. But despite their advantages, LMs have certain idiosyncratic limitations such as the problem of `strong priors', where a model learns to output typical continuations in response to certain, usually local, portions of the input regardless of any earlier instructions. For example, prompt injection attacks can induce models to ignore explicit directives. In some cases, larger models have been shown to be more susceptible to these problems than similar smaller models, an example of the phenomenon of `inverse scaling'. We develop a new technique for mitigating the problem of strong priors: we take the original set of instructions, produce a weakened version of the original prompt that is even more susceptible to the strong priors problem, and then extrapolate the continuation away from the weakened prompt. This lets us infer how the model would continue a hypothetical strengthened set of instructions. Our technique conceptualises LMs as mixture models which combine a family of data generation processes, reinforcing the desired elements of the mixture. Our approach works at inference time, removing any need for retraining. We apply it to eleven models including GPT-2, GPT-3, Llama 2, and Mistral on four tasks, and find improvements in 41/44. Across all 44 combinations the median increase in proportion of tasks completed is 40%.</li>
</ul>

<h3>Title: Datacube segmentation via Deep Spectral Clustering</h3>
<ul>
<li><strong>Authors: </strong>Alessandro Bombini, Fernando García-Avello Bofías, Caterina Bracci, Michele Ginolfi, Chiara Ruberto</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, physics.app-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17695">https://arxiv.org/abs/2401.17695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17695">https://arxiv.org/pdf/2401.17695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17695]] Datacube segmentation via Deep Spectral Clustering(https://arxiv.org/abs/2401.17695)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Extended Vision techniques are ubiquitous in physics. However, the data cubes steaming from such analysis often pose a challenge in their interpretation, due to the intrinsic difficulty in discerning the relevant information from the spectra composing the data cube. Furthermore, the huge dimensionality of data cube spectra poses a complex task in its statistical interpretation; nevertheless, this complexity contains a massive amount of statistical information that can be exploited in an unsupervised manner to outline some essential properties of the case study at hand, e.g.~it is possible to obtain an image segmentation via (deep) clustering of data-cube's spectra, performed in a suitably defined low-dimensional embedding space. To tackle this topic, we explore the possibility of applying unsupervised clustering methods in encoded space, i.e. perform deep clustering on the spectral properties of datacube pixels. A statistical dimensional reduction is performed by an ad hoc trained (Variational) AutoEncoder, in charge of mapping spectra into lower dimensional metric spaces, while the clustering process is performed by a (learnable) iterative K-Means clustering algorithm. We apply this technique to two different use cases, of different physical origins: a set of Macro mapping X-Ray Fluorescence (MA-XRF) synthetic data on pictorial artworks, and a dataset of simulated astrophysical observations.</li>
</ul>

<h3>Title: Unified Physical-Digital Face Attack Detection</h3>
<ul>
<li><strong>Authors: </strong>Hao Fang, Ajian Liu, Haocheng Yuan, Junze Zheng, Dingheng Zeng, Yanhong Liu, Jiankang Deng, Sergio Escalera, Xiaoming Liu, Jun Wan, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17699">https://arxiv.org/abs/2401.17699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17699">https://arxiv.org/pdf/2401.17699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17699]] Unified Physical-Digital Face Attack Detection(https://arxiv.org/abs/2401.17699)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Face Recognition (FR) systems can suffer from physical (i.e., print photo) and digital (i.e., DeepFake) attacks. However, previous related work rarely considers both situations at the same time. This implies the deployment of multiple models and thus more computational burden. The main reasons for this lack of an integrated model are caused by two factors: (1) The lack of a dataset including both physical and digital attacks with ID consistency which means the same ID covers the real face and all attack types; (2) Given the large intra-class variance between these two attacks, it is difficult to learn a compact feature space to detect both attacks simultaneously. To address these issues, we collect a Unified physical-digital Attack dataset, called UniAttackData. The dataset consists of $1,800$ participations of 2 and 12 physical and digital attacks, respectively, resulting in a total of 29,706 videos. Then, we propose a Unified Attack Detection framework based on Vision-Language Models (VLMs), namely UniAttackDetection, which includes three main modules: the Teacher-Student Prompts (TSP) module, focused on acquiring unified and specific knowledge respectively; the Unified Knowledge Mining (UKM) module, designed to capture a comprehensive feature space; and the Sample-Level Prompt Interaction (SLPI) module, aimed at grasping sample-level semantics. These three modules seamlessly form a robust unified attack detection framework. Extensive experiments on UniAttackData and three other datasets demonstrate the superiority of our approach for unified face attack detection.</li>
</ul>

<h3>Title: WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Pardis Sadat Zahraei, Ali Emami</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17703">https://arxiv.org/abs/2401.17703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17703">https://arxiv.org/pdf/2401.17703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17703]] WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts(https://arxiv.org/abs/2401.17703)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Winograd Schema Challenge (WSC) serves as a prominent benchmark for evaluating machine understanding. While Large Language Models (LLMs) excel at answering WSC questions, their ability to generate such questions remains less explored. In this work, we propose Tree-of-Experts (ToE), a novel prompting method which enhances the generation of WSC instances (50% valid cases vs. 10% in recent methods). Using this approach, we introduce WSC+, a novel dataset comprising 3,026 LLM-generated sentences. Notably, we extend the WSC framework by incorporating new 'ambiguous' and 'offensive' categories, providing a deeper insight into model overconfidence and bias. Our analysis reveals nuances in generation-evaluation consistency, suggesting that LLMs may not always outperform in evaluating their own generated questions when compared to those crafted by other models. On WSC+, GPT-4, the top-performing LLM, achieves an accuracy of 68.7%, significantly below the human benchmark of 95.1%.</li>
</ul>

<h3>Title: Enhancing Large Language Model with Decomposed Reasoning for Emotion  Cause Pair Extraction</h3>
<ul>
<li><strong>Authors: </strong>Jialiang Wu, Yi Shen, Ziheng Zhang, Longjun Cai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17716">https://arxiv.org/abs/2401.17716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17716">https://arxiv.org/pdf/2401.17716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17716]] Enhancing Large Language Model with Decomposed Reasoning for Emotion  Cause Pair Extraction(https://arxiv.org/abs/2401.17716)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Emotion-Cause Pair Extraction (ECPE) involves extracting clause pairs representing emotions and their causes in a document. Existing methods tend to overfit spurious correlations, such as positional bias in existing benchmark datasets, rather than capturing semantic features. Inspired by recent work, we explore leveraging large language model (LLM) to address ECPE task without additional training. Despite strong capabilities, LLMs suffer from uncontrollable outputs, resulting in mediocre performance. To address this, we introduce chain-of-thought to mimic human cognitive process and propose the Decomposed Emotion-Cause Chain (DECC) framework. Combining inducing inference and logical pruning, DECC guides LLMs to tackle ECPE task. We further enhance the framework by incorporating in-context learning. Experiment results demonstrate the strength of DECC compared to state-of-the-art supervised fine-tuning methods. Finally, we analyze the effectiveness of each component and the robustness of the method in various scenarios, including different LLM bases, rebalanced datasets, and multi-pair extraction.</li>
</ul>

<h3>Title: COMET: Contrastive Mean Teacher for Online Source-Free Universal Domain  Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Pascal Schlachter, Bin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17728">https://arxiv.org/abs/2401.17728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17728">https://arxiv.org/pdf/2401.17728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17728]] COMET: Contrastive Mean Teacher for Online Source-Free Universal Domain  Adaptation(https://arxiv.org/abs/2401.17728)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In real-world applications, there is often a domain shift from training to test data. This observation resulted in the development of test-time adaptation (TTA). It aims to adapt a pre-trained source model to the test data without requiring access to the source data. Thereby, most existing works are limited to the closed-set assumption, i.e. there is no category shift between source and target domain. We argue that in a realistic open-world setting a category shift can appear in addition to a domain shift. This means, individual source classes may not appear in the target domain anymore, samples of new classes may be part of the target domain or even both at the same time. Moreover, in many real-world scenarios the test data is not accessible all at once but arrives sequentially as a stream of batches demanding an immediate prediction. Hence, TTA must be applied in an online manner. To the best of our knowledge, the combination of these aspects, i.e. online source-free universal domain adaptation (online SF-UniDA), has not been studied yet. In this paper, we introduce a Contrastive Mean Teacher (COMET) tailored to this novel scenario. It applies a contrastive loss to rebuild a feature space where the samples of known classes build distinct clusters and the samples of new classes separate well from them. It is complemented by an entropy loss which ensures that the classifier output has a small entropy for samples of known classes and a large entropy for samples of new classes to be easily detected and rejected as unknown. To provide the losses with reliable pseudo labels, they are embedded into a mean teacher (MT) framework. We evaluate our method across two datasets and all category shifts to set an initial benchmark for online SF-UniDA. Thereby, COMET yields state-of-the-art performance and proves to be consistent and robust across a variety of different scenarios.</li>
</ul>

<h3>Title: Leveraging Human-Machine Interactions for Computer Vision Dataset  Quality Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Esla Timothy Anzaku (1,2,3), Hyesoo Hong (1), Jin-Woo Park (1), Wonjun Yang (1), Kangmin Kim (1), JongBum Won (1), Deshika Vinoshani Kumari Herath (6), Arnout Van Messem (5), Wesley De Neve (1,2,3)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17736">https://arxiv.org/abs/2401.17736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17736">https://arxiv.org/pdf/2401.17736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17736]] Leveraging Human-Machine Interactions for Computer Vision Dataset  Quality Enhancement(https://arxiv.org/abs/2401.17736)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large-scale datasets for single-label multi-class classification, such as \emph{ImageNet-1k}, have been instrumental in advancing deep learning and computer vision. However, a critical and often understudied aspect is the comprehensive quality assessment of these datasets, especially regarding potential multi-label annotation errors. In this paper, we introduce a lightweight, user-friendly, and scalable framework that synergizes human and machine intelligence for efficient dataset validation and quality enhancement. We term this novel framework \emph{Multilabelfy}. Central to Multilabelfy is an adaptable web-based platform that systematically guides annotators through the re-evaluation process, effectively leveraging human-machine interactions to enhance dataset quality. By using Multilabelfy on the ImageNetV2 dataset, we found that approximately $47.88\%$ of the images contained at least two labels, underscoring the need for more rigorous assessments of such influential datasets. Furthermore, our analysis showed a negative correlation between the number of potential labels per image and model top-1 accuracy, illuminating a crucial factor in model evaluation and selection. Our open-source framework, Multilabelfy, offers a convenient, lightweight solution for dataset enhancement, emphasizing multi-label proportions. This study tackles major challenges in dataset integrity and provides key insights into model performance evaluation. Moreover, it underscores the advantages of integrating human expertise with machine capabilities to produce more robust models and trustworthy data development. The source code for Multilabelfy will be available at https://github.com/esla/Multilabelfy. \keywords{Computer Vision \and Dataset Quality Enhancement \and Dataset Validation \and Human-Computer Interaction \and Multi-label Annotation.}</li>
</ul>

<h3>Title: Algorithmic Robust Forecast Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Yongkang Guo, Jason D. Hartline, Zhihuan Huang, Yuqing Kong, Anant Shah, Fang-Yi Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17743">https://arxiv.org/abs/2401.17743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17743">https://arxiv.org/pdf/2401.17743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17743]] Algorithmic Robust Forecast Aggregation(https://arxiv.org/abs/2401.17743)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Forecast aggregation combines the predictions of multiple forecasters to improve accuracy. However, the lack of knowledge about forecasters' information structure hinders optimal aggregation. Given a family of information structures, robust forecast aggregation aims to find the aggregator with minimal worst-case regret compared to the omniscient aggregator. Previous approaches for robust forecast aggregation rely on heuristic observations and parameter tuning. We propose an algorithmic framework for robust forecast aggregation. Our framework provides efficient approximation schemes for general information aggregation with a finite family of possible information structures. In the setting considered by Arieli et al. (2018) where two agents receive independent signals conditioned on a binary state, our framework also provides efficient approximation schemes by imposing Lipschitz conditions on the aggregator or discrete conditions on agents' reports. Numerical experiments demonstrate the effectiveness of our method by providing a nearly optimal aggregator in the setting considered by Arieli et al. (2018).</li>
</ul>

<h3>Title: Logit Poisoning Attack in Distillation-based Federated Learning and its  Countermeasures</h3>
<ul>
<li><strong>Authors: </strong>Yonghao Yu, Shunan Zhu, Jinglu Hu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17746">https://arxiv.org/abs/2401.17746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17746">https://arxiv.org/pdf/2401.17746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17746]] Logit Poisoning Attack in Distillation-based Federated Learning and its  Countermeasures(https://arxiv.org/abs/2401.17746)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Distillation-based federated learning has emerged as a promising collaborative learning approach, where clients share the output logit vectors of a public dataset rather than their private model parameters. This practice reduces the risk of privacy invasion attacks and facilitates heterogeneous learning. The landscape of poisoning attacks within distillation-based federated learning is complex, with existing research employing traditional data poisoning strategies targeting the models' parameters. However, these attack schemes primarily have shortcomings rooted in their original designs, which target the model parameters rather than the logit vectors. Furthermore, they do not adequately consider the role of logit vectors in carrying information during the knowledge transfer process. This misalignment results in less efficiency in the context of distillation-based federated learning. Due to the limitations of existing methodologies, our research delves into the intrinsic properties of the logit vector, striving for a more nuanced understanding. We introduce a two-stage scheme for logit poisoning attacks, addressing previous shortcomings. Initially, we collect the local logits, generate the representative vectors, categorize the logit elements within the vector, and design a shuffling table to maximize information entropy. Then, we intentionally scale the shuffled logit vectors to enhance the magnitude of the target vectors. Concurrently, we propose an efficient defense algorithm to counter this new poisoning scheme by calculating the distance between estimated benign vectors and vectors uploaded by users. Through extensive experiments, our study illustrates the significant threat posed by the proposed logit poisoning attack and highlights the effectiveness of our defense algorithm.</li>
</ul>

<h3>Title: Tiered approach for rapid damage characterisation of infrastructure  enabled by remote sensing and deep learning technologies</h3>
<ul>
<li><strong>Authors: </strong>Nadiia Kopiika, Andreas Karavias, Pavlos Krassakis, Zehao Ye, Jelena Ninic, Nataliya Shakhovska, Nikolaos Koukouzas, Sotirios Argyroudis, Stergios-Aristoteles Mitoulis</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17759">https://arxiv.org/abs/2401.17759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17759">https://arxiv.org/pdf/2401.17759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17759]] Tiered approach for rapid damage characterisation of infrastructure  enabled by remote sensing and deep learning technologies(https://arxiv.org/abs/2401.17759)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, segmentation</a></li>
<li><strong>Abstract: </strong>Critical infrastructure such as bridges are systematically targeted during wars and conflicts. This is because critical infrastructure is vital for enabling connectivity and transportation of people and goods, and hence, underpinning the national and international defence planning and economic growth. Mass destruction of bridges, along with minimal or no accessibility to these assets during natural and anthropogenic disasters, prevents us from delivering rapid recovery. As a result, systemic resilience is drastically reduced. A solution to this challenge is to use technology for stand-off observations. Yet, no method exists to characterise damage at different scales, i.e. regional, asset, and structural (component), and more so there is little or no systematic correlation between assessments at scale. We propose an integrated three-level tiered approach to fill this capability gap, and we demonstrate the methods for damage characterisation enabled by fit-for-purpose digital technologies. Next, this method is applied and validated to a case study in Ukraine that includes 17 bridges. From macro to micro, we deploy technology at scale, from Sentinel-1 SAR images, crowdsourced information, and high-resolution images to deep learning for damaged infrastructure. For the first time, the interferometric coherence difference and semantic segmentation of images were deployed to improve the reliability of damage characterisations from regional to infrastructure component level, when enhanced assessment accuracy is required. This integrated method improves the speed of decision-making, and thus, enhances resilience. Keywords: critical infrastructure, damage characterisation, targeted attacks, restoration</li>
</ul>

<h3>Title: Double InfoGAN for Contrastive Analysis</h3>
<ul>
<li><strong>Authors: </strong>Florence Carton, Robin Louiset, Pietro Gori</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17776">https://arxiv.org/abs/2401.17776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17776">https://arxiv.org/pdf/2401.17776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17776]] Double InfoGAN for Contrastive Analysis(https://arxiv.org/abs/2401.17776)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don't enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality. Datasets and code are available online.</li>
</ul>

<h3>Title: Robustly overfitting latents for flexible neural image compression</h3>
<ul>
<li><strong>Authors: </strong>Yura Perugachi-Diaz, Arwin Gansekoele, Sandjai Bhulai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17789">https://arxiv.org/abs/2401.17789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17789">https://arxiv.org/pdf/2401.17789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17789]] Robustly overfitting latents for flexible neural image compression(https://arxiv.org/abs/2401.17789)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural image compression has made a great deal of progress. State-of-the-art models are based on variational autoencoders and are outperforming classical models. Neural compression models learn to encode an image into a quantized latent representation that can be efficiently sent to the decoder, which decodes the quantized latent into a reconstructed image. While these models have proven successful in practice, they lead to sub-optimal results due to imperfect optimization and limitations in the encoder and decoder capacity. Recent work shows how to use stochastic Gumbel annealing (SGA) to refine the latents of pre-trained neural image compression models. We extend this idea by introducing SGA+, which contains three different methods that build upon SGA. Further, we give a detailed analysis of our proposed methods, show how they improve performance, and show that they are less sensitive to hyperparameter choices. Besides, we show how each method can be extended to three- instead of two-class rounding. Finally, we show how refinement of the latents with our best-performing method improves the compression performance on the Tecnick dataset and how it can be deployed to partly move along the rate-distortion curve.</li>
</ul>

<h3>Title: Graph Transformers without Positional Encodings</h3>
<ul>
<li><strong>Authors: </strong>Ayush Garg</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17791">https://arxiv.org/abs/2401.17791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17791">https://arxiv.org/pdf/2401.17791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17791]] Graph Transformers without Positional Encodings(https://arxiv.org/abs/2401.17791)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently, Transformers for graph representation learning have become increasingly popular, achieving state-of-the-art performance on a wide-variety of datasets, either alone or in combination with message-passing graph neural networks (MP-GNNs). Infusing graph inductive-biases in the innately structure-agnostic transformer architecture in the form of structural or positional encodings (PEs) is key to achieving these impressive results. However, designing such encodings is tricky and disparate attempts have been made to engineer such encodings including Laplacian eigenvectors, relative random-walk probabilities (RRWP), spatial encodings, centrality encodings, edge encodings etc. In this work, we argue that such encodings may not be required at all, provided the attention mechanism itself incorporates information about the graph structure. We introduce Eigenformer, which uses a novel spectrum-aware attention mechanism cognizant of the Laplacian spectrum of the graph, and empirically show that it achieves performance comparable to SOTA MP-GNN architectures and Graph Transformers on a number of standard GNN benchmark datasets, even surpassing the SOTA on some datasets. We also find that our architecture is much faster to train in terms of number of epochs, presumably due to the innate graph inductive biases.</li>
</ul>

<h3>Title: M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based  Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Xingning Dong, Zipeng Feng, Chunluan Zhou, Xuzheng Yu, Ming Yang, Qingpei Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17797">https://arxiv.org/abs/2401.17797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17797">https://arxiv.org/pdf/2401.17797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17797]] M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based  Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval(https://arxiv.org/abs/2401.17797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a Multi-Modal Recipe for Advancing Adaptation-based Pre-training towards effective and efficient zero-shot video-text retrieval, dubbed M2-RAAP. Upon popular image-text models like CLIP, most current adaptation-based video-text pre-training methods are confronted by three major issues, i.e., noisy data corpus, time-consuming pre-training, and limited performance gain. Towards this end, we conduct a comprehensive study including four critical steps in video-text pre-training. Specifically, we investigate 1) data filtering and refinement, 2) video input type selection, 3) temporal modeling, and 4) video feature enhancement. We then summarize this empirical study into the M2-RAAP recipe, where our technical contributions lie in 1) the data filtering and text re-writing pipeline resulting in 1M high-quality bilingual video-text pairs, 2) the replacement of video inputs with key-frames to accelerate pre-training, and 3) the Auxiliary-Caption-Guided (ACG) strategy to enhance video features. We conduct extensive experiments by adapting three image-text foundation models on two refined video-text datasets from different languages, validating the robustness and reproducibility of M2-RAAP for adaptation-based pre-training. Results demonstrate that M2-RAAP yields superior performance with significantly reduced data (-90%) and time consumption (-95%), establishing a new SOTA on four English zero-shot retrieval datasets and two Chinese ones. We are preparing our refined bilingual data annotations and codebase, which will be available at https://github.com/alipay/Ant-Multi-Modal-Framework/tree/main/prj/M2_RAAP.</li>
</ul>

<h3>Title: Distillation Enhanced Time Series Forecasting Network with Momentum  Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Haozhi Gao, Qianqian Ren, Jinbao Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17802">https://arxiv.org/abs/2401.17802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17802">https://arxiv.org/pdf/2401.17802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17802]] Distillation Enhanced Time Series Forecasting Network with Momentum  Contrastive Learning(https://arxiv.org/abs/2401.17802)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Contrastive representation learning is crucial in time series analysis as it alleviates the issue of data noise and incompleteness as well as sparsity of supervision signal. However, existing constrastive learning frameworks usually focus on intral-temporal features, which fails to fully exploit the intricate nature of time series data. To address this issue, we propose DE-TSMCL, an innovative distillation enhanced framework for long sequence time series forecasting. Specifically, we design a learnable data augmentation mechanism which adaptively learns whether to mask a timestamp to obtain optimized sub-sequences. Then, we propose a contrastive learning task with momentum update to explore inter-sample and intra-temporal correlations of time series to learn the underlying structure feature on the unlabeled time series. Meanwhile, we design a supervised task to learn more robust representations and facilitate the contrastive learning process. Finally, we jointly optimize the above two tasks. By developing model loss from multiple tasks, we can learn effective representations for downstream forecasting task. Extensive experiments, in comparison with state-of-the-arts, well demonstrate the effectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%.</li>
</ul>

<h3>Title: SimAda: A Simple Unified Framework for Adapting Segment Anything Model  in Underperformed Scenes</h3>
<ul>
<li><strong>Authors: </strong>Yiran Song, Qianyu Zhou, Xuequan Lu, Zhiwen Shao, Lizhuang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17803">https://arxiv.org/abs/2401.17803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17803">https://arxiv.org/pdf/2401.17803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17803]] SimAda: A Simple Unified Framework for Adapting Segment Anything Model  in Underperformed Scenes(https://arxiv.org/abs/2401.17803)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Segment anything model (SAM) has demonstrated excellent generalization capabilities in common vision scenarios, yet lacking an understanding of specialized data. Although numerous works have focused on optimizing SAM for downstream tasks, these task-specific approaches usually limit the generalizability to other downstream tasks. In this paper, we aim to investigate the impact of the general vision modules on finetuning SAM and enable them to generalize across all downstream tasks. We propose a simple unified framework called SimAda for adapting SAM in underperformed scenes. Specifically, our framework abstracts the general modules of different methods into basic design elements, and we design four variants based on a shared theoretical framework. SimAda is simple yet effective, which removes all dataset-specific designs and focuses solely on general optimization, ensuring that SimAda can be applied to all SAM-based and even Transformer-based models. We conduct extensive experiments on nine datasets of six downstream tasks. The results demonstrate that SimAda significantly improves the performance of SAM on multiple downstream tasks and achieves state-of-the-art performance on most of them, without requiring task-specific designs. Code is available at: https://github.com/zongzi13545329/SimAda</li>
</ul>

<h3>Title: Advances in 3D Generation: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Li, Qi Zhang, Di Kang, Weihao Cheng, Yiming Gao, Jingbo Zhang, Zhihao Liang, Jing Liao, Yan-Pei Cao, Ying Shan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17807">https://arxiv.org/abs/2401.17807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17807">https://arxiv.org/pdf/2401.17807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17807]] Advances in 3D Generation: A Survey(https://arxiv.org/abs/2401.17807)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generating 3D models lies at the core of computer graphics and has been the focus of decades of research. With the emergence of advanced neural representations and generative models, the field of 3D content generation is developing rapidly, enabling the creation of increasingly high-quality and diverse 3D models. The rapid growth of this field makes it difficult to stay abreast of all recent developments. In this survey, we aim to introduce the fundamental methodologies of 3D generation methods and establish a structured roadmap, encompassing 3D representation, generation methods, datasets, and corresponding applications. Specifically, we introduce the 3D representations that serve as the backbone for 3D generation. Furthermore, we provide a comprehensive overview of the rapidly growing literature on generation methods, categorized by the type of algorithmic paradigms, including feedforward generation, optimization-based generation, procedural generation, and generative novel view synthesis. Lastly, we discuss available datasets, applications, and open challenges. We hope this survey will help readers explore this exciting topic and foster further advancements in the field of 3D content generation.</li>
</ul>

<h3>Title: SWEA: Changing Factual Knowledge in Large Language Models via Subject  Word Embedding Altering</h3>
<ul>
<li><strong>Authors: </strong>Xiaopeng Li, Shasha Li, Bin Ji, Shezheng Song, Xi Wang, Jun Ma, Jie Yu, Xiaodong Liu, Jing Wang, Weimin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17809">https://arxiv.org/abs/2401.17809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17809">https://arxiv.org/pdf/2401.17809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17809]] SWEA: Changing Factual Knowledge in Large Language Models via Subject  Word Embedding Altering(https://arxiv.org/abs/2401.17809)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Model editing has recently gained widespread attention. Current model editing methods primarily involve modifying model parameters or adding additional modules to the existing model. However, the former causes irreversible damage to LLMs, while the latter incurs additional inference overhead and fuzzy vector matching is not always reliable. To address these issues, we propose an expandable Subject Word Embedding Altering (SWEA) framework, which modifies the representation of subjects and achieve the goal of editing knowledge during the inference stage. SWEA uses precise key matching outside the model and performs reliable subject word embedding altering, thus protecting the original weights of the model without increasing inference overhead. We then propose optimizing then suppressing fusion method, which first optimizes the embedding vector for the editing target and then suppresses the Knowledge Embedding Dimension (KED) to obtain the final fused embedding. We thus propose SWEAOS method for editing factual knowledge in LLMs. We demonstrate the state-of-the-art performance of SWEAOS on the COUNTERFACT and zsRE datasets. To further validate the reasoning ability of SWEAOS in editing knowledge, we evaluate it on the more complex RIPPLEEDITS benchmark. The results on two subdatasets demonstrate that our SWEAOS possesses state-of-the-art reasoning ability.</li>
</ul>

<h3>Title: QTFlow: Quantitative Timing-Sensitive Information Flow for  Security-Aware Hardware Design on RTL</h3>
<ul>
<li><strong>Authors: </strong>Lennart M. Reimann, Anschul Prashar, Chiara Ghinami, Rebecca Pelke, Dominik Sisejkovic, Farhad Merchant, Rainer Leupers</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17819">https://arxiv.org/abs/2401.17819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17819">https://arxiv.org/pdf/2401.17819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17819]] QTFlow: Quantitative Timing-Sensitive Information Flow for  Security-Aware Hardware Design on RTL(https://arxiv.org/abs/2401.17819)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>In contemporary Electronic Design Automation (EDA) tools, security often takes a backseat to the primary goals of power, performance, and area optimization. Commonly, the security analysis is conducted by hand, leading to vulnerabilities in the design remaining unnoticed. Security-aware EDA tools assist the designer in the identification and removal of security threats while keeping performance and area in mind. Cutting-edge methods employ information flow analysis to identify inadvertent information leaks in design structures. Current information leakage detection methods use quantitative information flow analysis to quantify the leaks. However, handling sequential circuits poses challenges for state-of-the-art techniques due to their time-agnostic nature, overlooking timing channels, and introducing false positives. To address this, we introduce QTFlow, a timing-sensitive framework for quantifying hardware information leakages during the design phase. Illustrating its effectiveness on open-source benchmarks, QTFlow autonomously identifies timing channels and diminishes all false positives arising from time-agnostic analysis when contrasted with current state-of-the-art techniques.</li>
</ul>

<h3>Title: Privacy-preserving data release leveraging optimal transport and  particle gradient descent</h3>
<ul>
<li><strong>Authors: </strong>Konstantin Donhauser, Javier Abad, Neha Hulkund, Fanny Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17823">https://arxiv.org/abs/2401.17823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17823">https://arxiv.org/pdf/2401.17823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17823]] Privacy-preserving data release leveraging optimal transport and  particle gradient descent(https://arxiv.org/abs/2401.17823)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>We present a novel approach for differentially private data synthesis of protected tabular datasets, a relevant task in highly sensitive domains such as healthcare and government. Current state-of-the-art methods predominantly use marginal-based approaches, where a dataset is generated from private estimates of the marginals. In this paper, we introduce PrivPGD, a new generation method for marginal-based private data synthesis, leveraging tools from optimal transport and particle gradient descent. Our algorithm outperforms existing methods on a large range of datasets while being highly scalable and offering the flexibility to incorporate additional domain-specific constraints.</li>
</ul>

<h3>Title: Leveraging Swin Transformer for Local-to-Global Weakly Supervised  Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Rozhan Ahmadi, Shohreh Kasaei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17828">https://arxiv.org/abs/2401.17828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17828">https://arxiv.org/pdf/2401.17828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17828]] Leveraging Swin Transformer for Local-to-Global Weakly Supervised  Semantic Segmentation(https://arxiv.org/abs/2401.17828)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, weakly supervised semantic segmentation using image-level labels as supervision has received significant attention in the field of computer vision. Most existing methods have addressed the challenges arising from the lack of spatial information in these labels by focusing on facilitating supervised learning through the generation of pseudo-labels from class activation maps (CAMs). Due to the localized pattern detection of Convolutional Neural Networks (CNNs), CAMs often emphasize only the most discriminative parts of an object, making it challenging to accurately distinguish foreground objects from each other and the background. Recent studies have shown that Vision Transformer (ViT) features, due to their global view, are more effective in capturing the scene layout than CNNs. However, the use of hierarchical ViTs has not been extensively explored in this field. This work explores the use of Swin Transformer by proposing "SWTformer" to enhance the accuracy of the initial seed CAMs by bringing local and global views together. SWTformer-V1 generates class probabilities and CAMs using only the patch tokens as features. SWTformer-V2 incorporates a multi-scale feature fusion mechanism to extract additional information and utilizes a background-aware mechanism to generate more accurate localization maps with improved cross-object discrimination. Based on experiments on the PascalVOC 2012 dataset, SWTformer-V1 achieves a 0.98% mAP higher localization accuracy, outperforming state-of-the-art models. It also yields comparable performance by 0.82% mIoU on average higher than other methods in generating initial localization maps, depending only on the classification network. SWTformer-V2 further improves the accuracy of the generated seed CAMs by 5.32% mIoU, further proving the effectiveness of the local-to-global view provided by the Swin transformer.</li>
</ul>

<h3>Title: Global-Liar: Factuality of LLMs over Time and Geographic Regions</h3>
<ul>
<li><strong>Authors: </strong>Shujaat Mirza, Bruno Coelho, Yuyuan Cui, Christina Pöpper, Damon McCoy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17839">https://arxiv.org/abs/2401.17839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17839">https://arxiv.org/pdf/2401.17839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17839]] Global-Liar: Factuality of LLMs over Time and Geographic Regions(https://arxiv.org/abs/2401.17839)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The increasing reliance on AI-driven solutions, particularly Large Language Models (LLMs) like the GPT series, for information retrieval highlights the critical need for their factuality and fairness, especially amidst the rampant spread of misinformation and disinformation online. Our study evaluates the factual accuracy, stability, and biases in widely adopted GPT models, including GPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated information dissemination. We introduce 'Global-Liar,' a dataset uniquely balanced in terms of geographic and temporal representation, facilitating a more nuanced evaluation of LLM biases. Our analysis reveals that newer iterations of GPT models do not always equate to improved performance. Notably, the GPT-4 version from March demonstrates higher factual accuracy than its subsequent June release. Furthermore, a concerning bias is observed, privileging statements from the Global North over the Global South, thus potentially exacerbating existing informational inequities. Regions such as Africa and the Middle East are at a disadvantage, with much lower factual accuracy. The performance fluctuations over time suggest that model updates may not consistently benefit all regions equally. Our study also offers insights into the impact of various LLM configuration settings, such as binary decision forcing, model re-runs and temperature, on model's factuality. Models constrained to binary (true/false) choices exhibit reduced factuality compared to those allowing an 'unclear' option. Single inference at a low temperature setting matches the reliability of majority voting across various configurations. The insights gained highlight the need for culturally diverse and geographically inclusive model training and evaluation. This approach is key to achieving global equity in technology, distributing AI benefits fairly worldwide.</li>
</ul>

<h3>Title: Semantic Anything in 3D Gaussians</h3>
<ul>
<li><strong>Authors: </strong>Xu Hu, Yuxi Wang, Lue Fan, Junsong Fan, Junran Peng, Zhen Lei, Qing Li, Zhaoxiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17857">https://arxiv.org/abs/2401.17857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17857">https://arxiv.org/pdf/2401.17857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17857]] Semantic Anything in 3D Gaussians(https://arxiv.org/abs/2401.17857)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting has emerged as an alternative 3D representation of Neural Radiance Fields (NeRFs), benefiting from its high-quality rendering results and real-time rendering speed. Considering the 3D Gaussian representation remains unparsed, it is necessary first to execute object segmentation within this domain. Subsequently, scene editing and collision detection can be performed, proving vital to a multitude of applications, such as virtual reality (VR), augmented reality (AR), game/movie production, etc. In this paper, we propose a novel approach to achieve object segmentation in 3D Gaussian via an interactive procedure without any training process and learned parameters. We refer to the proposed method as SA-GS, for Segment Anything in 3D Gaussians. Given a set of clicked points in a single input view, SA-GS can generalize SAM to achieve 3D consistent segmentation via the proposed multi-view mask generation and view-wise label assignment methods. We also propose a cross-view label-voting approach to assign labels from different views. In addition, in order to address the boundary roughness issue of segmented objects resulting from the non-negligible spatial sizes of 3D Gaussian located at the boundary, SA-GS incorporates the simple but effective Gaussian Decomposition scheme. Extensive experiments demonstrate that SA-GS achieves high-quality 3D segmentation results, which can also be easily applied for scene editing and collision detection tasks. Codes will be released soon.</li>
</ul>

<h3>Title: Probing Language Models' Gesture Understanding for Enhanced Human-AI  Interaction</h3>
<ul>
<li><strong>Authors: </strong>Philipp Wicke</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17858">https://arxiv.org/abs/2401.17858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17858">https://arxiv.org/pdf/2401.17858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17858]] Probing Language Models' Gesture Understanding for Enhanced Human-AI  Interaction(https://arxiv.org/abs/2401.17858)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models (LLMs) has affected various disciplines that got beyond mere text generation. Going beyond their textual nature, this project proposal aims to investigate the interaction between LLMs and non-verbal communication, specifically focusing on gestures. The proposal sets out a plan to examine the proficiency of LLMs in deciphering both explicit and implicit non-verbal cues within textual prompts and their ability to associate these gestures with various contextual factors. The research proposes to test established psycholinguistic study designs to construct a comprehensive dataset that pairs textual prompts with detailed gesture descriptions, encompassing diverse regional variations, and semantic labels. To assess LLMs' comprehension of gestures, experiments are planned, evaluating their ability to simulate human behaviour in order to replicate psycholinguistic experiments. These experiments consider cultural dimensions and measure the agreement between LLM-identified gestures and the dataset, shedding light on the models' contextual interpretation of non-verbal cues (e.g. gestures).</li>
</ul>

<h3>Title: Proximity QA: Unleashing the Power of Multi-Modal Large Language Models  for Spatial Proximity Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jianing Li, Xi Nan, Ming Lu, Li Du, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17862">https://arxiv.org/abs/2401.17862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17862">https://arxiv.org/pdf/2401.17862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17862]] Proximity QA: Unleashing the Power of Multi-Modal Large Language Models  for Spatial Proximity Analysis(https://arxiv.org/abs/2401.17862)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) have demonstrated remarkable vision-language capabilities, primarily due to the exceptional in-context understanding and multi-task learning strengths of large language models (LLMs). The advent of visual instruction tuning has further enhanced MLLMs' performance in vision-language understanding. However, while existing MLLMs adeptly recognize \textit{what} objects are in an image, they still face challenges in effectively discerning \textit{where} these objects are, particularly along the distance (scene depth) axis. To overcome this limitation in MLLMs, we introduce Proximity Question Answering (Proximity QA), a novel framework designed to enable MLLMs to infer the proximity relationship between objects in images. The framework operates in two phases: the first phase focuses on guiding the models to understand the relative depth of objects, and the second phase further encourages the models to infer the proximity relationships between objects based on their depth perceptions. We also propose a VQA dataset called Proximity-110K, containing additional instructions that incorporate depth information and the proximity relationships of objects. We have conducted extensive experiments to validate Proximity QA's superior ability in depth perception and proximity analysis, outperforming other state-of-the-art MLLMs. Code and dataset will be released at \textcolor{magenta}{https://github.com/NorthSummer/ProximityQA.git}.</li>
</ul>

<h3>Title: Convolution Meets LoRA: Parameter Efficient Finetuning for Segment  Anything Model</h3>
<ul>
<li><strong>Authors: </strong>Zihan Zhong, Zhiqiang Tang, Tong He, Haoyang Fang, Chun Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17868">https://arxiv.org/abs/2401.17868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17868">https://arxiv.org/pdf/2401.17868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17868]] Convolution Meets LoRA: Parameter Efficient Finetuning for Segment  Anything Model(https://arxiv.org/abs/2401.17868)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM) stands as a foundational framework for image segmentation. While it exhibits remarkable zero-shot generalization in typical scenarios, its advantage diminishes when applied to specialized domains like medical imagery and remote sensing. To address this limitation, this paper introduces Conv-LoRA, a simple yet effective parameter-efficient fine-tuning approach. By integrating ultra-lightweight convolutional parameters into Low-Rank Adaptation (LoRA), Conv-LoRA can inject image-related inductive biases into the plain ViT encoder, further reinforcing SAM's local prior assumption. Notably, Conv-LoRA not only preserves SAM's extensive segmentation knowledge but also revives its capacity of learning high-level image semantics, which is constrained by SAM's foreground-background segmentation pretraining. Comprehensive experimentation across diverse benchmarks spanning multiple domains underscores Conv-LoRA's superiority in adapting SAM to real-world semantic segmentation tasks.</li>
</ul>

<h3>Title: Efficient Subseasonal Weather Forecast using Teleconnection-informed  Transformers</h3>
<ul>
<li><strong>Authors: </strong>Shan Zhao, Zhitong Xiong, Xiao Xiang Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17870">https://arxiv.org/abs/2401.17870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17870">https://arxiv.org/pdf/2401.17870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17870]] Efficient Subseasonal Weather Forecast using Teleconnection-informed  Transformers(https://arxiv.org/abs/2401.17870)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Subseasonal forecasting, which is pivotal for agriculture, water resource management, and early warning of disasters, faces challenges due to the chaotic nature of the atmosphere. Recent advances in machine learning (ML) have revolutionized weather forecasting by achieving competitive predictive skills to numerical models. However, training such foundation models requires thousands of GPU days, which causes substantial carbon emissions and limits their broader applicability. Moreover, ML models tend to fool the pixel-wise error scores by producing smoothed results which lack physical consistency and meteorological meaning. To deal with the aforementioned problems, we propose a teleconnection-informed transformer. Our architecture leverages the pretrained Pangu model to achieve good initial weights and integrates a teleconnection-informed temporal module to improve predictability in an extended temporal range. Remarkably, by adjusting 1.1% of the Pangu model's parameters, our method enhances predictability on four surface and five upper-level atmospheric variables at a two-week lead time. Furthermore, the teleconnection-filtered features improve the spatial granularity of outputs significantly, indicating their potential physical consistency. Our research underscores the importance of atmospheric and oceanic teleconnections in driving future weather conditions. Besides, it presents a resource-efficient pathway for researchers to leverage existing foundation models on versatile downstream tasks.</li>
</ul>

<h3>Title: AEROBLADE: Training-Free Detection of Latent Diffusion Images Using  Autoencoder Reconstruction Error</h3>
<ul>
<li><strong>Authors: </strong>Jonas Ricker, Denis Lukovnikov, Asja Fischer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17879">https://arxiv.org/abs/2401.17879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17879">https://arxiv.org/pdf/2401.17879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17879]] AEROBLADE: Training-Free Detection of Latent Diffusion Images Using  Autoencoder Reconstruction Error(https://arxiv.org/abs/2401.17879)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With recent text-to-image models, anyone can generate deceptively realistic images with arbitrary contents, fueling the growing threat of visual disinformation. A key enabler for generating high-resolution images with low computational cost has been the development of latent diffusion models (LDMs). In contrast to conventional diffusion models, LDMs perform the denoising process in the low-dimensional latent space of a pre-trained autoencoder (AE) instead of the high-dimensional image space. Despite their relevance, the forensic analysis of LDMs is still in its infancy. In this work we propose AEROBLADE, a novel detection method which exploits an inherent component of LDMs: the AE used to transform images between image and latent space. We find that generated images can be more accurately reconstructed by the AE than real images, allowing for a simple detection approach based on the reconstruction error. Most importantly, our method is easy to implement and does not require any training, yet nearly matches the performance of detectors that rely on extensive training. We empirically demonstrate that AEROBLADE is effective against state-of-the-art LDMs including Stable Diffusion and Midjourney. Beyond detection, our approach allows for the qualitative analysis of images, which can be leveraged for identifying inpainted regions.</li>
</ul>

<h3>Title: I Think, Therefore I am: Awareness in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuan Li, Yue Huang, Yuli Lin, Siyuan Wu, Yao Wan, Lichao Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17882">https://arxiv.org/abs/2401.17882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17882">https://arxiv.org/pdf/2401.17882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17882]] I Think, Therefore I am: Awareness in Large Language Models(https://arxiv.org/abs/2401.17882)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Do large language models (LLMs) exhibit any forms of awareness similar to humans? In this paper, we introduce the concept of awareness to LLMs, arguing that awareness is an essential aspect of trustworthiness for LLMs to enhance their interaction with humans while ensuring ethical responses. We define awareness in LLMs as the ability to perceive and understand themselves as AI models and to exhibit social intelligence. We identify four key dimensions of awareness: capability, mission, emotion, and perspective. To assess LLMs on these dimensions, we introduce a specialized dataset, AwareLLM dataset. Our findings reveal that LLMs demonstrate a decent degree of awareness, though they still lack substantial capability awareness.</li>
</ul>

<h3>Title: Employing Label Models on ChatGPT Answers Improves Legal Text Entailment  Performance</h3>
<ul>
<li><strong>Authors: </strong>Chau Nguyen, Le-Minh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17897">https://arxiv.org/abs/2401.17897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17897">https://arxiv.org/pdf/2401.17897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17897]] Employing Label Models on ChatGPT Answers Improves Legal Text Entailment  Performance(https://arxiv.org/abs/2401.17897)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The objective of legal text entailment is to ascertain whether the assertions in a legal query logically follow from the information provided in one or multiple legal articles. ChatGPT, a large language model, is robust in many natural language processing tasks, including legal text entailment: when we set the temperature = 0 (the ChatGPT answers are deterministic) and prompt the model, it achieves 70.64% accuracy on COLIEE 2022 dataset, which outperforms the previous SOTA of 67.89%. On the other hand, if the temperature is larger than zero, ChatGPT answers are not deterministic, leading to inconsistent answers and fluctuating results. We propose to leverage label models (a fundamental component of weak supervision techniques) to integrate the provisional answers by ChatGPT into consolidated labels. By that way, we treat ChatGPT provisional answers as noisy predictions which can be consolidated by label models. The experimental results demonstrate that this approach can attain an accuracy of 76.15%, marking a significant improvement of 8.26% over the prior state-of-the-art benchmark. Additionally, we perform an analysis of the instances where ChatGPT produces incorrect answers, then we classify the errors, offering insights that could guide potential enhancements for future research endeavors.</li>
</ul>

<h3>Title: Hi-SAM: Marrying Segment Anything Model for Hierarchical Text  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Maoyuan Ye, Jing Zhang, Juhua Liu, Chenyu Liu, Baocai Yin, Cong Liu, Bo Du, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17904">https://arxiv.org/abs/2401.17904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17904">https://arxiv.org/pdf/2401.17904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17904]] Hi-SAM: Marrying Segment Anything Model for Hierarchical Text  Segmentation(https://arxiv.org/abs/2401.17904)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM), a profound vision foundation model pre-trained on a large-scale dataset, breaks the boundaries of general segmentation and sparks various downstream applications. This paper introduces Hi-SAM, a unified model leveraging SAM for hierarchical text segmentation. Hi-SAM excels in text segmentation across four hierarchies, including stroke, word, text-line, and paragraph, while realizing layout analysis as well. Specifically, we first turn SAM into a high-quality text stroke segmentation (TSS) model through a parameter-efficient fine-tuning approach. We use this TSS model to iteratively generate the text stroke labels in a semi-automatical manner, unifying labels across the four text hierarchies in the HierText dataset. Subsequently, with these complete labels, we launch the end-to-end trainable Hi-SAM based on the TSS architecture with a customized hierarchical mask decoder. During inference, Hi-SAM offers both automatic mask generation (AMG) mode and promptable segmentation mode. In terms of the AMG mode, Hi-SAM segments text stroke foreground masks initially, then samples foreground points for hierarchical text mask generation and achieves layout analysis in passing. As for the promptable mode, Hi-SAM provides word, text-line, and paragraph masks with a single point click. Experimental results show the state-of-the-art performance of our TSS model: 84.86% fgIOU on Total-Text and 88.96% fgIOU on TextSeg for text stroke segmentation. Moreover, compared to the previous specialist for joint hierarchical detection and layout analysis on HierText, Hi-SAM achieves significant improvements: 4.73% PQ and 5.39% F1 on the text-line level, 5.49% PQ and 7.39% F1 on the paragraph level layout analysis, requiring 20x fewer training epochs. The code is available at https://github.com/ymy-k/Hi-SAM.</li>
</ul>

<h3>Title: Source-free Domain Adaptive Object Detection in Remote Sensing Images</h3>
<ul>
<li><strong>Authors: </strong>Weixing Liu, Jun Liu, Xin Su, Han Nie, Bin Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17916">https://arxiv.org/abs/2401.17916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17916">https://arxiv.org/pdf/2401.17916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17916]] Source-free Domain Adaptive Object Detection in Remote Sensing Images(https://arxiv.org/abs/2401.17916)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Recent studies have used unsupervised domain adaptive object detection (UDAOD) methods to bridge the domain gap in remote sensing (RS) images. However, UDAOD methods typically assume that the source domain data can be accessed during the domain adaptation process. This setting is often impractical in the real world due to RS data privacy and transmission difficulty. To address this challenge, we propose a practical source-free object detection (SFOD) setting for RS images, which aims to perform target domain adaptation using only the source pre-trained model. We propose a new SFOD method for RS images consisting of two parts: perturbed domain generation and alignment. The proposed multilevel perturbation constructs the perturbed domain in a simple yet efficient form by perturbing the domain-variant features at the image level and feature level according to the color and style bias. The proposed multilevel alignment calculates feature and label consistency between the perturbed domain and the target domain across the teacher-student network, and introduces the distillation of feature prototype to mitigate the noise of pseudo-labels. By requiring the detector to be consistent in the perturbed domain and the target domain, the detector is forced to focus on domaininvariant features. Extensive results of three synthetic-to-real experiments and three cross-sensor experiments have validated the effectiveness of our method which does not require access to source domain RS images. Furthermore, experiments on computer vision datasets show that our method can be extended to other fields as well. Our code will be available at: https://weixliu.github.io/ .</li>
</ul>

<h3>Title: GuardFS: a File System for Integrated Detection and Mitigation of  Linux-based Ransomware</h3>
<ul>
<li><strong>Authors: </strong>Jan von der Assen, Chao Feng, Alberto Huertas Celdrán, Róbert Oleš, Gérôme Bovet, Burkhard Stiller</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17917">https://arxiv.org/abs/2401.17917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17917">https://arxiv.org/pdf/2401.17917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17917]] GuardFS: a File System for Integrated Detection and Mitigation of  Linux-based Ransomware(https://arxiv.org/abs/2401.17917)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense</a></li>
<li><strong>Abstract: </strong>Although ransomware has received broad attention in media and research, this evolving threat vector still poses a systematic threat. Related literature has explored their detection using various approaches leveraging Machine and Deep Learning. While these approaches are effective in detecting malware, they do not answer how to use this intelligence to protect against threats, raising concerns about their applicability in a hostile environment. Solutions that focus on mitigation rarely explore how to prevent and not just alert or halt its execution, especially when considering Linux-based samples. This paper presents GuardFS, a file system-based approach to investigate the integration of detection and mitigation of ransomware. Using a bespoke overlay file system, data is extracted before files are accessed. Models trained on this data are used by three novel defense configurations that obfuscate, delay, or track access to the file system. The experiments on GuardFS test the configurations in a reactive setting. The results demonstrate that although data loss cannot be completely prevented, it can be significantly reduced. Usability and performance analysis demonstrate that the defense effectiveness of the configurations relates to their impact on resource consumption and usability.</li>
</ul>

<h3>Title: LOCOST: State-Space Models for Long Document Abstractive Summarization</h3>
<ul>
<li><strong>Authors: </strong>Florian Le Bronnec, Song Duong, Mathieu Ravaut, Alexandre Allauzen, Nancy F. Chen, Vincent Guigue, Alberto Lumbreras, Laure Soulier, Patrick Gallinari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17919">https://arxiv.org/abs/2401.17919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17919">https://arxiv.org/pdf/2401.17919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17919]] LOCOST: State-Space Models for Long Document Abstractive Summarization(https://arxiv.org/abs/2401.17919)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies. We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs. With a computational complexity of $O(L \log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns. We evaluate our model on a series of long document abstractive summarization tasks. The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference. Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing.</li>
</ul>

<h3>Title: HyperZ$\cdot$Z$\cdot$W Operator Connects Slow-Fast Networks for Full  Context Interaction</h3>
<ul>
<li><strong>Authors: </strong>Harvie Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17948">https://arxiv.org/abs/2401.17948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17948">https://arxiv.org/pdf/2401.17948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17948]] HyperZ$\cdot$Z$\cdot$W Operator Connects Slow-Fast Networks for Full  Context Interaction(https://arxiv.org/abs/2401.17948)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The self-attention mechanism utilizes large implicit weight matrices, programmed through dot product-based activations with very few trainable parameters, to enable long sequence modeling. In this paper, we investigate the possibility of discarding residual learning by employing large implicit kernels to achieve full context interaction at each layer of the network. To accomplish it, we introduce coordinate-based implicit MLPs as a slow network to generate hyper-kernels for another fast convolutional network. To get context-varying weights for fast dynamic encoding, we propose a $\mathrm{Hyper}\mathcal{Z{\cdot}Z{\cdot}W}$ operator that connects hyper-kernels ($\mathcal{W}$) and hidden activations ($\mathcal{Z}$) through simple elementwise multiplication, followed by convolution of $\mathcal{Z}$ using the context-dependent $\mathcal{W}$. Based on this design, we present a novel Terminator architecture that integrates hyper-kernels of different sizes to produce multi-branch hidden representations for enhancing the feature extraction capability of each layer. Additionally, a bottleneck layer is employed to compress the concatenated channels, allowing only valuable information to propagate to the subsequent layers. Notably, our model incorporates several innovative components and exhibits excellent properties, such as introducing local feedback error for updating the slow network, stable zero-mean features, faster training convergence, and fewer model parameters. Extensive experimental results on pixel-level 1D and 2D image classification benchmarks demonstrate the superior performance of our architecture.</li>
</ul>

<h3>Title: Understanding polysemanticity in neural networks through coding theory</h3>
<ul>
<li><strong>Authors: </strong>Simon C. Marshall, Jan H. Kirchner</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17975">https://arxiv.org/abs/2401.17975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17975">https://arxiv.org/pdf/2401.17975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17975]] Understanding polysemanticity in neural networks through coding theory(https://arxiv.org/abs/2401.17975)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Despite substantial efforts, neural network interpretability remains an elusive goal, with previous research failing to provide succinct explanations of most single neurons' impact on the network output. This limitation is due to the polysemantic nature of most neurons, whereby a given neuron is involved in multiple unrelated network states, complicating the interpretation of that neuron. In this paper, we apply tools developed in neuroscience and information theory to propose both a novel practical approach to network interpretability and theoretical insights into polysemanticity and the density of codes. We infer levels of redundancy in the network's code by inspecting the eigenspectrum of the activation's covariance matrix. Furthermore, we show how random projections can reveal whether a network exhibits a smooth or non-differentiable code and hence how interpretable the code is. This same framework explains the advantages of polysemantic neurons to learning performance and explains trends found in recent results by Elhage et al.~(2022). Our approach advances the pursuit of interpretability in neural networks, providing insights into their underlying structure and suggesting new avenues for circuit-level interpretability.</li>
</ul>

<h3>Title: Enhancing Multimodal Large Language Models with Vision Detection Models:  An Empirical Study</h3>
<ul>
<li><strong>Authors: </strong>Qirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, Ying Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17981">https://arxiv.org/abs/2401.17981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17981">https://arxiv.org/pdf/2401.17981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17981]] Enhancing Multimodal Large Language Models with Vision Detection Models:  An Empirical Study(https://arxiv.org/abs/2401.17981)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the impressive capabilities of Multimodal Large Language Models (MLLMs) in integrating text and image modalities, challenges remain in accurately interpreting detailed visual elements. This paper presents an empirical study on enhancing MLLMs with state-of-the-art (SOTA) object detection and Optical Character Recognition models to improve fine-grained image understanding and reduce hallucination in responses. Our research investigates the embedding-based infusion of detection information, the impact of such infusion on the MLLMs' original abilities, and the interchangeability of detection models. We conduct systematic experiments with models such as LLaVA-1.5, DINO, and PaddleOCRv2, revealing that our approach not only refines MLLMs' performance in specific visual tasks but also maintains their original strengths. The resulting enhanced MLLMs outperform SOTA models on 9 out of 10 benchmarks, achieving an improvement of up to 12.99% on the normalized average score, marking a notable advancement in multimodal understanding. We release our codes to facilitate further exploration into the fine-grained multimodal dialogue capabilities of MLLMs.</li>
</ul>

<h3>Title: Shrub of a thousand faces: an individual segmentation from satellite  images using deep learning</h3>
<ul>
<li><strong>Authors: </strong>Rohaifa Khaldi, Siham Tabik, Sergio Puertas-Ruiz, Julio Peñas de Giles, José Antonio Hódar Correa, Regino Zamora, Domingo Alcaraz Segura</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.17985">https://arxiv.org/abs/2401.17985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.17985">https://arxiv.org/pdf/2401.17985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.17985]] Shrub of a thousand faces: an individual segmentation from satellite  images using deep learning(https://arxiv.org/abs/2401.17985)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Monitoring the distribution and size structure of long-living shrubs, such as Juniperus communis, can be used to estimate the long-term effects of climate change on high-mountain and high latitude ecosystems. Historical aerial very-high resolution imagery offers a retrospective tool to monitor shrub growth and distribution at high precision. Currently, deep learning models provide impressive results for detecting and delineating the contour of objects with defined shapes. However, adapting these models to detect natural objects that express complex growth patterns, such as junipers, is still a challenging task. This research presents a novel approach that leverages remotely sensed RGB imagery in conjunction with Mask R-CNN-based instance segmentation models to individually delineate Juniperus shrubs above the treeline in Sierra Nevada (Spain). In this study, we propose a new data construction design that consists in using photo interpreted (PI) and field work (FW) data to respectively develop and externally validate the model. We also propose a new shrub-tailored evaluation algorithm based on a new metric called Multiple Intersections over Ground Truth Area (MIoGTA) to assess and optimize the model shrub delineation performance. Finally, we deploy the developed model for the first time to generate a wall-to-wall map of Juniperus individuals. The experimental results demonstrate the efficiency of our dual data construction approach in overcoming the limitations associated with traditional field survey methods. They also highlight the robustness of MIoGTA metric in evaluating instance segmentation models on species with complex growth patterns showing more resilience against data annotation uncertainty. Furthermore, they show the effectiveness of employing Mask R-CNN with ResNet101-C4 backbone in delineating PI and FW shrubs, achieving an F1-score of 87,87% and 76.86%, respectively.</li>
</ul>

<h3>Title: Desiderata for the Context Use of Question Answering Systems</h3>
<ul>
<li><strong>Authors: </strong>Sagi Shaier, Lawrence E Hunter, Katharina von der Wense</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18001">https://arxiv.org/abs/2401.18001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18001">https://arxiv.org/pdf/2401.18001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18001]] Desiderata for the Context Use of Question Answering Systems(https://arxiv.org/abs/2401.18001)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Prior work has uncovered a set of common problems in state-of-the-art context-based question answering (QA) systems: a lack of attention to the context when the latter conflicts with a model's parametric knowledge, little robustness to noise, and a lack of consistency with their answers. However, most prior work focus on one or two of those problems in isolation, which makes it difficult to see trends across them. We aim to close this gap, by first outlining a set of -- previously discussed as well as novel -- desiderata for QA models. We then survey relevant analysis and methods papers to provide an overview of the state of the field. The second part of our work presents experiments where we evaluate 15 QA systems on 5 datasets according to all desiderata at once. We find many novel trends, including (1) systems that are less susceptible to noise are not necessarily more consistent with their answers when given irrelevant context; (2) most systems that are more susceptible to noise are more likely to correctly answer according to a context that conflicts with their parametric knowledge; and (3) the combination of conflicting knowledge and noise can reduce system performance by up to 96%. As such, our desiderata help increase our understanding of how these models work and reveal potential avenues for improvements.</li>
</ul>

<h3>Title: Prompt-Driven LLM Safeguarding via Directed Representation Optimization</h3>
<ul>
<li><strong>Authors: </strong>Chujie Zheng, Fan Yin, Hao Zhou, Fandong Meng, Jie Zhou, Kai-Wei Chang, Minlie Huang, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18018">https://arxiv.org/abs/2401.18018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18018">https://arxiv.org/pdf/2401.18018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18018]] Prompt-Driven LLM Safeguarding via Directed Representation Optimization(https://arxiv.org/abs/2401.18018)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not yet been fully understood, which hinders the potential for automatically optimizing them for improved LLM safety. Motivated by this problem, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by different safety prompts in similar directions, where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. DRO treats safety prompts as continuous, trainable embeddings and learns to move the representations of harmful/harmless queries along/opposite the direction in which the model's refusal probability increases. We demonstrate that DRO remarkably improves the safeguarding performance of human-crafted safety prompts and outperforms strong baselines, as evaluated on out-of-domain benchmarks, without compromising the general model capability.</li>
</ul>

<h3>Title: Benchmarking Private Population Data Release Mechanisms: Synthetic Data  vs. TopDown</h3>
<ul>
<li><strong>Authors: </strong>Aadyaa Maddi, Swadhin Routray, Alexander Goldberg, Giulia Fanti</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18024">https://arxiv.org/abs/2401.18024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18024">https://arxiv.org/pdf/2401.18024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18024]] Benchmarking Private Population Data Release Mechanisms: Synthetic Data  vs. TopDown(https://arxiv.org/abs/2401.18024)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Differential privacy (DP) is increasingly used to protect the release of hierarchical, tabular population data, such as census data. A common approach for implementing DP in this setting is to release noisy responses to a predefined set of queries. For example, this is the approach of the TopDown algorithm used by the US Census Bureau. Such methods have an important shortcoming: they cannot answer queries for which they were not optimized. An appealing alternative is to generate DP synthetic data, which is drawn from some generating distribution. Like the TopDown method, synthetic data can also be optimized to answer specific queries, while also allowing the data user to later submit arbitrary queries over the synthetic population data. To our knowledge, there has not been a head-to-head empirical comparison of these approaches. This study conducts such a comparison between the TopDown algorithm and private synthetic data generation to determine how accuracy is affected by query complexity, in-distribution vs. out-of-distribution queries, and privacy guarantees. Our results show that for in-distribution queries, the TopDown algorithm achieves significantly better privacy-fidelity tradeoffs than any of the synthetic data methods we evaluated; for instance, in our experiments, TopDown achieved at least $20\times$ lower error on counting queries than the leading synthetic data method at the same privacy budget. Our findings suggest guidelines for practitioners and the synthetic data research community.</li>
</ul>

<h3>Title: Supporting Anticipatory Governance using LLMs: Evaluating and Aligning  Large Language Models with the News Media to Anticipate the Negative Impacts  of AI</h3>
<ul>
<li><strong>Authors: </strong>Mowafak Allaham, Nicholas Diakopoulos</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18028">https://arxiv.org/abs/2401.18028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18028">https://arxiv.org/pdf/2401.18028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18028]] Supporting Anticipatory Governance using LLMs: Evaluating and Aligning  Large Language Models with the News Media to Anticipate the Negative Impacts  of AI(https://arxiv.org/abs/2401.18028)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Anticipating the negative impacts of emerging AI technologies is a challenge, especially in the early stages of development. An understudied approach to such anticipation is the use of LLMs to enhance and guide this process. Despite advancements in LLMs and evaluation metrics to account for biases in generated text, it is unclear how well these models perform in anticipatory tasks. Specifically, the use of LLMs to anticipate AI impacts raises questions about the quality and range of categories of negative impacts these models are capable of generating. In this paper we leverage news media, a diverse data source that is rich with normative assessments of emerging technologies, to formulate a taxonomy of impacts to act as a baseline for comparing against. By computationally analyzing thousands of news articles published by hundreds of online news domains around the world, we develop a taxonomy consisting of ten categories of AI impacts. We then evaluate both instruction-based (GPT-4 and Mistral-7B-Instruct) and fine-tuned completion models (Mistral-7B and GPT-3) using a sample from this baseline. We find that the generated impacts using Mistral-7B, fine-tuned on impacts from the news media, tend to be qualitatively on par with impacts generated using a larger scale model such as GPT-4. Moreover, we find that these LLMs generate impacts that largely reflect the taxonomy of negative impacts identified in the news media, however the impacts produced by instruction-based models had gaps in the production of certain categories of impacts in comparison to fine-tuned models. This research highlights a potential bias in state-of-the-art LLMs when used for anticipating impacts and demonstrates the advantages of aligning smaller LLMs with a diverse range of impacts, such as those reflected in the news media, to better reflect such impacts during anticipatory exercises.</li>
</ul>

<h3>Title: Paramanu: A Family of Novel Efficient Indic Generative Foundation  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mitodru Niyogi, Arnab Bhattacharya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18034">https://arxiv.org/abs/2401.18034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18034">https://arxiv.org/pdf/2401.18034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18034]] Paramanu: A Family of Novel Efficient Indic Generative Foundation  Language Models(https://arxiv.org/abs/2401.18034)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We present Gyan AI Paramanu ("atom"), a family of novel language models for Indian languages. It is a collection of auto-regressive monolingual, bilingual, and multilingual Indic language models pretrained from scratch on a single GPU for 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi, Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia, Tamil, Telugu) of varying sizes ranging from 13.29M to 367.5M.The models are pretrained with a context size of 1024 on a single GPU. The models are very efficient, small, fast, and powerful. We have also developed an efficient most advanced Indic tokenizer that can even tokenize unseen languages. In order to avoid the "curse of multi-linguality" in our multilingual mParamanu model, we pretrained on comparable corpora by typological grouping using the same script. We performed human evaluation of our pretrained models for open end text generation on grammar, coherence, creativity, and factuality metrics for Bangla, Hindi, and Sanskrit. Our Bangla, Hindi, and Sanskrit models outperformed GPT-3.5-Turbo (ChatGPT), Bloom 7B, LLaMa-2 7B, OPT 6.7B, GPT-J 6B, GPTNeo 1.3B, GPT2-XL large language models (LLMs) by a large margin despite being smaller in size by 66 to 20 times compared to standard 7B LLMs. To run inference on our pretrained models, CPU is enough, and GPU is not needed. We also instruction-tuned our pretrained Bangla, Hindi, Marathi, Tamil, and Telugu models on 23k instructions in respective languages. Our pretrained and instruction-tuned models which are first of its kind, most powerful efficient small generative language models ever developed for Indic languages, and the various results lead to the conclusion that high quality generative language models are possible without high amount of compute power and humongous number of parameters. We plan to release our models at https://www.bharatgpts.com.</li>
</ul>

<h3>Title: Multipath parsing in the brain</h3>
<ul>
<li><strong>Authors: </strong>Berta Franzluebbers, Donald Dunagan, Miloš Stanojević, Jan Buys, John T. Hale</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18046">https://arxiv.org/abs/2401.18046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18046">https://arxiv.org/pdf/2401.18046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18046]] Multipath parsing in the brain(https://arxiv.org/abs/2401.18046)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Humans understand sentences word-by-word, in the order that they hear them. This incrementality entails resolving temporary ambiguities about syntactic relationships. We investigate how humans process these syntactic ambiguities by correlating predictions from incremental generative dependency parsers with timecourse data from people undergoing functional neuroimaging while listening to an audiobook. In particular, we compare competing hypotheses regarding the number of developing syntactic analyses in play during word-by-word comprehension: one vs more than one. This comparison involves evaluating syntactic surprisal from a state-of-the-art dependency parser with LLM-adapted encodings against an existing fMRI dataset. In both English and Chinese data, we find evidence for multipath parsing. Brain regions associated with this multipath effect include bilateral superior temporal gyrus.</li>
</ul>

<h3>Title: Benchmarking Sensitivity of Continual Graph Learning for Skeleton-Based  Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Wei Wei, Tom De Schepper, Kevin Mets</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18054">https://arxiv.org/abs/2401.18054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18054">https://arxiv.org/pdf/2401.18054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18054]] Benchmarking Sensitivity of Continual Graph Learning for Skeleton-Based  Action Recognition(https://arxiv.org/abs/2401.18054)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Continual learning (CL) is the research field that aims to build machine learning models that can accumulate knowledge continuously over different tasks without retraining from scratch. Previous studies have shown that pre-training graph neural networks (GNN) may lead to negative transfer (Hu et al., 2020) after fine-tuning, a setting which is closely related to CL. Thus, we focus on studying GNN in the continual graph learning (CGL) setting. We propose the first continual graph learning benchmark for spatio-temporal graphs and use it to benchmark well-known CGL methods in this novel setting. The benchmark is based on the N-UCLA and NTU-RGB+D datasets for skeleton-based action recognition. Beyond benchmarking for standard performance metrics, we study the class and task-order sensitivity of CGL methods, i.e., the impact of learning order on each class/task's performance, and the architectural sensitivity of CGL methods with backbone GNN at various widths and depths. We reveal that task-order robust methods can still be class-order sensitive and observe results that contradict previous empirical observations on architectural sensitivity in CL.</li>
</ul>

<h3>Title: Rank Supervised Contrastive Learning for Time Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Qianying Ren, Dongsheng Luo, Dongjin Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18057">https://arxiv.org/abs/2401.18057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18057">https://arxiv.org/pdf/2401.18057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18057]] Rank Supervised Contrastive Learning for Time Series Classification(https://arxiv.org/abs/2401.18057)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, various contrastive learning techniques have been developed to categorize time series data and exhibit promising performance. A general paradigm is to utilize appropriate augmentations and construct feasible positive samples such that the encoder can yield robust and discriminative representations by mapping similar data points closer together in the feature space while pushing dissimilar data points farther apart. Despite its efficacy, the fine-grained relative similarity (e.g., rank) information of positive samples is largely ignored, especially when labeled samples are limited. To this end, we present Rank Supervised Contrastive Learning (RankSCL) to perform time series classification. Different from conventional contrastive learning frameworks, RankSCL augments raw data in a targeted way in the embedding space and adopts certain filtering rules to select more informative positive and negative pairs of samples. Moreover, a novel rank loss is developed to assign different weights for different levels of positive samples, enable the encoder to extract the fine-grained information of the same class, and produce a clear boundary among different classes. Thoroughly empirical studies on 128 UCR datasets and 30 UEA datasets demonstrate that the proposed RankSCL can achieve state-of-the-art performance compared to existing baseline methods.</li>
</ul>

<h3>Title: LongAlign: A Recipe for Long Context Alignment of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yushi Bai, Xin Lv, Jiajie Zhang, Yuze He, Ji Qi, Lei Hou, Jie Tang, Yuxiao Dong, Juanzi Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18058">https://arxiv.org/abs/2401.18058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18058">https://arxiv.org/pdf/2401.18058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18058]] LongAlign: A Recipe for Long Context Alignment of Large Language Models(https://arxiv.org/abs/2401.18058)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length. To address this, we present LongAlign -- a recipe of the instruction data, training, and evaluation for long context alignment. First, we construct a long instruction-following dataset using Self-Instruct. To ensure the data diversity, it covers a broad range of tasks from various long context sources. Second, we adopt the packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions. Additionally, we develop a loss weighting method to balance the contribution to the loss across different sequences during packing training. Third, we introduce the LongBench-Chat benchmark for evaluating instruction-following capabilities on queries of 10k-100k in length. Experiments show that LongAlign outperforms existing recipes for LLMs in long context tasks by up to 30\%, while also maintaining their proficiency in handling short, generic tasks. The code, data, and long-aligned models are open-sourced at https://github.com/THUDM/LongAlign.</li>
</ul>

<h3>Title: Do Language Models Exhibit the Same Cognitive Biases in Problem Solving  as Human Learners?</h3>
<ul>
<li><strong>Authors: </strong>Andreas Opedal, Alessandro Stolfo, Haruki Shirakami, Ying Jiao, Ryan Cotterell, Bernhard Schölkopf, Abulhair Saparov, Mrinmaya Sachan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18070">https://arxiv.org/abs/2401.18070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18070">https://arxiv.org/pdf/2401.18070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18070]] Do Language Models Exhibit the Same Cognitive Biases in Problem Solving  as Human Learners?(https://arxiv.org/abs/2401.18070)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>There is increasing interest in employing large language models (LLMs) as cognitive models. For such purposes, it is central to understand which cognitive properties are well-modeled by LLMs, and which are not. In this work, we study the biases of LLMs in relation to those known in children when solving arithmetic word problems. Surveying the learning science literature, we posit that the problem-solving process can be split into three distinct steps: text comprehension, solution planning and solution execution. We construct tests for each one in order to understand which parts of this process can be faithfully modeled by current state-of-the-art LLMs. We generate a novel set of word problems for each of these tests, using a neuro-symbolic method that enables fine-grained control over the problem features. We find evidence that LLMs, with and without instruction-tuning, exhibit human-like biases in both the text-comprehension and the solution-planning steps of the solving process, but not during the final step which relies on the problem's arithmetic expressions (solution execution).</li>
</ul>

<h3>Title: Improved Scene Landmark Detection for Camera Localization</h3>
<ul>
<li><strong>Authors: </strong>Tien Do, Sudipta N. Sinha</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18083">https://arxiv.org/abs/2401.18083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18083">https://arxiv.org/pdf/2401.18083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18083]] Improved Scene Landmark Detection for Camera Localization(https://arxiv.org/abs/2401.18083)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Camera localization methods based on retrieval, local feature matching, and 3D structure-based pose estimation are accurate but require high storage, are slow, and are not privacy-preserving. A method based on scene landmark detection (SLD) was recently proposed to address these limitations. It involves training a convolutional neural network (CNN) to detect a few predetermined, salient, scene-specific 3D points or landmarks and computing camera pose from the associated 2D-3D correspondences. Although SLD outperformed existing learning-based approaches, it was notably less accurate than 3D structure-based methods. In this paper, we show that the accuracy gap was due to insufficient model capacity and noisy labels during training. To mitigate the capacity issue, we propose to split the landmarks into subgroups and train a separate network for each subgroup. To generate better training labels, we propose using dense reconstructions to estimate visibility of scene landmarks. Finally, we present a compact architecture to improve memory efficiency. Accuracy wise, our approach is on par with state of the art structure based methods on the INDOOR-6 dataset but runs significantly faster and uses less storage. Code and models can be found at https://github.com/microsoft/SceneLandmarkLocalization.</li>
</ul>

<h3>Title: Motion Guidance: Diffusion-Based Image Editing with Differentiable  Motion Estimators</h3>
<ul>
<li><strong>Authors: </strong>Daniel Geng, Andrew Owens</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.18085">https://arxiv.org/abs/2401.18085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.18085">https://arxiv.org/pdf/2401.18085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.18085]] Motion Guidance: Diffusion-Based Image Editing with Differentiable  Motion Estimators(https://arxiv.org/abs/2401.18085)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models are capable of generating impressive images conditioned on text descriptions, and extensions of these models allow users to edit images at a relatively coarse scale. However, the ability to precisely edit the layout, position, pose, and shape of objects in images with diffusion models is still difficult. To this end, we propose motion guidance, a zero-shot technique that allows a user to specify dense, complex motion fields that indicate where each pixel in an image should move. Motion guidance works by steering the diffusion sampling process with the gradients through an off-the-shelf optical flow network. Specifically, we design a guidance loss that encourages the sample to have the desired motion, as estimated by a flow network, while also being visually similar to the source image. By simultaneously sampling from a diffusion model and guiding the sample to have low guidance loss, we can obtain a motion-edited image. We demonstrate that our technique works on complex motions and produces high quality edits of real and generated images.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
