<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: CNS-Net: Conservative Novelty Synthesizing Network for Malware Recognition in an Open-set Scenario. (arXiv:2305.01236v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01236">http://arxiv.org/abs/2305.01236</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01236] CNS-Net: Conservative Novelty Synthesizing Network for Malware Recognition in an Open-set Scenario](http://arxiv.org/abs/2305.01236) #security</code></li>
<li>Summary: <p>We study the challenging task of malware recognition on both known and novel
unknown malware families, called malware open-set recognition (MOSR). Previous
works usually assume the malware families are known to the classifier in a
close-set scenario, i.e., testing families are the subset or at most identical
to training families. However, novel unknown malware families frequently emerge
in real-world applications, and as such, require to recognize malware instances
in an open-set scenario, i.e., some unknown families are also included in the
test-set, which has been rarely and non-thoroughly investigated in the
cyber-security domain. One practical solution for MOSR may consider jointly
classifying known and detecting unknown malware families by a single classifier
(e.g., neural network) from the variance of the predicted probability
distribution on known families. However, conventional well-trained classifiers
usually tend to obtain overly high recognition probabilities in the outputs,
especially when the instance feature distributions are similar to each other,
e.g., unknown v.s. known malware families, and thus dramatically degrades the
recognition on novel unknown malware families. In this paper, we propose a
novel model that can conservatively synthesize malware instances to mimic
unknown malware families and support a more robust training of the classifier.
Moreover, we also build a new large-scale malware dataset, named MAL-100, to
fill the gap of lacking large open-set malware benchmark dataset. Experimental
results on two widely used malware datasets and our MAL-100 demonstrate the
effectiveness of our model compared with other representative methods.
</p></li>
</ul>

<h3>Title: Towards a better labeling process for network security datasets. (arXiv:2305.01337v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01337">http://arxiv.org/abs/2305.01337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01337] Towards a better labeling process for network security datasets](http://arxiv.org/abs/2305.01337) #security</code></li>
<li>Summary: <p>Most network security datasets do not have comprehensive label assignment
criteria, hindering the evaluation of the datasets, the training of models, the
results obtained, the comparison with other methods, and the evaluation in
real-life scenarios. There is no labeling ontology nor tools to help assign the
labels, resulting in most analyzed datasets assigning labels in files or
directory names. This paper addresses the problem of having a better labeling
process by (i) reviewing the needs of stakeholders of the datasets, from
creators to model users, (ii) presenting a new ontology of label assignment,
(iii) presenting a new tool for assigning structured labels for Zeek network
flows based on the ontology, and (iv) studying the differences between
generating labels and consuming labels in real-life scenarios. We conclude that
a process for structured label assignment is paramount for advancing research
in network security and that the new ontology-based label assignation rules
should be published as an artifact of every dataset.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Synthetic Data for Face Recognition: Current State and Future Prospects. (arXiv:2305.01021v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01021">http://arxiv.org/abs/2305.01021</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01021] Synthetic Data for Face Recognition: Current State and Future Prospects](http://arxiv.org/abs/2305.01021) #privacy</code></li>
<li>Summary: <p>Over the past years, deep learning capabilities and the availability of
large-scale training datasets advanced rapidly, leading to breakthroughs in
face recognition accuracy. However, these technologies are foreseen to face a
major challenge in the next years due to the legal and ethical concerns about
using authentic biometric data in AI model training and evaluation along with
increasingly utilizing data-hungry state-of-the-art deep learning models. With
the recent advances in deep generative models and their success in generating
realistic and high-resolution synthetic image data, privacy-friendly synthetic
data has been recently proposed as an alternative to privacy-sensitive
authentic data to overcome the challenges of using authentic data in face
recognition development. This work aims at providing a clear and structured
picture of the use-cases taxonomy of synthetic face data in face recognition
along with the recent emerging advances of face recognition models developed on
the bases of synthetic data. We also discuss the challenges facing the use of
synthetic data in face recognition development and several future prospects of
synthetic data in the domain of face recognition.
</p></li>
</ul>

<h3>Title: Mitigating Approximate Memorization in Language Models via Dissimilarity Learned Policy. (arXiv:2305.01550v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01550">http://arxiv.org/abs/2305.01550</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01550] Mitigating Approximate Memorization in Language Models via Dissimilarity Learned Policy](http://arxiv.org/abs/2305.01550) #privacy</code></li>
<li>Summary: <p>Large Language models (LLMs) are trained on large amounts of data, which can
include sensitive information that may compromise personal privacy. LLMs showed
to memorize parts of the training data and emit those data verbatim when an
adversary prompts appropriately. Previous research has primarily focused on
data preprocessing and differential privacy techniques to address memorization
or prevent verbatim memorization exclusively, which can give a false sense of
privacy. However, these methods rely on explicit and implicit assumptions about
the structure of the data to be protected, which often results in an incomplete
solution to the problem. To address this, we propose a novel framework that
utilizes a reinforcement learning approach (PPO) to fine-tune LLMs to mitigate
approximate memorization. Our approach utilizes a negative similarity score,
such as BERTScore or SacreBLEU, as a reward signal to learn a dissimilarity
policy. Our results demonstrate that this framework effectively mitigates
approximate memorization while maintaining high levels of coherence and fluency
in the generated samples. Furthermore, our framework is robust in mitigating
approximate memorization across various circumstances, including longer
context, which is known to increase memorization in LLMs.
</p></li>
</ul>

<h3>Title: Exploring the Privacy Concerns in Permissionless Blockchain Networks and Potential Solutions. (arXiv:2305.01038v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01038">http://arxiv.org/abs/2305.01038</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01038] Exploring the Privacy Concerns in Permissionless Blockchain Networks and Potential Solutions](http://arxiv.org/abs/2305.01038) #privacy</code></li>
<li>Summary: <p>In recent years, permissionless blockchains have gained significant attention
for their ability to secure and provide transparency in transactions. The
development of blockchain technology has shifted from cryptocurrency to
decentralized finance, benefiting millions of unbanked individuals, and serving
as the foundation of Web3, which aims to provide the next generation of the
internet with data ownership for users. The rise of NFTs has also helped
artists and creative workers to protect their intellectual property and reap
the benefits of their work. However, privacy risks associated with
permissionless blockchains have become a major concern for individuals and
institutions. The role of blockchain in the transition from Web2 to Web3 is
crucial, as it is rapidly evolving. As more individuals, institutions, and
organizations adopt this technology, it becomes increasingly important to
closely monitor the new risks associated with permissionless blockchains and
provide updated solutions to mitigate them. This paper endeavors to examine the
privacy risks inherent in permissionless blockchains, including Remote
Procedure Call (RPC) issues, Ethereum Name Service (ENS), miner extractable
value (MEV) bots, on-chain data analysis, data breaches, transaction linking,
transaction metadata, and others. The existing solutions to these privacy
risks, such as zero-knowledge proofs, ring signatures, Hyperledger Fabric, and
stealth addresses, shall be analyzed. Finally, suggestions for the future
improvement of privacy solutions in the permissionless blockchain space shall
be put forward.
</p></li>
</ul>

<h3>Title: Block Design-Based Local Differential Privacy Mechanisms. (arXiv:2305.01261v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01261">http://arxiv.org/abs/2305.01261</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01261] Block Design-Based Local Differential Privacy Mechanisms](http://arxiv.org/abs/2305.01261) #privacy</code></li>
<li>Summary: <p>In this paper, we propose a new class of local differential privacy (LDP)
schemes based on combinatorial block designs for a discrete distribution
estimation. This class not only recovers many known LDP schemes in a unified
framework of combinatorial block design, but also suggests a novel way of
finding new schemes achieving the optimal (or near-optimal) privacy-utility
trade-off with lower communication costs. Indeed, we find many new LDP schemes
that achieve both the optimal privacy-utility trade-off and the minimum
communication cost among all the unbiased schemes for a certain set of input
data size and LDP constraint. Furthermore, to partially solve the sparse
existence issue of block design schemes, we consider a broader class of LDP
schemes based on regular and pairwise-balanced designs, called RPBD schemes,
which relax one of the symmetry requirements on block designs. By considering
this broader class of RPBD schemes, we can find LDP schemes achieving
near-optimal privacy-utility trade-off with reasonably low communication costs
for a much larger set of input data size and LDP constraint.
</p></li>
</ul>

<h3>Title: SoK: Log Based Transparency Enhancing Technologies. (arXiv:2305.01378v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01378">http://arxiv.org/abs/2305.01378</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01378] SoK: Log Based Transparency Enhancing Technologies](http://arxiv.org/abs/2305.01378) #privacy</code></li>
<li>Summary: <p>This paper systematizes log based Transparency Enhancing Technologies. Based
on established work on transparency from multiple disciplines we outline the
purpose, usefulness, and pitfalls of transparency. We outline the mechanisms
that allow log based transparency enhancing technologies to be implemented, in
particular logging mechanisms, sanitisation mechanisms and the trade-offs with
privacy, data release and query mechanisms, and how transparency relates to the
external mechanisms that can provide the ability to contest a system and hold
system operators accountable. We illustrate the role these mechanisms play with
two case studies, Certificate Transparency and cryptocurrencies, and show the
role that transparency plays in their function as well as the issues these
systems face in delivering transparency.
</p></li>
</ul>

<h3>Title: Differentially Private In-Context Learning. (arXiv:2305.01639v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01639">http://arxiv.org/abs/2305.01639</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01639] Differentially Private In-Context Learning](http://arxiv.org/abs/2305.01639) #privacy</code></li>
<li>Summary: <p>An important question in deploying large language models (LLMs) is how to
augment LLMs with private data. We propose Differentially Private In-context
Learning (DP-ICL) to enable LLMs to adapt to new tasks while maintaining
privacy guarantees. DP-ICL performs private inference by establishing noisy
consensus over an ensemble of exemplars using the Report-Noisy-Max mechanism.
We evaluate DP-ICL on four benchmarks and find that it achieves comparable
performance (<2\% degradation) with non-private ICL.
</p></li>
</ul>

<h3>Title: Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees. (arXiv:2305.01588v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01588">http://arxiv.org/abs/2305.01588</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01588] Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees](http://arxiv.org/abs/2305.01588) #privacy</code></li>
<li>Summary: <p>Gradient clipping is a popular modification to standard (stochastic) gradient
descent, at every iteration limiting the gradient norm to a certain value $c
>0$. It is widely used for example for stabilizing the training of deep
learning models (Goodfellow et al., 2016), or for enforcing differential
privacy (Abadi et al., 2016). Despite popularity and simplicity of the clipping
mechanism, its convergence guarantees often require specific values of $c$ and
strong noise assumptions.
</p></li>
</ul>

<p>In this paper, we give convergence guarantees that show precise dependence on
arbitrary clipping thresholds $c$ and show that our guarantees are tight with
both deterministic and stochastic gradients. In particular, we show that (i)
for deterministic gradient descent, the clipping threshold only affects the
higher-order terms of convergence, (ii) in the stochastic setting convergence
to the true optimum cannot be guaranteed under the standard noise assumption,
even under arbitrary small step-sizes. We give matching upper and lower bounds
for convergence of the gradient norm when running clipped SGD, and illustrate
these results with experiments.
</p>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Boosting Adversarial Transferability via Fusing Logits of Top-1 Decomposed Feature. (arXiv:2305.01361v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01361">http://arxiv.org/abs/2305.01361</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01361] Boosting Adversarial Transferability via Fusing Logits of Top-1 Decomposed Feature](http://arxiv.org/abs/2305.01361) #defense</code></li>
<li>Summary: <p>Recent research has shown that Deep Neural Networks (DNNs) are highly
vulnerable to adversarial samples, which are highly transferable and can be
used to attack other unknown black-box models. To improve the transferability
of adversarial samples, several feature-based adversarial attack methods have
been proposed to disrupt neuron activation in middle layers. However, current
state-of-the-art feature-based attack methods typically require additional
computation costs for estimating the importance of neurons. To address this
challenge, we propose a Singular Value Decomposition (SVD)-based feature-level
attack method. Our approach is inspired by the discovery that eigenvectors
associated with the larger singular values decomposed from the middle layer
features exhibit superior generalization and attention properties.
Specifically, we conduct the attack by retaining the decomposed Top-1 singular
value-associated feature for computing the output logits, which are then
combined with the original logits to optimize adversarial perturbations. Our
extensive experimental results verify the effectiveness of our proposed method,
which significantly enhances the transferability of adversarial samples against
various baseline models and defense strategies.The source code of this study is
available at \href{https://anonymous.4open.science/r/SVD-SSA-13BF/README.md}.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Physical Adversarial Attacks for Surveillance: A Survey. (arXiv:2305.01074v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01074">http://arxiv.org/abs/2305.01074</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01074] Physical Adversarial Attacks for Surveillance: A Survey](http://arxiv.org/abs/2305.01074) #attack</code></li>
<li>Summary: <p>Modern automated surveillance techniques are heavily reliant on deep learning
methods. Despite the superior performance, these learning systems are
inherently vulnerable to adversarial attacks - maliciously crafted inputs that
are designed to mislead, or trick, models into making incorrect predictions. An
adversary can physically change their appearance by wearing adversarial
t-shirts, glasses, or hats or by specific behavior, to potentially avoid
various forms of detection, tracking and recognition of surveillance systems;
and obtain unauthorized access to secure properties and assets. This poses a
severe threat to the security and safety of modern surveillance systems. This
paper reviews recent attempts and findings in learning and designing physical
adversarial attacks for surveillance applications. In particular, we propose a
framework to analyze physical adversarial attacks and provide a comprehensive
survey of physical adversarial attacks on four key surveillance tasks:
detection, identification, tracking, and action recognition under this
framework. Furthermore, we review and analyze strategies to defend against the
physical adversarial attacks and the methods for evaluating the strengths of
the defense. The insights in this paper present an important step in building
resilience within surveillance systems to physical adversarial attacks.
</p></li>
</ul>

<h3>Title: DABS: Data-Agnostic Backdoor attack at the Server in Federated Learning. (arXiv:2305.01267v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01267">http://arxiv.org/abs/2305.01267</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01267] DABS: Data-Agnostic Backdoor attack at the Server in Federated Learning](http://arxiv.org/abs/2305.01267) #attack</code></li>
<li>Summary: <p>Federated learning (FL) attempts to train a global model by aggregating local
models from distributed devices under the coordination of a central server.
However, the existence of a large number of heterogeneous devices makes FL
vulnerable to various attacks, especially the stealthy backdoor attack.
Backdoor attack aims to trick a neural network to misclassify data to a target
label by injecting specific triggers while keeping correct predictions on
original training data. Existing works focus on client-side attacks which try
to poison the global model by modifying the local datasets. In this work, we
propose a new attack model for FL, namely Data-Agnostic Backdoor attack at the
Server (DABS), where the server directly modifies the global model to backdoor
an FL system. Extensive simulation results show that this attack scheme
achieves a higher attack success rate compared with baseline methods while
maintaining normal accuracy on the clean data.
</p></li>
</ul>

<h3>Title: Differential Newborn Face Morphing Attack Detection using Wavelet Scatter Network. (arXiv:2305.01294v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01294">http://arxiv.org/abs/2305.01294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01294] Differential Newborn Face Morphing Attack Detection using Wavelet Scatter Network](http://arxiv.org/abs/2305.01294) #attack</code></li>
<li>Summary: <p>Face Recognition System (FRS) are shown to be vulnerable to morphed images of
newborns. Detecting morphing attacks stemming from face images of newborn is
important to avoid unwanted consequences, both for security and society. In
this paper, we present a new reference-based/Differential Morphing Attack
Detection (MAD) method to detect newborn morphing images using Wavelet
Scattering Network (WSN). We propose a two-layer WSN with 250 $\times$ 250
pixels and six rotations of wavelets per layer, resulting in 577 paths. The
proposed approach is validated on a dataset of 852 bona fide images and 2460
morphing images constructed using face images of 42 unique newborns. The
obtained results indicate a gain of over 10\% in detection accuracy over other
existing D-MAD techniques.
</p></li>
</ul>

<h3>Title: Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01219">http://arxiv.org/abs/2305.01219</a></li>
<li>Code URL: <a href="https://github.com/shuaizhao95/prompt_attack">https://github.com/shuaizhao95/prompt_attack</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01219] Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models](http://arxiv.org/abs/2305.01219) #attack</code></li>
<li>Summary: <p>The prompt-based learning paradigm, which bridges the gap between
pre-training and fine-tuning, achieves state-of-the-art performance on several
NLP tasks, particularly in few-shot settings. Despite being widely applied,
prompt-based learning is vulnerable to backdoor attacks. Textual backdoor
attacks are designed to introduce targeted vulnerabilities into models by
poisoning a subset of training samples through trigger injection and label
modification. However, they suffer from flaws such as abnormal natural language
expressions resulting from the trigger and incorrect labeling of poisoned
samples. In this study, we propose {\bf ProAttack}, a novel and efficient
method for performing clean-label backdoor attacks based on the prompt, which
uses the prompt itself as a trigger. Our method does not require external
triggers and ensures correct labeling of poisoned samples, improving the
stealthy nature of the backdoor attack. With extensive experiments on
rich-resource and few-shot text classification tasks, we empirically validate
ProAttack's competitive performance in textual backdoor attacks. Notably, in
the rich-resource setting, ProAttack achieves state-of-the-art attack success
rates in the clean-label backdoor attack benchmark without external triggers.
All data and code used in our models are publically
available\footnote{\url{https://github.com/shuaizhao95/Prompt_attack}}.
</p></li>
</ul>

<h3>Title: Sentiment Perception Adversarial Attacks on Neural Machine Translation Systems. (arXiv:2305.01437v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01437">http://arxiv.org/abs/2305.01437</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01437] Sentiment Perception Adversarial Attacks on Neural Machine Translation Systems](http://arxiv.org/abs/2305.01437) #attack</code></li>
<li>Summary: <p>With the advent of deep learning methods, Neural Machine Translation (NMT)
systems have become increasingly powerful. However, deep learning based systems
are susceptible to adversarial attacks, where imperceptible changes to the
input can cause undesirable changes at the output of the system. To date there
has been little work investigating adversarial attacks on sequence-to-sequence
systems, such as NMT models. Previous work in NMT has examined attacks with the
aim of introducing target phrases in the output sequence. In this work,
adversarial attacks for NMT systems are explored from an output perception
perspective. Thus the aim of an attack is to change the perception of the
output sequence, without altering the perception of the input sequence. For
example, an adversary may distort the sentiment of translated reviews to have
an exaggerated positive sentiment. In practice it is challenging to run
extensive human perception experiments, so a proxy deep-learning classifier
applied to the NMT output is used to measure perception changes. Experiments
demonstrate that the sentiment perception of NMT systems' output sequences can
be changed significantly.
</p></li>
</ul>

<h3>Title: An extension of Overbeck's attack with an application to cryptanalysis of Twisted Gabidulin-based schemes. (arXiv:2305.01287v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01287">http://arxiv.org/abs/2305.01287</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01287] An extension of Overbeck's attack with an application to cryptanalysis of Twisted Gabidulin-based schemes](http://arxiv.org/abs/2305.01287) #attack</code></li>
<li>Summary: <p>In the present article, we discuss the decoding of Gabidulin and related
codes from a cryptographic perspective and we observe that these codes can be
decoded with the single knowledge of a generator matrix. Then, we extend and
revisit Gibson's and Overbeck's attacks on the generalised GPT encryption
scheme (instantiated with Gabidulin codes) for various ranks of the distortion
matrix and apply our attack to the case of an instantiation with twisted
Gabidulin codes.
</p></li>
</ul>

<h3>Title: Attacker Profiling Through Analysis of Attack Patterns in Geographically Distributed Honeypots. (arXiv:2305.01346v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01346">http://arxiv.org/abs/2305.01346</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01346] Attacker Profiling Through Analysis of Attack Patterns in Geographically Distributed Honeypots](http://arxiv.org/abs/2305.01346) #attack</code></li>
<li>Summary: <p>Honeypots are a well-known and widely used technology in the cybersecurity
community, where it is assumed that placing honeypots in different geographical
locations provides better visibility and increases effectiveness. However, how
geolocation affects the usefulness of honeypots is not well-studied, especially
for threat intelligence as early warning systems. This paper examines attack
patterns in a large public dataset of geographically distributed honeypots by
answering methodological questions and creating behavioural profiles of
attackers. Results show that the location of honeypots helps identify attack
patterns and build profiles for the attackers. We conclude that not all the
intelligence collected from geographically distributed honeypots is equally
valuable and that a good early warning system against resourceful attackers may
be built with only two distributed honeypots and a production server.
</p></li>
</ul>

<h3>Title: Two-phase Dual COPOD Method for Anomaly Detection in Industrial Control System. (arXiv:2305.00982v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.00982">http://arxiv.org/abs/2305.00982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.00982] Two-phase Dual COPOD Method for Anomaly Detection in Industrial Control System](http://arxiv.org/abs/2305.00982) #attack</code></li>
<li>Summary: <p>Critical infrastructures like water treatment facilities and power plants
depend on industrial control systems (ICS) for monitoring and control, making
them vulnerable to cyber attacks and system malfunctions. Traditional ICS
anomaly detection methods lack transparency and interpretability, which make it
difficult for practitioners to understand and trust the results. This paper
proposes a two-phase dual Copula-based Outlier Detection (COPOD) method that
addresses these challenges. The first phase removes unwanted outliers using an
empirical cumulative distribution algorithm, and the second phase develops two
parallel COPOD models based on the output data of phase 1. The method is based
on empirical distribution functions, parameter-free, and provides
interpretability by quantifying each feature's contribution to an anomaly. The
method is also computationally and memory-efficient, suitable for low- and
high-dimensional datasets. Experimental results demonstrate superior
performance in terms of F1-score and recall on three open-source ICS datasets,
enabling real-time ICS anomaly detection.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Venn Diagram Multi-label Class Interpretation of Diabetic Foot Ulcer with Color and Sharpness Enhancement. (arXiv:2305.01044v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01044">http://arxiv.org/abs/2305.01044</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01044] Venn Diagram Multi-label Class Interpretation of Diabetic Foot Ulcer with Color and Sharpness Enhancement](http://arxiv.org/abs/2305.01044) #robust</code></li>
<li>Summary: <p>DFU is a severe complication of diabetes that can lead to amputation of the
lower limb if not treated properly. Inspired by the 2021 Diabetic Foot Ulcer
Grand Challenge, researchers designed automated multi-class classification of
DFU, including infection, ischaemia, both of these conditions, and none of
these conditions. However, it remains a challenge as classification accuracy is
still not satisfactory. This paper proposes a Venn Diagram interpretation of
multi-label CNN-based method, utilizing different image enhancement strategies,
to improve the multi-class DFU classification. We propose to reduce the four
classes into two since both class wounds can be interpreted as the simultaneous
occurrence of infection and ischaemia and none class wounds as the absence of
infection and ischaemia. We introduce a novel Venn Diagram representation block
in the classifier to interpret all four classes from these two classes. To make
our model more resilient, we propose enhancing the perceptual quality of DFU
images, particularly blurry or inconsistently lit DFU images, by performing
color and sharpness enhancements on them. We also employ a fine-tuned
optimization technique, adaptive sharpness aware minimization, to improve the
CNN model generalization performance. The proposed method is evaluated on the
test dataset of DFUC2021, containing 5,734 images and the results are compared
with the top-3 winning entries of DFUC2021. Our proposed approach outperforms
these existing approaches and achieves Macro-Average F1, Recall and Precision
scores of 0.6592, 0.6593, and 0.6652, respectively.Additionally, We perform
ablation studies and image quality measurements to further interpret our
proposed method. This proposed method will benefit patients with DFUs since it
tackles the inconsistencies in captured images and can be employed for a more
robust remote DFU wound classification.
</p></li>
</ul>

<h3>Title: Stratified Adversarial Robustness with Rejection. (arXiv:2305.01139v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01139">http://arxiv.org/abs/2305.01139</a></li>
<li>Code URL: <a href="https://github.com/jfc43/stratified-adv-rej">https://github.com/jfc43/stratified-adv-rej</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01139] Stratified Adversarial Robustness with Rejection](http://arxiv.org/abs/2305.01139) #robust</code></li>
<li>Summary: <p>Recently, there is an emerging interest in adversarially training a
classifier with a rejection option (also known as a selective classifier) for
boosting adversarial robustness. While rejection can incur a cost in many
applications, existing studies typically associate zero cost with rejecting
perturbed inputs, which can result in the rejection of numerous
slightly-perturbed inputs that could be correctly classified. In this work, we
study adversarially-robust classification with rejection in the stratified
rejection setting, where the rejection cost is modeled by rejection loss
functions monotonically non-increasing in the perturbation magnitude. We
theoretically analyze the stratified rejection setting and propose a novel
defense method -- Adversarial Training with Consistent Prediction-based
Rejection (CPR) -- for building a robust selective classifier. Experiments on
image datasets demonstrate that the proposed method significantly outperforms
existing methods under strong adaptive attacks. For instance, on CIFAR-10, CPR
reduces the total robust loss (for different rejection losses) by at least 7.3%
under both seen and unseen attacks.
</p></li>
</ul>

<h3>Title: ARBEx: Attentive Feature Extraction with Reliability Balancing for Robust Facial Expression Learning. (arXiv:2305.01486v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01486">http://arxiv.org/abs/2305.01486</a></li>
<li>Code URL: <a href="https://github.com/takihasan/arbex">https://github.com/takihasan/arbex</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01486] ARBEx: Attentive Feature Extraction with Reliability Balancing for Robust Facial Expression Learning](http://arxiv.org/abs/2305.01486) #robust</code></li>
<li>Summary: <p>In this paper, we introduce a framework ARBEx, a novel attentive feature
extraction framework driven by Vision Transformer with reliability balancing to
cope against poor class distributions, bias, and uncertainty in the facial
expression learning (FEL) task. We reinforce several data pre-processing and
refinement methods along with a window-based cross-attention ViT to squeeze the
best of the data. We also employ learnable anchor points in the embedding space
with label distributions and multi-head self-attention mechanism to optimize
performance against weak predictions with reliability balancing, which is a
strategy that leverages anchor points, attention scores, and confidence values
to enhance the resilience of label predictions. To ensure correct label
classification and improve the models' discriminative power, we introduce
anchor loss, which encourages large margins between anchor points.
Additionally, the multi-head self-attention mechanism, which is also trainable,
plays an integral role in identifying accurate labels. This approach provides
critical elements for improving the reliability of predictions and has a
substantial positive effect on final prediction capabilities. Our adaptive
model can be integrated with any deep neural network to forestall challenges in
various recognition tasks. Our strategy outperforms current state-of-the-art
methodologies, according to extensive experiments conducted in a variety of
contexts.
</p></li>
</ul>

<h3>Title: Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators. (arXiv:2305.01579v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01579">http://arxiv.org/abs/2305.01579</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01579] Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators](http://arxiv.org/abs/2305.01579) #robust</code></li>
<li>Summary: <p>Most existing retrieval-augmented language models (LMs) for question
answering assume all retrieved information is factually correct. In this work,
we study a more realistic scenario in which retrieved documents may contain
misinformation, causing conflicts among them. We observe that the existing
models are highly brittle to such information in both fine-tuning and
in-context few-shot learning settings. We propose approaches to make
retrieval-augmented LMs robust to misinformation by explicitly fine-tuning a
discriminator or prompting to elicit discrimination capability in GPT-3. Our
empirical results on open-domain question answering show that these approaches
significantly improve LMs' robustness to knowledge conflicts. We also provide
our findings on interleaving the fine-tuned model's decision with the
in-context learning process, paving a new path to leverage the best of both
worlds.
</p></li>
</ul>

<h3>Title: FreeLM: Fine-Tuning-Free Language Model. (arXiv:2305.01616v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01616">http://arxiv.org/abs/2305.01616</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01616] FreeLM: Fine-Tuning-Free Language Model](http://arxiv.org/abs/2305.01616) #robust</code></li>
<li>Summary: <p>Pre-trained language models (PLMs) have achieved remarkable success in NLP
tasks. Despite the great success, mainstream solutions largely follow the
pre-training then finetuning paradigm, which brings in both high deployment
costs and low training efficiency. Nevertheless, fine-tuning on a specific task
is essential because PLMs are only pre-trained with language signal from large
raw data. In this paper, we propose a novel fine-tuning-free strategy for
language models, to consider both language signal and teacher signal. Teacher
signal is an abstraction of a battery of downstream tasks, provided in a
unified proposition format. Trained with both language and strong task-aware
teacher signals in an interactive manner, our FreeLM model demonstrates strong
generalization and robustness. FreeLM outperforms large models e.g., GPT-3 and
InstructGPT, on a range of language understanding tasks in experiments. FreeLM
is much smaller with 0.3B parameters, compared to 175B in these models.
</p></li>
</ul>

<h3>Title: Autoencoders for discovering manifold dimension and coordinates in data from complex dynamical systems. (arXiv:2305.01090v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01090">http://arxiv.org/abs/2305.01090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01090] Autoencoders for discovering manifold dimension and coordinates in data from complex dynamical systems](http://arxiv.org/abs/2305.01090) #robust</code></li>
<li>Summary: <p>While many phenomena in physics and engineering are formally
high-dimensional, their long-time dynamics often live on a lower-dimensional
manifold. The present work introduces an autoencoder framework that combines
implicit regularization with internal linear layers and $L_2$ regularization
(weight decay) to automatically estimate the underlying dimensionality of a
data set, produce an orthogonal manifold coordinate system, and provide the
mapping functions between the ambient space and manifold space, allowing for
out-of-sample projections. We validate our framework's ability to estimate the
manifold dimension for a series of datasets from dynamical systems of varying
complexities and compare to other state-of-the-art estimators. We analyze the
training dynamics of the network to glean insight into the mechanism of
low-rank learning and find that collectively each of the implicit regularizing
layers compound the low-rank representation and even self-correct during
training. Analysis of gradient descent dynamics for this architecture in the
linear case reveals the role of the internal linear layers in leading to faster
decay of a "collective weight variable" incorporating all layers, and the role
of weight decay in breaking degeneracies and thus driving convergence along
directions in which no decay would occur in its absence. We show that this
framework can be naturally extended for applications of state-space modeling
and forecasting by generating a data-driven dynamic model of a spatiotemporally
chaotic partial differential equation using only the manifold coordinates.
Finally, we demonstrate that our framework is robust to hyperparameter choices.
</p></li>
</ul>

<h3>Title: PGrad: Learning Principal Gradients For Domain Generalization. (arXiv:2305.01134v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01134">http://arxiv.org/abs/2305.01134</a></li>
<li>Code URL: <a href="https://github.com/qdata/pgrad">https://github.com/qdata/pgrad</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01134] PGrad: Learning Principal Gradients For Domain Generalization](http://arxiv.org/abs/2305.01134) #robust</code></li>
<li>Summary: <p>Machine learning models fail to perform when facing out-of-distribution (OOD)
domains, a challenging task known as domain generalization (DG). In this work,
we develop a novel DG training strategy, we call PGrad, to learn a robust
gradient direction, improving models' generalization ability on unseen domains.
The proposed gradient aggregates the principal directions of a sampled roll-out
optimization trajectory that measures the training dynamics across all training
domains. PGrad's gradient design forces the DG training to ignore
domain-dependent noise signals and updates all training domains with a robust
direction covering main components of parameter dynamics. We further improve
PGrad via bijection-based computational refinement and directional plus
length-based calibrations. Our theoretical proof connects PGrad to the spectral
analysis of Hessian in training neural networks. Experiments on DomainBed and
WILDS benchmarks demonstrate that our approach effectively enables robust DG
optimization and leads to smoothly decreased loss curves. Empirically, PGrad
achieves competitive results across seven datasets, demonstrating its efficacy
across both synthetic and real-world distributional shifts. Code is available
at https://github.com/QData/PGrad.
</p></li>
</ul>

<h3>Title: Memory of recurrent networks: Do we compute it right?. (arXiv:2305.01457v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01457">http://arxiv.org/abs/2305.01457</a></li>
<li>Code URL: <a href="https://github.com/learning-of-dynamic-processes/memorycapacity">https://github.com/learning-of-dynamic-processes/memorycapacity</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01457] Memory of recurrent networks: Do we compute it right?](http://arxiv.org/abs/2305.01457) #robust</code></li>
<li>Summary: <p>Numerical evaluations of the memory capacity (MC) of recurrent neural
networks reported in the literature often contradict well-established
theoretical bounds. In this paper, we study the case of linear echo state
networks, for which the total memory capacity has been proven to be equal to
the rank of the corresponding Kalman controllability matrix. We shed light on
various reasons for the inaccurate numerical estimations of the memory, and we
show that these issues, often overlooked in the recent literature, are of an
exclusively numerical nature. More explicitly, we prove that when the Krylov
structure of the linear MC is ignored, a gap between the theoretical MC and its
empirical counterpart is introduced. As a solution, we develop robust numerical
approaches by exploiting a result of MC neutrality with respect to the input
mask matrix. Simulations show that the memory curves that are recovered using
the proposed methods fully agree with the theory.
</p></li>
</ul>

<h3>Title: Efficient Sensitivity Analysis for Parametric Robust Markov Chains. (arXiv:2305.01473v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01473">http://arxiv.org/abs/2305.01473</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01473] Efficient Sensitivity Analysis for Parametric Robust Markov Chains](http://arxiv.org/abs/2305.01473) #robust</code></li>
<li>Summary: <p>We provide a novel method for sensitivity analysis of parametric robust
Markov chains. These models incorporate parameters and sets of probability
distributions to alleviate the often unrealistic assumption that precise
probabilities are available. We measure sensitivity in terms of partial
derivatives with respect to the uncertain transition probabilities regarding
measures such as the expected reward. As our main contribution, we present an
efficient method to compute these partial derivatives. To scale our approach to
models with thousands of parameters, we present an extension of this method
that selects the subset of $k$ parameters with the highest partial derivative.
Our methods are based on linear programming and differentiating these programs
around a given value for the parameters. The experiments show the applicability
of our approach on models with over a million states and thousands of
parameters. Moreover, we embed the results within an iterative learning scheme
that profits from having access to a dedicated sensitivity analysis.
</p></li>
</ul>

<h3>Title: Unlocking the Power of Representations in Long-term Novelty-based Exploration. (arXiv:2305.01521v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01521">http://arxiv.org/abs/2305.01521</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01521] Unlocking the Power of Representations in Long-term Novelty-based Exploration](http://arxiv.org/abs/2305.01521) #robust</code></li>
<li>Summary: <p>We introduce Robust Exploration via Clustering-based Online Density
Estimation (RECODE), a non-parametric method for novelty-based exploration that
estimates visitation counts for clusters of states based on their similarity in
a chosen embedding space. By adapting classical clustering to the nonstationary
setting of Deep RL, RECODE can efficiently track state visitation counts over
thousands of episodes. We further propose a novel generalization of the inverse
dynamics loss, which leverages masked transformer architectures for multi-step
prediction; which in conjunction with RECODE achieves a new state-of-the-art in
a suite of challenging 3D-exploration tasks in DM-Hard-8. RECODE also sets new
state-of-the-art in hard exploration Atari games, and is the first agent to
reach the end screen in "Pitfall!".
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01555">http://arxiv.org/abs/2305.01555</a></li>
<li>Code URL: <a href="https://github.com/zjunlp/DeepKE/tree/main/example/llm">https://github.com/zjunlp/DeepKE/tree/main/example/llm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01555] How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?](http://arxiv.org/abs/2305.01555) #extraction</code></li>
<li>Summary: <p>Scaling language models have revolutionized widespread NLP tasks, yet little
comprehensively explored few-shot relation extraction with large language
models. In this paper, we investigate principal methodologies, in-context
learning and data generation, for few-shot relation extraction via GPT-3.5
through exhaustive experiments. To enhance few-shot performance, we further
propose task-related instructions and schema-constrained data generation. We
observe that in-context learning can achieve performance on par with previous
prompt learning approaches, and data generation with the large language model
can boost previous solutions to obtain new state-of-the-art few-shot results on
four widely-studied relation extraction datasets. We hope our work can inspire
future research for the capabilities of large language models in few-shot
relation extraction. Code is available in
\url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
</p></li>
</ul>

<h3>Title: UNTER: A Unified Knowledge Interface for Enhancing Pre-trained Language Models. (arXiv:2305.01624v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01624">http://arxiv.org/abs/2305.01624</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01624] UNTER: A Unified Knowledge Interface for Enhancing Pre-trained Language Models](http://arxiv.org/abs/2305.01624) #extraction</code></li>
<li>Summary: <p>Recent research demonstrates that external knowledge injection can advance
pre-trained language models (PLMs) in a variety of downstream NLP tasks.
However, existing knowledge injection methods are either applicable to
structured knowledge or unstructured knowledge, lacking a unified usage. In
this paper, we propose a UNified knowledge inTERface, UNTER, to provide a
unified perspective to exploit both structured knowledge and unstructured
knowledge. In UNTER, we adopt the decoder as a unified knowledge interface,
aligning span representations obtained from the encoder with their
corresponding knowledge. This approach enables the encoder to uniformly invoke
span-related knowledge from its parameters for downstream applications.
Experimental results show that, with both forms of knowledge injected, UNTER
gains continuous improvements on a series of knowledge-driven NLP tasks,
including entity typing, named entity recognition and relation extraction,
especially in low-resource scenarios.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Neural Radiance Fields. (arXiv:2305.01163v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01163">http://arxiv.org/abs/2305.01163</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01163] Federated Neural Radiance Fields](http://arxiv.org/abs/2305.01163) #federate</code></li>
<li>Summary: <p>The ability of neural radiance fields or NeRFs to conduct accurate 3D
modelling has motivated application of the technique to scene representation.
Previous approaches have mainly followed a centralised learning paradigm, which
assumes that all training images are available on one compute node for
training. In this paper, we consider training NeRFs in a federated manner,
whereby multiple compute nodes, each having acquired a distinct set of
observations of the overall scene, learn a common NeRF in parallel. This
supports the scenario of cooperatively modelling a scene using multiple agents.
Our contribution is the first federated learning algorithm for NeRF, which
splits the training effort across multiple compute nodes and obviates the need
to pool the images at a central node. A technique based on low-rank
decomposition of NeRF layers is introduced to reduce bandwidth consumption to
transmit the model parameters for aggregation. Transferring compressed models
instead of the raw data also contributes to the privacy of the data collecting
agents.
</p></li>
</ul>

<h3>Title: Personalized Federated Learning under Mixture of Distributions. (arXiv:2305.01068v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01068">http://arxiv.org/abs/2305.01068</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01068] Personalized Federated Learning under Mixture of Distributions](http://arxiv.org/abs/2305.01068) #federate</code></li>
<li>Summary: <p>The recent trend towards Personalized Federated Learning (PFL) has garnered
significant attention as it allows for the training of models that are tailored
to each client while maintaining data privacy. However, current PFL techniques
primarily focus on modeling the conditional distribution heterogeneity (i.e.
concept shift), which can result in suboptimal performance when the
distribution of input data across clients diverges (i.e. covariate shift).
Additionally, these techniques often lack the ability to adapt to unseen data,
further limiting their effectiveness in real-world scenarios. To address these
limitations, we propose a novel approach, FedGMM, which utilizes Gaussian
mixture models (GMM) to effectively fit the input data distributions across
diverse clients. The model parameters are estimated by maximum likelihood
estimation utilizing a federated Expectation-Maximization algorithm, which is
solved in closed form and does not assume gradient similarity. Furthermore,
FedGMM possesses an additional advantage of adapting to new clients with
minimal overhead, and it also enables uncertainty quantification. Empirical
evaluations on synthetic and benchmark datasets demonstrate the superior
performance of our method in both PFL classification and novel sample
detection.
</p></li>
</ul>

<h3>Title: FedAVO: Improving Communication Efficiency in Federated Learning with African Vultures Optimizer. (arXiv:2305.01154v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01154">http://arxiv.org/abs/2305.01154</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01154] FedAVO: Improving Communication Efficiency in Federated Learning with African Vultures Optimizer](http://arxiv.org/abs/2305.01154) #federate</code></li>
<li>Summary: <p>Federated Learning (FL), a distributed machine learning technique has
recently experienced tremendous growth in popularity due to its emphasis on
user data privacy. However, the distributed computations of FL can result in
constrained communication and drawn-out learning processes, necessitating the
client-server communication cost optimization. The ratio of chosen clients and
the quantity of local training passes are two hyperparameters that have a
significant impact on FL performance. Due to different training preferences
across various applications, it can be difficult for FL practitioners to
manually select such hyperparameters. In our research paper, we introduce
FedAVO, a novel FL algorithm that enhances communication effectiveness by
selecting the best hyperparameters leveraging the African Vulture Optimizer
(AVO). Our research demonstrates that the communication costs associated with
FL operations can be substantially reduced by adopting AVO for FL
hyperparameter adjustment. Through extensive evaluations of FedAVO on benchmark
datasets, we show that FedAVO achieves significant improvement in terms of
model accuracy and communication round, particularly with realistic cases of
Non-IID datasets. Our extensive evaluation of the FedAVO algorithm identifies
the optimal hyperparameters that are appropriately fitted for the benchmark
datasets, eventually increasing global model accuracy by 6% in comparison to
the state-of-the-art FL algorithms (such as FedAvg, FedProx, FedPSO, etc.).
</p></li>
</ul>

<h3>Title: Dynamic Scheduling for Federated Edge Learning with Streaming Data. (arXiv:2305.01238v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01238">http://arxiv.org/abs/2305.01238</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01238] Dynamic Scheduling for Federated Edge Learning with Streaming Data](http://arxiv.org/abs/2305.01238) #federate</code></li>
<li>Summary: <p>In this work, we consider a Federated Edge Learning (FEEL) system where
training data are randomly generated over time at a set of distributed edge
devices with long-term energy constraints. Due to limited communication
resources and latency requirements, only a subset of devices is scheduled for
participating in the local training process in every iteration. We formulate a
stochastic network optimization problem for designing a dynamic scheduling
policy that maximizes the time-average data importance from scheduled user sets
subject to energy consumption and latency constraints. Our proposed algorithm
based on the Lyapunov optimization framework outperforms alternative methods
without considering time-varying data importance, especially when the
generation of training data shows strong temporal correlation.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: On the Impact of Data Quality on Image Classification Fairness. (arXiv:2305.01595v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01595">http://arxiv.org/abs/2305.01595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01595] On the Impact of Data Quality on Image Classification Fairness](http://arxiv.org/abs/2305.01595) #fair</code></li>
<li>Summary: <p>With the proliferation of algorithmic decision-making, increased scrutiny has
been placed on these systems. This paper explores the relationship between the
quality of the training data and the overall fairness of the models trained
with such data in the context of supervised classification. We measure key
fairness metrics across a range of algorithms over multiple image
classification datasets that have a varying level of noise in both the labels
and the training data itself. We describe noise in the labels as inaccuracies
in the labelling of the data in the training set and noise in the data as
distortions in the data, also in the training set. By adding noise to the
original datasets, we can explore the relationship between the quality of the
training data and the fairness of the output of the models trained on that
data.
</p></li>
</ul>

<h3>Title: Are demographically invariant models and representations in medical imaging fair?. (arXiv:2305.01397v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01397">http://arxiv.org/abs/2305.01397</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01397] Are demographically invariant models and representations in medical imaging fair?](http://arxiv.org/abs/2305.01397) #fair</code></li>
<li>Summary: <p>Medical imaging models have been shown to encode information about patient
demographics (age, race, sex) in their latent representation, raising concerns
about their potential for discrimination. Here, we ask whether it is feasible
and desirable to train models that do not encode demographic attributes. We
consider different types of invariance with respect to demographic attributes -
marginal, class-conditional, and counterfactual model invariance - and lay out
their equivalence to standard notions of algorithmic fairness. Drawing on
existing theory, we find that marginal and class-conditional invariance can be
considered overly restrictive approaches for achieving certain fairness
notions, resulting in significant predictive performance losses. Concerning
counterfactual model invariance, we note that defining medical image
counterfactuals with respect to demographic attributes is fraught with
complexities. Finally, we posit that demographic encoding may even be
considered advantageous if it enables learning a task-specific encoding of
demographic features that does not rely on human-constructed categories such as
'race' and 'gender'. We conclude that medical imaging models may need to encode
demographic attributes, lending further urgency to calls for comprehensive
model fairness assessments in terms of predictive performance.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Logion: Machine Learning for Greek Philology. (arXiv:2305.01099v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01099">http://arxiv.org/abs/2305.01099</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01099] Logion: Machine Learning for Greek Philology](http://arxiv.org/abs/2305.01099) #interpretability</code></li>
<li>Summary: <p>This paper presents machine-learning methods to address various problems in
Greek philology. After training a BERT model on the largest premodern Greek
dataset used for this purpose to date, we identify and correct previously
undetected errors made by scribes in the process of textual transmission, in
what is, to our knowledge, the first successful identification of such errors
via machine learning. Additionally, we demonstrate the model's capacity to fill
gaps caused by material deterioration of premodern manuscripts and compare the
model's performance to that of a domain expert. We find that best performance
is achieved when the domain expert is provided with model suggestions for
inspiration. With such human-computer collaborations in mind, we explore the
model's interpretability and find that certain attention heads appear to encode
select grammatical features of premodern Greek.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: In-Context Learning Unlocked for Diffusion Models. (arXiv:2305.01115v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01115">http://arxiv.org/abs/2305.01115</a></li>
<li>Code URL: <a href="https://github.com/zhendong-wang/prompt-diffusion">https://github.com/zhendong-wang/prompt-diffusion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01115] In-Context Learning Unlocked for Diffusion Models](http://arxiv.org/abs/2305.01115) #diffusion</code></li>
<li>Summary: <p>We present Prompt Diffusion, a framework for enabling in-context learning in
diffusion-based generative models. Given a pair of task-specific example
images, such as depth from/to image and scribble from/to image, and a text
guidance, our model automatically understands the underlying task and performs
the same task on a new query image following the text guidance. To achieve
this, we propose a vision-language prompt that can model a wide range of
vision-language tasks and a diffusion model that takes it as input. The
diffusion model is trained jointly over six different tasks using these
prompts. The resulting Prompt Diffusion model is the first diffusion-based
vision-language foundation model capable of in-context learning. It
demonstrates high-quality in-context generation on the trained tasks and
generalizes effectively to new, unseen vision tasks with their respective
prompts. Our model also shows compelling text-guided image editing results. Our
framework, with code publicly available at
https://github.com/Zhendong-Wang/Prompt-Diffusion, aims to facilitate research
into in-context learning for computer vision.
</p></li>
</ul>

<h3>Title: DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling. (arXiv:2305.01257v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01257">http://arxiv.org/abs/2305.01257</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01257] DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling](http://arxiv.org/abs/2305.01257) #diffusion</code></li>
<li>Summary: <p>We introduce DreamPaint, a framework to intelligently inpaint any e-commerce
product on any user-provided context image. The context image can be, for
example, the user's own image for virtual try-on of clothes from the e-commerce
catalog on themselves, the user's room image for virtual try-on of a piece of
furniture from the e-commerce catalog in their room, etc. As opposed to
previous augmented-reality (AR)-based virtual try-on methods, DreamPaint does
not use, nor does it require, 3D modeling of neither the e-commerce product nor
the user context. Instead, it directly uses 2D images of the product as
available in product catalog database, and a 2D picture of the context, for
example taken from the user's phone camera. The method relies on few-shot fine
tuning a pre-trained diffusion model with the masked latents (e.g., Masked
DreamBooth) of the catalog images per item, whose weights are then loaded on a
pre-trained inpainting module that is capable of preserving the characteristics
of the context image. DreamPaint allows to preserve both the product image and
the context (environment/user) image without requiring text guidance to
describe the missing part (product/context). DreamPaint also allows to
intelligently infer the best 3D angle of the product to place at the desired
location on the user context, even if that angle was previously unseen in the
product's reference 2D images. We compare our results against both text-guided
and image-guided inpainting modules and show that DreamPaint yields superior
performance in both subjective human study and quantitative metrics.
</p></li>
</ul>

<h3>Title: ContactArt: Learning 3D Interaction Priors for Category-level Articulated Object and Hand Poses Estimation. (arXiv:2305.01618v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01618">http://arxiv.org/abs/2305.01618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01618] ContactArt: Learning 3D Interaction Priors for Category-level Articulated Object and Hand Poses Estimation](http://arxiv.org/abs/2305.01618) #diffusion</code></li>
<li>Summary: <p>We propose a new dataset and a novel approach to learning hand-object
interaction priors for hand and articulated object pose estimation. We first
collect a dataset using visual teleoperation, where the human operator can
directly play within a physical simulator to manipulate the articulated
objects. We record the data and obtain free and accurate annotations on object
poses and contact information from the simulator. Our system only requires an
iPhone to record human hand motion, which can be easily scaled up and largely
lower the costs of data and annotation collection. With this data, we learn 3D
interaction priors including a discriminator (in a GAN) capturing the
distribution of how object parts are arranged, and a diffusion model which
generates the contact regions on articulated objects, guiding the hand pose
estimation. Such structural and contact priors can easily transfer to
real-world data with barely any domain gap. By using our data and learned
priors, our method significantly improves the performance on joint hand and
articulated object poses estimation over the existing state-of-the-art methods.
The project is available at https://zehaozhu.github.io/ContactArt/ .
</p></li>
</ul>

<h3>Title: Geometric Latent Diffusion Models for 3D Molecule Generation. (arXiv:2305.01140v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01140">http://arxiv.org/abs/2305.01140</a></li>
<li>Code URL: <a href="https://github.com/minkaixu/geoldm">https://github.com/minkaixu/geoldm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01140] Geometric Latent Diffusion Models for 3D Molecule Generation](http://arxiv.org/abs/2305.01140) #diffusion</code></li>
<li>Summary: <p>Generative models, especially diffusion models (DMs), have achieved promising
results for generating feature-rich geometries and advancing foundational
science problems such as molecule design. Inspired by the recent huge success
of Stable (latent) Diffusion models, we propose a novel and principled method
for 3D molecule generation named Geometric Latent Diffusion Models (GeoLDM).
GeoLDM is the first latent DM model for the molecular geometry domain, composed
of autoencoders encoding structures into continuous latent codes and DMs
operating in the latent space. Our key innovation is that for modeling the 3D
molecular geometries, we capture its critical roto-translational equivariance
constraints by building a point-structured latent space with both invariant
scalars and equivariant tensors. Extensive experiments demonstrate that GeoLDM
can consistently achieve better performance on multiple molecule generation
benchmarks, with up to 7\% improvement for the valid percentage of large
biomolecules. Results also demonstrate GeoLDM's higher capacity for
controllable generation thanks to the latent modeling. Code is provided at
\url{https://github.com/MinkaiXu/GeoLDM}.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: PU-EdgeFormer: Edge Transformer for Dense Prediction in Point Cloud Upsampling. (arXiv:2305.01148v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01148">http://arxiv.org/abs/2305.01148</a></li>
<li>Code URL: <a href="https://github.com/dohoon2045/pu-edgeformer">https://github.com/dohoon2045/pu-edgeformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01148] PU-EdgeFormer: Edge Transformer for Dense Prediction in Point Cloud Upsampling](http://arxiv.org/abs/2305.01148) #transformer</code></li>
<li>Summary: <p>Despite the recent development of deep learning-based point cloud upsampling,
most MLP-based point cloud upsampling methods have limitations in that it is
difficult to train the local and global structure of the point cloud at the
same time. To solve this problem, we present a combined graph convolution and
transformer for point cloud upsampling, denoted by PU-EdgeFormer. The proposed
method constructs EdgeFormer unit that consists of graph convolution and
multi-head self-attention modules. We employ graph convolution using EdgeConv,
which learns the local geometry and global structure of point cloud better than
existing point-to-feature method. Through in-depth experiments, we confirmed
that the proposed method has better point cloud upsampling performance than the
existing state-of-the-art method in both subjective and objective aspects. The
code is available at https://github.com/dohoon2045/PU-EdgeFormer.
</p></li>
</ul>

<h3>Title: Exploring vision transformer layer choosing for semantic segmentation. (arXiv:2305.01279v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01279">http://arxiv.org/abs/2305.01279</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01279] Exploring vision transformer layer choosing for semantic segmentation](http://arxiv.org/abs/2305.01279) #transformer</code></li>
<li>Summary: <p>Extensive work has demonstrated the effectiveness of Vision Transformers. The
plain Vision Transformer tends to obtain multi-scale features by selecting
fixed layers, or the last layer of features aiming to achieve higher
performance in dense prediction tasks. However, this selection is often based
on manual operation. And different samples often exhibit different features at
different layers (e.g., edge, structure, texture, detail, etc.). This requires
us to seek a dynamic adaptive fusion method to filter different layer features.
In this paper, unlike previous encoder and decoder work, we design a neck
network for adaptive fusion and feature selection, called ViTController. We
validate the effectiveness of our method on different datasets and models and
surpass previous state-of-the-art methods. Finally, our method can also be used
as a plug-in module and inserted into different networks.
</p></li>
</ul>

<h3>Title: AxWin Transformer: A Context-Aware Vision Transformer Backbone with Axial Windows. (arXiv:2305.01280v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01280">http://arxiv.org/abs/2305.01280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01280] AxWin Transformer: A Context-Aware Vision Transformer Backbone with Axial Windows](http://arxiv.org/abs/2305.01280) #transformer</code></li>
<li>Summary: <p>Recently Transformer has shown good performance in several vision tasks due
to its powerful modeling capabilities. To reduce the quadratic complexity
caused by the attention, some outstanding work restricts attention to local
regions or extends axial interactions. However, these methos often lack the
interaction of local and global information, balancing coarse and fine-grained
information. To address this problem, we propose AxWin Attention, which models
context information in both local windows and axial views. Based on the AxWin
Attention, we develop a context-aware vision transformer backbone, named AxWin
Transformer, which outperforming the state-of-the-art methods in both
classification and downstream segmentation and detection tasks.
</p></li>
</ul>

<h3>Title: Scalable Mask Annotation for Video Text Spotting. (arXiv:2305.01443v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01443">http://arxiv.org/abs/2305.01443</a></li>
<li>Code URL: <a href="https://github.com/vitae-transformer/samtext">https://github.com/vitae-transformer/samtext</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01443] Scalable Mask Annotation for Video Text Spotting](http://arxiv.org/abs/2305.01443) #transformer</code></li>
<li>Summary: <p>Video text spotting refers to localizing, recognizing, and tracking textual
elements such as captions, logos, license plates, signs, and other forms of
text within consecutive video frames. However, current datasets available for
this task rely on quadrilateral ground truth annotations, which may result in
including excessive background content and inaccurate text boundaries.
Furthermore, methods trained on these datasets often produce prediction results
in the form of quadrilateral boxes, which limits their ability to handle
complex scenarios such as dense or curved text. To address these issues, we
propose a scalable mask annotation pipeline called SAMText for video text
spotting. SAMText leverages the SAM model to generate mask annotations for
scene text images or video frames at scale. Using SAMText, we have created a
large-scale dataset, SAMText-9M, that contains over 2,400 video clips sourced
from existing datasets and over 9 million mask annotations. We have also
conducted a thorough statistical analysis of the generated masks and their
quality, identifying several research topics that could be further explored
based on this dataset. The code and dataset will be released at
\url{https://github.com/ViTAE-Transformer/SAMText}.
</p></li>
</ul>

<h3>Title: Sequence Modeling with Multiresolution Convolutional Memory. (arXiv:2305.01638v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01638">http://arxiv.org/abs/2305.01638</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01638] Sequence Modeling with Multiresolution Convolutional Memory](http://arxiv.org/abs/2305.01638) #transformer</code></li>
<li>Summary: <p>Efficiently capturing the long-range patterns in sequential data sources
salient to a given task -- such as classification and generative modeling --
poses a fundamental challenge. Popular approaches in the space tradeoff between
the memory burden of brute-force enumeration and comparison, as in
transformers, the computational burden of complicated sequential dependencies,
as in recurrent neural networks, or the parameter burden of convolutional
networks with many or large filters. We instead take inspiration from
wavelet-based multiresolution analysis to define a new building block for
sequence modeling, which we call a MultiresLayer. The key component of our
model is the multiresolution convolution, capturing multiscale trends in the
input sequence. Our MultiresConv can be implemented with shared filters across
a dilated causal convolution tree. Thus it garners the computational advantages
of convolutional networks and the principled theoretical motivation of wavelet
decompositions. Our MultiresLayer is straightforward to implement, requires
significantly fewer parameters, and maintains at most a $\mathcal{O}(N\log N)$
memory footprint for a length $N$ sequence. Yet, by stacking such layers, our
model yields state-of-the-art performance on a number of sequence
classification and autoregressive density estimation tasks using CIFAR-10,
ListOps, and PTB-XL datasets.
</p></li>
</ul>

<h3>Title: Company classification using zero-shot learning. (arXiv:2305.01028v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01028">http://arxiv.org/abs/2305.01028</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01028] Company classification using zero-shot learning](http://arxiv.org/abs/2305.01028) #transformer</code></li>
<li>Summary: <p>In recent years, natural language processing (NLP) has become increasingly
important in a variety of business applications, including sentiment analysis,
text classification, and named entity recognition. In this paper, we propose an
approach for company classification using NLP and zero-shot learning. Our
method utilizes pre-trained transformer models to extract features from company
descriptions, and then applies zero-shot learning to classify companies into
relevant categories without the need for specific training data for each
category. We evaluate our approach on publicly available datasets of textual
descriptions of companies, and demonstrate that it can streamline the process
of company classification, thereby reducing the time and resources required in
traditional approaches such as the Global Industry Classification Standard
(GICS). The results show that this method has potential for automation of
company classification, making it a promising avenue for future research in
this area.
</p></li>
</ul>

<h3>Title: ADVISE: AI-accelerated Design of Evidence Synthesis for Global Development. (arXiv:2305.01145v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01145">http://arxiv.org/abs/2305.01145</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01145] ADVISE: AI-accelerated Design of Evidence Synthesis for Global Development](http://arxiv.org/abs/2305.01145) #transformer</code></li>
<li>Summary: <p>When designing evidence-based policies and programs, decision-makers must
distill key information from a vast and rapidly growing literature base.
Identifying relevant literature from raw search results is time and resource
intensive, and is often done by manual screening. In this study, we develop an
AI agent based on a bidirectional encoder representations from transformers
(BERT) model and incorporate it into a human team designing an evidence
synthesis product for global development. We explore the effectiveness of the
human-AI hybrid team in accelerating the evidence synthesis process. To further
improve team efficiency, we enhance the human-AI hybrid team through active
learning (AL). Specifically, we explore different sampling strategies,
including random sampling, least confidence (LC) sampling, and highest priority
(HP) sampling, to study their influence on the collaborative screening process.
Results show that incorporating the BERT-based AI agent into the human team can
reduce the human screening effort by 68.5% compared to the case of no AI
assistance and by 16.8% compared to the case of using a support vector machine
(SVM)-based AI agent for identifying 80% of all relevant documents. When we
apply the HP sampling strategy for AL, the human screening effort can be
reduced even more: by 78.3% for identifying 80% of all relevant documents
compared to no AI assistance. We apply the AL-enhanced human-AI hybrid teaming
workflow in the design process of three evidence gap maps (EGMs) for USAID and
find it to be highly effective. These findings demonstrate how AI can
accelerate the development of evidence synthesis products and promote timely
evidence-based decision making in global development in a human-AI hybrid
teaming context.
</p></li>
</ul>

<h3>Title: MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset. (arXiv:2305.01211v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01211">http://arxiv.org/abs/2305.01211</a></li>
<li>Code URL: <a href="https://github.com/tobiasbrugger/multilegalsbd">https://github.com/tobiasbrugger/multilegalsbd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01211] MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset](http://arxiv.org/abs/2305.01211) #transformer</code></li>
<li>Summary: <p>Sentence Boundary Detection (SBD) is one of the foundational building blocks
of Natural Language Processing (NLP), with incorrectly split sentences heavily
influencing the output quality of downstream tasks. It is a challenging task
for algorithms, especially in the legal domain, considering the complex and
different sentence structures used. In this work, we curated a diverse
multilingual legal dataset consisting of over 130'000 annotated sentences in 6
languages. Our experimental results indicate that the performance of existing
SBD models is subpar on multilingual legal data. We trained and tested
monolingual and multilingual models based on CRF, BiLSTM-CRF, and transformers,
demonstrating state-of-the-art performance. We also show that our multilingual
models outperform all baselines in the zero-shot setting on a Portuguese test
set. To encourage further research and development by the community, we have
made our dataset, models, and code publicly available.
</p></li>
</ul>

<h3>Title: Unlimiformer: Long-Range Transformers with Unlimited Length Input. (arXiv:2305.01625v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01625">http://arxiv.org/abs/2305.01625</a></li>
<li>Code URL: <a href="https://github.com/abertsch72/unlimiformer">https://github.com/abertsch72/unlimiformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01625] Unlimiformer: Long-Range Transformers with Unlimited Length Input](http://arxiv.org/abs/2305.01625) #transformer</code></li>
<li>Summary: <p>Transformer-based models typically have a predefined bound to their input
length, because of their need to potentially attend to every token in the
input. In this work, we propose Unlimiformer: a general approach that can wrap
any existing pretrained encoder-decoder transformer, and offload the attention
computation across all layers to a single $k$-nearest-neighbor index; this
index can be kept on either the GPU or CPU memory and queried in sub-linear
time. This way, we can index extremely long input sequences, while every
attention head in every decoder layer retrieves its top-$k$ keys, instead of
attending to every key. We demonstrate Unlimiformers's efficacy on several
long-document and multi-document summarization benchmarks, showing that it can
summarize even 350k token-long inputs from the BookSum dataset, without any
input truncation at test time. Unlimiformer improves pretrained models such as
BART and Longformer by extending them to unlimited inputs without additional
learned weights and without modifying their code. We make our code and models
publicly available at https://github.com/abertsch72/unlimiformer .
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Learning Structured Output Representations from Attributes using Deep Conditional Generative Models. (arXiv:2305.00980v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.00980">http://arxiv.org/abs/2305.00980</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.00980] Learning Structured Output Representations from Attributes using Deep Conditional Generative Models](http://arxiv.org/abs/2305.00980) #generative</code></li>
<li>Summary: <p>Structured output representation is a generative task explored in computer
vision that often times requires the mapping of low dimensional features to
high dimensional structured outputs. Losses in complex spatial information in
deterministic approaches such as Convolutional Neural Networks (CNN) lead to
uncertainties and ambiguous structures within a single output representation. A
probabilistic approach through deep Conditional Generative Models (CGM) is
presented by Sohn et al. in which a particular model known as the Conditional
Variational Auto-encoder (CVAE) is introduced and explored. While the original
paper focuses on the task of image segmentation, this paper adopts the CVAE
framework for the task of controlled output representation through attributes.
This approach allows us to learn a disentangled multimodal prior distribution,
resulting in more controlled and robust approach to sample generation. In this
work we recreate the CVAE architecture and train it on images conditioned on
various attributes obtained from two image datasets; the Large-scale CelebFaces
Attributes (CelebA) dataset and the Caltech-UCSD Birds (CUB-200-2011) dataset.
We attempt to generate new faces with distinct attributes such as hair color
and glasses, as well as different bird species samples with various attributes.
We further introduce strategies for improving generalized sample generation by
applying a weighted term to the variational lower bound.
</p></li>
</ul>

<h3>Title: AutoColor: Learned Light Power Control for Multi-Color Holograms. (arXiv:2305.01611v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01611">http://arxiv.org/abs/2305.01611</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01611] AutoColor: Learned Light Power Control for Multi-Color Holograms](http://arxiv.org/abs/2305.01611) #generative</code></li>
<li>Summary: <p>Multi-color holograms rely on simultaneous illumination from multiple light
sources. These multi-color holograms could utilize light sources better than
conventional single-color holograms and can improve the dynamic range of
holographic displays. In this letter, we introduce \projectname, the first
learned method for estimating the optimal light source powers required for
illuminating multi-color holograms. For this purpose, we establish the first
multi-color hologram dataset using synthetic images and their depth
information. We generate these synthetic images using a trending pipeline
combining generative, large language, and monocular depth estimation models.
Finally, we train our learned model using our dataset and experimentally
demonstrate that \projectname significantly decreases the number of steps
required to optimize multi-color holograms from $>1000$ to $70$ iteration steps
without compromising image quality.
</p></li>
</ul>

<h3>Title: Generalizing Dataset Distillation via Deep Generative Prior. (arXiv:2305.01649v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01649">http://arxiv.org/abs/2305.01649</a></li>
<li>Code URL: <a href="https://github.com/georgecazenavette/glad">https://github.com/georgecazenavette/glad</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01649] Generalizing Dataset Distillation via Deep Generative Prior](http://arxiv.org/abs/2305.01649) #generative</code></li>
<li>Summary: <p>Dataset Distillation aims to distill an entire dataset's knowledge into a few
synthetic images. The idea is to synthesize a small number of synthetic data
points that, when given to a learning algorithm as training data, result in a
model approximating one trained on the original data. Despite recent progress
in the field, existing dataset distillation methods fail to generalize to new
architectures and scale to high-resolution datasets. To overcome the above
issues, we propose to use the learned prior from pre-trained deep generative
models to synthesize the distilled data. To achieve this, we present a new
optimization algorithm that distills a large number of images into a few
intermediate feature vectors in the generative model's latent space. Our method
augments existing techniques, significantly improving cross-architecture
generalization in all settings.
</p></li>
</ul>

<h3>Title: Humans as Light Bulbs: 3D Human Reconstruction from Thermal Reflection. (arXiv:2305.01652v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01652">http://arxiv.org/abs/2305.01652</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01652] Humans as Light Bulbs: 3D Human Reconstruction from Thermal Reflection](http://arxiv.org/abs/2305.01652) #generative</code></li>
<li>Summary: <p>The relatively hot temperature of the human body causes people to turn into
long-wave infrared light sources. Since this emitted light has a larger
wavelength than visible light, many surfaces in typical scenes act as infrared
mirrors with strong specular reflections. We exploit the thermal reflections of
a person onto objects in order to locate their position and reconstruct their
pose, even if they are not visible to a normal camera. We propose an
analysis-by-synthesis framework that jointly models the objects, people, and
their thermal reflections, which allows us to combine generative models with
differentiable rendering of reflections. Quantitative and qualitative
experiments show our approach works in highly challenging cases, such as with
curved mirrors or when the person is completely unseen by a normal camera.
</p></li>
</ul>

<h3>Title: The Role of Summarization in Generative Agents: A Preliminary Perspective. (arXiv:2305.01253v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01253">http://arxiv.org/abs/2305.01253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01253] The Role of Summarization in Generative Agents: A Preliminary Perspective](http://arxiv.org/abs/2305.01253) #generative</code></li>
<li>Summary: <p>Generative agents that simulate human society show tremendous potential for
further research and practical applications. Specifically, the generative agent
architecture comprising several meticulously designed modules constitutes the
most critical component. To facilitate progress in this research, this report
presents our integrated perspective on comprehending generative agents through
summarization, since we believe summarization is the most fundamental and
indispensable capacity of generative agents manifested across diverse
scenarios. We hope this report can provide insight into understanding the
importance of summarization capacity in generative agents and motivate future
research.
</p></li>
</ul>

<h3>Title: Turning Flowchart into Dialog: Plan-based Data Augmentation for Low-Resource Flowchart-grounded Troubleshooting Dialogs. (arXiv:2305.01323v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01323">http://arxiv.org/abs/2305.01323</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01323] Turning Flowchart into Dialog: Plan-based Data Augmentation for Low-Resource Flowchart-grounded Troubleshooting Dialogs](http://arxiv.org/abs/2305.01323) #generative</code></li>
<li>Summary: <p>Flowchart-grounded troubleshooting dialogue (FTD) systems, which follow the
instructions of a flowchart to diagnose users' problems in specific domains
(eg., vehicle, laptop), have been gaining research interest in recent years.
However, collecting sufficient dialogues that are naturally grounded on
flowcharts is costly, thus FTD systems are impeded by scarce training data. To
mitigate the data sparsity issue, we propose a plan-based data augmentation
(PlanDA) approach that generates diverse synthetic dialog data at scale by
transforming concise flowchart into dialogues. Specifically, its generative
model employs a variational-base framework with a hierarchical planning
strategy that includes global and local latent planning variables. Experiments
on the FloDial dataset show that synthetic dialogue produced by PlanDA improves
the performance of downstream tasks, including flowchart path retrieval and
response generation, in particular on the Out-of-Flowchart settings. In
addition, further analysis demonstrate the quality of synthetic data generated
by PlanDA in paths that are covered by current sample dialogues and paths that
are not covered.
</p></li>
</ul>

<h3>Title: Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks. (arXiv:2305.01626v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01626">http://arxiv.org/abs/2305.01626</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01626] Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks](http://arxiv.org/abs/2305.01626) #generative</code></li>
<li>Summary: <p>Computational models of syntax are predominantly text-based. Here we propose
that basic syntax can be modeled directly from raw speech in a fully
unsupervised way. We focus on one of the most ubiquitous and basic properties
of syntax -- concatenation. We introduce spontaneous concatenation: a
phenomenon where convolutional neural networks (CNNs) trained on acoustic
recordings of individual words start generating outputs with two or even three
words concatenated without ever accessing data with multiple words in the
input. Additionally, networks trained on two words learn to embed words into
novel unobserved word combinations. To our knowledge, this is a previously
unreported property of CNNs trained on raw speech in the Generative Adversarial
Network setting and has implications both for our understanding of how these
architectures learn as well as for modeling syntax and its evolution from raw
acoustic inputs.
</p></li>
</ul>

<h3>Title: The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers. (arXiv:2305.01628v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01628">http://arxiv.org/abs/2305.01628</a></li>
<li>Code URL: <a href="https://github.com/ibm/auto-contrastive-generation">https://github.com/ibm/auto-contrastive-generation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01628] The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers](http://arxiv.org/abs/2305.01628) #generative</code></li>
<li>Summary: <p>Applying language models to natural language processing tasks typically
relies on the representations in the final model layer, as intermediate hidden
layer representations are presumed to be less informative. In this work, we
argue that due to the gradual improvement across model layers, additional
information can be gleaned from the contrast between higher and lower layers
during inference. Specifically, in choosing between the probable next token
predictions of a generative model, the predictions of lower layers can be used
to highlight which candidates are best avoided. We propose a novel approach
that utilizes the contrast between layers to improve text generation outputs,
and show that it mitigates degenerative behaviors of the model in open-ended
generation, significantly improving the quality of generated texts.
Furthermore, our results indicate that contrasting between model layers at
inference time can yield substantial benefits to certain aspects of general
language model capabilities, more effectively extracting knowledge during
inference from a given set of model parameters.
</p></li>
</ul>

<h3>Title: On the use of Deep Generative Models for Perfect Prognosis Climate Downscaling. (arXiv:2305.00974v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.00974">http://arxiv.org/abs/2305.00974</a></li>
<li>Code URL: <a href="https://github.com/jgonzalezab/cvae-pp-downscaling">https://github.com/jgonzalezab/cvae-pp-downscaling</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.00974] On the use of Deep Generative Models for Perfect Prognosis Climate Downscaling](http://arxiv.org/abs/2305.00974) #generative</code></li>
<li>Summary: <p>Deep Learning has recently emerged as a perfect prognosis downscaling
technique to compute high-resolution fields from large-scale coarse atmospheric
data. Despite their promising results to reproduce the observed local
variability, they are based on the estimation of independent distributions at
each location, which leads to deficient spatial structures, especially when
downscaling precipitation. This study proposes the use of generative models to
improve the spatial consistency of the high-resolution fields, very demanded by
some sectoral applications (e.g., hydrology) to tackle climate change.
</p></li>
</ul>

<h3>Title: Computing Expected Motif Counts for Exchangeable Graph Generative Models. (arXiv:2305.01089v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01089">http://arxiv.org/abs/2305.01089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01089] Computing Expected Motif Counts for Exchangeable Graph Generative Models](http://arxiv.org/abs/2305.01089) #generative</code></li>
<li>Summary: <p>Estimating the expected value of a graph statistic is an important inference
task for using and learning graph models. This note presents a scalable
estimation procedure for expected motif counts, a widely used type of graph
statistic. The procedure applies for generative mixture models of the type used
in neural and Bayesian approaches to graph data.
</p></li>
</ul>

<h3>Title: Solving Inverse Problems with Score-Based Generative Priors learned from Noisy Data. (arXiv:2305.01166v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01166">http://arxiv.org/abs/2305.01166</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01166] Solving Inverse Problems with Score-Based Generative Priors learned from Noisy Data](http://arxiv.org/abs/2305.01166) #generative</code></li>
<li>Summary: <p>We present SURE-Score: an approach for learning score-based generative models
using training samples corrupted by additive Gaussian noise. When a large
training set of clean samples is available, solving inverse problems via
score-based (diffusion) generative models trained on the underlying
fully-sampled data distribution has recently been shown to outperform
end-to-end supervised deep learning. In practice, such a large collection of
training data may be prohibitively expensive to acquire in the first place. In
this work, we present an approach for approximately learning a score-based
generative model of the clean distribution, from noisy training data. We
formulate and justify a novel loss function that leverages Stein's unbiased
risk estimate to jointly denoise the data and learn the score function via
denoising score matching, while using only the noisy samples. We demonstrate
the generality of SURE-Score by learning priors and applying posterior sampling
to ill-posed inverse problems in two practical applications from different
domains: compressive wireless multiple-input multiple-output channel estimation
and accelerated 2D multi-coil magnetic resonance imaging reconstruction, where
we demonstrate competitive reconstruction performance when learning at
signal-to-noise ratio values of 0 and 10 dB, respectively.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Evaluating statistical language models as pragmatic reasoners. (arXiv:2305.01020v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01020">http://arxiv.org/abs/2305.01020</a></li>
<li>Code URL: <a href="https://github.com/benlipkin/probsem">https://github.com/benlipkin/probsem</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01020] Evaluating statistical language models as pragmatic reasoners](http://arxiv.org/abs/2305.01020) #large language model</code></li>
<li>Summary: <p>The relationship between communicated language and intended meaning is often
probabilistic and sensitive to context. Numerous strategies attempt to estimate
such a mapping, often leveraging recursive Bayesian models of communication. In
parallel, large language models (LLMs) have been increasingly applied to
semantic parsing applications, tasked with inferring logical representations
from natural language. While existing LLM explorations have been largely
restricted to literal language use, in this work, we evaluate the capacity of
LLMs to infer the meanings of pragmatic utterances. Specifically, we explore
the case of threshold estimation on the gradable adjective ``strong'',
contextually conditioned on a strength prior, then extended to composition with
qualification, negation, polarity inversion, and class comparison. We find that
LLMs can derive context-grounded, human-like distributions over the
interpretations of several complex pragmatic utterances, yet struggle composing
with negation. These results inform the inferential capacity of statistical
language models, and their use in pragmatic and semantic parsing applications.
All corresponding code is made publicly available
(https://github.com/benlipkin/probsem/tree/CogSci2023).
</p></li>
</ul>

<h3>Title: RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models. (arXiv:2305.01146v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01146">http://arxiv.org/abs/2305.01146</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01146] RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models](http://arxiv.org/abs/2305.01146) #large language model</code></li>
<li>Summary: <p>We systematically investigate lightweight strategies to adapt large language
models (LLMs) for the task of radiology report summarization (RRS).
Specifically, we focus on domain adaptation via pretraining (on natural
language, biomedical text, and clinical text) and via prompting (zero-shot,
in-context learning) or parameter-efficient fine-tuning (prefix tuning, LoRA).
Our results on the MIMIC-III dataset consistently demonstrate best performance
by maximally adapting to the task via pretraining on clinical text and
parameter-efficient fine-tuning on RRS examples. Importantly, this method
fine-tunes a mere 0.32% of parameters throughout the model, in contrast to
end-to-end fine-tuning (100% of parameters). Additionally, we study the effect
of in-context examples and out-of-distribution (OOD) training before concluding
with a radiologist reader study and qualitative analysis. Our findings
highlight the importance of domain adaptation in RRS and provide valuable
insights toward developing effective natural language processing solutions for
clinical tasks.
</p></li>
</ul>

<h3>Title: New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. (arXiv:2305.01181v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01181">http://arxiv.org/abs/2305.01181</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01181] New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT](http://arxiv.org/abs/2305.01181) #large language model</code></li>
<li>Summary: <p>Machine Translation (MT) has made significant progress in recent years using
deep learning, especially after the emergence of large language models (LLMs)
such as GPT-3 and ChatGPT. This brings new challenges and opportunities for MT
using LLMs. In this paper, we brainstorm some interesting directions for MT
using LLMs, including stylized MT, interactive MT, and Translation Memory-based
MT, as well as a new evaluation paradigm using LLMs. We also discuss the
privacy concerns in MT using LLMs and a basic privacy-preserving method to
mitigate such risks. To illustrate the potential of our proposed directions, we
present several examples for the new directions mentioned above, demonstrating
the feasibility of the proposed directions and highlight the opportunities and
challenges for future research in MT using LLMs.
</p></li>
</ul>

<h3>Title: Beyond Classification: Financial Reasoning in State-of-the-Art Language Models. (arXiv:2305.01505v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01505">http://arxiv.org/abs/2305.01505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01505] Beyond Classification: Financial Reasoning in State-of-the-Art Language Models](http://arxiv.org/abs/2305.01505) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs), consisting of 100 billion or more parameters,
have demonstrated remarkable ability in complex multi-step reasoning tasks.
However, the application of such generic advancements has been limited to a few
fields, such as clinical or legal, with the field of financial reasoning
remaining largely unexplored. To the best of our knowledge, the ability of LLMs
to solve financial reasoning problems has never been dealt with, and whether it
can be performed at any scale remains unknown. To address this knowledge gap,
this research presents a comprehensive investigation into the potential
application of LLMs in the financial domain. The investigation includes a
detailed exploration of a range of subjects, including task formulation,
synthetic data generation, prompting methods, and evaluation capability.
Furthermore, the study benchmarks various GPT variants with parameter scales
ranging from 2.8B to 13B, with and without instruction tuning, on diverse
dataset sizes. By analyzing the results, we reveal that the ability to generate
coherent financial reasoning first emerges at 6B parameters, and continues to
improve with better instruction-tuning or larger datasets. Additionally, the
study provides a publicly accessible dataset named sFIOG (Synthetic-Financial
Investment Opinion Generation), consisting of 11,802 synthetic investment
thesis samples, to support further research in the field of financial
reasoning. Overall, this research seeks to contribute to the understanding of
the efficacy of language models in the field of finance, with a particular
emphasis on their ability to engage in sophisticated reasoning and analysis
within the context of investment decision-making.
</p></li>
</ul>

<h3>Title: FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information. (arXiv:2305.01528v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01528">http://arxiv.org/abs/2305.01528</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01528] FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information](http://arxiv.org/abs/2305.01528) #large language model</code></li>
<li>Summary: <p>Dungeons &amp; Dragons (D&amp;D) is a tabletop roleplaying game with complex natural
language interactions between players and hidden state information. Recent work
has shown that large language models (LLMs) that have access to state
information can generate higher quality game turns than LLMs that use dialog
history alone. However, previous work used game state information that was
heuristically created and was not a true gold standard game state. We present
FIREBALL, a large dataset containing nearly 25,000 unique sessions from real
D\&amp;D gameplay on Discord with true game state info. We recorded game play
sessions of players who used the Avrae bot, which was developed to aid people
in playing D&amp;D online, capturing language, game commands and underlying game
state information. We demonstrate that FIREBALL can improve natural language
generation (NLG) by using Avrae state information, improving both automated
metrics and human judgments of quality. Additionally, we show that LLMs can
generate executable Avrae commands, particularly after finetuning.
</p></li>
</ul>

<h3>Title: Accelerating Neural Self-Improvement via Bootstrapping. (arXiv:2305.01547v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01547">http://arxiv.org/abs/2305.01547</a></li>
<li>Code URL: <a href="https://github.com/idsia/modern-srwm">https://github.com/idsia/modern-srwm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01547] Accelerating Neural Self-Improvement via Bootstrapping](http://arxiv.org/abs/2305.01547) #large language model</code></li>
<li>Summary: <p>Few-shot learning with sequence-processing neural networks (NNs) has recently
attracted a new wave of attention in the context of large language models. In
the standard N-way K-shot learning setting, an NN is explicitly optimised to
learn to classify unlabelled inputs by observing a sequence of NK labelled
examples. This pressures the NN to learn a learning algorithm that achieves
optimal performance, given the limited number of training examples. Here we
study an auxiliary loss that encourages further acceleration of few-shot
learning, by applying recently proposed bootstrapped meta-learning to NN
few-shot learners: we optimise the K-shot learner to match its own performance
achievable by observing more than NK examples, using only NK examples.
Promising results are obtained on the standard Mini-ImageNet dataset. Our code
is public.
</p></li>
</ul>

<h3>Title: Finding Neurons in a Haystack: Case Studies with Sparse Probing. (arXiv:2305.01610v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01610">http://arxiv.org/abs/2305.01610</a></li>
<li>Code URL: <a href="https://github.com/wesg52/sparse-probing-paper">https://github.com/wesg52/sparse-probing-paper</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01610] Finding Neurons in a Haystack: Case Studies with Sparse Probing](http://arxiv.org/abs/2305.01610) #large language model</code></li>
<li>Summary: <p>Despite rapid adoption and deployment of large language models (LLMs), the
internal computations of these models remain opaque and poorly understood. In
this work, we seek to understand how high-level human-interpretable features
are represented within the internal neuron activations of LLMs. We train
$k$-sparse linear classifiers (probes) on these internal activations to predict
the presence of features in the input; by varying the value of $k$ we study the
sparsity of learned representations and how this varies with model scale. With
$k=1$, we localize individual neurons which are highly relevant for a
particular feature, and perform a number of case studies to illustrate general
properties of LLMs. In particular, we show that early layers make use of sparse
combinations of neurons to represent many features in superposition, that
middle layers have seemingly dedicated neurons to represent higher-level
contextual features, and that increasing scale causes representational sparsity
to increase on average, but there are multiple types of scaling dynamics. In
all, we probe for over 100 unique features comprising 10 different categories
in 7 different models spanning 70 million to 6.9 billion parameters.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Detecting Novelties with Empty Classes. (arXiv:2305.00983v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.00983">http://arxiv.org/abs/2305.00983</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.00983] Detecting Novelties with Empty Classes](http://arxiv.org/abs/2305.00983) #segmentation</code></li>
<li>Summary: <p>For open world applications, deep neural networks (DNNs) need to be aware of
previously unseen data and adaptable to evolving environments. Furthermore, it
is desirable to detect and learn novel classes which are not included in the
DNNs underlying set of semantic classes in an unsupervised fashion. The method
proposed in this article builds upon anomaly detection to retrieve
out-of-distribution (OoD) data as candidates for new classes. We thereafter
extend the DNN by $k$ empty classes and fine-tune it on the OoD data samples.
To this end, we introduce two loss functions, which 1) entice the DNN to assign
OoD samples to the empty classes and 2) to minimize the inner-class feature
distances between them. Thus, instead of ground truth which contains labels for
the different novel classes, the DNN obtains a single OoD label together with a
distance matrix, which is computed in advance. We perform several experiments
for image classification and semantic segmentation, which demonstrate that a
DNN can extend its own semantic space by multiple classes without having access
to ground truth.
</p></li>
</ul>

<h3>Title: CLIP-S$^4$: Language-Guided Self-Supervised Semantic Segmentation. (arXiv:2305.01040v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01040">http://arxiv.org/abs/2305.01040</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01040] CLIP-S$^4$: Language-Guided Self-Supervised Semantic Segmentation](http://arxiv.org/abs/2305.01040) #segmentation</code></li>
<li>Summary: <p>Existing semantic segmentation approaches are often limited by costly
pixel-wise annotations and predefined classes. In this work, we present
CLIP-S$^4$ that leverages self-supervised pixel representation learning and
vision-language models to enable various semantic segmentation tasks (e.g.,
unsupervised, transfer learning, language-driven segmentation) without any
human annotations and unknown class information. We first learn pixel
embeddings with pixel-segment contrastive learning from different augmented
views of images. To further improve the pixel embeddings and enable
language-driven semantic segmentation, we design two types of consistency
guided by vision-language models: 1) embedding consistency, aligning our pixel
embeddings to the joint feature space of a pre-trained vision-language model,
CLIP; and 2) semantic consistency, forcing our model to make the same
predictions as CLIP over a set of carefully designed target classes with both
known and unknown prototypes. Thus, CLIP-S$^4$ enables a new task of class-free
semantic segmentation where no unknown class information is needed during
training. As a result, our approach shows consistent and substantial
performance improvement over four popular benchmarks compared with the
state-of-the-art unsupervised and language-driven semantic segmentation
methods. More importantly, our method outperforms these methods on unknown
class recognition by a large margin.
</p></li>
</ul>

<h3>Title: Long-Tailed Recognition by Mutual Information Maximization between Latent Features and Ground-Truth Labels. (arXiv:2305.01160v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01160">http://arxiv.org/abs/2305.01160</a></li>
<li>Code URL: <a href="https://github.com/bluecdm/Long-tailed-recognition">https://github.com/bluecdm/Long-tailed-recognition</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01160] Long-Tailed Recognition by Mutual Information Maximization between Latent Features and Ground-Truth Labels](http://arxiv.org/abs/2305.01160) #segmentation</code></li>
<li>Summary: <p>Although contrastive learning methods have shown prevailing performance on a
variety of representation learning tasks, they encounter difficulty when the
training dataset is long-tailed. Many researchers have combined contrastive
learning and a logit adjustment technique to address this problem, but the
combinations are done ad-hoc and a theoretical background has not yet been
provided. The goal of this paper is to provide the background and further
improve the performance. First, we show that the fundamental reason contrastive
learning methods struggle with long-tailed tasks is that they try to maximize
the mutual information maximization between latent features and input data. As
ground-truth labels are not considered in the maximization, they are not able
to address imbalances between class labels. Rather, we interpret the
long-tailed recognition task as a mutual information maximization between
latent features and ground-truth labels. This approach integrates contrastive
learning and logit adjustment seamlessly to derive a loss function that shows
state-of-the-art performance on long-tailed recognition benchmarks. It also
demonstrates its efficacy in image segmentation tasks, verifying its
versatility beyond image classification.
</p></li>
</ul>

<h3>Title: RT-K-Net: Revisiting K-Net for Real-Time Panoptic Segmentation. (arXiv:2305.01255v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01255">http://arxiv.org/abs/2305.01255</a></li>
<li>Code URL: <a href="https://github.com/markusschoen/rt-k-net">https://github.com/markusschoen/rt-k-net</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01255] RT-K-Net: Revisiting K-Net for Real-Time Panoptic Segmentation](http://arxiv.org/abs/2305.01255) #segmentation</code></li>
<li>Summary: <p>Panoptic segmentation is one of the most challenging scene parsing tasks,
combining the tasks of semantic segmentation and instance segmentation. While
much progress has been made, few works focus on the real-time application of
panoptic segmentation methods. In this paper, we revisit the recently
introduced K-Net architecture. We propose vital changes to the architecture,
training, and inference procedure, which massively decrease latency and improve
performance. Our resulting RT-K-Net sets a new state-of-the-art performance for
real-time panoptic segmentation methods on the Cityscapes dataset and shows
promising results on the challenging Mapillary Vistas dataset. On Cityscapes,
RT-K-Net reaches 60.2 % PQ with an average inference time of 32 ms for full
resolution 1024x2048 pixel images on a single Titan RTX GPU. On Mapillary
Vistas, RT-K-Net reaches 33.2 % PQ with an average inference time of 69 ms.
Source code is available at https://github.com/markusschoen/RT-K-Net.
</p></li>
</ul>

<h3>Title: Segment Anything is A Good Pseudo-label Generator for Weakly Supervised Semantic Segmentation. (arXiv:2305.01275v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01275">http://arxiv.org/abs/2305.01275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01275] Segment Anything is A Good Pseudo-label Generator for Weakly Supervised Semantic Segmentation](http://arxiv.org/abs/2305.01275) #segmentation</code></li>
<li>Summary: <p>Weakly supervised semantic segmentation with weak labels is a long-lived
ill-posed problem. Mainstream methods mainly focus on improving the quality of
pseudo labels. In this report, we attempt to explore the potential of 'prompt
to masks' from the powerful class-agnostic large segmentation model,
segment-anything. Specifically, different weak labels are used as prompts to
the segment-anything model, generating precise class masks. The class masks are
utilized to generate pseudo labels to train the segmentation networks. We have
conducted extensive experiments on PASCAL VOC 2012 dataset. Experiments
demonstrate that segment-anything can serve as a good pseudo-label generator.
The code will be made publicly available.
</p></li>
</ul>

<h3>Title: Oil Spill Segmentation using Deep Encoder-Decoder models. (arXiv:2305.01386v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01386">http://arxiv.org/abs/2305.01386</a></li>
<li>Code URL: <a href="https://github.com/abhishekrs4/htsm_oil_spill_segmentation">https://github.com/abhishekrs4/htsm_oil_spill_segmentation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01386] Oil Spill Segmentation using Deep Encoder-Decoder models](http://arxiv.org/abs/2305.01386) #segmentation</code></li>
<li>Summary: <p>Crude oil is an integral component of the modern world economy. With the
growing demand for crude oil due to its widespread applications, accidental oil
spills are unavoidable. Even though oil spills are in and themselves difficult
to clean up, the first and foremost challenge is to detect spills. In this
research, the authors test the feasibility of deep encoder-decoder models that
can be trained effectively to detect oil spills. The work compares the results
from several segmentation models on high dimensional satellite Synthetic
Aperture Radar (SAR) image data. Multiple combinations of models are used in
running the experiments. The best-performing model is the one with the
ResNet-50 encoder and DeepLabV3+ decoder. It achieves a mean Intersection over
Union (IoU) of 64.868% and a class IoU of 61.549% for the "oil spill" class
when compared with the current benchmark model, which achieved a mean IoU of
65.05% and a class IoU of 53.38% for the "oil spill" class.
</p></li>
</ul>

<h3>Title: An Alternative to WSSS? An Empirical Study of the Segment Anything Model (SAM) on Weakly-Supervised Semantic Segmentation Problems. (arXiv:2305.01586v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01586">http://arxiv.org/abs/2305.01586</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01586] An Alternative to WSSS? An Empirical Study of the Segment Anything Model (SAM) on Weakly-Supervised Semantic Segmentation Problems](http://arxiv.org/abs/2305.01586) #segmentation</code></li>
<li>Summary: <p>The Segment Anything Model (SAM) has demonstrated exceptional performance and
versatility, making it a promising tool for various related tasks. In this
report, we explore the application of SAM in Weakly-Supervised Semantic
Segmentation (WSSS). Particularly, we adapt SAM as the pseudo-label generation
pipeline given only the image-level class labels. While we observed impressive
results in most cases, we also identify certain limitations. Our study includes
performance evaluations on PASCAL VOC and MS-COCO, where we achieved remarkable
improvements over the latest state-of-the-art methods on both datasets. We
anticipate that this report encourages further explorations of adopting SAM in
WSSS, as well as wider real-world applications.
</p></li>
</ul>

<h3>Title: Neural LiDAR Fields for Novel View Synthesis. (arXiv:2305.01643v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.01643">http://arxiv.org/abs/2305.01643</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.01643] Neural LiDAR Fields for Novel View Synthesis](http://arxiv.org/abs/2305.01643) #segmentation</code></li>
<li>Summary: <p>We present Neural Fields for LiDAR (NFL), a method to optimise a neural field
scene representation from LiDAR measurements, with the goal of synthesizing
realistic LiDAR scans from novel viewpoints. NFL combines the rendering power
of neural fields with a detailed, physically motivated model of the LiDAR
sensing process, thus enabling it to accurately reproduce key sensor behaviors
like beam divergence, secondary returns, and ray dropping. We evaluate NFL on
synthetic and real LiDAR scans and show that it outperforms explicit
reconstruct-then-simulate methods as well as other NeRF-style methods on LiDAR
novel view synthesis task. Moreover, we show that the improved realism of the
synthesized views narrows the domain gap to real scans and translates to better
registration and semantic segmentation performance.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
