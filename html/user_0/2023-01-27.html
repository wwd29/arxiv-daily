<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Digital Inheritance in Web3: A Case Study of Soulbound Tokens and the Social Recovery Pallet within the Polkadot and Kusama Ecosystems. (arXiv:2301.11074v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11074">http://arxiv.org/abs/2301.11074</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11074] Digital Inheritance in Web3: A Case Study of Soulbound Tokens and the Social Recovery Pallet within the Polkadot and Kusama Ecosystems](http://arxiv.org/abs/2301.11074) #secure</code></li>
<li>Summary: <p>In recent years discussions centered around digital inheritance have
increased among social media users and across blockchain ecosystems. As a
result digital assets such as social media content cryptocurrencies and
non-fungible tokens have become increasingly valuable and widespread, leading
to the need for clear and secure mechanisms for transferring these assets upon
the testators death or incapacitation. This study proposes a framework for
digital inheritance using soulbound tokens and the social recovery pallet as a
use case in the Polkadot and Kusama blockchain networks. The findings discussed
within this study suggest that while soulbound tokens and the social recovery
pallet offer a promising solution for creating a digital inheritance plan the
findings also raise important considerations for testators digital executors
and developers. While further research is needed to fully understand the
potential impacts and risks of other technologies such as artificial
intelligence and quantum computing this study provides a primer for users to
begin planning a digital inheritance strategy and for developers to develop a
more intuitive solution.
</p></li>
</ul>

<h3>Title: LemonLDAP::NG -- A Full AAA Free Open Source WebSSO Solution. (arXiv:2301.11092v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11092">http://arxiv.org/abs/2301.11092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11092] LemonLDAP::NG -- A Full AAA Free Open Source WebSSO Solution](http://arxiv.org/abs/2301.11092) #secure</code></li>
<li>Summary: <p>Nowadays, security is becoming a major issue and concern. More and more
organizations like hospitals, metropolis or banks are under cyberattacks and
have to improve their network infrastructure security. The first prerequisites
are to authenticate users, to provide identity and to grant just the needed and
useful accesses. These requirements can be solved by implementing a Single
Sign-On (SSO) solution. It is an authentication scheme that permits a user to
log in with a single identity to any of several related, yet independent,
systems. It allows users to log in once and to access services without
authenticating again. SSO solutions are classified depending on Authentication,
Authorization, and Accounting features. The 'AAA' acronym defines a framework
for intelligently controlling access to resources, enforcing security policies,
auditing usage, and providing the information necessary to bill for services.
These combined processes are considered important for effective network
management and cybersecurity. LemonLDAP::NG (LL::NG) is a full AAA WebSSO
solution. It implements all standard authentication and identity federation
(IdF) protocols. The main LL::NG's advantages compared to other products are
its plug-in engine and its advanced handlerbased protection mechanism that can
be employed to protect Server2Server exchanges or to offer the SSO as a
Service, a solution to implement a full DevOps architecture. LL::NG is a
community and professional project mainly employed by the French government to
secure Police, Finance or Justice Ministries and a French mobile operator IT
infrastructures since 2010. But for several years, contributions come from all
around the world and LL::NG is becoming more and more popular.
</p></li>
</ul>

<h3>Title: Blockchain-aided Secure Semantic Communication for AI-Generated Content in Metaverse. (arXiv:2301.11289v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11289">http://arxiv.org/abs/2301.11289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11289] Blockchain-aided Secure Semantic Communication for AI-Generated Content in Metaverse](http://arxiv.org/abs/2301.11289) #secure</code></li>
<li>Summary: <p>The construction of virtual transportation networks requires massive data to
be transmitted from edge devices to Virtual Service Providers (VSP) to
facilitate circulations between the physical and virtual domains in Metaverse.
Leveraging semantic communication for reducing information redundancy, VSPs can
receive semantic data from edge devices to provide varied services through
advanced techniques, e.g., AI-Generated Content (AIGC), for users to explore
digital worlds. But the use of semantic communication raises a security issue
because attackers could send malicious semantic data with similar semantic
information but different desired content to break Metaverse services and cause
wrong output of AIGC. Therefore, in this paper, we first propose a
blockchain-aided semantic communication framework for AIGC services in virtual
transportation networks to facilitate interactions of the physical and virtual
domains among VSPs and edge devices. We illustrate a training-based targeted
semantic attack scheme to generate adversarial semantic data by various loss
functions. We also design a semantic defense scheme that uses the blockchain
and zero-knowledge proofs to tell the difference between the semantic
similarities of adversarial and authentic semantic data and to check the
authenticity of semantic data transformations. Simulation results show that the
proposed defense method can reduce the semantic similarity of the adversarial
semantic data and the authentic ones by up to 30% compared with the attack
scheme.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: New Approach to Malware Detection Using Optimized Convolutional Neural Network. (arXiv:2301.11161v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11161">http://arxiv.org/abs/2301.11161</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11161] New Approach to Malware Detection Using Optimized Convolutional Neural Network](http://arxiv.org/abs/2301.11161) #security</code></li>
<li>Summary: <p>Cyber-crimes have become a multi-billion-dollar industry in the recent years.
Most cybercrimes/attacks involve deploying some type of malware. Malware that
viciously targets every industry, every sector, every enterprise and even
individuals has shown its capabilities to take entire business organizations
offline and cause significant financial damage in billions of dollars annually.
Malware authors are constantly evolving in their attack strategies and
sophistication and are developing malware that is difficult to detect and can
lay dormant in the background for quite some time in order to evade security
controls. Given the above argument, Traditional approaches to malware detection
are no longer effective. As a result, deep learning models have become an
emerging trend to detect and classify malware. This paper proposes a new
convolutional deep learning neural network to accurately and effectively detect
malware with high precision. This paper is different than most other papers in
the literature in that it uses an expert data science approach by developing a
convolutional neural network from scratch to establish a baseline of the
performance model first, explores and implements an improvement model from the
baseline model, and finally it evaluates the performance of the final model.
The baseline model initially achieves 98% accurate rate but after increasing
the depth of the CNN model, its accuracy reaches 99.183 which outperforms most
of the CNN models in the literature. Finally, to further solidify the
effectiveness of this CNN model, we use the improved model to make predictions
on new malware samples within our dataset.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy-Preserving Joint Edge Association and Power Optimization for the Internet of Vehicles via Federated Multi-Agent Reinforcement Learning. (arXiv:2301.11014v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11014">http://arxiv.org/abs/2301.11014</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11014] Privacy-Preserving Joint Edge Association and Power Optimization for the Internet of Vehicles via Federated Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2301.11014) #privacy</code></li>
<li>Summary: <p>Proactive edge association is capable of improving wireless connectivity at
the cost of increased handover (HO) frequency and energy consumption, while
relying on a large amount of private information sharing required for decision
making. In order to improve the connectivity-cost trade-off without privacy
leakage, we investigate the privacy-preserving joint edge association and power
allocation (JEAPA) problem in the face of the environmental uncertainty and the
infeasibility of individual learning. Upon modelling the problem by a
decentralized partially observable Markov Decision Process (Dec-POMDP), it is
solved by federated multi-agent reinforcement learning (FMARL) through only
sharing encrypted training data for federatively learning the policy sought.
Our simulation results show that the proposed solution strikes a compelling
trade-off, while preserving a higher privacy level than the state-of-the-art
solutions.
</p></li>
</ul>

<h3>Title: Multi-Agent congestion cost minimization with linear function approximation. (arXiv:2301.10993v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10993">http://arxiv.org/abs/2301.10993</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10993] Multi-Agent congestion cost minimization with linear function approximation](http://arxiv.org/abs/2301.10993) #privacy</code></li>
<li>Summary: <p>This work considers multiple agents traversing a network from a source node
to the goal node. The cost to an agent for traveling a link has a private as
well as a congestion component. The agent's objective is to find a path to the
goal node with minimum overall cost in a decentralized way. We model this as a
fully decentralized multi-agent reinforcement learning problem and propose a
novel multi-agent congestion cost minimization (MACCM) algorithm. Our MACCM
algorithm uses linear function approximations of transition probabilities and
the global cost function. In the absence of a central controller and to
preserve privacy, agents communicate the cost function parameters to their
neighbors via a time-varying communication network. Moreover, each agent
maintains its estimate of the global state-action value, which is updated via a
multi-agent extended value iteration (MAEVI) sub-routine. We show that our
MACCM algorithm achieves a sub-linear regret. The proof requires the
convergence of cost function parameters, the MAEVI algorithm, and analysis of
the regret bounds induced by the MAEVI triggering condition for each agent. We
implement our algorithm on a two node network with multiple links to validate
it. We first identify the optimal policy, the optimal number of agents going to
the goal node in each period. We observe that the average regret is close to
zero for 2 and 3 agents. The optimal policy captures the trade-off between the
minimum cost of staying at a node and the congestion cost of going to the goal
node. Our work is a generalization of learning the stochastic shortest path
problem.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Hybrid Protection of Digital FIR Filters. (arXiv:2301.11115v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11115">http://arxiv.org/abs/2301.11115</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11115] Hybrid Protection of Digital FIR Filters](http://arxiv.org/abs/2301.11115) #protect</code></li>
<li>Summary: <p>A digital Finite Impulse Response (FIR) filter is a ubiquitous block in
digital signal processing applications and its behavior is determined by its
coefficients. To protect filter coefficients from an adversary, efficient
obfuscation techniques have been proposed, either by hiding them behind decoys
or replacing them by key bits. In this article, we initially introduce a query
attack that can discover the secret key of such obfuscated FIR filters, which
could not be broken by existing prominent attacks. Then, we propose a first of
its kind hybrid technique, including both hardware obfuscation and logic
locking using a point function for the protection of parallel direct and
transposed forms of digital FIR filters. Experimental results show that the
hybrid protection technique can lead to FIR filters with higher security while
maintaining the hardware complexity competitive or superior to those locked by
prominent logic locking methods. It is also shown that the protected multiplier
blocks and FIR filters are resilient to existing attacks. The results on
different forms and realizations of FIR filters show that the parallel direct
form FIR filter has a promising potential for a secure design.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Minerva: A File-Based Ransomware Detector. (arXiv:2301.11050v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11050">http://arxiv.org/abs/2301.11050</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11050] Minerva: A File-Based Ransomware Detector](http://arxiv.org/abs/2301.11050) #defense</code></li>
<li>Summary: <p>Ransomware is a rapidly evolving type of malware designed to encrypt user
files on a device, making them inaccessible in order to exact a ransom.
Ransomware attacks resulted in billions of dollars in damages in recent years
and are expected to cause hundreds of billions more in the next decade. With
current state-of-the-art process-based detectors being heavily susceptible to
evasion attacks, no comprehensive solution to this problem is available today.
This paper presents Minerva, a new approach to ransomware detection. Unlike
current methods focused on identifying ransomware based on process-level
behavioral modeling, Minerva detects ransomware by building behavioral profiles
of files based on all the operations they receive in a time window. Minerva
addresses some of the critical challenges associated with process-based
approaches, specifically their vulnerability to complex evasion attacks. Our
evaluation of Minerva demonstrates its effectiveness in detecting ransomware
attacks, including those that are able to bypass existing defenses. Our results
show that Minerva identifies ransomware activity with an average accuracy of
99.45% and an average recall of 99.66%, with 99.97% of ransomware detected
within 1 second.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Distilling Cognitive Backdoor Patterns within an Image. (arXiv:2301.10908v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10908">http://arxiv.org/abs/2301.10908</a></li>
<li>Code URL: <a href="https://github.com/HanxunH/CognitiveDistillation">https://github.com/HanxunH/CognitiveDistillation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10908] Distilling Cognitive Backdoor Patterns within an Image](http://arxiv.org/abs/2301.10908) #attack</code></li>
<li>Summary: <p>This paper proposes a simple method to distill and detect backdoor patterns
within an image: \emph{Cognitive Distillation} (CD). The idea is to extract the
"minimal essence" from an input image responsible for the model's prediction.
CD optimizes an input mask to extract a small pattern from the input image that
can lead to the same model output (i.e., logits or deep features). The
extracted pattern can help understand the cognitive mechanism of a model on
clean vs. backdoor images and is thus called a \emph{Cognitive Pattern} (CP).
Using CD and the distilled CPs, we uncover an interesting phenomenon of
backdoor attacks: despite the various forms and sizes of trigger patterns used
by different attacks, the CPs of backdoor samples are all surprisingly and
suspiciously small. One thus can leverage the learned mask to detect and remove
backdoor examples from poisoned training datasets. We conduct extensive
experiments to show that CD can robustly detect a wide range of advanced
backdoor attacks. We also show that CD can potentially be applied to help
detect potential biases from face datasets. Code is available at
\url{https://github.com/HanxunH/CognitiveDistillation}.
</p></li>
</ul>

<h3>Title: RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks. (arXiv:2301.10822v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10822">http://arxiv.org/abs/2301.10822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10822] RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks](http://arxiv.org/abs/2301.10822) #attack</code></li>
<li>Summary: <p>The state-of-the-art predictive maintenance (PdM) techniques have shown great
success in reducing maintenance costs and downtime of complicated machines
while increasing overall productivity through extensive utilization of
Internet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors and
DL algorithms are both prone to cyber-attacks. For instance, DL algorithms are
known for their susceptibility to adversarial examples. Such adversarial
attacks are vastly under-explored in the PdM domain. This is because the
adversarial attacks in the computer vision domain for classification tasks
cannot be directly applied to the PdM domain for multivariate time series (MTS)
regression tasks. In this work, we propose an end-to-end methodology to design
adversarially robust PdM systems by extensively analyzing the effect of
different types of adversarial attacks and proposing a novel adversarial
defense technique for DL-enabled PdM models. First, we propose novel MTS
Projected Gradient Descent (PGD) and MTS PGD with random restarts (PGD_r)
attacks. Then, we evaluate the impact of MTS PGD and PGD_r along with MTS Fast
Gradient Sign Method (FGSM) and MTS Basic Iterative Method (BIM) on Long
Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), Convolutional Neural
Network (CNN), and Bi-directional LSTM based PdM system. Our results using
NASA's turbofan engine dataset show that adversarial attacks can cause a severe
defect (up to 11X) in the RUL prediction, outperforming the effectiveness of
the state-of-the-art PdM attacks by 3X. Furthermore, we present a novel
approximate adversarial training method to defend against adversarial attacks.
We observe that approximate adversarial training can significantly improve the
robustness of PdM models (up to 54X) and outperforms the state-of-the-art PdM
defense methods by offering 3X more robustness.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach. (arXiv:2301.10847v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10847">http://arxiv.org/abs/2301.10847</a></li>
<li>Code URL: <a href="https://github.com/mindflow-institue/transception">https://github.com/mindflow-institue/transception</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10847] Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach](http://arxiv.org/abs/2301.10847) #robust</code></li>
<li>Summary: <p>While CNN-based methods have been the cornerstone of medical image
segmentation due to their promising performance and robustness, they suffer
from limitations in capturing long-range dependencies. Transformer-based
approaches are currently prevailing since they enlarge the reception field to
model global contextual correlation. To further extract rich representations,
some extensions of the U-Net employ multi-scale feature extraction and fusion
modules and obtain improved performance. Inspired by this idea, we propose
TransCeption for medical image segmentation, a pure transformer-based U-shape
network featured by incorporating the inception-like module into the encoder
and adopting a contextual bridge for better feature fusion. The design proposed
in this work is based on three core principles: (1) The patch merging module in
the encoder is redesigned with ResInception Patch Merging (RIPM). Multi-branch
transformer (MB transformer) adopts the same number of branches as the outputs
of RIPM. Combining the two modules enables the model to capture a multi-scale
representation within a single stage. (2) We construct an Intra-stage Feature
Fusion (IFF) module following the MB transformer to enhance the aggregation of
feature maps from all the branches and particularly focus on the interaction
between the different channels of all the scales. (3) In contrast to a bridge
that only contains token-wise self-attention, we propose a Dual Transformer
Bridge that also includes channel-wise self-attention to exploit correlations
between scales at different stages from a dual perspective. Extensive
experiments on multi-organ and skin lesion segmentation tasks present the
superior performance of TransCeption compared to previous work. The code is
publicly available at \url{https://github.com/mindflow-institue/TransCeption}.
</p></li>
</ul>

<h3>Title: Neurorehab: An Interface for Rehabilitation. (arXiv:2301.10957v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10957">http://arxiv.org/abs/2301.10957</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10957] Neurorehab: An Interface for Rehabilitation](http://arxiv.org/abs/2301.10957) #robust</code></li>
<li>Summary: <p>About 15% of the world population is affected by a disability in some form,
amongst whom only 31% perform the recommended exercises without intervention.
We are working on developing a motivating and effective way to encourage
people. In our work, we leverage the fact that repetitive exercises can help
people with motor disabilities due to the robust plasticity of the pre-frontal
cognitive control system in the brain. We investigate the role of repetitive
activities for neurorehabilitation with the help of a brain computer interface,
formulated using immersive game design with Kinect v2.0 and Unity 3D. We also
introduce a game design paradigm for adaptive learning for the patients.
</p></li>
</ul>

<h3>Title: Self-Supervised RGB-T Tracking with Cross-Input Consistency. (arXiv:2301.11274v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11274">http://arxiv.org/abs/2301.11274</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11274] Self-Supervised RGB-T Tracking with Cross-Input Consistency](http://arxiv.org/abs/2301.11274) #robust</code></li>
<li>Summary: <p>In this paper, we propose a self-supervised RGB-T tracking method. Different
from existing deep RGB-T trackers that use a large number of annotated RGB-T
image pairs for training, our RGB-T tracker is trained using unlabeled RGB-T
video pairs in a self-supervised manner. We propose a novel cross-input
consistency-based self-supervised training strategy based on the idea that
tracking can be performed using different inputs. Specifically, we construct
two distinct inputs using unlabeled RGB-T video pairs. We then track objects
using these two inputs to generate results, based on which we construct our
cross-input consistency loss. Meanwhile, we propose a reweighting strategy to
make our loss function robust to low-quality training samples. We build our
tracker on a Siamese correlation filter network. To the best of our knowledge,
our tracker is the first self-supervised RGB-T tracker. Extensive experiments
on two public RGB-T tracking benchmarks demonstrate that the proposed training
strategy is effective. Remarkably, despite training only with a corpus of
unlabeled RGB-T video pairs, our tracker outperforms seven supervised RGB-T
trackers on the GTOT dataset.
</p></li>
</ul>

<h3>Title: Cut and Learn for Unsupervised Object Detection and Instance Segmentation. (arXiv:2301.11320v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11320">http://arxiv.org/abs/2301.11320</a></li>
<li>Code URL: <a href="https://github.com/facebookresearch/cutler">https://github.com/facebookresearch/cutler</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11320] Cut and Learn for Unsupervised Object Detection and Instance Segmentation](http://arxiv.org/abs/2301.11320) #robust</code></li>
<li>Summary: <p>We propose Cut-and-LEaRn (CutLER), a simple approach for training
unsupervised object detection and segmentation models. We leverage the property
of self-supervised models to 'discover' objects without supervision and amplify
it to train a state-of-the-art localization model without any human labels.
CutLER first uses our proposed MaskCut approach to generate coarse masks for
multiple objects in an image and then learns a detector on these masks using
our robust loss function. We further improve the performance by self-training
the model on its predictions. Compared to prior work, CutLER is simpler,
compatible with different detection architectures, and detects multiple
objects. CutLER is also a zero-shot unsupervised detector and improves
detection performance AP50 by over 2.7 times on 11 benchmarks across domains
like video frames, paintings, sketches, etc. With finetuning, CutLER serves as
a low-shot detector surpassing MoCo-v2 by 7.3% APbox and 6.6% APmask on COCO
when training with 5% labels.
</p></li>
</ul>

<h3>Title: Characterizing the Entities in Harmful Memes: Who is the Hero, the Villain, the Victim?. (arXiv:2301.11219v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11219">http://arxiv.org/abs/2301.11219</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11219] Characterizing the Entities in Harmful Memes: Who is the Hero, the Villain, the Victim?](http://arxiv.org/abs/2301.11219) #robust</code></li>
<li>Summary: <p>Memes can sway people's opinions over social media as they combine visual and
textual information in an easy-to-consume manner. Since memes instantly turn
viral, it becomes crucial to infer their intent and potentially associated
harmfulness to take timely measures as needed. A common problem associated with
meme comprehension lies in detecting the entities referenced and characterizing
the role of each of these entities. Here, we aim to understand whether the meme
glorifies, vilifies, or victimizes each entity it refers to. To this end, we
address the task of role identification of entities in harmful memes, i.e.,
detecting who is the 'hero', the 'villain', and the 'victim' in the meme, if
any. We utilize HVVMemes - a memes dataset on US Politics and Covid-19 memes,
released recently as part of the CONSTRAINT@ACL-2022 shared-task. It contains
memes, entities referenced, and their associated roles: hero, villain, victim,
and other. We further design VECTOR (Visual-semantic role dEteCToR), a robust
multi-modal framework for the task, which integrates entity-based contextual
information in the multi-modal representation and compare it to several
standard unimodal (text-only or image-only) or multi-modal (image+text) models.
Our experimental results show that our proposed model achieves an improvement
of 4% over the best baseline and 1% over the best competing stand-alone
submission from the shared-task. Besides divulging an extensive experimental
setup with comparative analyses, we finally highlight the challenges
encountered in addressing the complex task of semantic role labeling within
memes.
</p></li>
</ul>

<h3>Title: Robust multi-party semi-quantum private comparison protocols with decoherence-free states against collective noises. (arXiv:2301.11119v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11119">http://arxiv.org/abs/2301.11119</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11119] Robust multi-party semi-quantum private comparison protocols with decoherence-free states against collective noises](http://arxiv.org/abs/2301.11119) #robust</code></li>
<li>Summary: <p>Based on decoherence-free states, two multi-party semi-quantum private
comparison protocols are proposed to counteract collective noises. One could
resist the collective-dephasing noise well, whereas the other could resist the
collective-rotation noise. Multiple classical participants could compare their
secret information by performing the proposed protocols once. It is manifested
that the proposed protocols could resist both external attacks and internal
attacks. Besides, the operations of our protocols were simulated on the IBM
Quantum Experience.
</p></li>
</ul>

<h3>Title: When Layers Play the Lottery, all Tickets Win at Initialization. (arXiv:2301.10835v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10835">http://arxiv.org/abs/2301.10835</a></li>
<li>Code URL: <a href="https://github.com/arturjordao/layerlottery">https://github.com/arturjordao/layerlottery</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10835] When Layers Play the Lottery, all Tickets Win at Initialization](http://arxiv.org/abs/2301.10835) #robust</code></li>
<li>Summary: <p>Pruning is a standard technique for reducing the computational cost of deep
networks. Many advances in pruning leverage concepts from the Lottery Ticket
Hypothesis (LTH). LTH reveals that inside a trained dense network exists sparse
subnetworks (tickets) able to achieve similar accuracy (i.e., win the lottery -
winning tickets). Pruning at initialization focuses on finding winning tickets
without training a dense network. Studies on these concepts share the trend
that subnetworks come from weight or filter pruning. In this work, we
investigate LTH and pruning at initialization from the lens of layer pruning.
First, we confirm the existence of winning tickets when the pruning process
removes layers. Leveraged by this observation, we propose to discover these
winning tickets at initialization, eliminating the requirement of heavy
computational resources for training the initial (over-parameterized) dense
network. Extensive experiments show that our winning tickets notably speed up
the training phase and reduce up to 51% of carbon emission, an important step
towards democratization and green Artificial Intelligence. Beyond computational
benefits, our winning tickets exhibit robustness against adversarial and
out-of-distribution examples. Finally, we show that our subnetworks easily win
the lottery at initialization while tickets from filter removal (the standard
structured LTH) hardly become winning tickets.
</p></li>
</ul>

<h3>Title: Finding Regions of Counterfactual Explanations via Robust Optimization. (arXiv:2301.11113v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11113">http://arxiv.org/abs/2301.11113</a></li>
<li>Code URL: <a href="https://github.com/donato-maragno/robust-ce">https://github.com/donato-maragno/robust-ce</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11113] Finding Regions of Counterfactual Explanations via Robust Optimization](http://arxiv.org/abs/2301.11113) #robust</code></li>
<li>Summary: <p>Counterfactual explanations play an important role in detecting bias and
improving the explainability of data-driven classification models. A
counterfactual explanation (CE) is a minimal perturbed data point for which the
decision of the model changes. Most of the existing methods can only provide
one CE, which may not be achievable for the user. In this work we derive an
iterative method to calculate robust CEs, i.e. CEs that remain valid even after
the features are slightly perturbed. To this end, our method provides a whole
region of CEs allowing the user to choose a suitable recourse to obtain a
desired outcome. We use algorithmic ideas from robust optimization and prove
convergence results for the most common machine learning methods including
logistic regression, decision trees, random forests, and neural networks. Our
experiments show that our method can efficiently generate globally optimal
robust CEs for a variety of common data sets and classification models.
</p></li>
</ul>

<h3>Title: Train Hard, Fight Easy: Robust Meta Reinforcement Learning. (arXiv:2301.11147v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11147">http://arxiv.org/abs/2301.11147</a></li>
<li>Code URL: <a href="https://github.com/ido90/robustmetarl">https://github.com/ido90/robustmetarl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11147] Train Hard, Fight Easy: Robust Meta Reinforcement Learning](http://arxiv.org/abs/2301.11147) #robust</code></li>
<li>Summary: <p>A major challenge of reinforcement learning (RL) in real-world applications
is the variation between environments, tasks or clients. Meta-RL (MRL)
addresses this issue by learning a meta-policy that adapts to new tasks.
Standard MRL methods optimize the average return over tasks, but often suffer
from poor results in tasks of high risk or difficulty. This limits system
reliability whenever test tasks are not known in advance. In this work, we
propose a robust MRL objective with a controlled robustness level. Optimization
of analogous robust objectives in RL often leads to both biased gradients and
data inefficiency. We prove that the former disappears in MRL, and address the
latter via the novel Robust Meta RL algorithm (RoML). RoML is a meta-algorithm
that generates a robust version of any given MRL algorithm, by identifying and
over-sampling harder tasks throughout training. We demonstrate that RoML learns
substantially different meta-policies and achieves robust returns on several
navigation and continuous control benchmarks.
</p></li>
</ul>

<h3>Title: Neural Inverse Operators for Solving PDE Inverse Problems. (arXiv:2301.11167v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11167">http://arxiv.org/abs/2301.11167</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11167] Neural Inverse Operators for Solving PDE Inverse Problems](http://arxiv.org/abs/2301.11167) #robust</code></li>
<li>Summary: <p>A large class of inverse problems for PDEs are only well-defined as mappings
from operators to functions. Existing operator learning frameworks map
functions to functions and need to be modified to learn inverse maps from data.
We propose a novel architecture termed Neural Inverse Operators (NIOs) to solve
these PDE inverse problems. Motivated by the underlying mathematical structure,
NIO is based on a suitable composition of DeepONets and FNOs to approximate
mappings from operators to functions. A variety of experiments are presented to
demonstrate that NIOs significantly outperform baselines and solve PDE inverse
problems robustly, accurately and are several orders of magnitude faster than
existing direct and PDE-constrained optimization methods.
</p></li>
</ul>

<h3>Title: Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning. (arXiv:2301.11321v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11321">http://arxiv.org/abs/2301.11321</a></li>
<li>Code URL: <a href="https://github.com/brett-daley/trajectory-aware-etraces">https://github.com/brett-daley/trajectory-aware-etraces</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11321] Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning](http://arxiv.org/abs/2301.11321) #robust</code></li>
<li>Summary: <p>Off-policy learning from multistep returns is crucial for sample-efficient
reinforcement learning, but counteracting off-policy bias without exacerbating
variance is challenging. Classically, off-policy bias is corrected in a
per-decision manner: past temporal-difference errors are re-weighted by the
instantaneous Importance Sampling (IS) ratio after each action via eligibility
traces. Many off-policy algorithms rely on this mechanism, along with differing
protocols for cutting the IS ratios to combat the variance of the IS estimator.
Unfortunately, once a trace has been fully cut, the effect cannot be reversed.
This has led to the development of credit-assignment strategies that account
for multiple past experiences at a time. These trajectory-aware methods have
not been extensively analyzed, and their theoretical justification remains
uncertain. In this paper, we propose a multistep operator that can express both
per-decision and trajectory-aware methods. We prove convergence conditions for
our operator in the tabular setting, establishing the first guarantees for
several existing methods as well as many new ones. Finally, we introduce
Recency-Bounded Importance Sampling (RBIS), which leverages trajectory
awareness to perform robustly across $\lambda$-values in an off-policy control
task.
</p></li>
</ul>

<h3>Title: Certified Interpretability Robustness for Class Activation Mapping. (arXiv:2301.11324v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11324">http://arxiv.org/abs/2301.11324</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11324] Certified Interpretability Robustness for Class Activation Mapping](http://arxiv.org/abs/2301.11324) #robust</code></li>
<li>Summary: <p>Interpreting machine learning models is challenging but crucial for ensuring
the safety of deep networks in autonomous driving systems. Due to the
prevalence of deep learning based perception models in autonomous vehicles,
accurately interpreting their predictions is crucial. While a variety of such
methods have been proposed, most are shown to lack robustness. Yet, little has
been done to provide certificates for interpretability robustness. Taking a
step in this direction, we present CORGI, short for Certifiably prOvable
Robustness Guarantees for Interpretability mapping. CORGI is an algorithm that
takes in an input image and gives a certifiable lower bound for the robustness
of the top k pixels of its CAM interpretability map. We show the effectiveness
of CORGI via a case study on traffic sign data, certifying lower bounds on the
minimum adversarial perturbation not far from (4-5x) state-of-the-art attack
methods.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental Health on Social Media. (arXiv:2301.11004v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11004">http://arxiv.org/abs/2301.11004</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11004] NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental Health on Social Media](http://arxiv.org/abs/2301.11004) #extraction</code></li>
<li>Summary: <p>Interactions among humans on social media often convey intentions behind
their actions, yielding a psychological language resource for Mental Health
Analysis (MHA) of online users. The success of Computational Intelligence
Techniques (CIT) for inferring mental illness from such social media resources
points to NLP as a lens for causal analysis and perception mining. However, we
argue that more consequential and explainable research is required for optimal
impact on clinical psychology practice and personalized mental healthcare. To
bridge this gap, we posit two significant dimensions: (1) Causal analysis to
illustrate a cause and effect relationship in the user generated text; (2)
Perception mining to infer psychological perspectives of social effects on
online users intentions. Within the scope of Natural Language Processing (NLP),
we further explore critical areas of inquiry associated with these two
dimensions, specifically through recent advancements in discourse analysis.
This position paper guides the community to explore solutions in this space and
advance the state of practice in developing conversational agents for inferring
mental health from social media. We advocate for a more explainable approach
toward modeling computational psychology problems through the lens of language
as we observe an increased number of research contributions in dataset and
problem formulation for causal relation extraction and perception enhancements
while inferring mental states.
</p></li>
</ul>

<h3>Title: Understanding Finetuning for Factual Knowledge Extraction from Language Models. (arXiv:2301.11293v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11293">http://arxiv.org/abs/2301.11293</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11293] Understanding Finetuning for Factual Knowledge Extraction from Language Models](http://arxiv.org/abs/2301.11293) #extraction</code></li>
<li>Summary: <p>Language models (LMs) pretrained on large corpora of text from the web have
been observed to contain large amounts of various types of knowledge about the
world. This observation has led to a new and exciting paradigm in knowledge
graph construction where, instead of manual curation or text mining, one
extracts knowledge from the parameters of an LM. Recently, it has been shown
that finetuning LMs on a set of factual knowledge makes them produce better
answers to queries from a different set, thus making finetuned LMs a good
candidate for knowledge extraction and, consequently, knowledge graph
construction. In this paper, we analyze finetuned LMs for factual knowledge
extraction. We show that along with its previously known positive effects,
finetuning also leads to a (potentially harmful) phenomenon which we call
Frequency Shock, where at the test time the model over-predicts rare entities
that appear in the training set and under-predicts common entities that do not
appear in the training set enough times. We show that Frequency Shock leads to
a degradation in the predictions of the model and beyond a point, the harm from
Frequency Shock can even outweigh the positive effects of finetuning, making
finetuning harmful overall. We then consider two solutions to remedy the
identified negative effect: 1- model mixing and 2- mixture finetuning with the
LM's pre-training task. The two solutions combined lead to significant
improvements compared to vanilla finetuning.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Open Problems in Applied Deep Learning. (arXiv:2301.11316v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11316">http://arxiv.org/abs/2301.11316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11316] Open Problems in Applied Deep Learning](http://arxiv.org/abs/2301.11316) #federate</code></li>
<li>Summary: <p>This work formulates the machine learning mechanism as a bi-level
optimization problem. The inner level optimization loop entails minimizing a
properly chosen loss function evaluated on the training data. This is nothing
but the well-studied training process in pursuit of optimal model parameters.
The outer level optimization loop is less well-studied and involves maximizing
a properly chosen performance metric evaluated on the validation data. This is
what we call the "iteration process", pursuing optimal model hyper-parameters.
Among many other degrees of freedom, this process entails model engineering
(e.g., neural network architecture design) and management, experiment tracking,
dataset versioning and augmentation. The iteration process could be automated
via Automatic Machine Learning (AutoML) or left to the intuitions of machine
learning students, engineers, and researchers. Regardless of the route we take,
there is a need to reduce the computational cost of the iteration step and as a
direct consequence reduce the carbon footprint of developing artificial
intelligence algorithms. Despite the clean and unified mathematical formulation
of the iteration step as a bi-level optimization problem, its solutions are
case specific and complex. This work will consider such cases while increasing
the level of complexity from supervised learning to semi-supervised,
self-supervised, unsupervised, few-shot, federated, reinforcement, and
physics-informed learning. As a consequence of this exercise, this proposal
surfaces a plethora of open problems in the field, many of which can be
addressed in parallel.
</p></li>
</ul>

<h3>Title: SuperFed: Weight Shared Federated Learning. (arXiv:2301.10879v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10879">http://arxiv.org/abs/2301.10879</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10879] SuperFed: Weight Shared Federated Learning](http://arxiv.org/abs/2301.10879) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) is a well-established technique for privacy
preserving distributed training. Much attention has been given to various
aspects of FL training. A growing number of applications that consume
FL-trained models, however, increasingly operate under dynamically and
unpredictably variable conditions, rendering a single model insufficient. We
argue for training a global family of models cost efficiently in a federated
fashion. Training them independently for different tradeoff points incurs
$O(k)$ cost for any k architectures of interest, however. Straightforward
applications of FL techniques to recent weight-shared training approaches is
either infeasible or prohibitively expensive. We propose SuperFed - an
architectural framework that incurs $O(1)$ cost to co-train a large family of
models in a federated fashion by leveraging weight-shared learning. We achieve
an order of magnitude cost savings on both communication and computation by
proposing two novel training mechanisms: (a) distribution of weight-shared
models to federated clients, (b) central aggregation of arbitrarily overlapping
weight-shared model parameters. The combination of these mechanisms is shown to
reach an order of magnitude (9.43x) reduction in computation and communication
cost for training a $5*10^{18}$-sized family of models, compared to
independently training as few as $k = 9$ DNNs without any accuracy loss.
</p></li>
</ul>

<h3>Title: Time-sensitive Learning for Heterogeneous Federated Edge Intelligence. (arXiv:2301.10977v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10977">http://arxiv.org/abs/2301.10977</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10977] Time-sensitive Learning for Heterogeneous Federated Edge Intelligence](http://arxiv.org/abs/2301.10977) #federate</code></li>
<li>Summary: <p>Real-time machine learning has recently attracted significant interest due to
its potential to support instantaneous learning, adaptation, and decision
making in a wide range of application domains, including self-driving vehicles,
intelligent transportation, and industry automation. We investigate real-time
ML in a federated edge intelligence (FEI) system, an edge computing system that
implements federated learning (FL) solutions based on data samples collected
and uploaded from decentralized data networks. FEI systems often exhibit
heterogenous communication and computational resource distribution, as well as
non-i.i.d. data samples, resulting in long model training time and inefficient
resource utilization. Motivated by this fact, we propose a time-sensitive
federated learning (TS-FL) framework to minimize the overall run-time for
collaboratively training a shared ML model. Training acceleration solutions for
both TS-FL with synchronous coordination (TS-FL-SC) and asynchronous
coordination (TS-FL-ASC) are investigated. To address straggler effect in
TS-FL-SC, we develop an analytical solution to characterize the impact of
selecting different subsets of edge servers on the overall model training time.
A server dropping-based solution is proposed to allow slow-performance edge
servers to be removed from participating in model training if their impact on
the resulting model accuracy is limited. A joint optimization algorithm is
proposed to minimize the overall time consumption of model training by
selecting participating edge servers, local epoch number. We develop an
analytical expression to characterize the impact of staleness effect of
asynchronous coordination and straggler effect of FL on the time consumption of
TS-FL-ASC. Experimental results show that TS-FL-SC and TS-FL-ASC can provide up
to 63% and 28% of reduction, in the overall model training time, respectively.
</p></li>
</ul>

<h3>Title: Federated Learning over Coupled Graphs. (arXiv:2301.11099v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11099">http://arxiv.org/abs/2301.11099</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11099] Federated Learning over Coupled Graphs](http://arxiv.org/abs/2301.11099) #federate</code></li>
<li>Summary: <p>Graphs are widely used to represent the relations among entities. When one
owns the complete data, an entire graph can be easily built, therefore
performing analysis on the graph is straightforward. However, in many
scenarios, it is impractical to centralize the data due to data privacy
concerns. An organization or party only keeps a part of the whole graph data,
i.e., graph data is isolated from different parties. Recently, Federated
Learning (FL) has been proposed to solve the data isolation issue, mainly for
Euclidean data. It is still a challenge to apply FL on graph data because
graphs contain topological information which is notorious for its non-IID
nature and is hard to partition. In this work, we propose a novel FL framework
for graph data, FedCog, to efficiently handle coupled graphs that are a kind of
distributed graph data, but widely exist in a variety of real-world
applications such as mobile carriers' communication networks and banks'
transaction networks. We theoretically prove the correctness and security of
FedCog. Experimental results demonstrate that our method FedCog significantly
outperforms traditional FL methods on graphs. Remarkably, our FedCog improves
the accuracy of node classification tasks by up to 14.7%.
</p></li>
</ul>

<h3>Title: FedHQL: Federated Heterogeneous Q-Learning. (arXiv:2301.11135v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11135">http://arxiv.org/abs/2301.11135</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11135] FedHQL: Federated Heterogeneous Q-Learning](http://arxiv.org/abs/2301.11135) #federate</code></li>
<li>Summary: <p>Federated Reinforcement Learning (FedRL) encourages distributed agents to
learn collectively from each other's experience to improve their performance
without exchanging their raw trajectories. The existing work on FedRL assumes
that all participating agents are homogeneous, which requires all agents to
share the same policy parameterization (e.g., network architectures and
training configurations). However, in real-world applications, agents are often
in disagreement about the architecture and the parameters, possibly also
because of disparate computational budgets. Because homogeneity is not given in
practice, we introduce the problem setting of Federated Reinforcement Learning
with Heterogeneous And bLack-box agEnts (FedRL-HALE). We present the unique
challenges this new setting poses and propose the Federated Heterogeneous
Q-Learning (FedHQL) algorithm that principally addresses these challenges. We
empirically demonstrate the efficacy of FedHQL in boosting the sample
efficiency of heterogeneous agents with distinct policy parameterization using
standard RL tasks.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Learning from Mistakes: Self-Regularizing Hierarchical Semantic Representations in Point Cloud Segmentation. (arXiv:2301.11145v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11145">http://arxiv.org/abs/2301.11145</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11145] Learning from Mistakes: Self-Regularizing Hierarchical Semantic Representations in Point Cloud Segmentation](http://arxiv.org/abs/2301.11145) #fair</code></li>
<li>Summary: <p>Recent advances in autonomous robotic technologies have highlighted the
growing need for precise environmental analysis. LiDAR semantic segmentation
has gained attention to accomplish fine-grained scene understanding by acting
directly on raw content provided by sensors. Recent solutions showed how
different learning techniques can be used to improve the performance of the
model, without any architectural or dataset change. Following this trend, we
present a coarse-to-fine setup that LEArns from classification mistaKes (LEAK)
derived from a standard model. First, classes are clustered into macro groups
according to mutual prediction errors; then, the learning process is
regularized by: (1) aligning class-conditional prototypical feature
representation for both fine and coarse classes, (2) weighting instances with a
per-class fairness index. Our LEAK approach is very general and can be
seamlessly applied on top of any segmentation architecture; indeed,
experimental results showed that it enables state-of-the-art performances on
different architectures, datasets and tasks, while ensuring more balanced
class-wise results and faster convergence.
</p></li>
</ul>

<h3>Title: BiBench: Benchmarking and Analyzing Network Binarization. (arXiv:2301.11233v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11233">http://arxiv.org/abs/2301.11233</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11233] BiBench: Benchmarking and Analyzing Network Binarization](http://arxiv.org/abs/2301.11233) #fair</code></li>
<li>Summary: <p>Network binarization emerges as one of the most promising compression
approaches offering extraordinary computation and memory savings by minimizing
the bit-width. However, recent research has shown that applying existing
binarization algorithms to diverse tasks, architectures, and hardware in
realistic scenarios is still not straightforward. Common challenges of
binarization, such as accuracy degradation and efficiency limitation, suggest
that its attributes are not fully understood. To close this gap, we present
BiBench, a rigorously designed benchmark with in-depth analysis for network
binarization. We first carefully scrutinize the requirements of binarization in
the actual production and define evaluation tracks and metrics for a
comprehensive and fair investigation. Then, we evaluate and analyze a series of
milestone binarization algorithms that function at the operator level and with
extensive influence. Our benchmark reveals that 1) the binarized operator has a
crucial impact on the performance and deployability of binarized networks; 2)
the accuracy of binarization varies significantly across different learning
tasks and neural architectures; 3) binarization has demonstrated promising
efficiency potential on edge devices despite the limited hardware support. The
results and analysis also lead to a promising paradigm for accurate and
efficient binarization. We believe that BiBench will contribute to the broader
adoption of binarization and serve as a foundation for future research.
</p></li>
</ul>

<h3>Title: Increasing Fairness in Compromise on Accuracy via Weighted Vote with Learning Guarantees. (arXiv:2301.10813v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10813">http://arxiv.org/abs/2301.10813</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10813] Increasing Fairness in Compromise on Accuracy via Weighted Vote with Learning Guarantees](http://arxiv.org/abs/2301.10813) #fair</code></li>
<li>Summary: <p>As the bias issue is being taken more and more seriously in widely applied
machine learning systems, the decrease in accuracy in most cases deeply
disturbs researchers when increasing fairness. To address this problem, we
present a novel analysis of the expected fairness quality via weighted vote,
suitable for both binary and multi-class classification. The analysis takes the
correction of biased predictions by ensemble members into account and provides
learning bounds that are amenable to efficient minimisation. We further propose
a pruning method based on this analysis and the concepts of domination and
Pareto optimality, which is able to increase fairness under a prerequisite of
little or even no accuracy decline. The experimental results indicate that the
proposed learning bounds are faithful and that the proposed pruning method can
indeed increase ensemble fairness without much accuracy degradation.
</p></li>
</ul>

<h3>Title: ZiCo: Zero-shot NAS via Inverse Coefficient of Variation on Gradients. (arXiv:2301.11300v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11300">http://arxiv.org/abs/2301.11300</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11300] ZiCo: Zero-shot NAS via Inverse Coefficient of Variation on Gradients](http://arxiv.org/abs/2301.11300) #fair</code></li>
<li>Summary: <p>Neural Architecture Search (NAS) is widely used to automatically design the
neural network with the best performance among a large number of candidate
architectures. To reduce the search time, zero-shot NAS aims at designing
training-free proxies that can predict the test performance of a given
architecture. However, as shown recently, none of the zero-shot proxies
proposed to date can actually work consistently better than a naive proxy,
namely, the number of network parameters (#Params). To improve this state of
affairs, as the main theoretical contribution, we first reveal how some
specific gradient properties across different samples impact the convergence
rate and generalization capacity of neural networks. Based on this theoretical
analysis, we propose a new zero-shot proxy, ZiCo, the first proxy that works
consistently better than #Params. We demonstrate that ZiCo works better than
State-Of-The-Art (SOTA) proxies on several popular NAS-Benchmarks (NASBench101,
NATSBench-SSS/TSS, TransNASBench-101) for multiple applications (e.g., image
classification/reconstruction and pixel-level prediction). Finally, we
demonstrate that the optimal architectures found via ZiCo are as competitive as
the ones found by one-shot and multi-shot NAS methods, but with much less
search time. For example, ZiCo-based NAS can find optimal architectures with
78.1%, 79.4%, and 80.4% test accuracy under inference budgets of 450M, 600M,
and 1000M FLOPs on ImageNet within 0.4 GPU days.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h2>watermark</h2>
<h3>Title: DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. (arXiv:2301.11305v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11305">http://arxiv.org/abs/2301.11305</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11305] DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature](http://arxiv.org/abs/2301.11305) #watermark</code></li>
<li>Summary: <p>The fluency and factual knowledge of large language models (LLMs) heightens
the need for corresponding systems to detect whether a piece of text is
machine-written. For example, students may use LLMs to complete written
assignments, leaving instructors unable to accurately assess student learning.
In this paper, we first demonstrate that text sampled from an LLM tends to
occupy negative curvature regions of the model's log probability function.
Leveraging this observation, we then define a new curvature-based criterion for
judging if a passage is generated from a given LLM. This approach, which we
call DetectGPT, does not require training a separate classifier, collecting a
dataset of real or generated passages, or explicitly watermarking generated
text. It uses only log probabilities computed by the model of interest and
random perturbations of the passage from another generic pre-trained language
model (e.g, T5). We find DetectGPT is more discriminative than existing
zero-shot methods for model sample detection, notably improving detection of
fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the
strongest zero-shot baseline to 0.95 AUROC for DetectGPT. See
https://ericmitchell.ai/detectgpt for code, data, and other project
information.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: On the Importance of Noise Scheduling for Diffusion Models. (arXiv:2301.10972v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.10972">http://arxiv.org/abs/2301.10972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.10972] On the Importance of Noise Scheduling for Diffusion Models](http://arxiv.org/abs/2301.10972) #diffusion</code></li>
<li>Summary: <p>We empirically study the effect of noise scheduling strategies for denoising
diffusion generative models. There are three findings: (1) the noise scheduling
is crucial for the performance, and the optimal one depends on the task (e.g.,
image sizes), (2) when increasing the image size, the optimal noise scheduling
shifts towards a noisier one (due to increased redundancy in pixels), and (3)
simply scaling the input data by a factor of $b$ while keeping the noise
schedule function fixed (equivalent to shifting the logSNR by $\log b$) is a
good strategy across image sizes. This simple recipe, when combined with
recently proposed Recurrent Interface Network (RIN), yields state-of-the-art
pixel-based diffusion models for high-resolution images on ImageNet, enabling
single-stage, end-to-end generation of diverse and high-fidelity images at
1024$\times$1024 resolution for the first time (without upsampling/cascades).
</p></li>
</ul>

<h3>Title: simple diffusion: End-to-end diffusion for high resolution images. (arXiv:2301.11093v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11093">http://arxiv.org/abs/2301.11093</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11093] simple diffusion: End-to-end diffusion for high resolution images](http://arxiv.org/abs/2301.11093) #diffusion</code></li>
<li>Summary: <p>Currently, applying diffusion models in pixel space of high resolution images
is difficult. Instead, existing approaches focus on diffusion in lower
dimensional spaces (latent diffusion), or have multiple super-resolution levels
of generation referred to as cascades. The downside is that these approaches
add additional complexity to the diffusion framework.
</p></li>
</ul>

<p>This paper aims to improve denoising diffusion for high resolution images
while keeping the model as simple as possible. The paper is centered around the
research question: How can one train a standard denoising diffusion models on
high resolution images, and still obtain performance comparable to these
alternate approaches?
</p>
<p>The four main findings are: 1) the noise schedule should be adjusted for high
resolution images, 2) It is sufficient to scale only a particular part of the
architecture, 3) dropout should be added at specific locations in the
architecture, and 4) downsampling is an effective strategy to avoid high
resolution feature maps. Combining these simple yet effective techniques, we
achieve state-of-the-art on image generation among diffusion models without
sampling modifiers on ImageNet.
</p>

<h3>Title: Text-To-4D Dynamic Scene Generation. (arXiv:2301.11280v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11280">http://arxiv.org/abs/2301.11280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11280] Text-To-4D Dynamic Scene Generation](http://arxiv.org/abs/2301.11280) #diffusion</code></li>
<li>Summary: <p>We present MAV3D (Make-A-Video3D), a method for generating three-dimensional
dynamic scenes from text descriptions. Our approach uses a 4D dynamic Neural
Radiance Field (NeRF), which is optimized for scene appearance, density, and
motion consistency by querying a Text-to-Video (T2V) diffusion-based model. The
dynamic video output generated from the provided text can be viewed from any
camera location and angle, and can be composited into any 3D environment. MAV3D
does not require any 3D or 4D data and the T2V model is trained only on
Text-Image pairs and unlabeled videos. We demonstrate the effectiveness of our
approach using comprehensive quantitative and qualitative experiments and show
an improvement over previously established internal baselines. To the best of
our knowledge, our method is the first to generate 3D dynamic scenes given a
text description.
</p></li>
</ul>

<h3>Title: Contextualizing Emerging Trends in Financial News Articles. (arXiv:2301.11318v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11318">http://arxiv.org/abs/2301.11318</a></li>
<li>Code URL: <a href="https://github.com/nnkhoa/ms-edf-evaluation">https://github.com/nnkhoa/ms-edf-evaluation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11318] Contextualizing Emerging Trends in Financial News Articles](http://arxiv.org/abs/2301.11318) #diffusion</code></li>
<li>Summary: <p>Identifying and exploring emerging trends in the news is becoming more
essential than ever with many changes occurring worldwide due to the global
health crises. However, most of the recent research has focused mainly on
detecting trends in social media, thus, benefiting from social features (e.g.
likes and retweets on Twitter) which helped the task as they can be used to
measure the engagement and diffusion rate of content. Yet, formal text data,
unlike short social media posts, comes with a longer, less restricted writing
format, and thus, more challenging. In this paper, we focus our study on
emerging trends detection in financial news articles about Microsoft, collected
before and during the start of the COVID-19 pandemic (July 2019 to July 2020).
We make the dataset accessible and propose a strong baseline (Contextual
Leap2Trend) for exploring the dynamics of similarities between pairs of
keywords based on topic modelling and term frequency. Finally, we evaluate
against a gold standard (Google Trends) and present noteworthy real-world
scenarios regarding the influence of the pandemic on Microsoft.
</p></li>
</ul>

<h3>Title: On the Mathematics of Diffusion Models. (arXiv:2301.11108v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.11108">http://arxiv.org/abs/2301.11108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.11108] On the Mathematics of Diffusion Models](http://arxiv.org/abs/2301.11108) #diffusion</code></li>
<li>Summary: <p>This paper attempts to present the stochastic differential equations of
diffusion models in a manner that is accessible to a broad audience. The
diffusion process is defined over a population density in R^d. Of particular
interest is a population of images. In a diffusion model one first defines a
diffusion process that takes a sample from the population and gradually adds
noise until only noise remains. The fundamental idea is to sample from the
population by a reverse-diffusion process mapping pure noise to a population
sample. The diffusion process is defined independent of any <code>interpretation''
but can be analyzed using the mathematics of variational auto-encoders (the</code>VAE interpretation'') or the Fokker-Planck equation (the ``score-matching
intgerpretation''). Both analyses yield reverse-diffusion methods involving the
score function. The Fokker-Planck analysis yields a family of reverse-diffusion
SDEs parameterized by any desired level of reverse-diffusion noise including
zero (deterministic reverse-diffusion). The VAE analysis yields the
reverse-diffusion SDE at the same noise level as the diffusion SDE. The VAE
analysis also yields a useful expression for computing the population
probabilities of a given point (image). This formula for the probability of a
given point does not seem to follow naturally from the Fokker-Planck analysis.
Much, but apparently not all, of the mathematics presented here can be found in
the literature. Attributions are given at the end of the paper.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
