<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Heart Diseases Prediction Using Block-chain and Machine Learning. (arXiv:2306.01817v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01817">http://arxiv.org/abs/2306.01817</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01817] Heart Diseases Prediction Using Block-chain and Machine Learning](http://arxiv.org/abs/2306.01817) #secure</code></li>
<li>Summary: <p>Most people around the globe are dying due to heart disease. The main reason
behind the rapid increase in the death rate due to heart disease is that there
is no infrastructure developed for the healthcare department that can provide a
secure way of data storage and transmission. Due to redundancy in the patient
data, it is difficult for cardiac Professionals to predict the disease early
on. This rapid increase in the death rate due to heart disease can be
controlled by monitoring and eliminating some of the key attributes in the
early stages such as blood pressure, cholesterol level, body weight, and
addiction to smoking. Patient data can be monitored by cardiac Professionals
(Cp) by using the advanced framework in the healthcare departments. Blockchain
is the world's most reliable provider. The use of advanced systems in the
healthcare departments providing new ways of dealing with diseases has been
developed as well. In this article Machine Learning (ML) algorithm known as a
sine-cosine weighted k-nearest neighbor (SCA-WKNN) is used for predicting the
Hearth disease with the maximum accuracy among the existing approaches.
Blockchain technology has been used in the research to secure the data
throughout the session and can give more accurate results using this
technology. The performance of the system can be improved by using this
algorithm and the dataset proposed has been improved by using different
resources as well.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Systemic Risk and Vulnerability Analysis of Multi-cloud Environments. (arXiv:2306.01862v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01862">http://arxiv.org/abs/2306.01862</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01862] Systemic Risk and Vulnerability Analysis of Multi-cloud Environments](http://arxiv.org/abs/2306.01862) #security</code></li>
<li>Summary: <p>With the increasing use of multi-cloud environments, security professionals
face challenges in configuration, management, and integration due to uneven
security capabilities and features among providers. As a result, a fragmented
approach toward security has been observed, leading to new attack vectors and
potential vulnerabilities. Other research has focused on single-cloud platforms
or specific applications of multi-cloud environments. Therefore, there is a
need for a holistic security and vulnerability assessment and defense strategy
that applies to multi-cloud platforms. We perform a risk and vulnerability
analysis to identify attack vectors from software, hardware, and the network,
as well as interoperability security issues in multi-cloud environments.
Applying the STRIDE and DREAD threat modeling methods, we present an analysis
of the ecosystem across six attack vectors: cloud architecture, APIs,
authentication, automation, management differences, and cybersecurity
legislation. We quantitatively determine and rank the threats in multi-cloud
environments and suggest mitigation strategies.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: CSI-Based Efficient Self-Quarantine Monitoring System Using Branchy Convolution Neural Network. (arXiv:2306.01756v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01756">http://arxiv.org/abs/2306.01756</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01756] CSI-Based Efficient Self-Quarantine Monitoring System Using Branchy Convolution Neural Network](http://arxiv.org/abs/2306.01756) #privacy</code></li>
<li>Summary: <p>Nowadays, Coronavirus disease (COVID-19) has become a global pandemic because
of its fast spread in various countries. To build an anti-epidemic barrier,
self-isolation is required for people who have been to any at-risk places or
have been in close contact with infected people. However, existing camera or
wearable device-based monitoring systems may present privacy leakage risks or
cause user inconvenience in some cases. In this paper, we propose a Wi-Fi-based
device-free self-quarantine monitoring system. Specifically, we exploit channel
state information (CSI) derived from Wi-Fi signals as human activity features.
We collect CSI data in a simulated self-quarantine scenario and present
BranchyGhostNet, a lightweight convolution neural network (CNN) with an early
exit prediction branch, for the efficient joint task of room occupancy
detection (ROD) and human activity recognition (HAR). The early exiting branch
is used for ROD, and the final one is used for HAR. Our experimental results
indicate that the proposed model can achieve an average accuracy of 98.19% for
classifying five different human activities. They also confirm that after
leveraging the early exit prediction mechanism, the inference latency for ROD
can be significantly reduced by 54.04% when compared with the final exiting
branch while guaranteeing the accuracy of ROD.
</p></li>
</ul>

<h3>Title: Differential Privacy with Random Projections and Sign Random Projections. (arXiv:2306.01751v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01751">http://arxiv.org/abs/2306.01751</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01751] Differential Privacy with Random Projections and Sign Random Projections](http://arxiv.org/abs/2306.01751) #privacy</code></li>
<li>Summary: <p>In this paper, we develop a series of differential privacy (DP) algorithms
from a family of random projections (RP), for general applications in machine
learning, data mining, and information retrieval. Among the presented
algorithms, \textbf{iDP-SignRP} is remarkably effective under the setting of
<code>individual differential privacy'' (iDP), based on sign random projections
(SignRP). Also, \textbf{DP-SignOPORP} considerably improves existing algorithms
in the literature under the standard DP setting, using</code>one permutation + one
random projection'' (OPORP), where OPORP is a variant of the celebrated
count-sketch method with fixed-length binning and normalization. Without taking
signs, among the DP-RP family, \textbf{DP-OPORP} achieves the best performance.
</p></li>
</ul>

<p>The concept of iDP (individual differential privacy) is defined only on a
particular dataset of interest. While iDP is not strictly DP, iDP might be
useful in certain applications, such as releasing a dataset (including sharing
embeddings across companies or countries). In our study, we find that
\textbf{iDP-SignRP} is remarkably effective for search and machine learning
applications, in that the utilities are exceptionally good even at a very small
privacy parameter $\epsilon$ (e.g., $\epsilon<0.5$).
</p>

<h2>protect</h2>
<h3>Title: Discovering COVID-19 Coughing and Breathing Patterns from Unlabeled Data Using Contrastive Learning with Varying Pre-Training Domains. (arXiv:2306.01864v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01864">http://arxiv.org/abs/2306.01864</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01864] Discovering COVID-19 Coughing and Breathing Patterns from Unlabeled Data Using Contrastive Learning with Varying Pre-Training Domains](http://arxiv.org/abs/2306.01864) #protect</code></li>
<li>Summary: <p>Rapid discovery of new diseases, such as COVID-19 can enable a timely
epidemic response, preventing the large-scale spread and protecting public
health. However, limited research efforts have been taken on this problem. In
this paper, we propose a contrastive learning-based modeling approach for
COVID-19 coughing and breathing pattern discovery from non-COVID coughs. To
validate our models, extensive experiments have been conducted using four large
audio datasets and one image dataset. We further explore the effects of
different factors, such as domain relevance and augmentation order on the
pre-trained models. Our results show that the proposed model can effectively
distinguish COVID-19 coughing and breathing from unlabeled data and labeled
non-COVID coughs with an accuracy of up to 0.81 and 0.86, respectively.
Findings from this work will guide future research to detect an outbreak of a
new disease early.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Adversarial Attack Based on Prediction-Correction. (arXiv:2306.01809v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01809">http://arxiv.org/abs/2306.01809</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01809] Adversarial Attack Based on Prediction-Correction](http://arxiv.org/abs/2306.01809) #attack</code></li>
<li>Summary: <p>Deep neural networks (DNNs) are vulnerable to adversarial examples obtained
by adding small perturbations to original examples. The added perturbations in
existing attacks are mainly determined by the gradient of the loss function
with respect to the inputs. In this paper, the close relationship between
gradient-based attacks and the numerical methods for solving ordinary
differential equation (ODE) is studied for the first time. Inspired by the
numerical solution of ODE, a new prediction-correction (PC) based adversarial
attack is proposed. In our proposed PC-based attack, some existing attack can
be selected to produce a predicted example first, and then the predicted
example and the current example are combined together to determine the added
perturbations. The proposed method possesses good extensibility and can be
applied to all available gradient-based attacks easily. Extensive experiments
demonstrate that compared with the state-of-the-art gradient-based adversarial
attacks, our proposed PC-based attacks have higher attack success rates, and
exhibit better transferability.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Unifying (Machine) Vision via Counterfactual World Modeling. (arXiv:2306.01828v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01828">http://arxiv.org/abs/2306.01828</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01828] Unifying (Machine) Vision via Counterfactual World Modeling](http://arxiv.org/abs/2306.01828) #robust</code></li>
<li>Summary: <p>Leading approaches in machine vision employ different architectures for
different tasks, trained on costly task-specific labeled datasets. This
complexity has held back progress in areas, such as robotics, where robust
task-general perception remains a bottleneck. In contrast, "foundation models"
of natural language have shown how large pre-trained neural networks can
provide zero-shot solutions to a broad spectrum of apparently distinct tasks.
Here we introduce Counterfactual World Modeling (CWM), a framework for
constructing a visual foundation model: a unified, unsupervised network that
can be prompted to perform a wide variety of visual computations. CWM has two
key components, which resolve the core issues that have hindered application of
the foundation model concept to vision. The first is structured masking, a
generalization of masked prediction methods that encourages a prediction model
to capture the low-dimensional structure in visual data. The model thereby
factors the key physical components of a scene and exposes an interface to them
via small sets of visual tokens. This in turn enables CWM's second main idea --
counterfactual prompting -- the observation that many apparently distinct
visual representations can be computed, in a zero-shot manner, by comparing the
prediction model's output on real inputs versus slightly modified
("counterfactual") inputs. We show that CWM generates high-quality readouts on
real-world images and videos for a diversity of tasks, including estimation of
keypoints, optical flow, occlusions, object segments, and relative depth. Taken
together, our results show that CWM is a promising path to unifying the
manifold strands of machine vision in a conceptually simple foundation.
</p></li>
</ul>

<h3>Title: DH-PTAM: A Deep Hybrid Stereo Events-Frames Parallel Tracking And Mapping System. (arXiv:2306.01891v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01891">http://arxiv.org/abs/2306.01891</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01891] DH-PTAM: A Deep Hybrid Stereo Events-Frames Parallel Tracking And Mapping System](http://arxiv.org/abs/2306.01891) #robust</code></li>
<li>Summary: <p>This paper presents a robust approach for a visual parallel tracking and
mapping (PTAM) system that excels in challenging environments. Our proposed
method combines the strengths of heterogeneous multi-modal visual sensors,
including stereo event-based and frame-based sensors, in a unified reference
frame through a novel spatio-temporal synchronization of stereo visual frames
and stereo event streams. We employ deep learning-based feature extraction and
description for estimation to enhance robustness further. We also introduce an
end-to-end parallel tracking and mapping optimization layer complemented by a
simple loop-closure algorithm for efficient SLAM behavior. Through
comprehensive experiments on both small-scale and large-scale real-world
sequences of VECtor and TUM-VIE benchmarks, our proposed method (DH-PTAM)
demonstrates superior performance compared to state-of-the-art methods in terms
of robustness and accuracy in adverse conditions. Our implementation's
research-based Python API is publicly available on GitHub for further research
and development: https://github.com/AbanobSoliman/DH-PTAM.
</p></li>
</ul>

<h3>Title: Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes. (arXiv:2306.01805v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01805">http://arxiv.org/abs/2306.01805</a></li>
<li>Code URL: <a href="https://github.com/revathyramanan/cooking-action-generation">https://github.com/revathyramanan/cooking-action-generation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01805] Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes](http://arxiv.org/abs/2306.01805) #robust</code></li>
<li>Summary: <p>As people become more aware of their food choices, food computation models
have become increasingly popular in assisting people in maintaining healthy
eating habits. For example, food recommendation systems analyze recipe
instructions to assess nutritional contents and provide recipe recommendations.
The recent and remarkable successes of generative AI methods, such as
auto-regressive large language models, can lead to robust methods for a more
comprehensive understanding of recipes for healthy food recommendations beyond
surface-level nutrition content assessments. In this study, we explore the use
of generative AI methods to extend current food computation models, primarily
involving the analysis of nutrition and ingredients, to also incorporate
cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.).
Cooking actions are notoriously hard to model using statistical learning
methods due to irregular data patterns - significantly varying natural language
descriptions for the same action (e.g., marinate the meat vs. marinate the meat
and leave overnight) and infrequently occurring patterns (e.g., add salt occurs
far more frequently than marinating the meat). The prototypical approach to
handling irregular data patterns is to increase the volume of data that the
model ingests by orders of magnitude. Unfortunately, in the cooking domain,
these problems are further compounded with larger data volumes presenting a
unique challenge that is not easily handled by simply scaling up. In this work,
we propose novel aggregation-based generative AI methods, Cook-Gen, that
reliably generate cooking actions from recipes, despite difficulties with
irregular data patterns, while also outperforming Large Language Models and
other strong baselines.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Beta Thalassemia Carriers detection empowered federated Learning. (arXiv:2306.01818v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01818">http://arxiv.org/abs/2306.01818</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01818] Beta Thalassemia Carriers detection empowered federated Learning](http://arxiv.org/abs/2306.01818) #federate</code></li>
<li>Summary: <p>Thalassemia is a group of inherited blood disorders that happen when
hemoglobin, the protein in red blood cells that carries oxygen, is not made
enough. It is found all over the body and is needed for survival. If both
parents have thalassemia, a child's chance of getting it increases. Genetic
counselling and early diagnosis are essential for treating thalassemia and
stopping it from being passed on to future generations. It may be hard for
healthcare professionals to differentiate between people with thalassemia
carriers and those without. The current blood tests for beta thalassemia
carriers are too expensive, take too long, and require too much screening
equipment. The World Health Organization says there is a high death rate for
people with thalassemia. Therefore, it is essential to find thalassemia
carriers to act quickly. High-performance liquid chromatography (HPLC), the
standard test method, has problems such as cost, time, and equipment needs. So,
there must be a quick and cheap way to find people carrying the thalassemia
gene. Using federated learning (FL) techniques, this study shows a new way to
find people with the beta-thalassemia gene. FL allows data to be collected and
processed on-site while following privacy rules, making it an excellent choice
for sensitive health data. Researchers used FL to train a model for
beta-thalassemia carriers by looking at the complete blood count results and
red blood cell indices. The model was 92.38 % accurate at telling the
difference between beta-thalassemia carriers and people who did not have the
disease. The proposed FL model is better than other published methods in terms
of how well it works, how reliable it is, and how private it is. This research
shows a promising, quick, accurate, and low-cost way to find thalassemia
carriers and opens the door for screening them on a large scale.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01755">http://arxiv.org/abs/2306.01755</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01755] Training Priors Predict Text-To-Image Model Performance](http://arxiv.org/abs/2306.01755) #diffusion</code></li>
<li>Summary: <p>Text-to-image models can often generate some relations, i.e., "astronaut
riding horse", but fail to generate other relations composed of the same basic
parts, i.e., "horse riding astronaut". These failures are often taken as
evidence that the models rely on training priors rather than constructing novel
images compositionally. This paper tests this intuition directly on the
stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object
(SVO) triads that form the backbone of these prompts (e.g., "astronaut",
"ride", "horse"), we find that the more often an SVO triad appears in the
training data, the better the model can generate an image aligned with that
triad. Here, by aligned we mean that each of the terms appears in the generated
image in the proper relation to each other. However, this increased frequency
also diminishes how well the model can generate an image aligned with the
flipped triad. For example, if "astronaut riding horse" appears frequently in
the training data, the image for "horse riding astronaut" will tend to be
poorly aligned. We also find that models often struggle to generate terms in
atypical roles, e.g., if "horse" is more often the semantic patient (object),
the model might struggle to visualize it as a semantic agent (subject). Our
results thus show that current models are biased to generate images aligned
with relations seen in training and provide important new data in the ongoing
debate on whether these text-to-image models employ abstract compositional
structure in a traditional sense, or rather, interpolate between relations
explicitly seen in the training data.
</p></li>
</ul>

<h3>Title: DiffECG: A Generalized Probabilistic Diffusion Model for ECG Signals Synthesis. (arXiv:2306.01875v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01875">http://arxiv.org/abs/2306.01875</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01875] DiffECG: A Generalized Probabilistic Diffusion Model for ECG Signals Synthesis](http://arxiv.org/abs/2306.01875) #diffusion</code></li>
<li>Summary: <p>In recent years, deep generative models have gained attention as a promising
data augmentation solution for heart disease detection using deep learning
approaches applied to ECG signals. In this paper, we introduce a novel approach
based on denoising diffusion probabilistic models for ECG synthesis that covers
three scenarios: heartbeat generation, partial signal completion, and full
heartbeat forecasting. Our approach represents the first generalized
conditional approach for ECG synthesis, and our experimental results
demonstrate its effectiveness for various ECG-related tasks. Moreover, we show
that our approach outperforms other state-of-the-art ECG generative models and
can enhance the performance of state-of-the-art classifiers.
</p></li>
</ul>

<h3>Title: Conditional Generation from Unconditional Diffusion Models using Denoiser Representations. (arXiv:2306.01900v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01900">http://arxiv.org/abs/2306.01900</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01900] Conditional Generation from Unconditional Diffusion Models using Denoiser Representations](http://arxiv.org/abs/2306.01900) #diffusion</code></li>
<li>Summary: <p>Denoising diffusion models have gained popularity as a generative modeling
technique for producing high-quality and diverse images. Applying these models
to downstream tasks requires conditioning, which can take the form of text,
class labels, or other forms of guidance. However, providing conditioning
information to these models can be challenging, particularly when annotations
are scarce or imprecise. In this paper, we propose adapting pre-trained
unconditional diffusion models to new conditions using the learned internal
representations of the denoiser network. We demonstrate the effectiveness of
our approach on various conditional generation tasks, including
attribute-conditioned generation and mask-conditioned generation. Additionally,
we show that augmenting the Tiny ImageNet training set with synthetic images
generated by our approach improves the classification accuracy of ResNet
baselines by up to 8%. Our approach provides a powerful and flexible way to
adapt diffusion models to new conditions and generate high-quality augmented
data for various conditional generation tasks.
</p></li>
</ul>

<h3>Title: Extracting Reward Functions from Diffusion Models. (arXiv:2306.01804v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01804">http://arxiv.org/abs/2306.01804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01804] Extracting Reward Functions from Diffusion Models](http://arxiv.org/abs/2306.01804) #diffusion</code></li>
<li>Summary: <p>Diffusion models have achieved remarkable results in image generation, and
have similarly been used to learn high-performing policies in sequential
decision-making tasks. Decision-making diffusion models can be trained on
lower-quality data, and then be steered with a reward function to generate
near-optimal trajectories. We consider the problem of extracting a reward
function by comparing a decision-making diffusion model that models low-reward
behavior and one that models high-reward behavior; a setting related to inverse
reinforcement learning. We first define the notion of a relative reward
function of two diffusion models and show conditions under which it exists and
is unique. We then devise a practical learning algorithm for extracting it by
aligning the gradients of a reward function -- parametrized by a neural network
-- to the difference in outputs of both diffusion models. Our method finds
correct reward functions in navigation environments, and we demonstrate that
steering the base model with the learned reward functions results in
significantly increased performance in standard locomotion benchmarks. Finally,
we demonstrate that our approach generalizes beyond sequential decision-making
by learning a reward-like function from two large-scale image generation
diffusion models. The extracted reward function successfully assigns lower
rewards to harmful images.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Pre-trained transformer for adversarial purification. (arXiv:2306.01762v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01762">http://arxiv.org/abs/2306.01762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01762] Pre-trained transformer for adversarial purification](http://arxiv.org/abs/2306.01762) #transformer</code></li>
<li>Summary: <p>With more and more deep neural networks being deployed as various daily
services, their reliability is essential. It's frightening that deep neural
networks are vulnerable and sensitive to adversarial attacks, the most common
one of which for the services is evasion-based. Recent works usually strengthen
the robustness by adversarial training or leveraging the knowledge of an amount
of clean data. However, in practical terms, retraining and redeploying the
model need a large computational budget, leading to heavy losses to the online
service. In addition, when adversarial examples of a certain attack are
detected, only limited adversarial examples are available for the service
provider, while much clean data may not be accessible. Given the mentioned
problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is
to rapidly defend against a certain attack for the frozen original service
model with limitations of few clean and adversarial examples. Motivated by the
generalization and the universal computation ability of pre-trained transformer
models, we come up with a new defender method, CeTaD, which stands for
Considering Pre-trained Transformers as Defenders. In particular, we evaluate
the effectiveness and the transferability of CeTaD in the case of one-shot
adversarial examples and explore the impact of different parts of CeTaD as well
as training data conditions. CeTaD is flexible, able to be embedded into an
arbitrary differentiable model, and suitable for various types of attacks.
</p></li>
</ul>

<h3>Title: Open-world Text-specified Object Counting. (arXiv:2306.01851v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01851">http://arxiv.org/abs/2306.01851</a></li>
<li>Code URL: <a href="https://github.com/niki-amini-naieni/countx">https://github.com/niki-amini-naieni/countx</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01851] Open-world Text-specified Object Counting](http://arxiv.org/abs/2306.01851) #transformer</code></li>
<li>Summary: <p>Our objective is open-world object counting in images, where the target
object class is specified by a text description. To this end, we propose
CounTX, a class-agnostic, single-stage model using a transformer decoder
counting head on top of pre-trained joint text-image representations. CounTX is
able to count the number of instances of any class given only an image and a
text description of the target object class, and can be trained end-to-end. To
the best of our knowledge, we are the first to tackle the open-world counting
problem in this way. In addition to this model, we make the following
contributions: (i) we compare the performance of CounTX to prior work on
open-world object counting, and show that our approach exceeds the state of the
art on all measures on the FSC-147 benchmark for methods that use text to
specify the task; (ii) we present and release FSC-147-D, an enhanced version of
FSC-147 with text descriptions, so that object classes can be described with
more detailed language than their simple class names. FSC-147-D is available at
https://github.com/niki-amini-naieni/CounTX/.
</p></li>
</ul>

<h3>Title: Comparative study on Judgment Text Classification for Transformer Based Models. (arXiv:2306.01739v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01739">http://arxiv.org/abs/2306.01739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01739] Comparative study on Judgment Text Classification for Transformer Based Models](http://arxiv.org/abs/2306.01739) #transformer</code></li>
<li>Summary: <p>This work involves the usage of various NLP models to predict the winner of a
particular judgment by the means of text extraction and summarization from a
judgment document. These documents are useful when it comes to legal
proceedings. One such advantage is that these can be used for citations and
precedence reference in Lawsuits and cases which makes a strong argument for
their case by the ones using it. When it comes to precedence, it is necessary
to refer to an ample number of documents in order to collect legal points with
respect to the case. However, reviewing these documents takes a long time to
analyze due to the complex word structure and the size of the document. This
work involves the comparative study of 6 different self-attention-based
transformer models and how they perform when they are being tweaked in 4
different activation functions. These models which are trained with 200
judgement contexts and their results are being judged based on different
benchmark parameters. These models finally have a confidence level up to 99%
while predicting the judgment. This can be used to get a particular judgment
document without spending too much time searching relevant cases and reading
them completely.
</p></li>
</ul>

<h3>Title: Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning. (arXiv:2306.01761v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01761">http://arxiv.org/abs/2306.01761</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01761] Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning](http://arxiv.org/abs/2306.01761) #transformer</code></li>
<li>Summary: <p>ChatGPT is a conversational artificial intelligence that is a member of the
generative pre-trained transformer of the large language model family. This
text generative model was fine-tuned by both supervised learning and
reinforcement learning so that it can produce text documents that seem to be
written by natural intelligence. Although there are numerous advantages of this
generative model, it comes with some reasonable concerns as well. This paper
presents a machine learning-based solution that can identify the ChatGPT
delivered text from the human written text along with the comparative analysis
of a total of 11 machine learning and deep learning algorithms in the
classification process. We have tested the proposed model on a Kaggle dataset
consisting of 10,000 texts out of which 5,204 texts were written by humans and
collected from news and social media. On the corpus generated by GPT-3.5, the
proposed algorithm presents an accuracy of 77%.
</p></li>
</ul>

<h3>Title: A Quantitative Review on Language Model Efficiency Research. (arXiv:2306.01768v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01768">http://arxiv.org/abs/2306.01768</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01768] A Quantitative Review on Language Model Efficiency Research](http://arxiv.org/abs/2306.01768) #transformer</code></li>
<li>Summary: <p>Language models (LMs) are being scaled and becoming powerful. Improving their
efficiency is one of the core research topics in neural information processing
systems. Tay et al. (2022) provided a comprehensive overview of efficient
Transformers that have become an indispensable staple in the field of NLP.
However, in the section of "On Evaluation", they left an open question "which
fundamental efficient Transformer one should consider," answered by "still a
mystery" because "many research papers select their own benchmarks."
Unfortunately, there was not quantitative analysis about the performances of
Transformers on any benchmarks. Moreover, state space models (SSMs) have
demonstrated their abilities of modeling long-range sequences with
non-attention mechanisms, which were not discussed in the prior review. This
article makes a meta analysis on the results from a set of papers on efficient
Transformers as well as those on SSMs. It provides a quantitative review on LM
efficiency research and gives suggestions for future research.
</p></li>
</ul>

<h3>Title: Binary and Ternary Natural Language Generation. (arXiv:2306.01841v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01841">http://arxiv.org/abs/2306.01841</a></li>
<li>Code URL: <a href="https://github.com/facebookresearch/ternary_binary_transformer">https://github.com/facebookresearch/ternary_binary_transformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01841] Binary and Ternary Natural Language Generation](http://arxiv.org/abs/2306.01841) #transformer</code></li>
<li>Summary: <p>Ternary and binary neural networks enable multiplication-free computation and
promise multiple orders of magnitude efficiency gains over full-precision
networks if implemented on specialized hardware. However, since both the
parameter and the output space are highly discretized, such networks have
proven very difficult to optimize. The difficulties are compounded for the
class of transformer text generation models due to the sensitivity of the
attention operation to quantization and the noise-compounding effects of
autoregressive decoding in the high-cardinality output space. We approach the
problem with a mix of statistics-based quantization for the weights and elastic
quantization of the activations and demonstrate the first ternary and binary
transformer models on the downstream tasks of summarization and machine
translation. Our ternary BART base achieves an R1 score of 41 on the
CNN/DailyMail benchmark, which is merely 3.9 points behind the full model while
being 16x more efficient. Our binary model, while less accurate, achieves a
highly non-trivial score of 35.6. For machine translation, we achieved BLEU
scores of 21.7 and 17.6 on the WMT16 En-Ro benchmark, compared with a full
precision mBART model score of 26.8. We also compare our approach in the 8-bit
activation setting, where our ternary and even binary weight models can match
or outperform the best existing 8-bit weight models in the literature. Our code
and models are available at:
https://github.com/facebookresearch/Ternary_Binary_Transformer
</p></li>
</ul>

<h3>Title: Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?. (arXiv:2306.01754v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01754">http://arxiv.org/abs/2306.01754</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01754] Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?](http://arxiv.org/abs/2306.01754) #transformer</code></li>
<li>Summary: <p>Software vulnerabilities bear enterprises significant costs. Despite
extensive efforts in research and development of software vulnerability
detection methods, uncaught vulnerabilities continue to put software owners and
users at risk. Many current vulnerability detection methods require that code
snippets can compile and build before attempting detection. This,
unfortunately, introduces a long latency between the time a vulnerability is
injected to the time it is removed, which can substantially increases the cost
of fixing a vulnerability. We recognize that the current advances in machine
learning can be used to detect vulnerable code patterns on syntactically
incomplete code snippets as the developer is writing the code at EditTime. In
this paper we present a practical system that leverages deep learning on a
large-scale data set of vulnerable code patterns to learn complex
manifestations of more than 250 vulnerability types and detect vulnerable code
patterns at EditTime. We discuss zero-shot, few-shot, and fine-tuning
approaches on state of the art pre-trained Large Language Models (LLMs). We
show that in comparison with state of the art vulnerability detection models
our approach improves the state of the art by 10%. We also evaluate our
approach to detect vulnerability in auto-generated code by code LLMs.
Evaluation on a benchmark of high-risk code scenarios shows a reduction of up
to 90% vulnerability reduction.
</p></li>
</ul>

<h3>Title: Concurrent Classifier Error Detection (CCED) in Large Scale Machine Learning Systems. (arXiv:2306.01820v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01820">http://arxiv.org/abs/2306.01820</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01820] Concurrent Classifier Error Detection (CCED) in Large Scale Machine Learning Systems](http://arxiv.org/abs/2306.01820) #transformer</code></li>
<li>Summary: <p>The complexity of Machine Learning (ML) systems increases each year, with
current implementations of large language models or text-to-image generators
having billions of parameters and requiring billions of arithmetic operations.
As these systems are widely utilized, ensuring their reliable operation is
becoming a design requirement. Traditional error detection mechanisms introduce
circuit or time redundancy that significantly impacts system performance. An
alternative is the use of Concurrent Error Detection (CED) schemes that operate
in parallel with the system and exploit their properties to detect errors. CED
is attractive for large ML systems because it can potentially reduce the cost
of error detection. In this paper, we introduce Concurrent Classifier Error
Detection (CCED), a scheme to implement CED in ML systems using a concurrent ML
classifier to detect errors. CCED identifies a set of check signals in the main
ML system and feeds them to the concurrent ML classifier that is trained to
detect errors. The proposed CCED scheme has been implemented and evaluated on
two widely used large-scale ML models: Contrastive Language Image Pretraining
(CLIP) used for image classification and Bidirectional Encoder Representations
from Transformers (BERT) used for natural language applications. The results
show that more than 95 percent of the errors are detected when using a simple
Random Forest classifier that is order of magnitude simpler than CLIP or BERT.
These results illustrate the potential of CCED to implement error detection in
large-scale ML models.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. (arXiv:2306.01879v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01879">http://arxiv.org/abs/2306.01879</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01879] VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores](http://arxiv.org/abs/2306.01879) #generative</code></li>
<li>Summary: <p>Vision-language models (VLMs) discriminatively pre-trained with contrastive
image-text matching losses such as $P(\text{match}|\text{text}, \text{image})$
have been criticized for lacking compositional understanding. This means they
might output similar scores even if the original caption is rearranged into a
different semantic statement. To address this, we propose to use the ${\bf
V}$isual ${\bf G}$enerative ${\bf P}$re-${\bf T}$raining Score (${\bf
VisualGPTScore}$) of $P(\text{text}|\text{image})$, a $\textit{multimodal
generative}$ score that captures the likelihood of a text caption conditioned
on an image using an image-conditioned language model. Contrary to the belief
that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore
demonstrates top-tier performance on recently proposed image-text retrieval
benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore,
we factorize VisualGPTScore into a product of the $\textit{marginal}$ P(text)
and the $\textit{Pointwise Mutual Information}$ (PMI). This helps to (a)
diagnose datasets with strong language bias, and (b) debias results on other
benchmarks like Winoground using an information-theoretic framework.
VisualGPTScore provides valuable insights and serves as a strong baseline for
future evaluation of visio-linguistic compositionality.
</p></li>
</ul>

<h3>Title: Maximum Likelihood Training of Autoencoders. (arXiv:2306.01843v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01843">http://arxiv.org/abs/2306.01843</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01843] Maximum Likelihood Training of Autoencoders](http://arxiv.org/abs/2306.01843) #generative</code></li>
<li>Summary: <p>Maximum likelihood training has favorable statistical properties and is
popular for generative modeling, especially with normalizing flows. On the
other hand, generative autoencoders promise to be more efficient than
normalizing flows due to the manifold hypothesis. In this work, we introduce
successful maximum likelihood training of unconstrained autoencoders for the
first time, bringing the two paradigms together. To do so, we identify and
overcome two challenges: Firstly, existing maximum likelihood estimators for
free-form networks are unacceptably slow, relying on iteration schemes whose
cost scales linearly with latent dimension. We introduce an improved estimator
which eliminates iteration, resulting in constant cost (roughly double the
runtime per batch of a vanilla autoencoder). Secondly, we demonstrate that
naively applying maximum likelihood to autoencoders can lead to divergent
solutions and use this insight to motivate a stable maximum likelihood training
objective. We perform extensive experiments on toy, tabular and image data,
demonstrating the competitive performance of the resulting model. We call our
model the maximum likelihood autoencoder (MLAE).
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Conceptual Design Generation Using Large Language Models. (arXiv:2306.01779v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01779">http://arxiv.org/abs/2306.01779</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01779] Conceptual Design Generation Using Large Language Models](http://arxiv.org/abs/2306.01779) #large language model</code></li>
<li>Summary: <p>Concept generation is a creative step in the conceptual design phase, where
designers often turn to brainstorming, mindmapping, or crowdsourcing design
ideas to complement their own knowledge of the domain. Recent advances in
natural language processing (NLP) and machine learning (ML) have led to the
rise of Large Language Models (LLMs) capable of generating seemingly creative
outputs from textual prompts. The success of these models has led to their
integration and application across a variety of domains, including art,
entertainment, and other creative work. In this paper, we leverage LLMs to
generate solutions for a set of 12 design problems and compare them to a
baseline of crowdsourced solutions. We evaluate the differences between
generated and crowdsourced design solutions through multiple perspectives,
including human expert evaluations and computational metrics. Expert
evaluations indicate that the LLM-generated solutions have higher average
feasibility and usefulness while the crowdsourced solutions have more novelty.
We experiment with prompt engineering and find that leveraging few-shot
learning can lead to the generation of solutions that are more similar to the
crowdsourced solutions. These findings provide insight into the quality of
design solutions generated with LLMs and begins to evaluate prompt engineering
techniques that could be leveraged by practitioners to generate higher-quality
design solutions synergistically with LLMs.
</p></li>
</ul>

<h3>Title: Knowledge of cultural moral norms in large language models. (arXiv:2306.01857v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.01857">http://arxiv.org/abs/2306.01857</a></li>
<li>Code URL: <a href="https://github.com/aidaramezani/cultural_inference">https://github.com/aidaramezani/cultural_inference</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.01857] Knowledge of cultural moral norms in large language models](http://arxiv.org/abs/2306.01857) #large language model</code></li>
<li>Summary: <p>Moral norms vary across cultures. A recent line of work suggests that English
large language models contain human-like moral biases, but these studies
typically do not examine moral variation in a diverse cultural setting. We
investigate the extent to which monolingual English language models contain
knowledge about moral norms in different countries. We consider two levels of
analysis: 1) whether language models capture fine-grained moral variation
across countries over a variety of topics such as <code>homosexuality'' and</code>divorce''; 2) whether language models capture cultural diversity and shared
tendencies in which topics people around the globe tend to diverge or agree on
in their moral judgment. We perform our analyses with two public datasets from
the World Values Survey (across 55 countries) and PEW global surveys (across 40
countries) on morality. We find that pre-trained English language models
predict empirical moral norms across countries worse than the English moral
norms reported previously. However, fine-tuning language models on the survey
data improves inference across countries at the expense of a less accurate
estimate of the English moral norms. We discuss the relevance and challenges of
incorporating cultural knowledge into the automated inference of moral norms.
</p></li>
</ul>

<h2>segmentation</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
