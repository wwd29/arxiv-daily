<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Masked Autoencoders Enable Efficient Knowledge Distillers. (arXiv:2208.12256v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12256">http://arxiv.org/abs/2208.12256</a></li>
<li>Code URL: <a href="https://github.com/ucsc-vlaa/dmae">https://github.com/ucsc-vlaa/dmae</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12256] Masked Autoencoders Enable Efficient Knowledge Distillers](http://arxiv.org/abs/2208.12256)</code></li>
<li>Summary: <p>This paper studies the potential of distilling knowledge from pre-trained
models, especially Masked Autoencoders. Our approach is simple: in addition to
optimizing the pixel reconstruction loss on masked inputs, we minimize the
distance between the intermediate feature map of the teacher model and that of
the student model. This design leads to a computationally efficient knowledge
distillation framework, given 1) only a small visible subset of patches is
used, and 2) the (cumbersome) teacher model only needs to be partially
executed, \ie, forward propagate inputs through the first few layers, for
obtaining intermediate feature maps. Compared to directly distilling fine-tuned
models, distilling pre-trained models substantially improves downstream
performance. For example, by distilling the knowledge from an MAE pre-trained
ViT-L into a ViT-B, our method achieves 84.0% ImageNet top-1 accuracy,
outperforming the baseline of directly distilling a fine-tuned ViT-L by 1.2%.
More intriguingly, our method can robustly distill knowledge from teacher
models even with extremely high masking ratios: e.g., with 95% masking ratio
where merely TEN patches are visible during distillation, our ViT-B
competitively attains a top-1 ImageNet accuracy of 83.6%; surprisingly, it can
still secure 82.4% top-1 ImageNet accuracy by aggressively training with just
FOUR visible patches (98% masking ratio). The code and models are publicly
available at https://github.com/UCSC-VLAA/DMAE.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Automatic Mapping of Unstructured Cyber Threat Intelligence: An Experimental Study. (arXiv:2208.12144v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12144">http://arxiv.org/abs/2208.12144</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12144] Automatic Mapping of Unstructured Cyber Threat Intelligence: An Experimental Study](http://arxiv.org/abs/2208.12144)</code></li>
<li>Summary: <p>Proactive approaches to security, such as adversary emulation, leverage
information about threat actors and their techniques (Cyber Threat
Intelligence, CTI). However, most CTI still comes in unstructured forms (i.e.,
natural language), such as incident reports and leaked documents. To support
proactive security efforts, we present an experimental study on the automatic
classification of unstructured CTI into attack techniques using machine
learning (ML). We contribute with two new datasets for CTI analysis, and we
evaluate several ML models, including both traditional and deep learning-based
ones. We present several lessons learned about how ML can perform at this task,
which classifiers perform best and under which conditions, which are the main
causes of classification errors, and the challenges ahead for CTI analysis.
</p></li>
</ul>

<h3>Title: A Trusted, Verifiable and Differential Cyber Threat Intelligence Sharing Framework using Blockchain. (arXiv:2208.12031v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12031">http://arxiv.org/abs/2208.12031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12031] A Trusted, Verifiable and Differential Cyber Threat Intelligence Sharing Framework using Blockchain](http://arxiv.org/abs/2208.12031)</code></li>
<li>Summary: <p>Cyber Threat Intelligence (CTI) is the knowledge of cyber and physical
threats that help mitigate potential cyber attacks. The rapid evolution of the
current threat landscape has seen many organisations share CTI to strengthen
their security posture for mutual benefit. However, in many cases, CTI data
contains attributes (e.g., software versions) that have the potential to leak
sensitive information or cause reputational damage to the sharing organisation.
While current approaches allow restricting CTI sharing to trusted
organisations, they lack solutions where the shared data can be verified and
disseminated `differentially' (i.e., selective information sharing) with
policies and metrics flexibly defined by an organisation. In this paper, we
propose a blockchain-based CTI sharing framework that allows organisations to
share sensitive CTI data in a trusted, verifiable and differential manner. We
discuss the limitations associated with existing approaches and highlight the
advantages of the proposed CTI sharing framework. We further present a detailed
proof of concept using the Ethereum blockchain network. Our experimental
results show that the proposed framework can facilitate the exchange of CTI
without creating significant additional overheads.
</p></li>
</ul>

<h3>Title: Quo Vadis: Hybrid Machine Learning Meta-Model based on Contextual and Behavioral Malware Representations. (arXiv:2208.12248v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12248">http://arxiv.org/abs/2208.12248</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12248] Quo Vadis: Hybrid Machine Learning Meta-Model based on Contextual and Behavioral Malware Representations](http://arxiv.org/abs/2208.12248)</code></li>
<li>Summary: <p>We propose a hybrid machine learning architecture that simultaneously employs
multiple deep learning models analyzing contextual and behavioral
characteristics of Windows portable executable, producing a final prediction
based on a decision from the meta-model. The detection heuristic in
contemporary machine learning Windows malware classifiers is typically based on
the static properties of the sample since dynamic analysis through
virtualization is challenging for vast quantities of samples. To surpass this
limitation, we employ a Windows kernel emulation that allows the acquisition of
behavioral patterns across large corpora with minimal temporal and
computational costs. We partner with a security vendor for a collection of more
than 100k int-the-wild samples that resemble the contemporary threat landscape,
containing raw PE files and filepaths of applications at the moment of
execution. The acquired dataset is at least ten folds larger than reported in
related works on behavioral malware analysis. Files in the training dataset are
labeled by a professional threat intelligence team, utilizing manual and
automated reverse engineering tools. We estimate the hybrid classifier's
operational utility by collecting an out-of-sample test set three months later
from the acquisition of the training set. We report an improved detection rate,
above the capabilities of the current state-of-the-art model, especially under
low false-positive requirements. Additionally, we uncover a meta-model's
ability to identify malicious activity in validation and test sets even if none
of the individual models express enough confidence to mark the sample as
malevolent. We conclude that the meta-model can learn patterns typical to
malicious samples from representation combinations produced by different
analysis techniques. We publicly release pre-trained models and anonymized
dataset of emulation reports.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Two-stage Fall Events Classification with Human Skeleton Data. (arXiv:2208.12027v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12027">http://arxiv.org/abs/2208.12027</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12027] Two-stage Fall Events Classification with Human Skeleton Data](http://arxiv.org/abs/2208.12027)</code></li>
<li>Summary: <p>Fall detection and classification become an imper- ative problem for
healthcare applications particularity with the increasingly ageing population.
Currently, most of the fall clas- sification algorithms provide binary fall or
no-fall classification. For better healthcare, it is thus not enough to do
binary fall classification but to extend it to multiple fall events
classification. In this work, we utilize the privacy mitigating human skeleton
data for multiple fall events classification. The skeleton features are
extracted from the original RGB images to not only mitigate the personal
privacy, but also to reduce the impact of the dynamic illuminations. The
proposed fall events classification method is divided into two stages. In the
first stage, the model is trained to achieve the binary classification to
filter out the no-fall events. Then, in the second stage, the deep neural
network (DNN) model is trained to further classify the five types of fall
events. In order to confirm the efficiency of the proposed method, the
experiments on the UP-Fall dataset outperform the state-of-the-art.
</p></li>
</ul>

<h3>Title: On Differential Privacy for Federated Learning in Wireless Systems with Multiple Base Stations. (arXiv:2208.11848v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11848">http://arxiv.org/abs/2208.11848</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11848] On Differential Privacy for Federated Learning in Wireless Systems with Multiple Base Stations](http://arxiv.org/abs/2208.11848)</code></li>
<li>Summary: <p>In this work, we consider a federated learning model in a wireless system
with multiple base stations and inter-cell interference. We apply a
differential private scheme to transmit information from users to their
corresponding base station during the learning phase. We show the convergence
behavior of the learning process by deriving an upper bound on its optimality
gap. Furthermore, we define an optimization problem to reduce this upper bound
and the total privacy leakage. To find the locally optimal solutions of this
problem, we first propose an algorithm that schedules the resource blocks and
users. We then extend this scheme to reduce the total privacy leakage by
optimizing the differential privacy artificial noise. We apply the solutions of
these two procedures as parameters of a federated learning system. In this
setting, we assume that each user is equipped with a classifier. Moreover, the
communication cells are assumed to have mostly fewer resource blocks than
numbers of users. The simulation results show that our proposed scheduler
improves the average accuracy of the predictions compared with a random
scheduler. Furthermore, its extended version with noise optimizer significantly
reduces the amount of privacy leakage.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Empirical study of Machine Learning Classifier Evaluation Metrics behavior in Massively Imbalanced and Noisy data. (arXiv:2208.11904v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11904">http://arxiv.org/abs/2208.11904</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11904] Empirical study of Machine Learning Classifier Evaluation Metrics behavior in Massively Imbalanced and Noisy data](http://arxiv.org/abs/2208.11904)</code></li>
<li>Summary: <p>With growing credit card transaction volumes, the fraud percentages are also
rising, including overhead costs for institutions to combat and compensate
victims. The use of machine learning into the financial sector permits more
effective protection against fraud and other economic crime. Suitably trained
machine learning classifiers help proactive fraud detection, improving
stakeholder trust and robustness against illicit transactions. However, the
design of machine learning based fraud detection algorithms has been
challenging and slow due the massively unbalanced nature of fraud data and the
challenges of identifying the frauds accurately and completely to create a gold
standard ground truth. Furthermore, there are no benchmarks or standard
classifier evaluation metrics to measure and identify better performing
classifiers, thus keeping researchers in the dark.
</p></li>
</ul>

<p>In this work, we develop a theoretical foundation to model human annotation
errors and extreme imbalance typical in real world fraud detection data sets.
By conducting empirical experiments on a hypothetical classifier, with a
synthetic data distribution approximated to a popular real world credit card
fraud data set, we simulate human annotation errors and extreme imbalance to
observe the behavior of popular machine learning classifier evaluation
matrices. We demonstrate that a combined F1 score and g-mean, in that specific
order, is the best evaluation metric for typical imbalanced fraud detection
model classification.
</p>

<h2>defense</h2>
<h3>Title: A deep learning approach to predict the number of k-barriers for intrusion detection over a circular region using wireless sensor networks. (arXiv:2208.11887v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11887">http://arxiv.org/abs/2208.11887</a></li>
<li>Code URL: <a href="https://github.com/abhilash12iec002/intrusion_detection">https://github.com/abhilash12iec002/intrusion_detection</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11887] A deep learning approach to predict the number of k-barriers for intrusion detection over a circular region using wireless sensor networks](http://arxiv.org/abs/2208.11887)</code></li>
<li>Summary: <p>Wireless Sensor Networks (WSNs) is a promising technology with enormous
applications in almost every walk of life. One of the crucial applications of
WSNs is intrusion detection and surveillance at the border areas and in the
defense establishments. The border areas are stretched in hundreds to thousands
of miles, hence, it is not possible to patrol the entire border region. As a
result, an enemy may enter from any point absence of surveillance and cause the
loss of lives or destroy the military establishments. WSNs can be a feasible
solution for the problem of intrusion detection and surveillance at the border
areas. Detection of an enemy at the border areas and nearby critical areas such
as military cantonments is a time-sensitive task as a delay of few seconds may
have disastrous consequences. Therefore, it becomes imperative to design
systems that are able to identify and detect the enemy as soon as it comes in
the range of the deployed system. In this paper, we have proposed a deep
learning architecture based on a fully connected feed-forward Artificial Neural
Network (ANN) for the accurate prediction of the number of k-barriers for fast
intrusion detection and prevention. We have trained and evaluated the
feed-forward ANN model using four potential features, namely area of the
circular region, sensing range of sensors, the transmission range of sensors,
and the number of sensor for Gaussian and uniform sensor distribution. These
features are extracted through Monte Carlo simulation. In doing so, we found
that the model accurately predicts the number of k-barriers for both Gaussian
and uniform sensor distribution with correlation coefficient (R = 0.78) and
Root Mean Square Error (RMSE = 41.15) for the former and R = 0.79 and RMSE =
48.36 for the latter. Further, the proposed approach outperforms the other
benchmark algorithms in terms of accuracy and computational time complexity.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: A Perturbation Resistant Transformation and Classification System for Deep Neural Networks. (arXiv:2208.11839v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11839">http://arxiv.org/abs/2208.11839</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11839] A Perturbation Resistant Transformation and Classification System for Deep Neural Networks](http://arxiv.org/abs/2208.11839)</code></li>
<li>Summary: <p>Deep convolutional neural networks accurately classify a diverse range of
natural images, but may be easily deceived when designed, imperceptible
perturbations are embedded in the images. In this paper, we design a
multi-pronged training, input transformation, and image ensemble system that is
attack agnostic and not easily estimated. Our system incorporates two novel
features. The first is a transformation layer that computes feature level
polynomial kernels from class-level training data samples and iteratively
updates input image copies at inference time based on their feature kernel
differences to create an ensemble of transformed inputs. The second is a
classification system that incorporates the prediction of the undefended
network with a hard vote on the ensemble of filtered images. Our evaluations on
the CIFAR10 dataset show our system improves the robustness of an undefended
network against a variety of bounded and unbounded white-box attacks under
different distance metrics, while sacrificing little accuracy on clean images.
Against adaptive full-knowledge attackers creating end-to-end attacks, our
system successfully augments the existing robustness of adversarially trained
networks, for which our methods are most effectively applied.
</p></li>
</ul>

<h3>Title: XDRI Attacks - and - How to Enhance Resilience of Residential Routers. (arXiv:2208.12003v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12003">http://arxiv.org/abs/2208.12003</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12003] XDRI Attacks - and - How to Enhance Resilience of Residential Routers](http://arxiv.org/abs/2208.12003)</code></li>
<li>Summary: <p>We explore the security of residential routers and find a range of critical
vulnerabilities. Our evaluations show that 10 out of 36 popular routers are
vulnerable to injections of fake records via misinterpretation of special
characters. We also find that in 15 of the 36 routers the mechanisms, that are
meant to prevent cache poisoning attacks, can be circumvented. In our
Internet-wide study with an advertisement network, we identified and analyzed
976 residential routers used by web clients, out of which more than 95% were
found vulnerable to our attacks. Overall, vulnerable routers are prevalent and
are distributed among 177 countries and 4830 networks. To understand the core
factors causing the vulnerabilities we perform black- and white-box analyses of
the routers. We find that many problems can be attributed to incorrect
assumptions on the protocols' behaviour and the Internet, misunderstanding of
the standard recommendations, bugs, and simplified DNS software
implementations. We provide recommendations to mitigate our attacks. We also
set up a tool to enable everyone to evaluate the security of their routers at
https://xdi-attack.net/.
</p></li>
</ul>

<h3>Title: Passive Triangulation Attack on ORide. (arXiv:2208.12216v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12216">http://arxiv.org/abs/2208.12216</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12216] Passive Triangulation Attack on ORide](http://arxiv.org/abs/2208.12216)</code></li>
<li>Summary: <p>Privacy preservation in Ride Hailing Services is intended to protect privacy
of drivers and riders. ORide is one of the early RHS proposals published at
USENIX Security Symposium 2017. In the ORide protocol, riders and drivers,
operating in a zone, encrypt their locations using a Somewhat Homomorphic
Encryption scheme (SHE) and forward them to the Service Provider (SP). SP
homomorphically computes the squared Euclidean distance between riders and
available drivers. Rider receives the encrypted distances and selects the
optimal rider after decryption. In order to prevent a triangulation attack, SP
randomly permutes the distances before sending them to the rider. In this work,
we use propose a passive attack that uses triangulation to determine
coordinates of all participating drivers whose permuted distances are available
from the points of view of multiple honest-but-curious adversary riders. An
attack on ORide was published at SAC 2021. The same paper proposes a
countermeasure using noisy Euclidean distances to thwart their attack. We
extend our attack to determine locations of drivers when given their permuted
and noisy Euclidean distances from multiple points of reference, where the
noise perturbation comes from a uniform distribution. We conduct experiments
with different number of drivers and for different perturbation values. Our
experiments show that we can determine locations of all drivers participating
in the ORide protocol. For the perturbed distance version of the ORide
protocol, our algorithm reveals locations of about 25% to 50% of participating
drivers. Our algorithm runs in time polynomial in number of drivers.
</p></li>
</ul>

<h3>Title: Semantic Preserving Adversarial Attack Generation with Autoencoder and Genetic Algorithm. (arXiv:2208.12230v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12230">http://arxiv.org/abs/2208.12230</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12230] Semantic Preserving Adversarial Attack Generation with Autoencoder and Genetic Algorithm](http://arxiv.org/abs/2208.12230)</code></li>
<li>Summary: <p>Widely used deep learning models are found to have poor robustness. Little
noises can fool state-of-the-art models into making incorrect predictions.
While there is a great deal of high-performance attack generation methods, most
of them directly add perturbations to original data and measure them using L_p
norms; this can break the major structure of data, thus, creating invalid
attacks. In this paper, we propose a black-box attack, which, instead of
modifying original data, modifies latent features of data extracted by an
autoencoder; then, we measure noises in semantic space to protect the semantics
of data. We trained autoencoders on MNIST and CIFAR-10 datasets and found
optimal adversarial perturbations using a genetic algorithm. Our approach
achieved a 100% attack success rate on the first 100 data of MNIST and CIFAR-10
datasets with less perturbation than FGSM.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: A Compacted Structure for Cross-domain learning on Monocular Depth and Flow Estimation. (arXiv:2208.11993v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11993">http://arxiv.org/abs/2208.11993</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11993] A Compacted Structure for Cross-domain learning on Monocular Depth and Flow Estimation](http://arxiv.org/abs/2208.11993)</code></li>
<li>Summary: <p>Accurate motion and depth recovery is important for many robot vision tasks
including autonomous driving. Most previous studies have achieved cooperative
multi-task interaction via either pre-defined loss functions or cross-domain
prediction. This paper presents a multi-task scheme that achieves mutual
assistance by means of our Flow to Depth (F2D), Depth to Flow (D2F), and
Exponential Moving Average (EMA). F2D and D2F mechanisms enable multi-scale
information integration between optical flow and depth domain based on
differentiable shallow nets. A dual-head mechanism is used to predict optical
flow for rigid and non-rigid motion based on a divide-and-conquer manner, which
significantly improves the optical flow estimation performance. Furthermore, to
make the prediction more robust and stable, EMA is used for our multi-task
training. Experimental results on KITTI datasets show that our multi-task
scheme outperforms other multi-task schemes and provide marked improvements on
the prediction results.
</p></li>
</ul>

<h3>Title: Bridging the View Disparity of Radar and Camera Features for Multi-modal Fusion 3D Object Detection. (arXiv:2208.12079v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12079">http://arxiv.org/abs/2208.12079</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12079] Bridging the View Disparity of Radar and Camera Features for Multi-modal Fusion 3D Object Detection](http://arxiv.org/abs/2208.12079)</code></li>
<li>Summary: <p>Environmental perception with multi-modal fusion of radar and camera is
crucial in autonomous driving to increase the accuracy, completeness, and
robustness. This paper focuses on how to utilize millimeter-wave (MMW) radar
and camera sensor fusion for 3D object detection. A novel method which realizes
the feature-level fusion under bird-eye view (BEV) for a better feature
representation is proposed. Firstly, radar features are augmented with temporal
accumulation and sent to a temporal-spatial encoder for radar feature
extraction. Meanwhile, multi-scale image 2D features which adapt to various
spatial scales are obtained by image backbone and neck model. Then, image
features are transformed to BEV with the designed view transformer. In
addition, this work fuses the multi-modal features with a two-stage fusion
model called point fusion and ROI fusion, respectively. Finally, a detection
head regresses objects category and 3D locations. Experimental results
demonstrate that the proposed method realizes the state-of-the-art performance
under the most important detection metrics, mean average precision (mAP) and
nuScenes detection score (NDS) on the challenging nuScenes dataset.
</p></li>
</ul>

<h3>Title: Shortcut Learning of Large Language Models in Natural Language Understanding: A Survey. (arXiv:2208.11857v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11857">http://arxiv.org/abs/2208.11857</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11857] Shortcut Learning of Large Language Models in Natural Language Understanding: A Survey](http://arxiv.org/abs/2208.11857)</code></li>
<li>Summary: <p>Large language models (LLMs) have achieved state-of-the-art performance on a
series of natural language understanding tasks. However, these LLMs might rely
on dataset bias and artifacts as shortcuts for prediction. This has
significantly hurt their Out-of-Distribution (OOD) generalization and
adversarial robustness. In this paper, we provide a review of recent
developments that address the robustness challenge of LLMs. We first introduce
the concepts and robustness challenge of LLMs. We then introduce methods to
identify shortcut learning behavior in LLMs, characterize the reasons for
shortcut learning, as well as introduce mitigation solutions. Finally, we
identify key challenges and introduce the connections of this line of research
to other directions.
</p></li>
</ul>

<h3>Title: On Reality and the Limits of Language Data. (arXiv:2208.11981v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11981">http://arxiv.org/abs/2208.11981</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11981] On Reality and the Limits of Language Data](http://arxiv.org/abs/2208.11981)</code></li>
<li>Summary: <p>Recent advances in neural network language models have shown that it is
possible to derive expressive meaning representations by leveraging linguistic
associations in large-scale natural language data. These potentially Gestalt
representations have enabled state-of-the-art performance for many practical
applications. It would appear that we are on a pathway to empirically deriving
a robust and expressive computable semantics. A key question that arises is how
far can language data alone enable computers to understand the necessary truth
about the physical world? Attention to this question is warranted because our
future interactions with intelligent machines depends on how well our
techniques correctly represent and process the concepts (objects, properties,
and processes) that humans commonly observe to be true. After reviewing
existing protocols, the objective of this work is to explore this question
using a novel and tightly controlled reasoning test and to highlight what
models might learn directly from pure linguistic data.
</p></li>
</ul>

<h3>Title: Towards Unsupervised HPO for Outlier Detection. (arXiv:2208.11727v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11727">http://arxiv.org/abs/2208.11727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11727] Towards Unsupervised HPO for Outlier Detection](http://arxiv.org/abs/2208.11727)</code></li>
<li>Summary: <p>Given an unsupervised outlier detection (OD) algorithm, how can we optimize
its hyperparameter(s) (HP) on a new dataset, without any labels? In this work,
we address this challenging hyperparameter optimization for unsupervised OD
problem, and propose the first systematic approach called HPOD that is based on
meta-learning. HPOD capitalizes on the prior performance of a large collection
of HPs on existing OD benchmark datasets, and transfers this information to
enable HP evaluation on a new dataset without labels. Moreover, HPOD adapts
(originally supervised) sequential model-based optimization to identify
promising HPs efficiently. Extensive experiments show that HPOD works with both
deep (e.g., Robust AutoEncoder) and shallow (e.g., Local Outlier Factor (LOF)
and Isolation Forest (iForest)) OD algorithms on both discrete and continuous
HP spaces, and outperforms a wide range of baselines with on average 58% and
66% performance improvement over the default HPs of LOF and iForest.
</p></li>
</ul>

<h3>Title: Maximum Likelihood on the Joint (Data, Condition) Distribution for Solving Ill-Posed Problems with Conditional Flow Models. (arXiv:2208.11782v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11782">http://arxiv.org/abs/2208.11782</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11782] Maximum Likelihood on the Joint (Data, Condition) Distribution for Solving Ill-Posed Problems with Conditional Flow Models](http://arxiv.org/abs/2208.11782)</code></li>
<li>Summary: <p>I describe a trick for training flow models using a prescribed rule as a
surrogate for maximum likelihood. The utility of this trick is limited for
non-conditional models, but an extension of the approach, applied to maximum
likelihood of the joint probability distribution of data and conditioning
information, can be used to train sophisticated \textit{conditional} flow
models. Unlike previous approaches, this method is quite simple: it does not
require explicit knowledge of the distribution of conditions, auxiliary
networks or other specific architecture, or additional loss terms beyond
maximum likelihood, and it preserves the correspondence between latent and data
spaces. The resulting models have all the properties of non-conditional flow
models, are robust to unexpected inputs, and can predict the distribution of
solutions conditioned on a given input. They come with guarantees of prediction
representativeness and are a natural and powerful way to solve highly uncertain
problems. I demonstrate these properties on easily visualized toy problems,
then use the method to successfully generate class-conditional images and to
reconstruct highly degraded images via super-resolution.
</p></li>
</ul>

<h3>Title: Calibrated Selective Classification. (arXiv:2208.12084v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12084">http://arxiv.org/abs/2208.12084</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12084] Calibrated Selective Classification](http://arxiv.org/abs/2208.12084)</code></li>
<li>Summary: <p>Selective classification allows models to abstain from making predictions
(e.g., say "I don't know") when in doubt in order to obtain better effective
accuracy. While typical selective models can be effective at producing more
accurate predictions on average, they may still allow for wrong predictions
that have high confidence, or skip correct predictions that have low
confidence. Providing calibrated uncertainty estimates alongside predictions --
probabilities that correspond to true frequencies -- can be as important as
having predictions that are simply accurate on average. However, uncertainty
estimates can be unreliable for certain inputs. In this paper, we develop a new
approach to selective classification in which we propose a method for rejecting
examples with "uncertain" uncertainties. By doing so, we aim to make
predictions with {well-calibrated} uncertainty estimates over the distribution
of accepted examples, a property we call selective calibration. We present a
framework for learning selectively calibrated models, where a separate selector
network is trained to improve the selective calibration error of a given base
model. In particular, our work focuses on achieving robust calibration, where
the model is intentionally designed to be tested on out-of-domain data. We
achieve this through a training strategy inspired by distributionally robust
optimization, in which we apply simulated input perturbations to the known,
in-domain training data. We demonstrate the empirical effectiveness of our
approach on multiple image classification and lung cancer risk assessment
tasks.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Benchmarking Human Face Similarity Using Identical Twins. (arXiv:2208.11822v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11822">http://arxiv.org/abs/2208.11822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11822] Benchmarking Human Face Similarity Using Identical Twins](http://arxiv.org/abs/2208.11822)</code></li>
<li>Summary: <p>The problem of distinguishing identical twins and non-twin look-alikes in
automated facial recognition (FR) applications has become increasingly
important with the widespread adoption of facial biometrics. Due to the high
facial similarity of both identical twins and look-alikes, these face pairs
represent the hardest cases presented to facial recognition tools. This work
presents an application of one of the largest twin datasets compiled to date to
address two FR challenges: 1) determining a baseline measure of facial
similarity between identical twins and 2) applying this similarity measure to
determine the impact of doppelgangers, or look-alikes, on FR performance for
large face datasets. The facial similarity measure is determined via a deep
convolutional neural network. This network is trained on a tailored
verification task designed to encourage the network to group together highly
similar face pairs in the embedding space and achieves a test AUC of 0.9799.
The proposed network provides a quantitative similarity score for any two given
faces and has been applied to large-scale face datasets to identify similar
face pairs. An additional analysis which correlates the comparison score
returned by a facial recognition tool and the similarity score returned by the
proposed network has also been performed.
</p></li>
</ul>

<h3>Title: Identity-Sensitive Knowledge Propagation for Cloth-Changing Person Re-identification. (arXiv:2208.12023v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12023">http://arxiv.org/abs/2208.12023</a></li>
<li>Code URL: <a href="https://github.com/kimbingng/deskpro">https://github.com/kimbingng/deskpro</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12023] Identity-Sensitive Knowledge Propagation for Cloth-Changing Person Re-identification](http://arxiv.org/abs/2208.12023)</code></li>
<li>Summary: <p>Cloth-changing person re-identification (CC-ReID), which aims to match person
identities under clothing changes, is a new rising research topic in recent
years. However, typical biometrics-based CC-ReID methods often require
cumbersome pose or body part estimators to learn cloth-irrelevant features from
human biometric traits, which comes with high computational costs. Besides, the
performance is significantly limited due to the resolution degradation of
surveillance images. To address the above limitations, we propose an effective
Identity-Sensitive Knowledge Propagation framework (DeSKPro) for CC-ReID.
Specifically, a Cloth-irrelevant Spatial Attention module is introduced to
eliminate the distraction of clothing appearance by acquiring knowledge from
the human parsing module. To mitigate the resolution degradation issue and mine
identity-sensitive cues from human faces, we propose to restore the missing
facial details using prior facial knowledge, which is then propagated to a
smaller network. After training, the extra computations for human parsing or
face restoration are no longer required. Extensive experiments show that our
framework outperforms state-of-the-art methods by a large margin. Our code is
available at https://github.com/KimbingNg/DeskPro.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Fed-FSNet: Mitigating Non-I.I.D. Federated Learning via Fuzzy Synthesizing Network. (arXiv:2208.12044v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12044">http://arxiv.org/abs/2208.12044</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12044] Fed-FSNet: Mitigating Non-I](http://arxiv.org/abs/2208.12044)</code></li>
<li>Summary: <p>Federated learning (FL) has emerged as a promising privacy-preserving
distributed machine learning framework recently. It aims at collaboratively
learning a shared global model by performing distributed training locally on
edge devices and aggregating local models into a global one without centralized
raw data sharing in the cloud server. However, due to the large local data
heterogeneities (Non-I.I.D. data) across edge devices, the FL may easily obtain
a global model that can produce more shifted gradients on local datasets,
thereby degrading the model performance or even suffering from the
non-convergence during training. In this paper, we propose a novel FL training
framework, dubbed Fed-FSNet, using a properly designed Fuzzy Synthesizing
Network (FSNet) to mitigate the Non-I.I.D. FL at-the-source. Concretely, we
maintain an edge-agnostic hidden model in the cloud server to estimate a
less-accurate while direction-aware inversion of the global model. The hidden
model can then fuzzily synthesize several mimic I.I.D. data samples (sample
features) conditioned on only the global model, which can be shared by edge
devices to facilitate the FL training towards faster and better convergence.
Moreover, since the synthesizing process involves neither access to the
parameters/updates of local models nor analyzing individual local model
outputs, our framework can still ensure the privacy of FL. Experimental results
on several FL benchmarks demonstrate that our method can significantly mitigate
the Non-I.I.D. issue and obtain better performance against other representative
methods.
</p></li>
</ul>

<h3>Title: A Platform-Free Proof of Federated Learning Consensus Mechanism for Sustainable Blockchains. (arXiv:2208.12046v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12046">http://arxiv.org/abs/2208.12046</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12046] A Platform-Free Proof of Federated Learning Consensus Mechanism for Sustainable Blockchains](http://arxiv.org/abs/2208.12046)</code></li>
<li>Summary: <p>Proof of work (PoW), as the representative consensus protocol for blockchain,
consumes enormous amounts of computation and energy to determine bookkeeping
rights among miners but does not achieve any practical purposes. To address the
drawback of PoW, we propose a novel energy-recycling consensus mechanism named
platform-free proof of federated learning (PF-PoFL), which leverages the
computing power originally wasted in solving hard but meaningless PoW puzzles
to conduct practical federated learning (FL) tasks. Nevertheless, potential
security threats and efficiency concerns may occur due to the untrusted
environment and miners' self-interested features. In this paper, by devising a
novel block structure, new transaction types, and credit-based incentives,
PF-PoFL allows efficient artificial intelligence (AI) task outsourcing,
federated mining, model evaluation, and reward distribution in a fully
decentralized manner, while resisting spoofing and Sybil attacks. Besides,
PF-PoFL equips with a user-level differential privacy mechanism for miners to
prevent implicit privacy leakage in training FL models. Furthermore, by
considering dynamic miner characteristics (e.g., training samples, non-IID
degree, and network delay) under diverse FL tasks, a federation formation
game-based mechanism is presented to distributively form the optimized disjoint
miner partition structure with Nash-stable convergence. Extensive simulations
validate the efficiency and effectiveness of PF-PoFL.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Enforcing Delayed-Impact Fairness Guarantees. (arXiv:2208.11744v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11744">http://arxiv.org/abs/2208.11744</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11744] Enforcing Delayed-Impact Fairness Guarantees](http://arxiv.org/abs/2208.11744)</code></li>
<li>Summary: <p>Recent research has shown that seemingly fair machine learning models, when
used to inform decisions that have an impact on peoples' lives or well-being
(e.g., applications involving education, employment, and lending), can
inadvertently increase social inequality in the long term. This is because
prior fairness-aware algorithms only consider static fairness constraints, such
as equal opportunity or demographic parity. However, enforcing constraints of
this type may result in models that have negative long-term impact on
disadvantaged individuals and communities. We introduce ELF (Enforcing
Long-term Fairness), the first classification algorithm that provides
high-confidence fairness guarantees in terms of long-term, or delayed, impact.
We prove that the probability that ELF returns an unfair solution is less than
a user-specified tolerance and that (under mild assumptions), given sufficient
training data, ELF is able to find and return a fair solution if one exists. We
show experimentally that our algorithm can successfully mitigate long-term
unfairness.
</p></li>
</ul>

<h3>Title: Sustaining Fairness via Incremental Learning. (arXiv:2208.12212v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.12212">http://arxiv.org/abs/2208.12212</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.12212] Sustaining Fairness via Incremental Learning](http://arxiv.org/abs/2208.12212)</code></li>
<li>Summary: <p>Machine learning systems are often deployed for making critical decisions
like credit lending, hiring, etc. While making decisions, such systems often
encode the user's demographic information (like gender, age) in their
intermediate representations. This can lead to decisions that are biased
towards specific demographics. Prior work has focused on debiasing intermediate
representations to ensure fair decisions. However, these approaches fail to
remain fair with changes in the task or demographic distribution. To ensure
fairness in the wild, it is important for a system to adapt to such changes as
it accesses new data in an incremental fashion. In this work, we propose to
address this issue by introducing the problem of learning fair representations
in an incremental learning setting. To this end, we present Fairness-aware
Incremental Representation Learning (FaIRL), a representation learning system
that can sustain fairness while incrementally learning new tasks. FaIRL is able
to achieve fairness and learn new tasks by controlling the rate-distortion
function of the learned representations. Our empirical evaluations show that
FaIRL is able to make fair decisions while achieving high performance on the
target task, outperforming several baselines.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Interpretable Multimodal Emotion Recognition using Hybrid Fusion of Speech and Image Data. (arXiv:2208.11868v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.11868">http://arxiv.org/abs/2208.11868</a></li>
<li>Code URL: <a href="https://github.com/mintelligence-group/speechimg_emorec">https://github.com/mintelligence-group/speechimg_emorec</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.11868] Interpretable Multimodal Emotion Recognition using Hybrid Fusion of Speech and Image Data](http://arxiv.org/abs/2208.11868)</code></li>
<li>Summary: <p>This paper proposes a multimodal emotion recognition system based on hybrid
fusion that classifies the emotions depicted by speech utterances and
corresponding images into discrete classes. A new interpretability technique
has been developed to identify the important speech &amp; image features leading to
the prediction of particular emotion classes. The proposed system's
architecture has been determined through intensive ablation studies. It fuses
the speech &amp; image features and then combines speech, image, and intermediate
fusion outputs. The proposed interpretability technique incorporates the divide
&amp; conquer approach to compute shapely values denoting each speech &amp; image
feature's importance. We have also constructed a large-scale dataset (IIT-R
SIER dataset), consisting of speech utterances, corresponding images, and class
labels, i.e., 'anger,' 'happy,' 'hate,' and 'sad.' The proposed system has
achieved 83.29% accuracy for emotion recognition. The enhanced performance of
the proposed system advocates the importance of utilizing complementary
information from multiple modalities for emotion recognition.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
