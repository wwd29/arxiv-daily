<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-03-10</h1>
<h3>Title: Leveraging Large Language Models For Optimized Item Categorization using UNSPSC Taxonomy</h3>
<ul>
<li><strong>Authors: </strong>Anmolika Singh, Yuhang Diao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04728">https://arxiv.org/abs/2503.04728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04728">https://arxiv.org/pdf/2503.04728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04728]] Leveraging Large Language Models For Optimized Item Categorization using UNSPSC Taxonomy(https://arxiv.org/abs/2503.04728)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effective item categorization is vital for businesses, enabling the transformation of unstructured datasets into organized categories that streamline inventory management. Despite its importance, item categorization remains highly subjective and lacks a uniform standard across industries and businesses. The United Nations Standard Products and Services Code (UNSPSC) provides a standardized system for cataloguing inventory, yet employing UNSPSC categorizations often demands significant manual effort. This paper investigates the deployment of Large Language Models (LLMs) to automate the classification of inventory data into UNSPSC codes based on Item Descriptions. We evaluate the accuracy and efficiency of LLMs in categorizing diverse datasets, exploring their language processing capabilities and their potential as a tool for standardizing inventory classification. Our findings reveal that LLMs can substantially diminish the manual labor involved in item categorization while maintaining high accuracy, offering a scalable solution for businesses striving to enhance their inventory management practices.</li>
</ul>

<h3>Title: WinClick: GUI Grounding with Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zheng Hui, Yinheng Li, Dan zhao, Tianyi Chen, Colby Banbury, Kazuhito Koishida</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04730">https://arxiv.org/abs/2503.04730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04730">https://arxiv.org/pdf/2503.04730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04730]] WinClick: GUI Grounding with Multimodal Large Language Models(https://arxiv.org/abs/2503.04730)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graphical User Interface (GUI) tasks are vital for automating workflows such as software testing, user interface navigation. For users, the GUI is the most intuitive platform for interacting with a computer. Previous work identified a key challenge in developing visual GUI agents: GUI grounding - the ability to accurately locate screen elements based on instructions. However, most existing GUI agents rely on structured data formats like DOM or HTML files in training or inferencing, which are inaccessible across all applications, particular in a general desktop environments such as Windows OS. To address this, we introduce WinClick, a novel visual GUI agent developed in Windows platform. WinClick leverages screenshots to detect actionable regions. To overcome the challenge of GUI grounding, we enhance WinClick with GUI grounding pre-training and propose an LLM-based method for aligning GUI grounding data. Additionally, we introduce WinSpot, the first comprehensive benchmark for GUI grounding on Windows. Our experiments demonstrate that WinClick, combined with GUI grounding pre-training, significantly outperforms existing baselines, offering a scalable solution for GUI automation in desktop environments. WinSpot is publicly available at this https URL.</li>
</ul>

<h3>Title: Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content</h3>
<ul>
<li><strong>Authors: </strong>Bingbing Fan, Lin Chen, Songwei Li, Jian Yuan, Fengli Xu, Pan Hui, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04773">https://arxiv.org/abs/2503.04773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04773">https://arxiv.org/pdf/2503.04773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04773]] Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content(https://arxiv.org/abs/2503.04773)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding experienced segregation in urban daily life is crucial for addressing societal inequalities and fostering inclusivity. The abundance of user-generated reviews on social media encapsulates nuanced perceptions and feelings associated with different places, offering rich insights into segregation. However, leveraging this data poses significant challenges due to its vast volume, ambiguity, and confluence of diverse perspectives. To tackle these challenges, we propose using Large Language Models (LLMs) to automate online review mining for segregation prediction. We design a Reflective LLM Coder to digest social media content into insights consistent with real-world feedback, and eventually produce a codebook capturing key dimensions that signal segregation experience, such as cultural resonance and appeal, accessibility and convenience, and community engagement and local involvement. Guided by the codebook, LLMs can generate both informative review summaries and ratings for segregation prediction. Moreover, we design a REasoning-and-EMbedding (RE'EM) framework, which combines the reasoning and embedding capabilities of language models to integrate multi-channel features for segregation prediction. Experiments on real-world data demonstrate that our framework greatly improves prediction accuracy, with a 22.79% elevation in R2 and a 9.33% reduction in MSE. The derived codebook is generalizable across three different cities, consistently improving prediction this http URL, our user study confirms that the codebook-guided summaries provide cognitive gains for human participants in perceiving POIs' social this http URL study marks an important step toward understanding implicit social barriers and inequalities, demonstrating the great potential of promoting social inclusiveness with AI.</li>
</ul>

<h3>Title: MV-CLAM: Multi-View Molecular Interpretation with Cross-Modal Projection via Language Model</h3>
<ul>
<li><strong>Authors: </strong>Sumin Ha, Jun Hyeong Kim, Yinhua Piao, Sun Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, physics.atom-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04780">https://arxiv.org/abs/2503.04780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04780">https://arxiv.org/pdf/2503.04780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04780]] MV-CLAM: Multi-View Molecular Interpretation with Cross-Modal Projection via Language Model(https://arxiv.org/abs/2503.04780)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Human expertise in chemistry and biomedicine relies on contextual molecular understanding, a capability that large language models (LLMs) can extend through fine-grained alignment between molecular structures and text. Recent multimodal learning advances focus on cross-modal alignment, but existing molecule-text models ignore complementary information in different molecular views and rely on single-view representations, limiting molecular understanding. Moreover, na√Øve multi-view alignment strategies face two challenges: (1) separate aligned spaces with inconsistent mappings between molecule and text embeddings, and that (2) existing loss objectives fail to preserve complementary information for fine-grained alignment. This can limit the LLM's ability to fully understand the molecular properties. To address these issues, we propose MV-CLAM, a novel framework that aligns multi-view molecular representations into a unified textual space using a multi-query transformer (MQ-Former). Our approach ensures cross-view consistency while a token-level contrastive loss preserves diverse molecular features across textual queries. MV-CLAM enhances molecular reasoning, improving retrieval and captioning accuracy. The source code of MV-CLAM is available in this https URL.</li>
</ul>

<h3>Title: Bangla Fake News Detection Based On Multichannel Combined CNN-LSTM</h3>
<ul>
<li><strong>Authors: </strong>Md. Zahin Hossain George, Naimul Hossain, Md. Rafiuzzaman Bhuiyan, Abu Kaisar Mohammad Masum, Sheikh Abujar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04781">https://arxiv.org/abs/2503.04781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04781">https://arxiv.org/pdf/2503.04781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04781]] Bangla Fake News Detection Based On Multichannel Combined CNN-LSTM(https://arxiv.org/abs/2503.04781)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>There have recently been many cases of unverified or misleading information circulating quickly over bogus web networks and news portals. This false news creates big damage to society and misleads people. For Example, in 2019, there was a rumor that the Padma Bridge of Bangladesh needed 100,000 human heads for sacrifice. This rumor turns into a deadly position and this misleading information takes the lives of innocent people. There is a lot of work in English but a few works in Bangla. In this study, we are going to identify the fake news from the unconsidered news source to provide the newsreader with natural news or real news. The paper is based on the combination of convolutional neural network (CNN) and long short-term memory (LSTM), where CNN is used for deep feature extraction and LSTM is used for detection using the extracted feature. The first thing we did to deploy this piece of work was data collection. We compiled a data set from websites and attempted to deploy it using the methodology of deep learning which contains about 50k of news. With the proposed model of Multichannel combined CNN-LSTM architecture, our model gained an accuracy of 75.05%, which is a good sign for detecting fake news in Bangla.</li>
</ul>

<h3>Title: Comparative Analysis Based on DeepSeek, ChatGPT, and Google Gemini: Features, Techniques, Performance, Future Prospects</h3>
<ul>
<li><strong>Authors: </strong>Anichur Rahman, Shahariar Hossain Mahir, Md Tanjum An Tashrif, Airin Afroj Aishi, Md Ahsan Karim, Dipanjali Kundu, Tanoy Debnath, Md. Abul Ala Moududi, MD. Zunead Abedin Eidmum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04783">https://arxiv.org/abs/2503.04783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04783">https://arxiv.org/pdf/2503.04783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04783]] Comparative Analysis Based on DeepSeek, ChatGPT, and Google Gemini: Features, Techniques, Performance, Future Prospects(https://arxiv.org/abs/2503.04783)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Nowadays, DeepSeek, ChatGPT, and Google Gemini are the most trending and exciting Large Language Model (LLM) technologies for reasoning, multimodal capabilities, and general linguistic performance worldwide. DeepSeek employs a Mixture-of-Experts (MoE) approach, activating only the parameters most relevant to the task at hand, which makes it especially effective for domain-specific work. On the other hand, ChatGPT relies on a dense transformer model enhanced through reinforcement learning from human feedback (RLHF), and then Google Gemini actually uses a multimodal transformer architecture that integrates text, code, and images into a single framework. However, by using those technologies, people can be able to mine their desired text, code, images, etc, in a cost-effective and domain-specific inference. People may choose those techniques based on the best performance. In this regard, we offer a comparative study based on the DeepSeek, ChatGPT, and Gemini techniques in this research. Initially, we focus on their methods and materials, appropriately including the data selection criteria. Then, we present state-of-the-art features of DeepSeek, ChatGPT, and Gemini based on their applications. Most importantly, we show the technological comparison among them and also cover the dataset analysis for various applications. Finally, we address extensive research areas and future potential guidance regarding LLM-based AI research for the community.</li>
</ul>

<h3>Title: KunlunBaize: LLM with Multi-Scale Convolution and Multi-Token Prediction Under TransformerX Framework</h3>
<ul>
<li><strong>Authors: </strong>Jiexiong Liu, Yixuan Chen, Yanqin Jia, Zhepeng Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04784">https://arxiv.org/abs/2503.04784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04784">https://arxiv.org/pdf/2503.04784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04784]] KunlunBaize: LLM with Multi-Scale Convolution and Multi-Token Prediction Under TransformerX Framework(https://arxiv.org/abs/2503.04784)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated remarkable performance across various tasks, yet they face challenges such as low computational efficiency, gradient vanishing, and difficulties in capturing complex feature interactions. To address these limitations, a novel framework has been proposed. This framework incorporates a learnable dense residual skip connection mechanism, a TransformerX module a transformer based component integrating multiscale convolution and adaptive activation functions and a multitoken prediction interaction module. The learnable dense residual connections enhance information flow and feature capture across layers. Within the TransformerX module, large convolutional kernels aggregate semantic information from extensive text segments, while smaller convolutions focus on local word order and syntactic structures. The adaptive activation function dynamically adjusts its parameters based on the semantic features of the input text, improving the model's ability to handle diverse semantic expressions and complex relationships. The multitoken prediction module boosts data utilization and accelerates inference by predicting multiple future tokens. These components significantly enhance the performance and efficiency of large language models.</li>
</ul>

<h3>Title: Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice</h3>
<ul>
<li><strong>Authors: </strong>Jos√© Siqueira de Cerqueira, Kai-Kristian Kemell, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04785">https://arxiv.org/abs/2503.04785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04785">https://arxiv.org/pdf/2503.04785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04785]] Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice(https://arxiv.org/abs/2503.04785)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, explainability, large language model</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of Large Language Models (LLMs) has raised pressing concerns regarding their trustworthiness, spanning issues of reliability, transparency, fairness, and ethical alignment. Despite the increasing adoption of LLMs across various domains, there remains a lack of consensus on how to operationalize trustworthiness in practice. This study bridges the gap between theoretical discussions and implementation by conducting a bibliometric mapping analysis of 2,006 publications from 2019 to 2025. Through co-authorship networks, keyword co-occurrence analysis, and thematic evolution tracking, we identify key research trends, influential authors, and prevailing definitions of LLM trustworthiness. Additionally, a systematic review of 68 core papers is conducted to examine conceptualizations of trust and their practical implications. Our findings reveal that trustworthiness in LLMs is often framed through existing organizational trust frameworks, emphasizing dimensions such as ability, benevolence, and integrity. However, a significant gap exists in translating these principles into concrete development strategies. To address this, we propose a structured mapping of 20 trust-enhancing techniques across the LLM lifecycle, including retrieval-augmented generation (RAG), explainability techniques, and post-training audits. By synthesizing bibliometric insights with practical strategies, this study contributes towards fostering more transparent, accountable, and ethically aligned LLMs, ensuring their responsible deployment in real-world applications.</li>
</ul>

<h3>Title: Towards Anthropomorphic Conversational AI Part I: A Practical Framework</h3>
<ul>
<li><strong>Authors: </strong>Fei Wei, Yaliang Li, Bolin Ding</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04787">https://arxiv.org/abs/2503.04787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04787">https://arxiv.org/pdf/2503.04787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04787]] Towards Anthropomorphic Conversational AI Part I: A Practical Framework(https://arxiv.org/abs/2503.04787)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), due to their advanced natural language capabilities, have seen significant success in applications where the user interface is usually a conversational artificial intelligence (AI) agent and engages the user through multi-round conversations. However, many scenarios require the agents to exhibit stronger social and conversational intelligence and demonstrate more human-like (anthropomorphic) reactions. This is an aspect that foundational LLMs have yet to fully address such that a single call of foundational models might be insufficient. To bridge this gap, we propose a two-stage solution. In this work, we focus on the first stage, introducing a multi-module framework designed to replicate the key aspects of human intelligence involved in conversations. This framework comprises thinking modules for reasoning, resource modules for managing knowledge and external information, and response modules for generating contextually appropriate interactions. With all the modules cooperating, the framework would empower the agents to provide a better human-like conversation experience. In the second stage of our approach, these conversational data, after filtering and labeling, can serve as training and testing data for reinforcement learning, enabling AI to better capture human preferences. This stage is left for future work. In our experiments, volunteers engaged in over 3000 rounds of conversation with the same AI character powered by a standalone LLM and our framework which integrates the same LLM. A separate group of evaluators rated the conversation samples, revealing that our framework significantly enhanced the social and conversational intelligence, even without fine-tuning the LLM.</li>
</ul>

<h3>Title: AgroLLM: Connecting Farmers and Agricultural Practices through Large Language Models for Enhanced Knowledge Transfer and Practical Application</h3>
<ul>
<li><strong>Authors: </strong>Dinesh Jackson Samuel, Inna Skarga-Bandurova, David Sikolia, Muhammad Awais</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04788">https://arxiv.org/abs/2503.04788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04788">https://arxiv.org/pdf/2503.04788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04788]] AgroLLM: Connecting Farmers and Agricultural Practices through Large Language Models for Enhanced Knowledge Transfer and Practical Application(https://arxiv.org/abs/2503.04788)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>AgroLLM is an AI-powered chatbot designed to enhance knowledge-sharing and education in agriculture using Large Language Models (LLMs) and a Retrieval-Augmented Generation (RAG) framework. By using a comprehensive open-source agricultural database, AgroLLM provides accurate, contextually relevant responses while reducing incorrect information retrieval. The system utilizes the FAISS vector database for efficient similarity searches, ensuring rapid access to agricultural knowledge. A comparative study of three advanced models: Gemini 1.5 Flash, ChatGPT-4o Mini, and Mistral-7B-Instruct-v0.2 was conducted to evaluate performance across four key agricultural domains: Agriculture and Life Sciences, Agricultural Management, Agriculture and Forestry, and Agriculture Business. Key evaluation metrics included embedding quality, search efficiency, and response relevance. Results indicated that ChatGPT-4o Mini with RAG achieved the highest accuracy at 93%. Continuous feedback mechanisms enhance response quality, making AgroLLM a benchmark AI-driven educational tool for farmers, researchers, and professionals, promoting informed decision-making and improved agricultural practices.</li>
</ul>

<h3>Title: Ext2Gen: Alignment through Unified Extraction and Generation for Robust Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Hwanjun Song, Jeonghwan Choi, Minseok Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04789">https://arxiv.org/abs/2503.04789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04789">https://arxiv.org/pdf/2503.04789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04789]] Ext2Gen: Alignment through Unified Extraction and Generation for Robust Retrieval-Augmented Generation(https://arxiv.org/abs/2503.04789)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) enhances LLMs by integrating external knowledge, but generation remains fragile due to the uncertain placement of relevant chunks and retrieval-induced information overload, leading to hallucinations. We propose Ext2Gen, a novel extract-then-generate model that enhances RAG robustness by first extracting query-relevant sentences before generating answers. To optimize this model, we employ preference alignment through pairwise feedback learning, enabling the model to generate robust answers regardless of variations in retrieval results. Extensive experiments demonstrate that Ext2Gen effectively identifies query-relevant sentences with high precision and recall, leading to highly reliable answers. Furthermore, deploying our model in a RAG environment reveals that it not only boosts the performance of the base LLM but also synergizes with advanced retrieval strategies like query expansion. The dataset and model will be released soon.</li>
</ul>

<h3>Title: SuperRAG: Beyond RAG with Layout-Aware Graph Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jeff Yang, Duy-Khanh Vu, Minh-Tien Nguyen, Xuan-Quang Nguyen, Linh Nguyen, Hung Le</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04790">https://arxiv.org/abs/2503.04790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04790">https://arxiv.org/pdf/2503.04790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04790]] SuperRAG: Beyond RAG with Layout-Aware Graph Modeling(https://arxiv.org/abs/2503.04790)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces layout-aware graph modeling for multimodal RAG. Different from traditional RAG methods that mostly deal with flat text chunks, the proposed method takes into account the relationship of multimodalities by using a graph structure. To do that, a graph modeling structure is defined based on document layout parsing. The structure of an input document is retained with the connection of text chunks, tables, and figures. This representation allows the method to handle complex questions that require information from multimodalities. To confirm the efficiency of the graph modeling, a flexible RAG pipeline is developed using robust components. Experimental results on four benchmark test sets confirm the contribution of the layout-aware modeling for performance improvement of the RAG pipeline.</li>
</ul>

<h3>Title: Cross-linguistic disagreement as a conflict of semantic alignment norms in multilingual AI~Linguistic Diversity as a Problem for Philosophy, Cognitive Science, and AI~</h3>
<ul>
<li><strong>Authors: </strong>Masaharu Mizumoto, Dat Tien Nguyen, Justin Sytsma, Mark Alfano, Yu Izumi, Koji Fujita, Nguyen Le Minh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04792">https://arxiv.org/abs/2503.04792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04792">https://arxiv.org/pdf/2503.04792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04792]] Cross-linguistic disagreement as a conflict of semantic alignment norms in multilingual AI~Linguistic Diversity as a Problem for Philosophy, Cognitive Science, and AI~(https://arxiv.org/abs/2503.04792)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual large language models (LLMs) face an often-overlooked challenge stemming from intrinsic semantic differences across languages. Linguistic divergence can sometimes lead to cross-linguistic disagreements--disagreements purely due to semantic differences about a relevant concept. This paper identifies such disagreements as conflicts between two fundamental alignment norms in multilingual LLMs: cross-linguistic consistency (CL-consistency), which seeks universal concepts across languages, and consistency with folk judgments (Folk-consistency), which respects language-specific semantic norms. Through examining responses of conversational multilingual AIs in English and Japanese with the cases used in philosophy (cases of knowledge-how attributions), this study demonstrates that even state-of-the-art LLMs provide divergent and internally inconsistent responses. Such findings reveal a novel qualitative limitation in crosslingual knowledge transfer, or conceptual crosslingual knowledge barriers, challenging the assumption that universal representations and cross-linguistic transfer capabilities are inherently desirable. Moreover, they reveal conflicts of alignment policies of their developers, highlighting critical normative questions for LLM researchers and developers. The implications extend beyond technical alignment challenges, raising normative, moral-political, and metaphysical questions about the ideals underlying AI development--questions that are shared with philosophers and cognitive scientists but for which no one yet has definitive answers, inviting a multidisciplinary approach to balance the practical benefits of cross-linguistic consistency and respect for linguistic diversity.</li>
</ul>

<h3>Title: Cyber for AI at SemEval-2025 Task 4: Forgotten but Not Lost: The Balancing Act of Selective Unlearning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dinesh Srivasthav P, Bala Mallikarjunarao Garlapati</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04795">https://arxiv.org/abs/2503.04795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04795">https://arxiv.org/pdf/2503.04795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04795]] Cyber for AI at SemEval-2025 Task 4: Forgotten but Not Lost: The Balancing Act of Selective Unlearning in Large Language Models(https://arxiv.org/abs/2503.04795)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) face significant challenges in maintaining privacy, ethics, and compliance, when sensitive or obsolete data must be selectively removed. Retraining these models from scratch is computationally infeasible, necessitating efficient alternatives. As part of the SemEval 2025 Task 4, this work focuses on the application of selective unlearning in LLMs to address this challenge. In this paper, we present our experiments and findings, primarily leveraging global weight modification to achieve an equilibrium between effectiveness of unlearning, knowledge retention, and target model's post-unlearning utility. We also detail the task-specific evaluation mechanism, results, and challenges. Our algorithms have achieved an aggregate score of 0.409 and 0.389 on the test set for 7B and 1B target models, respectively, demonstrating promising results in verifiable LLM unlearning.</li>
</ul>

<h3>Title: Optimizing Multi-Hop Document Retrieval Through Intermediate Representations</h3>
<ul>
<li><strong>Authors: </strong>Jiaen Lin, Jingyu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04796">https://arxiv.org/abs/2503.04796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04796">https://arxiv.org/pdf/2503.04796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04796]] Optimizing Multi-Hop Document Retrieval Through Intermediate Representations(https://arxiv.org/abs/2503.04796)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) encounters challenges when addressing complex queries, particularly multi-hop questions. While several methods tackle multi-hop queries by iteratively generating internal queries and retrieving external documents, these approaches are computationally expensive. In this paper, we identify a three-stage information processing pattern in LLMs during layer-by-layer reasoning, consisting of extraction, processing, and subsequent extraction steps. This observation suggests that the representations in intermediate layers contain richer information compared to those in other layers. Building on this insight, we propose Layer-wise RAG (L-RAG). Unlike prior methods that focus on generating new internal queries, L-RAG leverages intermediate representations from the middle layers, which capture next-hop information, to retrieve external knowledge. L-RAG achieves performance comparable to multi-step approaches while maintaining inference overhead similar to that of standard RAG. Experimental results show that L-RAG outperforms existing RAG methods on open-domain multi-hop question-answering datasets, including MuSiQue, HotpotQA, and 2WikiMultiHopQA. The code is available in this https URL</li>
</ul>

<h3>Title: Parallel Corpora for Machine Translation in Low-resource Indic Languages: A Comprehensive Review</h3>
<ul>
<li><strong>Authors: </strong>Rahul Raja, Arpita Vats</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04797">https://arxiv.org/abs/2503.04797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04797">https://arxiv.org/pdf/2503.04797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04797]] Parallel Corpora for Machine Translation in Low-resource Indic Languages: A Comprehensive Review(https://arxiv.org/abs/2503.04797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Parallel corpora play an important role in training machine translation (MT) models, particularly for low-resource languages where high-quality bilingual data is scarce. This review provides a comprehensive overview of available parallel corpora for Indic languages, which span diverse linguistic families, scripts, and regional variations. We categorize these corpora into text-to-text, code-switched, and various categories of multimodal datasets, highlighting their significance in the development of robust multilingual MT systems. Beyond resource enumeration, we critically examine the challenges faced in corpus creation, including linguistic diversity, script variation, data scarcity, and the prevalence of informal textual this http URL also discuss and evaluate these corpora in various terms such as alignment quality and domain representativeness. Furthermore, we address open challenges such as data imbalance across Indic languages, the trade-off between quality and quantity, and the impact of noisy, informal, and dialectal data on MT performance. Finally, we outline future directions, including leveraging cross-lingual transfer learning, expanding multilingual datasets, and integrating multimodal resources to enhance translation quality. To the best of our knowledge, this paper presents the first comprehensive review of parallel corpora specifically tailored for low-resource Indic languages in the context of machine translation.</li>
</ul>

<h3>Title: HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Jie Ouyang, Tingyue Pan, Mingyue Cheng, Ruiran Yan, Yucong Luo, Jiaying Lin, Qi Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04800">https://arxiv.org/abs/2503.04800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04800">https://arxiv.org/pdf/2503.04800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04800]] HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation(https://arxiv.org/abs/2503.04800)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Retrieval-Augmented Generation (RAG) has emerged as an effective approach for addressing the knowledge outdating problem in Large Language Models (LLMs), it faces a critical challenge: the prevalence of outdated information in knowledge bases. Current research primarily focuses on incorporating up-to-date information, yet the impact of outdated information coexisting in retrieval sources remains inadequately addressed. To bridge this gap, we introduce HoH, the first benchmark specifically designed to evaluate the impact of outdated information on RAG. Our benchmark leverages token-level diff algorithms combined with LLM pipelines to efficiently create a large-scale QA dataset that accurately captures temporal knowledge evolution in real-world facts. Through comprehensive experiments, we reveal that outdated information significantly degrades RAG performance in two critical ways: (1) it substantially reduces response accuracy by distracting models from correct information, and (2) it can mislead models into generating potentially harmful outputs, even when current information is available. Current RAG approaches struggle with both retrieval and generation aspects when handling outdated information. These findings highlight the urgent need for innovative solutions to address the temporal challenges in RAG.</li>
</ul>

<h3>Title: Exploring and Evaluating Multimodal Knowledge Reasoning Consistency of Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Boyu Jia, Junzhe Zhang, Huixuan Zhang, Xiaojun Wan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04801">https://arxiv.org/abs/2503.04801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04801">https://arxiv.org/pdf/2503.04801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04801]] Exploring and Evaluating Multimodal Knowledge Reasoning Consistency of Multimodal Large Language Models(https://arxiv.org/abs/2503.04801)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, multimodal large language models (MLLMs) have achieved significant breakthroughs, enhancing understanding across text and vision. However, current MLLMs still face challenges in effectively integrating knowledge across these modalities during multimodal knowledge reasoning, leading to inconsistencies in reasoning outcomes. To systematically explore this issue, we propose four evaluation tasks and construct a new dataset. We conduct a series of experiments on this dataset to analyze and compare the extent of consistency degradation in multimodal knowledge reasoning within MLLMs. Based on the experimental results, we identify factors contributing to the observed degradation in consistency. Our research provides new insights into the challenges of multimodal knowledge reasoning and offers valuable guidance for future efforts aimed at improving MLLMs.</li>
</ul>

<h3>Title: The order in speech disorder: a scoping review of state of the art machine learning methods for clinical speech classification</h3>
<ul>
<li><strong>Authors: </strong>Birger Moell, Fredrik Sand Aronsson, Per √ñstberg, Jonas Beskow</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04802">https://arxiv.org/abs/2503.04802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04802">https://arxiv.org/pdf/2503.04802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04802]] The order in speech disorder: a scoping review of state of the art machine learning methods for clinical speech classification(https://arxiv.org/abs/2503.04802)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Background:Speech patterns have emerged as potential diagnostic markers for conditions with varying etiologies. Machine learning (ML) presents an opportunity to harness these patterns for accurate disease diagnosis. Objective: This review synthesized findings from studies exploring ML's capability in leveraging speech for the diagnosis of neurological, laryngeal and mental disorders. Methods: A systematic examination of 564 articles was conducted with 91 articles included in the study, which encompassed a wide spectrum of conditions, ranging from voice pathologies to mental and neurological disorders. Methods for speech classifications were assessed based on the relevant studies and scored between 0-10 based on the reported diagnostic accuracy of their ML models. Results: High diagnostic accuracies were consistently observed for laryngeal disorders, dysarthria, and changes related to speech in Parkinsons disease. These findings indicate the robust potential of speech as a diagnostic tool. Disorders like depression, schizophrenia, mild cognitive impairment and Alzheimers dementia also demonstrated high accuracies, albeit with some variability across studies. Meanwhile, disorders like OCD and autism highlighted the need for more extensive research to ascertain the relationship between speech patterns and the respective conditions. Conclusion: ML models utilizing speech patterns demonstrate promising potential in diagnosing a range of mental, laryngeal, and neurological disorders. However, the efficacy varies across conditions, and further research is needed. The integration of these models into clinical practice could potentially revolutionize the evaluation and diagnosis of a number of different medical conditions.</li>
</ul>

<h3>Title: The Post-Quantum Cryptography Transition: Making Progress, But Still a Long Road Ahead</h3>
<ul>
<li><strong>Authors: </strong>Brian LaMacchia (Farcaster Consulting Group), Matt Campagna (Amazon Web Services), William Gropp (University of Illinois Urbana-Champaign)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04806">https://arxiv.org/abs/2503.04806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04806">https://arxiv.org/pdf/2503.04806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04806]] The Post-Quantum Cryptography Transition: Making Progress, But Still a Long Road Ahead(https://arxiv.org/abs/2503.04806)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>The development of quantum computing threatens the security of our currently widely deployed cryptographic algorithms. While signicant progress has been made in developing post-quantum cryptography (PQC) standards to protect against future quantum computing threats, the U.S. government's estimated $7.1 billion transition cost for non-National Security Systems alone, coupled with an aggressive 2035 deadline, will require sustained funding, research, and international coordination to successfully upgrade existing cryptographic systems.</li>
</ul>

<h3>Title: Call for Rigor in Reporting Quality of Instruction Tuning Data</h3>
<ul>
<li><strong>Authors: </strong>Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04807">https://arxiv.org/abs/2503.04807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04807">https://arxiv.org/pdf/2503.04807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04807]] Call for Rigor in Reporting Quality of Instruction Tuning Data(https://arxiv.org/abs/2503.04807)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is crucial for adapting large language models (LLMs) to align with user intentions. Numerous studies emphasize the significance of the quality of instruction tuning (IT) data, revealing a strong correlation between IT data quality and the alignment performance of LLMs. In these studies, the quality of IT data is typically assessed by evaluating the performance of LLMs trained with that data. However, we identified a prevalent issue in such practice: hyperparameters for training models are often selected arbitrarily without adequate justification. We observed significant variations in hyperparameters applied across different studies, even when training the same model with the same data. In this study, we demonstrate the potential problems arising from this practice and emphasize the need for careful consideration in verifying data quality. Through our experiments on the quality of LIMA data and a selected set of 1,000 Alpaca data points, we demonstrate that arbitrary hyperparameter decisions can make any arbitrary conclusion.</li>
</ul>

<h3>Title: Learning from Failures in Multi-Attempt Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Stephen Chung, Wenyu Du, Jie Fu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04808">https://arxiv.org/abs/2503.04808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04808">https://arxiv.org/pdf/2503.04808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04808]] Learning from Failures in Multi-Attempt Reinforcement Learning(https://arxiv.org/abs/2503.04808)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in reinforcement learning (RL) for large language models (LLMs), exemplified by DeepSeek R1, have shown that even a simple question-answering task can substantially improve an LLM's reasoning capabilities. In this work, we extend this approach by modifying the task into a multi-attempt setting. Instead of generating a single response per question, the model is given multiple attempts, with feedback provided after incorrect responses. The multi-attempt task encourages the model to refine its previous attempts and improve search efficiency. Experimental results show that even a small LLM trained on a multi-attempt task achieves significantly higher accuracy when evaluated with more attempts, improving from 45.6% with 1 attempt to 52.5% with 2 attempts on the math benchmark. In contrast, the same LLM trained on a standard single-turn task exhibits only a marginal improvement, increasing from 42.3% to 43.2% when given more attempts during evaluation. The results indicate that, compared to the standard single-turn task, an LLM trained on a multi-attempt task achieves slightly better performance on math benchmarks while also learning to refine its responses more effectively based on user feedback. Full code is available at this https URL</li>
</ul>

<h3>Title: PanguIR Technical Report for NTCIR-18 AEOLLM Task</h3>
<ul>
<li><strong>Authors: </strong>Lang Mei, Chong Chen, Jiaxin Mao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04809">https://arxiv.org/abs/2503.04809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04809">https://arxiv.org/pdf/2503.04809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04809]] PanguIR Technical Report for NTCIR-18 AEOLLM Task(https://arxiv.org/abs/2503.04809)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) gain widespread attention in both academia and industry, it becomes increasingly critical and challenging to effectively evaluate their capabilities. Existing evaluation methods can be broadly categorized into two types: manual evaluation and automatic evaluation. Manual evaluation, while comprehensive, is often costly and resource-intensive. Conversely, automatic evaluation offers greater scalability but is constrained by the limitations of its evaluation criteria (dominated by reference-based answers). To address these challenges, NTCIR-18 introduced the AEOLLM (Automatic Evaluation of LLMs) task, aiming to encourage reference-free evaluation methods that can overcome the limitations of existing approaches. In this paper, to enhance the evaluation performance of the AEOLLM task, we propose three key methods to improve the reference-free evaluation: 1) Multi-model Collaboration: Leveraging multiple LLMs to approximate human ratings across various subtasks; 2) Prompt Auto-optimization: Utilizing LLMs to iteratively refine the initial task prompts based on evaluation feedback from training samples; and 3) In-context Learning (ICL) Optimization: Based on the multi-task evaluation feedback, we train a specialized in-context example retrieval model, combined with a semantic relevance retrieval model, to jointly identify the most effective in-context learning examples. Experiments conducted on the final dataset demonstrate that our approach achieves superior performance on the AEOLLM task.</li>
</ul>

<h3>Title: Self-Evolved Preference Optimization for Enhancing Mathematical Reasoning in Small Language Models</h3>
<ul>
<li><strong>Authors: </strong>Joykirat Singh, Tanmoy Chakraborty, Akshay Nambi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04813">https://arxiv.org/abs/2503.04813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04813">https://arxiv.org/pdf/2503.04813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04813]] Self-Evolved Preference Optimization for Enhancing Mathematical Reasoning in Small Language Models(https://arxiv.org/abs/2503.04813)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have significantly improved their reasoning capabilities; however, they still struggle with complex multi-step mathematical problem-solving due to error propagation, lack of self-correction, and limited adaptability to diverse reasoning styles. Existing methods rely on static fine-tuning or prompt engineering, which fail to generalize across problem complexities, while the scarcity of high-quality preference data further hinders reliable reasoning. We introduce SPHERE, a self-evolving data generation pipeline that enhances reasoning in small language models (SLMs) by iteratively generating, correcting, and diversifying reasoning chains. SPHERE operates in three stages: (i) Self-Generation, where the model autonomously constructs problem-solving steps; (ii) Self-Correction, enabling it to identify and rectify errors; and (iii) Diversity Induction, improving robustness through multiple valid reasoning trajectories. This self-evolution mechanism strengthens mathematical reasoning and enhances model reliability. Evaluations on MATH 500, GSM8K, AIME, AMC, and Olympiad show that SPHERE-trained models achieve significant gains over their base versions and match/surpass GPT-4o on certain benchmarks. Our findings demonstrate that self-evolving models can close the reasoning gap between SLMs and state-of-the-art LLMs, making mathematical AI more reliable, scalable, and efficient.</li>
</ul>

<h3>Title: Normalization through Fine-tuning: Understanding Wav2vec 2.0 Embeddings for Phonetic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yiming Wang, Yi Yang, Jiahong Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04814">https://arxiv.org/abs/2503.04814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04814">https://arxiv.org/pdf/2503.04814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04814]] Normalization through Fine-tuning: Understanding Wav2vec 2.0 Embeddings for Phonetic Analysis(https://arxiv.org/abs/2503.04814)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Phonetic normalization plays a crucial role in speech recognition and analysis, ensuring the comparability of features derived from raw audio data. However, in the current paradigm of fine-tuning pre-trained large transformer models, phonetic normalization is not deemed a necessary step; instead, it is implicitly executed within the models. This study investigates the normalization process within transformer models, especially wav2vec 2.0. Through a comprehensive analysis of embeddings from models fine-tuned for various tasks, our results demonstrate that fine-tuning wav2vec 2.0 effectively achieves phonetic normalization by selectively suppressing task-irrelevant information. We found that models fine-tuned for multiple tasks retain information for both tasks without compromising performance, and that suppressing task-irrelevant information is not necessary for effective classification. These findings provide new insights into how phonetic normalization can be flexibly achieved in speech models and how it is realized in human speech perception.</li>
</ul>

<h3>Title: Comparative Analysis of Lightweight Kubernetes Distributions for Edge Computing: Security, Resilience and Maintainability</h3>
<ul>
<li><strong>Authors: </strong>Diyaz Yakubov, David H√§stbacka</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04815">https://arxiv.org/abs/2503.04815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04815">https://arxiv.org/pdf/2503.04815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04815]] Comparative Analysis of Lightweight Kubernetes Distributions for Edge Computing: Security, Resilience and Maintainability(https://arxiv.org/abs/2503.04815)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The increasing demand for real-time data processing in Internet of Things (IoT) devices has elevated the importance of edge computing, necessitating efficient and secure deployment of applications on resource-constrained devices. Kubernetes and its lightweight distributions (k0s, k3s, KubeEdge, and OpenYurt) extend container orchestration to edge environments, but their security, reliability, and maintainability have not been comprehensively analyzed. This study compares Kubernetes and these lightweight distributions by evaluating security compliance using kube-bench, simulating network outages to assess resiliency, and documenting maintainability. Results indicate that while k3s and k0s offer superior ease of development due to their simplicity, they have lower security compliance compared to Kubernetes, KubeEdge, and OpenYurt. Kubernetes provides a balanced approach but may be resource-intensive for edge deployments. KubeEdge and OpenYurt enhance security features and reliability under network outages but increase complexity and resource consumption. The findings highlight trade-offs between performance, security, resiliency, and maintainability, offering insights for practitioners deploying Kubernetes in edge environments.</li>
</ul>

<h3>Title: Invisible Strings: Revealing Latent Dancer-to-Dancer Interactions with Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Luis Vitor Zerkowski, Zixuan Wang, Ilya Vidrin, Mariel Pettee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04816">https://arxiv.org/abs/2503.04816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04816">https://arxiv.org/pdf/2503.04816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04816]] Invisible Strings: Revealing Latent Dancer-to-Dancer Interactions with Graph Neural Networks(https://arxiv.org/abs/2503.04816)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Dancing in a duet often requires a heightened attunement to one's partner: their orientation in space, their momentum, and the forces they exert on you. Dance artists who work in partnered settings might have a strong embodied understanding in the moment of how their movements relate to their partner's, but typical documentation of dance fails to capture these varied and subtle relationships. Working closely with dance artists interested in deepening their understanding of partnering, we leverage Graph Neural Networks (GNNs) to highlight and interpret the intricate connections shared by two dancers. Using a video-to-3D-pose extraction pipeline, we extract 3D movements from curated videos of contemporary dance duets, apply a dedicated pre-processing to improve the reconstruction, and train a GNN to predict weighted connections between the dancers. By visualizing and interpreting the predicted relationships between the two movers, we demonstrate the potential for graph-based methods to construct alternate models of the collaborative dynamics of duets. Finally, we offer some example strategies for how to use these insights to inform a generative and co-creative studio practice.</li>
</ul>

<h3>Title: Multi-Agent System for AI-Assisted Extraction of Narrative Arcs in TV Series</h3>
<ul>
<li><strong>Authors: </strong>Roberto Balestri, Guglielmo Pescatore</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04817">https://arxiv.org/abs/2503.04817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04817">https://arxiv.org/pdf/2503.04817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04817]] Multi-Agent System for AI-Assisted Extraction of Narrative Arcs in TV Series(https://arxiv.org/abs/2503.04817)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Serialized TV shows are built on complex storylines that can be hard to track and evolve in ways that defy straightforward analysis. This paper introduces a multi-agent system designed to extract and analyze these narrative arcs. Tested on the first season of Grey's Anatomy (ABC 2005-), the system identifies three types of arcs: Anthology (self-contained), Soap (relationship-focused), and Genre-Specific (strictly related to the series' genre). Episodic progressions of these arcs are stored in both relational and semantic (vectorial) databases, enabling structured analysis and comparison. To bridge the gap between automation and critical interpretation, the system is paired with a graphical interface that allows for human refinement using tools to enhance and visualize the data. The system performed strongly in identifying Anthology Arcs and character entities, but its reliance on textual paratexts (such as episode summaries) revealed limitations in recognizing overlapping arcs and subtler dynamics. This approach highlights the potential of combining computational and human expertise in narrative analysis. Beyond television, it offers promise for serialized written formats, where the narrative resides entirely in the text. Future work will explore the integration of multimodal inputs, such as dialogue and visuals, and expand testing across a wider range of genres to refine the system further.</li>
</ul>

<h3>Title: Prompting Science Report 1: Prompt Engineering is Complicated and Contingent</h3>
<ul>
<li><strong>Authors: </strong>Lennart Meincke, Ethan Mollick, Lilach Mollick, Dan Shapiro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04818">https://arxiv.org/abs/2503.04818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04818">https://arxiv.org/pdf/2503.04818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04818]] Prompting Science Report 1: Prompt Engineering is Complicated and Contingent(https://arxiv.org/abs/2503.04818)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This is the first of a series of short reports that seek to help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. In this report, we demonstrate two things: - There is no single standard for measuring whether a Large Language Model (LLM) passes a benchmark, and that choosing a standard has a big impact on how well the LLM does on that benchmark. The standard you choose will depend on your goals for using an LLM in a particular case. - It is hard to know in advance whether a particular prompting approach will help or harm the LLM's ability to answer any particular question. Specifically, we find that sometimes being polite to the LLM helps performance, and sometimes it lowers performance. We also find that constraining the AI's answers helps performance in some cases, though it may lower performance in other cases. Taken together, this suggests that benchmarking AI performance is not one-size-fits-all, and also that particular prompting formulas or approaches, like being polite to the AI, are not universally valuable.</li>
</ul>

<h3>Title: DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature Extraction</h3>
<ul>
<li><strong>Authors: </strong>Yuheng Kuang, Zhengning Wang, Jianping Zhang, Zhenyu Shi, Yuding Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04823">https://arxiv.org/abs/2503.04823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04823">https://arxiv.org/pdf/2503.04823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04823]] DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature Extraction(https://arxiv.org/abs/2503.04823)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The importance of four-dimensional (4D) trajectory prediction within air traffic management systems is on the rise. Key operations such as conflict detection and resolution, aircraft anomaly monitoring, and the management of congested flight paths are increasingly reliant on this foundational technology, underscoring the urgent demand for intelligent solutions. The dynamics in airport terminal zones and crowded airspaces are intricate and ever-changing; however, current methodologies do not sufficiently account for the interactions among aircraft. To tackle these challenges, we propose DA-STGCN, an innovative spatiotemporal graph convolutional network that integrates a dual attention mechanism. Our model reconstructs the adjacency matrix through a self-attention approach, enhancing the capture of node correlations, and employs graph attention to distill spatiotemporal characteristics, thereby generating a probabilistic distribution of predicted trajectories. This novel adjacency matrix, reconstructed with the self-attention mechanism, is dynamically optimized throughout the network's training process, offering a more nuanced reflection of the inter-node relationships compared to traditional algorithms. The performance of the model is validated on two ADS-B datasets, one near the airport terminal area and the other in dense airspace. Experimental results demonstrate a notable improvement over current 4D trajectory prediction methods, achieving a 20% and 30% reduction in the Average Displacement Error (ADE) and Final Displacement Error (FDE), respectively. The incorporation of a Dual-Attention module has been shown to significantly enhance the extraction of node correlations, as verified by ablation experiments.</li>
</ul>

<h3>Title: Adversarial Example Based Fingerprinting for Robust Copyright Protection in Split Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhangting Lin, Mingfu Xue, Kewei Chen, Wenmao Liu, Xiang Gao, Leo Yu Zhang, Jian Wang, Yushu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04825">https://arxiv.org/abs/2503.04825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04825">https://arxiv.org/pdf/2503.04825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04825]] Adversarial Example Based Fingerprinting for Robust Copyright Protection in Split Learning(https://arxiv.org/abs/2503.04825)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>Currently, deep learning models are easily exposed to data leakage risks. As a distributed model, Split Learning thus emerged as a solution to address this issue. The model is splitted to avoid data uploading to the server and reduce computing requirements while ensuring data privacy and security. However, the transmission of data between clients and server creates a potential vulnerability. In particular, model is vulnerable to intellectual property (IP) infringement such as piracy. Alarmingly, a dedicated copyright protection framework tailored for Split Learning models is still lacking. To this end, we propose the first copyright protection scheme for Split Learning model, leveraging fingerprint to ensure effective and robust copyright protection. The proposed method first generates a set of specifically designed adversarial examples. Then, we select those examples that would induce misclassifications to form the fingerprint set. These adversarial examples are embedded as fingerprints into the model during the training process. Exhaustive experiments highlight the effectiveness of the scheme. This is demonstrated by a remarkable fingerprint verification success rate (FVSR) of 100% on MNIST, 98% on CIFAR-10, and 100% on ImageNet, respectively. Meanwhile, the model's accuracy only decreases slightly, indicating that the embedded fingerprints do not compromise model performance. Even under label inference attack, our approach consistently achieves a high fingerprint verification success rate that ensures robust verification.</li>
</ul>

<h3>Title: Beyond Next Word Prediction: Developing Comprehensive Evaluation Frameworks for measuring LLM performance on real world applications</h3>
<ul>
<li><strong>Authors: </strong>Vishakha Agrawal, Archie Chaudhury, Shreya Agrawal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04828">https://arxiv.org/abs/2503.04828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04828">https://arxiv.org/pdf/2503.04828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04828]] Beyond Next Word Prediction: Developing Comprehensive Evaluation Frameworks for measuring LLM performance on real world applications(https://arxiv.org/abs/2503.04828)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) are fundamentally next-token prediction systems, their practical applications extend far beyond this basic function. From natural language processing and text generation to conversational assistants and software use, LLMs have numerous use-cases, and have already acquired a significant degree of enterprise adoption. To evaluate such models, static evaluation datasets, consisting of a set of prompts and their corresponding ground truths, are often used to benchmark the efficacy of the model for a particular task. In this paper, we provide the basis for a more comprehensive evaluation framework, based upon a traditional game and tool-based architecture that enables a more overarching measurement of a model's capabilities. For simplicity, we provide a generalized foundation that can be extended, without significant alteration, to numerous scenarios, from specific use cases such as supply chain management or financial reasoning, to abstract measurements such as ethics or safety.</li>
</ul>

<h3>Title: StickMotion: Generating 3D Human Motions by Drawing a Stickman</h3>
<ul>
<li><strong>Authors: </strong>Tao Wang, Zhihua Wu, Qiaozhi He, Jiaming Chu, Ling Qian, Yu Cheng, Junliang Xing, Jian Zhao, Lei Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04829">https://arxiv.org/abs/2503.04829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04829">https://arxiv.org/pdf/2503.04829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04829]] StickMotion: Generating 3D Human Motions by Drawing a Stickman(https://arxiv.org/abs/2503.04829)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-motion generation, which translates textual descriptions into human motions, has been challenging in accurately capturing detailed user-imagined motions from simple text inputs. This paper introduces StickMotion, an efficient diffusion-based network designed for multi-condition scenarios, which generates desired motions based on traditional text and our proposed stickman conditions for global and local control of these motions, respectively. We address the challenges introduced by the user-friendly stickman from three perspectives: 1) Data generation. We develop an algorithm to generate hand-drawn stickmen automatically across different dataset formats. 2) Multi-condition fusion. We propose a multi-condition module that integrates into the diffusion process and obtains outputs of all possible condition combinations, reducing computational complexity and enhancing StickMotion's performance compared to conventional approaches with the self-attention module. 3) Dynamic supervision. We empower StickMotion to make minor adjustments to the stickman's position within the output sequences, generating more natural movements through our proposed dynamic supervision strategy. Through quantitative experiments and user studies, sketching stickmen saves users about 51.5% of their time generating motions consistent with their imagination. Our codes, demos, and relevant data will be released to facilitate further research and validation within the scientific community.</li>
</ul>

<h3>Title: Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents</h3>
<ul>
<li><strong>Authors: </strong>Jingying Zeng, Hui Liu, Zhenwei Dai, Xianfeng Tang, Chen Luo, Samarth Varshney, Zhen Li, Qi He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04830">https://arxiv.org/abs/2503.04830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04830">https://arxiv.org/pdf/2503.04830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04830]] Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents(https://arxiv.org/abs/2503.04830)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the advancement of conversational large language models (LLMs), several LLM-based Conversational Shopping Agents (CSA) have been developed to help customers answer questions and smooth their shopping journey in e-commerce domain. The primary objective in building a trustworthy CSA is to ensure the agent's responses are accurate and factually grounded, which is essential for building customer trust and encouraging continuous engagement. However, two challenges remain. First, LLMs produce hallucinated or unsupported claims. Such inaccuracies risk spreading misinformation and diminishing customer trust. Second, without providing knowledge source attribution in CSA response, customers struggle to verify LLM-generated information. To address these challenges, we present an easily productionized solution that enables a "citation experience" utilizing In-context Learning (ICL) and Multi-UX-Inference (MUI) to generate responses with citations to attribute its original sources without interfering other existing UX features. With proper UX design, these citation marks can be linked to the related product information and display the source to our customers. In this work, we also build auto-metrics and scalable benchmarks to holistically evaluate LLM's grounding and attribution capabilities. Our experiments demonstrate that incorporating this citation generation paradigm can substantially enhance the grounding of LLM responses by 13.83% on the real-world data. As such, our solution not only addresses the immediate challenges of LLM grounding issues but also adds transparency to conversational AI.</li>
</ul>

<h3>Title: "Only ChatGPT gets me": An Empirical Analysis of GPT versus other Large Language Models for Emotion Detection in Text</h3>
<ul>
<li><strong>Authors: </strong>Florian Lecourt (LIRMM | ADVANSE), Madalina Croitoru (GRAPHIK), Konstantin Todorov (LIRMM | WEB3, LIRMM, WEB3)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04831">https://arxiv.org/abs/2503.04831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04831">https://arxiv.org/pdf/2503.04831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04831]] "Only ChatGPT gets me": An Empirical Analysis of GPT versus other Large Language Models for Emotion Detection in Text(https://arxiv.org/abs/2503.04831)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work investigates the capabilities of large language models (LLMs) in detecting and understanding human emotions through text. Drawing upon emotion models from psychology, we adopt an interdisciplinary perspective that integrates computational and affective sciences insights. The main goal is to assess how accurately they can identify emotions expressed in textual interactions and compare different models on this specific task. This research contributes to broader efforts to enhance human-computer interaction, making artificial intelligence technologies more responsive and sensitive to users' emotional nuances. By employing a methodology that involves comparisons with a state-of-the-art model on the GoEmotions dataset, we aim to gauge LLMs' effectiveness as a system for emotional analysis, paving the way for potential applications in various fields that require a nuanced understanding of human language.</li>
</ul>

<h3>Title: Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks</h3>
<ul>
<li><strong>Authors: </strong>Liming Lu, Shuchao Pang, Siyuan Liang, Haotian Zhu, Xiyu Zeng, Aishan Liu, Yunhuai Liu, Yongbin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04833">https://arxiv.org/abs/2503.04833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04833">https://arxiv.org/pdf/2503.04833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04833]] Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks(https://arxiv.org/abs/2503.04833)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have made remarkable strides in cross-modal comprehension and generation tasks. However, they remain vulnerable to jailbreak attacks, where crafted perturbations bypass security guardrails and elicit harmful outputs. In this paper, we present the first adversarial training (AT) paradigm tailored to defend against jailbreak attacks during the MLLM training phase. Extending traditional AT to this domain poses two critical challenges: efficiently tuning massive parameters and ensuring robustness against attacks across multiple modalities. To address these challenges, we introduce Projection Layer Against Adversarial Training (ProEAT), an end-to-end AT framework. ProEAT incorporates a projector-based adversarial training architecture that efficiently handles large-scale parameters while maintaining computational feasibility by focusing adversarial training on a lightweight projector layer instead of the entire model; additionally, we design a dynamic weight adjustment mechanism that optimizes the loss function's weight allocation based on task demands, streamlining the tuning process. To enhance defense performance, we propose a joint optimization strategy across visual and textual modalities, ensuring robust resistance to jailbreak attacks originating from either modality. Extensive experiments conducted on five major jailbreak attack methods across three mainstream MLLMs demonstrate the effectiveness of our approach. ProEAT achieves state-of-the-art defense performance, outperforming existing baselines by an average margin of +34% across text and image modalities, while incurring only a 1% reduction in clean accuracy. Furthermore, evaluations on real-world embodied intelligent systems highlight the practical applicability of our framework, paving the way for the development of more secure and reliable multimodal systems.</li>
</ul>

<h3>Title: Extrapolation Merging: Keep Improving With Extrapolation and Merging</h3>
<ul>
<li><strong>Authors: </strong>Yiguan Lin, Bin Xu, Yinghao Li, Yang Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04834">https://arxiv.org/abs/2503.04834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04834">https://arxiv.org/pdf/2503.04834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04834]] Extrapolation Merging: Keep Improving With Extrapolation and Merging(https://arxiv.org/abs/2503.04834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) require instruction fine-tuning to perform different downstream tasks. However, the instruction fine-tuning phase still demands significant computational resources and labeled data, lacking a paradigm that can improve model performance without additional computational power and data. Model merging aims to enhance performance by combining the parameters of different models, but the lack of a clear optimization direction during the merging process does not always guarantee improved performance. In this paper, we attempt to provide a clear optimization direction for model merging. We first validate the effectiveness of the model extrapolation method during the instruction fine-tuning phase. Then, we propose Extrapolation Merging, a paradigm that can continue improving model performance without requiring extra computational resources or data. Using the extrapolation method, we provide a clear direction for model merging, achieving local optimization search, and consequently enhancing the merged model's performance. We conduct experiments on seven different tasks, and the results show that our method can consistently improve the model's performance after fine-tuning.</li>
</ul>

<h3>Title: FedPalm: A General Federated Learning Framework for Closed- and Open-Set Palmprint Verification</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan Yang, Yingyu Chen, Chengrui Gao, Andrew Beng Jin Teoh, Bob Zhang, Yi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04837">https://arxiv.org/abs/2503.04837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04837">https://arxiv.org/pdf/2503.04837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04837]] FedPalm: A General Federated Learning Framework for Closed- and Open-Set Palmprint Verification(https://arxiv.org/abs/2503.04837)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, biometric, federate</a></li>
<li><strong>Abstract: </strong>Current deep learning (DL)-based palmprint verification models rely on centralized training with large datasets, which raises significant privacy concerns due to biometric data's sensitive and immutable nature. Federated learning~(FL), a privacy-preserving distributed learning paradigm, offers a compelling alternative by enabling collaborative model training without the need for data sharing. However, FL-based palmprint verification faces critical challenges, including data heterogeneity from diverse identities and the absence of standardized evaluation benchmarks. This paper addresses these gaps by establishing a comprehensive benchmark for FL-based palmprint verification, which explicitly defines and evaluates two practical scenarios: closed-set and open-set verification. We propose FedPalm, a unified FL framework that balances local adaptability with global generalization. Each client trains a personalized textural expert tailored to local data and collaboratively contributes to a shared global textural expert for extracting generalized features. To further enhance verification performance, we introduce a Textural Expert Interaction Module that dynamically routes textural features among experts to generate refined side textural features. Learnable parameters are employed to model relationships between original and side features, fostering cross-texture-expert interaction and improving feature discrimination. Extensive experiments validate the effectiveness of FedPalm, demonstrating robust performance across both scenarios and providing a promising foundation for advancing FL-based palmprint verification research.</li>
</ul>

<h3>Title: Advancing Multimodal In-Context Learning in Large Vision-Language Models with Task-aware Demonstrations</h3>
<ul>
<li><strong>Authors: </strong>Yanshu Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04839">https://arxiv.org/abs/2503.04839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04839">https://arxiv.org/pdf/2503.04839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04839]] Advancing Multimodal In-Context Learning in Large Vision-Language Models with Task-aware Demonstrations(https://arxiv.org/abs/2503.04839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Multimodal in-context learning (ICL) has emerged as a key capability of Large Vision-Language Models (LVLMs), driven by their increasing scale and applicability. Despite its promise, effective ICL in the multimodal setting remains challenging due to the inherent complexity of image-text inputs and the high sensitivity of ICL performance to input configurations. In this work, we shed light on the core mechanism underlying multimodal ICL, identifying task mapping as a crucial factor in configuring robust in-context demonstration (ICD) sequences. Building on these insights, we propose \textit{SabER}, a lightweight yet powerful decoder-only transformer equipped with task-aware attention, which intelligently selects and arranges ICDs from a demonstration library in an autoregressive fashion. This design enables fine-grained feature extraction and cross-modal reasoning, iteratively refining task mapping to generate high-quality ICD sequences. Through extensive experiments covering five LVLMs and nine benchmark datasets, SabER not only demonstrates strong empirical performance, but also provides deeper understanding of how task semantics interact with multimodal ICDs. Our findings highlight the importance of principled ICD sequence configuration and open new avenues to enhance multimodal ICL in a wide range of real-world scenarios.</li>
</ul>

<h3>Title: Framing the Game: How Context Shapes LLM Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Isaac Robinson, John Burden</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04840">https://arxiv.org/abs/2503.04840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04840">https://arxiv.org/pdf/2503.04840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04840]] Framing the Game: How Context Shapes LLM Decision-Making(https://arxiv.org/abs/2503.04840)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed across diverse contexts to support decision-making. While existing evaluations effectively probe latent model capabilities, they often overlook the impact of context framing on perceived rational decision-making. In this study, we introduce a novel evaluation framework that systematically varies evaluation instances across key features and procedurally generates vignettes to create highly varied scenarios. By analyzing decision-making patterns across different contexts with the same underlying game structure, we uncover significant contextual variability in LLM responses. Our findings demonstrate that this variability is largely predictable yet highly sensitive to framing effects. Our results underscore the need for dynamic, context-aware evaluation methodologies for real-world deployments.</li>
</ul>

<h3>Title: Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model</h3>
<ul>
<li><strong>Authors: </strong>Necdet Gurkan, Kimathi Njoki, Jordan W. Suchow</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04842">https://arxiv.org/abs/2503.04842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04842">https://arxiv.org/pdf/2503.04842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04842]] Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model(https://arxiv.org/abs/2503.04842)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As artificial intelligence (AI) continues to advance--particularly in generative models--an open question is whether these systems can replicate foundational models of human social perception. A well-established framework in social cognition suggests that social judgments are organized along two primary dimensions: valence (e.g., trustworthiness, warmth) and dominance (e.g., power, assertiveness). This study examines whether multimodal generative AI systems can reproduce this valence-dominance structure when evaluating facial images and how their representations align with those observed across world regions. Through principal component analysis (PCA), we found that the extracted dimensions closely mirrored the theoretical structure of valence and dominance, with trait loadings aligning with established definitions. However, many world regions and generative AI models also exhibited a third component, the nature and significance of which warrant further investigation. These findings demonstrate that multimodal generative AI systems can replicate key aspects of human social perception, raising important questions about their implications for AI-driven decision-making and human-AI interactions.</li>
</ul>

<h3>Title: ZAugNet for Z-Slice Augmentation in Bio-Imaging</h3>
<ul>
<li><strong>Authors: </strong>Alessandro Pasqui, Sajjad Mahdavi, Benoit Vianay, Alexandra Colin, Alex McDougall, R√©mi Dumollard, Yekaterina A. Miroshnikova, Elsa Labrune, Herv√© Turlier</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04843">https://arxiv.org/abs/2503.04843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04843">https://arxiv.org/pdf/2503.04843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04843]] ZAugNet for Z-Slice Augmentation in Bio-Imaging(https://arxiv.org/abs/2503.04843)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Three-dimensional biological microscopy has significantly advanced our understanding of complex biological structures. However, limitations due to microscopy techniques, sample properties or phototoxicity often result in poor z-resolution, hindering accurate cellular measurements. Here, we introduce ZAugNet, a fast, accurate, and self-supervised deep learning method for enhancing z-resolution in biological images. By performing nonlinear interpolation between consecutive slices, ZAugNet effectively doubles resolution with each iteration. Compared on several microscopy modalities and biological objects, it outperforms competing methods on most metrics. Our method leverages a generative adversarial network (GAN) architecture combined with knowledge distillation to maximize prediction speed without compromising accuracy. We also developed ZAugNet+, an extended version enabling continuous interpolation at arbitrary distances, making it particularly useful for datasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide high-performance, scalable z-slice augmentation solutions for large-scale 3D imaging. They are available as open-source frameworks in PyTorch, with an intuitive Colab notebook interface for easy access by the scientific community.</li>
</ul>

<h3>Title: Universal Narrative Model: an Author-centric Storytelling Framework for Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Hank Gerba</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04844">https://arxiv.org/abs/2503.04844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04844">https://arxiv.org/pdf/2503.04844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04844]] Universal Narrative Model: an Author-centric Storytelling Framework for Generative AI(https://arxiv.org/abs/2503.04844)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative AI promises to finally realize dynamic, personalized storytelling technologies across a range of media. To date, experimentation with generative AI in the field of procedural narrative generation has been quite promising from a technical perspective. However, fundamental narrative dilemmas remain, such as the balance between player agency and narrative coherence, and no rigorous narrative standard has been proposed to specifically leverage the strengths of generative AI. In this paper, we propose the Universal Narrative Model (UNM), an open and extensible standard designed to place writers at the center of future narrative design workflows and enable interoperability across authoring platforms. By encoding an author's intent according to an objective narrative model, the UNM enables narrative portability as well as intent-based constraints for generative systems.</li>
</ul>

<h3>Title: Honest to a Fault: Root-Causing Fault Attacks with Pre-Silicon RISC Pipeline Characterization</h3>
<ul>
<li><strong>Authors: </strong>Arsalan Ali Malik, Harshvadan Mihir, Aydin Aysu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04846">https://arxiv.org/abs/2503.04846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04846">https://arxiv.org/pdf/2503.04846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04846]] Honest to a Fault: Root-Causing Fault Attacks with Pre-Silicon RISC Pipeline Characterization(https://arxiv.org/abs/2503.04846)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Fault injection attacks represent a class of threats that can compromise embedded systems across multiple layers of abstraction, such as system software, instruction set architecture (ISA), microarchitecture, and physical implementation. Early detection of these vulnerabilities and understanding their root causes along with their propagation from the physical layer to the system software is critical to secure the cyberinfrastructure. This present presents a comprehensive methodology for conducting controlled fault injection attacks at the pre-silicon level and an analysis of the underlying system for root-causing behavior. As the driving application, we use the clock glitch attacks in AI/ML applications for critical misclassification. Our study aims to characterize and diagnose the impact of faults within the RISC-V instruction set and pipeline stages, while tracing fault propagation from the circuit level to the AI/ML application software. This analysis resulted in discovering a novel vulnerability through controlled clock glitch parameters, specifically targeting the RISC-V decode stage.</li>
</ul>

<h3>Title: Three tiers of computation in transformers and in brain architectures</h3>
<ul>
<li><strong>Authors: </strong>E Graham, R Granger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.NE, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04848">https://arxiv.org/abs/2503.04848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04848">https://arxiv.org/pdf/2503.04848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04848]] Three tiers of computation in transformers and in brain architectures(https://arxiv.org/abs/2503.04848)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Specific empirical phenomena spanning human natural language, and mathematical and logical abilities, are rigorously situated in the well-studied grammar-automata (G-A) hierarchy. We identify three tiers and corresponding two transitions within the hierarchy and show their correspondence to the emergence of particular abilities in humans and in transformer-based language models (LMs). These emergent abilities have often been described in terms of "scaling"; we show that it is the transition between tiers, rather than size itself, that determines a system's capabilities. Specifically, humans effortlessly process language yet require specific training to perform arithmetic or logical reasoning tasks; and LMs possess language abilities absent from predecessor systems yet still struggle with logical processing. The resulting principled analyses provide underlying explanatory accounts of both the abilities and shortfalls of these systems, and suggest actionable insights into the expansion of logic abilities in AI systems.</li>
</ul>

<h3>Title: Enhancing Collective Intelligence in Large Language Models Through Emotional Integration</h3>
<ul>
<li><strong>Authors: </strong>Likith Kadiyala, Ramteja Sajja, Yusuf Sermet, Ibrahim Demir</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04849">https://arxiv.org/abs/2503.04849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04849">https://arxiv.org/pdf/2503.04849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04849]] Enhancing Collective Intelligence in Large Language Models Through Emotional Integration(https://arxiv.org/abs/2503.04849)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This research investigates the integration of emotional diversity into Large Language Models (LLMs) to enhance collective intelligence. Inspired by the human wisdom of crowds phenomenon, where group decisions often outperform individual judgments, we fine-tuned the DarkIdol-Llama-3.1-8B model using Google's GoEmotions dataset and Low-Rank Adaptation (LoRA) to simulate emotionally diverse responses. Evaluating the model on a distance estimation task between Fargo, ND, and Seattle, WA, across 15,064 unique persona configurations, we analyzed how emotional states and social attributes influence decision-making. Our findings demonstrate that emotional integration shapes response patterns while maintaining acceptable prediction accuracy, revealing its potential to enhance artificial collective intelligence. This study provides valuable insights into the interplay of emotional diversity and decision-making in LLMs, suggesting pathways for creating emotionally aware AI systems that balance emotional depth with analytical precision.</li>
</ul>

<h3>Title: Slow is Fast! Dissecting Ethereum's Slow Liquidity Drain</h3>
<ul>
<li><strong>Authors: </strong>Minh Trung Tran, Nasrin Sohrabi, Zahir Tari, Qin Wang, Xiaoyu Xia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04850">https://arxiv.org/abs/2503.04850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04850">https://arxiv.org/pdf/2503.04850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04850]] Slow is Fast! Dissecting Ethereum's Slow Liquidity Drain(https://arxiv.org/abs/2503.04850)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>We identify the slow liquidity drain (SLID) scam, an insidious and highly profitable threat to decentralized finance (DeFi), posing a large-scale, persistent, and growing risk to the ecosystem. Unlike traditional scams such as rug pulls or honeypots (USENIX Sec'19, USENIX Sec'23), SLID gradually siphons funds from liquidity pools over extended periods, making detection significantly more challenging. In this paper, we conducted the first large-scale empirical analysis of 319,166 liquidity pools across six major decentralized exchanges (DEXs) since 2018. We identified 3,117 SLID affected liquidity pools, resulting in cumulative losses of more than US$103 million. We propose a rule-based heuristic and an enhanced machine learning model for early detection. Our machine learning model achieves a detection speed 4.77 times faster than the heuristic while maintaining 95% accuracy. Our study establishes a foundation for protecting DeFi investors at an early stage and promoting transparency in the DeFi ecosystem.</li>
</ul>

<h3>Title: From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints</h3>
<ul>
<li><strong>Authors: </strong>Yansong Gao, Huaibing Peng, Hua Ma, Zhiyang Dai, Shuo Wang, Hongsheng Hu, Anmin Fu, Minhui Xue</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04853">https://arxiv.org/abs/2503.04853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04853">https://arxiv.org/pdf/2503.04853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04853]] From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints(https://arxiv.org/abs/2503.04853)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>For the first time, we unveil discernible temporal (or historical) trajectory imprints resulting from adversarial example (AE) attacks. Standing in contrast to existing studies all focusing on spatial (or static) imprints within the targeted underlying victim models, we present a fresh temporal paradigm for understanding these attacks. Of paramount discovery is that these imprints are encapsulated within a single loss metric, spanning universally across diverse tasks such as classification and regression, and modalities including image, text, and audio. Recognizing the distinct nature of loss between adversarial and clean examples, we exploit this temporal imprint for AE detection by proposing TRAIT (TRaceable Adversarial temporal trajectory ImprinTs). TRAIT operates under minimal assumptions without prior knowledge of attacks, thereby framing the detection challenge as a one-class classification problem. However, detecting AEs is still challenged by significant overlaps between the constructed synthetic losses of adversarial and clean examples due to the absence of ground truth for incoming inputs. TRAIT addresses this challenge by converting the synthetic loss into a spectrum signature, using the technique of Fast Fourier Transform to highlight the discrepancies, drawing inspiration from the temporal nature of the imprints, analogous to time-series signals. Across 12 AE attacks including SMACK (USENIX Sec'2023), TRAIT demonstrates consistent outstanding performance across comprehensively evaluated modalities, tasks, datasets, and model architectures. In all scenarios, TRAIT achieves an AE detection accuracy exceeding 97%, often around 99%, while maintaining a false rejection rate of 1%. TRAIT remains effective under the formulated strong adaptive attacks.</li>
</ul>

<h3>Title: One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04856">https://arxiv.org/abs/2503.04856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04856">https://arxiv.org/pdf/2503.04856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04856]] One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs(https://arxiv.org/abs/2503.04856)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Despite extensive safety enhancements in large language models (LLMs), multi-turn "jailbreak" conversations crafted by skilled human adversaries can still breach even the most sophisticated guardrails. However, these multi-turn attacks demand considerable manual effort, limiting their scalability. In this work, we introduce a novel approach called Multi-turn-to-Single-turn (M2S) that systematically converts multi-turn jailbreak prompts into single-turn attacks. Specifically, we propose three conversion strategies - Hyphenize, Numberize, and Pythonize - each preserving sequential context yet packaging it in a single query. Our experiments on the Multi-turn Human Jailbreak (MHJ) dataset show that M2S often increases or maintains high Attack Success Rates (ASRs) compared to original multi-turn conversations. Notably, using a StrongREJECT-based evaluation of harmfulness, M2S achieves up to 95.9% ASR on Mistral-7B and outperforms original multi-turn prompts by as much as 17.5% in absolute improvement on GPT-4o. Further analysis reveals that certain adversarial tactics, when consolidated into a single prompt, exploit structural formatting cues to evade standard policy checks. These findings underscore that single-turn attacks - despite being simpler and cheaper to conduct - can be just as potent, if not more, than their multi-turn counterparts. Our findings underscore the urgent need to reevaluate and reinforce LLM safety strategies, given how adversarial queries can be compacted into a single prompt while still retaining sufficient complexity to bypass existing safety measures.</li>
</ul>

<h3>Title: SHAPE : Self-Improved Visual Preference Alignment by Iteratively Generating Holistic Winner</h3>
<ul>
<li><strong>Authors: </strong>Kejia Chen, Jiawen Zhang, Jiacong Hu, Jiazhen Yang, Jian Lou, Zunlei Feng, Mingli Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04858">https://arxiv.org/abs/2503.04858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04858">https://arxiv.org/pdf/2503.04858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04858]] SHAPE : Self-Improved Visual Preference Alignment by Iteratively Generating Holistic Winner(https://arxiv.org/abs/2503.04858)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Visual Language Models (LVLMs) increasingly rely on preference alignment to ensure reliability, which steers the model behavior via preference fine-tuning on preference data structured as ``image - winner text - loser text'' triplets. However, existing approaches often suffer from limited diversity and high costs associated with human-annotated preference data, hindering LVLMs from fully achieving their intended alignment capabilities. We present \projectname, a self-supervised framework capable of transforming the already abundant supervised text-image pairs into holistic preference triplets for more effective and cheaper LVLM alignment, eliminating the need for human preference annotations. Our approach facilitates LVLMs in progressively enhancing alignment capabilities through iterative self-improvement. The key design rationale is to devise preference triplets where the winner text consistently improves in holisticness and outperforms the loser response in quality, thereby pushing the model to ``strive to the utmost'' of alignment performance through preference fine-tuning. For each given text-image pair, SHAPE introduces multiple visual augmentations and pairs them with a summarized text to serve as the winner response, while designating the original text as the loser response. Experiments across \textbf{12} benchmarks on various model architectures and sizes, including LLaVA and DeepSeek-VL, show that SHAPE achieves significant gains, for example, achieving +11.3\% on MMVet (comprehensive evaluation), +1.4\% on MMBench (general VQA), and +8.0\% on POPE (hallucination robustness) over baselines in 7B models. Notably, qualitative analyses confirm enhanced attention to visual details and better alignment with human preferences for holistic descriptions.</li>
</ul>

<h3>Title: Codebook Reduction and Saturation: Novel observations on Inductive Thematic Saturation for Large Language Models and initial coding in Thematic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Stefano De Paoli, Walter Stan Mathis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04859">https://arxiv.org/abs/2503.04859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04859">https://arxiv.org/pdf/2503.04859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04859]] Codebook Reduction and Saturation: Novel observations on Inductive Thematic Saturation for Large Language Models and initial coding in Thematic Analysis(https://arxiv.org/abs/2503.04859)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper reflects on the process of performing Thematic Analysis with Large Language Models (LLMs). Specifically, the paper deals with the problem of analytical saturation of initial codes, as produced by LLMs. Thematic Analysis is a well-established qualitative analysis method composed of interlinked phases. A key phase is the initial coding, where the analysts assign labels to discrete components of a dataset. Saturation is a way to measure the validity of a qualitative analysis and relates to the recurrence and repetition of initial codes. In the paper we reflect on how well LLMs achieve analytical saturation and propose also a novel technique to measure Inductive Thematic Saturation (ITS). This novel technique leverages a programming framework called DSPy. The proposed novel approach allows a precise measurement of ITS.</li>
</ul>

<h3>Title: Out-of-Distribution Radar Detection in Compound Clutter and Thermal Noise through Variational Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Y A Rouzoumka (SONDRA), E Terreaux, C Morisseau, J.-P Ovarlez (SONDRA), C Ren (SONDRA)</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04861">https://arxiv.org/abs/2503.04861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04861">https://arxiv.org/pdf/2503.04861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04861]] Out-of-Distribution Radar Detection in Compound Clutter and Thermal Noise through Variational Autoencoders(https://arxiv.org/abs/2503.04861)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a novel approach to radar target detection using Variational AutoEncoders (VAEs). Known for their ability to learn complex distributions and identify out-ofdistribution samples, the proposed VAE architecture effectively distinguishes radar targets from various noise types, including correlated Gaussian and compound Gaussian clutter, often combined with additive white Gaussian thermal noise. Simulation results demonstrate that the proposed VAE outperforms classical adaptive detectors such as the Matched Filter and the Normalized Matched Filter, especially in challenging noise conditions, highlighting its robustness and adaptability in radar applications.</li>
</ul>

<h3>Title: High-Precision Transformer-Based Visual Servoing for Humanoid Robots in Aligning Tiny Objects</h3>
<ul>
<li><strong>Authors: </strong>Jialong Xue, Wei Gao, Yu Wang, Chao Ji, Dongdong Zhao, Shi Yan, Shiwu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04862">https://arxiv.org/abs/2503.04862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04862">https://arxiv.org/pdf/2503.04862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04862]] High-Precision Transformer-Based Visual Servoing for Humanoid Robots in Aligning Tiny Objects(https://arxiv.org/abs/2503.04862)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>High-precision tiny object alignment remains a common and critical challenge for humanoid robots in real-world. To address this problem, this paper proposes a vision-based framework for precisely estimating and controlling the relative position between a handheld tool and a target object for humanoid robots, e.g., a screwdriver tip and a screw head slot. By fusing images from the head and torso cameras on a robot with its head joint angles, the proposed Transformer-based visual servoing method can correct the handheld tool's positional errors effectively, especially at a close distance. Experiments on M4-M8 screws demonstrate an average convergence error of 0.8-1.3 mm and a success rate of 93\%-100\%. Through comparative analysis, the results validate that this capability of high-precision tiny object alignment is enabled by the Distance Estimation Transformer architecture and the Multi-Perception-Head mechanism proposed in this paper.</li>
</ul>

<h3>Title: Privacy in Responsible AI: Approaches to Facial Recognition from Cloud Providers</h3>
<ul>
<li><strong>Authors: </strong>Anna Elivanova</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04866">https://arxiv.org/abs/2503.04866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04866">https://arxiv.org/pdf/2503.04866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04866]] Privacy in Responsible AI: Approaches to Facial Recognition from Cloud Providers(https://arxiv.org/abs/2503.04866)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>As the use of facial recognition technology is expanding in different domains, ensuring its responsible use is gaining more importance. This paper conducts a comprehensive literature review of existing studies on facial recognition technology from the perspective of privacy, which is one of the key Responsible AI principles. Cloud providers, such as Microsoft, AWS, and Google, are at the forefront of delivering facial-related technology services, but their approaches to responsible use of these technologies vary significantly. This paper compares how these cloud giants implement the privacy principle into their facial recognition and detection services. By analysing their approaches, it identifies both common practices and notable differences. The results of this research will be valuable for developers and businesses by providing them insights into best practices of three major companies for integration responsible AI, particularly privacy, into their cloud-based facial recognition technologies.</li>
</ul>

<h3>Title: Security and Real-time FPGA integration for Learned Image Compression</h3>
<ul>
<li><strong>Authors: </strong>Alaa Mazouz, Carl De Sousa Tria, Sumanta Chaudhuri, Attilio Fiandrotti, Marco Cagnanzzo, Mihai Mitrea, Enzo Tartaglione</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04867">https://arxiv.org/abs/2503.04867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04867">https://arxiv.org/pdf/2503.04867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04867]] Security and Real-time FPGA integration for Learned Image Compression(https://arxiv.org/abs/2503.04867)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, robust, watermark</a></li>
<li><strong>Abstract: </strong>Learnable Image Compression (LIC) has proven capable of outperforming standardized video codecs in compression efficiency. However, achieving both real-time and secure LIC operations on hardware presents significant conceptual and methodological challenges. The present work addresses these challenges by providing an integrated workflow and platform for training, securing, and deploying LIC models on hardware. To this end, a hardware-friendly LIC model is obtained by iteratively pruning and quantizing the model within a standard end-to-end learning framework. Notably, we introduce a novel Quantization-Aware Watermarking (QAW) technique, where the model is watermarked during quantization using a join loss function, ensuring robust security without compromising model performance. The watermarked weights are then public-key encrypted, guaranteeing both content protection and user traceability. Experimental results across different FPGA platforms evaluate real-time performance, latency, energy consumption, and compression efficiency, highlighting that the watermarking and encryption processes maintain negligible impact on compression efficiency (average of -0.4 PSNR) and energy consumption (average of +2%), while still meeting real-time constraints and preserving security properties.</li>
</ul>

<h3>Title: Toward Lightweight and Fast Decoders for Diffusion Models in Image and Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Alexey Buzovkin, Evgeny Shilov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04871">https://arxiv.org/abs/2503.04871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04871">https://arxiv.org/pdf/2503.04871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04871]] Toward Lightweight and Fast Decoders for Diffusion Models in Image and Video Generation(https://arxiv.org/abs/2503.04871)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We investigate methods to reduce inference time and memory footprint in stable diffusion models by introducing lightweight decoders for both image and video synthesis. Traditional latent diffusion pipelines rely on large Variational Autoencoder decoders that can slow down generation and consume considerable GPU memory. We propose custom-trained decoders using lightweight Vision Transformer and Taming Transformer architectures. Experiments show up to 15% overall speed-ups for image generation on COCO2017 and up to 20 times faster decoding in the sub-module, with additional gains on UCF-101 for video tasks. Memory requirements are moderately reduced, and while there is a small drop in perceptual quality compared to the default decoder, the improvements in speed and scalability are crucial for large-scale inference scenarios such as generating 100K images. Our work is further contextualized by advances in efficient video generation, including dual masking strategies, illustrating a broader effort to improve the scalability and efficiency of generative models.</li>
</ul>

<h3>Title: TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Lin Sun, Guangxiang Zhao, Xiaoqi Jian, Yuhan Wu, Weihong Lin, Yongfu Zhu, Change Jia, Linglin Zhang, Jinzhu Wu, Junfeng Ran, Sai-er Hu, Zihan Jiang, Junting Zhou, Wenrui Liu, Bin Cui, Tong Yang, Xiangzheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04872">https://arxiv.org/abs/2503.04872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04872">https://arxiv.org/pdf/2503.04872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04872]] TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation(https://arxiv.org/abs/2503.04872)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The challenge of reducing the size of Large Language Models (LLMs) while maintaining their performance has gained significant attention. However, existing methods, such as model distillation and transfer learning, often fail to achieve high accuracy. To address this limitation, we introduce the Branch-Merge distillation approach, which enhances model compression through two phases: (1) the Branch Phase, where knowledge from a large teacher model is \textit{selectively distilled} into specialized student models via domain-specific supervised fine-tuning (SFT); And (2) the Merge Phase, where these student models are merged to enable cross-domain knowledge transfer and improve generalization. We validate our distillation approach using DeepSeek-R1 as the teacher and DeepSeek-R1-Distill-Qwen-32B as the student. The resulting merged model, TinyR1-32B-Preview, outperforms its counterpart DeepSeek-R1-Distill-Qwen-32B across multiple benchmarks, including Mathematics (+5.5 points), Coding (+4.4 points) and Science (+2.9 points), while achieving near-equal performance to DeepSeek-R1 on AIME 2024. The Branch-Merge distillation approach provides a scalable solution for creating smaller, high-performing LLMs with reduced computational cost and time.</li>
</ul>

<h3>Title: Are Large Language Models Good In-context Learners for Financial Sentiment Analysis?</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Wei, Luojia Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04873">https://arxiv.org/abs/2503.04873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04873">https://arxiv.org/pdf/2503.04873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04873]] Are Large Language Models Good In-context Learners for Financial Sentiment Analysis?(https://arxiv.org/abs/2503.04873)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, large language models (LLMs) with hundreds of billions of parameters have demonstrated the emergent ability, surpassing traditional methods in various domains even without fine-tuning over domain-specific data. However, when it comes to financial sentiment analysis (FSA)$\unicode{x2013}$a fundamental task in financial AI$\unicode{x2013}$these models often encounter various challenges, such as complex financial terminology, subjective human emotions, and ambiguous inclination expressions. In this paper, we aim to answer the fundamental question: whether LLMs are good in-context learners for FSA? Unveiling this question can yield informative insights on whether LLMs can learn to address the challenges by generalizing in-context demonstrations of financial document-sentiment pairs to the sentiment analysis of new documents, given that finetuning these models on finance-specific data is difficult, if not impossible at all. To the best of our knowledge, this is the first paper exploring in-context learning for FSA that covers most modern LLMs (recently released DeepSeek V3 included) and multiple in-context sample selection methods. Comprehensive experiments validate the in-context learning capability of LLMs for FSA.</li>
</ul>

<h3>Title: Memory Is All You Need: Testing How Model Memory Affects LLM Performance in Annotation Tasks</h3>
<ul>
<li><strong>Authors: </strong>Joan C. Timoneda, Sebasti√°n Vallejo Vera</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04874">https://arxiv.org/abs/2503.04874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04874">https://arxiv.org/pdf/2503.04874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04874]] Memory Is All You Need: Testing How Model Memory Affects LLM Performance in Annotation Tasks(https://arxiv.org/abs/2503.04874)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative Large Language Models (LLMs) have shown promising results in text annotation using zero-shot and few-shot learning. Yet these approaches do not allow the model to retain information from previous annotations, making each response independent from the preceding ones. This raises the question of whether model memory -- the LLM having knowledge about its own previous annotations in the same task -- affects performance. In this article, using OpenAI's GPT-4o and Meta's Llama 3.1 on two political science datasets, we demonstrate that allowing the model to retain information about its own previous classifications yields significant performance improvements: between 5 and 25\% when compared to zero-shot and few-shot learning. Moreover, memory reinforcement, a novel approach we propose that combines model memory and reinforcement learning, yields additional performance gains in three out of our four tests. These findings have important implications for applied researchers looking to improve performance and efficiency in LLM annotation tasks.</li>
</ul>

<h3>Title: Architecture for a Trustworthy Quantum Chatbot</h3>
<ul>
<li><strong>Authors: </strong>Yaiza Aragon√©s-Soria, Manuel Oriol</a></li>
<li><strong>Subjects: </strong>cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04875">https://arxiv.org/abs/2503.04875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04875">https://arxiv.org/pdf/2503.04875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04875]] Architecture for a Trustworthy Quantum Chatbot(https://arxiv.org/abs/2503.04875)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM)-based tools such as ChatGPT seem useful for classical programming assignments. The more specialized the field, the more likely they lack reliability because of the lack of data to train them. In the case of quantum computing, the quality of answers of generic chatbots is low. C4Q is a chatbot focused on quantum programs that addresses this challenge through a software architecture that integrates specialized LLMs to classify requests and specialized question answering modules with a deterministic logical engine to provide trustworthy quantum computing support. This article describes the latest version (2.0) of C4Q, which delivers several enhancements: ready-to-run Qiskit code for gate definitions and circuit operations, expanded features to solve software engineering tasks such as the travelling salesperson problem and the knapsack problem, and a feedback mechanism for iterative improvement. Extensive testing of the backend confirms the system's reliability, while empirical evaluations show that C4Q 2.0's classification LLM reaches near-perfect accuracy. The evaluation of the result consists in a comparative study with three existing chatbots highlighting C4Q 2.0's maintainability and correctness, reflecting on how software architecture decisions, such as separating deterministic logic from probabilistic text generation impact the quality of the results.</li>
</ul>

<h3>Title: Extracting Symbolic Sequences from Visual Representations via Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Victor Sebastian Martinez Pozos, Ivan Vladimir Meza Ruiz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04900">https://arxiv.org/abs/2503.04900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04900">https://arxiv.org/pdf/2503.04900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04900]] Extracting Symbolic Sequences from Visual Representations via Self-Supervised Learning(https://arxiv.org/abs/2503.04900)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>This paper explores the potential of abstracting complex visual information into discrete, structured symbolic sequences using self-supervised learning (SSL). Inspired by how language abstracts and organizes information to enable better reasoning and generalization, we propose a novel approach for generating symbolic representations from visual data. To learn these sequences, we extend the DINO framework to handle visual and symbolic information. Initial experiments suggest that the generated symbolic sequences capture a meaningful level of abstraction, though further refinement is required. An advantage of our method is its interpretability: the sequences are produced by a decoder transformer using cross-attention, allowing attention maps to be linked to specific symbols and offering insight into how these representations correspond to image regions. This approach lays the foundation for creating interpretable symbolic representations with potential applications in high-level scene understanding.</li>
</ul>

<h3>Title: Maximizing Signal in Human-Model Preference Alignment</h3>
<ul>
<li><strong>Authors: </strong>Kelsey Kraus, Margaret Kroll</a></li>
<li><strong>Subjects: </strong>cs.CL, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04910">https://arxiv.org/abs/2503.04910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04910">https://arxiv.org/pdf/2503.04910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04910]] Maximizing Signal in Human-Model Preference Alignment(https://arxiv.org/abs/2503.04910)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>The emergence of powerful LLMs has led to a paradigm shift in Natural Language Understanding and Natural Language Generation. The properties that make LLMs so valuable for these tasks -- creativity, ability to produce fluent speech, and ability to quickly and effectively abstract information from large corpora -- also present new challenges to evaluating their outputs. The rush to market has led teams to fall back on quick, cost-effective automatic evaluations which offer value, but do not obviate the need for human judgments in model training and evaluation. This paper argues that in cases in which end users need to agree with the decisions made by ML models -- e.g. in toxicity detection or extraction of main points for summarization -- models should be trained and evaluated on data that represent the preferences of those users. We support this argument by explicating the role of human feedback in labeling and judgment tasks for model training and evaluation. First, we propose methods for disentangling noise from signal in labeling tasks. Then we show that noise in labeling disagreement can be minimized by adhering to proven methodological best practices, while signal can be maximized to play an integral role in model training and evaluation tasks. Finally, we illustrate best practices by providing a case study in which two guardrails classifiers are evaluated using human judgments to align final model behavior to user preferences. We aim for this paper to provide researchers and professionals with guidelines to integrating human judgments into their ML and generative AI evaluation toolkit, particularly when working toward achieving accurate and unbiased features that align with users' needs and expectations.</li>
</ul>

<h3>Title: Fine-Tuning Florence2 for Enhanced Object Detection in Un-constructed Environments: Vision-Language Model Approach</h3>
<ul>
<li><strong>Authors: </strong>Soumyadeep Ro, Sanapala Satwika, Pamarthi Yasoda Gayathri, Mohmmad Ghaith Balsha, Aysegul Ucar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04918">https://arxiv.org/abs/2503.04918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04918">https://arxiv.org/pdf/2503.04918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04918]] Fine-Tuning Florence2 for Enhanced Object Detection in Un-constructed Environments: Vision-Language Model Approach(https://arxiv.org/abs/2503.04918)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Artificial intelligence has progressed through the development of Vision-Language Models (VLMs), which integrate text and visual inputs to achieve comprehensive understanding and interaction in various contexts. Enhancing the performance of these models such as the transformer based Florence 2 on specialized tasks like object detection in complex and unstructured environments requires fine-tuning. The goal of this paper is to improve the efficiency of the Florence 2 model in challenging environments by finetuning it. We accomplished this by experimenting with different configurations, using various GPU types (T4, L4, A100) and optimizers such as AdamW and SGD. We also employed a range of learning rates and LoRA (Low Rank Adaptation) settings. Analyzing the performance metrics, such as Mean Average Precision (mAP) scores,reveals that the finetuned Florence 2 models performed comparably to YOLO models, including YOLOv8, YOLOv9, and YOLOv10. This demonstrates how transformer based VLMs can be adapted for detailed object detection tasks. The paper emphasizes the capability of optimized transformer based VLMs to address specific challenges in object detection within unstructured environments, opening up promising avenues for practical applications in demanding and complex settings.</li>
</ul>

<h3>Title: FirePlace: Geometric Refinements of LLM Common Sense Reasoning for 3D Object Placement</h3>
<ul>
<li><strong>Authors: </strong>Ian Huang, Yanan Bao, Karen Truong, Howard Zhou, Cordelia Schmid, Leonidas Guibas, Alireza Fathi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04919">https://arxiv.org/abs/2503.04919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04919">https://arxiv.org/pdf/2503.04919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04919]] FirePlace: Geometric Refinements of LLM Common Sense Reasoning for 3D Object Placement(https://arxiv.org/abs/2503.04919)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Scene generation with 3D assets presents a complex challenge, requiring both high-level semantic understanding and low-level geometric reasoning. While Multimodal Large Language Models (MLLMs) excel at semantic tasks, their application to 3D scene generation is hindered by their limited grounding on 3D geometry. In this paper, we investigate how to best work with MLLMs in an object placement task. Towards this goal, we introduce a novel framework, FirePlace, that applies existing MLLMs in (1) 3D geometric reasoning and the extraction of relevant geometric details from the 3D scene, (2) constructing and solving geometric constraints on the extracted low-level geometry, and (3) pruning for final placements that conform to common sense. By combining geometric reasoning with real-world understanding of MLLMs, our method can propose object placements that satisfy both geometric constraints as well as high-level semantic common-sense considerations. Our experiments show that these capabilities allow our method to place objects more effectively in complex scenes with intricate geometry, surpassing the quality of prior work.</li>
</ul>

<h3>Title: Metadata-free Georegistration of Ground and Airborne Imagery</h3>
<ul>
<li><strong>Authors: </strong>Adam Bredvik, Scott Richardson, Daniel Crispell</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04927">https://arxiv.org/abs/2503.04927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04927">https://arxiv.org/pdf/2503.04927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04927]] Metadata-free Georegistration of Ground and Airborne Imagery(https://arxiv.org/abs/2503.04927)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, data-free</a></li>
<li><strong>Abstract: </strong>Heterogeneous collections of ground and airborne imagery can readily be used to create high-quality 3D models and novel viewpoint renderings of the observed scene. Standard photogrammetry pipelines generate models in arbitrary coordinate systems, which is problematic for applications that require georegistered models. Even for applications that do not require georegistered models, georegistration is useful as a mechanism for aligning multiple disconnected models generated from non-overlapping data. The proposed method leverages satellite imagery, an associated digital surface model (DSM), and the novel view generation capabilities of modern 3D modeling techniques (e.g. neural radiance fields) to provide a robust method for georegistering airborne imagery, and a related technique for registering ground-based imagery to models created from airborne imagery. Experiments demonstrate successful georegistration of airborne and ground-based photogrammetric models across a variety of distinct sites. The proposed method does not require use of any metadata other than a satellite-based reference product and therefore has general applicability.</li>
</ul>

<h3>Title: HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yao Ge, Yuting Guo, Sudeshna Das, Swati Rajwal, Selen Bozkurt, Abeed Sarker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04930">https://arxiv.org/abs/2503.04930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04930">https://arxiv.org/pdf/2503.04930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04930]] HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models(https://arxiv.org/abs/2503.04930)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We present HILGEN, a Hierarchically-Informed Data Generation approach that combines domain knowledge from the Unified Medical Language System (UMLS) with synthetic data generated by large language models (LLMs), specifically GPT-3.5. Our approach leverages UMLS's hierarchical structure to expand training data with related concepts, while incorporating contextual information from LLMs through targeted prompts aimed at automatically generating synthetic examples for sparsely occurring named entities. The performance of the HILGEN approach was evaluated across four biomedical NER datasets (MIMIC III, BC5CDR, NCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation with Nearest Neighbor Classifier) models, applying various data generation strategies, including UMLS, GPT-3.5, and their best ensemble. For the BERT-Large model, incorporating UMLS led to an average F1 score improvement of 40.36%, while using GPT-3.5 resulted in a comparable average increase of 40.52%. The Best-Ensemble approach using BERT-Large achieved the highest improvement, with an average increase of 42.29%. DANN model's F1 score improved by 22.74% on average using the UMLS-only approach. The GPT-3.5-based method resulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more notable improvement, with an average increase of 25.03%. Our proposed HILGEN approach improves NER performance in few-shot settings without requiring additional manually annotated data. Our experiments demonstrate that an effective strategy for optimizing biomedical NER is to combine biomedical knowledge curated in the past, such as the UMLS, and generative LLMs to create synthetic training instances. Our future research will focus on exploring additional innovative synthetic data generation strategies for further improving NER performance.</li>
</ul>

<h3>Title: Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems</h3>
<ul>
<li><strong>Authors: </strong>Jooyoung Lee, Xiaochen Zhu, Georgi Karadzhov, Tom Stafford, Andreas Vlachos, Dongwon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04945">https://arxiv.org/abs/2503.04945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04945">https://arxiv.org/pdf/2503.04945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04945]] Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems(https://arxiv.org/abs/2503.04945)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The proliferation of generative models has presented significant challenges in distinguishing authentic human-authored content from deepfake content. Collaborative human efforts, augmented by AI tools, present a promising solution. In this study, we explore the potential of DeepFakeDeLiBot, a deliberation-enhancing chatbot, to support groups in detecting deepfake text. Our findings reveal that group-based problem-solving significantly improves the accuracy of identifying machine-generated paragraphs compared to individual efforts. While engagement with DeepFakeDeLiBot does not yield substantial performance gains overall, it enhances group dynamics by fostering greater participant engagement, consensus building, and the frequency and diversity of reasoning-based utterances. Additionally, participants with higher perceived effectiveness of group collaboration exhibited performance benefits from DeepFakeDeLiBot. These findings underscore the potential of deliberative chatbots in fostering interactive and productive group dynamics while ensuring accuracy in collaborative deepfake text detection. \textit{Dataset and source code used in this study will be made publicly available upon acceptance of the manuscript.</li>
</ul>

<h3>Title: Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation</h3>
<ul>
<li><strong>Authors: </strong>Changchang Yin, Hong-You Chen, Wei-Lun Chao, Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04946">https://arxiv.org/abs/2503.04946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04946">https://arxiv.org/pdf/2503.04946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04946]] Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation(https://arxiv.org/abs/2503.04946)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Individual treatment effect (ITE) estimation is to evaluate the causal effects of treatment strategies on some important outcomes, which is a crucial problem in healthcare. Most existing ITE estimation methods are designed for centralized settings. However, in real-world clinical scenarios, the raw data are usually not shareable among hospitals due to the potential privacy and security risks, which makes the methods not applicable. In this work, we study the ITE estimation task in a federated setting, which allows us to harness the decentralized data from multiple hospitals. Due to the unavoidable confounding bias in the collected data, a model directly learned from it would be inaccurate. One well-known solution is Inverse Probability Treatment Weighting (IPTW), which uses the conditional probability of treatment given the covariates to re-weight each training example. Applying IPTW in a federated setting, however, is non-trivial. We found that even with a well-estimated conditional probability, the local model training step using each hospital's data alone would still suffer from confounding bias. To address this, we propose FED-IPTW, a novel algorithm to extend IPTW into a federated setting that enforces both global (over all the data) and local (within each hospital) decorrelation between covariates and treatments. We validated our approach on the task of comparing the treatment effects of mechanical ventilation on improving survival probability for patients with breadth difficulties in the intensive care unit (ICU). We conducted experiments on both synthetic and real-world eICU datasets and the results show that FED-IPTW outperform state-of-the-art methods on all the metrics on factual prediction and ITE estimation tasks, paving the way for personalized treatment strategy design in mechanical ventilation usage.</li>
</ul>

<h3>Title: Spectral Informed Mamba for Robust Point Cloud Processing</h3>
<ul>
<li><strong>Authors: </strong>Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, Sahar Dastani, Milad Cheraghalikhani, David Osowiechi, Gustavo Adolfo Vargas Hakim, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04953">https://arxiv.org/abs/2503.04953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04953">https://arxiv.org/pdf/2503.04953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04953]] Spectral Informed Mamba for Robust Point Cloud Processing(https://arxiv.org/abs/2503.04953)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>State space models have shown significant promise in Natural Language Processing (NLP) and, more recently, computer vision. This paper introduces a new methodology leveraging Mamba and Masked Autoencoder networks for point cloud data in both supervised and self-supervised learning. We propose three key contributions to enhance Mamba's capability in processing complex point cloud structures. First, we exploit the spectrum of a graph Laplacian to capture patch connectivity, defining an isometry-invariant traversal order that is robust to viewpoints and better captures shape manifolds than traditional 3D grid-based traversals. Second, we adapt segmentation via a recursive patch partitioning strategy informed by Laplacian spectral components, allowing finer integration and segment analysis. Third, we address token placement in Masked Autoencoder for Mamba by restoring tokens to their original positions, which preserves essential order and improves learning. Extensive experiments demonstrate the improvements of our approach in classification, segmentation, and few-shot tasks over state-of-the-art baselines.</li>
</ul>

<h3>Title: Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator</h3>
<ul>
<li><strong>Authors: </strong>R. Spencer Hallyburton, Miroslav Pajic</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04954">https://arxiv.org/abs/2503.04954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04954">https://arxiv.org/pdf/2503.04954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04954]] Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator(https://arxiv.org/abs/2503.04954)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Lacking security awareness, sensor fusion in systems with multi-agent networks such as smart cities is vulnerable to attacks. To guard against recent threats, we design security-aware sensor fusion that is based on the estimates of distributions over trust. Trust estimation can be cast as a hidden Markov model, and we solve it by mapping sensor data to trust pseudomeasurements (PSMs) that recursively update trust posteriors in a Bayesian context. Trust then feeds sensor fusion to facilitate trust-weighted updates to situational awareness. Essential to security-awareness are a novel field of view estimator, logic to map sensor data into PSMs, and the derivation of efficient Bayesian updates. We evaluate security-aware fusion under attacks on agents using case studies and Monte Carlo simulation in the physics-based Unreal Engine simulator, CARLA. A mix of novel and classical security-relevant metrics show that our security-aware fusion enables building trustworthy situational awareness even in hostile conditions.</li>
</ul>

<h3>Title: DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Ma, Yongliang Shen, Hengwei Liu, Wenqi Zhang, Haolei Xu, Qiuying Peng, Jun Wang, Weiming Lu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04959">https://arxiv.org/abs/2503.04959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04959">https://arxiv.org/pdf/2503.04959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04959]] DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL(https://arxiv.org/abs/2503.04959)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent text-to-SQL systems powered by large language models (LLMs) have demonstrated remarkable performance in translating natural language queries into SQL. However, these systems often struggle with complex database structures and domain-specific queries, as they primarily focus on enhancing logical reasoning and SQL syntax while overlooking the critical need for comprehensive database understanding. To address this limitation, we propose DB-Explore, a novel framework that systematically aligns LLMs with database knowledge through automated exploration and instruction synthesis. DB-Explore constructs database graphs to capture complex relational schemas, leverages GPT-4 to systematically mine structural patterns and semantic knowledge, and synthesizes instructions to distill this knowledge for efficient fine-tuning of LLMs. Our framework enables comprehensive database understanding through diverse sampling strategies and automated instruction generation, bridging the gap between database structures and language models. Experiments conducted on the SPIDER and BIRD benchmarks validate the effectiveness of DB-Explore, achieving an execution accuracy of 52.1% on BIRD and 84.0% on SPIDER. Notably, our open-source implementation, based on the Qwen2.5-coder-7B model, outperforms multiple GPT-4-driven text-to-SQL systems in comparative evaluations, and achieves near state-of-the-art performance with minimal computational cost.</li>
</ul>

<h3>Title: Energy-Latency Attacks: A New Adversarial Threat to Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Deforges</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04963">https://arxiv.org/abs/2503.04963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04963">https://arxiv.org/pdf/2503.04963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04963]] Energy-Latency Attacks: A New Adversarial Threat to Deep Learning(https://arxiv.org/abs/2503.04963)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>The growing computational demand for deep neural networks ( DNNs) has raised concerns about their energy consumption and carbon footprint, particularly as the size and complexity of the models continue to increase. To address these challenges, energy-efficient hardware and custom accelerators have become essential. Additionally, adaptable DNN s are being developed to dynamically balance performance and efficiency. The use of these strategies became more common to enable sustainable AI deployment. However, these efficiency-focused designs may also introduce vulnerabilities, as attackers can potentially exploit them to increase latency and energy usage by triggering their worst-case-performance scenarios. This new type of attack, called energy-latency attacks, has recently gained significant research attention, focusing on the vulnerability of DNN s to this emerging attack paradigm, which can trigger denial-of-service ( DoS) attacks. This paper provides a comprehensive overview of current research on energy-latency attacks, categorizing them using the established taxonomy for traditional adversarial attacks. We explore different metrics used to measure the success of these attacks and provide an analysis and comparison of existing attack strategies. We also analyze existing defense mechanisms and highlight current challenges and potential areas for future research in this developing field. The GitHub page for this work can be accessed at this https URL</li>
</ul>

<h3>Title: Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge</h3>
<ul>
<li><strong>Authors: </strong>Songyuan Li, Jia Hu, Geyong Min, Haojun Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04971">https://arxiv.org/abs/2503.04971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04971">https://arxiv.org/pdf/2503.04971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04971]] Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge(https://arxiv.org/abs/2503.04971)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, generative</a></li>
<li><strong>Abstract: </strong>Foundation models (FMs) such as GPT-4 exhibit exceptional generative capabilities across diverse downstream tasks through fine-tuning. Split Federated Learning (SFL) facilitates privacy-preserving FM fine-tuning on resource-constrained local devices by offloading partial FM computations to edge servers, enabling device-edge synergistic fine-tuning. Practical edge networks often host multiple SFL tenants to support diversified downstream tasks. However, existing research primarily focuses on single-tenant SFL scenarios, and lacks tailored incentive mechanisms for multi-tenant settings, which are essential to effectively coordinate self-interested local devices for participation in various downstream tasks, ensuring that each SFL tenant's distinct FM fine-tuning requirements (e.g., FM types, performance targets, and fine-tuning deadlines) are met. To address this gap, we propose a novel Price-Incentive Mechanism (PRINCE) that guides multiple SFL tenants to offer strategic price incentives, which solicit high-quality device participation for efficient FM fine-tuning. Specifically, we first develop a bias-resilient global SFL model aggregation scheme to eliminate model biases caused by independent device participation. We then derive a rigorous SFL convergence bound to evaluate the contributions of heterogeneous devices to FM performance improvements, guiding the incentive strategies of SFL tenants. Furthermore, we model inter-tenant device competition as a congestion game for Stackelberg equilibrium (SE) analysis, deriving each SFL tenant's optimal incentive strategy. Extensive simulations involving four representative SFL tenant types (ViT, BERT, Whisper, and LLaMA) across diverse data modalities (text, images, and audio) demonstrate that PRINCE accelerates FM fine-tuning by up to 3.07x compared to state-of-the-art approaches, while consistently meeting fine-tuning performance targets.</li>
</ul>

<h3>Title: Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Giulio Corallo, Orion Weller, Fabio Petroni, Paolo Papotti</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04973">https://arxiv.org/abs/2503.04973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04973">https://arxiv.org/pdf/2503.04973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04973]] Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning(https://arxiv.org/abs/2503.04973)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Incorporating external knowledge in large language models (LLMs) enhances their utility across diverse applications, but existing methods have trade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via similarity search, but key information may fall outside top ranked results. Long-context models can process multiple documents but are computationally expensive and limited by context window size. Inspired by students condensing study material for open-book exams, we propose task-aware key-value (KV) cache compression, which compresses external knowledge in a zero- or few-shot setup. This enables LLMs to reason efficiently over a compacted representation of all relevant information. Experiments show our approach outperforms both RAG and task-agnostic compression methods. On LongBench v2, it improves accuracy by up to 7 absolute points over RAG with a 30x compression rate, while reducing inference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG performs well when sparse evidence suffices, whereas task-aware compression is superior for broad knowledge tasks.</li>
</ul>

<h3>Title: Energy-Weighted Flow Matching for Offline Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Shiyuan Zhang, Weitong Zhang, Quanquan Gu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04975">https://arxiv.org/abs/2503.04975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04975">https://arxiv.org/pdf/2503.04975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04975]] Energy-Weighted Flow Matching for Offline Reinforcement Learning(https://arxiv.org/abs/2503.04975)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper investigates energy guidance in generative modeling, where the target distribution is defined as $q(\mathbf x) \propto p(\mathbf x)\exp(-\beta \mathcal E(\mathbf x))$, with $p(\mathbf x)$ being the data distribution and $\mathcal E(\mathcal x)$ as the energy function. To comply with energy guidance, existing methods often require auxiliary procedures to learn intermediate guidance during the diffusion process. To overcome this limitation, we explore energy-guided flow matching, a generalized form of the diffusion process. We introduce energy-weighted flow matching (EFM), a method that directly learns the energy-guided flow without the need for auxiliary models. Theoretical analysis shows that energy-weighted flow matching accurately captures the guided flow. Additionally, we extend this methodology to energy-weighted diffusion models and apply it to offline reinforcement learning (RL) by proposing the Q-weighted Iterative Policy Optimization (QIPO). Empirically, we demonstrate that the proposed QIPO algorithm improves performance in offline RL tasks. Notably, our algorithm is the first energy-guided diffusion model that operates independently of auxiliary models and the first exact energy-guided flow matching model in the literature.</li>
</ul>

<h3>Title: A Consensus Privacy Metrics Framework for Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Lisa Pilgram, Fida K. Dankar, Jorg Drechsler, Mark Elliot, Josep Domingo-Ferrer, Paul Francis, Murat Kantarcioglu, Linglong Kong, Bradley Malin, Krishnamurty Muralidhar, Puja Myles, Fabian Prasser, Jean Louis Raisaro, Chao Yan, Khaled El Emam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04980">https://arxiv.org/abs/2503.04980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04980">https://arxiv.org/pdf/2503.04980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04980]] A Consensus Privacy Metrics Framework for Synthetic Data(https://arxiv.org/abs/2503.04980)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Synthetic data generation is one approach for sharing individual-level data. However, to meet legislative requirements, it is necessary to demonstrate that the individuals' privacy is adequately protected. There is no consolidated standard for measuring privacy in synthetic data. Through an expert panel and consensus process, we developed a framework for evaluating privacy in synthetic data. Our findings indicate that current similarity metrics fail to measure identity disclosure, and their use is discouraged. For differentially private synthetic data, a privacy budget other than close to zero was not considered interpretable. There was consensus on the importance of membership and attribute disclosure, both of which involve inferring personal information about an individual without necessarily revealing their identity. The resultant framework provides precise recommendations for metrics that address these types of disclosures effectively. Our findings further present specific opportunities for future research that can help with widespread adoption of synthetic data.</li>
</ul>

<h3>Title: LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression</h3>
<ul>
<li><strong>Authors: </strong>Souvik Kundu, Anahita Bhiwandiwalla, Sungduk Yu, Phillip Howard, Tiep Le, Sharath Nittur Sridhar, David Cobbley, Hao Kang, Vasudev Lal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04982">https://arxiv.org/abs/2503.04982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04982">https://arxiv.org/pdf/2503.04982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04982]] LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression(https://arxiv.org/abs/2503.04982)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Despite recent efforts in understanding the compression impact on large language models (LLMs) in terms of their downstream task performance and trustworthiness on relatively simpler uni-modal benchmarks (for example, question answering, common sense reasoning), their detailed study on multi-modal Large Vision-Language Models (LVLMs) is yet to be unveiled. Towards mitigating this gap, we present LVLM-Compress-Bench, a framework to first thoroughly study the broad impact of compression on the generative performance of LVLMs with multi-modal input driven tasks. In specific, we consider two major classes of compression for autoregressive models, namely KV cache and weight compression, for the dynamically growing intermediate cache and static weights, respectively. We use four LVLM variants of the popular LLaVA framework to present our analysis via integrating various state-of-the-art KV and weight compression methods including uniform, outlier-reduced, and group quantization for the KV cache and weights. With this framework we demonstrate on ten different multi-modal datasets with different capabilities including recognition, knowledge, language generation, spatial awareness, visual reasoning, hallucination and visual illusion identification, toxicity, stereotypes and bias. In specific, our framework demonstrates the compression impact on both general and ethically critical metrics leveraging a combination of real world and synthetic datasets to encompass diverse societal intersectional attributes. Extensive experimental evaluations yield diverse and intriguing observations on the behavior of LVLMs at different quantization budget of KV and weights, in both maintaining and losing performance as compared to the baseline model with FP16 data format. Code will be open-sourced at this https URL.</li>
</ul>

<h3>Title: Leveraging Large Language Models For Scalable Vector Graphics Processing: A Review</h3>
<ul>
<li><strong>Authors: </strong>Boris Malashenko, Ivan Jarsky, Valeria Efimova</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04983">https://arxiv.org/abs/2503.04983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04983">https://arxiv.org/pdf/2503.04983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04983]] Leveraging Large Language Models For Scalable Vector Graphics Processing: A Review(https://arxiv.org/abs/2503.04983)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, rapid advances in computer vision have significantly improved the processing and generation of raster images. However, vector graphics, which is essential in digital design, due to its scalability and ease of editing, have been relatively understudied. Traditional vectorization techniques, which are often used in vector generation, suffer from long processing times and excessive output complexity, limiting their usability in practical applications. The advent of large language models (LLMs) has opened new possibilities for the generation, editing, and analysis of vector graphics, particularly in the SVG format, which is inherently text-based and well-suited for integration with LLMs. This paper provides a systematic review of existing LLM-based approaches for SVG processing, categorizing them into three main tasks: generation, editing, and understanding. We observe notable models such as IconShop, StrokeNUWA, and StarVector, highlighting their strengths and limitations. Furthermore, we analyze benchmark datasets designed for assessing SVG-related tasks, including SVGEditBench, VGBench, and SGP-Bench, and conduct a series of experiments to evaluate various LLMs in these domains. Our results demonstrate that for vector graphics reasoning-enhanced models outperform standard LLMs, particularly in generation and understanding tasks. Furthermore, our findings underscore the need to develop more diverse and richly annotated datasets to further improve LLM capabilities in vector graphics tasks.</li>
</ul>

<h3>Title: Application of integrated gradients explainability to sociopsychological semantic markers</h3>
<ul>
<li><strong>Authors: </strong>Ali Aghababaei, Jan Nikadon, Magdalena Formanowicz, Maria Laura Bettinsoli, Carmen Cervone, Caterina Suitner, Tomaso Erseghe</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04989">https://arxiv.org/abs/2503.04989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04989">https://arxiv.org/pdf/2503.04989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04989]] Application of integrated gradients explainability to sociopsychological semantic markers(https://arxiv.org/abs/2503.04989)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Classification of textual data in terms of sentiment, or more nuanced sociopsychological markers (e.g., agency), is now a popular approach commonly applied at the sentence level. In this paper, we exploit the integrated gradient (IG) method to capture the classification output at the word level, revealing which words actually contribute to the classification process. This approach improves explainability and provides in-depth insights into the text. We focus on sociopsychological markers beyond sentiment and investigate how to effectively train IG in agency, one of the very few markers for which a verified deep learning classifier, BERTAgent, is currently available. Performance and system parameters are carefully tested, alternatives to the IG approach are evaluated, and the usefulness of the result is verified in a relevant application scenario. The method is also applied in a scenario where only a small labeled dataset is available, with the aim of exploiting IG to identify the salient words that contribute to building the different classes that relate to relevant sociopsychological markers. To achieve this, an uncommon training procedure that encourages overfitting is employed to enhance the distinctiveness of each class. The results are analyzed through the lens of social psychology, offering valuable insights.</li>
</ul>

<h3>Title: DP-GTR: Differentially Private Prompt Protection via Group Text Rewriting</h3>
<ul>
<li><strong>Authors: </strong>Mingchen Li, Heng Fan, Song Fu, Junhua Ding, Yunhe Feng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04990">https://arxiv.org/abs/2503.04990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04990">https://arxiv.org/pdf/2503.04990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04990]] DP-GTR: Differentially Private Prompt Protection via Group Text Rewriting(https://arxiv.org/abs/2503.04990)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Prompt privacy is crucial, especially when using online large language models (LLMs), due to the sensitive information often contained within prompts. While LLMs can enhance prompt privacy through text rewriting, existing methods primarily focus on document-level rewriting, neglecting the rich, multi-granular representations of text. This limitation restricts LLM utilization to specific tasks, overlooking their generalization and in-context learning capabilities, thus hindering practical application. To address this gap, we introduce DP-GTR, a novel three-stage framework that leverages local differential privacy (DP) and the composition theorem via group text rewriting. DP-GTR is the first framework to integrate both document-level and word-level information while exploiting in-context learning to simultaneously improve privacy and utility, effectively bridging local and global DP mechanisms at the individual data point level. Experiments on CommonSense QA and DocVQA demonstrate that DP-GTR outperforms existing approaches, achieving a superior privacy-utility trade-off. Furthermore, our framework is compatible with existing rewriting techniques, serving as a plug-in to enhance privacy protection. Our code is publicly available at this https URL for reproducibility.</li>
</ul>

<h3>Title: Wanda++: Pruning Large Language Models via Regional Gradients</h3>
<ul>
<li><strong>Authors: </strong>Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus M√ºller, Jonas M. K√ºbler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.04992">https://arxiv.org/abs/2503.04992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.04992">https://arxiv.org/pdf/2503.04992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.04992]] Wanda++: Pruning Large Language Models via Regional Gradients(https://arxiv.org/abs/2503.04992)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) pruning seeks to remove unimportant weights for inference speedup with minimal performance impact. However, existing methods often suffer from performance loss without full-model sparsity-aware fine-tuning. This paper presents Wanda++, a novel pruning framework that outperforms the state-of-the-art methods by utilizing decoder-block-level \textbf{regional} gradients. Specifically, Wanda++ improves the pruning score with regional gradients for the first time and proposes an efficient regional optimization method to minimize pruning-induced output discrepancies between the dense and sparse decoder output. Notably, Wanda++ improves perplexity by up to 32\% over Wanda in the language modeling task and generalizes effectively to downstream tasks. Further experiments indicate our proposed method is orthogonal to sparsity-aware fine-tuning, where Wanda++ can be combined with LoRA fine-tuning to achieve a similar perplexity improvement as the Wanda method. The proposed method is lightweight, pruning a 7B LLaMA model in under 10 minutes on a single NVIDIA H100 GPU.</li>
</ul>

<h3>Title: Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models</h3>
<ul>
<li><strong>Authors: </strong>Benyamin Jamialahmadi, Parsa Kavehzadeh, Mehdi Rezagholizadeh, Parsa Farinneya, Hossein Rajabzadeh, Aref Jafari, Boxing Chen, Marzieh Tahaei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05005">https://arxiv.org/abs/2503.05005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05005">https://arxiv.org/pdf/2503.05005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05005]] Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models(https://arxiv.org/abs/2503.05005)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Deploying large language models (LLMs) in real-world applications is often hindered by strict computational and latency constraints. While dynamic inference offers the flexibility to adjust model behavior based on varying resource budgets, existing methods are frequently limited by hardware inefficiencies or performance degradation. In this paper, we introduce Balcony, a simple yet highly effective framework for depth-based dynamic inference. By freezing the pretrained LLM and inserting additional transformer layers at selected exit points, Balcony maintains the full model's performance while enabling real-time adaptation to different computational budgets. These additional layers are trained using a straightforward self-distillation loss, aligning the sub-model outputs with those of the full model. This approach requires significantly fewer training tokens and tunable parameters, drastically reducing computational costs compared to prior methods. When applied to the LLaMA3-8B model, using only 0.2% of the original pretraining data, Balcony achieves minimal performance degradation while enabling significant speedups. Remarkably, we show that Balcony outperforms state-of-the-art methods such as Flextron and Layerskip as well as other leading compression techniques on multiple models and at various scales, across a variety of benchmarks.</li>
</ul>

<h3>Title: Leveraging Domain Knowledge at Inference Time for LLM Translation: Retrieval versus Generation</h3>
<ul>
<li><strong>Authors: </strong>Bryan Li, Jiaming Luo, Eleftheria Briakou, Colin Cherry</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05010">https://arxiv.org/abs/2503.05010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05010">https://arxiv.org/pdf/2503.05010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05010]] Leveraging Domain Knowledge at Inference Time for LLM Translation: Retrieval versus Generation(https://arxiv.org/abs/2503.05010)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) have been increasingly adopted for machine translation (MT), their performance for specialist domains such as medicine and law remains an open challenge. Prior work has shown that LLMs can be domain-adapted at test-time by retrieving targeted few-shot demonstrations or terminologies for inclusion in the prompt. Meanwhile, for general-purpose LLM MT, recent studies have found some success in generating similarly useful domain knowledge from an LLM itself, prior to translation. Our work studies domain-adapted MT with LLMs through a careful prompting setup, finding that demonstrations consistently outperform terminology, and retrieval consistently outperforms generation. We find that generating demonstrations with weaker models can close the gap with larger model's zero-shot performance. Given the effectiveness of demonstrations, we perform detailed analyses to understand their value. We find that domain-specificity is particularly important, and that the popular multi-domain benchmark is testing adaptation to a particular writing style more so than to a specific domain.</li>
</ul>

<h3>Title: Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety</h3>
<ul>
<li><strong>Authors: </strong>Yuyou Zhang, Miao Li, William Han, Yihang Yao, Zhepeng Cen, Ding Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05021">https://arxiv.org/abs/2503.05021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05021">https://arxiv.org/pdf/2503.05021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05021]] Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety(https://arxiv.org/abs/2503.05021)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are vulnerable to jailbreak attacks that exploit weaknesses in traditional safety alignment, which often relies on rigid refusal heuristics or representation engineering to block harmful outputs. While they are effective for direct adversarial attacks, they fall short of broader safety challenges requiring nuanced, context-aware decision-making. To address this, we propose Reasoning-enhanced Finetuning for interpretable LLM Safety (Rational), a novel framework that trains models to engage in explicit safe reasoning before response. Fine-tuned models leverage the extensive pretraining knowledge in self-generated reasoning to bootstrap their own safety through structured reasoning, internalizing context-sensitive decision-making. Our findings suggest that safety extends beyond refusal, requiring context awareness for more robust, interpretable, and adaptive responses. Reasoning is not only a core capability of LLMs but also a fundamental mechanism for LLM safety. Rational employs reasoning-enhanced fine-tuning, allowing it to reject harmful prompts while providing meaningful and context-aware responses in complex scenarios.</li>
</ul>

<h3>Title: Continual Pre-training of MoEs: How robust is your router?</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Th√©rien, Charles-√âtienne Joseph, Zain Sarwar, Ashwinee Panda, Anirban Das, Shi-Xiong Zhang, Stephen Rawls, Sambit Sahu, Eugene Belilovsky, Irina Rish</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05029">https://arxiv.org/abs/2503.05029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05029">https://arxiv.org/pdf/2503.05029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05029]] Continual Pre-training of MoEs: How robust is your router?(https://arxiv.org/abs/2503.05029)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Sparsely-activated Mixture of Experts (MoE) transformers are promising architectures for foundation models. Compared to dense transformers that require the same amount of floating point operations (FLOPs) per forward pass, MoEs benefit from improved sample efficiency at training time and achieve much stronger performance. Many closed-source and open-source frontier language models have thus adopted an MoE architecture. Naturally, practitioners will want to extend the capabilities of these models with large amounts of newly collected data without completely re-training them. Prior work has shown that a simple combination of replay and learning rate re-warming and re-decaying can enable the continual pre-training (CPT) of dense decoder-only transformers with minimal performance degradation compared to full re-training. In the case of decoder-only MoE transformers, however, it is unclear how the routing algorithm will impact continual pre-training performance: 1) do the MoE transformer's routers exacerbate forgetting relative to a dense model?; 2) do the routers maintain a balanced load on previous distributions after CPT?; 3) are the same strategies applied to dense models sufficient to continually pre-train MoE LLMs? In what follows, we conduct a large-scale (>2B parameter switch and DeepSeek MoE LLMs trained for 600B tokens) empirical study across four MoE transformers to answer these questions. Our results establish a surprising robustness to distribution shifts for both Sinkhorn-Balanced and Z-and-Aux-loss-balanced routing algorithms, even in MoEs continually pre-trained without replay. Moreover, we show that MoE LLMs maintain their sample efficiency (relative to a FLOP-matched dense model) during CPT and that they can match the performance of a fully re-trained MoE at a fraction of the cost.</li>
</ul>

<h3>Title: Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence</h3>
<ul>
<li><strong>Authors: </strong>Mohsen Fayyaz, Ali Modarressi, Hinrich Schuetze, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05037">https://arxiv.org/abs/2503.05037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05037">https://arxiv.org/pdf/2503.05037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05037]] Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence(https://arxiv.org/abs/2503.05037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Dense retrieval models are commonly used in Information Retrieval (IR) applications, such as Retrieval-Augmented Generation (RAG). Since they often serve as the first step in these systems, their robustness is critical to avoid failures. In this work, by repurposing a relation extraction dataset (e.g. Re-DocRED), we design controlled experiments to quantify the impact of heuristic biases, such as favoring shorter documents, in retrievers like Dragon+ and Contriever. Our findings reveal significant vulnerabilities: retrievers often rely on superficial patterns like over-prioritizing document beginnings, shorter documents, repeated entities, and literal matches. Additionally, they tend to overlook whether the document contains the query's answer, lacking deep semantic understanding. Notably, when multiple biases combine, models exhibit catastrophic performance degradation, selecting the answer-containing document in less than 3% of cases over a biased document without the answer. Furthermore, we show that these biases have direct consequences for downstream applications like RAG, where retrieval-preferred documents can mislead LLMs, resulting in a 34% performance drop than not providing any documents at all.</li>
</ul>

<h3>Title: Biases in Large Language Model-Elicited Text: A Case Study in Natural Language Inference</h3>
<ul>
<li><strong>Authors: </strong>Grace Proebsting, Adam Poliak</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05047">https://arxiv.org/abs/2503.05047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05047">https://arxiv.org/pdf/2503.05047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05047]] Biases in Large Language Model-Elicited Text: A Case Study in Natural Language Inference(https://arxiv.org/abs/2503.05047)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We test whether NLP datasets created with Large Language Models (LLMs) contain annotation artifacts and social biases like NLP datasets elicited from crowd-source workers. We recreate a portion of the Stanford Natural Language Inference corpus using GPT-4, Llama-2 70b for Chat, and Mistral 7b Instruct. We train hypothesis-only classifiers to determine whether LLM-elicited NLI datasets contain annotation artifacts. Next, we use pointwise mutual information to identify the words in each dataset that are associated with gender, race, and age-related terms. On our LLM-generated NLI datasets, fine-tuned BERT hypothesis-only classifiers achieve between 86-96% accuracy. Our analyses further characterize the annotation artifacts and stereotypical biases in LLM-generated datasets.</li>
</ul>

<h3>Title: Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question Answering Datasets</h3>
<ul>
<li><strong>Authors: </strong>Preetam Prabhu Srikar Dammu, Himanshu Naidu, Chirag Shah</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05049">https://arxiv.org/abs/2503.05049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05049">https://arxiv.org/pdf/2503.05049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05049]] Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question Answering Datasets(https://arxiv.org/abs/2503.05049)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>As question answering (QA) systems advance alongside the rapid evolution of foundation models, the need for robust, adaptable, and large-scale evaluation benchmarks becomes increasingly critical. Traditional QA benchmarks are often static and publicly available, making them susceptible to data contamination and memorization by large language models (LLMs). Consequently, static benchmarks may overestimate model generalization and hinder a reliable assessment of real-world performance. In this work, we introduce Dynamic-KGQA, a scalable framework for generating adaptive QA datasets from knowledge graphs (KGs), designed to mitigate memorization risks while maintaining statistical consistency across iterations. Unlike fixed benchmarks, Dynamic-KGQA generates a new dataset variant on every run while preserving the underlying distribution, enabling fair and reproducible evaluations. Furthermore, our framework provides fine-grained control over dataset characteristics, supporting domain-specific and topic-focused QA dataset generation. Additionally, Dynamic-KGQA produces compact, semantically coherent subgraphs that facilitate both training and evaluation of KGQA models, enhancing their ability to leverage structured knowledge effectively. To align with existing evaluation protocols, we also provide static large-scale train/test/validation splits, ensuring comparability with prior methods. By introducing a dynamic, customizable benchmarking paradigm, Dynamic-KGQA enables a more rigorous and adaptable evaluation of QA systems.</li>
</ul>

<h3>Title: A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Melkamu Abay Mersha, Mesay Gemeda Yigezu, Hassan shakil, Ali Al shami, Sanghyun Byun, Jugal Kalita</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05050">https://arxiv.org/abs/2503.05050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05050">https://arxiv.org/pdf/2503.05050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05050]] A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs(https://arxiv.org/abs/2503.05050)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>The increasing complexity of LLMs presents significant challenges to their transparency and interpretability, necessitating the use of eXplainable AI (XAI) techniques to enhance trustworthiness and usability. This study introduces a comprehensive evaluation framework with four novel metrics for assessing the effectiveness of five XAI techniques across five LLMs and two downstream tasks. We apply this framework to evaluate several XAI techniques LIME, SHAP, Integrated Gradients, Layer-wise Relevance Propagation (LRP), and Attention Mechanism Visualization (AMV) using the IMDB Movie Reviews and Tweet Sentiment Extraction datasets. The evaluation focuses on four key metrics: Human-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. Our results show that LIME consistently achieves high scores across multiple LLMs and evaluation metrics, while AMV demonstrates superior Robustness and near-perfect Consistency. LRP excels in Contrastivity, particularly with more complex models. Our findings provide valuable insights into the strengths and limitations of different XAI methods, offering guidance for developing and selecting appropriate XAI techniques for LLMs.</li>
</ul>

<h3>Title: ModernBERT is More Efficient than Conventional BERT for Chest CT Findings Classification in Japanese Radiology Reports</h3>
<ul>
<li><strong>Authors: </strong>Yosuke Yamagishi, Tomohiro Kikuchi, Shouhei Hanaoka, Takeharu Yoshikawa, Osamu Abe</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05060">https://arxiv.org/abs/2503.05060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05060">https://arxiv.org/pdf/2503.05060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05060]] ModernBERT is More Efficient than Conventional BERT for Chest CT Findings Classification in Japanese Radiology Reports(https://arxiv.org/abs/2503.05060)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Objective: This study aims to evaluate and compare the performance of two Japanese language models-conventional Bidirectional Encoder Representations from Transformers (BERT) and the newer ModernBERT-in classifying findings from chest CT reports, with a focus on tokenization efficiency, processing time, and classification performance. Methods: We conducted a retrospective study using the CT-RATE-JPN dataset containing 22,778 training reports and 150 test reports. Both models were fine-tuned for multi-label classification of 18 common chest CT conditions. The training data was split in 18,222:4,556 for training and validation. Performance was evaluated using F1 scores for each condition and exact match accuracy across all 18 labels. Results: ModernBERT demonstrated superior tokenization efficiency, requiring 24.0% fewer tokens per document (258.1 vs. 339.6) compared to BERT Base. This translated to significant performance improvements, with ModernBERT completing training in 1877.67 seconds versus BERT's 3090.54 seconds (39% reduction). ModernBERT processed 38.82 samples per second during training (1.65x faster) and 139.90 samples per second during inference (1.66x faster). Despite these efficiency gains, classification performance remained comparable, with ModernBERT achieving superior F1 scores in 8 conditions, while BERT performed better in 4 conditions. Overall exact match accuracy was slightly higher for ModernBERT (74.67% vs. 72.67%), though this difference was not statistically significant (p=0.6291). Conclusion: ModernBERT offers substantial improvements in tokenization efficiency and training speed without sacrificing classification performance. These results suggest that ModernBERT is a promising candidate for clinical applications in Japanese radiology reports analysis.</li>
</ul>

<h3>Title: No Free Labels: Limitations of LLM-as-a-Judge Without Human Grounding</h3>
<ul>
<li><strong>Authors: </strong>Michael Krumdick, Charles Lovering, Varshini Reddy, Seth Ebner, Chris Tanner</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05061">https://arxiv.org/abs/2503.05061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05061">https://arxiv.org/pdf/2503.05061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05061]] No Free Labels: Limitations of LLM-as-a-Judge Without Human Grounding(https://arxiv.org/abs/2503.05061)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLM-as-a-Judge is a framework that uses an LLM (large language model) to evaluate the quality of natural language text - typically text that is also generated by an LLM. This framework holds great promise due to its relative low-cost, ease of use, and strong correlations with human stylistic preferences. However, LLM Judges have been shown to exhibit biases that can distort their judgments. We evaluate how well LLM Judges can grade whether a given response to a conversational question is correct, an ability crucial to soundly estimating the overall response quality. To do so, we create and publicly release a human-annotated dataset with labels of correctness for 1,200 LLM responses. We source questions from a combination of existing datasets and a novel, challenging benchmark (BFF-Bench) created for this analysis. We demonstrate a strong connection between an LLM's ability to correctly answer a question and grade responses to that question. Although aggregate level statistics might imply a judge has high agreement with human annotators, it will struggle on the subset of questions it could not answer. To address this issue, we recommend a simple solution: provide the judge with a correct, human-written reference answer. We perform an in-depth analysis on how reference quality can affect the performance of an LLM Judge. We show that providing a weaker judge (e.g. Qwen 2.5 7B) with higher quality references reaches better agreement with human annotators than a stronger judge (e.g. GPT-4o) with synthetic references.</li>
</ul>

<h3>Title: The study of short texts in digital politics: Document aggregation for topic modeling</h3>
<ul>
<li><strong>Authors: </strong>Nitheesha Nakka, Omer F. Yalcin, Bruce A. Desmarais, Sarah Rajtmajer, Burt Monroe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05065">https://arxiv.org/abs/2503.05065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05065">https://arxiv.org/pdf/2503.05065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05065]] The study of short texts in digital politics: Document aggregation for topic modeling(https://arxiv.org/abs/2503.05065)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Statistical topic modeling is widely used in political science to study text. Researchers examine documents of varying lengths, from tweets to speeches. There is ongoing debate on how document length affects the interpretability of topic models. We investigate the effects of aggregating short documents into larger ones based on natural units that partition the corpus. In our study, we analyze one million tweets by U.S. state legislators from April 2016 to September 2020. We find that for documents aggregated at the account level, topics are more associated with individual states than when using individual tweets. This finding is replicated with Wikipedia pages aggregated by birth cities, showing how document definitions can impact topic modeling results.</li>
</ul>

<h3>Title: Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts</h3>
<ul>
<li><strong>Authors: </strong>Shwai He, Weilin Cai, Jiayi Huang, Ang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05066">https://arxiv.org/abs/2503.05066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05066">https://arxiv.org/pdf/2503.05066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05066]] Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts(https://arxiv.org/abs/2503.05066)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Mixture of Experts (MoE) is an effective architecture for scaling large language models by leveraging sparse expert activation, optimizing the trade-off between performance and efficiency. However, under expert parallelism, MoE suffers from inference inefficiencies due to imbalanced token-to-expert assignment, where some experts are overloaded while others remain underutilized. This imbalance leads to poor resource utilization and increased latency, as the most burdened expert dictates the overall delay, a phenomenon we define as the \textbf{\textit{Straggler Effect}}. To mitigate this, we propose Capacity-Aware Inference, including two key techniques: (1) \textbf{\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens to regulate the maximum latency of MoE, and (2) \textbf{\textit{Capacity-Aware Token Reroute}}, which reallocates overflowed tokens to underutilized experts, balancing the token distribution. These techniques collectively optimize both high-load and low-load expert utilization, leading to a more efficient MoE inference pipeline. Extensive experiments demonstrate the effectiveness of our methods, showing significant improvements in inference efficiency, e.g., 0.2\% average performance increase and a 1.94$\times$ inference speedup on Mixtral-8$\times$7B-Instruct.</li>
</ul>

<h3>Title: On a Connection Between Imitation Learning and RLHF</h3>
<ul>
<li><strong>Authors: </strong>Teng Xiao, Yige Yuan, Mingxiao Li, Zhengyu Chen, Vasant G Honavar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05079">https://arxiv.org/abs/2503.05079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05079">https://arxiv.org/pdf/2503.05079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05079]] On a Connection Between Imitation Learning and RLHF(https://arxiv.org/abs/2503.05079)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work studies the alignment of large language models with preference data from an imitation learning perspective. We establish a close theoretical connection between reinforcement learning from human feedback RLHF and imitation learning (IL), revealing that RLHF implicitly performs imitation learning on the preference data distribution. Building on this connection, we propose DIL, a principled framework that directly optimizes the imitation learning objective. DIL provides a unified imitation learning perspective on alignment, encompassing existing alignment algorithms as special cases while naturally introducing new variants. By bridging IL and RLHF, DIL offers new insights into alignment with RLHF. Extensive experiments demonstrate that DIL outperforms existing methods on various challenging benchmarks.</li>
</ul>

<h3>Title: Taming Video Diffusion Prior with Scene-Grounding Guidance for 3D Gaussian Splatting from Sparse Inputs</h3>
<ul>
<li><strong>Authors: </strong>Yingji Zhong, Zhihao Li, Dave Zhenyu Chen, Lanqing Hong, Dan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05082">https://arxiv.org/abs/2503.05082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05082">https://arxiv.org/pdf/2503.05082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05082]] Taming Video Diffusion Prior with Scene-Grounding Guidance for 3D Gaussian Splatting from Sparse Inputs(https://arxiv.org/abs/2503.05082)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite recent successes in novel view synthesis using 3D Gaussian Splatting (3DGS), modeling scenes with sparse inputs remains a challenge. In this work, we address two critical yet overlooked issues in real-world sparse-input modeling: extrapolation and occlusion. To tackle these issues, we propose to use a reconstruction by generation pipeline that leverages learned priors from video diffusion models to provide plausible interpretations for regions outside the field of view or occluded. However, the generated sequences exhibit inconsistencies that do not fully benefit subsequent 3DGS modeling. To address the challenge of inconsistencies, we introduce a novel scene-grounding guidance based on rendered sequences from an optimized 3DGS, which tames the diffusion model to generate consistent sequences. This guidance is training-free and does not require any fine-tuning of the diffusion model. To facilitate holistic scene modeling, we also propose a trajectory initialization method. It effectively identifies regions that are outside the field of view and occluded. We further design a scheme tailored for 3DGS optimization with generated sequences. Experiments demonstrate that our method significantly improves upon the baseline and achieves state-of-the-art performance on challenging benchmarks.</li>
</ul>

<h3>Title: S2S-Arena, Evaluating Speech2Speech Protocols on Instruction Following with Paralinguistic Information</h3>
<ul>
<li><strong>Authors: </strong>Feng Jiang, Zhiyu Lin, Fan Bu, Yuhao Du, Benyou Wang, Haizhou Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05085">https://arxiv.org/abs/2503.05085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05085">https://arxiv.org/pdf/2503.05085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05085]] S2S-Arena, Evaluating Speech2Speech Protocols on Instruction Following with Paralinguistic Information(https://arxiv.org/abs/2503.05085)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of large language models (LLMs) has brought significant attention to speech models, particularly recent progress in speech2speech protocols supporting speech input and output. However, the existing benchmarks adopt automatic text-based evaluators for evaluating the instruction following ability of these models lack consideration for paralinguistic information in both speech understanding and generation. To address these issues, we introduce S2S-Arena, a novel arena-style S2S benchmark that evaluates instruction-following capabilities with paralinguistic information in both speech-in and speech-out across real-world tasks. We design 154 samples that fused TTS and live recordings in four domains with 21 tasks and manually evaluate existing popular speech models in an arena-style manner. The experimental results show that: (1) in addition to the superior performance of GPT-4o, the speech model of cascaded ASR, LLM, and TTS outperforms the jointly trained model after text-speech alignment in speech2speech protocols; (2) considering paralinguistic information, the knowledgeability of the speech model mainly depends on the LLM backbone, and the multilingual support of that is limited by the speech module; (3) excellent speech models can already understand the paralinguistic information in speech input, but generating appropriate audio with paralinguistic information is still a challenge.</li>
</ul>

<h3>Title: Fake It To Make It: Virtual Multiviews to Enhance Monocular Indoor Semantic Scene Completion</h3>
<ul>
<li><strong>Authors: </strong>Anith Selvakumar, Manasa Bharadwaj</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05086">https://arxiv.org/abs/2503.05086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05086">https://arxiv.org/pdf/2503.05086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05086]] Fake It To Make It: Virtual Multiviews to Enhance Monocular Indoor Semantic Scene Completion(https://arxiv.org/abs/2503.05086)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Monocular Indoor Semantic Scene Completion (SSC) aims to reconstruct a 3D semantic occupancy map from a single RGB image of an indoor scene, inferring spatial layout and object categories from 2D image cues. The challenge of this task arises from the depth, scale, and shape ambiguities that emerge when transforming a 2D image into 3D space, particularly within the complex and often heavily occluded environments of indoor scenes. Current SSC methods often struggle with these ambiguities, resulting in distorted or missing object representations. To overcome these limitations, we introduce an innovative approach that leverages novel view synthesis and multiview fusion. Specifically, we demonstrate how virtual cameras can be placed around the scene to emulate multiview inputs that enhance contextual scene information. We also introduce a Multiview Fusion Adaptor (MVFA) to effectively combine the multiview 3D scene predictions into a unified 3D semantic occupancy map. Finally, we identify and study the inherent limitation of generative techniques when applied to SSC, specifically the Novelty-Consistency tradeoff. Our system, GenFuSE, demonstrates IoU score improvements of up to 2.8% for Scene Completion and 4.9% for Semantic Scene Completion when integrated with existing SSC networks on the NYUv2 dataset. This work introduces GenFuSE as a standard framework for advancing monocular SSC with synthesized inputs.</li>
</ul>

<h3>Title: SpecServe: Efficient and SLO-Aware Large Language Model Serving with Adaptive Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Kaiyu Huang, Hao Wu, Zhubo Shi, Han Zou, Minchen Yu, Qingjiang Shi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05096">https://arxiv.org/abs/2503.05096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05096">https://arxiv.org/pdf/2503.05096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05096]] SpecServe: Efficient and SLO-Aware Large Language Model Serving with Adaptive Speculative Decoding(https://arxiv.org/abs/2503.05096)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) services often face challenges in achieving low inference latency and meeting Service Level Objectives (SLOs) under dynamic request patterns. Speculative decoding, which exploits lightweight models for drafting and LLMs for verification, has emerged as a compelling technique to accelerate LLM inference. However, existing speculative decoding solutions often fail to adapt to varying workloads and system environments, resulting in performance variability and SLO violations. In this paper, we introduce SpecServe, an efficient LLM inference system that dynamically adjusts speculative strategies according to real-time request loads and system configurations. SpecServe proposes a theoretical model to understand and predict the efficiency of speculative decoding across diverse scenarios. Additionally, it implements intelligent drafting and verification algorithms to guarantee optimal performance while achieving high SLO attainment. Experimental results on real-world LLM traces demonstrate that SpecServe consistently meets SLOs and achieves substantial performance improvements, yielding 1.14$\times$-14.3$\times$ speedups over state-of-the-art speculative inference systems.</li>
</ul>

<h3>Title: Grouped Sequential Optimization Strategy -- the Application of Hyperparameter Importance Assessment in Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Ruinan Wang, Ian Nabney, Mohammad Golbabaee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05106">https://arxiv.org/abs/2503.05106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05106">https://arxiv.org/pdf/2503.05106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05106]] Grouped Sequential Optimization Strategy -- the Application of Hyperparameter Importance Assessment in Deep Learning(https://arxiv.org/abs/2503.05106)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hyperparameter optimization (HPO) is a critical component of machine learning pipelines, significantly affecting model robustness, stability, and generalization. However, HPO is often a time-consuming and computationally intensive task. Traditional HPO methods, such as grid search and random search, often suffer from inefficiency. Bayesian optimization, while more efficient, still struggles with high-dimensional search spaces. In this paper, we contribute to the field by exploring how insights gained from hyperparameter importance assessment (HIA) can be leveraged to accelerate HPO, reducing both time and computational resources. Building on prior work that quantified hyperparameter importance by evaluating 10 hyperparameters on CNNs using 10 common image classification datasets, we implement a novel HPO strategy called 'Sequential Grouping.' That prior work assessed the importance weights of the investigated hyperparameters based on their influence on model performance, providing valuable insights that we leverage to optimize our HPO process. Our experiments, validated across six additional image classification datasets, demonstrate that incorporating hyperparameter importance assessment (HIA) can significantly accelerate HPO without compromising model performance, reducing optimization time by an average of 31.9\% compared to the conventional simultaneous strategy.</li>
</ul>

<h3>Title: TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Shibo Feng, Wanjin Feng, Xingyu Gao, Peilin Zhao, Zhiqi Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05108">https://arxiv.org/abs/2503.05108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05108">https://arxiv.org/pdf/2503.05108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05108]] TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting(https://arxiv.org/abs/2503.05108)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Spiking Neural Networks (SNNs) offer a promising, biologically inspired approach for processing spatiotemporal data, particularly for time series forecasting. However, conventional neuron models like the Leaky Integrate-and-Fire (LIF) struggle to capture long-term dependencies and effectively process multi-scale temporal dynamics. To overcome these limitations, we introduce the Temporal Segment Leaky Integrate-and-Fire (TS-LIF) model, featuring a novel dual-compartment architecture. The dendritic and somatic compartments specialize in capturing distinct frequency components, providing functional heterogeneity that enhances the neuron's ability to process both low- and high-frequency information. Furthermore, the newly introduced direct somatic current injection reduces information loss during intra-neuronal transmission, while dendritic spike generation improves multi-scale information extraction. We provide a theoretical stability analysis of the TS-LIF model and explain how each compartment contributes to distinct frequency response characteristics. Experimental results show that TS-LIF outperforms traditional SNNs in time series forecasting, demonstrating better accuracy and robustness, even with missing data. TS-LIF advances the application of SNNs in time-series forecasting, providing a biologically inspired approach that captures complex temporal dynamics and offers potential for practical implementation in diverse forecasting scenarios. The source code is available at this https URL.</li>
</ul>

<h3>Title: SMILENet: Unleashing Extra-Large Capacity Image Steganography via a Synergistic Mosaic InvertibLE Hiding Network</h3>
<ul>
<li><strong>Authors: </strong>Jun-Jie Huang, Zihan Chen, Tianrui Liu, Wentao Zhao, Xin Deng, Xinwang Liu, Meng Wang, Pier Luigi Dragotti</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05118">https://arxiv.org/abs/2503.05118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05118">https://arxiv.org/pdf/2503.05118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05118]] SMILENet: Unleashing Extra-Large Capacity Image Steganography via a Synergistic Mosaic InvertibLE Hiding Network(https://arxiv.org/abs/2503.05118)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Existing image steganography methods face fundamental limitations in hiding capacity (typically $1\sim7$ images) due to severe information interference and uncoordinated capacity-distortion trade-off. We propose SMILENet, a novel synergistic framework that achieves 25 image hiding through three key innovations: (i) A synergistic network architecture coordinates reversible and non-reversible operations to efficiently exploit information redundancy in both secret and cover images. The reversible Invertible Cover-Driven Mosaic (ICDM) module and Invertible Mosaic Secret Embedding (IMSE) module establish cover-guided mosaic transformations and representation embedding with mathematically guaranteed invertibility for distortion-free embedding. The non-reversible Secret Information Selection (SIS) module and Secret Detail Enhancement (SDE) module implement learnable feature modulation for critical information selection and enhancement. (ii) A unified training strategy that coordinates complementary modules to achieve 3.0x higher capacity than existing methods with superior visual quality. (iii) Last but not least, we introduce a new metric to model Capacity-Distortion Trade-off for evaluating the image steganography algorithms that jointly considers hiding capacity and distortion, and provides a unified evaluation approach for accessing results with different number of secret image. Extensive experiments on DIV2K, Paris StreetView and ImageNet1K show that SMILENet outperforms state-of-the-art methods in terms of hiding capacity, recovery quality as well as security against steganalysis methods.</li>
</ul>

<h3>Title: HexPlane Representation for 3D Semantic Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Zeren Chen, Yuenan Hou, Yulin Chen, Li Liu, Xiao Sun, Lu Sheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05127">https://arxiv.org/abs/2503.05127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05127">https://arxiv.org/pdf/2503.05127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05127]] HexPlane Representation for 3D Semantic Scene Understanding(https://arxiv.org/abs/2503.05127)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the HexPlane representation for 3D semantic scene understanding. Specifically, we first design the View Projection Module (VPM) to project the 3D point cloud into six planes to maximally retain the original spatial information. Features of six planes are extracted by the 2D encoder and sent to the HexPlane Association Module (HAM) to adaptively fuse the most informative information for each point. The fused point features are further fed to the task head to yield the ultimate predictions. Compared to the popular point and voxel representation, the HexPlane representation is efficient and can utilize highly optimized 2D operations to process sparse and unordered 3D point clouds. It can also leverage off-the-shelf 2D models, network weights, and training recipes to achieve accurate scene understanding in 3D space. On ScanNet and SemanticKITTI benchmarks, our algorithm, dubbed HexNet3D, achieves competitive performance with previous algorithms. In particular, on the ScanNet 3D segmentation task, our method obtains 77.0 mIoU on the validation set, surpassing Point Transformer V2 by 1.6 mIoU. We also observe encouraging results in indoor 3D detection tasks. Note that our method can be seamlessly integrated into existing voxel-based, point-based, and range-based approaches and brings considerable gains without bells and whistles. The codes will be available upon publication.</li>
</ul>

<h3>Title: Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs</h3>
<ul>
<li><strong>Authors: </strong>Ling Team, Binwei Zeng, Chao Huang, Chao Zhang, Changxin Tian, Cong Chen, Dingnan Jin, Feng Yu, Feng Zhu, Feng Yuan, Fakang Wang, Gangshan Wang, Guangyao Zhai, Haitao Zhang, Huizhong Li, Jun Zhou, Jia Liu, Junpeng Fang, Junjie Ou, Jun Hu, Ji Luo, Ji Zhang, Jian Liu, Jian Sha, Jianxue Qian, Jiewei Wu, Junping Zhao, Jianguo Li, Jubao Feng, Jingchao Di, Junming Xu, Jinghua Yao, Kuan Xu, Kewei Du, Longfei Li, Lei Liang, Lu Yu, Li Tang, Lin Ju, Peng Xu, Qing Cui, Song Liu, Shicheng Li, Shun Song, Song Yan, Tengwei Cai, Tianyi Chen, Ting Guo, Ting Huang, Tao Feng, Tao Wu, Wei Wu, Xiaolu Zhang, Xueming Yang, Xin Zhao, Xiaobo Hu, Xin Lin, Yao Zhao, Yilong Wang, Yongzhen Guo, Yuanyuan Wang, Yue Yang, Yang Cao, Yuhao Fu, Yi Xiong, Yanzhe Li, Zhe Li, Zhiqiang Zhang, Ziqi Liu, Zhaoxin Huan, Zujie Wen, Zhenhang Sun, Zhuoxuan Du, Zhengyu He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05139">https://arxiv.org/abs/2503.05139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05139">https://arxiv.org/pdf/2503.05139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05139]] Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs(https://arxiv.org/abs/2503.05139)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this technical report, we tackle the challenges of training large-scale Mixture of Experts (MoE) models, focusing on overcoming cost inefficiency and resource limitations prevalent in such systems. To address these issues, we present two differently sized MoE large language models (LLMs), namely Ling-Lite and Ling-Plus (referred to as "Bailing" in Chinese, spelled B«éil√≠ng in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75 billion activated parameters, while Ling-Plus boasts 290 billion parameters with 28.8 billion activated parameters. Both models exhibit comparable performance to leading industry benchmarks. This report offers actionable insights to improve the efficiency and accessibility of AI development in resource-constrained settings, promoting more scalable and sustainable technologies. Specifically, to reduce training costs for large-scale MoE models, we propose innovative methods for (1) optimization of model architecture and training processes, (2) refinement of training anomaly handling, and (3) enhancement of model evaluation efficiency. Additionally, leveraging high-quality data generated from knowledge graphs, our models demonstrate superior capabilities in tool use compared to other models. Ultimately, our experimental findings demonstrate that a 300B MoE LLM can be effectively trained on lower-performance devices while achieving comparable performance to models of a similar scale, including dense and MoE models. Compared to high-performance devices, utilizing a lower-specification hardware system during the pre-training phase demonstrates significant cost savings, reducing computing costs by approximately 20%. The models can be accessed at this https URL.</li>
</ul>

<h3>Title: RocketEval: Efficient Automated LLM Evaluation via Grading Checklist</h3>
<ul>
<li><strong>Authors: </strong>Tianjun Wei, Wei Wen, Ruizhi Qiao, Xing Sun, Jianghong Ma</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05142">https://arxiv.org/abs/2503.05142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05142">https://arxiv.org/pdf/2503.05142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05142]] RocketEval: Efficient Automated LLM Evaluation via Grading Checklist(https://arxiv.org/abs/2503.05142)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Evaluating large language models (LLMs) in diverse and challenging scenarios is essential to align them with human preferences. To mitigate the prohibitive costs associated with human evaluations, utilizing a powerful LLM as a judge has emerged as a favored approach. Nevertheless, this methodology encounters several challenges, including substantial expenses, concerns regarding privacy and security, and reproducibility. In this paper, we propose a straightforward, replicable, and accurate automated evaluation method by leveraging a lightweight LLM as the judge, named RocketEval. Initially, we identify that the performance disparity between lightweight and powerful LLMs in evaluation tasks primarily stems from their ability to conduct comprehensive analyses, which is not easily enhanced through techniques such as chain-of-thought reasoning. By reframing the evaluation task as a multi-faceted Q&A using an instance-specific checklist, we demonstrate that the limited judgment accuracy of lightweight LLMs is largely attributes to high uncertainty and positional bias. To address these challenges, we introduce an automated evaluation process grounded in checklist grading, which is designed to accommodate a variety of scenarios and questions. This process encompasses the creation of checklists, the grading of these checklists by lightweight LLMs, and the reweighting of checklist items to align with the supervised annotations. Our experiments carried out on the automated evaluation benchmarks, MT-Bench and WildBench datasets, reveal that RocketEval, when using Gemma-2-2B as the judge, achieves a high correlation (0.965) with human preferences, which is comparable to GPT-4o. Moreover, RocketEval provides a cost reduction exceeding 50-fold for large-scale evaluation and comparison scenarios. Our code is available at this https URL .</li>
</ul>

<h3>Title: Development and Enhancement of Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Rajdeep Roshan Sahu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05149">https://arxiv.org/abs/2503.05149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05149">https://arxiv.org/pdf/2503.05149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05149]] Development and Enhancement of Text-to-Image Diffusion Models(https://arxiv.org/abs/2503.05149)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This research focuses on the development and enhancement of text-to-image denoising diffusion models, addressing key challenges such as limited sample diversity and training instability. By incorporating Classifier-Free Guidance (CFG) and Exponential Moving Average (EMA) techniques, this study significantly improves image quality, diversity, and stability. Utilizing Hugging Face's state-of-the-art text-to-image generation model, the proposed enhancements establish new benchmarks in generative AI. This work explores the underlying principles of diffusion models, implements advanced strategies to overcome existing limitations, and presents a comprehensive evaluation of the improvements achieved. Results demonstrate substantial progress in generating stable, diverse, and high-quality images from textual descriptions, advancing the field of generative artificial intelligence and providing new foundations for future applications. Keywords: Text-to-image, Diffusion model, Classifier-free guidance, Exponential moving average, Image generation.</li>
</ul>

<h3>Title: Accelerating Diffusion Transformer via Gradient-Optimized Cache</h3>
<ul>
<li><strong>Authors: </strong>Junxiang Qiu, Lin Liu, Shuo Wang, Jinda Lu, Kezhou Chen, Yanbin Hao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05156">https://arxiv.org/abs/2503.05156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05156">https://arxiv.org/pdf/2503.05156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05156]] Accelerating Diffusion Transformer via Gradient-Optimized Cache(https://arxiv.org/abs/2503.05156)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Feature caching has emerged as an effective strategy to accelerate diffusion transformer (DiT) sampling through temporal feature reuse. It is a challenging problem since (1) Progressive error accumulation from cached blocks significantly degrades generation quality, particularly when over 50\% of blocks are cached; (2) Current error compensation approaches neglect dynamic perturbation patterns during the caching process, leading to suboptimal error correction. To solve these problems, we propose the Gradient-Optimized Cache (GOC) with two key innovations: (1) Cached Gradient Propagation: A gradient queue dynamically computes the gradient differences between cached and recomputed features. These gradients are weighted and propagated to subsequent steps, directly compensating for the approximation errors introduced by caching. (2) Inflection-Aware Optimization: Through statistical analysis of feature variation patterns, we identify critical inflection points where the denoising trajectory changes direction. By aligning gradient updates with these detected phases, we prevent conflicting gradient directions during error correction. Extensive evaluations on ImageNet demonstrate GOC's superior trade-off between efficiency and quality. With 50\% cached blocks, GOC achieves IS 216.28 (26.3\% higher) and FID 3.907 (43\% lower) compared to baseline DiT, while maintaining identical computational costs. These improvements persist across various cache ratios, demonstrating robust adaptability to different acceleration requirements.</li>
</ul>

<h3>Title: Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting Accuracy</h3>
<ul>
<li><strong>Authors: </strong>Ruixi Lin, Ziqiao Wang, Yang You</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05157">https://arxiv.org/abs/2503.05157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05157">https://arxiv.org/pdf/2503.05157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05157]] Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting Accuracy(https://arxiv.org/abs/2503.05157)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Language models are strong few-shot learners and achieve good overall accuracy in text classification tasks, masking the fact that their results suffer from great class accuracy imbalance. We believe that the pursuit of overall accuracy should not come from enriching the strong classes, but from raising up the weak ones. To address the imbalance, we propose a post-hoc nonlinear integer programming based debiasing method that ensembles weight correction and membership correction to enable flexible rectifications of class probabilities at both class and sample levels, enhancing the performance of LLMs directly from their outputs. Evaluations with Llama-2-13B on seven text classification benchmarks show that our approach achieves state-of-the-art overall accuracy gains with balanced class accuracies. The resulted probability correction scheme demonstrates that sample-level corrections are necessary to elevate weak classes. In addition, due to effectively correcting weak classes, our method also brings significant performance gains to Llama-2-70B, especially on a biomedical domain task, demonstrating its effectiveness across both small and large model variants.</li>
</ul>

<h3>Title: GaussianCAD: Robust Self-Supervised CAD Reconstruction from Three Orthographic Views Using 3D Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhou, Zhe Li, Bo Yu, Lina Hu, Liang Dong, Zijian Yang, Xiaoli Liu, Ning Xu, Ziwei Wang, Yonghao Dang, Jianqin Yin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05161">https://arxiv.org/abs/2503.05161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05161">https://arxiv.org/pdf/2503.05161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05161]] GaussianCAD: Robust Self-Supervised CAD Reconstruction from Three Orthographic Views Using 3D Gaussian Splatting(https://arxiv.org/abs/2503.05161)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The automatic reconstruction of 3D computer-aided design (CAD) models from CAD sketches has recently gained significant attention in the computer vision community. Most existing methods, however, rely on vector CAD sketches and 3D ground truth for supervision, which are often difficult to be obtained in industrial applications and are sensitive to noise inputs. We propose viewing CAD reconstruction as a specific instance of sparse-view 3D reconstruction to overcome these limitations. While this reformulation offers a promising perspective, existing 3D reconstruction methods typically require natural images and corresponding camera poses as inputs, which introduces two major significant challenges: (1) modality discrepancy between CAD sketches and natural images, and (2) difficulty of accurate camera pose estimation for CAD sketches. To solve these issues, we first transform the CAD sketches into representations resembling natural images and extract corresponding masks. Next, we manually calculate the camera poses for the orthographic views to ensure accurate alignment within the 3D coordinate system. Finally, we employ a customized sparse-view 3D reconstruction method to achieve high-quality reconstructions from aligned orthographic views. By leveraging raster CAD sketches for self-supervision, our approach eliminates the reliance on vector CAD sketches and 3D ground truth. Experiments on the Sub-Fusion360 dataset demonstrate that our proposed method significantly outperforms previous approaches in CAD reconstruction performance and exhibits strong robustness to noisy inputs.</li>
</ul>

<h3>Title: FMCHS: Advancing Traditional Chinese Medicine Herb Recommendation with Fusion of Multiscale Correlations of Herbs and Symptoms</h3>
<ul>
<li><strong>Authors: </strong>Xinhan Zheng, Huyu Wu, Haopeng Jin, Ruotai Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05167">https://arxiv.org/abs/2503.05167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05167">https://arxiv.org/pdf/2503.05167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05167]] FMCHS: Advancing Traditional Chinese Medicine Herb Recommendation with Fusion of Multiscale Correlations of Herbs and Symptoms(https://arxiv.org/abs/2503.05167)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Traditional Chinese medicine (TCM) exhibits remarkable therapeutic efficacy in disease treatment and healthcare through personalized herb prescriptions. However, current herb recommendation models inadequately capture the multiscale relations between herbs and clinical symptoms, particularly neglecting latent correlations at the chemical-molecular scale. To address these limitations, we propose the Fusion of Multiscale Correlations of Herbs and Symptoms (FMCHS), an innovative framework that synergistically integrates molecular-scale chemical characteristics of herbs with clinical symptoms. The framework employs multi-relational graph transformer layers to generate enriched embeddings that preserve both structural and semantic features within herbs and symptoms. Through systematic incorporation of herb chemical profiles into node embeddings and implementation of attention-based feature fusion, FMCHS effectively utilizes multiscale correlations. Comprehensive evaluations demonstrate FMCHS's superior performance over the state-of-the-art (SOTA) baseline, achieving relative improvements of 8.85% in Precision@5, 12.30% in Recall@5, and 10.86% in F1@5 compared to the SOTA model on benchmark datasets. This work facilitates the practical application of TCM in disease treatment and healthcare.</li>
</ul>

<h3>Title: Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching</h3>
<ul>
<li><strong>Authors: </strong>Simon A. Aytes, Jinheon Baek, Sung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05179">https://arxiv.org/abs/2503.05179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05179">https://arxiv.org/pdf/2503.05179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05179]] Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching(https://arxiv.org/abs/2503.05179)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models have demonstrated remarkable reasoning capabilities through Chain of Thought (CoT) prompting, but often at the cost of excessive verbosity in their intermediate outputs, which increases computational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting framework that combines cognitive-inspired reasoning paradigms with linguistic constraints to minimize token usage while preserving reasoning accuracy. SoT is designed as a flexible framework that can incorporate any custom reasoning paradigms based on cognitive science, and we instantiate it with three such paradigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each tailored to different reasoning tasks and selected dynamically via a lightweight routing model. Through comprehensive evaluation across 15 reasoning datasets with multiple languages and multimodal scenarios, we demonstrate that SoT achieves token reductions of 76% with negligible accuracy impact. In certain domains like mathematical and multi-hop reasoning, it even improves accuracy while using significantly fewer tokens. Our code is publicly available: this https URL.</li>
</ul>

<h3>Title: Spectral-Spatial Extraction through Layered Tensor Decomposition for Hyperspectral Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Quan Yu, Yu-Hong Dai, Minru Bai</a></li>
<li><strong>Subjects: </strong>cs.CV, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05183">https://arxiv.org/abs/2503.05183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05183">https://arxiv.org/pdf/2503.05183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05183]] Spectral-Spatial Extraction through Layered Tensor Decomposition for Hyperspectral Anomaly Detection(https://arxiv.org/abs/2503.05183)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Low rank tensor representation (LRTR) methods are very useful for hyperspectral anomaly detection (HAD). To overcome the limitations that they often overlook spectral anomaly and rely on large-scale matrix singular value decomposition, we first apply non-negative matrix factorization (NMF) to alleviate spectral dimensionality redundancy and extract spectral anomaly and then employ LRTR to extract spatial anomaly while mitigating spatial redundancy, yielding a highly efffcient layered tensor decomposition (LTD) framework for HAD. An iterative algorithm based on proximal alternating minimization is developed to solve the proposed LTD model, with convergence guarantees provided. Moreover, we introduce a rank reduction strategy with validation mechanism that adaptively reduces data size while preventing excessive reduction. Theoretically, we rigorously establish the equivalence between the tensor tubal rank and tensor group sparsity regularization (TGSR) and, under mild conditions, demonstrate that the relaxed formulation of TGSR shares the same global minimizers and optimal values as its original counterpart. Experimental results on the Airport-Beach-Urban and MVTec datasets demonstrate that our approach outperforms state-of-the-art methods in the HAD task.</li>
</ul>

<h3>Title: Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions</h3>
<ul>
<li><strong>Authors: </strong>Chan hur, Jeong-hun Hong, Dong-hun Lee, Dabin Kang, Semin Myeong, Sang-hyo Park, Hyeyoung Park</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05186">https://arxiv.org/abs/2503.05186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05186">https://arxiv.org/pdf/2503.05186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05186]] Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions(https://arxiv.org/abs/2503.05186)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In recent text-video retrieval, the use of additional captions from vision-language models has shown promising effects on the performance. However, existing models using additional captions often have struggled to capture the rich semantics, including temporal changes, inherent in the video. In addition, incorrect information caused by generative models can lead to inaccurate retrieval. To address these issues, we propose a new framework, Narrating the Video (NarVid), which strategically leverages the comprehensive information available from frame-level captions, the narration. The proposed NarVid exploits narration in multiple ways: 1) feature enhancement through cross-modal interactions between narration and video, 2) query-aware adaptive filtering to suppress irrelevant or incorrect information, 3) dual-modal matching score by adding query-video similarity and query-narration similarity, and 4) hard-negative loss to learn discriminative features from multiple perspectives using the two similarities from different views. Experimental results demonstrate that NarVid achieves state-of-the-art performance on various benchmark datasets.</li>
</ul>

<h3>Title: Partially Supervised Unpaired Multi-Modal Learning for Label-Efficient Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lei Zhu, Yanyu Xu, Huazhu Fu, Xinxing Xu, Rick Siow Mong Goh, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05190">https://arxiv.org/abs/2503.05190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05190">https://arxiv.org/pdf/2503.05190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05190]] Partially Supervised Unpaired Multi-Modal Learning for Label-Efficient Medical Image Segmentation(https://arxiv.org/abs/2503.05190)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Unpaired Multi-Modal Learning (UMML) which leverages unpaired multi-modal data to boost model performance on each individual modality has attracted a lot of research interests in medical image analysis. However, existing UMML methods require multi-modal datasets to be fully labeled, which incurs tremendous annotation cost. In this paper, we investigate the use of partially labeled data for label-efficient unpaired multi-modal learning, which can reduce the annotation cost by up to one half. We term the new learning paradigm as Partially Supervised Unpaired Multi-Modal Learning (PSUMML) and propose a novel Decomposed partial class adaptation with snapshot Ensembled Self-Training (DEST) framework for it. Specifically, our framework consists of a compact segmentation network with modality specific normalization layers for learning with partially labeled unpaired multi-modal data. The key challenge in PSUMML lies in the complex partial class distribution discrepancy due to partial class annotation, which hinders effective knowledge transfer across modalities. We theoretically analyze this phenomenon with a decomposition theorem and propose a decomposed partial class adaptation technique to precisely align the partially labeled classes across modalities to reduce the distribution discrepancy. We further propose a snapshot ensembled self-training technique to leverage the valuable snapshot models during training to assign pseudo-labels to partially labeled pixels for self-training to boost model performance. We perform extensive experiments under different scenarios of PSUMML for two medical image segmentation tasks, namely cardiac substructure segmentation and abdominal multi-organ segmentation. Our framework outperforms existing methods significantly.</li>
</ul>

<h3>Title: Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Mufan Xu, Gewen Liang, Kehai Chen, Wei Wang, Xun Zhou, Muyun Yang, Tiejun Zhao, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05193">https://arxiv.org/abs/2503.05193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05193">https://arxiv.org/pdf/2503.05193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05193]] Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning(https://arxiv.org/abs/2503.05193)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable performance on knowledge graph question answering (KGQA) tasks by planning and interacting with knowledge graphs. However, existing methods often confuse tool utilization with knowledge reasoning, harming readability of model outputs and giving rise to hallucinatory tool invocations, which hinder the advancement of KGQA. To address this issue, we propose Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning (MemQ) to decouple LLM from tool invocation tasks using LLM-built query memory. By establishing a memory module with explicit descriptions of query statements, the proposed MemQ facilitates the KGQA process with natural language reasoning and memory-augmented query reconstruction. Meanwhile, we design an effective and readable reasoning to enhance the LLM's reasoning capability in KGQA. Experimental results that MemQ achieves state-of-the-art performance on widely used benchmarks WebQSP and CWQ.</li>
</ul>

<h3>Title: Uncertainty-Aware Explainable Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yanci Zhang, Han Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05194">https://arxiv.org/abs/2503.05194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05194">https://arxiv.org/pdf/2503.05194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05194]] Uncertainty-Aware Explainable Federated Learning(https://arxiv.org/abs/2503.05194)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a collaborative machine learning paradigm for enhancing data privacy preservation. Its privacy-preserving nature complicates the explanation of the decision-making processes and the evaluation of the reliability of the generated explanations. In this paper, we propose the Uncertainty-aware eXplainable Federated Learning (UncertainXFL) to address these challenges. It generates explanations for decision-making processes under FL settings and provides information regarding the uncertainty of these explanations. UncertainXFL is the first framework to explicitly offer uncertainty evaluation for explanations within the FL context. Explanatory information is initially generated by the FL clients and then aggregated by the server in a comprehensive and conflict-free manner during FL training. The quality of the explanations, including the uncertainty score and tested validity, guides the FL training process by prioritizing clients with the most reliable explanations through higher weights during model aggregation. Extensive experimental evaluation results demonstrate that UncertainXFL achieves superior model accuracy and explanation accuracy, surpassing the current state-of-the-art model that does not incorporate uncertainty information by 2.71% and 1.77%, respectively. By integrating and quantifying uncertainty in the data into the explanation process, UncertainXFL not only clearly presents the explanation alongside its uncertainty, but also leverages this uncertainty to guide the FL training process, thereby enhancing the robustness and reliability of the resulting models.</li>
</ul>

<h3>Title: ORANSight-2.0: Foundational LLMs for O-RAN</h3>
<ul>
<li><strong>Authors: </strong>Pranshav Gajjar, Vijay K. Shah</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05200">https://arxiv.org/abs/2503.05200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05200">https://arxiv.org/pdf/2503.05200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05200]] ORANSight-2.0: Foundational LLMs for O-RAN(https://arxiv.org/abs/2503.05200)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative aimed at developing specialized foundational LLMs tailored for O-RAN. Built on 18 LLMs spanning five open-source LLM frameworks, ORANSight-2.0 fine-tunes models ranging from 1 to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance for O-RAN. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG) based instruction-tuning framework that employs two LLM agents to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack. We also leverage ORANBench13K, an existing benchmark for assessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate that ORANSight-2.0 models outperform general-purpose and closed-source models, such as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on srsRANBench, achieving superior performance while maintaining lower computational and energy costs. We also experiment with RAG-augmented variants of ORANSight-2.0 LLMs and thoroughly evaluate their energy characteristics, demonstrating costs for training, standard inference, and RAG-augmented inference.</li>
</ul>

<h3>Title: Operationalizing Cybersecurity Knowledge: Design, Implementation & Evaluation of a Knowledge Management System for CACAO Playbooks</h3>
<ul>
<li><strong>Authors: </strong>Orestis Tsirakis, Konstantinos Fysarakis, Vasileios Mavroeidis, Ioannis Papaefstathiou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05206">https://arxiv.org/abs/2503.05206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05206">https://arxiv.org/pdf/2503.05206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05206]] Operationalizing Cybersecurity Knowledge: Design, Implementation & Evaluation of a Knowledge Management System for CACAO Playbooks(https://arxiv.org/abs/2503.05206)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Modern cybersecurity threats are growing in complexity, targeting increasingly intricate & interconnected systems. To effectively defend against these evolving threats, security teams utilize automation & orchestration to enhance response efficiency and consistency. In that sense, cybersecurity playbooks are key enablers, providing a structured, reusable, and continuously improving approach to incident response, enabling organizations to codify requirements, domain expertise, and best practices and automate decision-making processes to the extent possible. The emerging Collaborative Automated Course of Action Operations (CACAO) standard defines a common machine-processable schema for cybersecurity playbooks, facilitating interoperability for their exchange and ensuring the ability to orchestrate and automate cybersecurity operations. However, despite its potential and the fact that it is a relatively new standardization work, there is a lack of tools to support its adoption and, in particular, the management & lifecycle development of CACAO playbooks, limiting their practical deployment. Motivated by the above, this work presents the design, development, and evaluation of a Knowledge Management System (KMS) for managing CACAO cybersecurity playbooks throughout their lifecycle, providing essential tools to streamline playbook management. Using open technologies & standards, the proposed approach fosters standards-based interoperability & enhances the usability of state-of-the-art cybersecurity orchestration & automation primitives. To encourage adoption, the resulting implementation is released as open-source, which, to the extent of our knowledge, comprises the first publicly available & documented work in this domain, supporting the broader uptake of CACAO playbooks & promoting the widespread use of interoperable automation and orchestration mechanisms in cybersecurity operations.</li>
</ul>

<h3>Title: Policy Constraint by Only Support Constraint for Offline Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yunkai Gao, Jiaming Guo, Fan Wu, Rui Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05207">https://arxiv.org/abs/2503.05207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05207">https://arxiv.org/pdf/2503.05207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05207]] Policy Constraint by Only Support Constraint for Offline Reinforcement Learning(https://arxiv.org/abs/2503.05207)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) aims to optimize a policy by using pre-collected datasets, to maximize cumulative rewards. However, offline reinforcement learning suffers challenges due to the distributional shift between the learned and behavior policies, leading to errors when computing Q-values for out-of-distribution (OOD) actions. To mitigate this issue, policy constraint methods aim to constrain the learned policy's distribution with the distribution of the behavior policy or confine action selection within the support of the behavior policy. However, current policy constraint methods tend to exhibit excessive conservatism, hindering the policy from further surpassing the behavior policy's performance. In this work, we present Only Support Constraint (OSC) which is derived from maximizing the total probability of learned policy in the support of behavior policy, to address the conservatism of policy constraint. OSC presents a regularization term that only restricts policies to the support without imposing extra constraints on actions within the support. Additionally, to fully harness the performance of the new policy constraints, OSC utilizes a diffusion model to effectively characterize the support of behavior policies. Experimental evaluations across a variety of offline RL benchmarks demonstrate that OSC significantly enhances performance, alleviating the challenges associated with distributional shifts and mitigating conservatism of policy constraints. Code is available at this https URL.</li>
</ul>

<h3>Title: Knowledge Updating? No More Model Editing! Just Selective Contextual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Guoxiu He, Xin Song, Aixin Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05212">https://arxiv.org/abs/2503.05212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05212">https://arxiv.org/pdf/2503.05212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05212]] Knowledge Updating? No More Model Editing! Just Selective Contextual Reasoning(https://arxiv.org/abs/2503.05212)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As real-world knowledge evolves, the information embedded within large language models (LLMs) can become outdated, inadequate, or erroneous. Model editing has emerged as a prominent approach for updating LLMs' knowledge with minimal computational costs and parameter changes. This approach typically identifies and adjusts specific model parameters associated with newly acquired knowledge. However, existing methods often underestimate the adverse effects that parameter modifications can have on broadly distributed knowledge. More critically, post-edit LLMs frequently struggle with multi-hop reasoning and continuous knowledge updates. Although various studies have discussed these shortcomings, there is a lack of comprehensive evaluation. In this paper, we provide an evaluation of ten model editing methods along four dimensions: reliability, generalization, locality, and portability. Results confirm that all ten popular model editing methods show significant shortcomings across multiple dimensions, suggesting model editing is less promising. We then propose a straightforward method called Selective Contextual Reasoning (SCR), for knowledge updating. SCR does not modify model parameters but harnesses LLM's inherent contextual reasoning capabilities utilizing the updated knowledge pieces. Under SCR, an LLM first assesses whether an incoming query falls within the scope of an external knowledge base. If it does, the relevant external knowledge texts are contextualized to enhance reasoning; otherwise, the query is answered directly. We evaluate SCR against the ten model editing methods on two counterfactual datasets with three backbone LLMs. Empirical results confirm the effectiveness and efficiency of contextual reasoning for knowledge updating.</li>
</ul>

<h3>Title: Robustness of Generalized Median Computation for Consensus Learning in Arbitrary Spaces</h3>
<ul>
<li><strong>Authors: </strong>Andreas Nienk√∂tter, Sandro Vega-Pons, Xiaoyi Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05215">https://arxiv.org/abs/2503.05215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05215">https://arxiv.org/pdf/2503.05215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05215]] Robustness of Generalized Median Computation for Consensus Learning in Arbitrary Spaces(https://arxiv.org/abs/2503.05215)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robustness in terms of outliers is an important topic and has been formally studied for a variety of problems in machine learning and computer vision. Generalized median computation is a special instance of consensus learning and a common approach to finding prototypes. Related research can be found in numerous problem domains with a broad range of applications. So far, however, robustness of generalized median has only been studied in a few specific spaces. To our knowledge, there is no robustness characterization in a general setting, i.e. for arbitrary spaces. We address this open issue in our work. The breakdown point >=0.5 is proved for generalized median with metric distance functions in general. We also study the detailed behavior in case of outliers from different perspectives. In addition, we present robustness results for weighted generalized median computation and non-metric distance functions. Given the importance of robustness, our work contributes to closing a gap in the literature. The presented results have general impact and applicability, e.g. providing deeper understanding of generalized median computation and practical guidance to avoid non-robust computation.</li>
</ul>

<h3>Title: Separability Membrane: 3D Active Contour for Point Cloud Surface Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Gulpi Qorik Oktagalu Pratamasunu, Guoqing Hao, Kazuhiro Fukui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05217">https://arxiv.org/abs/2503.05217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05217">https://arxiv.org/pdf/2503.05217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05217]] Separability Membrane: 3D Active Contour for Point Cloud Surface Reconstruction(https://arxiv.org/abs/2503.05217)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes Separability Membrane, a robust 3D active contour for extracting a surface from 3D point cloud object. Our approach defines the surface of a 3D object as the boundary that maximizes the separability of point features, such as intensity, color, or local density, between its inner and outer regions based on Fisher's ratio. Separability Membrane identifies the exact surface of a 3D object by maximizing class separability while controlling the rigidity of the 3D surface model with an adaptive B-spline surface that adjusts its properties based on the local and global separability. A key advantage of our method is its ability to accurately reconstruct surface boundaries even when they are ambiguous due to noise or outliers, without requiring any training data or conversion to volumetric representation. Evaluations on a synthetic 3D point cloud dataset and the 3DNet dataset demonstrate the membrane's effectiveness and robustness under diverse conditions.</li>
</ul>

<h3>Title: Robust Conformal Prediction with a Single Binary Certificate</h3>
<ul>
<li><strong>Authors: </strong>Soroush H. Zargarbashi, Aleksandar Bojchevski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05239">https://arxiv.org/abs/2503.05239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05239">https://arxiv.org/pdf/2503.05239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05239]] Robust Conformal Prediction with a Single Binary Certificate(https://arxiv.org/abs/2503.05239)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Conformal prediction (CP) converts any model's output to prediction sets with a guarantee to cover the true label with (adjustable) high probability. Robust CP extends this guarantee to worst-case (adversarial) inputs. Existing baselines achieve robustness by bounding randomly smoothed conformity scores. In practice, they need expensive Monte-Carlo (MC) sampling (e.g. $\sim10^4$ samples per point) to maintain an acceptable set size. We propose a robust conformal prediction that produces smaller sets even with significantly lower MC samples (e.g. 150 for CIFAR10). Our approach binarizes samples with an adjustable (or automatically adjusted) threshold selected to preserve the coverage guarantee. Remarkably, we prove that robustness can be achieved by computing only one binary certificate, unlike previous methods that certify each calibration (or test) point. Thus, our method is faster and returns smaller robust sets. We also eliminate a previous limitation that requires a bounded score function.</li>
</ul>

<h3>Title: MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio</h3>
<ul>
<li><strong>Authors: </strong>Xuenan Xu, Jiahao Mei, Chenliang Li, Yuning Wu, Ming Yan, Shaopeng Lai, Ji Zhang, Mengyue Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05242">https://arxiv.org/abs/2503.05242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05242">https://arxiv.org/pdf/2503.05242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05242]] MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio(https://arxiv.org/abs/2503.05242)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) and artificial intelligence-generated content (AIGC) has accelerated AI-native applications, such as AI-based storybooks that automate engaging story production for children. However, challenges remain in improving story attractiveness, enriching storytelling expressiveness, and developing open-source evaluation benchmarks and frameworks. Therefore, we propose and opensource MM-StoryAgent, which creates immersive narrated video storybooks with refined plots, role-consistent images, and multi-channel audio. MM-StoryAgent designs a multi-agent framework that employs LLMs and diverse expert tools (generative models and APIs) across several modalities to produce expressive storytelling videos. The framework enhances story attractiveness through a multi-stage writing pipeline. In addition, it improves the immersive storytelling experience by integrating sound effects with visual, music and narrative assets. MM-StoryAgent offers a flexible, open-source platform for further development, where generative modules can be substituted. Both objective and subjective evaluation regarding textual story quality and alignment between modalities validate the effectiveness of our proposed MM-StoryAgent system. The demo and source code are available.</li>
</ul>

<h3>Title: ColFigPhotoAttnNet: Reliable Finger Photo Presentation Attack Detection Leveraging Window-Attention on Color Spaces</h3>
<ul>
<li><strong>Authors: </strong>Anudeep Vurity, Emanuela Marasco, Raghavendra Ramachandra, Jongwoo Park</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05247">https://arxiv.org/abs/2503.05247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05247">https://arxiv.org/pdf/2503.05247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05247]] ColFigPhotoAttnNet: Reliable Finger Photo Presentation Attack Detection Leveraging Window-Attention on Color Spaces(https://arxiv.org/abs/2503.05247)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Finger photo Presentation Attack Detection (PAD) can significantly strengthen smartphone device security. However, these algorithms are trained to detect certain types of attacks. Furthermore, they are designed to operate on images acquired by specific capture devices, leading to poor generalization and a lack of robustness in handling the evolving nature of mobile hardware. The proposed investigation is the first to systematically analyze the performance degradation of existing deep learning PAD systems, convolutional and transformers, in cross-capture device settings. In this paper, we introduce the ColFigPhotoAttnNet architecture designed based on window attention on color channels, followed by the nested residual network as the predictor to achieve a reliable PAD. Extensive experiments using various capture devices, including iPhone13 Pro, GooglePixel 3, Nokia C5, and OnePlusOne, were carried out to evaluate the performance of proposed and existing methods on three publicly available databases. The findings underscore the effectiveness of our approach.</li>
</ul>

<h3>Title: CMMCoT: Enhancing Complex Multi-Image Comprehension via Multi-Modal Chain-of-Thought and Memory Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Guanghao Zhang, Tao Zhong, Yan Xia, Zhelun Yu, Haoyuan Li, Wanggui He, Fangxun Shu, Mushui Liu, Dong She, Yi Wang, Hao Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05255">https://arxiv.org/abs/2503.05255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05255">https://arxiv.org/pdf/2503.05255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05255]] CMMCoT: Enhancing Complex Multi-Image Comprehension via Multi-Modal Chain-of-Thought and Memory Augmentation(https://arxiv.org/abs/2503.05255)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>While previous multimodal slow-thinking methods have demonstrated remarkable success in single-image understanding scenarios, their effectiveness becomes fundamentally constrained when extended to more complex multi-image comprehension tasks. This limitation stems from their predominant reliance on text-based intermediate reasoning processes. While for human, when engaging in sophisticated multi-image analysis, they typically perform two complementary cognitive operations: (1) continuous cross-image visual comparison through region-of-interest matching, and (2) dynamic memorization of critical visual concepts throughout the reasoning chain. Motivated by these observations, we propose the Complex Multi-Modal Chain-of-Thought (CMMCoT) framework, a multi-step reasoning framework that mimics human-like "slow thinking" for multi-image understanding. Our approach incorporates two key innovations: 1. The construction of interleaved multimodal multi-step reasoning chains, which utilize critical visual region tokens, extracted from intermediate reasoning steps, as supervisory signals. This mechanism not only facilitates comprehensive cross-modal understanding but also enhances model interpretability. 2. The introduction of a test-time memory augmentation module that expands the model reasoning capacity during inference while preserving parameter efficiency. Furthermore, to facilitate research in this direction, we have curated a novel multi-image slow-thinking dataset. Extensive experiments demonstrate the effectiveness of our model.</li>
</ul>

<h3>Title: Jailbreaking is (Mostly) Simpler Than You Think</h3>
<ul>
<li><strong>Authors: </strong>Mark Russinovich, Ahmed Salem</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05264">https://arxiv.org/abs/2503.05264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05264">https://arxiv.org/pdf/2503.05264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05264]] Jailbreaking is (Mostly) Simpler Than You Think(https://arxiv.org/abs/2503.05264)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We introduce the Context Compliance Attack (CCA), a novel, optimization-free method for bypassing AI safety mechanisms. Unlike current approaches -- which rely on complex prompt engineering and computationally intensive optimization -- CCA exploits a fundamental architectural vulnerability inherent in many deployed AI systems. By subtly manipulating conversation history, CCA convinces the model to comply with a fabricated dialogue context, thereby triggering restricted behavior. Our evaluation across a diverse set of open-source and proprietary models demonstrates that this simple attack can circumvent state-of-the-art safety protocols. We discuss the implications of these findings and propose practical mitigation strategies to fortify AI systems against such elementary yet effective adversarial tactics.</li>
</ul>

<h3>Title: PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and Latin Lexicons</h3>
<ul>
<li><strong>Authors: </strong>Rumi A. Allbert, Makai L. Allbert</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05265">https://arxiv.org/abs/2503.05265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05265">https://arxiv.org/pdf/2503.05265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05265]] PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and Latin Lexicons(https://arxiv.org/abs/2503.05265)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present PhiloBERTA, a cross-lingual transformer model that measures semantic relationships between ancient Greek and Latin lexicons. Through analysis of selected term pairs from classical texts, we use contextual embeddings and angular similarity metrics to identify precise semantic alignments. Our results show that etymologically related pairs demonstrate significantly higher similarity scores, particularly for abstract philosophical concepts such as epistƒìmƒì (scientia) and dikaiosynƒì (iustitia). Statistical analysis reveals consistent patterns in these relationships (p = 0.012), with etymologically related pairs showing remarkably stable semantic preservation compared to control pairs. These findings establish a quantitative framework for examining how philosophical concepts moved between Greek and Latin traditions, offering new methods for classical philological research.</li>
</ul>

<h3>Title: Similarity-Based Domain Adaptation with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jie He, Wendi Zhou, Xiang Lorraine Li, Jeff Z. Pan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05281">https://arxiv.org/abs/2503.05281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05281">https://arxiv.org/pdf/2503.05281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05281]] Similarity-Based Domain Adaptation with LLMs(https://arxiv.org/abs/2503.05281)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Unsupervised domain adaptation leverages abundant labeled data from various source domains to generalize onto unlabeled target data. Prior research has primarily focused on learning domain-invariant features across the source and target domains. However, these methods often require training a model using source domain data, which is time-consuming and can limit model usage for applications with different source data. This paper introduces a simple framework that utilizes the impressive generalization capabilities of Large Language Models (LLMs) for target data annotation without the need of source model training, followed by a novel similarity-based knowledge distillation loss. Our extensive experiments on cross-domain text classification reveal that our framework achieves impressive performance, specifically, 2.44\% accuracy improvement when compared to the SOTA method.</li>
</ul>

<h3>Title: Robust Intrusion Detection System with Explainable Artificial Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Bet√ºl G√ºven√ß Paltun, Ramin Fuladi, Rim El Malki</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05303">https://arxiv.org/abs/2503.05303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05303">https://arxiv.org/pdf/2503.05303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05303]] Robust Intrusion Detection System with Explainable Artificial Intelligence(https://arxiv.org/abs/2503.05303)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) models serve as powerful tools for threat detection and mitigation; however, they also introduce potential new risks. Adversarial input can exploit these models through standard interfaces, thus creating new attack pathways that threaten critical network operations. As ML advancements progress, adversarial strategies become more advanced, and conventional defenses such as adversarial training are costly in computational terms and often fail to provide real-time detection. These methods typically require a balance between robustness and model performance, which presents challenges for applications that demand instant response. To further investigate this vulnerability, we suggest a novel strategy for detecting and mitigating adversarial attacks using eXplainable Artificial Intelligence (XAI). This approach is evaluated in real time within intrusion detection systems (IDS), leading to the development of a zero-touch mitigation strategy. Additionally, we explore various scenarios in the Radio Resource Control (RRC) layer within the Open Radio Access Network (O-RAN) framework, emphasizing the critical need for enhanced mitigation techniques to strengthen IDS defenses against advanced threats and implement a zero-touch mitigation solution. Extensive testing across different scenarios in the RRC layer of the O-RAN infrastructure validates the ability of the framework to detect and counteract integrated RRC-layer attacks when paired with adversarial strategies, emphasizing the essential need for robust defensive mechanisms to strengthen IDS against complex threats.</li>
</ul>

<h3>Title: Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation</h3>
<ul>
<li><strong>Authors: </strong>Xinkun Wang, Yifang Wang, Senwei Liang, Feilong Tang, Chengzhi Liu, Ming Hu, Chao Hu, Junjun He, Zongyuan Ge, Imran Razzak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05319">https://arxiv.org/abs/2503.05319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05319">https://arxiv.org/pdf/2503.05319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05319]] Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation(https://arxiv.org/abs/2503.05319)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper discusses how ophthalmologists often rely on multimodal data to improve diagnostic accuracy. However, complete multimodal data is rare in real-world applications due to a lack of medical equipment and concerns about data privacy. Traditional deep learning methods typically address these issues by learning representations in latent space. However, the paper highlights two key limitations of these approaches: (i) Task-irrelevant redundant information (e.g., numerous slices) in complex modalities leads to significant redundancy in latent space representations. (ii) Overlapping multimodal representations make it difficult to extract unique features for each modality. To overcome these challenges, the authors propose the Essence-Point and Disentangle Representation Learning (EDRL) strategy, which integrates a self-distillation mechanism into an end-to-end framework to enhance feature selection and disentanglement for more robust multimodal learning. Specifically, the Essence-Point Representation Learning module selects discriminative features that improve disease grading performance. The Disentangled Representation Learning module separates multimodal data into modality-common and modality-unique representations, reducing feature entanglement and enhancing both robustness and interpretability in ophthalmic disease diagnosis. Experiments on multimodal ophthalmology datasets show that the proposed EDRL strategy significantly outperforms current state-of-the-art methods.</li>
</ul>

<h3>Title: Disentangling Task Interference within Neurons: Model Merging in Alignment with Neuronal Mechanisms</h3>
<ul>
<li><strong>Authors: </strong>Zitao Fang, Guodong DU, Shuyang Yu, Yifei Guo, Yiwei Zhang, Jing Li, Ho-Kin Tang, Sim Kuan Goh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05320">https://arxiv.org/abs/2503.05320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05320">https://arxiv.org/pdf/2503.05320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05320]] Disentangling Task Interference within Neurons: Model Merging in Alignment with Neuronal Mechanisms(https://arxiv.org/abs/2503.05320)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Fine-tuning pre-trained models on targeted datasets enhances task-specific performance but often comes at the expense of generalization. Model merging techniques, which integrate multiple fine-tuned models into a single multi-task model through task arithmetic at various levels: model, layer, or parameter, offer a promising solution. However, task interference remains a fundamental challenge, leading to performance degradation and suboptimal merged models. Existing approaches largely overlook the fundamental role of individual neurons and their connectivity, resulting in a lack of interpretability in both the merging process and the merged models. In this work, we present the first study on the impact of neuronal alignment in model merging. We decompose task-specific representations into two complementary neuronal subspaces that regulate neuron sensitivity and input adaptability. Leveraging this decomposition, we introduce NeuroMerging, a novel merging framework developed to mitigate task interference within neuronal subspaces, enabling training-free model fusion across diverse tasks. Through extensive experiments, we demonstrate that NeuroMerging achieves superior performance compared to existing methods on multi-task benchmarks across both vision and natural language domains. Our findings highlight the importance of aligning neuronal mechanisms in model merging, offering new insights into mitigating task interference and improving knowledge fusion.</li>
</ul>

<h3>Title: Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anar Yeginbergen, Maite Oronoz, Rodrigo Agerri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05328">https://arxiv.org/abs/2503.05328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05328">https://arxiv.org/pdf/2503.05328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05328]] Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models(https://arxiv.org/abs/2503.05328)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the role of dynamic external knowledge integration in improving counter-argument generation using Large Language Models (LLMs). While LLMs have shown promise in argumentative tasks, their tendency to generate lengthy, potentially unfactual responses highlights the need for more controlled and evidence-based approaches. We introduce a new manually curated dataset of argument and counter-argument pairs specifically designed to balance argumentative complexity with evaluative feasibility. We also propose a new LLM-as-a-Judge evaluation methodology that shows a stronger correlation with human judgments compared to traditional reference-based metrics. Our experimental results demonstrate that integrating dynamic external knowledge from the web significantly improves the quality of generated counter-arguments, particularly in terms of relatedness, persuasiveness, and factuality. The findings suggest that combining LLMs with real-time external knowledge retrieval offers a promising direction for developing more effective and reliable counter-argumentation systems.</li>
</ul>

<h3>Title: PhysicsGen: Can Generative Models Learn from Images to Predict Complex Physical Relations?</h3>
<ul>
<li><strong>Authors: </strong>Martin Spitznagel, Jan Vaillant, Janis Keuper</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05333">https://arxiv.org/abs/2503.05333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05333">https://arxiv.org/pdf/2503.05333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05333]] PhysicsGen: Can Generative Models Learn from Images to Predict Complex Physical Relations?(https://arxiv.org/abs/2503.05333)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The image-to-image translation abilities of generative learning models have recently made significant progress in the estimation of complex (steered) mappings between image distributions. While appearance based tasks like image in-painting or style transfer have been studied at length, we propose to investigate the potential of generative models in the context of physical simulations. Providing a dataset of 300k image-pairs and baseline evaluations for three different physical simulation tasks, we propose a benchmark to investigate the following research questions: i) are generative models able to learn complex physical relations from input-output image pairs? ii) what speedups can be achieved by replacing differential equation based simulations? While baseline evaluations of different current models show the potential for high speedups (ii), these results also show strong limitations toward the physical correctness (i). This underlines the need for new methods to enforce physical correctness. Data, baseline models and evaluation code this http URL.</li>
</ul>

<h3>Title: New multimodal similarity measure for image registration via modeling local functional dependence with linear combination of learned basis functions</h3>
<ul>
<li><strong>Authors: </strong>Joel Honkamaa, Pekka Marttinen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05335">https://arxiv.org/abs/2503.05335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05335">https://arxiv.org/pdf/2503.05335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05335]] New multimodal similarity measure for image registration via modeling local functional dependence with linear combination of learned basis functions(https://arxiv.org/abs/2503.05335)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The deformable registration of images of different modalities, essential in many medical imaging applications, remains challenging. The main challenge is developing a robust measure for image overlap despite the compared images capturing different aspects of the underlying tissue. Here, we explore similarity metrics based on functional dependence between intensity values of registered images. Although functional dependence is too restrictive on the global scale, earlier work has shown competitive performance in deformable registration when such measures are applied over small enough contexts. We confirm this finding and further develop the idea by modeling local functional dependence via the linear basis function model with the basis functions learned jointly with the deformation. The measure can be implemented via convolutions, making it efficient to compute on GPUs. We release the method as an easy-to-use tool and show good performance on three datasets compared to well-established baseline and earlier functional dependence-based methods.</li>
</ul>

<h3>Title: AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications</h3>
<ul>
<li><strong>Authors: </strong>Leming Shen, Qiang Yang, Yuanqing Zheng, Mo Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05346">https://arxiv.org/abs/2503.05346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05346">https://arxiv.org/pdf/2503.05346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05346]] AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications(https://arxiv.org/abs/2503.05346)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) has profoundly transformed our lives, revolutionizing interactions with AI and lowering the barrier to AI usage. While LLMs are primarily designed for natural language interaction, the extensive embedded knowledge empowers them to comprehend digital sensor data. This capability enables LLMs to engage with the physical world through IoT sensors and actuators, performing a myriad of AIoT tasks. Consequently, this evolution triggers a paradigm shift in conventional AIoT application development, democratizing its accessibility to all by facilitating the design and development of AIoT applications via natural language. However, some limitations need to be addressed to unlock the full potential of LLMs in AIoT application development. First, existing solutions often require transferring raw sensor data to LLM servers, which raises privacy concerns, incurs high query fees, and is limited by token size. Moreover, the reasoning processes of LLMs are opaque to users, making it difficult to verify the robustness and correctness of inference results. This paper introduces AutoIOT, an LLM-based automated program generator for AIoT applications. AutoIOT enables users to specify their requirements using natural language (input) and automatically synthesizes interpretable programs with documentation (output). AutoIOT automates the iterative optimization to enhance the quality of generated code with minimum user involvement. AutoIOT not only makes the execution of AIoT tasks more explainable but also mitigates privacy concerns and reduces token costs with local execution of synthesized programs. Extensive experiments and user studies demonstrate AutoIOT's remarkable capability in program synthesis for various AIoT tasks. The synthesized programs can match and even outperform some representative baselines.</li>
</ul>

<h3>Title: GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Zhenxuan Zhang, Kinhei Lee, Weihang Deng, Huichi Zhou, Zihao Jin, Jiahao Huang, Zhifan Gao, Dominic C Marshall, Yingying Fang, Guang Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05347">https://arxiv.org/abs/2503.05347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05347">https://arxiv.org/pdf/2503.05347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05347]] GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation(https://arxiv.org/abs/2503.05347)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automatic medical report generation supports clinical diagnosis, reduces the workload of radiologists, and holds the promise of improving diagnosis consistency. However, existing evaluation metrics primarily assess the accuracy of key medical information coverage in generated reports compared to human-written reports, while overlooking crucial details such as the location and certainty of reported abnormalities. These limitations hinder the comprehensive assessment of the reliability of generated reports and pose risks in their selection for clinical use. Therefore, we propose a Granular Explainable Multi-Agent Score (GEMA-Score) in this paper, which conducts both objective quantification and subjective evaluation through a large language model-based multi-agent workflow. Our GEMA-Score parses structured reports and employs NER-F1 calculations through interactive exchanges of information among agents to assess disease diagnosis, location, severity, and uncertainty. Additionally, an LLM-based scoring agent evaluates completeness, readability, and clinical terminology while providing explanatory feedback. Extensive experiments validate that GEMA-Score achieves the highest correlation with human expert evaluations on a public dataset, demonstrating its effectiveness in clinical scoring (Kendall coefficient = 0.70 for Rexval dataset and Kendall coefficient = 0.54 for RadEvalX dataset). The anonymous project demo is available at: this https URL.</li>
</ul>

<h3>Title: Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter</h3>
<ul>
<li><strong>Authors: </strong>Weixiang Zhao, Xingyu Sui, Xinyang Han, Yang Deng, Yulin Hu, Jiahe Guo, Libo Qin, Qianyun Du, Shijin Wang, Yanyan Zhao, Bing Qin, Ting Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05362">https://arxiv.org/abs/2503.05362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05362">https://arxiv.org/pdf/2503.05362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05362]] Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter(https://arxiv.org/abs/2503.05362)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing emotional stress in modern society has increased the demand for Emotional Support Conversations (ESC). While Large Language Models (LLMs) show promise for ESC, they face two key challenges: (1) low strategy selection accuracy, and (2) preference bias, limiting their adaptability to emotional needs of users. Existing supervised fine-tuning (SFT) struggles to address these issues, as it rigidly trains models on single gold-standard responses without modeling nuanced strategy trade-offs. To overcome these limitations, we propose Chain-of-Strategy Optimization (CSO), a novel approach that optimizes strategy selection preferences at each dialogue turn. We first leverage Monte Carlo Tree Search to construct ESC-Pro, a high-quality preference dataset with turn-level strategy-response pairs. Training on ESC-Pro with CSO improves both strategy accuracy and bias mitigation, enabling LLMs to generate more empathetic and contextually appropriate responses. Experiments on LLaMA-3.1-8B, Gemma-2-9B, and Qwen2.5-7B demonstrate that CSO outperforms standard SFT, highlighting the efficacy of fine-grained, turn-level preference modeling in ESC.</li>
</ul>

<h3>Title: Multi-Grained Feature Pruning for Video-Based Human Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Zhigang Wang, Shaojing Fan, Zhenguang Liu, Zheqi Wu, Sifan Wu, Yingying Jiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05365">https://arxiv.org/abs/2503.05365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05365">https://arxiv.org/pdf/2503.05365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05365]] Multi-Grained Feature Pruning for Video-Based Human Pose Estimation(https://arxiv.org/abs/2503.05365)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Human pose estimation, with its broad applications in action recognition and motion capture, has experienced significant advancements. However, current Transformer-based methods for video pose estimation often face challenges in managing redundant temporal information and achieving fine-grained perception because they only focus on processing low-resolution features. To address these challenges, we propose a novel multi-scale resolution framework that encodes spatio-temporal representations at varying granularities and executes fine-grained perception compensation. Furthermore, we employ a density peaks clustering method to dynamically identify and prioritize tokens that offer important semantic information. This strategy effectively prunes redundant feature tokens, especially those arising from multi-frame features, thereby optimizing computational efficiency without sacrificing semantic richness. Empirically, it sets new benchmarks for both performance and efficiency on three large-scale datasets. Our method achieves a 93.8% improvement in inference speed compared to the baseline, while also enhancing pose estimation accuracy, reaching 87.4 mAP on the PoseTrack2017 dataset.</li>
</ul>

<h3>Title: Shifting Perspectives: Steering Vector Ensembles for Robust Bias Mitigation in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zara Siddique, Irtaza Khalid, Liam D. Turner, Luis Espinosa-Anke</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05371">https://arxiv.org/abs/2503.05371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05371">https://arxiv.org/pdf/2503.05371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05371]] Shifting Perspectives: Steering Vector Ensembles for Robust Bias Mitigation in LLMs(https://arxiv.org/abs/2503.05371)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We present a novel approach to bias mitigation in large language models (LLMs) by applying steering vectors to modify model activations in forward passes. We employ Bayesian optimization to systematically identify effective contrastive pair datasets across nine bias axes. When optimized on the BBQ dataset, our individually tuned steering vectors achieve average improvements of 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen, respectively. Building on these promising results, we introduce Steering Vector Ensembles (SVE), a method that averages multiple individually optimized steering vectors, each targeting a specific bias axis such as age, race, or gender. By leveraging their collective strength, SVE outperforms individual steering vectors in both bias reduction and maintaining model performance. The work presents the first systematic investigation of steering vectors for bias mitigation, and we demonstrate that SVE is a powerful and computationally efficient strategy for reducing bias in LLMs, with broader implications for enhancing AI safety.</li>
</ul>

<h3>Title: Leveraging Semantic Type Dependencies for Clinical Named Entity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Linh Le, Guido Zuccon, Gianluca Demartini, Genghong Zhao, Xia Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05373">https://arxiv.org/abs/2503.05373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05373">https://arxiv.org/pdf/2503.05373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05373]] Leveraging Semantic Type Dependencies for Clinical Named Entity Recognition(https://arxiv.org/abs/2503.05373)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Previous work on clinical relation extraction from free-text sentences leveraged information about semantic types from clinical knowledge bases as a part of entity representations. In this paper, we exploit additional evidence by also making use of domain-specific semantic type dependencies. We encode the relation between a span of tokens matching a Unified Medical Language System (UMLS) concept and other tokens in the sentence. We implement our method and compare against different named entity recognition (NER) architectures (i.e., BiLSTM-CRF and BiLSTM-GCN-CRF) using different pre-trained clinical embeddings (i.e., BERT, BioBERT, UMLSBert). Our experimental results on clinical datasets show that in some cases NER effectiveness can be significantly improved by making use of domain-specific semantic type dependencies. Our work is also the first study generating a matrix encoding to make use of more than three dependencies in one pass for the NER task.</li>
</ul>

<h3>Title: Femur: A Flexible Framework for Fast and Secure Querying from Public Key-Value Store</h3>
<ul>
<li><strong>Authors: </strong>Jiaoyi Zhang, Liqiang Peng, Mo Sha, Weiran Liu, Xiang Li, Sheng Wang, Feifei Li, Mingyu Gao, Huanchen Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05376">https://arxiv.org/abs/2503.05376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05376">https://arxiv.org/pdf/2503.05376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05376]] Femur: A Flexible Framework for Fast and Secure Querying from Public Key-Value Store(https://arxiv.org/abs/2503.05376)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect</a></li>
<li><strong>Abstract: </strong>With increasing demands for privacy, it becomes necessary to protect sensitive user query data when accessing public key-value databases. Existing Private Information Retrieval (PIR) schemes provide full security but suffer from poor scalability, limiting their applicability in large-scale deployment. We argue that in many real-world scenarios, a more practical solution should allow users to flexibly determine the privacy levels of their queries in a theoretically guided way, balancing security and performance based on specific needs. To formally provide provable guarantees, we introduce a novel concept of distance-based indistinguishability, which can facilitate users to comfortably relax their security requirements. We then design Femur, an efficient framework to securely query public key-value stores with flexible security and performance trade-offs. It uses a space-efficient learned index to convert query keys into storage locations, obfuscates these locations with extra noise provably derived by the distance-based indistinguishability theory, and sends the expanded range to the server. The server then adaptively utilizes the best scheme to retrieve data. We also propose a novel variable-range PIR scheme optimized for bandwidth-constrained environments. Experiments show that Femur outperforms the state-of-the-art designs even when ensuring the same full security level. When users are willing to relax their privacy requirements, Femur can further improve the performance gains to up to 163.9X, demonstrating an effective trade-off between security and performance.</li>
</ul>

<h3>Title: R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcing Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiaxing Zhao, Xihan Wei, Liefeng Bo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05379">https://arxiv.org/abs/2503.05379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05379">https://arxiv.org/pdf/2503.05379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05379]] R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcing Learning(https://arxiv.org/abs/2503.05379)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In this work, we present the first application of Reinforcement Learning with Verifiable Reward (RLVR) to an Omni-multimodal large language model in the context of emotion recognition, a task where both visual and audio modalities play crucial roles. We leverage RLVR to optimize the Omni model, significantly enhancing its performance in three key aspects: reasoning capability, emotion recognition accuracy, and generalization ability. The introduction of RLVR not only improves the model's overall performance on in-distribution data but also demonstrates superior robustness when evaluated on out-of-distribution datasets. More importantly, the improved reasoning capability enables clear analysis of the contributions of different modalities, particularly visual and audio information, in the emotion recognition process. This provides valuable insights into the optimization of multimodal large language models.</li>
</ul>

<h3>Title: Towards Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients</h3>
<ul>
<li><strong>Authors: </strong>Niklas Penzel, Joachim Denzler</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05424">https://arxiv.org/abs/2503.05424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05424">https://arxiv.org/pdf/2503.05424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05424]] Towards Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients(https://arxiv.org/abs/2503.05424)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Deep learning models achieve high predictive performance but lack intrinsic interpretability, hindering our understanding of the learned prediction behavior. Existing local explainability methods focus on associations, neglecting the causal drivers of model predictions. Other approaches adopt a causal perspective but primarily provide more general global explanations. However, for specific inputs, it's unclear whether globally identified factors apply locally. To address this limitation, we introduce a novel framework for local interventional explanations by leveraging recent advances in image-to-image editing models. Our approach performs gradual interventions on semantic properties to quantify the corresponding impact on a model's predictions using a novel score, the expected property gradient magnitude. We demonstrate the effectiveness of our approach through an extensive empirical evaluation on a wide range of architectures and tasks. First, we validate it in a synthetic scenario and demonstrate its ability to locally identify biases. Afterward, we apply our approach to analyze network training dynamics, investigate medical skin lesion classifiers, and study a pre-trained CLIP model with real-life interventional data. Our results highlight the potential of interventional explanations on the property level to reveal new insights into the behavior of deep models.</li>
</ul>

<h3>Title: An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for Robust Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Navdeep Kaur, Lachlan McPheat, Alessandra Russo, Anthony G Cohn, Pranava Madhyastha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05439">https://arxiv.org/abs/2503.05439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05439">https://arxiv.org/pdf/2503.05439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05439]] An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for Robust Reasoning(https://arxiv.org/abs/2503.05439)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we examine the use of Conformal Language Modelling (CLM) alongside Answer Set Programming (ASP) to enhance the performance of standard open-weight LLMs on complex multi-step reasoning tasks. Using the StepGame dataset, which requires spatial reasoning, we apply CLM to generate sets of ASP programs from an LLM, providing statistical guarantees on the correctness of the outputs. Experimental results show that CLM significantly outperforms baseline models that use standard sampling methods, achieving substantial accuracy improvements across different levels of reasoning complexity. Additionally, the LLM-as-Judge metric enhances CLM's performance, especially in assessing structurally and logically correct ASP outputs. However, calibrating CLM with diverse calibration sets did not improve generalizability for tasks requiring much longer reasoning steps, indicating limitations in handling more complex tasks.</li>
</ul>

<h3>Title: Are Your LLM-based Text-to-SQL Models Secure? Exploring SQL Injection via Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Meiyu Lin, Haichuan Zhang, Jiale Lao, Renyuan Li, Yuanchun Zhou, Carl Yang, Yang Cao, Mingjie Tang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05445">https://arxiv.org/abs/2503.05445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05445">https://arxiv.org/pdf/2503.05445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05445]] Are Your LLM-based Text-to-SQL Models Secure? Exploring SQL Injection via Backdoor Attacks(https://arxiv.org/abs/2503.05445)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, attack, robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown state-of-the-art results in translating natural language questions into SQL queries (Text-to-SQL), a long-standing challenge within the database community. However, security concerns remain largely unexplored, particularly the threat of backdoor attacks, which can introduce malicious behaviors into models through fine-tuning with poisoned datasets. In this work, we systematically investigate the vulnerabilities of LLM-based Text-to-SQL models and present ToxicSQL, a novel backdoor attack framework. Our approach leverages stealthy {semantic and character-level triggers} to make backdoors difficult to detect and remove, ensuring that malicious behaviors remain covert while maintaining high model accuracy on benign inputs. Furthermore, we propose leveraging SQL injection payloads as backdoor targets, enabling the generation of malicious yet executable SQL queries, which pose severe security and privacy risks in language model-based SQL development. We demonstrate that injecting only 0.44% of poisoned data can result in an attack success rate of 79.41%, posing a significant risk to database security. Additionally, we propose detection and mitigation strategies to enhance model reliability. Our findings highlight the urgent need for security-aware Text-to-SQL development, emphasizing the importance of robust defenses against backdoor threats.</li>
</ul>

<h3>Title: Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Weigao Sun, Disen Lan, Tong Zhu, Xiaoye Qu, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05447">https://arxiv.org/abs/2503.05447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05447">https://arxiv.org/pdf/2503.05447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05447]] Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts(https://arxiv.org/abs/2503.05447)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Linear Sequence Modeling (LSM) like linear attention, state space models and linear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant architectural improvements. In this paper, we introduce Linear-MoE, a production-level system for modeling and training large-scale models that integrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules for linear-complexity sequence modeling and MoE layers for sparsely activation, aiming to offer high performance with efficient training. The Linear-MoE system comprises: 1) Modeling subsystem, which provides a unified framework supporting all instances of LSM. and 2) Training subsystem, which facilitates efficient training by incorporating various advanced parallelism technologies, particularly Sequence Parallelism designed for Linear-MoE models. Additionally, we explore hybrid models that combine Linear-MoE layers with standard Transformer-MoE layers with its Sequence Parallelism to further enhance model flexibility and performance. Evaluations on two model series, A0.3B-2B and A1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining competitive performance on various benchmarks, showcasing its potential as a next-generation foundational model architecture. Code: this https URL.</li>
</ul>

<h3>Title: Personalized Federated Learning via Learning Dynamic Graphs</h3>
<ul>
<li><strong>Authors: </strong>Ziran Zhou, Guanyu Gao, Xiaohu Wu, Yan Lyu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05474">https://arxiv.org/abs/2503.05474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05474">https://arxiv.org/pdf/2503.05474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05474]] Personalized Federated Learning via Learning Dynamic Graphs(https://arxiv.org/abs/2503.05474)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Personalized Federated Learning (PFL) aims to train a personalized model for each client that is tailored to its local data distribution, learning fails to perform well on individual clients due to variations in their local data distributions. Most existing PFL methods focus on personalizing the aggregated global model for each client, neglecting the fundamental aspect of federated learning: the regulation of how client models are aggregated. Additionally, almost all of them overlook the graph structure formed by clients in federated learning. In this paper, we propose a novel method, Personalized Federated Learning with Graph Attention Network (pFedGAT), which captures the latent graph structure between clients and dynamically determines the importance of other clients for each client, enabling fine-grained control over the aggregation process. We evaluate pFedGAT across multiple data distribution scenarios, comparing it with twelve state of the art methods on three datasets: Fashion MNIST, CIFAR-10, and CIFAR-100, and find that it consistently performs well.</li>
</ul>

<h3>Title: Enhancing Network Security: A Hybrid Approach for Detection and Mitigation of Distributed Denial-of-Service Attacks Using Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Nizo Jaman Shohan, Gazi Tanbhir, Faria Elahi, Ahsan Ullah, Md. Nazmus Sakib</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05477">https://arxiv.org/abs/2503.05477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05477">https://arxiv.org/pdf/2503.05477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05477]] Enhancing Network Security: A Hybrid Approach for Detection and Mitigation of Distributed Denial-of-Service Attacks Using Machine Learning(https://arxiv.org/abs/2503.05477)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>The distributed denial-of-service (DDoS) attack stands out as a highly formidable cyber threat, representing an advanced form of the denial-of-service (DoS) attack. A DDoS attack involves multiple computers working together to overwhelm a system, making it unavailable. On the other hand, a DoS attack is a one-on-one attempt to make a system or website inaccessible. Thus, it is crucial to construct an effective model for identifying various DDoS incidents. Although extensive research has focused on binary detection models for DDoS identification, they face challenges to adapt evolving threats, necessitating frequent updates. Whereas multiclass detection models offer a comprehensive defense against diverse DDoS attacks, ensuring adaptability in the ever-changing cyber threat landscape. In this paper, we propose a Hybrid Model to strengthen network security by combining the featureextraction abilities of 1D Convolutional Neural Networks (CNNs) with the classification skills of Random Forest (RF) and Multi-layer Perceptron (MLP) classifiers. Using the CIC-DDoS2019 dataset, we perform multiclass classification of various DDoS attacks and conduct a comparative analysis of evaluation metrics for RF, MLP, and our proposed Hybrid Model. After analyzing the results, we draw meaningful conclusions and confirm the superiority of our Hybrid Model by performing thorough cross-validation. Additionally, we integrate our machine learning model with Snort, which provides a robust and adaptive solution for detecting and mitigating various DDoS attacks.</li>
</ul>

<h3>Title: Bridging the Semantic Gap in Virtual Machine Introspection and Forensic Memory Analysis</h3>
<ul>
<li><strong>Authors: </strong>Christofer Fellicious, Hans P. Reiser, Michael Granitzer</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05482">https://arxiv.org/abs/2503.05482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05482">https://arxiv.org/pdf/2503.05482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05482]] Bridging the Semantic Gap in Virtual Machine Introspection and Forensic Memory Analysis(https://arxiv.org/abs/2503.05482)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>Forensic Memory Analysis (FMA) and Virtual Machine Introspection (VMI) are critical tools for security in a virtualization-based approach. VMI and FMA involves using digital forensic methods to extract information from the system to identify and explain security incidents. A key challenge in both FMA and VMI is the "Semantic Gap", which is the difficulty of interpreting raw memory data without specialized tools and expertise. In this work, we investigate how a priori knowledge, metadata and engineered features can aid VMI and FMA, leveraging machine learning to automate information extraction and reduce the workload of forensic investigators. We choose OpenSSH as our use case to test different methods to extract high level structures. We also test our method on complete physical memory dumps to showcase the effectiveness of the engineered features. Our features range from basic statistical features to advanced graph-based representations using malloc headers and pointer translations. The training and testing are carried out on public datasets that we compare against already recognized baseline methods. We show that using metadata, we can improve the performance of the algorithm when there is very little training data and also quantify how having more data results in better generalization performance. The final contribution is an open dataset of physical memory dumps, totalling more than 1 TB of different memory state, software environments, main memory capacities and operating system versions. Our methods show that having more metadata boosts performance with all methods obtaining an F1-Score of over 80%. Our research underscores the possibility of using feature engineering and machine learning techniques to bridge the semantic gap.</li>
</ul>

<h3>Title: KIEval: Evaluation Metric for Document Key Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Minsoo Khang, Sang Chul Jung, Sungrae Park, Teakgyu Hong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05488">https://arxiv.org/abs/2503.05488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05488">https://arxiv.org/pdf/2503.05488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05488]] KIEval: Evaluation Metric for Document Key Information Extraction(https://arxiv.org/abs/2503.05488)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Document Key Information Extraction (KIE) is a technology that transforms valuable information in document images into structured data, and it has become an essential function in industrial settings. However, current evaluation metrics of this technology do not accurately reflect the critical attributes of its industrial applications. In this paper, we present KIEval, a novel application-centric evaluation metric for Document KIE models. Unlike prior metrics, KIEval assesses Document KIE models not just on the extraction of individual information (entity) but also of the structured information (grouping). Evaluation of structured information provides assessment of Document KIE models that are more reflective of extracting grouped information from documents in industrial settings. Designed with industrial application in mind, we believe that KIEval can become a standard evaluation metric for developing or applying Document KIE models in practice. The code will be publicly available.</li>
</ul>

<h3>Title: FastMap: Fast Queries Initialization Based Vectorized HD Map Reconstruction Framework</h3>
<ul>
<li><strong>Authors: </strong>Haotian Hu, Jingwei Xu, Fanyi Wang, Toyota Li, Yaonong Wang, Laifeng Hu, Zhiwang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05492">https://arxiv.org/abs/2503.05492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05492">https://arxiv.org/pdf/2503.05492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05492]] FastMap: Fast Queries Initialization Based Vectorized HD Map Reconstruction Framework(https://arxiv.org/abs/2503.05492)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Reconstruction of high-definition maps is a crucial task in perceiving the autonomous driving environment, as its accuracy directly impacts the reliability of prediction and planning capabilities in downstream modules. Current vectorized map reconstruction methods based on the DETR framework encounter limitations due to the redundancy in the decoder structure, necessitating the stacking of six decoder layers to maintain performance, which significantly hampers computational efficiency. To tackle this issue, we introduce FastMap, an innovative framework designed to reduce decoder redundancy in existing approaches. FastMap optimizes the decoder architecture by employing a single-layer, two-stage transformer that achieves multilevel representation capabilities. Our framework eliminates the conventional practice of randomly initializing queries and instead incorporates a heatmap-guided query generation module during the decoding phase, which effectively maps image features into structured query vectors using learnable positional encoding. Additionally, we propose a geometry-constrained point-to-line loss mechanism for FastMap, which adeptly addresses the challenge of distinguishing highly homogeneous features that often arise in traditional point-to-point loss computations. Extensive experiments demonstrate that FastMap achieves state-of-the-art performance in both nuScenes and Argoverse2 datasets, with its decoder operating 3.2 faster than the baseline. Code and more demos are available at this https URL.</li>
</ul>

<h3>Title: Mol-CADiff: Causality-Aware Autoregressive Diffusion for Molecule Generation</h3>
<ul>
<li><strong>Authors: </strong>Md Atik Ahamed, Qiang Ye, Qiang Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05499">https://arxiv.org/abs/2503.05499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05499">https://arxiv.org/pdf/2503.05499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05499]] Mol-CADiff: Causality-Aware Autoregressive Diffusion for Molecule Generation(https://arxiv.org/abs/2503.05499)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The design of novel molecules with desired properties is a key challenge in drug discovery and materials science. Traditional methods rely on trial-and-error, while recent deep learning approaches have accelerated molecular generation. However, existing models struggle with generating molecules based on specific textual descriptions. We introduce Mol-CADiff, a novel diffusion-based framework that uses causal attention mechanisms for text-conditional molecular generation. Our approach explicitly models the causal relationship between textual prompts and molecular structures, overcoming key limitations in existing methods. We enhance dependency modeling both within and across modalities, enabling precise control over the generation process. Our extensive experiments demonstrate that Mol-CADiff outperforms state-of-the-art methods in generating diverse, novel, and chemically valid molecules, with better alignment to specified properties, enabling more intuitive language-driven molecular design.</li>
</ul>

<h3>Title: EuroBERT: Scaling Multilingual Encoders for European Languages</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Boizard, Hippolyte Gisserot-Boukhlef, Duarte M. Alves, Andr√© Martins, Ayoub Hammal, Caio Corro, C√©line Hudelot, Emmanuel Malherbe, Etienne Malaboeuf, Fanny Jourdan, Gabriel Hautreux, Jo√£o Alves, Kevin El-Haddad, Manuel Faysse, Maxime Peyrard, Nuno M. Guerreiro, Patrick Fernandes, Ricardo Rei, Pierre Colombo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05500">https://arxiv.org/abs/2503.05500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05500">https://arxiv.org/pdf/2503.05500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05500]] EuroBERT: Scaling Multilingual Encoders for European Languages(https://arxiv.org/abs/2503.05500)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>General-purpose multilingual vector representations, used in retrieval, regression and classification, are traditionally obtained from bidirectional encoder models. Despite their wide applicability, encoders have been recently overshadowed by advances in generative decoder-only models. However, many innovations driving this progress are not inherently tied to decoders. In this paper, we revisit the development of multilingual encoders through the lens of these advances, and introduce EuroBERT, a family of multilingual encoders covering European and widely spoken global languages. Our models outperform existing alternatives across a diverse range of tasks, spanning multilingual capabilities, mathematics, and coding, and natively supporting sequences of up to 8,192 tokens. We also examine the design decisions behind EuroBERT, offering insights into our dataset composition and training pipeline. We publicly release the EuroBERT models, including intermediate training checkpoints, together with our training framework.</li>
</ul>

<h3>Title: Statistical Guarantees of Correctness Coverage for Medical Multiple-Choice Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Yusong Ke</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05505">https://arxiv.org/abs/2503.05505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05505">https://arxiv.org/pdf/2503.05505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05505]] Statistical Guarantees of Correctness Coverage for Medical Multiple-Choice Question Answering(https://arxiv.org/abs/2503.05505)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in real-world question-answering (QA) applications. However, LLMs have been proven to generate hallucinations and nonfactual information, undermining their trustworthiness in high-stakes medical tasks. Conformal prediction (CP) is well-known to be model-agnostic and distribution-free, which creates statistically rigorous prediction sets in classification tasks. In this work, we for the first time adapt the CP framework to medical multiple-choice question-answering (MCQA) tasks, by correlating the nonconformity score with the frequency score of correct options grounded in self-consistency theory, assuming no access to internal model information. Considering that the adapted CP framework can only control the (mis)coverage rate, we employ a risk control framework, which can manage task-specific metrics by devising a monotonically decreasing loss function. We evaluate our framework on 3 popular medical MCQA datasets utilizing 4 ``off-the-shelf'' LLMs. Empirical results demonstrate that we achieve user-specified average (or marginal) error rates on the test set. Furthermore, we observe that the average prediction set size (APSS) on the test set decreases as the risk level increases, which concludes a promising evaluation metric for the uncertainty of LLMs.</li>
</ul>

<h3>Title: Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept Representations</h3>
<ul>
<li><strong>Authors: </strong>Eren Erogullari, Sebastian Lapuschkin, Wojciech Samek, Frederik Pahde</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05522">https://arxiv.org/abs/2503.05522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05522">https://arxiv.org/pdf/2503.05522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05522]] Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept Representations(https://arxiv.org/abs/2503.05522)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Concept Activation Vectors (CAVs) are widely used to model human-understandable concepts as directions within the latent space of neural networks. They are trained by identifying directions from the activations of concept samples to those of non-concept samples. However, this method often produces similar, non-orthogonal directions for correlated concepts, such as "beard" and "necktie" within the CelebA dataset, which frequently co-occur in images of men. This entanglement complicates the interpretation of concepts in isolation and can lead to undesired effects in CAV applications, such as activation steering. To address this issue, we introduce a post-hoc concept disentanglement method that employs a non-orthogonality loss, facilitating the identification of orthogonal concept directions while preserving directional correctness. We evaluate our approach with real-world and controlled correlated concepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18 architectures. We further demonstrate the superiority of orthogonalized concept representations in activation steering tasks, allowing (1) the insertion of isolated concepts into input images through generative models and (2) the removal of concepts for effective shortcut suppression with reduced impact on correlated concepts in comparison to baseline CAVs.</li>
</ul>

<h3>Title: S4M: Segment Anything with 4 Extreme Points</h3>
<ul>
<li><strong>Authors: </strong>Adrien Meyer, Lorenzo Arboit, Giuseppe Massimiani, Francesco Brucchi, Luca Emanuele Amodio, Didier Mutter, Nicolas Padoy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05534">https://arxiv.org/abs/2503.05534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05534">https://arxiv.org/pdf/2503.05534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05534]] S4M: Segment Anything with 4 Extreme Points(https://arxiv.org/abs/2503.05534)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM) has revolutionized open-set interactive image segmentation, inspiring numerous adapters for the medical domain. However, SAM primarily relies on sparse prompts such as point or bounding box, which may be suboptimal for fine-grained instance segmentation, particularly in endoscopic imagery, where precise localization is critical and existing prompts struggle to capture object boundaries effectively. To address this, we introduce S4M (Segment Anything with 4 Extreme Points), which augments SAM by leveraging extreme points -- the top-, bottom-, left-, and right-most points of an instance -- prompts. These points are intuitive to identify and provide a faster, structured alternative to box prompts. However, a na√Øve use of extreme points degrades performance, due to SAM's inability to interpret their semantic roles. To resolve this, we introduce dedicated learnable embeddings, enabling the model to distinguish extreme points from generic free-form points and better reason about their spatial relationships. We further propose an auxiliary training task through the Canvas module, which operates solely on prompts -- without vision input -- to predict a coarse instance mask. This encourages the model to internalize the relationship between extreme points and mask distributions, leading to more robust segmentation. S4M outperforms other SAM-based approaches on three endoscopic surgical datasets, demonstrating its effectiveness in complex scenarios. Finally, we validate our approach through a human annotation study on surgical endoscopic videos, confirming that extreme points are faster to acquire than bounding boxes.</li>
</ul>

<h3>Title: Disconnect to Connect: A Data Augmentation Method for Improving Topology Accuracy in Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Juan Miguel Valverde, Maja √òstergaard, Adrian Rodriguez-Palomo, Peter Alling Strange Vibe, Nina K√∏lln Wittig, Henrik Birkedal, Anders Bjorholm Dahl</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05541">https://arxiv.org/abs/2503.05541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05541">https://arxiv.org/pdf/2503.05541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05541]] Disconnect to Connect: A Data Augmentation Method for Improving Topology Accuracy in Image Segmentation(https://arxiv.org/abs/2503.05541)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of thin, tubular structures (e.g., blood vessels) is challenging for deep neural networks. These networks classify individual pixels, and even minor misclassifications can break the thin connections within these structures. Existing methods for improving topology accuracy, such as topology loss functions, rely on very precise, topologically-accurate training labels, which are difficult to obtain. This is because annotating images, especially 3D images, is extremely laborious and time-consuming. Low image resolution and contrast further complicates the annotation by causing tubular structures to appear disconnected. We present CoLeTra, a data augmentation strategy that integrates to the models the prior knowledge that structures that appear broken are actually connected. This is achieved by creating images with the appearance of disconnected structures while maintaining the original labels. Our extensive experiments, involving different architectures, loss functions, and datasets, demonstrate that CoLeTra leads to segmentations topologically more accurate while often improving the Dice coefficient and Hausdorff distance. CoLeTra's hyper-parameters are intuitive to tune, and our sensitivity analysis shows that CoLeTra is robust to changes in these hyper-parameters. We also release a dataset specifically suited for image segmentation methods with a focus on topology accuracy. CoLetra's code can be found at this https URL.</li>
</ul>

<h3>Title: Stereo Any Video: Temporally Consistent Stereo Matching</h3>
<ul>
<li><strong>Authors: </strong>Junpeng Jing, Weixun Luo, Ye Mao, Krystian Mikolajczyk</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05549">https://arxiv.org/abs/2503.05549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05549">https://arxiv.org/pdf/2503.05549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05549]] Stereo Any Video: Temporally Consistent Stereo Matching(https://arxiv.org/abs/2503.05549)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces Stereo Any Video, a powerful framework for video stereo matching. It can estimate spatially accurate and temporally consistent disparities without relying on auxiliary information such as camera poses or optical flow. The strong capability is driven by rich priors from monocular video depth models, which are integrated with convolutional features to produce stable representations. To further enhance performance, key architectural innovations are introduced: all-to-all-pairs correlation, which constructs smooth and robust matching cost volumes, and temporal convex upsampling, which improves temporal coherence. These components collectively ensure robustness, accuracy, and temporal consistency, setting a new standard in video stereo matching. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple datasets both qualitatively and quantitatively in zero-shot settings, as well as strong generalization to real-world indoor and outdoor scenarios.</li>
</ul>

<h3>Title: Revitalizing Saturated Benchmarks: A Weighted Metric Approach for Differentiating Large Language Model Performance</h3>
<ul>
<li><strong>Authors: </strong>Bryan Etzine, Masoud Hashemi, Nishanth Madhusudhan, Sagar Davasam, Roshnee Sharma, Sathwik Tejaswi Madhusudhan, Vikas Yadav</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05551">https://arxiv.org/abs/2503.05551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05551">https://arxiv.org/pdf/2503.05551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05551]] Revitalizing Saturated Benchmarks: A Weighted Metric Approach for Differentiating Large Language Model Performance(https://arxiv.org/abs/2503.05551)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing benchmarks are becoming saturated and struggle to separate model performances due to factors like data contamination and advancing LLM capabilities. This paper introduces EMDM (Enhanced Model Differentiation Metric), a novel weighted metric that revitalizes benchmarks by enhancing model separation. EMDM integrates final answer and Chain-of-Thought (CoT) reasoning correctness, assigning weights based on the complexity and reasoning depth required to solve a given sample in the evaluation data. Using a baseline LLM in two setups-Unguided, where the model has no prior exposure to test samples, and Guided, where the model has prior knowledge of the desired answer-EMDM distinguishes instances of varying difficulty. The CoT and answer correctness from these setups inform an optimization objective for weight assignment, resulting in a more nuanced evaluation of model performance. Compared to the exact match (EM) metric, which achieves 17% separation on ARC-Challenge, EMDM achieves 46%, demonstrating its effectiveness in differentiating models based on reasoning and knowledge requirements.</li>
</ul>

<h3>Title: Diffusion Models for Cayley Graphs</h3>
<ul>
<li><strong>Authors: </strong>Michael R. Douglas, Cristofero Fraser-Taliente</a></li>
<li><strong>Subjects: </strong>cs.LG, math.CO, math.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05558">https://arxiv.org/abs/2503.05558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05558">https://arxiv.org/pdf/2503.05558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05558]] Diffusion Models for Cayley Graphs(https://arxiv.org/abs/2503.05558)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We review the problem of finding paths in Cayley graphs of groups and group actions, using the Rubik's cube as an example, and we list several more examples of significant mathematical interest. We then show how to formulate these problems in the framework of diffusion models. The exploration of the graph is carried out by the forward process, while finding the target nodes is done by the inverse backward process. This systematizes the discussion and suggests many generalizations. To improve exploration, we propose a ``reversed score'' ansatz which substantially improves over previous comparable algorithms.</li>
</ul>

<h3>Title: TomatoScanner: phenotyping tomato fruit based on only RGB image</h3>
<ul>
<li><strong>Authors: </strong>Xiaobei Zhao (1), Xiangrong Zeng (1), Yihang Ma (1), Pengjin Tang (1), Xiang Li (1) ((1) China Agricultural University)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05568">https://arxiv.org/abs/2503.05568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05568">https://arxiv.org/pdf/2503.05568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05568]] TomatoScanner: phenotyping tomato fruit based on only RGB image(https://arxiv.org/abs/2503.05568)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In tomato greenhouse, phenotypic measurement is meaningful for researchers and farmers to monitor crop growth, thereby precisely control environmental conditions in time, leading to better quality and higher yield. Traditional phenotyping mainly relies on manual measurement, which is accurate but inefficient, more importantly, endangering the health and safety of people. Several studies have explored computer vision-based methods to replace manual phenotyping. However, the 2D-based need extra calibration, or cause destruction to fruit, or can only measure limited and meaningless traits. The 3D-based need extra depth camera, which is expensive and unacceptable for most farmers. In this paper, we propose a non-contact tomato fruit phenotyping method, titled TomatoScanner, where RGB image is all you need for input. First, pixel feature is extracted by instance segmentation of our proposed EdgeYOLO with preprocessing of individual separation and pose correction. Second, depth feature is extracted by depth estimation of Depth Pro. Third, pixel and depth feature are fused to output phenotype results in reality. We establish self-built Tomato Phenotype Dataset to test TomatoScanner, which achieves excellent phenotyping on width, height, vertical area and volume, with median relative error of 5.63%, 7.03%, -0.64% and 37.06%, respectively. We propose and add three innovative modules - EdgeAttention, EdgeLoss and EdgeBoost - into EdgeYOLO, to enhance the segmentation accuracy on edge portion. Precision and mean Edge Error greatly improve from 0.943 and 5.641% to 0.986 and 2.963%, respectively. Meanwhile, EdgeYOLO keeps lightweight and efficient, with 48.7 M weights size and 76.34 FPS. Codes and datasets: this https URL.</li>
</ul>

<h3>Title: MPTSNet: Integrating Multiscale Periodic Local Patterns and Global Dependencies for Multivariate Time Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Yang Mu, Muhammad Shahzad, Xiao Xiang Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05582">https://arxiv.org/abs/2503.05582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05582">https://arxiv.org/pdf/2503.05582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05582]] MPTSNet: Integrating Multiscale Periodic Local Patterns and Global Dependencies for Multivariate Time Series Classification(https://arxiv.org/abs/2503.05582)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Multivariate Time Series Classification (MTSC) is crucial in extensive practical applications, such as environmental monitoring, medical EEG analysis, and action recognition. Real-world time series datasets typically exhibit complex dynamics. To capture this complexity, RNN-based, CNN-based, Transformer-based, and hybrid models have been proposed. Unfortunately, current deep learning-based methods often neglect the simultaneous construction of local features and global dependencies at different time scales, lacking sufficient feature extraction capabilities to achieve satisfactory classification accuracy. To address these challenges, we propose a novel Multiscale Periodic Time Series Network (MPTSNet), which integrates multiscale local patterns and global correlations to fully exploit the inherent information in time series. Recognizing the multi-periodicity and complex variable correlations in time series, we use the Fourier transform to extract primary periods, enabling us to decompose data into multiscale periodic segments. Leveraging the inherent strengths of CNN and attention mechanism, we introduce the PeriodicBlock, which adaptively captures local patterns and global dependencies while offering enhanced interpretability through attention integration across different periodic scales. The experiments on UEA benchmark datasets demonstrate that the proposed MPTSNet outperforms 21 existing advanced baselines in the MTSC tasks.</li>
</ul>

<h3>Title: QArtSR: Quantization via Reverse-Module and Timestep-Retraining in One-Step Diffusion based Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Libo Zhu, Haotong Qin, Kaicheng Yang, Wenbo Li, Yong Guo, Yulun Zhang, Susanto Rahardja, Xiaokang Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05584">https://arxiv.org/abs/2503.05584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05584">https://arxiv.org/pdf/2503.05584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05584]] QArtSR: Quantization via Reverse-Module and Timestep-Retraining in One-Step Diffusion based Image Super-Resolution(https://arxiv.org/abs/2503.05584)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>One-step diffusion-based image super-resolution (OSDSR) models are showing increasingly superior performance nowadays. However, although their denoising steps are reduced to one and they can be quantized to 8-bit to reduce the costs further, there is still significant potential for OSDSR to quantize to lower bits. To explore more possibilities of quantized OSDSR, we propose an efficient method, Quantization via reverse-module and timestep-retraining for OSDSR, named QArtSR. Firstly, we investigate the influence of timestep value on the performance of quantized models. Then, we propose Timestep Retraining Quantization (TRQ) and Reversed Per-module Quantization (RPQ) strategies to calibrate the quantized model. Meanwhile, we adopt the module and image losses to update all quantized modules. We only update the parameters in quantization finetuning components, excluding the original weights. To ensure that all modules are fully finetuned, we add extended end-to-end training after per-module stage. Our 4-bit and 2-bit quantization experimental results indicate that QArtSR obtains superior effects against the recent leading comparison methods. The performance of 4-bit QArtSR is close to the full-precision one. Our code will be released at this https URL.</li>
</ul>

<h3>Title: Quantifying the Robustness of Retrieval-Augmented Language Models Against Spurious Features in Grounding Data</h3>
<ul>
<li><strong>Authors: </strong>Shiping Yang, Jie Wu, Wenbiao Ding, Ning Wu, Shining Liang, Ming Gong, Hengyuan Zhang, Dongmei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05587">https://arxiv.org/abs/2503.05587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05587">https://arxiv.org/pdf/2503.05587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05587]] Quantifying the Robustness of Retrieval-Augmented Language Models Against Spurious Features in Grounding Data(https://arxiv.org/abs/2503.05587)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robustness has become a critical attribute for the deployment of RAG systems in real-world applications. Existing research focuses on robustness to explicit noise (e.g., document semantics) but overlooks spurious features (a.k.a. implicit noise). While previous works have explored spurious features in LLMs, they are limited to specific features (e.g., formats) and narrow scenarios (e.g., ICL). In this work, we statistically confirm the presence of spurious features in the RAG paradigm, a robustness problem caused by the sensitivity of LLMs to semantic-agnostic features. Moreover, we provide a comprehensive taxonomy of spurious features and empirically quantify their impact through controlled experiments. Further analysis reveals that not all spurious features are harmful and they can even be beneficial sometimes. Extensive evaluation results across multiple LLMs suggest that spurious features are a widespread and challenging problem in the field of RAG. The code and dataset will be released to facilitate future research. We release all codes and data at: $\\\href{this https URL}{this https URL}$.</li>
</ul>

<h3>Title: Anti-Diffusion: Preventing Abuse of Modifications of Diffusion-Based Models</h3>
<ul>
<li><strong>Authors: </strong>Zheng Li, Liangbin Xie, Jiantao Zhou, Xintao Wang, Haiwei Wu, Jinyu Tian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05595">https://arxiv.org/abs/2503.05595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05595">https://arxiv.org/pdf/2503.05595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05595]] Anti-Diffusion: Preventing Abuse of Modifications of Diffusion-Based Models(https://arxiv.org/abs/2503.05595)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, diffusion</a></li>
<li><strong>Abstract: </strong>Although diffusion-based techniques have shown remarkable success in image generation and editing tasks, their abuse can lead to severe negative social impacts. Recently, some works have been proposed to provide defense against the abuse of diffusion-based methods. However, their protection may be limited in specific scenarios by manually defined prompts or the stable diffusion (SD) version. Furthermore, these methods solely focus on tuning methods, overlooking editing methods that could also pose a significant threat. In this work, we propose Anti-Diffusion, a privacy protection system designed for general diffusion-based methods, applicable to both tuning and editing techniques. To mitigate the limitations of manually defined prompts on defense performance, we introduce the prompt tuning (PT) strategy that enables precise expression of original images. To provide defense against both tuning and editing methods, we propose the semantic disturbance loss (SDL) to disrupt the semantic information of protected images. Given the limited research on the defense against editing methods, we develop a dataset named Defense-Edit to assess the defense performance of various methods. Experiments demonstrate that our Anti-Diffusion achieves superior defense performance across a wide range of diffusion-based techniques in different scenarios.</li>
</ul>

<h3>Title: D2GV: Deformable 2D Gaussian Splatting for Video Representation in 400FPS</h3>
<ul>
<li><strong>Authors: </strong>Mufan Liu, Qi Yang, Miaoran Zhao, He Huang, Le Yang, Zhu Li, Yiling Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05600">https://arxiv.org/abs/2503.05600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05600">https://arxiv.org/pdf/2503.05600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05600]] D2GV: Deformable 2D Gaussian Splatting for Video Representation in 400FPS(https://arxiv.org/abs/2503.05600)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Implicit Neural Representations (INRs) have emerged as a powerful approach for video representation, offering versatility across tasks such as compression and inpainting. However, their implicit formulation limits both interpretability and efficacy, undermining their practicality as a comprehensive solution. We propose a novel video representation based on deformable 2D Gaussian splatting, dubbed D2GV, which aims to achieve three key objectives: 1) improved efficiency while delivering superior quality; 2) enhanced scalability and interpretability; and 3) increased friendliness for downstream tasks. Specifically, we initially divide the video sequence into fixed-length Groups of Pictures (GoP) to allow parallel training and linear scalability with video length. For each GoP, D2GV represents video frames by applying differentiable rasterization to 2D Gaussians, which are deformed from a canonical space into their corresponding timestamps. Notably, leveraging efficient CUDA-based rasterization, D2GV converges fast and decodes at speeds exceeding 400 FPS, while delivering quality that matches or surpasses state-of-the-art INRs. Moreover, we incorporate a learnable pruning and quantization strategy to streamline D2GV into a more compact representation. We demonstrate D2GV's versatility in tasks including video interpolation, inpainting and denoising, underscoring its potential as a promising solution for video representation. Code is available at: \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment and Classification of Ultrasound Images Using Deep Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Hanae Elmekki, Ahmed Alagha, Hani Sami, Amanda Spilkin, Antonela Mariel Zanuttini, Ehsan Zakeri, Jamal Bentahar, Lyes Kadem, Wen-Fang Xie, Philippe Pibarot, Rabeb Mizouni, Hadi Otrok, Shakti Singh, Azzam Mourad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05604">https://arxiv.org/abs/2503.05604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05604">https://arxiv.org/pdf/2503.05604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05604]] CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment and Classification of Ultrasound Images Using Deep Transfer Learning(https://arxiv.org/abs/2503.05604)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cardiac ultrasound (US) scanning is a commonly used techniques in cardiology to diagnose the health of the heart and its proper functioning. Therefore, it is necessary to consider ways to automate these tasks and assist medical professionals in classifying and assessing cardiac US images. Machine learning (ML) techniques are regarded as a prominent solution due to their success in numerous applications aimed at enhancing the medical field, including addressing the shortage of echography technicians. However, the limited availability of medical data presents a significant barrier to applying ML in cardiology, particularly regarding US images of the heart. This paper addresses this challenge by introducing the first open graded dataset for Cardiac Assessment and ClassificaTion of UltraSound (CACTUS), which is available online. This dataset contains images obtained from scanning a CAE Blue Phantom and representing various heart views and different quality levels, exceeding the conventional cardiac views typically found in the literature. Additionally, the paper introduces a Deep Learning (DL) framework consisting of two main components. The first component classifies cardiac US images based on the heart view using a Convolutional Neural Network (CNN). The second component uses Transfer Learning (TL) to fine-tune the knowledge from the first component and create a model for grading and assessing cardiac images. The framework demonstrates high performance in both classification and grading, achieving up to 99.43% accuracy and as low as 0.3067 error, respectively. To showcase its robustness, the framework is further fine-tuned using new images representing additional cardiac views and compared to several other state-of-the-art architectures. The framework's outcomes and performance in handling real-time scans were also assessed using a questionnaire answered by cardiac experts.</li>
</ul>

<h3>Title: AceWGS: An LLM-Aided Framework to Accelerate Catalyst Design for Water-Gas Shift Reactions</h3>
<ul>
<li><strong>Authors: </strong>Joyjit Chattoraj, Brahim Hamadicharef, Teo Shi Chang, Yingzhi Zeng, Chee Kok Poh, Luwei Chen, Teck Leong Tan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05607">https://arxiv.org/abs/2503.05607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05607">https://arxiv.org/pdf/2503.05607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05607]] AceWGS: An LLM-Aided Framework to Accelerate Catalyst Design for Water-Gas Shift Reactions(https://arxiv.org/abs/2503.05607)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While the Water-Gas Shift (WGS) reaction plays a crucial role in hydrogen production for fuel cells, finding suitable catalysts to achieve high yields for low-temperature WGS reactions remains a persistent challenge. Artificial Intelligence (AI) has shown promise in accelerating catalyst design by exploring vast candidate spaces, however, two key gaps limit its effectiveness. First, AI models primarily train on numerical data, which fail to capture essential text-based information, such as catalyst synthesis methods. Second, the cross-disciplinary nature of catalyst design requires seamless collaboration between AI, theory, experiments, and numerical simulations, often leading to communication barriers. To address these gaps, we present AceWGS, a Large Language Models (LLMs)-aided framework to streamline WGS catalyst design. AceWGS interacts with researchers through natural language, answering queries based on four features: (i) answering general queries, (ii) extracting information about the database comprising WGS-related journal articles, (iii) comprehending the context described in these articles, and (iv) identifying catalyst candidates using our proposed AI inverse model. We presented a practical case study demonstrating how AceWGS can accelerate the catalyst design process. AceWGS, built with open-source tools, offers an adjustable framework that researchers can readily adapt for a range of AI-accelerated catalyst design applications, supporting seamless integration across cross-disciplinary studies.</li>
</ul>

<h3>Title: A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dong Shu, Xuansheng Wu, Haiyan Zhao, Daking Rai, Ziyu Yao, Ninghao Liu, Mengnan Du</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05613">https://arxiv.org/abs/2503.05613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05613">https://arxiv.org/pdf/2503.05613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05613]] A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models(https://arxiv.org/abs/2503.05613)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized natural language processing, yet their internal mechanisms remain largely opaque. Recently, mechanistic interpretability has attracted significant attention from the research community as a means to understand the inner workings of LLMs. Among various mechanistic interpretability approaches, Sparse Autoencoders (SAEs) have emerged as a particularly promising method due to their ability to disentangle the complex, superimposed features within LLMs into more interpretable components. This paper presents a comprehensive examination of SAEs as a promising approach to interpreting and understanding LLMs. We provide a systematic overview of SAE principles, architectures, and applications specifically tailored for LLM analysis, covering theoretical foundations, implementation strategies, and recent developments in sparsity mechanisms. We also explore how SAEs can be leveraged to explain the internal workings of LLMs, steer model behaviors in desired directions, and develop more transparent training methodologies for future models. Despite the challenges that remain around SAE implementation and scaling, they continue to provide valuable tools for understanding the internal mechanisms of large language models.</li>
</ul>

<h3>Title: Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as hyperelastic constitutive artificial neural networks (CANs)</h3>
<ul>
<li><strong>Authors: </strong>Prakash Thakolkaran, Yaqi Guo, Shivam Saini, Mathias Peirlinck, Benjamin Alheit, Siddhant Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05617">https://arxiv.org/abs/2503.05617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05617">https://arxiv.org/pdf/2503.05617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05617]] Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as hyperelastic constitutive artificial neural networks (CANs)(https://arxiv.org/abs/2503.05617)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Traditional constitutive models rely on hand-crafted parametric forms with limited expressivity and generalizability, while neural network-based models can capture complex material behavior but often lack interpretability. To balance these trade-offs, we present Input-Convex Kolmogorov-Arnold Networks (ICKANs) for learning polyconvex hyperelastic constitutive laws. ICKANs leverage the Kolmogorov-Arnold representation, decomposing the model into compositions of trainable univariate spline-based activation functions for rich expressivity. We introduce trainable input-convex splines within the KAN architecture, ensuring physically admissible polyconvex hyperelastic models. The resulting models are both compact and interpretable, enabling explicit extraction of analytical constitutive relationships through an input-convex symbolic regression techinque. Through unsupervised training on full-field strain data and limited global force measurements, ICKANs accurately capture nonlinear stress-strain behavior across diverse strain states. Finite element simulations of unseen geometries with trained ICKAN hyperelastic constitutive models confirm the framework's robustness and generalization capability.</li>
</ul>

<h3>Title: Conformal Prediction for Image Segmentation Using Morphological Prediction Sets</h3>
<ul>
<li><strong>Authors: </strong>Luca Mossina, Corentin Friedrich</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05618">https://arxiv.org/abs/2503.05618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05618">https://arxiv.org/pdf/2503.05618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05618]] Conformal Prediction for Image Segmentation Using Morphological Prediction Sets(https://arxiv.org/abs/2503.05618)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Image segmentation is a challenging task influenced by multiple sources of uncertainty, such as the data labeling process or the sampling of training data. In this paper we focus on binary segmentation and address these challenges using conformal prediction, a family of model- and data-agnostic methods for uncertainty quantification that provide finite-sample theoretical guarantees and applicable to any pretrained predictor. Our approach involves computing nonconformity scores, a type of prediction residual, on held-out calibration data not used during training. We use dilation, one of the fundamental operations in mathematical morphology, to construct a margin added to the borders of predicted segmentation masks. At inference, the predicted set formed by the mask and its margin contains the ground-truth mask with high probability, at a confidence level specified by the user. The size of the margin serves as an indicator of predictive uncertainty for a given model and dataset. We work in a regime of minimal information as we do not require any feedback from the predictor: only the predicted masks are needed for computing the prediction sets. Hence, our method is applicable to any segmentation model, including those based on deep learning; we evaluate our approach on several medical imaging applications.</li>
</ul>

<h3>Title: Learning LLM Preference over Intra-Dialogue Pairs: A Framework for Utterance-level Understandings</h3>
<ul>
<li><strong>Authors: </strong>Xuanqing Liu, Luyang Kong, Wei Niu, Afshin Khashei, Belinda Zeng, Steve Johnson, Jon Jay, Davor Golac, Matt Pope</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05620">https://arxiv.org/abs/2503.05620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05620">https://arxiv.org/pdf/2503.05620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05620]] Learning LLM Preference over Intra-Dialogue Pairs: A Framework for Utterance-level Understandings(https://arxiv.org/abs/2503.05620)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in handling complex dialogue tasks without requiring use case-specific fine-tuning. However, analyzing live dialogues in real-time necessitates low-latency processing systems, making it impractical to deploy models with billions of parameters due to latency constraints. As a result, practitioners often prefer smaller models with millions of parameters, trained on high-quality, human-annotated datasets. Yet, curating such datasets is both time-consuming and costly. Consequently, there is a growing need to combine the scalability of LLM-generated labels with the precision of human annotations, enabling fine-tuned smaller models to achieve both higher speed and accuracy comparable to larger models. In this paper, we introduce a simple yet effective framework to address this challenge. Our approach is specifically designed for per-utterance classification problems, which encompass tasks such as intent detection, dialogue state tracking, and more. To mitigate the impact of labeling errors from LLMs -- the primary source of inaccuracies in student models -- we propose a noise-reduced preference learning loss. Experimental results demonstrate that our method significantly improves accuracy across utterance-level dialogue tasks, including sentiment detection (over $2\%$), dialogue act classification (over $1.5\%$), etc.</li>
</ul>

<h3>Title: FMT:A Multimodal Pneumonia Detection Model Based on Stacking MOE Framework</h3>
<ul>
<li><strong>Authors: </strong>Jingyu Xu, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05626">https://arxiv.org/abs/2503.05626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05626">https://arxiv.org/pdf/2503.05626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05626]] FMT:A Multimodal Pneumonia Detection Model Based on Stacking MOE Framework(https://arxiv.org/abs/2503.05626)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Artificial intelligence has shown the potential to improve diagnostic accuracy through medical image analysis for pneumonia diagnosis. However, traditional multimodal approaches often fail to address real-world challenges such as incomplete data and modality loss. In this study, a Flexible Multimodal Transformer (FMT) was proposed, which uses ResNet-50 and BERT for joint representation learning, followed by a dynamic masked attention strategy that simulates clinical modality loss to improve robustness; finally, a sequential mixture of experts (MOE) architecture was used to achieve multi-level decision refinement. After evaluation on a small multimodal pneumonia dataset, FMT achieved state-of-the-art performance with 94% accuracy, 95% recall, and 93% F1 score, outperforming single-modal baselines (ResNet: 89%; BERT: 79%) and the medical benchmark CheXMed (90%), providing a scalable solution for multimodal diagnosis of pneumonia in resource-constrained medical settings.</li>
</ul>

<h3>Title: Strategy Coopetition Explains the Emergence and Transience of In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Aaditya K. Singh, Ted Moskovitz, Sara Dragutinovic, Felix Hill, Stephanie C.Y. Chan, Andrew M. Saxe</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05631">https://arxiv.org/abs/2503.05631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05631">https://arxiv.org/pdf/2503.05631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05631]] Strategy Coopetition Explains the Emergence and Transience of In-Context Learning(https://arxiv.org/abs/2503.05631)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) is a powerful ability that emerges in transformer models, enabling them to learn from context without weight updates. Recent work has established emergent ICL as a transient phenomenon that can sometimes disappear after long training times. In this work, we sought a mechanistic understanding of these transient dynamics. Firstly, we find that, after the disappearance of ICL, the asymptotic strategy is a remarkable hybrid between in-weights and in-context learning, which we term "context-constrained in-weights learning" (CIWL). CIWL is in competition with ICL, and eventually replaces it as the dominant strategy of the model (thus leading to ICL transience). However, we also find that the two competing strategies actually share sub-circuits, which gives rise to cooperative dynamics as well. For example, in our setup, ICL is unable to emerge quickly on its own, and can only be enabled through the simultaneous slow development of asymptotic CIWL. CIWL thus both cooperates and competes with ICL, a phenomenon we term "strategy coopetition." We propose a minimal mathematical model that reproduces these key dynamics and interactions. Informed by this model, we were able to identify a setup where ICL is truly emergent and persistent.</li>
</ul>

<h3>Title: TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Mark YU, Wenbo Hu, Jinbo Xing, Ying Shan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05638">https://arxiv.org/abs/2503.05638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05638">https://arxiv.org/pdf/2503.05638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05638]] TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models(https://arxiv.org/abs/2503.05638)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We present TrajectoryCrafter, a novel approach to redirect camera trajectories for monocular videos. By disentangling deterministic view transformations from stochastic content generation, our method achieves precise control over user-specified camera trajectories. We propose a novel dual-stream conditional video diffusion model that concurrently integrates point cloud renders and source videos as conditions, ensuring accurate view transformations and coherent 4D content generation. Instead of leveraging scarce multi-view videos, we curate a hybrid training dataset combining web-scale monocular videos with static multi-view datasets, by our innovative double-reprojection strategy, significantly fostering robust generalization across diverse scenes. Extensive evaluations on multi-view and large-scale monocular videos demonstrate the superior performance of our method.</li>
</ul>

<h3>Title: VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Bian, Zhaoyang Zhang, Xuan Ju, Mingdeng Cao, Liangbin Xie, Ying Shan, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05639">https://arxiv.org/abs/2503.05639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05639">https://arxiv.org/pdf/2503.05639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05639]] VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control(https://arxiv.org/abs/2503.05639)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Video inpainting, which aims to restore corrupted video content, has experienced substantial progress. Despite these advances, existing methods, whether propagating unmasked region pixels through optical flow and receptive field priors, or extending image-inpainting models temporally, face challenges in generating fully masked objects or balancing the competing objectives of background context preservation and foreground generation in one model, respectively. To address these limitations, we propose a novel dual-stream paradigm VideoPainter that incorporates an efficient context encoder (comprising only 6% of the backbone parameters) to process masked videos and inject backbone-aware background contextual cues to any pre-trained video DiT, producing semantically consistent content in a plug-and-play manner. This architectural separation significantly reduces the model's learning complexity while enabling nuanced integration of crucial background context. We also introduce a novel target region ID resampling technique that enables any-length video inpainting, greatly enhancing our practical applicability. Additionally, we establish a scalable dataset pipeline leveraging current vision understanding models, contributing VPData and VPBench to facilitate segmentation-based inpainting training and assessment, the largest video inpainting dataset and benchmark to date with over 390K diverse clips. Using inpainting as a pipeline basis, we also explore downstream applications including video editing and video editing pair data generation, demonstrating competitive performance and significant practical potential. Extensive experiments demonstrate VideoPainter's superior performance in both any-length video inpainting and editing, across eight key metrics, including video quality, mask region preservation, and textual coherence.</li>
</ul>

<h3>Title: Physics-based machine learning framework for predicting NOx emissions from compression ignition engines using on-board diagnostics data</h3>
<ul>
<li><strong>Authors: </strong>Harish Panneer Selvam, Bharat Jayaprakash, Yan Li, Shashi Shekhar, William F. Northrop</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05648">https://arxiv.org/abs/2503.05648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05648">https://arxiv.org/pdf/2503.05648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05648]] Physics-based machine learning framework for predicting NOx emissions from compression ignition engines using on-board diagnostics data(https://arxiv.org/abs/2503.05648)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This work presents a physics-based machine learning framework to predict and analyze oxides of nitrogen (NOx) emissions from compression-ignition engine-powered vehicles using on-board diagnostics (OBD) data as input. Accurate NOx prediction from OBD datasets is difficult because NOx formation inside an engine combustion chamber is governed by complex processes occurring on timescales much shorter than the data collection rate. Thus, emissions generally cannot be predicted accurately using simple empirically derived physics models. Black box models like genetic algorithms or neural networks can be more accurate, but have poor interpretability. The transparent model presented in this paper has both high accuracy and can explain potential sources of high emissions. The proposed framework consists of two major steps: a physics-based NOx prediction model combined with a novel Divergent Window Co-occurrence (DWC) Pattern detection algorithm to analyze operating conditions that are not adequately addressed by the physics-based model. The proposed framework is validated for generalizability with a second vehicle OBD dataset, a sensitivity analysis is performed, and model predictions are compared with that from a deep neural network. The results show that NOx emissions predictions using the proposed model has around 55% better root mean square error, and around 60% higher mean absolute error compared to the baseline NOx prediction model from previously published work. The DWC Pattern Detection Algorithm identified low engine power conditions to have high statistical significance, indicating an operating regime where the model can be improved. This work shows that the physics-based machine learning framework is a viable method for predicting NOx emissions from engines that do not incorporate NOx sensing.</li>
</ul>

<h3>Title: NoT: Federated Unlearning via Weight Negation</h3>
<ul>
<li><strong>Authors: </strong>Yasser H. Khalil, Leo Brunswic, Soufiane Lamghari, Xu Li, Mahdi Beitollahi, Xi Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05657">https://arxiv.org/abs/2503.05657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05657">https://arxiv.org/pdf/2503.05657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05657]] NoT: Federated Unlearning via Weight Negation(https://arxiv.org/abs/2503.05657)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated unlearning (FU) aims to remove a participant's data contributions from a trained federated learning (FL) model, ensuring privacy and regulatory compliance. Traditional FU methods often depend on auxiliary storage on either the client or server side or require direct access to the data targeted for removal-a dependency that may not be feasible if the data is no longer available. To overcome these limitations, we propose NoT, a novel and efficient FU algorithm based on weight negation (multiplying by -1), which circumvents the need for additional storage and access to the target data. We argue that effective and efficient unlearning can be achieved by perturbing model parameters away from the set of optimal parameters, yet being well-positioned for quick re-optimization. This technique, though seemingly contradictory, is theoretically grounded: we prove that the weight negation perturbation effectively disrupts inter-layer co-adaptation, inducing unlearning while preserving an approximate optimality property, thereby enabling rapid recovery. Experimental results across three datasets and three model architectures demonstrate that NoT significantly outperforms existing baselines in unlearning efficacy as well as in communication and computational efficiency.</li>
</ul>

<h3>Title: AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning Biased Models with Contextual Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Zengqun Zhao, Ziquan Liu, Yu Cao, Shaogang Gong, Ioannis Patras</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05665">https://arxiv.org/abs/2503.05665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05665">https://arxiv.org/pdf/2503.05665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05665]] AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning Biased Models with Contextual Synthetic Data(https://arxiv.org/abs/2503.05665)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative models have sparked research on improving model fairness with AI-generated data. However, existing methods often face limitations in the diversity and quality of synthetic data, leading to compromised fairness and overall model accuracy. Moreover, many approaches rely on the availability of demographic group labels, which are often costly to annotate. This paper proposes AIM-Fair, aiming to overcome these limitations and harness the potential of cutting-edge generative models in promoting algorithmic fairness. We investigate a fine-tuning paradigm starting from a biased model initially trained on real-world data without demographic annotations. This model is then fine-tuned using unbiased synthetic data generated by a state-of-the-art diffusion model to improve its fairness. Two key challenges are identified in this fine-tuning paradigm, 1) the low quality of synthetic data, which can still happen even with advanced generative models, and 2) the domain and bias gap between real and synthetic data. To address the limitation of synthetic data quality, we propose Contextual Synthetic Data Generation (CSDG) to generate data using a text-to-image diffusion model (T2I) with prompts generated by a context-aware LLM, ensuring both data diversity and control of bias in synthetic data. To resolve domain and bias shifts, we introduce a novel selective fine-tuning scheme in which only model parameters more sensitive to bias and less sensitive to domain shift are updated. Experiments on CelebA and UTKFace datasets show that our AIM-Fair improves model fairness while maintaining utility, outperforming both fully and partially fine-tuned approaches to model fairness.</li>
</ul>

<h3>Title: Algorithmic Data Minimization for Machine Learning over Internet-of-Things Data Streams</h3>
<ul>
<li><strong>Authors: </strong>Ted Shaowang, Shinan Liu, Jonatas Marques, Nick Feamster, Sanjay Krishnan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05675">https://arxiv.org/abs/2503.05675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05675">https://arxiv.org/pdf/2503.05675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05675]] Algorithmic Data Minimization for Machine Learning over Internet-of-Things Data Streams(https://arxiv.org/abs/2503.05675)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Machine learning can analyze vast amounts of data generated by IoT devices to identify patterns, make predictions, and enable real-time decision-making. By processing sensor data, machine learning models can optimize processes, improve efficiency, and enhance personalized user experiences in smart systems. However, IoT systems are often deployed in sensitive environments such as households and offices, where they may inadvertently expose identifiable information, including location, habits, and personal identifiers. This raises significant privacy concerns, necessitating the application of data minimization -- a foundational principle in emerging data regulations, which mandates that service providers only collect data that is directly relevant and necessary for a specified purpose. Despite its importance, data minimization lacks a precise technical definition in the context of sensor data, where collections of weak signals make it challenging to apply a binary "relevant and necessary" rule. This paper provides a technical interpretation of data minimization in the context of sensor streams, explores practical methods for implementation, and addresses the challenges involved. Through our approach, we demonstrate that our framework can reduce user identifiability by up to 16.7% while maintaining accuracy loss below 1%, offering a viable path toward privacy-preserving IoT data processing.</li>
</ul>

<h3>Title: Understanding the Limits of Lifelong Knowledge Editing in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Lukas Thede, Karsten Roth, Matthias Bethge, Zeynep Akata, Tom Hartvigsen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05683">https://arxiv.org/abs/2503.05683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05683">https://arxiv.org/pdf/2503.05683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05683]] Understanding the Limits of Lifelong Knowledge Editing in LLMs(https://arxiv.org/abs/2503.05683)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Keeping large language models factually up-to-date is crucial for deployment, yet costly retraining remains a challenge. Knowledge editing offers a promising alternative, but methods are only tested on small-scale or synthetic edit benchmarks. In this work, we aim to bridge research into lifelong knowledge editing to real-world edits at practically relevant scale. We first introduce WikiBigEdit; a large-scale benchmark of real-world Wikidata edits, built to automatically extend lifelong for future-proof benchmarking. In its first instance, it includes over 500K question-answer pairs for knowledge editing alongside a comprehensive evaluation pipeline. Finally, we use WikiBigEdit to study existing knowledge editing techniques' ability to incorporate large volumes of real-world facts and contrast their capabilities to generic modification techniques such as retrieval augmentation and continual finetuning to acquire a complete picture of the practical extent of current lifelong knowledge editing.</li>
</ul>

<h3>Title: Fairness-Aware Low-Rank Adaptation Under Demographic Privacy Constraints</h3>
<ul>
<li><strong>Authors: </strong>Parameswaran Kamalaruban, Mark Anderson, Stuart Burrell, Maeve Madigan, Piotr Skalski, David Sutton</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05684">https://arxiv.org/abs/2503.05684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05684">https://arxiv.org/pdf/2503.05684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05684]] Fairness-Aware Low-Rank Adaptation Under Demographic Privacy Constraints(https://arxiv.org/abs/2503.05684)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>Pre-trained foundation models can be adapted for specific tasks using Low-Rank Adaptation (LoRA). However, the fairness properties of these adapted classifiers remain underexplored. Existing fairness-aware fine-tuning methods rely on direct access to sensitive attributes or their predictors, but in practice, these sensitive attributes are often held under strict consumer privacy controls, and neither the attributes nor their predictors are available to model developers, hampering the development of fair models. To address this issue, we introduce a set of LoRA-based fine-tuning methods that can be trained in a distributed fashion, where model developers and fairness auditors collaborate without sharing sensitive attributes or predictors. In this paper, we evaluate three such methods - sensitive unlearning, adversarial training, and orthogonality loss - against a fairness-unaware baseline, using experiments on the CelebA and UTK-Face datasets with an ImageNet pre-trained ViT-Base model. We find that orthogonality loss consistently reduces bias while maintaining or improving utility, whereas adversarial training improves False Positive Rate Parity and Demographic Parity in some cases, and sensitive unlearning provides no clear benefit. In tasks where significant biases are present, distributed fairness-aware fine-tuning methods can effectively eliminate bias without compromising consumer privacy and, in most cases, improve model utility.</li>
</ul>

<h3>Title: GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Zebin Xing, Xingyu Zhang, Yang Hu, Bo Jiang, Tong He, Qian Zhang, Xiaoxiao Long, Wei Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05689">https://arxiv.org/abs/2503.05689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05689">https://arxiv.org/pdf/2503.05689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05689]] GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving(https://arxiv.org/abs/2503.05689)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose GoalFlow, an end-to-end autonomous driving method for generating high-quality multimodal trajectories. In autonomous driving scenarios, there is rarely a single suitable trajectory. Recent methods have increasingly focused on modeling multimodal trajectory distributions. However, they suffer from trajectory selection complexity and reduced trajectory quality due to high trajectory divergence and inconsistencies between guidance and scene information. To address these issues, we introduce GoalFlow, a novel method that effectively constrains the generative process to produce high-quality, multimodal trajectories. To resolve the trajectory divergence problem inherent in diffusion-based methods, GoalFlow constrains the generated trajectories by introducing a goal point. GoalFlow establishes a novel scoring mechanism that selects the most appropriate goal point from the candidate points based on scene information. Furthermore, GoalFlow employs an efficient generative method, Flow Matching, to generate multimodal trajectories, and incorporates a refined scoring mechanism to select the optimal trajectory from the candidates. Our experimental results, validated on the Navsim\cite{Dauner2024_navsim}, demonstrate that GoalFlow achieves state-of-the-art performance, delivering robust multimodal trajectories for autonomous driving. GoalFlow achieved PDMS of 90.3, significantly surpassing other methods. Compared with other diffusion-policy-based methods, our approach requires only a single denoising step to obtain excellent performance. The code is available at this https URL.</li>
</ul>

<h3>Title: Multi-Fidelity Policy Gradient Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Xinjie Liu, Cyrus Neary, Kushagra Gupta, Christian Ellis, Ufuk Topcu, David Fridovich-Keil</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.05696">https://arxiv.org/abs/2503.05696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.05696">https://arxiv.org/pdf/2503.05696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.05696]] Multi-Fidelity Policy Gradient Algorithms(https://arxiv.org/abs/2503.05696)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Many reinforcement learning (RL) algorithms require large amounts of data, prohibiting their use in applications where frequent interactions with operational systems are infeasible, or high-fidelity simulations are expensive or unavailable. Meanwhile, low-fidelity simulators--such as reduced-order models, heuristic reward functions, or generative world models--can cheaply provide useful data for RL training, even if they are too coarse for direct sim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL framework that mixes a small amount of data from the target environment with a large volume of low-fidelity simulation data to form unbiased, reduced-variance estimators (control variates) for on-policy policy gradients. We instantiate the framework by developing multi-fidelity variants of two policy gradient algorithms: REINFORCE and proximal policy optimization. Experimental results across a suite of simulated robotics benchmark problems demonstrate that when target-environment samples are limited, MFPG achieves up to 3.9x higher reward and improves training stability when compared to baselines that only use high-fidelity data. Moreover, even when the baselines are given more high-fidelity samples--up to 10x as many interactions with the target environment--MFPG continues to match or outperform them. Finally, we observe that MFPG is capable of training effective policies even when the low-fidelity environment is drastically different from the target environment. MFPG thus not only offers a novel paradigm for efficient sim-to-real transfer but also provides a principled approach to managing the trade-off between policy performance and data collection costs.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
