<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Enhancing General Face Forgery Detection via Vision Transformer with Low-Rank Adaptation. (arXiv:2303.00917v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00917">http://arxiv.org/abs/2303.00917</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00917] Enhancing General Face Forgery Detection via Vision Transformer with Low-Rank Adaptation](http://arxiv.org/abs/2303.00917) #security</code></li>
<li>Summary: <p>Nowadays, forgery faces pose pressing security concerns over fake news,
fraud, impersonation, etc. Despite the demonstrated success in intra-domain
face forgery detection, existing detection methods lack generalization
capability and tend to suffer from dramatic performance drops when deployed to
unforeseen domains. To mitigate this issue, this paper designs a more general
fake face detection model based on the vision transformer(ViT) architecture. In
the training phase, the pretrained ViT weights are freezed, and only the
Low-Rank Adaptation(LoRA) modules are updated. Additionally, the Single Center
Loss(SCL) is applied to supervise the training process, further improving the
generalization capability of the model. The proposed method achieves
state-of-the-arts detection performances in both cross-manipulation and
cross-dataset evaluations.
</p></li>
</ul>

<h3>Title: APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth Estimation for Autonomous Navigation. (arXiv:2303.01351v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01351">http://arxiv.org/abs/2303.01351</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01351] APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth Estimation for Autonomous Navigation](http://arxiv.org/abs/2303.01351) #security</code></li>
<li>Summary: <p>In recent years, monocular depth estimation (MDE) has witnessed a substantial
performance improvement due to convolutional neural networks (CNNs). However,
CNNs are vulnerable to adversarial attacks, which pose serious concerns for
safety-critical and security-sensitive systems. Specifically, adversarial
attacks can have catastrophic impact on MDE given its importance for scene
understanding in applications like autonomous driving and robotic navigation.
To physically assess the vulnerability of CNN-based depth prediction methods,
recent work tries to design adversarial patches against MDE. However, these
methods are not powerful enough to fully fool the vision system in a
systemically threatening manner. In fact, their impact is partial and locally
limited; they mislead the depth prediction of only the overlapping region with
the input image regardless of the target object size, shape and location. In
this paper, we investigate MDE vulnerability to adversarial patches in a more
comprehensive manner. We propose a novel adaptive adversarial patch (APARATE)
that is able to selectively jeopardize MDE by either corrupting the estimated
distance, or simply manifesting an object as disappeared for the autonomous
system. Specifically, APARATE is optimized to be shape and scale-aware, and its
impact adapts to the target object instead of being limited to the immediate
neighborhood. Our proposed patch achieves more than $14~meters$ mean depth
estimation error, with $99\%$ of the target region being affected. We believe
this work highlights the threat of adversarial attacks in the context of MDE,
and we hope it would alert the community to the real-life potential harm of
this attack and motivate investigating more robust and adaptive defenses for
autonomous robots.
</p></li>
</ul>

<h3>Title: Explainable Artificial Intelligence and Cybersecurity: A Systematic Literature Review. (arXiv:2303.01259v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01259">http://arxiv.org/abs/2303.01259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01259] Explainable Artificial Intelligence and Cybersecurity: A Systematic Literature Review](http://arxiv.org/abs/2303.01259) #security</code></li>
<li>Summary: <p>Cybersecurity vendors consistently apply AI (Artificial Intelligence) to
their solutions and many cybersecurity domains can benefit from AI technology.
However, black-box AI techniques present some difficulties in comprehension and
adoption by its operators, given that their decisions are not always humanly
understandable (as is usually the case with deep neural networks, for example).
Since it aims to make the operation of AI algorithms more interpretable for its
users and developers, XAI (eXplainable Artificial Intelligence) can be used to
address this issue. Through a systematic literature review, this work seeks to
investigate the current research scenario on XAI applied to cybersecurity,
aiming to discover which XAI techniques have been applied in cybersecurity, and
which areas of cybersecurity have already benefited from this technology.
</p></li>
</ul>

<h3>Title: A Large-Scale Study of Personal Identifiability of Virtual Reality Motion Over Time. (arXiv:2303.01430v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01430">http://arxiv.org/abs/2303.01430</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01430] A Large-Scale Study of Personal Identifiability of Virtual Reality Motion Over Time](http://arxiv.org/abs/2303.01430) #security</code></li>
<li>Summary: <p>In recent years, social virtual reality (VR), sometimes described as the
"metaverse," has become widely available. With its potential comes risks,
including risks to privacy. To understand these risks, we study the
identifiability of participants' motion in VR in a dataset of 232 VR users with
eight weekly sessions of about thirty minutes each, totaling 764 hours of
social interaction. The sample is unique as we are able to study the effect of
user, session, and time independently. We find that the number of sessions
recorded greatly increases identifiability, and duration per session increases
identifiability as well, but to a lesser degree. We also find that greater
delay between training and testing sessions reduces identifiability.
Ultimately, understanding the identifiability of VR activities will help
designers, security professionals, and consumer advocates make VR safer.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Practical Network Acceleration with Tiny Sets: Hypothesis, Theory, and Algorithm. (arXiv:2303.00972v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00972">http://arxiv.org/abs/2303.00972</a></li>
<li>Code URL: <a href="https://github.com/doctorkey/practise">https://github.com/doctorkey/practise</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00972] Practical Network Acceleration with Tiny Sets: Hypothesis, Theory, and Algorithm](http://arxiv.org/abs/2303.00972) #privacy</code></li>
<li>Summary: <p>Due to data privacy issues, accelerating networks with tiny training sets has
become a critical need in practice. Previous methods achieved promising results
empirically by filter-level pruning. In this paper, we both study this problem
theoretically and propose an effective algorithm aligning well with our
theoretical results. First, we propose the finetune convexity hypothesis to
explain why recent few-shot compression algorithms do not suffer from
overfitting problems. Based on it, a theory is further established to explain
these methods for the first time. Compared to naively finetuning a pruned
network, feature mimicking is proved to achieve a lower variance of parameters
and hence enjoys easier optimization. With our theoretical conclusions, we
claim dropping blocks is a fundamentally superior few-shot compression scheme
in terms of more convex optimization and a higher acceleration ratio. To choose
which blocks to drop, we propose a new metric, recoverability, to effectively
measure the difficulty of recovering the compressed network. Finally, we
propose an algorithm named PRACTISE to accelerate networks using only tiny
training sets. PRACTISE outperforms previous methods by a significant margin.
For 22% latency reduction, it surpasses previous methods by on average 7
percentage points on ImageNet-1k. It also works well under data-free or
out-of-domain data settings. Our code is at
https://github.com/DoctorKey/Practise
</p></li>
</ul>

<h3>Title: Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves. (arXiv:2303.01112v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01112">http://arxiv.org/abs/2303.01112</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01112] Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves](http://arxiv.org/abs/2303.01112) #privacy</code></li>
<li>Summary: <p>Formula-driven supervised learning (FDSL) has been shown to be an effective
method for pre-training vision transformers, where ExFractalDB-21k was shown to
exceed the pre-training effect of ImageNet-21k. These studies also indicate
that contours mattered more than textures when pre-training vision
transformers. However, the lack of a systematic investigation as to why these
contour-oriented synthetic datasets can achieve the same accuracy as real
datasets leaves much room for skepticism. In the present work, we develop a
novel methodology based on circular harmonics for systematically investigating
the design space of contour-oriented synthetic datasets. This allows us to
efficiently search the optimal range of FDSL parameters and maximize the
variety of synthetic images in the dataset, which we found to be a critical
factor. When the resulting new dataset VisualAtom-21k is used for pre-training
ViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k.
This is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training,
while the number of images is 1/14. Unlike JFT-300M which is a static dataset,
the quality of synthetic datasets will continue to improve, and the current
work is a testament to this possibility. FDSL is also free of the common issues
associated with real images, e.g. privacy/copyright issues, labeling
costs/errors, and ethical biases.
</p></li>
</ul>

<h3>Title: An Improved Christofides Mechanism for Local Differential Privacy Framework. (arXiv:2303.00857v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00857">http://arxiv.org/abs/2303.00857</a></li>
<li>Code URL: <a href="https://github.com/ssjhf/ImprovedLDPMechanism">https://github.com/ssjhf/ImprovedLDPMechanism</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00857] An Improved Christofides Mechanism for Local Differential Privacy Framework](http://arxiv.org/abs/2303.00857) #privacy</code></li>
<li>Summary: <p>The development of Internet technology enables an analysis on the whole
population rather than a certain number of samples, and leads to increasing
requirement for privacy protection. Local differential privacy (LDP) is an
effective standard of privacy measurement; however, its large variance of mean
estimation causes challenges in application. To address this problem, this
paper presents a new LDP approach, an improved Christofides mechanism.
</p></li>
</ul>

<p>It compared four statistical survey methods for conducting surveys on
sensitive topics -- modified Warner, Simmons, Christofides, and the improved
Christofides mechanism. Specifically, Warner, Simmons and Christofides
mechanisms have been modified to draw a sample from the population without
replacement, to decrease variance. Furthermore, by drawing cards without
replacement based on modified Christofides mechanism, we introduce a new
mechanism called the improved Christofides mechanism, which is found to have
the smallest variance under certain assumption when using LDP as a measurement
of privacy leakage. The assumption is do satisfied usually in the real world.
Actually, we decrease the variance to 28.7% of modified Christofides
mechanism's variance in our experiment based on the HCOVANY dataset -- a real
world dataset of IPUMS USA. This means our method gets a more accurate estimate
by using LDP as a measurement of privacy leakage. This is the first time the
improved Christofides mechanism is proposed for LDP framework based on
comparative analysis of four mechanisms using LDP as the same measurement of
privacy leakage.
</p>

<h3>Title: What Is Synthetic Data? The Good, The Bad, and The Ugly. (arXiv:2303.01230v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01230">http://arxiv.org/abs/2303.01230</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01230] What Is Synthetic Data? The Good, The Bad, and The Ugly](http://arxiv.org/abs/2303.01230) #privacy</code></li>
<li>Summary: <p>Sharing data can often enable compelling applications and analytics. However,
more often than not, valuable datasets contain information of sensitive nature,
and thus sharing them can endanger the privacy of users and organizations. A
possible alternative gaining momentum in the research community is to share
synthetic data instead. The idea is to release artificially generated datasets
that resemble the actual data -- more precisely, having similar statistical
properties.
</p></li>
</ul>

<p>So how do you generate synthetic data? What is that useful for? What are the
benefits and the risks? What are the open research questions that remain
unanswered? In this article, we provide a gentle introduction to synthetic data
and discuss its use cases, the privacy challenges that are still unaddressed,
and its inherent limitations as an effective privacy-enhancing technology.
</p>

<h3>Title: Privacy-Preserving Tree-Based Inference with Fully Homomorphic Encryption. (arXiv:2303.01254v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01254">http://arxiv.org/abs/2303.01254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01254] Privacy-Preserving Tree-Based Inference with Fully Homomorphic Encryption](http://arxiv.org/abs/2303.01254) #privacy</code></li>
<li>Summary: <p>Privacy enhancing technologies (PETs) have been proposed as a way to protect
the privacy of data while still allowing for data analysis. In this work, we
focus on Fully Homomorphic Encryption (FHE), a powerful tool that allows for
arbitrary computations to be performed on encrypted data. FHE has received lots
of attention in the past few years and has reached realistic execution times
and correctness.
</p></li>
</ul>

<p>More precisely, we explain in this paper how we apply FHE to tree-based
models and get state-of-the-art solutions over encrypted tabular data. We show
that our method is applicable to a wide range of tree-based models, including
decision trees, random forests, and gradient boosted trees, and has been
implemented within the Concrete-ML library, which is open-source at
https://github.com/zama-ai/concrete-ml. With a selected set of use-cases, we
demonstrate that our FHE version is very close to the unprotected version in
terms of accuracy.
</p>

<h3>Title: CADeSH: Collaborative Anomaly Detection for Smart Homes. (arXiv:2303.01021v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01021">http://arxiv.org/abs/2303.01021</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01021] CADeSH: Collaborative Anomaly Detection for Smart Homes](http://arxiv.org/abs/2303.01021) #privacy</code></li>
<li>Summary: <p>Although home IoT (Internet of Things) devices are typically plain and task
oriented, the context of their daily use may affect their traffic patterns. For
this reason, anomaly-based intrusion detection systems tend to suffer from a
high false positive rate (FPR). To overcome this, we propose a two-step
collaborative anomaly detection method which first uses an autoencoder to
differentiate frequent (<code>benign') and infrequent (possibly</code>malicious') traffic
flows. Clustering is then used to analyze only the infrequent flows and
classify them as either known ('rare yet benign') or unknown (`malicious'). Our
method is collaborative, in that (1) normal behaviors are characterized more
robustly, as they take into account a variety of user interactions and network
topologies, and (2) several features are computed based on a pool of identical
devices rather than just the inspected device.
</p></li>
</ul>

<p>We evaluated our method empirically, using 21 days of real-world traffic data
that emanated from eight identical IoT devices deployed on various networks,
one of which was located in our controlled lab where we implemented two popular
IoT-related cyber-attacks. Our collaborative anomaly detection method achieved
a macro-average area under the precision-recall curve of 0.841, an F1 score of
0.929, and an FPR of only 0.014. These promising results were obtained by using
labeled traffic data from our lab as the test set, while training the models on
the traffic of devices deployed outside the lab, and thus demonstrate a high
level of generalizability. In addition to its high generalizability and
promising performance, our proposed method also offers benefits such as privacy
preservation, resource savings, and model poisoning mitigation. On top of that,
as a contribution to the scientific community, our novel dataset is available
online.
</p>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Evaluation of drain, a deep-learning approach to rain retrieval from gpm passive microwave radiometer. (arXiv:2303.01220v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01220">http://arxiv.org/abs/2303.01220</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01220] Evaluation of drain, a deep-learning approach to rain retrieval from gpm passive microwave radiometer](http://arxiv.org/abs/2303.01220) #defense</code></li>
<li>Summary: <p>Retrieval of rain from Passive Microwave radiometers data has been a
challenge ever since the launch of the first Defense Meteorological Satellite
Program in the late 70s. Enormous progress has been made since the launch of
the Tropical Rainfall Measuring Mission (TRMM) in 1997 but until recently the
data were processed pixel-by-pixel or taking a few neighboring pixels into
account. Deep learning has obtained remarkable improvement in the computer
vision field, and offers a whole new way to tackle the rain retrieval problem.
The Global Precipitation Measurement (GPM) Core satellite carries similarly to
TRMM, a passive microwave radiometer and a radar that share part of their
swath. The brightness temperatures measured in the 37 and 89 GHz channels are
used like the RGB components of a regular image while rain rate from Dual
Frequency radar provides the surface rain. A U-net is then trained on these
data to develop a retrieval algorithm: Deep-learning RAIN (DRAIN). With only
four brightness temperatures as an input and no other a priori information,
DRAIN is offering similar or slightly better performances than GPROF, the GPM
official algorithm, in most situations. These performances are assumed to be
due to the fact that DRAIN works on an image basis instead of the classical
pixel-by-pixel basis.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision Systems. (arXiv:2303.01338v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01338">http://arxiv.org/abs/2303.01338</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01338] AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision Systems](http://arxiv.org/abs/2303.01338) #attack</code></li>
<li>Summary: <p>Vision-based perception modules are increasingly deployed in many
applications, especially autonomous vehicles and intelligent robots. These
modules are being used to acquire information about the surroundings and
identify obstacles. Hence, accurate detection and classification are essential
to reach appropriate decisions and take appropriate and safe actions at all
times. Current studies have demonstrated that "printed adversarial attacks",
known as physical adversarial attacks, can successfully mislead perception
models such as object detectors and image classifiers. However, most of these
physical attacks are based on noticeable and eye-catching patterns for
generated perturbations making them identifiable/detectable by human eye or in
test drives. In this paper, we propose a camera-based inconspicuous adversarial
attack (\textbf{AdvRain}) capable of fooling camera-based perception systems
over all objects of the same class. Unlike mask based fake-weather attacks that
require access to the underlying computing hardware or image memory, our attack
is based on emulating the effects of a natural weather condition (i.e.,
Raindrops) that can be printed on a translucent sticker, which is externally
placed over the lens of a camera. To accomplish this, we provide an iterative
process based on performing a random search aiming to identify critical
positions to make sure that the performed transformation is adversarial for a
target classifier. Our transformation is based on blurring predefined parts of
the captured image corresponding to the areas covered by the raindrop. We
achieve a drop in average model accuracy of more than $45\%$ and $40\%$ on
VGG19 for ImageNet and Resnet34 for Caltech-101, respectively, using only $20$
raindrops.
</p></li>
</ul>

<h3>Title: MoSFPAD: An end-to-end Ensemble of MobileNet and Support Vector Classifier for Fingerprint Presentation Attack Detection. (arXiv:2303.01465v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01465">http://arxiv.org/abs/2303.01465</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01465] MoSFPAD: An end-to-end Ensemble of MobileNet and Support Vector Classifier for Fingerprint Presentation Attack Detection](http://arxiv.org/abs/2303.01465) #attack</code></li>
<li>Summary: <p>Automatic fingerprint recognition systems are the most extensively used
systems for person authentication although they are vulnerable to Presentation
attacks. Artificial artifacts created with the help of various materials are
used to deceive these systems causing a threat to the security of
fingerprint-based applications. This paper proposes a novel end-to-end model to
detect fingerprint Presentation attacks. The proposed model incorporates
MobileNet as a feature extractor and a Support Vector Classifier as a
classifier to detect presentation attacks in cross-material and cross-sensor
paradigms. The feature extractor's parameters are learned with the loss
generated by the support vector classifier. The proposed model eliminates the
need for intermediary data preparation procedures, unlike other static hybrid
architectures. The performance of the proposed model has been validated on
benchmark LivDet 2011, 2013, 2015, 2017, and 2019 databases, and overall
accuracy of 98.64%, 99.50%, 97.23%, 95.06%, and 95.20% is achieved on these
databases, respectively. The performance of the proposed model is compared with
state-of-the-art methods and the proposed method outperforms in cross-material
and cross-sensor paradigms in terms of average classification error.
</p></li>
</ul>

<h3>Title: Targeted Adversarial Attacks against Neural Machine Translation. (arXiv:2303.01068v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01068">http://arxiv.org/abs/2303.01068</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01068] Targeted Adversarial Attacks against Neural Machine Translation](http://arxiv.org/abs/2303.01068) #attack</code></li>
<li>Summary: <p>Neural Machine Translation (NMT) systems are used in various applications.
However, it has been shown that they are vulnerable to very small perturbations
of their inputs, known as adversarial attacks. In this paper, we propose a new
targeted adversarial attack against NMT models. In particular, our goal is to
insert a predefined target keyword into the translation of the adversarial
sentence while maintaining similarity between the original sentence and the
perturbed one in the source domain. To this aim, we propose an optimization
problem, including an adversarial loss term and a similarity term. We use
gradient projection in the embedding space to craft an adversarial sentence.
Experimental results show that our attack outperforms Seq2Sick, the other
targeted adversarial attack against NMT models, in terms of success rate and
decrease in translation quality. Our attack succeeds in inserting a keyword
into the translation for more than 75% of sentences while similarity with the
original sentence stays preserved.
</p></li>
</ul>

<h3>Title: Frauds Bargain Attack: Generating Adversarial Text Samples via Word Manipulation Process. (arXiv:2303.01234v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01234">http://arxiv.org/abs/2303.01234</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01234] Frauds Bargain Attack: Generating Adversarial Text Samples via Word Manipulation Process](http://arxiv.org/abs/2303.01234) #attack</code></li>
<li>Summary: <p>Recent studies on adversarial examples expose vulnerabilities of natural
language processing (NLP) models. Existing techniques for generating
adversarial examples are typically driven by deterministic heuristic rules that
are agnostic to the optimal adversarial examples, a strategy that often results
in attack failures. To this end, this research proposes Fraud's Bargain Attack
(FBA) which utilizes a novel randomization mechanism to enlarge the search
space and enables high-quality adversarial examples to be generated with high
probabilities. FBA applies the Metropolis-Hasting sampler, a member of Markov
Chain Monte Carlo samplers, to enhance the selection of adversarial examples
from all candidates proposed by a customized stochastic process that we call
the Word Manipulation Process (WMP). WMP perturbs one word at a time via
insertion, removal or substitution in a contextual-aware manner. Extensive
experiments demonstrate that FBA outperforms the state-of-the-art methods in
terms of both attack success rate and imperceptibility.
</p></li>
</ul>

<h3>Title: D-Score: An Expert-Based Method for Assessing the Detectability of IoT-Related Cyber-Attacks. (arXiv:2303.01041v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01041">http://arxiv.org/abs/2303.01041</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01041] D-Score: An Expert-Based Method for Assessing the Detectability of IoT-Related Cyber-Attacks](http://arxiv.org/abs/2303.01041) #attack</code></li>
<li>Summary: <p>IoT devices are known to be vulnerable to various cyber-attacks, such as data
exfiltration and the execution of flooding attacks as part of a DDoS attack.
When it comes to detecting such attacks using network traffic analysis, it has
been shown that some attack scenarios are not always equally easy to detect if
they involve different IoT models. That is, when targeted at some IoT models, a
given attack can be detected rather accurately, while when targeted at others
the same attack may result in too many false alarms. In this research, we
attempt to explain this variability of IoT attack detectability and devise a
risk assessment method capable of addressing a key question: how easy is it for
an anomaly-based network intrusion detection system to detect a given
cyber-attack involving a specific IoT model? In the process of addressing this
question we (a) investigate the predictability of IoT network traffic, (b)
present a novel taxonomy for IoT attack detection which also encapsulates
traffic predictability aspects, (c) propose an expert-based attack
detectability estimation method which uses this taxonomy to derive a
detectability score (termed `D-Score') for a given combination of IoT model and
attack scenario, and (d) empirically evaluate our method while comparing it
with a data-driven method.
</p></li>
</ul>

<h3>Title: Poster: Sponge ML Model Attacks of Mobile Apps. (arXiv:2303.01243v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01243">http://arxiv.org/abs/2303.01243</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01243] Poster: Sponge ML Model Attacks of Mobile Apps](http://arxiv.org/abs/2303.01243) #attack</code></li>
<li>Summary: <p>Machine Learning (ML)-powered apps are used in pervasive devices such as
phones, tablets, smartwatches and IoT devices. Recent advances in
collaborative, distributed ML such as Federated Learning (FL) attempt to solve
privacy concerns of users and data owners, and thus used by tech industry
leaders such as Google, Facebook and Apple. However, FL systems and models are
still vulnerable to adversarial membership and attribute inferences and model
poisoning attacks, especially in FL-as-a-Service ecosystems recently proposed,
which can enable attackers to access multiple ML-powered apps. In this work, we
focus on the recently proposed Sponge attack: It is designed to soak up energy
consumed while executing inference (not training) of ML model, without
hampering the classifier's performance. Recent work has shown sponge attacks on
ASCI-enabled GPUs can potentially escalate the power consumption and inference
time. For the first time, in this work, we investigate this attack in the
mobile setting and measure the effect it can have on ML models running inside
apps on mobile devices.
</p></li>
</ul>

<h3>Title: An Incremental Gray-box Physical Adversarial Attack on Neural Network Training. (arXiv:2303.01245v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01245">http://arxiv.org/abs/2303.01245</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01245] An Incremental Gray-box Physical Adversarial Attack on Neural Network Training](http://arxiv.org/abs/2303.01245) #attack</code></li>
<li>Summary: <p>Neural networks have demonstrated remarkable success in learning and solving
complex tasks in a variety of fields. Nevertheless, the rise of those networks
in modern computing has been accompanied by concerns regarding their
vulnerability to adversarial attacks. In this work, we propose a novel
gradient-free, gray box, incremental attack that targets the training process
of neural networks. The proposed attack, which implicitly poisons the
intermediate data structures that retain the training instances between
training epochs acquires its high-risk property from attacking data structures
that are typically unobserved by professionals. Hence, the attack goes
unnoticed despite the damage it can cause. Moreover, the attack can be executed
without the attackers' knowledge of the neural network structure or training
data making it more dangerous. The attack was tested under a sensitive
application of secure cognitive cities, namely, biometric authentication. The
conducted experiments showed that the proposed attack is effective and
stealthy. Finally, the attack effectiveness property was concluded from the
fact that it was able to flip the sign of the loss gradient in the conducted
experiments to become positive, which indicated noisy and unstable training.
Moreover, the attack was able to decrease the inference probability in the
poisoned networks compared to their unpoisoned counterparts by 15.37%, 14.68%,
and 24.88% for the Densenet, VGG, and Xception, respectively. Finally, the
attack retained its stealthiness despite its high effectiveness. This was
demonstrated by the fact that the attack did not cause a notable increase in
the training time, in addition, the Fscore values only dropped by an average of
1.2%, 1.9%, and 1.5% for the poisoned Densenet, VGG, and Xception,
respectively.
</p></li>
</ul>

<h3>Title: Unnoticeable Backdoor Attacks on Graph Neural Networks. (arXiv:2303.01263v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01263">http://arxiv.org/abs/2303.01263</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01263] Unnoticeable Backdoor Attacks on Graph Neural Networks](http://arxiv.org/abs/2303.01263) #attack</code></li>
<li>Summary: <p>Graph Neural Networks (GNNs) have achieved promising results in various tasks
such as node classification and graph classification. Recent studies find that
GNNs are vulnerable to adversarial attacks. However, effective backdoor attacks
on graphs are still an open problem. In particular, backdoor attack poisons the
graph by attaching triggers and the target class label to a set of nodes in the
training graph. The backdoored GNNs trained on the poisoned graph will then be
misled to predict test nodes to target class once attached with triggers.
Though there are some initial efforts in graph backdoor attacks, our empirical
analysis shows that they may require a large attack budget for effective
backdoor attacks and the injected triggers can be easily detected and pruned.
Therefore, in this paper, we study a novel problem of unnoticeable graph
backdoor attacks with limited attack budget. To fully utilize the attack
budget, we propose to deliberately select the nodes to inject triggers and
target class labels in the poisoning phase. An adaptive trigger generator is
deployed to obtain effective triggers that are difficult to be noticed.
Extensive experiments on real-world datasets against various defense strategies
demonstrate the effectiveness of our proposed method in conducting effective
unnoticeable backdoor attacks.
</p></li>
</ul>

<h3>Title: Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning. (arXiv:2303.01289v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01289">http://arxiv.org/abs/2303.01289</a></li>
<li>Code URL: <a href="https://github.com/pku-ml/dynacl">https://github.com/pku-ml/dynacl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01289] Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning](http://arxiv.org/abs/2303.01289) #attack</code></li>
<li>Summary: <p>Recent works have shown that self-supervised learning can achieve remarkable
robustness when integrated with adversarial training (AT). However, the
robustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT)
remains significant. Motivated by this observation, we revisit existing self-AT
methods and discover an inherent dilemma that affects self-AT robustness:
either strong or weak data augmentations are harmful to self-AT, and a medium
strength is insufficient to bridge the gap. To resolve this dilemma, we propose
a simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In
particular, we propose an augmentation schedule that gradually anneals from a
strong augmentation to a weak one to benefit from both extreme cases. Besides,
we adopt a fast post-processing stage for adapting it to downstream tasks.
Through extensive experiments, we show that DYNACL can improve state-of-the-art
self-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can
even outperform vanilla supervised adversarial training for the first time. Our
code is available at \url{https://github.com/PKU-ML/DYNACL}.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: AMIGO: Sparse Multi-Modal Graph Transformer with Shared-Context Processing for Representation Learning of Giga-pixel Images. (arXiv:2303.00865v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00865">http://arxiv.org/abs/2303.00865</a></li>
<li>Code URL: <a href="https://github.com/raminnakhli/amigo">https://github.com/raminnakhli/amigo</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00865] AMIGO: Sparse Multi-Modal Graph Transformer with Shared-Context Processing for Representation Learning of Giga-pixel Images](http://arxiv.org/abs/2303.00865) #robust</code></li>
<li>Summary: <p>Processing giga-pixel whole slide histopathology images (WSI) is a
computationally expensive task. Multiple instance learning (MIL) has become the
conventional approach to process WSIs, in which these images are split into
smaller patches for further processing. However, MIL-based techniques ignore
explicit information about the individual cells within a patch. In this paper,
by defining the novel concept of shared-context processing, we designed a
multi-modal Graph Transformer (AMIGO) that uses the celluar graph within the
tissue to provide a single representation for a patient while taking advantage
of the hierarchical structure of the tissue, enabling a dynamic focus between
cell-level and tissue-level information. We benchmarked the performance of our
model against multiple state-of-the-art methods in survival prediction and
showed that ours can significantly outperform all of them including
hierarchical Vision Transformer (ViT). More importantly, we show that our model
is strongly robust to missing information to an extent that it can achieve the
same performance with as low as 20% of the data. Finally, in two different
cancer datasets, we demonstrated that our model was able to stratify the
patients into low-risk and high-risk groups while other state-of-the-art
methods failed to achieve this goal. We also publish a large dataset of
immunohistochemistry images (InUIT) containing 1,600 tissue microarray (TMA)
cores from 188 patients along with their survival information, making it one of
the largest publicly available datasets in this context.
</p></li>
</ul>

<h3>Title: Spatial Layout Consistency for 3D Semantic Segmentation. (arXiv:2303.00939v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00939">http://arxiv.org/abs/2303.00939</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00939] Spatial Layout Consistency for 3D Semantic Segmentation](http://arxiv.org/abs/2303.00939) #robust</code></li>
<li>Summary: <p>Due to the aged nature of much of the utility network infrastructure,
developing a robust and trustworthy computer vision system capable of
inspecting it with minimal human intervention has attracted considerable
research attention. The airborne laser terrain mapping (ALTM) system quickly
becomes the central data collection system among the numerous available
sensors. Its ability to penetrate foliage with high-powered energy provides
wide coverage and achieves survey-grade ranging accuracy. However, the
post-data acquisition process for classifying the ALTM's dense and irregular
point clouds is a critical bottleneck that must be addressed to improve
efficiency and accuracy. We introduce a novel deep convolutional neural network
(DCNN) technique for achieving voxel-based semantic segmentation of the ALTM's
point clouds. The suggested deep learning method, Semantic Utility Network
(SUNet) is a multi-dimensional and multi-resolution network. SUNet combines two
networks: one classifies point clouds at multi-resolution with object
categories in three dimensions and another predicts two-dimensional regional
labels distinguishing corridor regions from non-corridors. A significant
innovation of the SUNet is that it imposes spatial layout consistency on the
outcomes of voxel-based and regional segmentation results. The proposed
multi-dimensional DCNN combines hierarchical context for spatial layout
embedding with a coarse-to-fine strategy. We conducted a comprehensive ablation
study to test SUNet's performance using 67 km x 67 km of utility corridor data
at a density of 5pp/m2. Our experiments demonstrated that SUNet's spatial
layout consistency and a multi-resolution feature aggregation could
significantly improve performance, outperforming the SOTA baseline network and
achieving a good F1 score for pylon 89%, ground 99%, vegetation 99% and
powerline 98% classes.
</p></li>
</ul>

<h3>Title: Evolutionary Computation in Action: Hyperdimensional Deep Embedding Spaces of Gigapixel Pathology Images. (arXiv:2303.00943v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00943">http://arxiv.org/abs/2303.00943</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00943] Evolutionary Computation in Action: Hyperdimensional Deep Embedding Spaces of Gigapixel Pathology Images](http://arxiv.org/abs/2303.00943) #robust</code></li>
<li>Summary: <p>One of the main obstacles of adopting digital pathology is the challenge of
efficient processing of hyperdimensional digitized biopsy samples, called whole
slide images (WSIs). Exploiting deep learning and introducing compact WSI
representations are urgently needed to accelerate image analysis and facilitate
the visualization and interpretability of pathology results in a postpandemic
world. In this paper, we introduce a new evolutionary approach for WSI
representation based on large-scale multi-objective optimization (LSMOP) of
deep embeddings. We start with patch-based sampling to feed KimiaNet , a
histopathology-specialized deep network, and to extract a multitude of feature
vectors. Coarse multi-objective feature selection uses the reduced search space
strategy guided by the classification accuracy and the number of features. In
the second stage, the frequent features histogram (FFH), a novel WSI
representation, is constructed by multiple runs of coarse LSMOP. Fine
evolutionary feature selection is then applied to find a compact (short-length)
feature vector based on the FFH and contributes to a more robust deep-learning
approach to digital pathology supported by the stochastic power of evolutionary
algorithms. We validate the proposed schemes using The Cancer Genome Atlas
(TCGA) images in terms of WSI representation, classification accuracy, and
feature quality. Furthermore, a novel decision space for multicriteria decision
making in the LSMOP field is introduced. Finally, a patch-level visualization
approach is proposed to increase the interpretability of deep features. The
proposed evolutionary algorithm finds a very compact feature vector to
represent a WSI (almost 14,000 times smaller than the original feature vectors)
with 8% higher accuracy compared to the codes provided by the state-of-the-art
methods.
</p></li>
</ul>

<h3>Title: Image Labels Are All You Need for Coarse Seagrass Segmentation. (arXiv:2303.00973v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00973">http://arxiv.org/abs/2303.00973</a></li>
<li>Code URL: <a href="https://github.com/sgraine/bag-of-seagrass">https://github.com/sgraine/bag-of-seagrass</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00973] Image Labels Are All You Need for Coarse Seagrass Segmentation](http://arxiv.org/abs/2303.00973) #robust</code></li>
<li>Summary: <p>Seagrass meadows serve as critical carbon sinks, but accurately estimating
the amount of carbon they store requires knowledge of the seagrass species
present. Using underwater and surface vehicles equipped with machine learning
algorithms can help to accurately estimate the composition and extent of
seagrass meadows at scale. However, previous approaches for seagrass detection
and classification have required full supervision from patch-level labels. In
this paper, we reframe seagrass classification as a weakly supervised coarse
segmentation problem where image-level labels are used during training (25
times fewer labels compared to patch-level labeling) and patch-level outputs
are obtained at inference time. To this end, we introduce SeaFeats, an
architecture that uses unsupervised contrastive pretraining and feature
similarity to separate background and seagrass patches, and SeaCLIP, a model
that showcases the effectiveness of large language models as a supervisory
signal in domain-specific applications. We demonstrate that an ensemble of
SeaFeats and SeaCLIP leads to highly robust performance, with SeaCLIP
conservatively predicting the background class to avoid false seagrass
misclassifications in blurry or dark patches. Our method outperforms previous
approaches that require patch-level labels on the multi-species 'DeepSeagrass'
dataset by 6.8% (absolute) for the class-weighted F1 score, and by 12.1%
(absolute) F1 score for seagrass presence/absence on the 'Global Wetlands'
dataset. We also present two case studies for real-world deployment: outlier
detection on the Global Wetlands dataset, and application of our method on
imagery collected by FloatyBoat, an autonomous surface vehicle.
</p></li>
</ul>

<h3>Title: Demystifying Causal Features on Adversarial Examples and Causal Inoculation for Robust Network by Adversarial Instrumental Variable Regression. (arXiv:2303.01052v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01052">http://arxiv.org/abs/2303.01052</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01052] Demystifying Causal Features on Adversarial Examples and Causal Inoculation for Robust Network by Adversarial Instrumental Variable Regression](http://arxiv.org/abs/2303.01052) #robust</code></li>
<li>Summary: <p>The origin of adversarial examples is still inexplicable in research fields,
and it arouses arguments from various viewpoints, albeit comprehensive
investigations. In this paper, we propose a way of delving into the unexpected
vulnerability in adversarially trained networks from a causal perspective,
namely adversarial instrumental variable (IV) regression. By deploying it, we
estimate the causal relation of adversarial prediction under an unbiased
environment dissociated from unknown confounders. Our approach aims to
demystify inherent causal features on adversarial examples by leveraging a
zero-sum optimization game between a casual feature estimator (i.e., hypothesis
model) and worst-case counterfactuals (i.e., test function) disturbing to find
causal features. Through extensive analyses, we demonstrate that the estimated
causal features are highly related to the correct prediction for adversarial
robustness, and the counterfactuals exhibit extreme features significantly
deviating from the correct prediction. In addition, we present how to
effectively inoculate CAusal FEatures (CAFE) into defense networks for
improving adversarial robustness.
</p></li>
</ul>

<h3>Title: ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations. (arXiv:2303.01092v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01092">http://arxiv.org/abs/2303.01092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01092] ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations](http://arxiv.org/abs/2303.01092) #robust</code></li>
<li>Summary: <p>Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data
for model training. Empirical studies show that SSL can achieve promising
performance in distribution shift scenarios, where the downstream and training
distributions differ. However, the theoretical understanding of its
transferability remains limited. In this paper, we develop a theoretical
framework to analyze the transferability of self-supervised contrastive
learning, by investigating the impact of data augmentation on it. Our results
reveal that the downstream performance of contrastive learning depends largely
on the choice of data augmentation. Moreover, we show that contrastive learning
fails to learn domain-invariant features, which limits its transferability.
Based on these theoretical insights, we propose a novel method called
Augmentation-robust Contrastive Learning (ArCL), which guarantees to learn
domain-invariant features and can be easily integrated with existing
contrastive learning algorithms. We conduct experiments on several datasets and
show that ArCL significantly improves the transferability of contrastive
learning.
</p></li>
</ul>

<h3>Title: STDepthFormer: Predicting Spatio-temporal Depth from Video with a Self-supervised Transformer Model. (arXiv:2303.01196v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01196">http://arxiv.org/abs/2303.01196</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01196] STDepthFormer: Predicting Spatio-temporal Depth from Video with a Self-supervised Transformer Model](http://arxiv.org/abs/2303.01196) #robust</code></li>
<li>Summary: <p>In this paper, a self-supervised model that simultaneously predicts a
sequence of future frames from video-input with a novel spatial-temporal
attention (ST) network is proposed. The ST transformer network allows
constraining both temporal consistency across future frames whilst constraining
consistency across spatial objects in the image at different scales. This was
not the case in prior works for depth prediction, which focused on predicting a
single frame as output. The proposed model leverages prior scene knowledge such
as object shape and texture similar to single-image depth inference methods,
whilst also constraining the motion and geometry from a sequence of input
images. Apart from the transformer architecture, one of the main contributions
with respect to prior works lies in the objective function that enforces
spatio-temporal consistency across a sequence of output frames rather than a
single output frame. As will be shown, this results in more accurate and robust
depth sequence forecasting. The model achieves highly accurate depth
forecasting results that outperform existing baselines on the KITTI benchmark.
Extensive ablation studies were performed to assess the effectiveness of the
proposed techniques. One remarkable result of the proposed model is that it is
implicitly capable of forecasting the motion of objects in the scene, rather
than requiring complex models involving multi-object detection, segmentation
and tracking.
</p></li>
</ul>

<h3>Title: Grid-Centric Traffic Scenario Perception for Autonomous Driving: A Comprehensive Review. (arXiv:2303.01212v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01212">http://arxiv.org/abs/2303.01212</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01212] Grid-Centric Traffic Scenario Perception for Autonomous Driving: A Comprehensive Review](http://arxiv.org/abs/2303.01212) #robust</code></li>
<li>Summary: <p>Grid-centric perception is a crucial field for mobile robot perception and
navigation. Nonetheless, grid-centric perception is less prevalent than
object-centric perception for autonomous driving as autonomous vehicles need to
accurately perceive highly dynamic, large-scale outdoor traffic scenarios and
the complexity and computational costs of grid-centric perception are high. The
rapid development of deep learning techniques and hardware gives fresh insights
into the evolution of grid-centric perception and enables the deployment of
many real-time algorithms. Current industrial and academic research
demonstrates the great advantages of grid-centric perception, such as
comprehensive fine-grained environmental representation, greater robustness to
occlusion, more efficient sensor fusion, and safer planning policies. Given the
lack of current surveys for this rapidly expanding field, we present a
hierarchically-structured review of grid-centric perception for autonomous
vehicles. We organize previous and current knowledge of occupancy grid
techniques and provide a systematic in-depth analysis of algorithms in terms of
three aspects: feature representation, data utility, and applications in
autonomous driving systems. Lastly, we present a summary of the current
research trend and provide some probable future outlooks.
</p></li>
</ul>

<h3>Title: Learning Person-specific Network Representation for Apparent Personality Traits Recognition. (arXiv:2303.01236v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01236">http://arxiv.org/abs/2303.01236</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01236] Learning Person-specific Network Representation for Apparent Personality Traits Recognition](http://arxiv.org/abs/2303.01236) #robust</code></li>
<li>Summary: <p>Recent studies show that apparent personality traits can be reflected from
human facial behavior dynamics. However, most existing methods can only encode
single-scale short-term facial behaviors in the latent features for personality
recognition. In this paper, we propose to recognize apparent personality
recognition approach which first trains a person-specific network for each
subject, modelling multi-scale long-term person-specific behavior evolution of
the subject. Consequently, we hypothesize that the weights of the network
contain the person-specific facial behavior-related cues of the subject. Then,
we propose to encode the weights of the person-specific network to a graph
representation, as the personality representation for the subject, allowing
them to be processed by standard Graph Neural Networks (GNNs) for personality
traits recognition. The experimental results show that our novel network
weights-based approach achieved superior performance than most traditional
latent feature-based approaches, and has comparable performance to the
state-of-the-art method. Importantly, the produced graph representations
produce robust results when using different GNNs. This paper further validated
that person-specific network's weights are correlated to the subject's
personality.
</p></li>
</ul>

<h3>Title: Analyzing Effects of Fake Training Data on the Performance of Deep Learning Systems. (arXiv:2303.01268v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01268">http://arxiv.org/abs/2303.01268</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01268] Analyzing Effects of Fake Training Data on the Performance of Deep Learning Systems](http://arxiv.org/abs/2303.01268) #robust</code></li>
<li>Summary: <p>Deep learning models frequently suffer from various problems such as class
imbalance and lack of robustness to distribution shift. It is often difficult
to find data suitable for training beyond the available benchmarks. This is
especially the case for computer vision models. However, with the advent of
Generative Adversarial Networks (GANs), it is now possible to generate
high-quality synthetic data. This synthetic data can be used to alleviate some
of the challenges faced by deep learning models. In this work we present a
detailed analysis of the effect of training computer vision models using
different proportions of synthetic data along with real (organic) data. We
analyze the effect that various quantities of synthetic data, when mixed with
original data, can have on a model's robustness to out-of-distribution data and
the general quality of predictions.
</p></li>
</ul>

<h3>Title: Cluster-Guided Semi-Supervised Domain Adaptation for Imbalanced Medical Image Classification. (arXiv:2303.01283v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01283">http://arxiv.org/abs/2303.01283</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01283] Cluster-Guided Semi-Supervised Domain Adaptation for Imbalanced Medical Image Classification](http://arxiv.org/abs/2303.01283) #robust</code></li>
<li>Summary: <p>Semi-supervised domain adaptation is a technique to build a classifier for a
target domain by modifying a classifier in another (source) domain using many
unlabeled samples and a small number of labeled samples from the target domain.
In this paper, we develop a semi-supervised domain adaptation method, which has
robustness to class-imbalanced situations, which are common in medical image
classification tasks. For robustness, we propose a weakly-supervised clustering
pipeline to obtain high-purity clusters and utilize the clusters in
representation learning for domain adaptation. The proposed method showed
state-of-the-art performance in the experiment using severely class-imbalanced
pathological image patches.
</p></li>
</ul>

<h3>Title: Active Learning Enhances Classification of Histopathology Whole Slide Images with Attention-based Multiple Instance Learning. (arXiv:2303.01342v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01342">http://arxiv.org/abs/2303.01342</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01342] Active Learning Enhances Classification of Histopathology Whole Slide Images with Attention-based Multiple Instance Learning](http://arxiv.org/abs/2303.01342) #robust</code></li>
<li>Summary: <p>In many histopathology tasks, sample classification depends on morphological
details in tissue or single cells that are only visible at the highest
magnification. For a pathologist, this implies tedious zooming in and out,
while for a computational decision support algorithm, it leads to the analysis
of a huge number of small image patches per whole slide image (WSI).
Attention-based multiple instance learning (MIL), where attention estimation is
learned in a weakly supervised manner, has been successfully applied in
computational histopathology, but it is challenged by large numbers of
irrelevant patches, reducing its accuracy. Here, we present an active learning
approach to the problem. Querying the expert to annotate regions of interest in
a WSI guides the formation of high-attention regions for MIL. We train an
attention-based MIL and calculate a confidence metric for every image in the
dataset to select the most uncertain WSIs for expert annotation. We test our
approach on the CAMELYON17 dataset classifying metastatic lymph node sections
in breast cancer. With a novel attention guiding loss, this leads to an
accuracy boost of the trained models with few regions annotated for each class.
Active learning thus improves WSIs classification accuracy, leads to faster and
more robust convergence, and speeds up the annotation process. It may in the
future serve as an important contribution to train MIL models in the clinically
relevant context of cancer classification in histopathology.
</p></li>
</ul>

<h3>Title: Deep-NFA: a Deep $\textit{a contrario}$ Framework for Small Object Detection. (arXiv:2303.01363v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01363">http://arxiv.org/abs/2303.01363</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01363] Deep-NFA: a Deep $\textit{a contrario}$ Framework for Small Object Detection](http://arxiv.org/abs/2303.01363) #robust</code></li>
<li>Summary: <p>The detection of small objects is a challenging task in computer vision.
Conventional object detection methods have difficulty in finding the balance
between high detection and low false alarm rates. In the literature, some
methods have addressed this issue by enhancing the feature map responses, but
without guaranteeing robustness with respect to the number of false alarms
induced by background elements. To tackle this problem, we introduce an
$\textit{a contrario}$ decision criterion into the learning process to take
into account the unexpectedness of small objects. This statistic criterion
enhances the feature map responses while controlling the number of false alarms
(NFA) and can be integrated into any semantic segmentation neural network. Our
add-on NFA module not only allows us to obtain competitive results for small
target and crack detection tasks respectively, but also leads to more robust
and interpretable results.
</p></li>
</ul>

<h3>Title: MLANet: Multi-Level Attention Network with Sub-instruction for Continuous Vision-and-Language Navigation. (arXiv:2303.01396v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01396">http://arxiv.org/abs/2303.01396</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01396] MLANet: Multi-Level Attention Network with Sub-instruction for Continuous Vision-and-Language Navigation](http://arxiv.org/abs/2303.01396) #robust</code></li>
<li>Summary: <p>Vision-and-Language Navigation (VLN) aims to develop intelligent agents to
navigate in unseen environments only through language and vision supervision.
In the recently proposed continuous settings (continuous VLN), the agent must
act in a free 3D space and faces tougher challenges like real-time execution,
complex instruction understanding, and long action sequence prediction. For a
better performance in continuous VLN, we design a multi-level instruction
understanding procedure and propose a novel model, Multi-Level Attention
Network (MLANet). The first step of MLANet is to generate sub-instructions
efficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the
raw instruction into sub-instructions and generate a new sub-instruction
dataset named ``FSASub". FSA is annotation-free and faster than the current
method by 70 times, thus fitting the real-time requirement in continuous VLN.
To solve the complex instruction understanding problem, MLANet needs a global
perception of the instruction and observations. We propose a Multi-Level
Attention (MLA) module to fuse vision, low-level semantics, and high-level
semantics, which produce features containing a dynamic and global comprehension
of the task. MLA also mitigates the adverse effects of noise words, thus
ensuring a robust understanding of the instruction. To correctly predict
actions in long trajectories, MLANet needs to focus on what sub-instruction is
being executed every step. We propose a Peak Attention Loss (PAL) to improve
the flexible and adaptive selection of the current sub-instruction. PAL
benefits the navigation agent by concentrating its attention on the local
information, thus helping the agent predict the most appropriate actions. We
train and test MLANet in the standard benchmark. Experiment results show MLANet
outperforms baselines by a significant margin.
</p></li>
</ul>

<h3>Title: Delivering Arbitrary-Modal Semantic Segmentation. (arXiv:2303.01480v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01480">http://arxiv.org/abs/2303.01480</a></li>
<li>Code URL: <a href="https://github.com/jamycheung/DELIVER">https://github.com/jamycheung/DELIVER</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01480] Delivering Arbitrary-Modal Semantic Segmentation](http://arxiv.org/abs/2303.01480) #robust</code></li>
<li>Summary: <p>Multimodal fusion can make semantic segmentation more robust. However, fusing
an arbitrary number of modalities remains underexplored. To delve into this
problem, we create the DeLiVER arbitrary-modal segmentation benchmark, covering
Depth, LiDAR, multiple Views, Events, and RGB. Aside from this, we provide this
dataset in four severe weather conditions as well as five sensor failure cases
to exploit modal complementarity and resolve partial outages. To make this
possible, we present the arbitrary cross-modal segmentation model CMNeXt. It
encompasses a Self-Query Hub (SQ-Hub) designed to extract effective information
from any modality for subsequent fusion with the RGB representation and adds
only negligible amounts of parameters (~0.01M) per additional modality. On top,
to efficiently and flexibly harvest discriminative cues from the auxiliary
modalities, we introduce the simple Parallel Pooling Mixer (PPX). With
extensive experiments on a total of six benchmarks, our CMNeXt achieves
state-of-the-art performance on the DeLiVER, KITTI-360, MFNet, NYU Depth V2,
UrbanLF, and MCubeS datasets, allowing to scale from 1 to 81 modalities. On the
freshly collected DeLiVER, the quad-modal CMNeXt reaches up to 66.30% in mIoU
with a +9.10% gain as compared to the mono-modal baseline. The DeLiVER dataset
and our code are at: https://jamycheung.github.io/DELIVER.html.
</p></li>
</ul>

<h3>Title: Leveraging Large Text Corpora for End-to-End Speech Summarization. (arXiv:2303.00978v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00978">http://arxiv.org/abs/2303.00978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00978] Leveraging Large Text Corpora for End-to-End Speech Summarization](http://arxiv.org/abs/2303.00978) #robust</code></li>
<li>Summary: <p>End-to-end speech summarization (E2E SSum) is a technique to directly
generate summary sentences from speech. Compared with the cascade approach,
which combines automatic speech recognition (ASR) and text summarization
models, the E2E approach is more promising because it mitigates ASR errors,
incorporates nonverbal information, and simplifies the overall system. However,
since collecting a large amount of paired data (i.e., speech and summary) is
difficult, the training data is usually insufficient to train a robust E2E SSum
system. In this paper, we present two novel methods that leverage a large
amount of external text summarization data for E2E SSum training. The first
technique is to utilize a text-to-speech (TTS) system to generate synthesized
speech, which is used for E2E SSum training with the text summary. The second
is a TTS-free method that directly inputs phoneme sequence instead of
synthesized speech to the E2E SSum model. Experiments show that our proposed
TTS- and phoneme-based methods improve several metrics on the How2 dataset. In
particular, our best system outperforms a previous state-of-the-art one by a
large margin (i.e., METEOR score improvements of more than 6 points). To the
best of our knowledge, this is the first work to use external language
resources for E2E SSum. Moreover, we report a detailed analysis of the How2
dataset to confirm the validity of our proposed E2E SSum system.
</p></li>
</ul>

<h3>Title: Denoising-based UNMT is more robust to word-order divergence than MASS-based UNMT. (arXiv:2303.01191v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01191">http://arxiv.org/abs/2303.01191</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01191] Denoising-based UNMT is more robust to word-order divergence than MASS-based UNMT](http://arxiv.org/abs/2303.01191) #robust</code></li>
<li>Summary: <p>We aim to investigate whether UNMT approaches with self-supervised
pre-training are robust to word-order divergence between language pairs. We
achieve this by comparing two models pre-trained with the same self-supervised
pre-training objective. The first model is trained on language pairs with
different word-orders, and the second model is trained on the same language
pairs with source language re-ordered to match the word-order of the target
language. Ideally, UNMT approaches which are robust to word-order divergence
should exhibit no visible performance difference between the two
configurations. In this paper, we investigate two such self-supervised
pre-training based UNMT approaches, namely Masked Sequence-to-Sequence
Pre-Training, (MASS) (which does not have shuffling noise) and Denoising
AutoEncoder (DAE), (which has shuffling noise).
</p></li>
</ul>

<p>We experiment with five English$\rightarrow$Indic language pairs, i.e.,
en-hi, en-bn, en-gu, en-kn, and en-ta) where word-order of the source language
is SVO (Subject-Verb-Object), and the word-order of the target languages is SOV
(Subject-Object-Verb). We observed that for these language pairs, DAE-based
UNMT approach consistently outperforms MASS in terms of translation accuracies.
Moreover, bridging the word-order gap using reordering improves the translation
accuracy of MASS-based UNMT models, while it cannot improve the translation
accuracy of DAE-based UNMT models. This observation indicates that DAE-based
UNMT is more robust to word-order divergence than MASS-based UNMT.
Word-shuffling noise in DAE approach could be the possible reason for the
approach being robust to word-order divergence.
</p>

<h3>Title: Can ChatGPT Assess Human Personalities? A General Evaluation Framework. (arXiv:2303.01248v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01248">http://arxiv.org/abs/2303.01248</a></li>
<li>Code URL: <a href="https://github.com/kali-hac/chatgpt-mbti">https://github.com/kali-hac/chatgpt-mbti</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01248] Can ChatGPT Assess Human Personalities? A General Evaluation Framework](http://arxiv.org/abs/2303.01248) #robust</code></li>
<li>Summary: <p>Large Language Models (LLMs) especially ChatGPT have produced impressive
results in various areas, but their potential human-like psychology is still
largely unexplored. Existing works study the virtual personalities of LLMs but
rarely explore the possibility of analyzing human personalities via LLMs. This
paper presents a generic evaluation framework for LLMs to assess human
personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,
we first devise unbiased prompts by randomly permuting options in MBTI
questions and adopt the average testing result to encourage more impartial
answer generation. Then, we propose to replace the subject in question
statements to enable flexible queries and assessments on different subjects
from LLMs. Finally, we re-formulate the question instructions in a manner of
correctness evaluation to facilitate LLMs to generate clearer responses. The
proposed framework enables LLMs to flexibly assess personalities of different
groups of people. We further propose three evaluation metrics to measure the
consistency, robustness, and fairness of assessment results from
state-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal
ChatGPT's ability to assess human personalities, and the average results
demonstrate that it can achieve more consistent and fairer assessments in spite
of lower robustness against prompt biases compared with InstructGPT.
</p></li>
</ul>

<h3>Title: Adversarial Examples Exist in Two-Layer ReLU Networks for Low Dimensional Data Manifolds. (arXiv:2303.00783v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00783">http://arxiv.org/abs/2303.00783</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00783] Adversarial Examples Exist in Two-Layer ReLU Networks for Low Dimensional Data Manifolds](http://arxiv.org/abs/2303.00783) #robust</code></li>
<li>Summary: <p>Despite a great deal of research, it is still not well-understood why trained
neural networks are highly vulnerable to adversarial examples. In this work we
focus on two-layer neural networks trained using data which lie on a low
dimensional linear subspace. We show that standard gradient methods lead to
non-robust neural networks, namely, networks which have large gradients in
directions orthogonal to the data subspace, and are susceptible to small
adversarial $L_2$-perturbations in these directions. Moreover, we show that
decreasing the initialization scale of the training algorithm, or adding $L_2$
regularization, can make the trained network more robust to adversarial
perturbations orthogonal to the data.
</p></li>
</ul>

<h3>Title: Multi-task neural networks by learned contextual inputs. (arXiv:2303.00788v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00788">http://arxiv.org/abs/2303.00788</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00788] Multi-task neural networks by learned contextual inputs](http://arxiv.org/abs/2303.00788) #robust</code></li>
<li>Summary: <p>This paper explores learned-context neural networks. It is a multi-task
learning architecture based on a fully shared neural network and an augmented
input vector containing trainable task parameters. The architecture is
interesting due to its powerful task adaption mechanism, which facilitates a
low-dimensional task parameter space. Theoretically, we show that a scalar task
parameter is sufficient for universal approximation of all tasks, which is not
necessarily the case for more common architectures. Evidence towards the
practicality of such a small task parameter space is given empirically. The
task parameter space is found to be well-behaved, and simplifies workflows
related to updating models as new data arrives, and training new tasks when the
shared parameters are frozen. Additionally, the architecture displays
robustness towards cases with few data points. The architecture's performance
is compared to similar neural network architectures on ten datasets.
</p></li>
</ul>

<h3>Title: Physics-informed neural networks for solving forward and inverse problems in complex beam systems. (arXiv:2303.01055v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01055">http://arxiv.org/abs/2303.01055</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01055] Physics-informed neural networks for solving forward and inverse problems in complex beam systems](http://arxiv.org/abs/2303.01055) #robust</code></li>
<li>Summary: <p>This paper proposes a new framework using physics-informed neural networks
(PINNs) to simulate complex structural systems that consist of single and
double beams based on Euler-Bernoulli and Timoshenko theory, where the double
beams are connected with a Winkler foundation. In particular, forward and
inverse problems for the Euler-Bernoulli and Timoshenko partial differential
equations (PDEs) are solved using nondimensional equations with the
physics-informed loss function. Higher-order complex beam PDEs are efficiently
solved for forward problems to compute the transverse displacements and
cross-sectional rotations with less than 1e-3 percent error. Furthermore,
inverse problems are robustly solved to determine the unknown dimensionless
model parameters and applied force in the entire space-time domain, even in the
case of noisy data. The results suggest that PINNs are a promising strategy for
solving problems in engineering structures and machines involving beam systems.
</p></li>
</ul>

<h3>Title: The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness in ReLU Networks. (arXiv:2303.01456v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01456">http://arxiv.org/abs/2303.01456</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01456] The Double-Edged Sword of Implicit Bias: Generalization vs](http://arxiv.org/abs/2303.01456) #robust</code></li>
<li>Summary: <p>In this work, we study the implications of the implicit bias of gradient flow
on generalization and adversarial robustness in ReLU networks. We focus on a
setting where the data consists of clusters and the correlations between
cluster means are small, and show that in two-layer ReLU networks gradient flow
is biased towards solutions that generalize well, but are highly vulnerable to
adversarial examples. Our results hold even in cases where the network has many
more parameters than training examples. Despite the potential for harmful
overfitting in such overparameterized settings, we prove that the implicit bias
of gradient flow prevents it. However, the implicit bias also leads to
non-robust solutions (susceptible to small adversarial $\ell_2$-perturbations),
even though robust networks that fit the data exist.
</p></li>
</ul>

<h3>Title: Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using Online Function Approximation. (arXiv:2303.01464v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01464">http://arxiv.org/abs/2303.01464</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01464] Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using Online Function Approximation](http://arxiv.org/abs/2303.01464) #robust</code></li>
<li>Summary: <p>We present the OMG-CMDP! algorithm for regret minimization in adversarial
Contextual MDPs. The algorithm operates under the minimal assumptions of
realizable function class and access to online least squares and log loss
regression oracles. Our algorithm is efficient (assuming efficient online
regression oracles), simple and robust to approximation errors. It enjoys an
$\widetilde{O}(H^{2.5} \sqrt{ T|S||A| ( \mathcal{R}(\mathcal{O}) + H
\log(\delta^{-1}) )})$ regret guarantee, with $T$ being the number of episodes,
$S$ the state space, $A$ the action space, $H$ the horizon and
$\mathcal{R}(\mathcal{O}) = \mathcal{R}(\mathcal{O}_{\mathrm{sq}}^\mathcal{F})</li>
<li>\mathcal{R}(\mathcal{O}_{\mathrm{log}}^\mathcal{P})$ is the sum of the
regression oracles' regret, used to approximate the context-dependent rewards
and dynamics, respectively. To the best of our knowledge, our algorithm is the
first efficient rate optimal regret minimization algorithm for adversarial
CMDPs that operates under the minimal standard assumption of online function
approximation.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis. (arXiv:2303.00815v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00815">http://arxiv.org/abs/2303.00815</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00815] Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis](http://arxiv.org/abs/2303.00815) #extraction</code></li>
<li>Summary: <p>Aspect term extraction is a fundamental task in fine-grained sentiment
analysis, which aims at detecting customer's opinion targets from reviews on
product or service. The traditional supervised models can achieve promising
results with annotated datasets, however, the performance dramatically
decreases when they are applied to the task of cross-domain aspect term
extraction. Existing cross-domain transfer learning methods either directly
inject linguistic features into Language models, making it difficult to
transfer linguistic knowledge to target domain, or rely on the fixed predefined
prompts, which is time-consuming to construct the prompts over all potential
aspect term spans. To resolve the limitations, we propose a soft prompt-based
joint learning method for cross domain aspect term extraction in this paper.
Specifically, by incorporating external linguistic features, the proposed
method learn domain-invariant representations between source and target domains
via multiple objectives, which bridges the gap between domains with varied
distributions of aspect terms. Further, the proposed method interpolates a set
of transferable soft prompts consisted of multiple learnable vectors that are
beneficial to detect aspect terms in target domain. Extensive experiments are
conducted on the benchmark datasets and the experimental results demonstrate
the effectiveness of the proposed method for cross-domain aspect terms
extraction.
</p></li>
</ul>

<h3>Title: NLP Workbench: Efficient and Extensible Integration of State-of-the-art Text Mining Tools. (arXiv:2303.01410v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01410">http://arxiv.org/abs/2303.01410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01410] NLP Workbench: Efficient and Extensible Integration of State-of-the-art Text Mining Tools](http://arxiv.org/abs/2303.01410) #extraction</code></li>
<li>Summary: <p>NLP Workbench is a web-based platform for text mining that allows non-expert
users to obtain semantic understanding of large-scale corpora using
state-of-the-art text mining models. The platform is built upon latest
pre-trained models and open source systems from academia that provide semantic
analysis functionalities, including but not limited to entity linking,
sentiment analysis, semantic parsing, and relation extraction. Its extensible
design enables researchers and developers to smoothly replace an existing model
or integrate a new one. To improve efficiency, we employ a microservice
architecture that facilitates allocation of acceleration hardware and
parallelization of computation. This paper presents the architecture of NLP
Workbench and discusses the challenges we faced in designing it. We also
discuss diverse use cases of NLP Workbench and the benefits of using it over
other approaches. The platform is under active development, with its source
code released under the MIT license. A website and a short video demonstrating
our platform are also available.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Stochastic Clustered Federated Learning. (arXiv:2303.00897v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00897">http://arxiv.org/abs/2303.00897</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00897] Stochastic Clustered Federated Learning](http://arxiv.org/abs/2303.00897) #federate</code></li>
<li>Summary: <p>Federated learning is a distributed learning framework that takes full
advantage of private data samples kept on edge devices. In real-world federated
learning systems, these data samples are often decentralized and
Non-Independently Identically Distributed (Non-IID), causing divergence and
performance degradation in the federated learning process. As a new solution,
clustered federated learning groups federated clients with similar data
distributions to impair the Non-IID effects and train a better model for every
cluster. This paper proposes StoCFL, a novel clustered federated learning
approach for generic Non-IID issues. In detail, StoCFL implements a flexible
CFL framework that supports an arbitrary proportion of client participation and
newly joined clients for a varying FL system, while maintaining a great
improvement in model performance. The intensive experiments are conducted by
using four basic Non-IID settings and a real-world dataset. The results show
that StoCFL could obtain promising cluster results even when the number of
clusters is unknown. Based on the client clustering results, models trained
with StoCFL outperform baseline approaches in a variety of contexts.
</p></li>
</ul>

<h3>Title: Communication Trade-offs in Federated Learning of Spiking Neural Networks. (arXiv:2303.00928v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00928">http://arxiv.org/abs/2303.00928</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00928] Communication Trade-offs in Federated Learning of Spiking Neural Networks](http://arxiv.org/abs/2303.00928) #federate</code></li>
<li>Summary: <p>Spiking Neural Networks (SNNs) are biologically inspired alternatives to
conventional Artificial Neural Networks (ANNs). Despite promising preliminary
results, the trade-offs in the training of SNNs in a distributed scheme are not
well understood. Here, we consider SNNs in a federated learning setting where a
high-quality global model is created by aggregating multiple local models from
the clients without sharing any data. We investigate federated learning for
training multiple SNNs at clients when two mechanisms reduce the uplink
communication cost: i) random masking of the model updates sent from the
clients to the server; and ii) client dropouts where some clients do not send
their updates to the server. We evaluated the performance of the SNNs using a
subset of the Spiking Heidelberg digits (SHD) dataset. The results show that a
trade-off between the random masking and the client drop probabilities is
crucial to obtain a satisfactory performance for a fixed number of clients.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: I2P-Rec: Recognizing Images on Large-scale Point Cloud Maps through Bird's Eye View Projections. (arXiv:2303.01043v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01043">http://arxiv.org/abs/2303.01043</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01043] I2P-Rec: Recognizing Images on Large-scale Point Cloud Maps through Bird's Eye View Projections](http://arxiv.org/abs/2303.01043) #fair</code></li>
<li>Summary: <p>Place recognition is an important technique for autonomous cars to achieve
full autonomy since it can provide an initial guess to online localization
algorithms. Although current methods based on images or point clouds have
achieved satisfactory performance, localizing the images on a large-scale point
cloud map remains a fairly unexplored problem. This cross-modal matching task
is challenging due to the difficulty in extracting consistent descriptors from
images and point clouds. In this paper, we propose the I2P-Rec method to solve
the problem by transforming the cross-modal data into the same modality.
Specifically, we leverage on the recent success of depth estimation networks to
recover point clouds from images. We then project the point clouds into Bird's
Eye View (BEV) images. Using the BEV image as an intermediate representation,
we extract global features with a Convolutional Neural Network followed by a
NetVLAD layer to perform matching. We evaluate our method on the KITTI dataset.
The experimental results show that, with only a small set of training data,
I2P-Rec can achieve a recall rate at Top-1 over 90\%. Also, it can generalize
well to unknown environments, achieving recall rates at Top-1\% over 80\% and
90\%, when localizing monocular images and stereo images on point cloud maps,
respectively.
</p></li>
</ul>

<h3>Title: Variance-reduced Clipping for Non-convex Optimization. (arXiv:2303.00883v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00883">http://arxiv.org/abs/2303.00883</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00883] Variance-reduced Clipping for Non-convex Optimization](http://arxiv.org/abs/2303.00883) #fair</code></li>
<li>Summary: <p>Gradient clipping is a standard training technique used in deep learning
applications such as large-scale language modeling to mitigate exploding
gradients. Recent experimental studies have demonstrated a fairly special
behavior in the smoothness of the training objective along its trajectory when
trained with gradient clipping. That is, the smoothness grows with the gradient
norm. This is in clear contrast to the well-established assumption in folklore
non-convex optimization, a.k.a. $L$-smoothness, where the smoothness is assumed
to be bounded by a constant $L$ globally. The recently introduced
$(L_0,L_1)$-smoothness is a more relaxed notion that captures such behavior in
non-convex optimization. In particular, it has been shown that under this
relaxed smoothness assumption, SGD with clipping requires $O(\epsilon^{-4})$
stochastic gradient computations to find an $\epsilon$-stationary solution. In
this paper, we employ a variance reduction technique, namely SPIDER, and
demonstrate that for a carefully designed learning rate, this complexity is
improved to $O(\epsilon^{-3})$ which is order-optimal. The corresponding
learning rate comprises the clipping technique to mitigate the growing
smoothness. Moreover, when the objective function is the average of $n$
components, we improve the existing $O(n\epsilon^{-2})$ bound on the stochastic
gradient complexity to order-optimal $O(\sqrt{n} \epsilon^{-2} + n)$.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Disentangling Orthogonal Planes for Indoor Panoramic Room Layout Estimation with Cross-Scale Distortion Awareness. (arXiv:2303.00971v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00971">http://arxiv.org/abs/2303.00971</a></li>
<li>Code URL: <a href="https://github.com/zhijieshen-bjtu/dopnet">https://github.com/zhijieshen-bjtu/dopnet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00971] Disentangling Orthogonal Planes for Indoor Panoramic Room Layout Estimation with Cross-Scale Distortion Awareness](http://arxiv.org/abs/2303.00971) #interpretability</code></li>
<li>Summary: <p>Based on the Manhattan World assumption, most existing indoor layout
estimation schemes focus on recovering layouts from vertically compressed 1D
sequences. However, the compression procedure confuses the semantics of
different planes, yielding inferior performance with ambiguous
interpretability.
</p></li>
</ul>

<p>To address this issue, we propose to disentangle this 1D representation by
pre-segmenting orthogonal (vertical and horizontal) planes from a complex
scene, explicitly capturing the geometric cues for indoor layout estimation.
Considering the symmetry between the floor boundary and ceiling boundary, we
also design a soft-flipping fusion strategy to assist the pre-segmentation.
Besides, we present a feature assembling mechanism to effectively integrate
shallow and deep features with distortion distribution awareness. To compensate
for the potential errors in pre-segmentation, we further leverage triple
attention to reconstruct the disentangled sequences for better performance.
Experiments on four popular benchmarks demonstrate our superiority over
existing SoTA solutions, especially on the 3DIoU metric. The code is available
at \url{https://github.com/zhijieshen-bjtu/DOPNet}.
</p>

<h3>Title: DAVA: Disentangling Adversarial Variational Autoencoder. (arXiv:2303.01384v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01384">http://arxiv.org/abs/2303.01384</a></li>
<li>Code URL: <a href="https://github.com/besterma/dava">https://github.com/besterma/dava</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01384] DAVA: Disentangling Adversarial Variational Autoencoder](http://arxiv.org/abs/2303.01384) #interpretability</code></li>
<li>Summary: <p>The use of well-disentangled representations offers many advantages for
downstream tasks, e.g. an increased sample efficiency, or better
interpretability. However, the quality of disentangled interpretations is often
highly dependent on the choice of dataset-specific hyperparameters, in
particular the regularization strength. To address this issue, we introduce
DAVA, a novel training procedure for variational auto-encoders. DAVA completely
alleviates the problem of hyperparameter selection. We compare DAVA to models
with optimal hyperparameters. Without any hyperparameter tuning, DAVA is
competitive on a diverse range of commonly used datasets. Underlying DAVA, we
discover a necessary condition for unsupervised disentanglement, which we call
PIPE. We demonstrate the ability of PIPE to positively predict the performance
of downstream models in abstract reasoning. We also thoroughly investigate
correlations with existing supervised and unsupervised metrics. The code is
available at https://github.com/besterma/dava.
</p></li>
</ul>

<h3>Title: Customer Churn Prediction Model using Explainable Machine Learning. (arXiv:2303.00960v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00960">http://arxiv.org/abs/2303.00960</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00960] Customer Churn Prediction Model using Explainable Machine Learning](http://arxiv.org/abs/2303.00960) #interpretability</code></li>
<li>Summary: <p>It becomes a significant challenge to predict customer behavior and retain an
existing customer with the rapid growth of digitization which opens up more
opportunities for customers to choose from subscription-based products and
services model. Since the cost of acquiring a new customer is five-times higher
than retaining an existing customer, henceforth, there is a need to address the
customer churn problem which is a major threat across the Industries.
Considering direct impact on revenues, companies identify the factors that
increases the customer churn rate. Here, key objective of the paper is to
develop a unique Customer churn prediction model which can help to predict
potential customers who are most likely to churn and such early warnings can
help to take corrective measures to retain them. Here, we evaluated and
analyzed the performance of various tree-based machine learning approaches and
algorithms and identified the Extreme Gradient Boosting XGBOOST Classifier as
the most optimal solution to Customer churn problem. To deal with such
real-world problems, Paper emphasize the Model interpretability which is an
important metric to help customers to understand how Churn Prediction Model is
making predictions. In order to improve Model explainability and transparency,
paper proposed a novel approach to calculate Shapley values for possible
combination of features to explain which features are the most
important/relevant features for a model to become highly interpretable,
transparent and explainable to potential customers.
</p></li>
</ul>

<h3>Title: Interpretable System Identification and Long-term Prediction on Time-Series Data. (arXiv:2303.01193v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01193">http://arxiv.org/abs/2303.01193</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01193] Interpretable System Identification and Long-term Prediction on Time-Series Data](http://arxiv.org/abs/2303.01193) #interpretability</code></li>
<li>Summary: <p>Time-series prediction has drawn considerable attention during the past
decades fueled by the emerging advances of deep learning methods. However, most
neural network based methods lack interpretability and fail in extracting the
hidden mechanism of the targeted physical system. To overcome these
shortcomings, an interpretable sparse system identification method without any
prior knowledge is proposed in this study. This method adopts the Fourier
transform to reduces the irrelevant items in the dictionary matrix, instead of
indiscriminate usage of polynomial functions in most system identification
methods. It shows an interpretable system representation and greatly reduces
computing cost. With the adoption of $l_1$ norm in regularizing the parameter
matrix, a sparse description of the system model can be achieved. Moreover,
Three data sets including the water conservancy data, global temperature data
and financial data are used to test the performance of the proposed method.
Although no prior knowledge was known about the physical background,
experimental results show that our method can achieve long-term prediction
regardless of the noise and incompleteness in the original data more accurately
than the widely-used baseline data-driven methods. This study may provide some
insight into time-series prediction investigations, and suggests that an
white-box system identification method may extract the easily overlooked yet
inherent periodical features and may beat neural-network based black-box
methods on long-term prediction tasks.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Human Motion Diffusion as a Generative Prior. (arXiv:2303.01418v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01418">http://arxiv.org/abs/2303.01418</a></li>
<li>Code URL: <a href="https://github.com/priormdm/priormdm">https://github.com/priormdm/priormdm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01418] Human Motion Diffusion as a Generative Prior](http://arxiv.org/abs/2303.01418) #diffusion</code></li>
<li>Summary: <p>In recent months, we witness a leap forward as denoising diffusion models
were introduced to Motion Generation. Yet, the main gap in this field remains
the low availability of data. Furthermore, the expensive acquisition process of
motion biases the already modest data towards short single-person sequences.
With such a shortage, more elaborate generative tasks are left behind. In this
paper, we show that this gap can be mitigated using a pre-trained
diffusion-based model as a generative prior. We demonstrate the prior is
effective for fine-tuning, in a few-, and even a zero-shot manner. For the
zero-shot setting, we tackle the challenge of long sequence generation. We
introduce DoubleTake, an inference-time method with which we demonstrate up to
10-minute long animations of prompted intervals and their meaningful and
controlled transition, using the prior that was trained for 10-second
generations. For the few-shot setting, we consider two-person generation. Using
two fixed priors and as few as a dozen training examples, we learn a slim
communication block, ComMDM, to infuse interaction between the two resulting
motions. Finally, using fine-tuning, we train the prior to semantically
complete motions from a single prescribed joint. Then, we use our
DiffusionBlending to blend a few such models into a single one that responds
well to the combination of the individual control signals, enabling
fine-grained joint- and trajectory-level control and editing. Using an
off-the-shelf state-of-the-art (SOTA) motion diffusion model as a prior, we
evaluate our approach for the three mentioned cases and show that we
consistently outperform SOTA models that were designed and trained for those
tasks.
</p></li>
</ul>

<h3>Title: Consistency Models. (arXiv:2303.01469v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.01469">http://arxiv.org/abs/2303.01469</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.01469] Consistency Models](http://arxiv.org/abs/2303.01469) #diffusion</code></li>
<li>Summary: <p>Diffusion models have made significant breakthroughs in image, audio, and
video generation, but they depend on an iterative generation process that
causes slow sampling speed and caps their potential for real-time applications.
To overcome this limitation, we propose consistency models, a new family of
generative models that achieve high sample quality without adversarial
training. They support fast one-step generation by design, while still allowing
for few-step sampling to trade compute for sample quality. They also support
zero-shot data editing, like image inpainting, colorization, and
super-resolution, without requiring explicit training on these tasks.
Consistency models can be trained either as a way to distill pre-trained
diffusion models, or as standalone generative models. Through extensive
experiments, we demonstrate that they outperform existing distillation
techniques for diffusion models in one- and few-step generation. For example,
we achieve the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on
ImageNet 64x64 for one-step generation. When trained as standalone generative
models, consistency models also outperform single-step, non-adversarial
generative models on standard benchmarks like CIFAR-10, ImageNet 64x64 and LSUN
256x256.
</p></li>
</ul>

<h3>Title: Continuous-Time Functional Diffusion Processes. (arXiv:2303.00800v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00800">http://arxiv.org/abs/2303.00800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00800] Continuous-Time Functional Diffusion Processes](http://arxiv.org/abs/2303.00800) #diffusion</code></li>
<li>Summary: <p>We introduce functional diffusion processes (FDPs), which generalize
traditional score-based diffusion models to infinite-dimensional function
spaces. FDPs require a new mathematical framework to describe the forward and
backward dynamics, and several extensions to derive practical training
objectives. These include infinite-dimensional versions of the Girsanov
theorem, in order to be able to compute an ELBO, and of the sampling theorem,
in order to guarantee that functional evaluations in a countable set of points
are equivalent to infinite-dimensional functions. We use FDPs to build a new
breed of generative models in function spaces, which do not require specialized
network architectures, and that can work with any kind of continuous data. Our
results on synthetic and real data illustrate the advantages of FDPs in
simplifying the design requirements of diffusion models.
</p></li>
</ul>

<h3>Title: Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.00848">http://arxiv.org/abs/2303.00848</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.00848] Understanding the Diffusion Objective as a Weighted Integral of ELBOs](http://arxiv.org/abs/2303.00848) #diffusion</code></li>
<li>Summary: <p>Diffusion models in the literature are optimized with various objectives that
are special cases of a weighted loss, where the weighting function specifies
the weight per noise level. Uniform weighting corresponds to maximizing the
ELBO, a principled approximation of maximum likelihood. In current practice
diffusion models are optimized with non-uniform weighting due to better results
in terms of sample quality. In this work we expose a direct relationship
between the weighted loss (with any weighting) and the ELBO objective.
</p></li>
</ul>

<p>We show that the weighted loss can be written as a weighted integral of
ELBOs, with one ELBO per noise level. If the weighting function is monotonic,
then the weighted loss is a likelihood-based objective: it maximizes the ELBO
under simple data augmentation, namely Gaussian noise perturbation. Our main
contribution is a deeper theoretical understanding of the diffusion objective,
but we also performed some experiments comparing monotonic with non-monotonic
weightings, finding that monotonic weighting performs competitively with the
best published results.
</p>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
