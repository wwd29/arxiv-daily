<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Class Attendance System in Education with Deep Learning Method. (arXiv:2309.13317v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13317">http://arxiv.org/abs/2309.13317</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13317]] Class Attendance System in Education with Deep Learning Method(http://arxiv.org/abs/2309.13317)</code></li>
<li>Summary: <p>With the advancing technology, the hardware gain of computers and the
increase in the processing capacity of processors have facilitated the
processing of instantaneous and real-time images. Face recognition processes
are also studies in the field of image processing. Facial recognition processes
are frequently used in security applications and commercial applications.
Especially in the last 20 years, the high performances of artificial
intelligence (AI) studies have contributed to the spread of these studies in
many different fields. Education is one of them. The potential and advantages
of using AI in education; can be grouped under three headings: student,
teacher, and institution. One of the institutional studies may be the security
of educational environments and the contribution of automation to education and
training processes. From this point of view, deep learning methods, one of the
sub-branches of AI, were used in this study. For object detection from images,
a pioneering study has been designed and successfully implemented to keep
records of students' entrance to the educational institution and to perform
class attendance with images taken from the camera using image processing
algorithms. The application of the study to real-life problems will be carried
out in a school determined in the 2022-2023 academic year.
</p></li>
</ul>

<h2>privacy</h2>
<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Investigating Efficient Deep Learning Architectures For Side-Channel Attacks on AES. (arXiv:2309.13170v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13170">http://arxiv.org/abs/2309.13170</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13170]] Investigating Efficient Deep Learning Architectures For Side-Channel Attacks on AES(http://arxiv.org/abs/2309.13170)</code></li>
<li>Summary: <p>Over the past few years, deep learning has been getting progressively more
popular for the exploitation of side-channel vulnerabilities in embedded
cryptographic applications, as it offers advantages in terms of the amount of
attack traces required for effective key recovery. A number of effective
attacks using neural networks have already been published, but reducing their
cost in terms of the amount of computing resources and data required is an
ever-present goal, which we pursue in this work. We focus on the ANSSI
Side-Channel Attack Database (ASCAD), and produce a JAX-based framework for
deep-learning-based SCA, with which we reproduce a selection of previous
results and build upon them in an attempt to improve their performance. We also
investigate the effectiveness of various Transformer-based models.
</p></li>
</ul>

<h3>Title: Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks. (arXiv:2309.13256v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13256">http://arxiv.org/abs/2309.13256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13256]] Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks(http://arxiv.org/abs/2309.13256)</code></li>
<li>Summary: <p>Pre-trained language models (PLMs) have demonstrated remarkable performance
as few-shot learners. However, their security risks under such settings are
largely unexplored. In this work, we conduct a pilot study showing that PLMs as
few-shot learners are highly vulnerable to backdoor attacks while existing
defenses are inadequate due to the unique challenges of few-shot scenarios. To
address such challenges, we advocate MDP, a novel lightweight, pluggable, and
effective defense for PLMs as few-shot learners. Specifically, MDP leverages
the gap between the masking-sensitivity of poisoned and clean samples: with
reference to the limited few-shot data as distributional anchors, it compares
the representations of given samples under varying masking and identifies
poisoned samples as ones with significant variations. We show analytically that
MDP creates an interesting dilemma for the attacker to choose between attack
effectiveness and detection evasiveness. The empirical evaluation using
benchmark datasets and representative attacks validates the efficacy of MDP.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations. (arXiv:2309.13150v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13150">http://arxiv.org/abs/2309.13150</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13150]] Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations(http://arxiv.org/abs/2309.13150)</code></li>
<li>Summary: <p>In recent years, computer vision has made remarkable advancements in
autonomous driving and robotics. However, it has been observed that deep
learning-based visual perception models lack robustness when faced with camera
motion perturbations. The current certification process for assessing
robustness is costly and time-consuming due to the extensive number of image
projections required for Monte Carlo sampling in the 3D camera motion space. To
address these challenges, we present a novel, efficient, and practical
framework for certifying the robustness of 3D-2D projective transformations
against camera motion perturbations. Our approach leverages a smoothing
distribution over the 2D pixel space instead of in the 3D physical space,
eliminating the need for costly camera motion sampling and significantly
enhancing the efficiency of robustness certifications. With the pixel-wise
smoothed classifier, we are able to fully upper bound the projection errors
using a technique of uniform partitioning in camera motion space. Additionally,
we extend our certification framework to a more general scenario where only a
single-frame point cloud is required in the projection oracle. This is achieved
by deriving Lipschitz-based approximated partition intervals. Through extensive
experimentation, we validate the trade-off between effectiveness and efficiency
enabled by our proposed method. Remarkably, our approach achieves approximately
80% certified accuracy while utilizing only 30% of the projected image frames.
</p></li>
</ul>

<h3>Title: Flow Factorized Representation Learning. (arXiv:2309.13167v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13167">http://arxiv.org/abs/2309.13167</a></li>
<li>Code URL: https://github.com/kingjamessong/latent-flow</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13167]] Flow Factorized Representation Learning(http://arxiv.org/abs/2309.13167)</code></li>
<li>Summary: <p>A prominent goal of representation learning research is to achieve
representations which are factorized in a useful manner with respect to the
ground truth factors of variation. The fields of disentangled and equivariant
representation learning have approached this ideal from a range of
complimentary perspectives; however, to date, most approaches have proven to
either be ill-specified or insufficiently flexible to effectively separate all
realistic factors of interest in a learned latent space. In this work, we
propose an alternative viewpoint on such structured representation learning
which we call Flow Factorized Representation Learning, and demonstrate it to
learn both more efficient and more usefully structured representations than
existing frameworks. Specifically, we introduce a generative model which
specifies a distinct set of latent probability paths that define different
input transformations. Each latent flow is generated by the gradient field of a
learned potential following dynamic optimal transport. Our novel setup brings
new understandings to both \textit{disentanglement} and \textit{equivariance}.
We show that our model achieves higher likelihoods on standard representation
learning benchmarks while simultaneously being closer to approximately
equivariant models. Furthermore, we demonstrate that the transformations
learned by our model are flexibly composable and can also extrapolate to new
data, implying a degree of robustness and generalizability approaching the
ultimate goal of usefully factorized representation learning.
</p></li>
</ul>

<h3>Title: Spatial-frequency channels, shape bias, and adversarial robustness. (arXiv:2309.13190v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13190">http://arxiv.org/abs/2309.13190</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13190]] Spatial-frequency channels, shape bias, and adversarial robustness(http://arxiv.org/abs/2309.13190)</code></li>
<li>Summary: <p>What spatial frequency information do humans and neural networks use to
recognize objects? In neuroscience, critical band masking is an established
tool that can reveal the frequency-selective filters used for object
recognition. Critical band masking measures the sensitivity of recognition
performance to noise added at each spatial frequency. Existing critical band
masking studies show that humans recognize periodic patterns (gratings) and
letters by means of a spatial-frequency filter (or "channel'') that has a
frequency bandwidth of one octave (doubling of frequency). Here, we introduce
critical band masking as a task for network-human comparison and test 14 humans
and 76 neural networks on 16-way ImageNet categorization in the presence of
narrowband noise. We find that humans recognize objects in natural images using
the same one-octave-wide channel that they use for letters and gratings, making
it a canonical feature of human object recognition. On the other hand, the
neural network channel, across various architectures and training strategies,
is 2-4 times as wide as the human channel. In other words, networks are
vulnerable to high and low frequency noise that does not affect human
performance. Adversarial and augmented-image training are commonly used to
increase network robustness and shape bias. Does this training align network
and human object recognition channels? Three network channel properties
(bandwidth, center frequency, peak noise sensitivity) correlate strongly with
shape bias (53% variance explained) and with robustness of
adversarially-trained networks (74% variance explained). Adversarial training
increases robustness but expands the channel bandwidth even further away from
the human bandwidth. Thus, critical band masking reveals that the network
channel is more than twice as wide as the human channel, and that adversarial
training only increases this difference.
</p></li>
</ul>

<h3>Title: MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual. (arXiv:2309.13216v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13216">http://arxiv.org/abs/2309.13216</a></li>
<li>Code URL: https://github.com/Aadharc/Visual_Thermal_Image_Fusion</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13216]] MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual(http://arxiv.org/abs/2309.13216)</code></li>
<li>Summary: <p>Detecting humans from airborne visual and thermal imagery is a fundamental
challenge for Wilderness Search-and-Rescue (WiSAR) teams, who must perform this
function accurately in the face of immense pressure. The ability to fuse these
two sensor modalities can potentially reduce the cognitive load on human
operators and/or improve the effectiveness of computer vision object detection
models. However, the fusion task is particularly challenging in the context of
WiSAR due to hardware limitations and extreme environmental factors. This work
presents Misaligned Image Synthesis and Fusion using Information from Thermal
and Visual (MISFIT-V), a novel two-pronged unsupervised deep learning approach
that utilizes a Generative Adversarial Network (GAN) and a cross-attention
mechanism to capture the most relevant features from each modality.
Experimental results show MISFIT-V offers enhanced robustness against
misalignment and poor lighting/thermal environmental conditions compared to
existing visual-thermal image fusion methods.
</p></li>
</ul>

<h3>Title: NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation. (arXiv:2309.13240v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13240">http://arxiv.org/abs/2309.13240</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13240]] NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation(http://arxiv.org/abs/2309.13240)</code></li>
<li>Summary: <p>In various applications, such as robotic navigation and remote visual
assistance, expanding the field of view (FOV) of the camera proves beneficial
for enhancing environmental perception. Unlike image outpainting techniques
aimed solely at generating aesthetically pleasing visuals, these applications
demand an extended view that faithfully represents the scene. To achieve this,
we formulate a new problem of faithful FOV extrapolation that utilizes a set of
pre-captured images as prior knowledge of the scene. To address this problem,
we present a simple yet effective solution called NeRF-Enhanced Outpainting
(NEO) that uses extended-FOV images generated through NeRF to train a
scene-specific image outpainting model. To assess the performance of NEO, we
conduct comprehensive evaluations on three photorealistic datasets and one
real-world dataset. Extensive experiments on the benchmark datasets showcase
the robustness and potential of our method in addressing this challenge. We
believe our work lays a strong foundation for future exploration within the
research community.
</p></li>
</ul>

<h3>Title: RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias. (arXiv:2309.13245v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13245">http://arxiv.org/abs/2309.13245</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13245]] RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias(http://arxiv.org/abs/2309.13245)</code></li>
<li>Summary: <p>Recently, there has been a surge of interest and attention in
Transformer-based structures, such as Vision Transformer (ViT) and Vision
Multilayer Perceptron (VMLP). Compared with the previous convolution-based
structures, the Transformer-based structure under investigation showcases a
comparable or superior performance under its distinctive attention-based input
token mixer strategy. Introducing adversarial examples as a robustness
consideration has had a profound and detrimental impact on the performance of
well-established convolution-based structures. This inherent vulnerability to
adversarial attacks has also been demonstrated in Transformer-based structures.
In this paper, our emphasis lies on investigating the intrinsic robustness of
the structure rather than introducing novel defense measures against
adversarial attacks. To address the susceptibility to robustness issues, we
employ a rational structure design approach to mitigate such vulnerabilities.
Specifically, we enhance the adversarial robustness of the structure by
increasing the proportion of high-frequency structural robust biases. As a
result, we introduce a novel structure called Robust Bias Transformer-based
Structure (RBFormer) that shows robust superiority compared to several existing
baseline structures. Through a series of extensive experiments, RBFormer
outperforms the original structures by a significant margin, achieving an
impressive improvement of +16.12% and +5.04% across different evaluation
criteria on CIFAR-10 and ImageNet-1k, respectively.
</p></li>
</ul>

<h3>Title: Order-preserving Consistency Regularization for Domain Adaptation and Generalization. (arXiv:2309.13258v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13258">http://arxiv.org/abs/2309.13258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13258]] Order-preserving Consistency Regularization for Domain Adaptation and Generalization(http://arxiv.org/abs/2309.13258)</code></li>
<li>Summary: <p>Deep learning models fail on cross-domain challenges if the model is
oversensitive to domain-specific attributes, e.g., lightning, background,
camera angle, etc. To alleviate this problem, data augmentation coupled with
consistency regularization are commonly adopted to make the model less
sensitive to domain-specific attributes. Consistency regularization enforces
the model to output the same representation or prediction for two views of one
image. These constraints, however, are either too strict or not
order-preserving for the classification probabilities. In this work, we propose
the Order-preserving Consistency Regularization (OCR) for cross-domain tasks.
The order-preserving property for the prediction makes the model robust to
task-irrelevant transformations. As a result, the model becomes less sensitive
to the domain-specific attributes. The comprehensive experiments show that our
method achieves clear advantages on five different cross-domain tasks.
</p></li>
</ul>

<h3>Title: A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression. (arXiv:2309.13077v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13077">http://arxiv.org/abs/2309.13077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13077]] A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression(http://arxiv.org/abs/2309.13077)</code></li>
<li>Summary: <p>Filter pruning and low-rank decomposition are two of the foundational
techniques for structured compression. Although recent efforts have explored
hybrid approaches aiming to integrate the advantages of both techniques, their
performance gains have been modest at best. In this study, we develop a
\textit{Differentiable Framework~(DF)} that can express filter selection, rank
selection, and budget constraint into a single analytical formulation. Within
the framework, we introduce DML-S for filter selection, integrating scheduling
into existing mask learning techniques. Additionally, we present DTL-S for rank
selection, utilizing a singular value thresholding operator. The framework with
DML-S and DTL-S offers a hybrid structured compression methodology that
facilitates end-to-end learning through gradient-base optimization.
Experimental results demonstrate the efficacy of DF, surpassing
state-of-the-art structured compression methods. Our work establishes a robust
and versatile avenue for advancing structured compression techniques.
</p></li>
</ul>

<h3>Title: Prototype-Enhanced Hypergraph Learning for Heterogeneous Information Networks. (arXiv:2309.13092v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13092">http://arxiv.org/abs/2309.13092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13092]] Prototype-Enhanced Hypergraph Learning for Heterogeneous Information Networks(http://arxiv.org/abs/2309.13092)</code></li>
<li>Summary: <p>The variety and complexity of relations in multimedia data lead to
Heterogeneous Information Networks (HINs). Capturing the semantics from such
networks requires approaches capable of utilizing the full richness of the
HINs. Existing methods for modeling HINs employ techniques originally designed
for graph neural networks, and HINs decomposition analysis, like using manually
predefined metapaths. In this paper, we introduce a novel prototype-enhanced
hypergraph learning approach for node classification in HINs. Using hypergraphs
instead of graphs, our method captures higher-order relationships among nodes
and extracts semantic information without relying on metapaths. Our method
leverages the power of prototypes to improve the robustness of the hypergraph
learning process and creates the potential to provide human-interpretable
insights into the underlying network structure. Extensive experiments on three
real-world HINs demonstrate the effectiveness of our method.
</p></li>
</ul>

<h3>Title: OpportunityFinder: A Framework for Automated Causal Inference. (arXiv:2309.13103v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13103">http://arxiv.org/abs/2309.13103</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13103]] OpportunityFinder: A Framework for Automated Causal Inference(http://arxiv.org/abs/2309.13103)</code></li>
<li>Summary: <p>We introduce OpportunityFinder, a code-less framework for performing a
variety of causal inference studies with panel data for non-expert users. In
its current state, OpportunityFinder only requires users to provide raw
observational data and a configuration file. A pipeline is then triggered that
inspects/processes data, chooses the suitable algorithm(s) to execute the
causal study. It returns the causal impact of the treatment on the configured
outcome, together with sensitivity and robustness results. Causal inference is
widely studied and used to estimate the downstream impact of individual's
interactions with products and features. It is common that these causal studies
are performed by scientists and/or economists periodically. Business
stakeholders are often bottle-necked on scientist or economist bandwidth to
conduct causal studies. We offer OpportunityFinder as a solution for commonly
performed causal studies with four key features: (1) easy to use for both
Business Analysts and Scientists, (2) abstraction of multiple algorithms under
a single I/O interface, (3) support for causal impact analysis under binary
treatment with panel data and (4) dynamic selection of algorithm based on scale
of data.
</p></li>
</ul>

<h3>Title: Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications. (arXiv:2309.13207v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13207">http://arxiv.org/abs/2309.13207</a></li>
<li>Code URL: https://github.com/AI2ES/miles-guess</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13207]] Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications(http://arxiv.org/abs/2309.13207)</code></li>
<li>Summary: <p>Robust quantification of predictive uncertainty is critical for understanding
factors that drive weather and climate outcomes. Ensembles provide predictive
uncertainty estimates and can be decomposed physically, but both physics and
machine learning ensembles are computationally expensive. Parametric deep
learning can estimate uncertainty with one model by predicting the parameters
of a probability distribution but do not account for epistemic uncertainty..
Evidential deep learning, a technique that extends parametric deep learning to
higher-order distributions, can account for both aleatoric and epistemic
uncertainty with one model. This study compares the uncertainty derived from
evidential neural networks to those obtained from ensembles. Through
applications of classification of winter precipitation type and regression of
surface layer fluxes, we show evidential deep learning models attaining
predictive accuracy rivaling standard methods, while robustly quantifying both
sources of uncertainty. We evaluate the uncertainty in terms of how well the
predictions are calibrated and how well the uncertainty correlates with
prediction error. Analyses of uncertainty in the context of the inputs reveal
sensitivities to underlying meteorological processes, facilitating
interpretation of the models. The conceptual simplicity, interpretability, and
computational efficiency of evidential neural networks make them highly
extensible, offering a promising approach for reliable and practical
uncertainty quantification in Earth system science modeling. In order to
encourage broader adoption of evidential deep learning in Earth System Science,
we have developed a new Python package, MILES-GUESS
(https://github.com/ai2es/miles-guess), that enables users to train and
evaluate both evidential and ensemble deep learning.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Applying BioBERT to Extract Germline Gene-Disease Associations for Building a Knowledge Graph from the Biomedical Literature. (arXiv:2309.13061v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13061">http://arxiv.org/abs/2309.13061</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13061]] Applying BioBERT to Extract Germline Gene-Disease Associations for Building a Knowledge Graph from the Biomedical Literature(http://arxiv.org/abs/2309.13061)</code></li>
<li>Summary: <p>Published biomedical information has and continues to rapidly increase. The
recent advancements in Natural Language Processing (NLP), have generated
considerable interest in automating the extraction, normalization, and
representation of biomedical knowledge about entities such as genes and
diseases. Our study analyzes germline abstracts in the construction of
knowledge graphs of the of the immense work that has been done in this area for
genes and diseases. This paper presents SimpleGermKG, an automatic knowledge
graph construction approach that connects germline genes and diseases. For the
extraction of genes and diseases, we employ BioBERT, a pre-trained BERT model
on biomedical corpora. We propose an ontology-based and rule-based algorithm to
standardize and disambiguate medical terms. For semantic relationships between
articles, genes, and diseases, we implemented a part-whole relation approach to
connect each entity with its data source and visualize them in a graph-based
knowledge representation. Lastly, we discuss the knowledge graph applications,
limitations, and challenges to inspire the future research of germline corpora.
Our knowledge graph contains 297 genes, 130 diseases, and 46,747 triples.
Graph-based visualizations are used to show the results.
</p></li>
</ul>

<h3>Title: Weakly Supervised Reasoning by Neuro-Symbolic Approaches. (arXiv:2309.13072v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13072">http://arxiv.org/abs/2309.13072</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13072]] Weakly Supervised Reasoning by Neuro-Symbolic Approaches(http://arxiv.org/abs/2309.13072)</code></li>
<li>Summary: <p>Deep learning has largely improved the performance of various natural
language processing (NLP) tasks. However, most deep learning models are
black-box machinery, and lack explicit interpretation. In this chapter, we will
introduce our recent progress on neuro-symbolic approaches to NLP, which
combines different schools of AI, namely, symbolism and connectionism.
Generally, we will design a neural system with symbolic latent structures for
an NLP task, and apply reinforcement learning or its relaxation to perform
weakly supervised reasoning in the downstream task. Our framework has been
successfully applied to various tasks, including table query reasoning,
syntactic structure reasoning, information extraction reasoning, and rule
reasoning. For each application, we will introduce the background, our
approach, and experimental results.
</p></li>
</ul>

<h3>Title: A Survey of Document-Level Information Extraction. (arXiv:2309.13249v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13249">http://arxiv.org/abs/2309.13249</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13249]] A Survey of Document-Level Information Extraction(http://arxiv.org/abs/2309.13249)</code></li>
<li>Summary: <p>Document-level information extraction (IE) is a crucial task in natural
language processing (NLP). This paper conducts a systematic review of recent
document-level IE literature. In addition, we conduct a thorough error analysis
with current state-of-the-art algorithms and identify their limitations as well
as the remaining challenges for the task of document-level IE. According to our
findings, labeling noises, entity coreference resolution, and lack of
reasoning, severely affect the performance of document-level IE. The objective
of this survey paper is to provide more insights and help NLP researchers to
further enhance document-level IE performance.
</p></li>
</ul>

<h3>Title: OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis. (arXiv:2309.13297v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13297">http://arxiv.org/abs/2309.13297</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13297]] OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis(http://arxiv.org/abs/2309.13297)</code></li>
<li>Summary: <p>Aspect-based sentiment Analysis (ABSA) delves into understanding sentiments
specific to distinct elements within textual content. It aims to analyze
user-generated reviews to determine a) the target entity being reviewed, b) the
high-level aspect to which it belongs, c) the sentiment words used to express
the opinion, and d) the sentiment expressed toward the targets and the aspects.
While various benchmark datasets have fostered advancements in ABSA, they often
come with domain limitations and data granularity challenges. Addressing these,
we introduce the OATS dataset, which encompasses three fresh domains and
consists of 20,000 sentence-level quadruples and 13,000 review-level tuples.
Our initiative seeks to bridge specific observed gaps: the recurrent focus on
familiar domains like restaurants and laptops, limited data for intricate
quadruple extraction tasks, and an occasional oversight of the synergy between
sentence and review-level sentiments. Moreover, to elucidate OATS's potential
and shed light on various ABSA subtasks that OATS can solve, we conducted
in-domain and cross-domain experiments, establishing initial baselines. We hope
the OATS dataset augments current resources, paving the way for an encompassing
exploration of ABSA.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Short-Term Load Forecasting with Personalization Layers for Heterogeneous Clients. (arXiv:2309.13194v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13194">http://arxiv.org/abs/2309.13194</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13194]] Federated Short-Term Load Forecasting with Personalization Layers for Heterogeneous Clients(http://arxiv.org/abs/2309.13194)</code></li>
<li>Summary: <p>The advent of smart meters has enabled pervasive collection of energy
consumption data for training short-term load forecasting (STLF) models. In
response to privacy concerns, federated learning (FL) has been proposed as a
privacy-preserving approach for training, but the quality of trained models
degrades as client data becomes heterogeneous. In this paper we alleviate this
drawback using personalization layers, wherein certain layers of an STLF model
in an FL framework are trained exclusively on the clients' own data. To that
end, we propose a personalized FL algorithm (PL-FL) enabling FL to handle
personalization layers. The PL-FL algorithm is implemented by using the Argonne
Privacy-Preserving Federated Learning package. We test the forecast performance
of models trained on the NREL ComStock dataset, which contains heterogeneous
energy consumption data of multiple commercial buildings. Superior performance
of models trained with PL-FL demonstrates that personalization layers enable
classical FL algorithms to handle clients with heterogeneous data.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Beyond Fairness: Age-Harmless Parkinson's Detection via Voice. (arXiv:2309.13292v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13292">http://arxiv.org/abs/2309.13292</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13292]] Beyond Fairness: Age-Harmless Parkinson's Detection via Voice(http://arxiv.org/abs/2309.13292)</code></li>
<li>Summary: <p>Parkinson's disease (PD), a neurodegenerative disorder, often manifests as
speech and voice dysfunction. While utilizing voice data for PD detection has
great potential in clinical applications, the widely used deep learning models
currently have fairness issues regarding different ages of onset. These deep
models perform well for the elderly group (age $&gt;$ 55) but are less accurate
for the young group (age $\leq$ 55). Through our investigation, the discrepancy
between the elderly and the young arises due to 1) an imbalanced dataset and 2)
the milder symptoms often seen in early-onset patients. However, traditional
debiasing methods are impractical as they typically impair the prediction
accuracy for the majority group while minimizing the discrepancy. To address
this issue, we present a new debiasing method using GradCAM-based feature
masking combined with ensemble models, ensuring that neither fairness nor
accuracy is compromised. Specifically, the GradCAM-based feature masking
selectively obscures age-related features in the input voice data while
preserving essential information for PD detection. The ensemble models further
improve the prediction accuracy for the minority (young group). Our approach
effectively improves detection accuracy for early-onset patients without
sacrificing performance for the elderly group. Additionally, we propose a
two-step detection strategy for the young group, offering a practical risk
assessment for potential early-onset PD patients.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h3>Title: Understanding Calibration of Deep Neural Networks for Medical Image Classification. (arXiv:2309.13132v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13132">http://arxiv.org/abs/2309.13132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13132]] Understanding Calibration of Deep Neural Networks for Medical Image Classification(http://arxiv.org/abs/2309.13132)</code></li>
<li>Summary: <p>In the field of medical image analysis, achieving high accuracy is not
enough; ensuring well-calibrated predictions is also crucial. Confidence scores
of a deep neural network play a pivotal role in explainability by providing
insights into the model's certainty, identifying cases that require attention,
and establishing trust in its predictions. Consequently, the significance of a
well-calibrated model becomes paramount in the medical imaging domain, where
accurate and reliable predictions are of utmost importance. While there has
been a significant effort towards training modern deep neural networks to
achieve high accuracy on medical imaging tasks, model calibration and factors
that affect it remain under-explored. To address this, we conducted a
comprehensive empirical study that explores model performance and calibration
under different training regimes. We considered fully supervised training,
which is the prevailing approach in the community, as well as rotation-based
self-supervised method with and without transfer learning, across various
datasets and architecture sizes. Multiple calibration metrics were employed to
gain a holistic understanding of model calibration. Our study reveals that
factors such as weight distributions and the similarity of learned
representations correlate with the calibration trends observed in the models.
Notably, models trained using rotation-based self-supervised pretrained regime
exhibit significantly better calibration while achieving comparable or even
superior performance compared to fully supervised models across different
medical imaging datasets. These findings shed light on the importance of model
calibration in medical image analysis and highlight the benefits of
incorporating self-supervised learning approach to improve both performance and
calibration.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Zero-Shot Object Counting with Language-Vision Models. (arXiv:2309.13097v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13097">http://arxiv.org/abs/2309.13097</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13097]] Zero-Shot Object Counting with Language-Vision Models(http://arxiv.org/abs/2309.13097)</code></li>
<li>Summary: <p>Class-agnostic object counting aims to count object instances of an arbitrary
class at test time. It is challenging but also enables many potential
applications. Current methods require human-annotated exemplars as inputs which
are often unavailable for novel categories, especially for autonomous systems.
Thus, we propose zero-shot object counting (ZSC), a new setting where only the
class name is available during test time. This obviates the need for human
annotators and enables automated operation. To perform ZSC, we propose finding
a few object crops from the input image and use them as counting exemplars. The
goal is to identify patches containing the objects of interest while also being
visually representative for all instances in the image. To do this, we first
construct class prototypes using large language-vision models, including CLIP
and Stable Diffusion, to select the patches containing the target objects.
Furthermore, we propose a ranking model that estimates the counting error of
each patch to select the most suitable exemplars for counting. Experimental
results on a recent class-agnostic counting dataset, FSC-147, validate the
effectiveness of our method.
</p></li>
</ul>

<h3>Title: GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER. (arXiv:2309.13274v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13274">http://arxiv.org/abs/2309.13274</a></li>
<li>Code URL: https://github.com/iva-mzsun/glober</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13274]] GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER(http://arxiv.org/abs/2309.13274)</code></li>
<li>Summary: <p>Video generation necessitates both global coherence and local realism. This
work presents a novel non-autoregressive method GLOBER, which first generates
global features to obtain comprehensive global guidance and then synthesizes
video frames based on the global features to generate coherent videos.
Specifically, we propose a video auto-encoder, where a video encoder encodes
videos into global features, and a video decoder, built on a diffusion model,
decodes the global features and synthesizes video frames in a
non-autoregressive manner. To achieve maximum flexibility, our video decoder
perceives temporal information through normalized frame indexes, which enables
it to synthesize arbitrary sub video clips with predetermined starting and
ending frame indexes. Moreover, a novel adversarial loss is introduced to
improve the global coherence and local realism between the synthesized video
frames. Finally, we employ a diffusion-based video generator to fit the global
features outputted by the video encoder for video generation. Extensive
experimental results demonstrate the effectiveness and efficiency of our
proposed method, and new state-of-the-art results have been achieved on
multiple benchmarks.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Trading-off Mutual Information on Feature Aggregation for Face Recognition. (arXiv:2309.13137v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13137">http://arxiv.org/abs/2309.13137</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13137]] Trading-off Mutual Information on Feature Aggregation for Face Recognition(http://arxiv.org/abs/2309.13137)</code></li>
<li>Summary: <p>Despite the advances in the field of Face Recognition (FR), the precision of
these methods is not yet sufficient. To improve the FR performance, this paper
proposes a technique to aggregate the outputs of two state-of-the-art (SOTA)
deep FR models, namely ArcFace and AdaFace. In our approach, we leverage the
transformer attention mechanism to exploit the relationship between different
parts of two feature maps. By doing so, we aim to enhance the overall
discriminative power of the FR system. One of the challenges in feature
aggregation is the effective modeling of both local and global dependencies.
Conventional transformers are known for their ability to capture long-range
dependencies, but they often struggle with modeling local dependencies
accurately. To address this limitation, we augment the self-attention mechanism
to capture both local and global dependencies effectively. This allows our
model to take advantage of the overlapping receptive fields present in
corresponding locations of the feature maps. However, fusing two feature maps
from different FR models might introduce redundancies to the face embedding.
Since these models often share identical backbone architectures, the resulting
feature maps may contain overlapping information, which can mislead the
training process. To overcome this problem, we leverage the principle of
Information Bottleneck to obtain a maximally informative facial representation.
This ensures that the aggregated features retain the most relevant and
discriminative information while minimizing redundant or misleading details. To
evaluate the effectiveness of our proposed method, we conducted experiments on
popular benchmarks and compared our results with state-of-the-art algorithms.
The consistent improvement we observed in these benchmarks demonstrates the
efficacy of our approach in enhancing FR performance.
</p></li>
</ul>

<h3>Title: ClusterFormer: Clustering As A Universal Visual Learner. (arXiv:2309.13196v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13196">http://arxiv.org/abs/2309.13196</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13196]] ClusterFormer: Clustering As A Universal Visual Learner(http://arxiv.org/abs/2309.13196)</code></li>
<li>Summary: <p>This paper presents CLUSTERFORMER, a universal vision model that is based on
the CLUSTERing paradigm with TransFORMER. It comprises two novel designs: 1.
recurrent cross-attention clustering, which reformulates the cross-attention
mechanism in Transformer and enables recursive updates of cluster centers to
facilitate strong representation learning; and 2. feature dispatching, which
uses the updated cluster centers to redistribute image features through
similarity-based metrics, resulting in a transparent pipeline. This elegant
design streamlines an explainable and transferable workflow, capable of
tackling heterogeneous vision tasks (i.e., image classification, object
detection, and image segmentation) with varying levels of clustering
granularity (i.e., image-, box-, and pixel-level). Empirical results
demonstrate that CLUSTERFORMER outperforms various well-known specialized
architectures, achieving 83.41% top-1 acc. over ImageNet-1K for image
classification, 54.2% and 47.0% mAP over MS COCO for object detection and
instance segmentation, 52.4% mIoU over ADE20K for semantic segmentation, and
55.8% PQ over COCO Panoptic for panoptic segmentation. For its efficacy, we
hope our work can catalyze a paradigm shift in universal models in computer
vision.
</p></li>
</ul>

<h3>Title: Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation. (arXiv:2309.13237v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13237">http://arxiv.org/abs/2309.13237</a></li>
<li>Code URL: https://github.com/hcplab-sysu/stket</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13237]] Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation(http://arxiv.org/abs/2309.13237)</code></li>
<li>Summary: <p>Video scene graph generation (VidSGG) aims to identify objects in visual
scenes and infer their relationships for a given video. It requires not only a
comprehensive understanding of each object scattered on the whole scene but
also a deep dive into their temporal motions and interactions. Inherently,
object pairs and their relationships enjoy spatial co-occurrence correlations
within each image and temporal consistency/transition correlations across
different images, which can serve as prior knowledge to facilitate VidSGG model
learning and inference. In this work, we propose a spatial-temporal
knowledge-embedded transformer (STKET) that incorporates the prior
spatial-temporal knowledge into the multi-head cross-attention mechanism to
learn more representative relationship representations. Specifically, we first
learn spatial co-occurrence and temporal transition correlations in a
statistical manner. Then, we design spatial and temporal knowledge-embedded
layers that introduce the multi-head cross-attention mechanism to fully explore
the interaction between visual representation and the knowledge to generate
spatial- and temporal-embedded representations, respectively. Finally, we
aggregate these representations for each subject-object pair to predict the
final semantic labels and their relationships. Extensive experiments show that
STKET outperforms current competing algorithms by a large margin, e.g.,
improving the mR@50 by 8.1%, 4.7%, and 2.1% on different settings over current
algorithms.
</p></li>
</ul>

<h3>Title: UniHead: Unifying Multi-Perception for Detection Heads. (arXiv:2309.13242v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13242">http://arxiv.org/abs/2309.13242</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13242]] UniHead: Unifying Multi-Perception for Detection Heads(http://arxiv.org/abs/2309.13242)</code></li>
<li>Summary: <p>The detection head constitutes a pivotal component within object detectors,
tasked with executing both classification and localization functions.
Regrettably, the commonly used parallel head often lacks omni perceptual
capabilities, such as deformation perception, global perception and cross-task
perception. Despite numerous methods attempt to enhance these abilities from a
single aspect, achieving a comprehensive and unified solution remains a
significant challenge. In response to this challenge, we have developed an
innovative detection head, termed UniHead, to unify three perceptual abilities
simultaneously. More precisely, our approach (1) introduces deformation
perception, enabling the model to adaptively sample object features; (2)
proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range
dependencies, thereby achieving global perception; and (3) devises a Cross-task
Interaction Transformer (CIT) that facilitates interaction between the
classification and localization branches, thus aligning the two tasks. As a
plug-and-play method, the proposed UniHead can be conveniently integrated with
existing detectors. Extensive experiments on the COCO dataset demonstrate that
our UniHead can bring significant improvements to many detectors. For instance,
the UniHead can obtain +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor,
and +2.1 AP gains in GFL. The code will be publicly available. Code Url:
https://github.com/zht8506/UniHead.
</p></li>
</ul>

<h3>Title: Automatic Reverse Engineering: Creating computer-aided design (CAD) models from multi-view images. (arXiv:2309.13281v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13281">http://arxiv.org/abs/2309.13281</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13281]] Automatic Reverse Engineering: Creating computer-aided design (CAD) models from multi-view images(http://arxiv.org/abs/2309.13281)</code></li>
<li>Summary: <p>Generation of computer-aided design (CAD) models from multi-view images may
be useful in many practical applications. To date, this problem is usually
solved with an intermediate point-cloud reconstruction and involves manual work
to create the final CAD models. In this contribution, we present a novel
network for an automated reverse engineering task. Our network architecture
combines three distinct stages: A convolutional neural network as the encoder
stage, a multi-view pooling stage and a transformer-based CAD sequence
generator.
</p>
<p>The model is trained and evaluated on a large number of simulated input
images and extensive optimization of model architectures and hyper-parameters
is performed. A proof-of-concept is demonstrated by successfully reconstructing
a number of valid CAD models from simulated test image data. Various accuracy
metrics are calculated and compared to a state-of-the-art point-based network.
</p>
<p>Finally, a real world test is conducted supplying the network with actual
photographs of two three-dimensional test objects. It is shown that some of the
capabilities of our network can be transferred to this domain, even though the
training exclusively incorporates purely synthetic training data. However to
date, the feasible model complexity is still limited to basic shapes.
</p></li>
</ul>

<h3>Title: Document Understanding for Healthcare Referrals. (arXiv:2309.13184v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13184">http://arxiv.org/abs/2309.13184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13184]] Document Understanding for Healthcare Referrals(http://arxiv.org/abs/2309.13184)</code></li>
<li>Summary: <p>Reliance on scanned documents and fax communication for healthcare referrals
leads to high administrative costs and errors that may affect patient care. In
this work we propose a hybrid model leveraging LayoutLMv3 along with
domain-specific rules to identify key patient, physician, and exam-related
entities in faxed referral documents. We explore some of the challenges in
applying a document understanding model to referrals, which have formats
varying by medical practice, and evaluate model performance using MUC-5 metrics
to obtain appropriate metrics for the practical use case. Our analysis shows
the addition of domain-specific rules to the transformer model yields greatly
increased precision and F1 scores, suggesting a hybrid model trained on a
curated dataset can increase efficiency in referral management.
</p></li>
</ul>

<h3>Title: Hindi to English: Transformer-Based Neural Machine Translation. (arXiv:2309.13222v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13222">http://arxiv.org/abs/2309.13222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13222]] Hindi to English: Transformer-Based Neural Machine Translation(http://arxiv.org/abs/2309.13222)</code></li>
<li>Summary: <p>Machine Translation (MT) is one of the most prominent tasks in Natural
Language Processing (NLP) which involves the automatic conversion of texts from
one natural language to another while preserving its meaning and fluency.
Although the research in machine translation has been going on since multiple
decades, the newer approach of integrating deep learning techniques in natural
language processing has led to significant improvements in the translation
quality. In this paper, we have developed a Neural Machine Translation (NMT)
system by training the Transformer model to translate texts from Indian
Language Hindi to English. Hindi being a low resource language has made it
difficult for neural networks to understand the language thereby leading to a
slow growth in the development of neural machine translators. Thus, to address
this gap, we implemented back-translation to augment the training data and for
creating the vocabulary, we experimented with both word and subword level
tokenization using Byte Pair Encoding (BPE) thereby ending up training the
Transformer in 10 different configurations. This led us to achieve a
state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay
English-Hindi Corpus in one of the configurations.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior. (arXiv:2309.13160v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13160">http://arxiv.org/abs/2309.13160</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13160]] GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior(http://arxiv.org/abs/2309.13160)</code></li>
<li>Summary: <p>Variational Autoencoders (VAEs) have become a cornerstone in generative
modeling and representation learning within machine learning. This paper
explores a nuanced aspect of VAEs, focusing on interpreting the Kullback
Leibler (KL) Divergence, a critical component within the Evidence Lower Bound
(ELBO) that governs the trade-off between reconstruction accuracy and
regularization. While the KL Divergence enforces alignment between latent
variable distributions and a prior imposing a structure on the overall latent
space but leaves individual variable distributions unconstrained. The proposed
method redefines the ELBO with a mixture of Gaussians for the posterior
probability, introduces a regularization term to prevent variance collapse, and
employs a PatchGAN discriminator to enhance texture realism. Implementation
details involve ResNetV2 architectures for both the Encoder and Decoder. The
experiments demonstrate the ability to generate realistic faces, offering a
promising solution for enhancing VAE based generative models.
</p></li>
</ul>

<h3>Title: ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education. (arXiv:2309.13243v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13243">http://arxiv.org/abs/2309.13243</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13243]] ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education(http://arxiv.org/abs/2309.13243)</code></li>
<li>Summary: <p>The integration of generative AI in education is expanding, yet empirical
analyses of large-scale, real-world interactions between students and AI
systems still remain limited. In this study, we present ChEDDAR, ChatGPT &amp; EFL
Learner's Dialogue Dataset As Revising an essay, which is collected from a
semester-long longitudinal experiment involving 212 college students enrolled
in English as Foreign Langauge (EFL) writing courses. The students were asked
to revise their essays through dialogues with ChatGPT. ChEDDAR includes a
conversation log, utterance-level essay edit history, self-rated satisfaction,
and students' intent, in addition to session-level pre-and-post surveys
documenting their objectives and overall experiences. We analyze students'
usage patterns and perceptions regarding generative AI with respect to their
intent and satisfaction. As a foundational step, we establish baseline results
for two pivotal tasks in task-oriented dialogue systems within educational
contexts: intent detection and satisfaction estimation. We finally suggest
further research to refine the integration of generative AI into education
settings, outlining potential scenarios utilizing ChEDDAR. ChEDDAR is publicly
available at https://github.com/zeunie/ChEDDAR.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Contextual Emotion Estimation from Image Captions. (arXiv:2309.13136v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13136">http://arxiv.org/abs/2309.13136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13136]] Contextual Emotion Estimation from Image Captions(http://arxiv.org/abs/2309.13136)</code></li>
<li>Summary: <p>Emotion estimation in images is a challenging task, typically using computer
vision methods to directly estimate people's emotions using face, body pose and
contextual cues. In this paper, we explore whether Large Language Models (LLMs)
can support the contextual emotion estimation task, by first captioning images,
then using an LLM for inference. First, we must understand: how well do LLMs
perceive human emotions? And which parts of the information enable them to
determine emotions? One initial challenge is to construct a caption that
describes a person within a scene with information relevant for emotion
perception. Towards this goal, we propose a set of natural language descriptors
for faces, bodies, interactions, and environments. We use them to manually
generate captions and emotion annotations for a subset of 331 images from the
EMOTIC dataset. These captions offer an interpretable representation for
emotion estimation, towards understanding how elements of a scene affect
emotion perception in LLMs and beyond. Secondly, we test the capability of a
large language model to infer an emotion from the resulting image captions. We
find that GPT-3.5, specifically the text-davinci-003 model, provides
surprisingly reasonable emotion predictions consistent with human annotations,
but accuracy can depend on the emotion concept. Overall, the results suggest
promise in the image captioning and LLM approach.
</p></li>
</ul>

<h3>Title: Large Language Models Are Also Good Prototypical Commonsense Reasoners. (arXiv:2309.13165v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13165">http://arxiv.org/abs/2309.13165</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13165]] Large Language Models Are Also Good Prototypical Commonsense Reasoners(http://arxiv.org/abs/2309.13165)</code></li>
<li>Summary: <p>Commonsense reasoning is a pivotal skill for large language models, yet it
presents persistent challenges in specific tasks requiring this competence.
Traditional fine-tuning approaches can be resource-intensive and potentially
compromise a model's generalization capacity. Furthermore, state-of-the-art
language models like GPT-3.5 and Claude are primarily accessible through API
calls, which makes fine-tuning models challenging. To address these challenges,
we draw inspiration from the outputs of large models for tailored tasks and
semi-automatically developed a set of novel prompts from several perspectives,
including task-relevance, supportive evidence generation (e.g. chain-of-thought
and knowledge), diverse path decoding to aid the model. Experimental results on
ProtoQA dataset demonstrate that with better designed prompts we can achieve
the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the Max
Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for the
first time) compared to the previous SOTA model and achieved an improvement on
StrategyQA and CommonsenseQA2.0 (3% and 1%, respectively). Furthermore, with
the generated Chain-of-Thought and knowledge, we can improve the
interpretability of the model while also surpassing the previous SOTA models.
We hope that our work can provide insight for the NLP community to develop
better prompts and explore the potential of large language models for more
complex reasoning tasks.
</p></li>
</ul>

<h3>Title: BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP. (arXiv:2309.13173v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13173">http://arxiv.org/abs/2309.13173</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13173]] BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP(http://arxiv.org/abs/2309.13173)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have emerged as one of the most important
breakthroughs in natural language processing (NLP) for their impressive skills
in language generation and other language-specific tasks. Though LLMs have been
evaluated in various tasks, mostly in English, they have not yet undergone
thorough evaluation in under-resourced languages such as Bengali (Bangla). In
this paper, we evaluate the performance of LLMs for the low-resourced Bangla
language. We select various important and diverse Bangla NLP tasks, such as
abstractive summarization, question answering, paraphrasing, natural language
inference, text classification, and sentiment analysis for zero-shot evaluation
with ChatGPT, LLaMA-2, and Claude-2 and compare the performance with
state-of-the-art fine-tuned models. Our experimental results demonstrate an
inferior performance of LLMs for different Bangla NLP tasks, calling for
further effort to develop better understanding of LLMs in low-resource
languages like Bangla.
</p></li>
</ul>

<h3>Title: Effective Distillation of Table-based Reasoning Ability from LLMs. (arXiv:2309.13182v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13182">http://arxiv.org/abs/2309.13182</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13182]] Effective Distillation of Table-based Reasoning Ability from LLMs(http://arxiv.org/abs/2309.13182)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing tasks. However, their remarkable
parameter size and their impressive high requirement of computing resources
pose challenges for their practical deployment. Recent research has revealed
that specific capabilities of LLMs, such as numerical reasoning, can be
transferred to smaller models through distillation. Some studies explore the
potential of leveraging LLMs to perform table-based reasoning. Nevertheless,
prior to our work, there has been no investigation into the prospect of
specialising table reasoning skills in smaller models specifically tailored for
table-to-text generation tasks. In this paper, we propose a novel table-based
reasoning distillation, with the aim of distilling distilling LLMs into
tailored, smaller models specifically designed for table-based reasoning task.
Experimental results have shown that a 0.22 billion parameter model
(Flan-T5-base) fine-tuned using distilled data, not only achieves a significant
improvement compared to traditionally fine-tuned baselines but also surpasses
specific LLMs like gpt-3.5-turbo on the scientific table-to-text generation
dataset (SciGen). The code and data are released in
https://github.com/Bernard-Yang/TableDistill.
</p></li>
</ul>

<h3>Title: Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts. (arXiv:2309.13202v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13202">http://arxiv.org/abs/2309.13202</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13202]] Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts(http://arxiv.org/abs/2309.13202)</code></li>
<li>Summary: <p>Biomedical literature often uses complex language and inaccessible
professional terminologies. That is why simplification plays an important role
in improving public health literacy. Applying Natural Language Processing (NLP)
models to automate such tasks allows for quick and direct accessibility for lay
readers. In this work, we investigate the ability of state-of-the-art large
language models (LLMs) on the task of biomedical abstract simplification, using
the publicly available dataset for plain language adaptation of biomedical
abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and
prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and
BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT,
and 3) Control-token mechanisms on BART-based models. We used a range of
automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and
also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT)
mechanisms reported the highest SARI score of 46.54 and T5-base reported the
highest BERTscore 72.62. In human evaluation, BART-L-w-CTs achieved a better
simplicity score over T5-Base (2.9 vs. 2.2), while T5-Base achieved a better
meaning preservation score over BART-L-w-CTs (3.1 vs. 2.6). We also categorised
the system outputs with examples, hoping this will shed some light for future
research on this task. Our code, fine-tuned models, and data splits are
available at \url{https://github.com/HECTA-UoM/PLABA-MU}
</p></li>
</ul>

<h3>Title: A Practical Survey on Zero-shot Prompt Design for In-context Learning. (arXiv:2309.13205v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13205">http://arxiv.org/abs/2309.13205</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13205]] A Practical Survey on Zero-shot Prompt Design for In-context Learning(http://arxiv.org/abs/2309.13205)</code></li>
<li>Summary: <p>The remarkable advancements in large language models (LLMs) have brought
about significant improvements in Natural Language Processing(NLP) tasks. This
paper presents a comprehensive review of in-context learning techniques,
focusing on different types of prompts, including discrete, continuous,
few-shot, and zero-shot, and their impact on LLM performance. We explore
various approaches to prompt design, such as manual design, optimization
algorithms, and evaluation methods, to optimize LLM performance across diverse
tasks. Our review covers key research studies in prompt engineering, discussing
their methodologies and contributions to the field. We also delve into the
challenges faced in evaluating prompt performance, given the absence of a
single "best" prompt and the importance of considering multiple metrics. In
conclusion, the paper highlights the critical role of prompt design in
harnessing the full potential of LLMs and provides insights into the
combination of manual design, optimization techniques, and rigorous evaluation
for more effective and efficient use of LLMs in various NLP tasks.
</p></li>
</ul>

<h3>Title: User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue. (arXiv:2309.13233v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13233">http://arxiv.org/abs/2309.13233</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13233]] User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue(http://arxiv.org/abs/2309.13233)</code></li>
<li>Summary: <p>One of the major impediments to the development of new task-oriented dialogue
(TOD) systems is the need for human evaluation at multiple stages and
iterations of the development process. In an effort to move toward automated
evaluation of TOD, we propose a novel user simulator built using recently
developed large pretrained language models (LLMs). In order to increase the
linguistic diversity of our system relative to the related previous work, we do
not fine-tune the LLMs used by our system on existing TOD datasets; rather we
use in-context learning to prompt the LLMs to generate robust and
linguistically diverse output with the goal of simulating the behavior of human
interlocutors. Unlike previous work, which sought to maximize goal success rate
(GSR) as the primary metric of simulator performance, our goal is a system
which achieves a GSR similar to that observed in human interactions with TOD
systems. Using this approach, our current simulator is effectively able to
interact with several TOD systems, especially on single-intent conversational
goals, while generating lexically and syntactically diverse output relative to
previous simulators that rely upon fine-tuned models. Finally, we collect a
Human2Bot dataset of humans interacting with the same TOD systems with which we
experimented in order to better quantify these achievements.
</p></li>
</ul>

<h3>Title: Calibrating LLM-Based Evaluator. (arXiv:2309.13308v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13308">http://arxiv.org/abs/2309.13308</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13308]] Calibrating LLM-Based Evaluator(http://arxiv.org/abs/2309.13308)</code></li>
<li>Summary: <p>Recent advancements in large language models (LLMs) on language modeling and
emergent capabilities make them a promising reference-free evaluator of natural
language generation quality, and a competent alternative to human evaluation.
However, hindered by the closed-source or high computational demand to host and
tune, there is a lack of practice to further calibrate an off-the-shelf
LLM-based evaluator towards better human alignment. In this work, we propose
AutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate
and align an LLM-based evaluator toward human preference. Instead of explicitly
modeling human preferences, we first implicitly encompass them within a set of
human labels. Then, an initial set of scoring criteria is drafted by the
language model itself, leveraging in-context learning on different few-shot
examples. To further calibrate this set of criteria, we select the best
performers and re-draft them with self-refinement. Our experiments on multiple
text quality evaluation datasets illustrate a significant improvement in
correlation with expert evaluation through calibration. Our comprehensive
qualitative analysis conveys insightful intuitions and observations on the
essence of effective scoring criteria.
</p></li>
</ul>

<h3>Title: Topological Data Mapping of Online Hate Speech, Misinformation, and General Mental Health: A Large Language Model Based Study. (arXiv:2309.13098v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13098">http://arxiv.org/abs/2309.13098</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13098]] Topological Data Mapping of Online Hate Speech, Misinformation, and General Mental Health: A Large Language Model Based Study(http://arxiv.org/abs/2309.13098)</code></li>
<li>Summary: <p>The advent of social media has led to an increased concern over its potential
to propagate hate speech and misinformation, which, in addition to contributing
to prejudice and discrimination, has been suspected of playing a role in
increasing social violence and crimes in the United States. While literature
has shown the existence of an association between posting hate speech and
misinformation online and certain personality traits of posters, the general
relationship and relevance of online hate speech/misinformation in the context
of overall psychological wellbeing of posters remain elusive. One difficulty
lies in the lack of adequate data analytics tools capable of adequately
analyzing the massive amount of social media posts to uncover the underlying
hidden links. Recent progresses in machine learning and large language models
such as ChatGPT have made such an analysis possible. In this study, we
collected thousands of posts from carefully selected communities on the social
media site Reddit. We then utilized OpenAI's GPT3 to derive embeddings of these
posts, which are high-dimensional real-numbered vectors that presumably
represent the hidden semantics of posts. We then performed various
machine-learning classifications based on these embeddings in order to
understand the role of hate speech/misinformation in various communities.
Finally, a topological data analysis (TDA) was applied to the embeddings to
obtain a visual map connecting online hate speech, misinformation, various
psychiatric disorders, and general mental health.
</p></li>
</ul>

<h3>Title: Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation. (arXiv:2309.13192v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13192">http://arxiv.org/abs/2309.13192</a></li>
<li>Code URL: https://github.com/pittisl/greentrainer</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13192]] Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation(http://arxiv.org/abs/2309.13192)</code></li>
<li>Summary: <p>Fine-tuning is the most effective way of adapting pre-trained large language
models (LLMs) to downstream applications. With the fast growth of LLM-enabled
AI applications and democratization of open-souced LLMs, fine-tuning has become
possible for non-expert individuals, but intensively performed LLM fine-tuning
worldwide could result in significantly high energy consumption and carbon
footprint, which may bring large environmental impact. Mitigating such
environmental impact towards Green AI directly correlates to reducing the FLOPs
of fine-tuning, but existing techniques on efficient LLM fine-tuning can only
achieve limited reduction of such FLOPs, due to their ignorance of the
backpropagation cost in fine-tuning. To address this limitation, in this paper
we present GreenTrainer, a new LLM fine-tuning technique that adaptively
evaluates different tensors' backpropagation costs and contributions to the
fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the
most appropriate set of tensors in training. Such selection in GreenTrainer is
made based on a given objective of FLOPs reduction, which can flexibly adapt to
the carbon footprint in energy supply and the need in Green AI. Experiment
results over multiple open-sourced LLM models and abstractive summarization
datasets show that, compared to fine-tuning the whole LLM model, GreenTrainer
can save up to 64% FLOPs in fine-tuning without any noticeable model accuracy
loss. Compared to the existing fine-tuning techniques such as LoRa,
GreenTrainer can achieve up to 4% improvement on model accuracy with on-par
FLOPs reduction.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and Siamese Decoders. (arXiv:2309.13235v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13235">http://arxiv.org/abs/2309.13235</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13235]] M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and Siamese Decoders(http://arxiv.org/abs/2309.13235)</code></li>
<li>Summary: <p>Masked point modeling has become a promising scheme of self-supervised
pre-training for point clouds. Existing methods reconstruct either the original
points or related features as the objective of pre-training. However,
considering the diversity of downstream tasks, it is necessary for the model to
have both low- and high-level representation modeling capabilities to capture
geometric details and semantic contexts during pre-training. To this end,
M$^3$CS is proposed to enable the model with the above abilities. Specifically,
with masked point cloud as input, M$^3$CS introduces two decoders to predict
masked representations and the original points simultaneously. While an extra
decoder doubles parameters for the decoding process and may lead to
overfitting, we propose siamese decoders to keep the amount of learnable
parameters unchanged. Further, we propose an online codebook projecting
continuous tokens into discrete ones before reconstructing masked points. In
such way, we can enforce the decoder to take effect through the combinations of
tokens rather than remembering each token. Comprehensive experiments show that
M$^3$CS achieves superior performance at both classification and segmentation
tasks, outperforming existing methods.
</p></li>
</ul>

<h3>Title: Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation. (arXiv:2309.13248v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13248">http://arxiv.org/abs/2309.13248</a></li>
<li>Code URL: https://github.com/kfan21/eoras</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13248]] Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation(http://arxiv.org/abs/2309.13248)</code></li>
<li>Summary: <p>Video amodal segmentation is a particularly challenging task in computer
vision, which requires to deduce the full shape of an object from the visible
parts of it. Recently, some studies have achieved promising performance by
using motion flow to integrate information across frames under a
self-supervised setting. However, motion flow has a clear limitation by the two
factors of moving cameras and object deformation. This paper presents a
rethinking to previous works. We particularly leverage the supervised signals
with object-centric representation in \textit{real-world scenarios}. The
underlying idea is the supervision signal of the specific object and the
features from different views can mutually benefit the deduction of the full
mask in any specific frame. We thus propose an Efficient object-centric
Representation amodal Segmentation (EoRaS). Specially, beyond solely relying on
supervision signals, we design a translation module to project image features
into the Bird's-Eye View (BEV), which introduces 3D information to improve
current feature quality. Furthermore, we propose a multi-view fusion layer
based temporal module which is equipped with a set of object slots and
interacts with features from different views by attention mechanism to fulfill
sufficient object representation completion. As a result, the full mask of the
object can be decoded from image features updated by object slots. Extensive
experiments on both real-world and synthetic benchmarks demonstrate the
superiority of our proposed method, achieving state-of-the-art performance. Our
code will be released at \url{https://github.com/kfan21/EoRaS}.
</p></li>
</ul>

<h3>Title: Randomize to Generalize: Domain Randomization for Runway FOD Detection. (arXiv:2309.13264v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13264">http://arxiv.org/abs/2309.13264</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13264]] Randomize to Generalize: Domain Randomization for Runway FOD Detection(http://arxiv.org/abs/2309.13264)</code></li>
<li>Summary: <p>Tiny Object Detection is challenging due to small size, low resolution,
occlusion, background clutter, lighting conditions and small object-to-image
ratio. Further, object detection methodologies often make underlying assumption
that both training and testing data remain congruent. However, this presumption
often leads to decline in performance when model is applied to
out-of-domain(unseen) data. Techniques like synthetic image generation are
employed to improve model performance by leveraging variations in input data.
Such an approach typically presumes access to 3D-rendered datasets. In
contrast, we propose a novel two-stage methodology Synthetic Randomized Image
Augmentation (SRIA), carefully devised to enhance generalization capabilities
of models encountering 2D datasets, particularly with lower resolution which is
more practical in real-world scenarios. The first stage employs a weakly
supervised technique to generate pixel-level segmentation masks. Subsequently,
the second stage generates a batch-wise synthesis of artificial images,
carefully designed with an array of diverse augmentations. The efficacy of
proposed technique is illustrated on challenging foreign object debris (FOD)
detection. We compare our results with several SOTA models including CenterNet,
SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit on a publicly available FOD-A
dataset. We also construct an out-of-distribution test set encompassing 800
annotated images featuring a corpus of ten common categories. Notably, by
harnessing merely 1.81% of objects from source training data and amalgamating
with 29 runway background images, we generate 2227 synthetic images. Subsequent
model retraining via transfer learning, utilizing enriched dataset generated by
domain randomization, demonstrates significant improvement in detection
accuracy. We report that detection accuracy improved from an initial 41% to 92%
for OOD test set.
</p></li>
</ul>

<h3>Title: Discwise Active Learning for LiDAR Semantic Segmentation. (arXiv:2309.13276v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13276">http://arxiv.org/abs/2309.13276</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13276]] Discwise Active Learning for LiDAR Semantic Segmentation(http://arxiv.org/abs/2309.13276)</code></li>
<li>Summary: <p>While LiDAR data acquisition is easy, labeling for semantic segmentation
remains highly time consuming and must therefore be done selectively. Active
learning (AL) provides a solution that can iteratively and intelligently label
a dataset while retaining high performance and a low budget. In this work we
explore AL for LiDAR semantic segmentation. As a human expert is a component of
the pipeline, a practical framework must consider common labeling techniques
such as sequential labeling that drastically improve annotation times. We
therefore propose a discwise approach (DiAL), where in each iteration, we query
the region a single frame covers on global coordinates, labeling all frames
simultaneously. We then tackle the two major challenges that emerge with
discwise AL. Firstly we devise a new acquisition function that takes 3D point
density changes into consideration which arise due to location changes or
ego-vehicle motion. Next we solve a mixed-integer linear program that provides
a general solution to the selection of multiple frames while taking into
consideration the possibilities of disc intersections. Finally we propose a
semi-supervised learning approach to utilize all frames within our dataset and
improve performance.
</p></li>
</ul>

<h3>Title: USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation. (arXiv:2309.13289v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13289">http://arxiv.org/abs/2309.13289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13289]] USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation(http://arxiv.org/abs/2309.13289)</code></li>
<li>Summary: <p>Unsupervised skin lesion segmentation offers several benefits, including
conserving expert human resources, reducing discrepancies due to subjective
human labeling, and adapting to novel environments. However, segmenting
dermoscopic images without manual labeling guidance presents significant
challenges due to dermoscopic image artifacts such as hair noise, blister
noise, and subtle edge differences. To address these challenges, we introduce
an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin
lesion segmentation. The USL-Net can effectively segment a range of lesions,
eliminating the need for manual labeling guidance. Initially, features are
extracted using contrastive learning, followed by the generation of Class
Activation Maps (CAMs) as saliency maps using these features. The different CAM
locations correspond to the importance of the lesion region based on their
saliency. High-saliency regions in the map serve as pseudo-labels for lesion
regions while low-saliency regions represent the background. However,
intermediate regions can be hard to classify, often due to their proximity to
lesion edges or interference from hair or blisters. Rather than risk potential
pseudo-labeling errors or learning confusion by forcefully classifying these
regions, we consider them as uncertainty regions, exempting them from
pseudo-labeling and allowing the network to self-learn. Further, we employ
connectivity detection and centrality detection to refine foreground
pseudo-labels and reduce noise-induced errors. The application of cycle
refining enhances performance further. Our method underwent thorough
experimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets,
demonstrating that its performance is on par with weakly supervised and
supervised methods, and exceeds that of other existing unsupervised methods.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
